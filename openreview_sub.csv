,conference,year,paper,authors,emails,ratings,confidences,decisions,cmt_before_review,cmt_between,cmt_after_decision,double_blinded,submission_date,institution,keywords,csranking,ranking,gender,regions,COO,theorem,categories_list
0,ICLR,2017,Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,Danica J. Sutherland;Hsiao-Yu Tung;Heiko Strathmann;Soumyajit De;Aaditya Ramdas;Alex Smola;Arthur Gretton,dsuth@cs.ubc.ca;htung@cs.cmu.edu;heiko.strathmann@gmail.com;soumyajitde.cse@gmail.com;aramdas@berkeley.edu;alex@smola.org;arthur.gretton@gmail.com,6;8;7,3;3;4,Accept (Poster),2,3,1.0,no,11/4/16,University of British Columbia;Carnegie Mellon University;Google;;University of California Berkeley;Carnegie-Mellon University;University College London,Unsupervised Learning,67;1;-1;-1;-1;1;-1,36;23;-1;-1;10;23;-1,-1;-1,usa,usa,y,5;4
1,ICLR,2017,A Simple but Tough-to-Beat Baseline for Sentence Embeddings,Sanjeev Arora;Yingyu Liang;Tengyu Ma,arora@cs.princeton.edu;yingyul@cs.princeton.edu;tengyu@cs.princeton.edu,7;7;8,4;4;3,Accept (Poster),8,4,0.0,no,11/4/16,Princeton University;Princeton University;Princeton University,Natural language processing;Unsupervised Learning,46;46;46,7;7;7,-1;-1,usa,usa,n,6;3;5
2,ICLR,2017,A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks,Dan Hendrycks;Kevin Gimpel,dan@ttic.edu;kgimpel@ttic.edu,6;6;6,3;3;3,Accept (Poster),2,4,0.0,no,11/4/16,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,Computer vision,-1;-1,380;380,-1;-1,NAN,NAN,n,2;3
3,ICLR,2017,MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset,Tri Nguyen;Mir Rosenberg;Xia Song;Jianfeng Gao;Saurabh Tiwary;Rangan Majumder;Li Deng,trnguye@microsoft.com;miriamr@microsoft.com;xiaso@microsoft.com;jfgao@microsoft.com;satiwary@microsoft.com;ranganm@microsoft.com;deng@microsoft.com,6;6;6,3;3,Reject,3,2,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
4,ICLR,2017,Dynamic Steerable Frame Networks,J√∂rn-Henrik Jacobsen;Bert De Brabandere;Arnold W.M. Smeulders,j.jacobsen@uva.nl;bert.debrabandere@esat.kuleuven.be;a.w.m.smeulders@uva.nl,5;4;7,4;3;3,Reject,1,4,0.0,no,11/4/16,University of Amsterdam;KU Leuven;University of Amsterdam,Computer vision;Deep learning,92;149;92,63;40;63,-1;-1,europe,nl,n,8
5,ICLR,2017,FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS,Xingyi Li;Fuxin Li;Xiaoli Fern;Raviv Raich,lixin@eecs.oregonstate.edu;lif@eecs.oregonstate.edu;xfern@eecs.oregonstate.edu;raich@eecs.oregonstate.edu,6;7;7,4;3;4,Accept (Poster),2,5,0.0,no,11/5/16,Oregon State University;Oregon State University;Oregon State University;Oregon State University,,67;67;67;67,316;316;316;316,-1;-1,usa,usa,y,
6,ICLR,2017, A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Samples,Beilun Wang;Ji Gao;Yanjun Qi,bw4mw@virginia.edu;jg6yd@virginia.edu;yanjun@virginia.edu,5;3;5,2;4;4,Invite to Workshop Track,8,21,0.0,no,11/4/16,University of Virginia;University of Virginia;University of Virginia,Deep learning,46;46;46,123;123;123,-1;-1,usa,usa,y,1;4
7,ICLR,2017,Efficient Vector Representation for Documents through Corruption,Minmin Chen,m.chen@criteo.com,6;7;7,4;3;4,Accept (Poster),2,8,3.0,no,11/5/16,Criteo,Natural language processing;Deep learning;Semi-Supervised Learning,-1,-1,-1,NAN,NAN,n,3
8,ICLR,2017,Adversarial Training Methods for Semi-Supervised Text Classification,Takeru Miyato;Andrew M. Dai;Ian Goodfellow,takeru.miyato@gmail.com;adai@google.com;ian@openai.com,6;7;7,4;3;5,Accept (Poster),1,4,0.0,no,11/3/16,"Preferred Networks, Inc.;Google;OpenAI",Natural language processing;Deep learning;Semi-Supervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;4
9,ICLR,2017,Neural Architecture Search with Reinforcement Learning,Barret Zoph;Quoc Le,barretzoph@google.com;qvl@google.com,9;9;9,4;4;5,Accept (Oral),8,8,4.0,no,11/4/16,Google;Google,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
10,ICLR,2017,Decomposing Motion and Content for Natural Video Sequence Prediction,Ruben Villegas;Jimei Yang;Seunghoon Hong;Xunyu Lin;Honglak Lee,rubville@umich.edu;jimyang@adobe.com;maga33@postech.ac.kr;timelin@buaa.edu.cn;honglak@umich.edu,7;7;6,5;4;4,Accept (Poster),5,4,4.0,no,11/4/16,University of Michigan;Adobe Systems;POSTECH;Beihang University;University of Michigan,Computer vision;Deep learning;Unsupervised Learning,11;-1;92;92;11,21;-1;104;-1;21,-1;-1,usa,usa,n,
11,ICLR,2017,Maximum Entropy Flow Networks,Gabriel Loaiza-Ganem *;Yuanjun Gao *;John P. Cunningham,gl2480@columbia.edu;yg2312@columbia.edu;jpc2181@columbia.edu,6;6;9,4;4;5,Accept (Poster),2,4,1.0,no,11/4/16,Columbia University;Columbia University;Columbia University,,31;31;31,16;16;16,-1;-1,usa,usa,n,2
12,ICLR,2017,beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework,Irina Higgins;Loic Matthey;Arka Pal;Christopher Burgess;Xavier Glorot;Matthew Botvinick;Shakir Mohamed;Alexander Lerchner,irinah@google.com;lmatthey@google.com;arkap@google.com;cpburgess@google.com;glorotx@google.com;botvinick@google.com;shakir@google.com;lerchner@google.com,5;7;6,4;4;4,Accept (Poster),2,4,0.0,no,11/4/16,Google;Google;Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
13,ICLR,2017,Soft Weight-Sharing for Neural Network Compression,Karen Ullrich;Edward Meeds;Max Welling,karen.ullrich@uva.nl;tmeeds@gmail.com;welling.max@gmail.com,7;7;7,3;4;3,Accept (Poster),3,2,1.0,no,11/4/16,"University of Amsterdam;;University of California, Irvine",Deep learning;Optimization,92;-1;-1,63;-1;99,-1;-1,usa,usa,n,
14,ICLR,2017,Support Regularized Sparse Coding and Its Fast Encoder,Yingzhen Yang;Jiahui Yu;Pushmeet Kohli;Jianchao Yang;Thomas S. Huang,superyyzg@gmail.com;jyu79@illinois.edu;pkohli@microsoft.com;jianchao.yang@snapchat.com;t-huang1@illinois.edu,6;7;7,3;4;4,Accept (Poster),1,4,0.0,no,11/4/16,"Independent Researcher;University of Illinois, Urbana Champaign;Microsoft;Snap Inc.;University of Illinois, Urbana Champaign",,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,y,
15,ICLR,2017,Stochastic Neural Networks for Hierarchical Reinforcement Learning,Carlos Florensa;Yan Duan;Pieter Abbeel,florensa@berkeley.edu;rocky@openai.com;pieter@openai.com,7;7;8,4;4;4,Accept (Poster),0,8,1.0,no,11/5/16,University of California Berkeley;OpenAI;OpenAI,Deep learning;Unsupervised Learning;Reinforcement Learning,-1;-1;-1,10;-1;-1,-1;-1,NAN,NAN,n,
16,ICLR,2017,Combining policy gradient and Q-learning,Brendan O'Donoghue;Remi Munos;Koray Kavukcuoglu;Volodymyr Mnih,bodonoghue@google.com;munos@google.com;korayk@google.com;vmnih@google.com,9;7;7,5;3;4,Accept (Poster),15,4,0.0,no,11/4/16,Google;Google;Google;Google,Deep learning;Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
17,ICLR,2017,Recurrent Environment Simulators,Silvia Chiappa;S√©bastien Racaniere;Daan Wierstra;Shakir Mohamed,csilvia@google.com;sracaniere@google.com;wierstra@google.com;shakir@google.com,7;5;8,5;4;4,Accept (Poster),3,5,0.0,no,11/4/16,Google;Google;Google;Google,Deep learning;Unsupervised Learning;Applications,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
18,ICLR,2017,Multi-Agent Cooperation and the Emergence of (Natural) Language,Angeliki Lazaridou;Alexander Peysakhovich;Marco Baroni,angeliki.lazaridou@unitn.it;alexpeys@fb.com;marco.baroni@unitn.it,7;7;7,3;3;3,Accept (Oral),0,3,7.0,no,11/4/16,University of Trento;Facebook;University of Trento,Natural language processing;Reinforcement Learning;Games,149;-1;149,236;-1;236,-1;-1,europe,gr,n,3
19,ICLR,2017,Stick-Breaking Variational Autoencoders,Eric Nalisnick;Padhraic Smyth,enalisni@uci.edu;smyth@ics.uci.edu,4;8;8,4;4;5,Accept (Poster),6,7,0.0,no,11/4/16,"University of California, Irvine;University of California, Irvine",Deep learning;Unsupervised Learning;Semi-Supervised Learning,-1;-1,99;99,-1;-1,usa,usa,n,11;5
20,ICLR,2017,Sigma Delta Quantized Networks,Peter O'Connor;Max Welling,peter.ed.oconnor@gmail.com;max.welling@uva.nl,8;6;8,4;3;4,Accept (Poster),3,2,0.0,no,11/4/16,University of Amsterdam;University of Amsterdam,Computer vision;Deep learning;Applications,-1;92,-1;63,-1;-1,europe,nl,n,
21,ICLR,2017,Semi-supervised deep learning by metric embedding,Elad Hoffer;Nir Ailon,ehoffer@tx.technion.ac.il;nailon@cs.technion.ac.il,4;6,4;4,Invite to Workshop Track,1,3,0.0,no,11/4/16,"Technion, Technion;Technion, Technion",Deep learning;Semi-Supervised Learning,22;22,-1;-1,-1;-1,NAN,NAN,n,
22,ICLR,2017,Adversarial Feature Learning,Jeff Donahue;Philipp Kr√§henb√ºhl;Trevor Darrell,jdonahue@cs.berkeley.edu;philkr@utexas.edu;trevor@eecs.berkeley.edu,7;7;7,3;3;4,Accept (Poster),2,1,1.0,no,11/4/16,"University of California Berkeley;University of Texas, Austin;University of California Berkeley",,-1;-1;-1,10;-1;10,-1;-1,usa,usa,y,5;4
23,ICLR,2017,Learning Visual Servoing with Deep Features and Fitted Q-Iteration,Alex X. Lee;Sergey Levine;Pieter Abbeel,alexlee_gk@cs.berkeley.edu;svlevine@cs.berkeley.edu;pabbeel@cs.berkeley.edu,8;7;7,3;4;3,Accept (Poster),3,0,0.0,no,11/5/16,University of California Berkeley;University of California Berkeley;University of California Berkeley,Computer vision;Deep learning;Reinforcement Learning,-1;-1;-1,10;10;10,-1;-1,usa,usa,n,1
24,ICLR,2017,Learning End-to-End Goal-Oriented Dialog,Antoine Bordes;Y-Lan Boureau;Jason Weston,abordes@fb.com;ylan@fb.com;jase@fb.com,7;8;8,4;5;4,Accept (Oral),3,5,0.0,no,11/4/16,Facebook;Facebook;Facebook,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
25,ICLR,2017,Learning Graphical State Transitions,Daniel D. Johnson,ddjohnson@hmc.edu,9;7;9,3;2;3,Accept (Oral),6,6,0.0,no,10/29/16,Harvey Mudd College,Natural language processing;Deep learning;Supervised Learning;Structured prediction,-1,-1,-1,NAN,NAN,n,8;10
26,ICLR,2017,Revisiting Classifier Two-Sample Tests,David Lopez-Paz;Maxime Oquab,dlp@fb.com;qas@fb.com,7;8;7,3;5;4,Accept (Poster),6,6,0.0,no,11/4/16,Facebook;Facebook,Theory;Unsupervised Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,y,5;4
27,ICLR,2017,Mollifying Networks,Caglar Gulcehre;Marcin Moczulski;Francesco Visin;Yoshua Bengio,gulcehrc@iro.umontreal.ca;marcin-m@post.pl;fvisin@gmail.com;yoshua.umontreal@gmail.com,7;6;6,5;4;4,Accept (Poster),3,3,0.0,no,11/4/16,University of Montreal;University of Oxford;;University of Montreal,Deep learning;Optimization,92;31;-1;92,103;1;-1;103,-1;-1,canada,ca,n,9;4
28,ICLR,2017,Introspection:Accelerating Neural Network Training By Learning Weight Evolution,Abhishek Sinha;Aahitagni Mukherjee;Mausoom Sarkar;Balaji Krishnamurthy,abhishek.sinha94@gmail.com;ahitagnimukherjeeam@gmail.com;msarkar@adobe.com;kbalaji@adobe.com,8;7;9,5;4;5,Accept (Poster),3,10,0.0,no,11/4/16,Stanford University;;Adobe Systems;Adobe Systems,Computer vision;Deep learning;Optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
29,ICLR,2017,Neural Program Lattices,Chengtao Li;Daniel Tarlow;Alexander L. Gaunt;Marc Brockschmidt;Nate Kushman,ctli@mit.edu;dtarlow@microsoft.com;algaunt@microsoft.com;mabrocks@microsoft.com;nkushman@microsoft.com,4;7;7,4;4;5,Accept (Poster),3,5,0.0,no,11/4/16,Massachusetts Institute of Technology;Microsoft;Microsoft;Microsoft;Microsoft,Deep learning;Semi-Supervised Learning,9;-1;-1;-1;-1,5;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
30,ICLR,2017,Highway and Residual Networks learn Unrolled Iterative Estimation,Klaus Greff;Rupesh K. Srivastava;J√ºrgen Schmidhuber,klaus@idsia.ch;rupesh@idsia.ch;juergen@idsia.ch,7;8;6,4;4;5,Accept (Poster),0,3,0.0,no,11/5/16,IDSIA;IDSIA;IDSIA,Theory;Deep learning;Supervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,n,
31,ICLR,2017,Hadamard Product for Low-rank Bilinear Pooling,Jin-Hwa Kim;Kyoung-Woon On;Woosang Lim;Jeonghee Kim;Jung-Woo Ha;Byoung-Tak Zhang,jnhwkim@snu.ac.kr;kwon@bi.snu.ac.kr;quasar17@kaist.ac.kr;jeonghee.kim@navercorp.com;jungwoo.ha@navercorp.com;btzhang@bi.snu.ac.kr,7;7;6,3;5;3,Accept (Poster),2,13,0.0,no,10/17/16,Seoul National University;Seoul National University;Korea Advanced Institute of Science and Technology;NAVER;NAVER;Seoul National University,Deep learning;Supervised Learning;Multi-modal learning,46;46;-1;-1;-1;46,72;72;88;-1;-1;72,-1;-1,asia,kr,n,8;2
32,ICLR,2017,Machine Comprehension Using Match-LSTM and Answer Pointer,Shuohang Wang;Jing Jiang,shwang.2014@phdis.smu.edu.sg;jingjiang@smu.edu.sg,7;6;6,3;4;3,Accept (Poster),4,5,0.0,no,11/4/16,Singapore Management University;Singapore Management University,Natural language processing;Deep learning,67;67,-1;-1,-1;-1,asia,sg,n,3
33,ICLR,2017,Unsupervised Cross-Domain Image Generation,Yaniv Taigman;Adam Polyak;Lior Wolf,yaniv@fb.com;adampolyak@fb.com;wolf@fb.com,7;6;7,3;3;4,Accept (Poster),18,8,1.0,no,11/4/16,Facebook;Facebook;Facebook,Computer vision;Deep learning;Unsupervised Learning;Transfer Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
34,ICLR,2017,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,Hakan Inan;Khashayar Khosravi;Richard Socher,inanh@stanford.edu;khosravi@stanford.edu;rsocher@salesforce.com,6;7;8,4;4;4,Accept (Poster),6,4,0.0,no,11/4/16,Stanford University;Stanford University;SalesForce.com,Natural language processing;Deep learning,3;3;-1,3;3;-1,-1;-1,NAN,NAN,n,3
35,ICLR,2017,Making Neural Programming Architectures Generalize via Recursion,Jonathon Cai;Richard Shin;Dawn Song,jonathon@cs.berkeley.edu;ricshin@cs.berkeley.edu;dawnsong@cs.berkeley.edu,8;8;9,4;3;5,Accept (Oral),1,5,1.0,no,11/5/16,University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep learning,-1;-1;-1,10;10;10,-1;-1,usa,usa,n,1
36,ICLR,2017,Generative Multi-Adversarial Networks,Ishan Durugkar;Ian Gemp;Sridhar Mahadevan,idurugkar@cs.umass.edu;imgemp@cs.umass.edu;mahadeva@cs.umass.edu,7;6;7,4;4;3,Accept (Poster),7,6,0.0,no,11/4/16,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",Deep learning;Unsupervised Learning;Games,15;15;15,166;166;166,-1;-1,usa,usa,n,5;4
37,ICLR,2017,Variational Recurrent Adversarial Deep Domain Adaptation,Sanjay Purushotham;Wilka Carvalho;Tanachat Nilanon;Yan Liu,spurusho@usc.edu;wcarvalh@usc.edu;nilanon@usc.edu;yanliu.cs@usc.edu,6;5;6,4;4;4,Accept (Poster),3,4,0.0,no,11/4/16,University of Southern California;University of Southern California;University of Southern California;University of Southern California,Deep learning;Transfer Learning,22;22;22;22,60;60;60;60,-1;-1,usa,usa,n,4
38,ICLR,2017,Data Noising as Smoothing in Neural Network Language Models,Ziang Xie;Sida I. Wang;Jiwei Li;Daniel L√©vy;Aiming Nie;Dan Jurafsky;Andrew Y. Ng,zxie@cs.stanford.edu;sidaw@cs.stanford.edu;jiweil@stanford.edu;danilevy@cs.stanford.edu;anie@cs.stanford.edu;jurafsky@stanford.edu;ang@cs.stanford.edu,6;6;8,4;4,Accept (Poster),2,3,0.0,no,11/4/16,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Natural language processing;Deep learning,3;3;3;3;3;3;3,3;3;3;3;3;3;3,-1;-1,usa,usa,n,3
39,ICLR,2017,Deep Probabilistic Programming,Dustin Tran;Matthew D. Hoffman;Rif A. Saurous;Eugene Brevdo;Kevin Murphy;David M. Blei,dustin@cs.columbia.edu;mathoffm@adobe.com;rif@google.com;ebrevdo@google.com;kpmurphy@google.com;david.blei@columbia.edu,5;8;7,4;4;4,Accept (Poster),2,4,0.0,no,11/4/16,Columbia University;Adobe Systems;Google;Google;Google;Columbia University,,31;-1;-1;-1;-1;31,16;-1;-1;-1;-1;16,-1;-1,usa,usa,n,5;4
40,ICLR,2017,Hierarchical Multiscale Recurrent Neural Networks,Junyoung Chung;Sungjin Ahn;Yoshua Bengio,junyoung.chung@umontreal.ca;sungjin.ahn@umontreal.ca;yoshua.bengio@umontreal.ca,8;7;8,4;3;4,Accept (Poster),2,3,0.0,no,10/29/16,University of Montreal;University of Montreal;University of Montreal,Natural language processing;Deep learning,92;92;92,103;103;103,-1;-1,canada,ca,n,3
41,ICLR,2017,Programming With a Differentiable Forth Interpreter,Matko Bo≈°njak;Tim Rockt√§schel;Jason Naradowsky;Sebastian Riedel,m.bosnjak@cs.ucl.ac.uk;t.rocktaschel@cs.ucl.ac.uk;j.narad@cs.ucl.ac.uk;s.riedel@cs.ucl.ac.uk,7;5;6,2;2;4,Invite to Workshop Track,1,4,1.0,no,11/4/16,University College London;University College London;University College London;University College London,,31;31;31;31,-1;-1;-1;-1,-1;-1,europe,uk,n,10
42,ICLR,2017,Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening,Frank S.He;Yang Liu;Alexander G. Schwing;Jian Peng,frankheshibi@gmail.com;liu301@illinois.edu;aschwing@illinois.edu;jianpeng@illinois.edu,9;4;9,3;4;4,Accept (Poster),10,9,0.0,no,11/4/16,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Reinforcement Learning;Optimization;Games,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,n,
43,ICLR,2017,Energy-based Generative Adversarial Networks,Junbo Zhao;Michael Mathieu;Yann LeCun,jakezhao@cs.nyu.edu;mathieu@cs.nyu.edu;yann@cs.nyu.edu,8;7;7,3;5;3,Accept (Poster),4,5,0.0,no,11/4/16,New York University;New York University;New York University,Deep learning;Unsupervised Learning;Semi-Supervised Learning,22;22;22,32;32;32,-1;-1,usa,usa,y,5;4
44,ICLR,2017,Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes,Mengye Ren;Renjie Liao;Raquel Urtasun;Fabian H. Sinz;Richard S. Zemel,mren@cs.toronto.edu;rjliao@cs.toronto.edu;urtasun@cs.toronto.edu;fabian.sinz@epagoge.de;zemel@cs.toronto.edu,7;5;9,4;4;5,Accept (Poster),0,7,1.0,no,11/5/16,University of Toronto;University of Toronto;University of Toronto;University of Goettingen;University of Toronto,,22;22;22;286;22,22;22;22;112;22,-1;-1,canada,ca,n,3
45,ICLR,2017,Learning through Dialogue Interactions by Asking Questions,Jiwei Li;Alexander H. Miller;Sumit Chopra;Marc'Aurelio Ranzato;Jason Weston,jiwel@fb.com;ahm@fb.com;spchopra@fb.com;ranzato@fb.com;jase@fb.com,7;8;7,3;5;3,Accept (Poster),4,9,0.0,no,11/4/16,Facebook;Facebook;Facebook;Facebook;Facebook,Natural language processing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
46,ICLR,2017,Third Person Imitation Learning,Bradly C Stadie;Pieter Abbeel;Ilya Sutskever,bstadie@openai.com;pieter@openai.com;ilyasu@openai.com,6;5;6,4;3;4,Accept (Poster),2,4,0.0,no,11/4/16,OpenAI;OpenAI;OpenAI,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
47,ICLR,2017,The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables,Chris J. Maddison;Andriy Mnih;Yee Whye Teh,cmaddis@stats.ox.ac.uk;amnih@google.com;y.w.teh@stats.ox.ac.uk,7;9;8,3;5;4,Accept (Poster),4,1,0.0,no,11/4/16,University of Oxford;Google;University of Oxford,Deep learning;Unsupervised Learning;Structured prediction,31;-1;31,1;-1;1,-1;-1,europe,uk,y,10
48,ICLR,2017,Pruning Convolutional Neural Networks for Resource Efficient Inference,Pavlo Molchanov;Stephen Tyree;Tero Karras;Timo Aila;Jan Kautz,pmolchanov@nvidia.com;styree@nvidia.com;tkarras@nvidia.com;taila@nvidia.com;jkautz@nvidia.com,7;6;9,4;4;4,Accept (Poster),5,6,0.0,no,11/4/16,NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA,Deep learning;Transfer Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;1
49,ICLR,2017,Adaptive Feature Abstraction for Translating Video to Language,Yunchen Pu;Martin Renqiang Min;Zhe Gan;Lawrence Carin,yunchen.pu@duke.edu;renqiang@nec-labs.com;zhe.gan@duke.edu;lcarin@duke.edu,4;4;7,5;4;4,Invite to Workshop Track,6,7,0.0,no,11/4/16,Duke University;NEC-Labs;Duke University;Duke University,Computer vision;Deep learning,22;-1;22;22,18;-1;18;18,-1;-1,europe,se,n,8
50,ICLR,2017,Learning Recurrent Representations for Hierarchical Behavior Modeling,Eyrun Eyjolfsdottir;Kristin Branson;Yisong Yue;Pietro Perona,eeyjolfs@caltech.edu;bransonk@janelia.hhmi.org;yyue@caltech.edu;perona@caltech.edu,7;6;7,3;4;4,Accept (Poster),3,7,0.0,no,11/3/16,California Institute of Technology;HHMI Janelia Research Campus;California Institute of Technology;California Institute of Technology,Unsupervised Learning;Semi-Supervised Learning;Reinforcement Learning;Applications,92;-1;92;92,2;-1;2;2,-1;-1,usa,usa,n,7;5
51,ICLR,2017,Generalizing Skills with Semi-Supervised Reinforcement Learning,Chelsea Finn;Tianhe Yu;Justin Fu;Pieter Abbeel;Sergey Levine,cbfinn@eecs.berkeley.edu;tianhe.yu@berkeley.edu;justinfu@eecs.berkeley.edu;pabbeel@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,6;7;8,5;3;4,Accept (Poster),2,0,0.0,no,11/4/16,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Reinforcement Learning,-1;-1;-1;-1;-1,10;10;10;10;10,-1;-1,usa,usa,n,1
52,ICLR,2017,Entropy-SGD: Biasing Gradient Descent Into Wide Valleys,Pratik Chaudhari;Anna Choromanska;Stefano Soatto;Yann LeCun;Carlo Baldassi;Christian Borgs;Jennifer Chayes;Levent Sagun;Riccardo Zecchina,pratikac@ucla.edu;achoroma@cims.nyu.edu;soatto@cs.ucla.edu;yann@cs.nyu.edu;carlo.baldassi@polito.it;borgs@microsoft.com;jchayes@microsoft.com;sagun@cims.nyu.edu;riccardo.zecchina@polito.it,7;8;9,4;4;3,Accept (Poster),4,13,0.0,no,11/4/16,"University of California, Los Angeles;New York University;University of California, Los Angeles;New York University;Politecnico di Torino;Microsoft;Microsoft;New York University;Politecnico di Torino",Deep learning;Optimization,-1;22;-1;22;-1;-1;-1;22;-1,14;32;14;32;-1;-1;-1;32;-1,-1;-1,NAN,NAN,y,1
53,ICLR,2017,Tree-structured decoding with doubly-recurrent neural networks,David Alvarez-Melis;Tommi S. Jaakkola,dalvmel@mit.edu;tommi@csail.mit.edu,7;6;6,4;4;4,Accept (Poster),3,10,0.0,no,11/4/16,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Natural language processing;Supervised Learning;Structured prediction,9;9,5;5,-1;-1,usa,usa,n,
54,ICLR,2017,A Compositional Object-Based Approach to Learning Physical Dynamics,Michael Chang;Tomer Ullman;Antonio Torralba;Joshua Tenenbaum,mbchang@mit.edu;tomeru@mit.edu;torralba@mit.edu;jbt@mit.edu,9;6;7,4;4;4,Accept (Poster),6,6,0.0,no,11/4/16,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deep learning;Unsupervised Learning,9;9;9;9,5;5;5;5,-1;-1,usa,usa,n,
55,ICLR,2017,"Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain",Janarthanan Rajendran;Aravind Lakshminarayanan;Mitesh M. Khapra;Prasanna P;Balaraman Ravindran,rjana@umich.edu;aravindsrinivas@gmail.com;miteshk@cse.iitm.ac.in;prasanna.p@cs.mcgill.ca;ravi@cse.iitm.ac.in,7;7;7,4;3;4,Accept (Poster),1,5,0.0,no,11/4/16,University of Michigan;;Indian Institute of Technology Madras;McGill University;Indian Institute of Technology Madras,Deep learning;Reinforcement Learning;Transfer Learning,11;-1;-1;92;-1,21;-1;472;42;472,-1;-1,NAN,NAN,n,
56,ICLR,2017,Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses,Eleanor Batty;Josh Merel;Nora Brackbill;Alexander Heitman;Alexander Sher;Alan Litke;E.J. Chichilnisky;Liam Paninski,erb2180@columbia.edu;jsmerel@gmail.com;nbrack@stanford.edu;alexkenheitmen@gmail.com;sashake3@uscs.edu;Alan.Litke@cern.ch;ej@stanford.edu;liam@stat.columbia.edu,8;7;4,5;4;4,Accept (Poster),2,5,0.0,no,11/5/16,Columbia University;Google;Stanford University;;;CERN;Stanford University;Columbia University,Deep learning;Applications,31;-1;3;-1;-1;-1;3;31,16;-1;3;-1;-1;-1;3;16,-1;-1,usa,usa,n,5
57,ICLR,2017,LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation,Jianwei Yang;Anitha Kannan;Dhruv Batra;Devi Parikh,jw2yang@vt.edu;akannan@fb.com;dbatra@gatech.edu;parikh@gatech.edu,6;6;7,3;4,Accept (Poster),5,5,0.0,no,11/4/16,Virginia Tech;Facebook;Georgia Institute of Technology;Georgia Institute of Technology,Computer vision;Deep learning;Unsupervised Learning,67;-1;11;11,-1;-1;33;33,-1;-1,usa,usa,n,5;4
58,ICLR,2017,Learning to Optimize,Ke Li;Jitendra Malik,ke.li@eecs.berkeley.edu;malik@eecs.berkeley.edu,7;6;7,4;4;4,Accept (Poster),5,5,1.0,no,11/4/16,University of California Berkeley;University of California Berkeley,Reinforcement Learning;Optimization,-1;-1,10;10,-1;-1,usa,usa,n,
59,ICLR,2017,Variational Lossy Autoencoder,Xi Chen;Diederik P. Kingma;Tim Salimans;Yan Duan;Prafulla Dhariwal;John Schulman;Ilya Sutskever;Pieter Abbeel,peter@openai.com;dpkingma@openai.com;tim@openai.com;rocky@openai.com;prafulla@mit.edu;joschu@openai.com;ilyasu@openai.com;pieter@openai.com,7;7;6,4;4;4,Accept (Poster),8,8,0.0,no,11/4/16,OpenAI;OpenAI;OpenAI;OpenAI;Massachusetts Institute of Technology;OpenAI;OpenAI;OpenAI,Deep learning;Unsupervised Learning,-1;-1;-1;-1;9;-1;-1;-1,-1;-1;-1;-1;5;-1;-1;-1,-1;-1,NAN,NAN,n,5
60,ICLR,2017,Improving Generative Adversarial Networks with Denoising Feature Matching,David Warde-Farley;Yoshua Bengio,d.warde.farley@gmail.com;yoshua.umontreal@gmail.com,7;6;7,4;2;5,Accept (Poster),5,4,0.0,no,11/5/16,Google;University of Montreal,Deep learning;Unsupervised Learning,-1;92,-1;103,-1;-1,canada,ca,n,5;4
61,ICLR,2017,Emergence of foveal image sampling from learning to attend in visual scenes,Brian Cheung;Eric Weiss;Bruno Olshausen,bcheung@berkeley.edu;eaweiss@berkeley.edu;baolshausen@berkeley.edu,6;5;6,4;4;5,Accept (Poster),3,3,0.0,no,11/5/16,University of California Berkeley;University of California Berkeley;University of California Berkeley,Computer vision;Deep learning;Supervised Learning,-1;-1;-1,10;10;10,-1;-1,usa,usa,n,8
62,ICLR,2017,Words or Characters? Fine-grained Gating for Reading Comprehension,Zhilin Yang;Bhuwan Dhingra;Ye Yuan;Junjie Hu;William W. Cohen;Ruslan Salakhutdinov,zhiliny@cs.cmu.edu;bdhingra@andrew.cmu.edu;yey1@andrew.cmu.edu;junjieh@cmu.edu;wcohen@cs.cmu.edu;rsalakhu@cs.cmu.edu,7;6;7,4;4;3,Accept (Poster),2,0,2.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Natural language processing;Deep learning,1;1;1;1;1;1,23;23;23;23;23;23,-1;-1,usa,usa,n,
63,ICLR,2017,Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks,Zhilin Yang;Ruslan Salakhutdinov;William W. Cohen,zhiliny@cs.cmu.edu;rsalakhu@cs.cmu.edu;wcohen@cs.cmu.edu,7;5;8,4;4;4,Accept (Poster),2,5,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Natural language processing;Deep learning;Transfer Learning,1;1;1,23;23;23,-1;-1,usa,usa,n,6
64,ICLR,2017,Bidirectional Attention Flow for Machine Comprehension,Minjoon Seo;Aniruddha Kembhavi;Ali Farhadi;Hannaneh Hajishirzi,minjoon@cs.washington.edu;anik@allenai.org;alif@allenai.org;hannaneh@cs.washington.edu,7;8;8,5;4;5,Accept (Poster),10,7,2.0,no,11/4/16,University of Washington;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;University of Washington,Natural language processing;Deep learning,5;-1;-1;5,25;-1;-1;25,-1;-1,usa,usa,n,8
65,ICLR,2017,Query-Reduction Networks for Question Answering,Minjoon Seo;Sewon Min;Ali Farhadi;Hannaneh Hajishirzi,minjoon@cs.washington.edu;shmsw25@snu.ac.kr;ali@cs.washington.edu;hannaneh@cs.washington.edu,7;7;7,3;4;4,Accept (Poster),7,2,1.0,no,11/4/16,University of Washington;Seoul National University;University of Washington;University of Washington,Natural language processing;Deep learning,5;46;5;5,25;72;25;25,-1;-1,usa,usa,n,
66,ICLR,2017,Training Compressed Fully-Connected Networks with a Density-Diversity Penalty,Shengjie Wang;Haoran Cai;Jeff Bilmes;William Noble,wangsj@cs.washington.edu;haoran@uw.edu;bilmes@uw.edu;william-noble@u.washington.edu,9;6;6,4;4;2,Accept (Poster),5,10,0.0,no,11/4/16,"University of Washington;University of Washington, Seattle;University of Washington, Seattle;University of Washington",Deep learning,5;5;5;5,25;25;25;25,-1;-1,usa,usa,n,
67,ICLR,2017,Do Deep Convolutional Nets Really Need to be Deep and Convolutional?,Gregor Urban;Krzysztof J. Geras;Samira Ebrahimi Kahou;Ozlem Aslan;Shengjie Wang;Abdelrahman Mohamed;Matthai Philipose;Matt Richardson;Rich Caruana,gurban@uci.edu;k.j.geras@sms.ed.ac.uk;samira.ebrahimi-kahou@polymtl.ca;ozlem@cs.ualberta.ca;wangsj@cs.washington.edu;asamir@microsoft.com;matthaip@microsoft.com;mattri@microsoft.com;rcaruana@microsoft.com,7;7,3;4,Accept (Poster),2,4,0.0,no,11/4/16,"University of California, Irvine;University of Edinburgh;Polytechnique Montreal;University of Alberta;University of Washington;Microsoft;Microsoft;Microsoft;Microsoft",Deep learning;Transfer Learning,-1;31;286;92;5;-1;-1;-1;-1,99;27;-1;106;25;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
68,ICLR,2017,Recurrent Hidden Semi-Markov Model,Hanjun Dai;Bo Dai;Yan-Ming Zhang;Shuang Li;Le Song,hanjundai@gatech.edu;bodai@gatech.edu;ymzhang@nlpr.ia.ac.cn;sli370@gatech.edu;lsong@cc.gatech.edu,7;7;7,4;3;4,Accept (Poster),2,3,0.0,no,11/4/16,"Georgia Institute of Technology;Georgia Institute of Technology;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Georgia Institute of Technology;Georgia Institute of Technology",Deep learning;Unsupervised Learning;Structured prediction,11;11;31;11;11,33;33;-1;33;33,-1;-1,usa,usa,n,2;5
69,ICLR,2017,Lie-Access Neural Turing Machines,Greg Yang;Alexander Rush,gyang@college.harvard.edu;srush@seas.harvard.edu,6;7;6;8,4;4;3;4,Accept (Poster),4,6,0.0,no,11/4/16,Harvard University;Harvard University,Natural language processing;Deep learning;Supervised Learning,46;46,6;6,-1;-1,usa,usa,n,1
70,ICLR,2017,What does it take to generate natural textures?,Ivan Ustyuzhaninov *;Wieland Brendel *;Leon Gatys;Matthias Bethge,ivan.ustyuzhaninov@bethgelab.org;wieland.brendel@bethgelab.org;leon.gatys@bethgelab.org;matthias.bethge@bethgelab.org,7;8;8,4;3;5,Accept (Poster),2,3,0.0,no,11/5/16,"Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge",Deep learning;Unsupervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
71,ICLR,2017,Tracking the World State with Recurrent Entity Networks,Mikael Henaff;Jason Weston;Arthur Szlam;Antoine Bordes;Yann LeCun,mbh305@nyu.edu;jase@fb.com;azslam@fb.com;abordes@fb.com;yann@fb.com,7;7;7,3;5;4,Accept (Poster),6,4,0.0,no,11/4/16,New York University;Facebook;Facebook;Facebook;Facebook,Natural language processing;Deep learning,22;-1;-1;-1;-1,32;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
72,ICLR,2017,Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning,Yuxin Wu;Yuandong Tian,ppwwyyxx@gmail.com;yuandong@fb.com,6;4;7,4;5;4,Accept (Poster),1,4,3.0,no,11/4/16,Facebook;Facebook,Reinforcement Learning;Applications;Games,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
73,ICLR,2017,Deep Biaffine Attention for Neural Dependency Parsing,Timothy Dozat;Christopher D. Manning,tdozat@stanford.edu;manning@stanford.edu,5;5;6,4;4;4,Accept (Poster),9,1,2.0,no,11/4/16,Stanford University;Stanford University,Natural language processing;Deep learning,3;3,3;3,-1;-1,usa,usa,n,8;10
74,ICLR,2017,Learning Curve Prediction with Bayesian Neural Networks,Aaron Klein;Stefan Falkner;Jost Tobias Springenberg;Frank Hutter,kleinaa@cs.uni-freiburg.de;sfalkner@cs.uni-freiburg.de;springj@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,7;7;7,4;4;5,Accept (Poster),3,3,0.0,no,11/4/16,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Deep learning;Applications,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,11
75,ICLR,2017,Deep Information Propagation,Samuel S. Schoenholz;Justin Gilmer;Surya Ganguli;Jascha Sohl-Dickstein,schsam@google.com;gilmer@google.com;sganguli@stanford.edu;jaschasd@google.com,8;9;8,2;4;3,Accept (Poster),0,3,0.0,no,11/4/16,Google;Google;Stanford University;Google,Theory;Deep learning,-1;-1;3;-1,-1;-1;3;-1,-1;-1,NAN,NAN,n,1
76,ICLR,2017,Pruning Filters for Efficient ConvNets,Hao Li;Asim Kadav;Igor Durdanovic;Hanan Samet;Hans Peter Graf,haoli@cs.umd.edu;asim@nec-labs.com;igord@nec-labs.com;hjs@cs.umd.edu;hpg@nec-labs.com,6;7;7;7,5;4;5;4,Accept (Poster),0,6,0.0,no,11/5/16,"University of Maryland, College Park;NEC-Labs;NEC-Labs;University of Maryland, College Park;NEC-Labs",Computer vision;Deep learning,11;-1;-1;11;-1,67;-1;-1;67;-1,-1;-1,NAN,NAN,n,
77,ICLR,2017,SGDR: Stochastic Gradient Descent with Warm Restarts,Ilya Loshchilov;Frank Hutter,ilya@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,7;7;7,3;4;5,Accept (Poster),2,2,0.0,no,11/4/16,Universit√§t Freiburg;Universit√§t Freiburg,Deep learning;Optimization,-1;-1,-1;-1,-1;-1,NAN,NAN,n,9
78,ICLR,2017,Program Synthesis for Character Level Language Modeling,Pavol Bielik;Veselin Raychev;Martin Vechev,pavol.bielik@inf.ethz.ch;veselin.raychev@inf.ethz.ch;martin.vechev@inf.ethz.ch,5;8;8,3;2;4,Accept (Poster),2,4,0.0,no,11/4/16,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
79,ICLR,2017,Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning,Abhishek Gupta;Coline Devin;YuXuan Liu;Pieter Abbeel;Sergey Levine,abhigupta@berkeley.edu;coline@berkeley.edu;yuxuanliu@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,7;6;6,3;5;4,Accept (Poster),3,6,0.0,no,11/5/16,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep learning;Reinforcement Learning;Transfer Learning,-1;-1;-1;-1;-1,10;10;10;10;10,-1;-1,usa,usa,n,6
80,ICLR,2017,On the Quantitative Analysis of Decoder-Based Generative Models,Yuhuai Wu;Yuri Burda;Ruslan Salakhutdinov;Roger Grosse,ywu@cs.toronto.edu;yburda@openai.com;rsalakhu@cs.cmu.edu;rgrosse@cs.toronto.edu,7;7;6,4;4;5,Accept (Poster),3,9,0.0,no,11/4/16,University of Toronto;OpenAI;Carnegie Mellon University;University of Toronto,Deep learning;Unsupervised Learning,22;-1;1;22,22;-1;23;22,-1;-1,canada,ca,n,5;4
81,ICLR,2017,Tighter bounds lead to improved classifiers,Nicolas Le Roux,nicolas@le-roux.name,6;8;4,4;5;4,Accept (Poster),0,3,1.0,no,11/2/16,0,,,,-1,NAN,NAN,n,1
82,ICLR,2017,Topology and Geometry of Half-Rectified Network Optimization,C. Daniel Freeman;Joan Bruna,daniel.freeman@berkeley.edu;bruna@cims.nyu.edu,2;7;8,5;3;3,Accept (Poster),5,5,0.0,no,11/4/16,University of California Berkeley;New York University,Theory;Deep learning,-1;22,10;32,-1;-1,usa,usa,y,1
83,ICLR,2017,Quasi-Recurrent Neural Networks,James Bradbury;Stephen Merity;Caiming Xiong;Richard Socher,james.bradbury@salesforce.com;smerity@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,6;7;7,4;4;4,Accept (Poster),2,5,0.0,no,11/4/16,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,Natural language processing;Deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
84,ICLR,2017,Pointer Sentinel Mixture Models,Stephen Merity;Caiming Xiong;James Bradbury;Richard Socher,smerity@salesforce.com;cxiong@salesforce.com;james.bradbury@salesforce.com;rsocher@salesforce.com,7;8;8,4;4;4,Accept (Poster),2,2,0.0,no,11/3/16,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,Natural language processing;Deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
85,ICLR,2017,Learning to Generate Samples from Noise through Infusion Training,Florian Bordes;Sina Honari;Pascal Vincent,florian.bordes@umontreal.ca;sina.honari@umontreal.ca;pascal.vincent@umontreal.ca,8;7;6,5;5;4,Accept (Poster),2,6,0.0,no,11/5/16,University of Montreal;University of Montreal;University of Montreal,Deep learning;Unsupervised Learning,92;92;92,103;103;103,-1;-1,canada,ca,n,5;4
86,ICLR,2017,EPOpt: Learning Robust Neural Network Policies Using Model Ensembles,Aravind Rajeswaran;Sarvjeet Ghotra;Balaraman Ravindran;Sergey Levine,aravraj@cs.washington.edu;sarvjeet.13it236@nitk.edu.in;ravi@cse.iitm.ac.in;svlevine@eecs.berkeley.edu,8;7;7,4;4,Accept (Poster),2,1,0.0,no,11/4/16,University of Washington;National Institute of Technology Karnataka;Indian Institute of Technology Madras;University of California Berkeley,Reinforcement Learning;Applications,5;-1;-1;-1,25;-1;472;10,-1;-1,usa,usa,n,11;4
87,ICLR,2017,Steerable CNNs,Taco S. Cohen;Max Welling,taco.cohen@gmail.com;m.welling@uva.nl,6;7;8,3;4;3,Accept (Poster),6,4,0.0,no,11/4/16,University of Amsterdam;University of Amsterdam,,-1;92,-1;63,-1;-1,europe,nl,n,1
88,ICLR,2017,Learning to Perform Physics Experiments via Deep Reinforcement Learning,Misha Denil;Pulkit Agrawal;Tejas D Kulkarni;Tom Erez;Peter Battaglia;Nando de Freitas,mdenil@google.com;pulkitag@berkeley.edu;tkulkarni@google.com;etom@google.com;peterbattaglia@google.com;nandodefreitas@google.com,7;7;6;7,4;3;3;3,Accept (Poster),3,6,0.0,no,11/4/16,Google;University of California Berkeley;Google;Google;Google;Google,Deep learning;Reinforcement Learning,-1;-1;-1;-1;-1;-1,-1;10;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
89,ICLR,2017,The Neural Noisy Channel,Lei Yu;Phil Blunsom;Chris Dyer;Edward Grefenstette;Tomas Kocisky,lei.yu@cs.ox.ac.uk;pblunsom@google.com;cdyer@google.com;etg@google.com;tkocisky@google.com,7;7;6,4;4;4,Accept (Poster),3,4,0.0,no,11/4/16,University of Oxford;Google;Google;Google;Google,Natural language processing;Deep learning;Semi-Supervised Learning,31;-1;-1;-1;-1,1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
90,ICLR,2017,Learning to Compose Words into Sentences with Reinforcement Learning,Dani Yogatama;Phil Blunsom;Chris Dyer;Edward Grefenstette;Wang Ling,dyogatama@google.com;pblunsom@google.com;cdyer@google.com;etg@google.com;lingwang@google.com,6;7;8,3;5;4,Accept (Poster),15,1,0.0,no,11/4/16,Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
91,ICLR,2017,Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data,Nicolas Papernot;Mart√≠n Abadi;√ölfar Erlingsson;Ian Goodfellow;Kunal Talwar,ngp5056@cse.psu.edu;abadi@google.com;ulfar@google.com;ian@openai.com;kunal@google.com,9;7;9,4;3;4,Accept (Oral),6,9,0.0,no,11/2/16,Pennsylvania State University;Google;Google;OpenAI;Google,,31;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,5
92,ICLR,2017,Diet Networks: Thin Parameters for Fat Genomics,Adriana Romero;Pierre Luc Carrier;Akram Erraqabi;Tristan Sylvain;Alex Auvolat;Etienne Dejoie;Marc-Andr√© Legault;Marie-Pierre Dub√©;Julie G. Hussin;Yoshua Bengio,adriana.romero.soriano@umontreal.ca;pierre-luc.carrier@umontreal.ca;akram.er-raqabi@umontreal.ca;Tristan.sylvain@umontreal.ca;alexis211@gmail.com;etiennedejoie@gmail.com;marc-andre.legault.1@umontreal.ca;julieh@well.ox.ac.uk;yoshua.umontreal@gmail.com,6;7;8,4;3;3,Accept (Poster),2,12,0.0,no,11/4/16,University of Montreal;University of Montreal;University of Montreal;University of Montreal;;;University of Montreal;University of Oxford;University of Montreal,Deep learning;Unsupervised Learning;Supervised Learning;Applications,92;92;92;92;-1;-1;92;31;92,103;103;103;103;-1;-1;103;1;103,-1;-1,canada,ca,n,
93,ICLR,2017,Autoencoding Variational Inference For Topic Models,Akash Srivastava;Charles Sutton,akash.srivastava@ed.ac.uk;csutton@inf.ed.ac.uk,6;7;6,4;3;5,Accept (Poster),9,8,0.0,no,11/4/16,University of Edinburgh;University of Edinburgh,Deep learning;Unsupervised Learning;Applications;Optimization,31;31,27;27,-1;-1,europe,uk,n,
94,ICLR,2017,Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data,Maximilian Karl;Maximilian Soelch;Justin Bayer;Patrick van der Smagt,karlma@in.tum.de;m.soelch@tum.de;bayer.justin@googlemail.com;smagt@brml.org,6;7;6,4;3;3,Accept (Poster),2,5,0.0,no,11/4/16,"Technical University Munich;Technical University Munich;Machine Learning Research Lab, Volkswagen Group;Machine Learning Research Lab, Volkswagen Group",Deep learning;Unsupervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
95,ICLR,2017,Why Deep Neural Networks for Function Approximation?,Shiyu Liang;R. Srikant,sliang26@illinois.edu;rsrikant@illinois.edu,7;7;7,4;4;3,Accept (Poster),2,3,0.0,no,11/1/16,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1,-1;-1,-1;-1,usa,usa,y,
96,ICLR,2017,Reinforcement Learning with Unsupervised Auxiliary Tasks,Max Jaderberg;Volodymyr Mnih;Wojciech Marian Czarnecki;Tom Schaul;Joel Z Leibo;David Silver;Koray Kavukcuoglu,jaderberg@google.com;vmnih@google.com;lejlot@google.com;schaul@google.com;jzl@google.com;davidsilver@google.com;korayk@google.com,7;8;8,4;4;4,Accept (Oral),12,4,0.0,no,11/4/16,Google;Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
97,ICLR,2017,Improving Policy Gradient by Exploring Under-appreciated Rewards,Ofir Nachum;Mohammad Norouzi;Dale Schuurmans,ofirnachum@google.com;mnorouzi@google.com;schuurmans@google.com,7;8;7,4;4;4,Accept (Poster),5,4,3.0,no,11/4/16,Google;Google;Google,Reinforcement Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
98,ICLR,2017,Mode Regularized Generative Adversarial Networks,Tong Che;Yanran Li;Athul Jacob;Yoshua Bengio;Wenjie Li,tong.che@umontreal.ca;csyli@comp.polyu.edu.hk;ap.jacob@umontreal.ca;yoshua.bengio@umontreal.ca;cswjli@comp.polyu.edu.hk,4;7;7,4;4;4,Accept (Poster),9,11,0.0,no,11/5/16,University of Montreal;The Hong Kong Polytechnic University;University of Montreal;University of Montreal;The Hong Kong Polytechnic University,Deep learning;Unsupervised Learning,92;92;92;92;92,103;192;103;103;192,-1;-1,asia,hk,n,5;4
99,ICLR,2017,An Actor-Critic Algorithm for Sequence Prediction,Dzmitry Bahdanau;Philemon Brakel;Kelvin Xu;Anirudh Goyal;Ryan Lowe;Joelle Pineau;Aaron Courville;Yoshua Bengio,dimabgv@gmail.com;pbpop3@gmail.com;iamkelvinxu@gmail.com;anirudhgoyal9119@gmail.com;lowe.ryan.t@gmail.com;jpineau@cs.mcgill.ca;aaron.courville@gmail.com;yoshua.bengio@gmail.com,4;8;8,4;5;4,Accept (Poster),5,9,0.0,no,11/2/16,Element AI;Google;University of California Berkeley;;McGill University;McGill University;University of Montreal;University of Montreal,Natural language processing;Deep learning;Reinforcement Learning;Structured prediction,-1;-1;-1;-1;92;92;92;-1,-1;-1;10;-1;42;42;103;-1,-1;-1,asia,in,n,3
100,ICLR,2017,Trusting SVM for Piecewise Linear CNNs,Leonard Berrada;Andrew Zisserman;M. Pawan Kumar,lberrada@robots.ox.ac.uk;az@robots.ox.ac.uk;pawan@robots.ox.ac.uk,5;4;6,4;4;4,Accept (Poster),1,4,0.0,no,11/4/16,University of Oxford;University of Oxford;University of Oxford,,31;31;31,1;1;1,-1;-1,europe,uk,y,
101,ICLR,2017,End-to-end Optimized Image Compression,Johannes Ball√©;Valero Laparra;Eero P. Simoncelli,johannes.balle@nyu.edu;valero.laparra@uv.es;eero.simoncelli@nyu.edu,8;9;8;8,4;4;4;3,Accept (Oral),3,3,0.0,no,11/5/16,New York University;Universitat de Val√®ncia;New York University,,22;-1;22,32;-1;32,-1;-1,usa,usa,n,5
102,ICLR,2017,"Snapshot Ensembles: Train 1, Get M for Free",Gao Huang;Yixuan Li;Geoff Pleiss;Zhuang Liu;John E. Hopcroft;Kilian Q. Weinberger,gh349@cornell.edu;yl2363@cornell.edu;geoff@cs.cornell.edu;liuzhuangthu@gmail.com;jeh@cs.cornell.edu;kqw4@cornell.edu,9;7;8,4;5;3,Accept (Poster),8,17,0.0,no,11/4/16,Cornell University;Cornell University;Cornell University;University of California Berkeley;Cornell University;Cornell University,Deep learning;Computer vision,5;5;5;-1;5;5,19;19;19;10;19;19,-1;-1,usa,usa,n,
103,ICLR,2017,Learning Features of Music From Scratch,John Thickstun;Zaid Harchaoui;Sham Kakade,thickstn@cs.washington.edu;sham@cs.washington.edu;zaid@uw.edu,8;6;6,4;4;4,Accept (Poster),3,3,0.0,no,11/4/16,"University of Washington;University of Washington;University of Washington, Seattle",Applications,5;5;5,25;25;25,-1;-1,NAN,NAN,n,
104,ICLR,2017,DeepCoder: Learning to Write Programs,Matej Balog;Alexander L. Gaunt;Marc Brockschmidt;Sebastian Nowozin;Daniel Tarlow,matej.balog@gmail.com;t-algaun@microsoft.com;mabrocks@microsoft.com;Sebastian.Nowozin@microsoft.com;dtarlow@microsoft.com,6;6;7,4;4;2,Accept (Poster),7,7,0.0,no,11/4/16,University of Cambridge;Microsoft;Microsoft;Microsoft;Microsoft,Deep learning;Supervised Learning;Applications;Structured prediction,67;-1;-1;-1;-1,4;-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
105,ICLR,2017,A Compare-Aggregate Model for Matching Text Sequences,Shuohang Wang;Jing Jiang,shwang.2014@phdis.smu.edu.sg;jingjiang@smu.edu.sg,6;7;8,4;5;5,Accept (Poster),4,4,0.0,no,11/4/16,Singapore Management University;Singapore Management University,Natural language processing;Deep learning,67;67,-1;-1,-1;-1,asia,sg,n,3
106,ICLR,2017,Automatic Rule Extraction from Long Short Term Memory Networks,W. James Murdoch;Arthur Szlam,jmurdoch@berkeley.edu;aszlam@fb.com,7;7;7,4;3;3,Accept (Poster),1,5,2.0,no,11/4/16,University of California Berkeley;Facebook,Natural language processing;Deep learning;Applications,-1;-1,10;-1,-1;-1,NAN,NAN,n,3
107,ICLR,2017,Capacity and Trainability in Recurrent Neural Networks,Jasmine Collins;Jascha Sohl-Dickstein;David Sussillo,jlcollins@google.com;jaschasd@google.com;sussillo@google.com,8;7;8,4;4;4,Accept (Poster),1,5,0.0,no,11/4/16,Google;Google;Google,Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1
108,ICLR,2017,Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning,Sahil Sharma;Aravind S. Lakshminarayanan;Balaraman Ravindran,ssahil08@gmail.com;aravindsrinivas@gmail.com;ravi@cse.iitm.ac.in,8;7;8,5;3;4,Accept (Poster),4,6,1.0,no,11/4/16,Indian Institute of Technology Madras;;Indian Institute of Technology Madras,Deep learning;Reinforcement Learning,-1;-1;-1,472;-1;472,-1;-1,NAN,NAN,n,
109,ICLR,2017,Multi-view Recurrent Neural Acoustic Word Embeddings,Wanjia He;Weiran Wang;Karen Livescu,wanjia@ttic.edu;weiranwang@ttic.edu;klivescu@ttic.edu,5;6;6,4;4;3,Accept (Poster),2,1,0.0,no,11/4/16,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,,-1;-1;-1,380;380;380,-1;-1,NAN,NAN,n,3
110,ICLR,2017,Neuro-Symbolic Program Synthesis,Emilio Parisotto;Abdel-rahman Mohamed;Rishabh Singh;Lihong Li;Dengyong Zhou;Pushmeet Kohli,eparisot@andrew.cmu.edu;asamir@microsoft.com;risin@microsoft.com;lihongli@microsoft.com;denzho@microsoft.com;pkohli@microsoft.com,5;7;8,4;3;4,Accept (Poster),2,4,0.0,no,11/4/16,Carnegie Mellon University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Deep learning;Structured prediction,1;-1;-1;-1;-1;-1,23;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
111,ICLR,2017,Learning to Remember Rare Events,Lukasz Kaiser;Ofir Nachum;Aurko Roy;Samy Bengio,lukaszkaiser@google.com;ofirnachum@google.com;aurko@gatech.edu;bengio@google.com,6;8;7,5;3;4,Accept (Poster),4,3,0.0,no,11/4/16,Google;Google;Georgia Institute of Technology;Google,Deep learning,-1;-1;11;-1,-1;-1;33;-1,-1;-1,NAN,NAN,n,3
112,ICLR,2017,Discrete Variational Autoencoders,Jason Tyler Rolfe,jrolfe@dwavesys.com,8;9;8,2;4;4,Accept (Poster),9,8,0.0,no,11/4/16,D-Wave Systems,Deep learning;Unsupervised Learning,-1,-1,-1,NAN,NAN,n,5
113,ICLR,2017,Understanding Trainable Sparse Coding with Matrix Factorization,Thomas Moreau;Joan Bruna,thomas.moreau@cmla.ens-cachan.fr;joan.bruna@berkeley.edu,6;8;5,3;4;2,Accept (Poster),1,3,0.0,no,11/2/16,ENS Paris-Saclay;University of California Berkeley,Theory;Deep learning;Optimization,-1;-1,-1;10,-1;-1,usa,usa,y,1
114,ICLR,2017,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts",Xiaoxiao Guo;Tim Klinger;Clemens Rosenbaum;Joseph P. Bigus;Murray Campbell;Ban Kawas;Kartik Talamadupula;Gerry Tesauro;Satinder   Singh,tklinger@us.ibm.com;guoxiao@umich.edu;cgbr@cs.umass.edu;jbigus@us.ibm.com;mcam@us.ibm.com;bkawas@us.ibm.com;krtalamad@us.ibm.com;gtesauro@us.ibm.com;baveja@umich.edu,6;7;7,3;4;3,Accept (Poster),5,2,0.0,no,11/4/16,"International Business Machines;University of Michigan;University of Massachusetts, Amherst;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Michigan",Natural language processing;Deep learning;Reinforcement Learning,-1;11;15;-1;-1;-1;-1;-1;11,-1;21;166;-1;-1;-1;-1;-1;21,-1;-1,usa,usa,n,
115,ICLR,2017,Variable Computation in Recurrent Neural Networks,Yacine Jernite;Edouard Grave;Armand Joulin;Tomas Mikolov,yacine.jernite@nyu.edu;egrave@fb.com;ajoulin@fb.com;tmikolov@fb.com,7;7;4,4;4;5,Accept (Poster),2,6,0.0,no,11/4/16,New York University;Facebook;Facebook;Facebook,Natural language processing;Deep learning,22;-1;-1;-1,32;-1;-1;-1,-1;-1,NAN,NAN,n,8
116,ICLR,2017,Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks,Stefan Depeweg;Jos√© Miguel Hern√°ndez-Lobato;Finale Doshi-Velez;Steffen Udluft,stefan.depeweg@siemens.com;jmh233@cam.ac.uk;finale@seas.harvard.edu;steffen.udluft@siemens.com,7;6;7,3;3;3,Accept (Poster),2,4,0.0,no,11/4/16,Siemens Corporate Research;University of Cambridge;Harvard University;Siemens Corporate Research,Deep learning;Reinforcement Learning,-1;67;46;-1,-1;4;6;-1,-1;-1,NAN,NAN,n,11
117,ICLR,2017,Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU,Mohammad Babaeizadeh;Iuri Frosio;Stephen Tyree;Jason Clemons;Jan Kautz,mb2@uiuc.edu;ifrosio@nvidia.com;styree@nvidia.com;jclemons@nvidia.com;jkautz@nvidia.com,5;7;8,5;5;3,Accept (Poster),7,2,0.0,no,11/4/16,"University of Illinois, Urbana-Champaign;NVIDIA;NVIDIA;NVIDIA;NVIDIA",Reinforcement Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
118,ICLR,2017,Reasoning with Memory Augmented Neural Networks for Language Comprehension,Tsendsuren Munkhdalai;Hong Yu,tsendsuren.munkhdalai@umassmed.edu;hong.yu@umassmed.edu,7;6;7,2;3;4,Accept (Poster),1,6,0.0,no,11/3/16,UMass;UMass,Natural language processing;Deep learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
119,ICLR,2017,Learning a Natural Language Interface with Neural Programmer,Arvind Neelakantan;Quoc V. Le;Martin Abadi;Andrew McCallum;Dario Amodei,arvind@cs.umass.edu;qvl@google.com;abadi@google.com;mccallum@cs.umass.edu;damodei@openai.com,7;6;6,3;3;4,Accept (Poster),3,6,1.0,no,11/4/16,"University of Massachusetts, Amherst;Google;Google;University of Massachusetts, Amherst;OpenAI",Natural language processing;Deep learning,15;-1;-1;15;-1,166;-1;-1;166;-1,-1;-1,NAN,NAN,n,3
120,ICLR,2017,Loss-aware Binarization of Deep Networks,Lu Hou;Quanming Yao;James T. Kwok,lhouab@cse.ust.hk;qyaoaa@cse.ust.hk;jamesk@cse.ust.hk,7;7;7,3;4;3,Accept (Poster),1,14,0.0,no,11/4/16,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Deep learning;Applications;Optimization,-1;-1;-1,48;48;48,-1;-1,NAN,NAN,y,
121,ICLR,2017,Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization,Lisha Li;Kevin Jamieson;Giulia DeSalvo;Afshin Rostamizadeh;Ameet Talwalkar,lishal@cs.ucla.edu;kjamieson@berkeley.edu;desalvo@cims.nyu.edu;rostami@google.com;ameet@cs.ucla.edu,8;7;7,4;5;4,Accept (Poster),3,4,1.0,no,11/4/16,"University of California, Los Angeles;University of California Berkeley;New York University;Google;University of California, Los Angeles",,-1;-1;22;-1;-1,14;10;32;-1;14,-1;-1,usa,usa,n,11
122,ICLR,2017,Nonparametric Neural Networks,George Philipp;Jaime G. Carbonell,george.philipp@email.de;jgc@cs.cmu.edu,7;7;5,3;4;4,Accept (Poster),2,9,0.0,no,11/5/16,Carnegie Mellon University;Carnegie Mellon University,Deep learning;Supervised Learning,1;1,23;23,-1;-1,usa,usa,y,1
123,ICLR,2017,Improving Neural Language Models with a Continuous Cache,Edouard Grave;Armand Joulin;Nicolas Usunier,egrave@fb.com;ajoulin@fb.com;usunier@fb.com,7;5;9,5;4;5,Accept (Poster),6,1,0.0,no,11/4/16,Facebook;Facebook;Facebook,Natural language processing,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
124,ICLR,2017,Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement,Nicolas Usunier;Gabriel Synnaeve;Zeming Lin;Soumith Chintala,usunier@fb.com;gab@fb.com;zlin@fb.com;soumith@fb.com,7;7;8,4;4;4,Accept (Poster),2,0,0.0,no,11/4/16,Facebook;Facebook;Facebook;Facebook,Deep learning;Reinforcement Learning;Games,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
125,ICLR,2017,Lossy Image Compression with Compressive Autoencoders,Lucas Theis;Wenzhe Shi;Andrew Cunningham;Ferenc Husz√°r,ltheis@twitter.com;wshi@twitter.com;acunningham@twitter.com;fhuszar@twitter.com,8;7;5,5;3;4,Accept (Poster),7,12,2.0,no,11/4/16,Twitter;Twitter;Twitter;Twitter,Computer vision;Deep learning;Applications,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
126,ICLR,2017,Temporal Ensembling for Semi-Supervised Learning,Samuli Laine;Timo Aila,slaine@nvidia.com;taila@nvidia.com,7;9;8,4;4;5,Accept (Poster),3,3,1.0,no,11/4/16,NVIDIA;NVIDIA,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
127,ICLR,2017,Optimization as a Model for Few-Shot Learning,Sachin Ravi;Hugo Larochelle,sachinr@twitter.com;hugo@twitter.com;sachinr@princeton.edu,8;9;6,4;5;4,Accept (Oral),4,5,0.0,no,11/4/16,Twitter;Twitter;Princeton University,,-1;-1;46,-1;-1;7,-1;-1,usa,usa,n,6
128,ICLR,2017,Towards a Neural Statistician,Harrison Edwards;Amos Storkey,h.l.edwards@sms.ed.ac.uk;amos.storkey@ed.ac.uk,8;8;6,2;4;4,Accept (Poster),2,3,0.0,no,11/4/16,University of Edinburgh;University of Edinburgh,,31;31,27;27,-1;-1,europe,uk,n,5
129,ICLR,2017,Faster CNNs with Direct Sparse Convolutions and Guided Pruning,Jongsoo Park;Sheng Li;Wei Wen;Ping Tak Peter Tang;Hai Li;Yiran Chen;Pradeep Dubey,jongsoo.park@intel.com;sheng.r.li@intel.com;peter.tang@intel.com;weiwen.web@gmail.com;HAL66@pitt.edu;yic52@pitt.edu;pradeep.dubey@intel.com,6;7;6,3;3;3,Accept (Poster),0,3,0.0,no,11/4/16,Intel;Intel;Intel;Facebook;University of Pittsburgh;University of Pittsburgh;Intel,Deep learning;Optimization,-1;-1;-1;-1;67;67;-1,-1;-1;-1;-1;80;80;-1,-1;-1,NAN,NAN,n,
130,ICLR,2017,Boosted Generative Models,Aditya Grover;Stefano Ermon,adityag@cs.stanford.edu;ermon@cs.stanford.edu,5;6;5,3;3;3,Reject,1,4,0.0,no,11/5/16,Stanford University;Stanford University,Theory;Deep learning;Unsupervised Learning,3;3,3;3,-1;-1,usa,usa,y,5
131,ICLR,2017,Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,William Lotter;Gabriel Kreiman;David Cox,lotter@fas.harvard.edu;gabriel.kreiman@tch.harvard.edu;davidcox@fas.harvard.edu,6;8;8,3;4;5,Accept (Poster),6,0,0.0,no,11/4/16,Harvard University;Harvard University;Harvard University,,46;46;46,6;6;6,-1;-1,usa,usa,n,
132,ICLR,2017, Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,Noam Shazeer;*Azalia Mirhoseini;*Krzysztof Maziarz;Andy Davis;Quoc Le;Geoffrey Hinton;Jeff Dean,noam@google.com;azalia@google.com;krzysztof.maziarz@student.uj.edu.pl;andydavis@google.com;qvl@google.com;geoffhinton@google.com;jeff@google.com,7;6;7,4;4;4,Accept (Poster),4,10,0.0,no,11/4/16,Google;Google;Jagiellonian University;Google;Google;Google;Google,Deep learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;625;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;1
133,ICLR,2017,Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic,Shixiang Gu;Timothy Lillicrap;Zoubin Ghahramani;Richard E. Turner;Sergey Levine,sg717@cam.ac.uk;countzero@google.com;zoubin@eng.cam.ac.uk;ret26@cam.ac.uk;svlevine@eecs.berkeley.edu,7;7;7;8,4;5;4;3,Accept (Oral),1,11,9.0,no,11/4/16,University of Cambridge;Google;University of Cambridge;University of Cambridge;University of California Berkeley,Deep learning;Reinforcement Learning,67;-1;67;67;-1,4;-1;4;4;10,-1;-1,usa,usa,n,1
134,ICLR,2017,Recurrent Batch Normalization,Tim Cooijmans;Nicolas Ballas;C√©sar Laurent;√áaƒülar G√ºl√ßehre;Aaron Courville,tim.cooijmans@umontreal.ca;nicolas.ballas@umontreal.ca;cesar.laurent@umontreal.ca;caglar.gulcehre@umontreal.ca;aaron.courville@umontreal.ca,7;8;7,4;4;4,Accept (Poster),3,4,0.0,no,11/4/16,University of Montreal;University of Montreal;University of Montreal;University of Montreal;University of Montreal,Deep learning;Optimization,92;92;92;92;92,103;103;103;103;103,-1;-1,canada,ca,n,3;1
135,ICLR,2017,Inductive Bias of Deep Convolutional Networks through Pooling Geometry,Nadav Cohen;Amnon Shashua,cohennadav@cs.huji.ac.il;shashua@cs.huji.ac.il,7;7;6,5;3;3,Accept (Poster),1,3,0.0,no,11/3/16,Hebrew University of Jerusalem;Hebrew University of Jerusalem,Theory;Deep learning,67;67,186;186,-1;-1,europe,il,n,2
136,ICLR,2017,,,,4;7;7,4;3;3,Reject,0,0,1.0,no,,0,,,,-1,NAN,NAN,pdf miss,
137,ICLR,2017,Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights,Aojun Zhou;Anbang Yao;Yiwen Guo;Lin Xu;Yurong Chen,aojun.zhou@intel.com;anbang.yao@intel.com;yiwen.guo@intel.com;lin.x.xu@intel.com;yurong.chen@intel.com,7;8;7,3;4;4,Accept (Poster),2,2,0.0,no,11/4/16,Intel;Intel;Intel;Intel;Intel,Deep learning;Optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
138,ICLR,2017,DSD: Dense-Sparse-Dense Training for Deep Neural Networks,Song Han;Jeff Pool;Sharan Narang;Huizi Mao;Enhao Gong;Shijian Tang;Erich Elsen;Peter Vajda;Manohar Paluri;John Tran;Bryan Catanzaro;William J. Dally,songhan@stanford.edu;jpool@nvidia.com;sharan@baidu.com;huizi@stanford.edu;enhaog@stanford.edu;sjtang@stanford.edu;eriche@google.com;vajdap@fb.com;mano@fb.com;johntran@nvidia.com;bcatanzaro@nvidia.com;dally@stanford.edu,8;8;5,3;3;4,Accept (Poster),3,3,0.0,no,11/4/16,Stanford University;NVIDIA;Baidu;Stanford University;Stanford University;Stanford University;Google;Facebook;Facebook;NVIDIA;NVIDIA;Stanford University,Deep learning,3;-1;-1;3;3;3;-1;-1;-1;-1;-1;3,3;-1;-1;3;3;3;-1;-1;-1;-1;-1;3,-1;-1,usa,usa,n,
139,ICLR,2017,TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency,Adji B. Dieng;Chong Wang;Jianfeng Gao;John Paisley,abd2141@columbia.edu;chowang@microsoft.com;jfgao@microsoft.com;jpaisley@columbia.edu,6;7;8,3;4;4,Accept (Poster),2,7,2.0,no,11/4/16,Columbia University;Microsoft;Microsoft;Columbia University,Natural language processing;Deep learning,31;-1;-1;31,16;-1;-1;16,-1;-1,usa,usa,n,3
140,ICLR,2017,Efficient Representation of Low-Dimensional Manifolds using Deep Networks,Ronen Basri;David W. Jacobs,ronen.basri@weizmann.ac.il;djacobs@cs.umd.edu,6;5;7,3;3;5,Accept (Poster),1,3,0.0,no,11/3/16,"Weizmann Institute;University of Maryland, College Park",Theory;Deep learning,92;11,-1;67,-1;-1,usa,usa,n,
141,ICLR,2017,Training deep neural-networks using a noise adaptation layer,Jacob Goldberger;Ehud Ben-Reuven,jacob.goldberger@biu.ac.il;udi.benreuven@gmail.com,5;7;5,4;5;5,Accept (Poster),2,3,0.0,no,11/4/16,Bar Ilan University;Tel Aviv University,Deep learning;Optimization,67;-1,489;-1,-1;-1,asia,in,n,
142,ICLR,2017,SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,Soroush Mehri;Kundan Kumar;Ishaan Gulrajani;Rithesh Kumar;Shubham Jain;Jose Sotelo;Aaron Courville;Yoshua Bengio,soroush.mehri@umontreal.ca;kundankumar2510@gmail.com;igul222@gmail.com;ritheshkumar.95@gmail.com;shubhamjain1310@gmail.com;rdz.sotelo@gmail.com;aaron.courville@umontreal.ca;yoshua.bengio@umontreal.ca,9;8;8,4;4;3,Accept (Poster),4,5,0.0,no,11/4/16,University of Montreal;University of Montreal;Stanford University;;;University of Montreal;University of Montreal;University of Montreal,Speech;Deep learning;Unsupervised Learning;Applications,92;92;3;-1;-1;92;92;92,103;103;3;-1;-1;103;103;103,-1;-1,canada,ca,n,
143,ICLR,2017,FractalNet: Ultra-Deep Neural Networks without Residuals,Gustav Larsson;Michael Maire;Gregory Shakhnarovich,larsson@cs.uchicago.edu;mmaire@ttic.edu;greg@ttic.edu,6;6;5,5;4;5,Accept (Poster),2,2,0.0,no,11/4/16,University of Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,,46;-1;-1,10;380;380,-1;-1,NAN,NAN,n,
144,ICLR,2017,Towards the Limit of Network Quantization,Yoojin Choi;Mostafa El-Khamy;Jungwon Lee,yoojin.c@samsung.com;mostafa.e@samsung.com;jungwon2.lee@samsung.com,7;7;7,3;3;4,Accept (Poster),3,5,0.0,no,11/4/16,Samsung;Samsung;Samsung,Theory;Deep learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,1
145,ICLR,2017,Understanding deep learning requires rethinking generalization,Chiyuan Zhang;Samy Bengio;Moritz Hardt;Benjamin Recht;Oriol Vinyals,chiyuan@mit.edu;bengio@google.com;mrtz@google.com;brecht@berkeley.edu;vinyals@google.com,10;9;10,4;3;4,Accept (Oral),2,33,9.0,no,11/4/16,Massachusetts Institute of Technology;Google;Google;University of California Berkeley;Google,Deep learning,9;-1;-1;-1;-1,5;-1;-1;10;-1,-1;-1,NAN,NAN,y,1
146,ICLR,2017,Optimal Binary Autoencoding with Pairwise Correlations,Akshay Balsubramani,abalsubr@stanford.edu,7;7;6,3;2;4,Accept (Poster),0,2,0.0,no,11/4/16,Stanford University,Theory;Unsupervised Learning;Games,3,3,-1,usa,usa,y,9
147,ICLR,2017,Metacontrol for Adaptive Imagination-Based Optimization,Jessica B. Hamrick;Andrew J. Ballard;Razvan Pascanu;Oriol Vinyals;Nicolas Heess;Peter W. Battaglia,jhamrick@berkeley.edu;aybd@google.com;razp@google.com;vinyals@google.com;heess@google.com;peterbattaglia@google.com,8;8;7;8,3;3;3;3,Accept (Poster),0,4,0.0,no,11/4/16,University of California Berkeley;Google;Google;Google;Google;Google,Deep learning;Reinforcement Learning;Optimization,-1;-1;-1;-1;-1;-1,10;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
148,ICLR,2017,Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks,Arash Ardakani;Carlo Condo;Warren J. Gross,arash.ardakani@mail.mcgill.ca;carlo.condo@mail.mcgill.ca;warren.gross@mcgill.ca,6;7;6,4;3;3,Accept (Poster),2,6,0.0,no,11/3/16,McGill University;McGill University;McGill University,Deep learning;Applications;Optimization,92;92;92,42;42;42,-1;-1,canada,ca,n,8
149,ICLR,2017,Calibrating Energy-based Generative Adversarial Networks,Zihang Dai;Amjad Almahairi;Philip Bachman;Eduard Hovy;Aaron Courville,zander.dai@gmail.com;amjadmahayri@gmail.com;phil.bachman@gmail.com;hovy@cmu.edu;aaron.courville@gmail.com,8;7;8,4;5;4,Accept (Poster),0,7,0.0,no,11/4/16,Google;Facebook;Microsoft;Carnegie Mellon University;University of Montreal,Deep learning,-1;-1;-1;1;92,-1;-1;-1;23;103,-1;-1,canada,ca,n,1;5;4
150,ICLR,2017,Designing Neural Network Architectures using Reinforcement Learning,Bowen Baker;Otkrist Gupta;Nikhil Naik;Ramesh Raskar,bowen@mit.edu;otkrist@mit.edu;naik@mit.edu;raskar@mit.edu,6;6;6,4;3;4,Accept (Poster),4,6,0.0,no,11/4/16,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deep learning;Reinforcement Learning,9;9;9;9,5;5;5;5,-1;-1,usa,usa,n,
151,ICLR,2017,Categorical Reparameterization with Gumbel-Softmax,Eric Jang;Shixiang Gu;Ben Poole,ejang@google.com;sg717@cam.ac.uk;poole@cs.stanford.edu,7;6;6,5;4;3,Accept (Poster),4,3,0.0,no,11/4/16,Google;University of Cambridge;Stanford University,Deep learning;Semi-Supervised Learning;Optimization;Structured prediction,-1;67;3,-1;4;3,-1;-1,usa,usa,n,5
152,ICLR,2017,PixelVAE: A Latent Variable Model for Natural Images,Ishaan Gulrajani;Kundan Kumar;Faruk Ahmed;Adrien Ali Taiga;Francesco Visin;David Vazquez;Aaron Courville,igul222@gmail.com;kundankumar2510@gmail.com;faruk.ahmed.91@gmail.com;adrien.alitaiga@gmail.com;francesco.visin@polimi.it;dvazquez@cvc.uab.es;aaron.courville@gmail.com,7;6;7,4;3;3,Accept (Poster),3,3,0.0,no,11/4/16,"Stanford University;University of Montreal;University of Montreal;Google;Politecnico di Milano;Computer Vision Center, Universitat Aut√≤noma de Barcelona;University of Montreal",Deep learning;Unsupervised Learning,3;92;92;-1;149;-1;92,3;103;103;-1;-1;-1;103,-1;-1,canada,ca,n,5
153,ICLR,2017,Transfer of View-manifold Learning to Similarity Perception of Novel Objects,Xingyu Lin;Hao Wang;Zhihao Li;Yimeng Zhang;Alan Yuille;Tai Sing Lee,sean.linxingyu@pku.edu.cn;hao.wang@pku.edu.cn;zhihaol@andrew.cmu.edu;yimengzh@andrew.cmu.edu;alan.yuille@jhu.edu;tai@cnbc.cmu.edu,5;6;7,5;4;3,Accept (Poster),2,4,0.0,no,11/5/16,Peking University;Peking University;Carnegie Mellon University;Carnegie Mellon University;Johns Hopkins University;Carnegie Mellon University,Deep learning;Transfer Learning,14;14;1;1;46;1,29;29;23;23;17;23,-1;-1,usa,usa,n,
154,ICLR,2017,Sample Efficient Actor-Critic with  Experience Replay,Ziyu Wang;Victor Bapst;Nicolas Heess;Volodymyr Mnih;Remi Munos;Koray Kavukcuoglu;Nando de Freitas,ziyu@google.com;vbapst@google.com;heess@google.com;vmnih@google.com;Munos@google.com;korayk@google.com;nandodefreitas@google.com,7;6;6,3;3;4,Accept (Poster),3,8,1.0,no,11/4/16,Google;Google;Google;Google;Google;Google;Google,Deep learning;Reinforcement Learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
155,ICLR,2017,Distributed Second-Order Optimization using Kronecker-Factored Approximations,Jimmy Ba;Roger Grosse;James Martens,jimmy@psi.toronto.edu;rgrosse@cs.toronto.edu;jmartens@cs.toronto.edu,7;6,4;3,Accept (Poster),6,3,0.0,no,11/5/16,University of Toronto;University of Toronto;University of Toronto,Deep learning;Optimization,22;22;22,22;22;22,-1;-1,canada,ca,n,
156,ICLR,2017,Learning to Navigate in Complex Environments,Piotr Mirowski;Razvan Pascanu;Fabio Viola;Hubert Soyer;Andy Ballard;Andrea Banino;Misha Denil;Ross Goroshin;Laurent Sifre;Koray Kavukcuoglu;Dharshan Kumaran;Raia Hadsell,piotrmirowski@google.com;razp@google.com;fviola@google.com;soyer@google.com;aybd@google.com;abanino@google.com;mdenil@google.com;goroshin@google.com;sifre@google.com;korayk@google.com;dkumaran@google.com;raia@google.com,7;5;7,5;4;3,Accept (Poster),6,9,0.0,no,11/4/16,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Deep learning;Reinforcement Learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
157,ICLR,2017,Learning to superoptimize programs,Rudy Bunel;Alban Desmaison;M. Pawan Kumar;Philip H.S. Torr;Pushmeet Kohli,rudy@robots.ox.ac.uk;alban@robots.ox.ac.uk;pawan@robots.ox.ac.uk;philip.torr@eng.ox.ac.uk;pkohli@microsoft.com,6;8;7,5;4;4,Accept (Poster),2,7,0.0,no,11/4/16,University of Oxford;University of Oxford;University of Oxford;University of Oxford;Microsoft,,31;31;31;31;-1,1;1;1;1;-1,-1;-1,NAN,NAN,n,3
158,ICLR,2017,Trained Ternary Quantization,Chenzhuo Zhu;Song Han;Huizi Mao;William J. Dally,zhucz13@mails.tsinghua.edu.cn;songhan@stanford.edu;huizi@stanford.edu;dally@stanford.edu,3;7;7;8,3;5;3;5,Accept (Poster),0,10,0.0,no,11/4/16,"Tsinghua University, Tsinghua University;Stanford University;Stanford University;Stanford University",Deep learning,5;3;3;3,35;3;3;3,-1;-1,usa,usa,n,
159,ICLR,2017,Online Bayesian Transfer Learning for Sequential Data Modeling,Priyank Jaini;Zhitang Chen;Pablo Carbajal;Edith Law;Laura Middleton;Kayla Regan;Mike Schaekermann;George Trimponias;James Tung;Pascal Poupart,pjaini@uwaterloo.ca;chenzhitang2@huawei.com;pablo@veedata.io;edith.law@uwaterloo.ca;lmiddlet@uwaterloo.ca;kregan@uwaterloo.ca;mschaekermann@uwaterloo.ca;g.trimponias@huawei.com;james.tung@uwaterloo.ca;ppoupart@uwaterloo.ca,7;6;6,3;3;3,Accept (Poster),2,7,0.0,no,11/4/16,University of Waterloo;Huawei Technologies Ltd.;;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;Huawei Technologies Ltd.;University of Waterloo;University of Waterloo,Unsupervised Learning;Transfer Learning;Applications,31;-1;-1;31;31;31;31;-1;31;31,174;-1;-1;174;174;174;174;-1;174;174,-1;-1,canada,ca,n,6;11
160,ICLR,2017,Deep Variational Information Bottleneck,Alexander A. Alemi;Ian Fischer;Joshua V. Dillon;Kevin Murphy,alemi@google.com;iansf@google.com;jvdillon@google.com;kpmurphy@google.com,7;6;6,4;4;3,Accept (Poster),2,8,0.0,no,11/4/16,Google;Google;Google;Google,Theory;Computer vision;Deep learning;Supervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;4
161,ICLR,2017,Exploring Sparsity in Recurrent Neural Networks,Sharan Narang;Greg Diamos;Shubho Sengupta;Erich Elsen,sharan@baidu.com;gdiamos@baidu.com;ssengupta@baidu.com;eriche@google.com,7;6,3;4,Accept (Poster),6,6,0.0,no,11/4/16,Baidu;Baidu;Baidu;Google,Speech;Deep learning;Supervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
162,ICLR,2017,Neural Photo Editing with Introspective Adversarial Networks,Andrew Brock;Theodore Lim;J.M. Ritchie;Nick Weston,ajb5@hw.ac.uk;t.lim@hw.ac.uk;j.m.ritchie@hw.ac.uk;Nick.Weston@renishaw.com,5;6;6,3;4;4,Accept (Poster),4,5,0.0,no,10/29/16,Heriot-Watt University;Heriot-Watt University;Heriot-Watt University;Renishaw,Computer vision;Unsupervised Learning;Applications,149;149;149;-1,429;429;429;-1,-1;-1,NAN,NAN,n,1;5;4
163,ICLR,2017,Semi-Supervised Classification with Graph Convolutional Networks,Thomas N. Kipf;Max Welling,T.N.Kipf@uva.nl;M.Welling@uva.nl,7;7;7,3;4;4,Accept (Poster),1,1,1.0,no,11/3/16,University of Amsterdam;University of Amsterdam,Deep learning;Semi-Supervised Learning,92;92,63;63,-1;-1,europe,nl,n,10
164,ICLR,2017,Deep Learning with Dynamic Computation Graphs,Moshe Looks;Marcello Herreshoff;DeLesley Hutchins;Peter Norvig,madscience@google.com;marcelloh@google.com;delesley@google.com;pnorvig@google.com,8;7;8,3;5;3,Accept (Poster),1,5,1.0,no,11/4/16,Google;Google;Google;Google,Deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;10
165,ICLR,2017,A recurrent neural network without chaos,Thomas Laurent;James von Brecht,tlaurent@lmu.edu;james.vonbrecht@csulb.edu,8;7;7,3;4;4,Accept (Poster),6,3,0.0,no,11/4/16,"Loyola Marymount University;California State University, Long Beach",,-1;-1,-1;-1,-1;-1,NAN,NAN,y,3;1
166,ICLR,2017,Adversarially Learned Inference,Vincent Dumoulin;Ishmael Belghazi;Ben Poole;Alex Lamb;Martin Arjovsky;Olivier Mastropietro;Aaron Courville,vincent.dumoulin@umontreal.ca;ishmael.belghazi@gmail.com;poole@cs.stanford.edu;alex6200@gmail.com;martinarjovsky@gmail.com;oli.mastro@gmail.com;aaron.courville@gmail.com,7;7;8,4;3;4,Accept (Poster),4,6,0.0,no,11/4/16,University of Montreal;University of Montreal;Stanford University;;;;University of Montreal,Computer vision;Deep learning;Unsupervised Learning;Semi-Supervised Learning,92;92;3;-1;-1;-1;92,103;103;3;-1;-1;-1;103,-1;-1,canada,ca,n,5;4
167,ICLR,2017,Amortised MAP Inference for Image Super-resolution,Casper Kaae S√∏nderby;Jose Caballero;Lucas Theis;Wenzhe Shi;Ferenc Husz√°r,casperkaae@gmail.com;jcaballero@twitter.com;ltheis@twitter.com;wshi@twitter.com;fhuszar@twitter.com,8;9;7,5;3;2,Accept (Oral),2,5,0.0,no,11/1/16,Google;Twitter;Twitter;Twitter;Twitter,Theory;Computer vision;Deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
168,ICLR,2017,A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING,Zhouhan Lin;Minwei Feng;Cicero Nogueira dos Santos;Mo Yu;Bing Xiang;Bowen Zhou;Yoshua Bengio,lin.zhouhan@gmail.com;mfeng@us.ibm.com;cicerons@us.ibm.com;yum@us.ibm.com;bingxia@us.ibm.com;zhou@us.ibm.com;yoshua.bengio@umontreal.ca,6;5;8,5;4;4,Accept (Poster),4,5,0.0,no,11/4/16,Shanghai Jiao Tong University;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Montreal,Natural language processing;Deep learning;Supervised Learning,46;-1;-1;-1;-1;-1;92,214;-1;-1;-1;-1;-1;103,-1;-1,canada,ca,n,8
169,ICLR,2017,Geometry of Polysemy,Jiaqi Mu;Suma Bhat;Pramod Viswanath,jiaqimu2@illinois.edu;spbhat2@illinois.edu;pramodv@illinois.edu,7;7;7,3;4;4,Accept (Poster),4,6,0.0,no,11/4/16,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Natural language processing,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,3
170,ICLR,2017,On Detecting Adversarial Perturbations,Jan Hendrik Metzen;Tim Genewein;Volker Fischer;Bastian Bischoff,JanHendrik.Metzen@de.bosch.com;Tim.Genewein@de.bosch.com;Volker.Fischer@de.bosch.com;Bastian.Bischoff@de.bosch.com,7;7;5,4;4;3,Accept (Poster),3,3,0.0,no,11/4/16,Bosch;Bosch;Bosch;Bosch,Computer vision;Deep learning;Supervised Learning,-1;-1;-1;-1,433;433;433;433,-1;-1,NAN,NAN,n,4
171,ICLR,2017,Frustratingly Short Attention Spans in Neural Language Modeling,Micha≈Ç Daniluk;Tim Rockt√§schel;Johannes Welbl;Sebastian Riedel,michal.daniluk.15@ucl.ac.uk;t.rocktaschel@cs.ucl.ac.uk;j.welbl@cs.ucl.ac.uk;s.riedel@cs.ucl.ac.uk,7;7;7,4;4;4,Accept (Poster),3,3,1.0,no,11/4/16,University College London;University College London;University College London;University College London,Natural language processing;Deep learning,31;31;31;31,-1;-1;-1;-1,-1;-1,europe,uk,n,8;3
172,ICLR,2017,Learning Invariant Representations Of Planar Curves ,Gautam Pai;Aaron Wetzler;Ron Kimmel,paigautam@cs.technion.ac.il;twerd@cs.technion.ac.il;ron@cs.technion.ac.il,5;6;8,2;5;3,Accept (Poster),3,4,0.0,no,11/4/16,"Technion, Technion;Technion, Technion;Technion, Technion",Computer vision;Deep learning;Supervised Learning;Applications,22;22;22,-1;-1;-1,-1;-1,NAN,NAN,n,
173,ICLR,2017,Deep Multi-task Representation Learning: A Tensor Factorisation Approach,Yongxin Yang;Timothy M. Hospedales,yongxin.yang@qmul.ac.uk;t.hospedales@qmul.ac.uk,5;7;8,3;4;4,Accept (Poster),1,5,0.0,no,11/4/16,Queen Mary University London;Queen Mary University London,,-1;-1,-1;-1,-1;-1,europe,uk,n,
174,ICLR,2017,Unrolled Generative Adversarial Networks,Luke Metz;Ben Poole;David Pfau;Jascha Sohl-Dickstein,lmetz@google.com;poole@cs.stanford.edu;pfau@google.com;jaschasd@google.com,7;7;9,5;5;5,Accept (Poster),3,8,0.0,no,11/4/16,Google;Stanford University;Google;Google,Deep learning;Unsupervised Learning;Optimization,-1;3;-1;-1,-1;3;-1;-1,-1;-1,NAN,NAN,n,5;4
175,ICLR,2017,Structured Attention Networks,Yoon Kim;Carl Denton;Luong Hoang;Alexander M. Rush,yoonkim@seas.harvard.edu;carldenton@college.harvard.edu;lhoang@g.harvard.edu;srush@seas.harvard.edu,8;8;8,4;5;3,Accept (Poster),3,2,0.0,no,11/4/16,Harvard University;Harvard University;Harvard University;Harvard University,,46;46;46;46,6;6;6;6,-1;-1,usa,usa,n,8;2;3;10
176,ICLR,2017,HyperNetworks,David Ha;Andrew M. Dai;Quoc V. Le,hadavid@google.com;adai@google.com;qvl@google.com,8;7;6,4;4;5,Accept (Poster),2,5,0.0,no,10/27/16,Google;Google;Google,Natural language processing;Deep learning;Supervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
177,ICLR,2017,Dropout with Expectation-linear Regularization,Xuezhe Ma;Yingkai Gao;Zhiting Hu;Yaoliang Yu;Yuntian Deng;Eduard Hovy,xuezhem@cs.cmu.edu;yingkaig@cs.cmu.edu;zhitinghu@cs.cmu.edu;yaoliang@cs.cmu.edu;dengyuntian@gmail.com;hovy@cmu.edu,8;7;8,3;4;3,Accept (Poster),1,4,0.0,no,10/28/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;;Carnegie Mellon University,Theory;Deep learning;Supervised Learning,1;1;1;1;-1;1,23;23;23;23;-1;23,-1;-1,usa,usa,y,1
178,ICLR,2017,Dynamic Coattention Networks For Question Answering,Caiming Xiong;Victor Zhong;Richard Socher,cxiong@salesforce.com;vzhong@salesforce.com;rsocher@salesforce.com,8;8;8,3;4;4,Accept (Poster),12,9,2.0,no,11/4/16,SalesForce.com;SalesForce.com;SalesForce.com,Natural language processing;Deep learning;Applications,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8
179,ICLR,2017,Visualizing Deep Neural Network Decisions: Prediction Difference Analysis,Luisa M Zintgraf;Taco S Cohen;Tameem Adel;Max Welling,lmzintgraf@gmail.com;t.s.cohen@uva.nl;tameem.hesham@gmail.com;m.welling@uva.nl,6;9;6,4;4;5,Accept (Poster),1,6,0.0,no,11/4/16,University of Oxford;University of Amsterdam;University of Cambridge;University of Amsterdam,Deep learning;Applications,31;92;67;92,1;63;4;63,-1;-1,europe,nl,n,
180,ICLR,2017,Density estimation using Real NVP,Laurent Dinh;Jascha Sohl-Dickstein;Samy Bengio,dinh.laurent@gmail.com;jaschasd@google.com;bengio@google.com,8;8;7,4;4;4,Accept (Poster),4,2,0.0,no,11/4/16,Google;Google;Google,Deep learning;Unsupervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
181,ICLR,2017,Dialogue Learning With Human-in-the-Loop,Jiwei Li;Alexander H. Miller;Sumit Chopra;Marc'Aurelio Ranzato;Jason Weston,jiwel@fb.com;ahm@fb.com;spchopra@fb.com;ranzato@fb.com;jase@fb.com,5;6;7,4;3;4,Accept (Poster),4,5,0.0,no,11/4/16,Facebook;Facebook;Facebook;Facebook;Facebook,Natural language processing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
182,ICLR,2017,Learning to Act by Predicting the Future,Alexey Dosovitskiy;Vladlen Koltun,adosovitskiy@gmail.com;vkoltun@gmail.com,7;8;8,4;4;4,Accept (Oral),4,1,0.0,no,11/4/16,Google;Intel,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
183,ICLR,2017,"Offline bilingual word vectors, orthogonal transformations and the inverted softmax",Samuel L. Smith;David H. P. Turban;Steven Hamblin;Nils Y. Hammerla,samuel.smith@babylonhealth.com;dt382@cam.ac.uk;steven.hamblin@babylonhealth.com;nils.hammerla@babylonhealth.com,7;8;6,5;5;3,Accept (Poster),2,6,1.0,no,11/4/16,babylon health;University of Cambridge;babylon health;babylon health,Natural language processing;Transfer Learning;Applications,-1;67;-1;-1,-1;4;-1;-1,-1;-1,NAN,NAN,n,1
184,ICLR,2017,Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer,Sergey Zagoruyko;Nikos Komodakis,sergey.zagoruyko@enpc.fr;nikos.komodakis@enpc.fr,6;6;6,4;4;4,Accept (Poster),4,7,0.0,no,11/5/16,ENPC;ENPC,Computer vision;Deep learning;Supervised Learning,-1;-1,-1;-1,-1;-1,europe,ch,n,8;2;3
185,ICLR,2017,Recurrent Mixture Density Network for Spatiotemporal Visual Attention,Loris Bazzani;Hugo Larochelle;Lorenzo Torresani,loris.bazzani@gmail.com;hugo.larochelle@usherbrooke.ca;lt@dartmouth.edu,7;6;6,4;4;4,Accept (Poster),4,7,0.0,no,11/3/16,Amazon;Universit√© de Sherbrooke;Dartmouth College,Computer vision;Deep learning;Applications,-1;286;149,-1;567;82,-1;-1,usa,usa,n,8;2
186,ICLR,2017,Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations,David Krueger;Tegan Maharaj;Janos Kramar;Mohammad Pezeshki;Nicolas Ballas;Nan Rosemary Ke;Anirudh  Goyal;Yoshua Bengio;Aaron Courville;Christopher Pal,davidscottkrueger@gmail.com;tegan.jrm@gmail.com;ballas.n@gmail.com,7;8;8,4;4;5,Accept (Poster),3,3,0.0,no,11/4/16,University of Montreal;Polytechnique Montreal;Facebook;Polytechnique Montreal,Deep learning,-1;286;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;1
187,ICLR,2017,Adversarial Machine Learning at Scale,Alexey Kurakin;Ian J. Goodfellow;Samy Bengio,kurakin@google.com;ian@openai.com;bengio@google.com,7;6;6,3;4;4,Accept (Poster),3,3,0.0,no,11/3/16,Google;OpenAI;Google,Computer vision;Supervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
188,ICLR,2017,A Learned Representation For Artistic Style,Vincent Dumoulin;Jonathon Shlens;Manjunath Kudlur,vi.dumoulin@gmail.com;shlens@google.com;keveman@google.com,7;8;8,3;5;5,Accept (Poster),6,10,0.0,no,10/26/16,Google;Google;Google,Computer vision;Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
189,ICLR,2017,Batch Policy Gradient  Methods for  Improving Neural Conversation Models,Kirthevasan Kandasamy;Yoram Bachrach;Ryota Tomioka;Daniel Tarlow;David Carter,kandasamy@cmu.edu;yorambac@gmail.com;ryoto@microsoft.com;dtarlow@microsoft.com;dacart@microsoft.com,6;7;8,3;3;3,Accept (Poster),2,5,0.0,no,11/4/16,Carnegie Mellon University;Google;Microsoft;Microsoft;Microsoft,Natural language processing;Reinforcement Learning,1;-1;-1;-1;-1,23;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
190,ICLR,2017,Incorporating long-range consistency in CNN-based texture generation,Guillaume Berger;Roland Memisevic,guillaume.berger@umontreal.ca;memisevr@iro.umontreal.ca,5;7;7,5;5;5,Accept (Poster),2,1,0.0,no,11/4/16,University of Montreal;University of Montreal,Computer vision;Deep learning,92;92,103;103,-1;-1,canada,ca,n,
191,ICLR,2017,Paleo: A Performance Model for Deep Neural Networks,Hang Qi;Evan R. Sparks;Ameet Talwalkar,hangqi@cs.ucla.edu;sparks@cs.berkeley.edu;ameet@cs.ucla.edu,6;7;6,4;4;4,Accept (Poster),2,3,0.0,no,11/4/16,"University of California, Los Angeles;University of California Berkeley;University of California, Los Angeles",Deep learning,-1;-1;-1,14;10;14,-1;-1,usa,usa,n,
192,ICLR,2017,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,Nitish Shirish Keskar;Dheevatsa Mudigere;Jorge Nocedal;Mikhail Smelyanskiy;Ping Tak Peter Tang,keskar.nitish@u.northwestern.edu;dheevatsa.mudigere@intel.com;j-nocedal@northwestern.edu;mikhail.smelyanskiy@intel.com;peter.tang@intel.com,8;10;6,3;3;4,Accept (Oral),2,5,2.0,no,11/3/16,Northwestern University;Intel;Northwestern University;Intel;Intel,Deep learning;Optimization,46;-1;46;-1;-1,20;-1;20;-1;-1,-1;-1,NAN,NAN,n,1
193,ICLR,2017,Predicting Medications from Diagnostic Codes with Recurrent Neural Networks,Jacek M. Bajor;Thomas A. Lasko,jacek.m.bajor@vanderbilt.edu;tom.lasko@vanderbilt.edu,6;8;7,3;4;5,Accept (Poster),3,3,0.0,no,11/3/16,Vanderbilt University;Vanderbilt University,Deep learning;Supervised Learning;Applications,286;286,108;108,-1;-1,usa,usa,n,
194,ICLR,2017,An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax,Wentao Huang;Kechen Zhang,whuang21@jhmi.edu;kzhang4@jhmi.edu,8;5;7,2;2;3,Accept (Poster),1,6,0.0,no,11/5/16,Johns Hopkins University;Johns Hopkins University,Unsupervised Learning;Theory;Deep learning,-1;46,-1;17,-1;-1,usa,usa,y,
195,ICLR,2017,Regularizing CNNs with Locally Constrained Decorrelations,Pau Rodr√≠guez;Jordi Gonz√†lez;Guillem Cucurull;Josep M. Gonfaus;Xavier Roca,pau.rodriguez@cvc.uab.es;poal@cvc.uab.es;pep.gonfaus@visual-tagging.com;xavier.roca@visual-tagging.com,7;7;7,3;4;4,Accept (Poster),4,4,0.0,no,11/4/16,"Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Visual-tagging;Visual-tagging",Computer vision;Deep learning;Optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
196,ICLR,2017,Generating Long and Diverse Responses with Neural Conversation Models,Louis Shao;Stephan Gouws;Denny Britz;Anna Goldie;Brian Strope;Ray Kurzweil,overmind@google.com;sgouws@google.com;dennybritz@google.com;agoldie@google.com;bps@google.com;raykurzweil@google.com,5;7;7,3;4;3,Reject,4,5,0.0,no,11/5/16,Google;Google;Google;Google;Google;Google,Natural language processing;Deep learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
197,ICLR,2017,DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning,Tian Zhao;Xiao Bing Huang;Yu Cao,tzhao@uwm.edu;xiaobing@uwm.edu;ycao@cs.uml.edu,6;7;8,4;4;3,Accept (Poster),3,2,0.0,no,11/4/16,"College of William and Mary;College of William and Mary;University of Massachusetts, Lowell",Deep learning;Applications;Optimization,286;286;149,-1;-1;166,-1;-1,usa,usa,n,
198,ICLR,2017,Delving into Transferable Adversarial Examples and Black-box Attacks,Yanpei Liu;Xinyun Chen;Chang Liu;Dawn Song,resodo.liu@gmail.com;jungyhuk@gmail.com;liuchang@eecs.berkeley.edu;dawnsong@cs.berkeley.edu,6;7;5,3;3;3,Accept (Poster),7,5,0.0,no,11/4/16,Shanghai Jiao Tong University;University of California Berkeley;University of California Berkeley;University of California Berkeley,Computer vision;Deep learning;Applications,-1;-1;-1;-1,-1;10;10;10,-1;-1,usa,usa,n,4
199,ICLR,2017,Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning,Werner Zellinger;Thomas Grubinger;Edwin Lughofer;Thomas Natschl√§ger;Susanne Saminger-Platz,werner.zellinger@jku.at;thomas.grubinger@scch.at;edwin.lughofer@jku.at;thomas.natschlaeger@scch.at;susanne.saminger-platz@jku.at,6;7;9,4;4;5,Accept (Poster),3,3,0.0,no,11/4/16,Johannes Kepler University Linz;Software Competence Center Hagenberg;Johannes Kepler University Linz;Software Competence Center Hagenberg;Johannes Kepler University Linz,Transfer Learning;Deep learning;Computer vision,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;4
200,ICLR,2017,Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music,Haizi Yu;Lav R. Varshney,haiziyu7@illinois.edu;varshney@illinois.edu,6;8;6,3;4;3,Accept (Poster),5,1,0.0,no,11/4/16,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1,-1;-1,-1;-1,usa,usa,n,3;1
201,ICLR,2017,PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications,Tim Salimans;Andrej Karpathy;Xi Chen;Diederik P. Kingma,tim@openai.com;karpathy@openai.com;peter@openai.com;dpkingma@openai.com,6;7;7,3;4;5,Accept (Poster),5,5,0.0,no,11/5/16,OpenAI;OpenAI;OpenAI;OpenAI,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
202,ICLR,2017,Latent Sequence Decompositions,William Chan;Yu Zhang;Quoc Le;Navdeep Jaitly,williamchan@cmu.edu;yzhang87@mit.edu;qvl@google.com;ndjaitly@google.com,7;8;7,4;4;5,Accept (Poster),2,3,0.0,no,11/4/16,Carnegie Mellon University;Massachusetts Institute of Technology;Google;Google,Speech;Applications;Natural language processing;Deep learning,1;9;-1;-1,23;5;-1;-1,-1;-1,NAN,NAN,n,
203,ICLR,2017,HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving,Cezary Kaliszyk;Fran√ßois Chollet;Christian Szegedy,cezary.kaliszyk@uibk.ac.at;fchollet@google.com;szegedy@google.com,6;8;7,3;3;3,Accept (Poster),2,2,0.0,no,11/2/16,University of Innsbruck;Google;Google,,-1;-1;-1,307;-1;-1,-1;-1,NAN,NAN,n,1
204,ICLR,2017,Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks,Yossi Adi;Einat Kermany;Yonatan Belinkov;Ofer Lavi;Yoav Goldberg,yossiadidrum@gmail.com;einatke@il.ibm.com;belinkov@mit.edu;oferl@il.ibm.com;yoav.goldberg@gmail.com,8;8;8,5;4;4,Accept (Poster),5,3,0.0,no,11/3/16,Facebook;International Business Machines;Massachusetts Institute of Technology;International Business Machines;Bar-Ilan University,Natural language processing;Deep learning,-1;-1;9;-1;67,-1;-1;5;-1;489,-1;-1,europe,il,n,
205,ICLR,2017,Learning similarity preserving representations with neural similarity and context encoders,Franziska Horn;Klaus-Robert M√ºller,franziska.horn@campus.tu-berlin.de;klaus-robert.mueller@tu-berlin.de,3;2;3,4;5;4,Reject,3,1,0.0,no,11/3/16,TU Berlin;TU Berlin,Natural language processing;Unsupervised Learning;Supervised Learning,92;92,-1;-1,-1;-1,europe,de,n,3
206,ICLR,2017,Memory-augmented Attention Modelling for Videos,Rasool Fakoor;Abdel-rahman Mohamed;Margaret Mitchell;Sing Bing Kang;Pushmeet Kohli,rasool.fakoor@mavs.uta.edu;asamir@microsoft.com;margarmitchell@gmail.com;SingBing.Kang@microsoft.com;pkohli@microsoft.com,4;4;4,4;5,Reject,9,3,0.0,no,11/4/16,"University of Texas, Arlington;Microsoft;;Microsoft;Microsoft",Deep learning;Multi-modal learning;Computer vision,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
207,ICLR,2017,Neural Causal Regularization under the Independence of Mechanisms Assumption,Mohammad Taha Bahadori;Krzysztof Chalupka;Edward Choi;Robert Chen;Walter F. Stewart;Jimeng Sun,bahadori@gatech.edu;kjchalup@caltech.edu;mp2893@gatech.edu;rchen87@gatech.edu;StewarWF@sutterhealth.org;jsun@cc.gatech.edu,5;4;6,4;4;5,Reject,7,5,0.0,no,11/4/16,Georgia Institute of Technology;California Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;;Georgia Institute of Technology,Deep learning;Applications,11;92;11;11;-1;11,33;2;33;33;-1;33,-1;-1,usa,usa,n,
208,ICLR,2017,New Learning Approach By Genetic Algorithm In A Convolutional Neural Network For Pattern Recognition,Mohammad Ali Mehrolhassani;Majid Mohammadi,Alimehrolhassani@yahoo.com;Mohammadi@uk.ac.ir,3;3;2,5;5;5,Reject,6,7,0.0,no,11/1/16,Shahid Bahonar University;University of Tehran,Deep learning;Supervised Learning;Optimization;Computer vision,-1;-1,-1;747,-1;-1,europe,ch,n,
209,ICLR,2017,Bit-Pragmatic Deep Neural Network Computing,Jorge Albericio;Patrick Judd;Alberto Delmas;Sayeh Sharify;Andreas Moshovos,jorge.albericio@gmail.com;judd@ece.utoronto.ca;delmas1@ece.utoronto.ca;sayeh@ece.utoronto.ca;moshovos@ece.utoronto.ca,6;7;5,3;2;2,Invite to Workshop Track,1,6,0.0,no,11/4/16,University of Toronto;Toronto University;Toronto University;Toronto University;Toronto University,Deep learning;Applications,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,10
210,ICLR,2017,Learning Identity Mappings with Residual Gates,Pedro H. P. Savarese;Leonardo O. Mazza;Daniel R. Figueiredo,savarese@land.ufrj.br;leonardomazza@poli.ufrj.br;daniel@land.ufrj.br,5;5;6,5;5;4,Reject,3,9,0.0,no,11/4/16,Federal University of Rio de Janeiro - UFRJ;Federal University of Rio de Janeiro - UFRJ;Federal University of Rio de Janeiro - UFRJ,Computer vision;Deep learning;Optimization,-1;-1;-1,693;693;693,-1;-1,NAN,NAN,n,
211,ICLR,2017,Investigating Different Context Types and Representations for Learning Word Embeddings,Bofang Li;Tao Liu;Zhe Zhao;Buzhou Tang;Xiaoyong Du,libofang@ruc.edu.cn;tliu@ruc.edu.cn;helloworld@ruc.edu.cn;tangbuzhou@gmail.com;duyong@ruc.edu.cn,4;6;4,5;4;3,Reject,4,5,0.0,no,11/4/16,"University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;;University of Illinois, Urbana-Champaign",Unsupervised Learning;Natural language processing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,n,3
212,ICLR,2017,Neural Combinatorial Optimization with Reinforcement Learning,Irwan Bello*;Hieu Pham*;Quoc V. Le;Mohammad Norouzi;Samy Bengio,ibello@google.com;hyhieu@google.com;qvl@google.com;mnorouzi@google.com;bengio@google.com,6;6;6,4;4;4,Reject,16,8,0.0,no,11/4/16,Google;Google;Google;Google;Google,Reinforcement Learning;Deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,10
213,ICLR,2017,A Differentiable Physics Engine for Deep Learning in Robotics,Jonas Degrave;Michiel Hermans;Joni Dambre;Francis wyffels,Jonas.Degrave@UGent.be;x@UGent.be;Joni.Dambre@UGent.be;Francis.wyffels@UGent.be,5;5;6,2;4;4,Invite to Workshop Track,3,4,0.0,no,11/3/16,Ghent University;;;Ghent University,Deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,
214,ICLR,2017,Two Methods for Wild Variational Inference,Qiang Liu;Yihao Feng,qiang.liu@dartmouth.edu;yihao.feng.gr@dartmouth.edu,3;3;3,4;4;4,Reject,1,1,0.0,no,11/4/16,Dartmouth College;Dartmouth College,Theory,149;149,82;82,-1;-1,usa,usa,n,
215,ICLR,2017,Sample Importance in Training Deep Neural Networks,Tianxiang Gao;Vladimir Jojic,tgao@cs.unc.edu;vjojic@cs.unc.edu,2;7;3,4;4;4,Reject,6,4,0.0,no,11/4/16,"University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",Deep learning;Supervised Learning,67;67,-1;-1,-1;-1,NAN,NAN,n,
216,ICLR,2017,Neural Code Completion,Chang Liu;Xin Wang;Richard Shin;Joseph E. Gonzalez;Dawn Song,xinw@eecs.berkeley.edu;liuchang@eecs.berkeley.edu;ricshin@berkeley.edu;jegonzal@berkeley.edu;dawnsong@cs.berkeley.edu,5;5;4,4;4;4,Reject,3,7,0.0,no,11/4/16,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep learning;Applications,-1;-1;-1;-1;-1,10;10;10;10;10,-1;-1,usa,usa,n,
217,ICLR,2017,Demystifying ResNet,Sihan Li;Jiantao Jiao;Yanjun Han;Tsachy Weissman,lisihan13@mails.tsinghua.edu.cn;jiantao@stanford.edu;yjhan@stanford.edu;tsachy@stanford.edu,4;5;4,4;3;5,Reject,7,3,0.0,no,11/3/16,"Tsinghua University, Tsinghua University;Stanford University;Stanford University;Stanford University",Deep learning;Optimization;Theory,5;3;3;3,35;3;3;3,-1;-1,usa,usa,y,9
218,ICLR,2017,Adjusting for Dropout Variance in Batch Normalization and Weight Initialization,Dan Hendrycks;Kevin Gimpel,dan@ttic.edu;kgimpel@ttic.edu,5;7;6,4;4;4,Reject,2,5,0.0,no,11/4/16,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,,-1;-1,380;380,-1;-1,NAN,NAN,n,
219,ICLR,2017,Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability,Alberto Delm√°s Lascorz;Sayeh Sharify;Patrick Judd;Andreas Moshovos,delmasl1@ece.utoronto.ca;sayeh@ece.utoronto.ca;moshovos@ece.utoronto.ca,5;5;6;4;4,5;5;2;1;3,Reject,2,8,0.0,no,11/4/16,Toronto University;Toronto University;Toronto University,Deep learning;Applications,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
220,ICLR,2017,Cooperative Training of Descriptor and Generator Networks,Jianwen Xie;Yang Lu;Ruiqi Gao;Song-Chun Zhu;Ying Nian Wu,jianwen@ucla.edu;yanglv@ucla.edu;ruiqigao@ucla.edu;sczhu@stat.ucla.edu;ywu@stat.ucla.edu,4;3;6,3;4;4,Reject,2,2,0.0,no,11/4/16,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Unsupervised Learning;Deep learning,-1;-1;-1;-1;-1,14;14;14;14;14,-1;-1,usa,usa,n,
221,ICLR,2017,Regularizing Neural Networks by Penalizing Confident Output Distributions,Gabriel Pereyra;George Tucker;Jan Chorowski;Lukasz Kaiser;Geoffrey Hinton,pereyra@google.com;gjt@google.com;chorowski@google.com;lukaszkaiser@google.com;geoffhinton@google.com,6;5;5,4;4;4,Reject,4,3,0.0,no,11/4/16,Google;Google;Google;Google;Google,Deep learning;Supervised Learning;Speech;Structured prediction,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
222,ICLR,2017,Song From PI: A Musically Plausible Network for Pop Music Generation,Hang Chu;Raquel Urtasun;Sanja Fidler,chuhang1122@cs.toronto.edu;urtasun@cs.toronto.edu;fidler@cs.toronto.edu,4;6;7,3;4;3,Invite to Workshop Track,3,1,0.0,no,11/4/16,University of Toronto;University of Toronto;University of Toronto,Applications,22;22;22,22;22;22,-1;-1,canada,ca,n,
223,ICLR,2017,Dataset Augmentation in Feature Space,Terrance DeVries;Graham W. Taylor,terrance@uoguelph.ca;gwtaylor@uoguelph.ca,4;7;6,5;4;5,Invite to Workshop Track,2,4,0.0,no,11/4/16,University of Guelph;University of Guelph,Unsupervised Learning,286;286,398;398,-1;-1,canada,ca,n,
224,ICLR,2017,Recurrent Neural Networks for Multivariate Time Series with Missing Values,Zhengping Che;Sanjay Purushotham;Kyunghyun Cho;David Sontag;Yan Liu,zche@usc.edu;spurusho@usc.edu;kyunghyun.cho@nyu.edu;dsontag@cs.nyu.edu;yanliu.cs@usc.edu,6;5;6,4;3;3,Reject,4,4,0.0,no,11/4/16,University of Southern California;University of Southern California;New York University;New York University;University of Southern California,Deep learning,22;22;22;22;22,60;60;32;32;60,-1;-1,usa,usa,n,
225,ICLR,2017,Counterpoint by Convolution,Cheng-Zhi Anna Huang;Tim Cooijmans;Adam Roberts;Aaron Courville;Douglas Eck,chengzhiannahuang@gmail.com;tim.cooijmans@umontreal.ca;adarob@google.com;aaron.courville@umontreal.ca;deck@google.com,6;5;6,5;4;3,Reject,2,4,0.0,no,11/4/16,Mila;University of Montreal;Google;University of Montreal;Google,Deep learning;Applications;Unsupervised Learning,149;92;-1;92;-1,240;103;-1;103;-1,-1;-1,NAN,NAN,n,5
226,ICLR,2017,Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech,Herve Glotin;Julien Ricard;Randall Balestriero,glotin@univ-tln.fr;julien.ricard@gmail.com;randallbalestriero@gmail.com,6;6;4,3;5;4,Invite to Workshop Track,1,8,0.0,no,11/4/16,CNRS university Toulon;;Rice University,Applications;Supervised Learning;Deep learning;Speech,-1;-1;92,-1;-1;87,-1;-1,australasia,au,n,6
227,ICLR,2017,Finding a Jack-of-All-Trades: An Examination of Semi-supervised Learning in Reading Comprehension,Rudolf Kadlec;Ond≈ôej Bajgar;Peter Hrincar;Jan Kleindienst,rudolf_kadlec@cz.ibm.com;obajgar@cz.ibm.com;phrincar@cz.ibm.com;jankle@cz.ibm.com,6;4;3,4;4;4,Reject,5,5,0.0,no,11/4/16,International Business Machines;International Business Machines;International Business Machines;International Business Machines,Natural language processing;Semi-Supervised Learning;Deep learning;Transfer Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;3
228,ICLR,2017,Efficient Summarization with Read-Again and Copy Mechanism,Wenyuan Zeng;Wenjie Luo;Sanja Fidler;Raquel Urtasun,cengwy13@mails.tsinghua.edu.cn;wenjie@cs.toronto.edu;fidler@cs.toronto.edu;urtasun@cs.toronto.edu,5;6;5,4;4;5,Reject,4,4,0.0,no,11/4/16,"Tsinghua University, Tsinghua University;University of Toronto;University of Toronto;University of Toronto",,5;22;22;22,35;22;22;22,-1;-1,canada,ca,n,
229,ICLR,2017,The Predictron: End-To-End Learning and Planning,David Silver;Hado van Hasselt;Matteo Hessel;Tom Schaul;Arthur Guez;Tim Harley;Gabriel Dulac-Arnold;David Reichert;Neil Rabinowitz;Andre Barreto;Thomas Degris,davidsilver@google.com;hado@google.com;mtthss@google.com;schaul@google.com;aguez@google.com;tharley@google.com;dulacarnold@google.com;reichert@google.com;ncr@google.com;andrebarreto@google.com;degris@google.com,4;6;9,4;5;2,Reject,2,10,0.0,no,11/4/16,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Deep learning;Reinforcement Learning;Supervised Learning;Semi-Supervised Learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
230,ICLR,2017,Training Group Orthogonal Neural Networks with Privileged Information,Yunpeng Chen;Xiaojie Jin;Jiashi Feng;Shuicheng Yan,chenyunpeng@u.nus.edu;xiaojie.jin@u.nus.edu;elefjia@nus.edu.sg;yanshuicheng@360.cn,6;5;6,4;4;4,Reject,2,4,0.0,no,11/3/16,National University of Singapore;National University of Singapore;National University of Singapore;Qihoo 360 Technology Co. Ltd,Deep learning;Computer vision;Supervised Learning,15;15;15;-1,24;24;24;-1,-1;-1,NAN,NAN,n,2;1
231,ICLR,2017,Neural Data Filter for Bootstrapping Stochastic Gradient Descent,Yang Fan;Fei Tian;Tao Qin;Tie-Yan Liu,v-yanfa@microsoft.com;fetia@microsoft.com;taoqin@microsoft.com;tie-yan.liu@microsoft.com,4;6;7,5;4,Invite to Workshop Track,2,8,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;Microsoft,Reinforcement Learning;Deep learning;Optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
232,ICLR,2017,Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning,Joshua Achiam;Shankar Sastry,jachiam@berkeley.edu;sastry@coe.berkeley.edu,6;6;6,3;3;4,Invite to Workshop Track,1,3,0.0,no,11/4/16,University of California Berkeley;University of California Berkeley,Reinforcement Learning,-1;-1,10;10,-1;-1,usa,usa,n,
233,ICLR,2017,Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond,Levent Sagun;Leon Bottou;Yann LeCun,leventsagun@gmail.com;leon@bottou.org;yann@cs.nyu.edu,3;4;4,4;5;5,Reject,0,8,0.0,no,11/4/16,Facebook;Facebook;New York University,Optimization;Deep learning,-1;-1;22,-1;-1;32,-1;-1,usa,usa,n,
234,ICLR,2017,Extensions and Limitations of the Neural GPU,Eric Price;Wojciech Zaremba;Ilya Sutskever,ecprice@cs.utexas.edu;woj@openai.com;ilyasu@openai.com,5;4;5,3;4;4,Reject,0,2,0.0,no,11/4/16,"University of Texas, Austin;OpenAI;OpenAI",,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1;4
235,ICLR,2017,Options Discovery with Budgeted Reinforcement Learning,Aurelia L√©on;Ludovic Denoyer,aurelia.leon@lip6.fr;ludovic.denoyer@lip6.fr,5;4;5;4,4;5;5;4,Reject,2,3,0.0,no,11/4/16,LIP6;LIP6,Reinforcement Learning,-1;-1,-1;-1,-1;-1,asia,ir,n,
236,ICLR,2017,On orthogonality and learning recurrent networks with long term dependencies,Eugene Vorontsov;Chiheb Trabelsi;Samuel Kadoury;Chris Pal,eugene.vorontsov@gmail.com;chiheb.trabelsi@polymtl.ca;samuel.kadoury@polymtl.ca;christopher.pal@polymtl.ca,7;5;5,4;4;5,Reject,5,4,0.0,no,11/5/16,Polytechnique Montreal;Polytechnique Montreal;Polytechnique Montreal;Polytechnique Montreal,Deep learning,286;286;286;286,-1;-1;-1;-1,-1;-1,canada,ca,n,1
237,ICLR,2017,Learning Continuous Semantic Representations of Symbolic Expressions,Miltiadis Allamanis;Pankajan Chanthirasegaran;Pushmeet Kohli;Charles Sutton,m.allamanis@ed.ac.uk;pankajan.chanthirasegaran@ed.ac.uk;pkohli@microsoft.com;csutton@ed.ac.uk,7;5;6,3;3;4,Invite to Workshop Track,2,5,0.0,no,11/4/16,University of Edinburgh;University of Edinburgh;Microsoft;University of Edinburgh,Deep learning,31;31;-1;31,27;27;-1;27,-1;-1,europe,uk,n,
238,ICLR,2017,Fuzzy paraphrases in learning word representations with a lexicon,Yuanzhi Ke;Masafumi Hagiwara,enshika8811.a6@keio.jp;hagiwara@keio.jp,5;3;6,3;4;4,Reject,1,9,0.0,no,11/3/16,Keio University;Keio University,Natural language processing;Unsupervised Learning,286;286,603;603,-1;-1,asia,jp,n,
239,ICLR,2017,Unsupervised Deep Learning of State Representation Using Robotic Priors ,Timothee LESORT;David FILLIAT,timothee.lesort@ensta-paristech.fr;david.filliat@ensta-paristech.fr,3;3;3,5;4;4,Reject,2,2,0.0,no,11/4/16,ENSTA ParisTech;ENSTA ParisTech,Deep learning;Computer vision;Unsupervised Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
240,ICLR,2017,LSTM-Based System-Call Language Modeling and Ensemble Method for Host-Based Intrusion Detection,Gyuwan Kim;Hayoon Yi;Jangho Lee;Yunheung Paek;Sungroh Yoon,kgwmath@snu.ac.kr;hyyi@snu.ac.kr;ubuntu@snu.ac.kr;ypaek@snu.ac.kr;sryoon@snu.ac.kr,5;5;8,3;4;3,Reject,1,4,0.0,no,11/4/16,Seoul National University;Seoul National University;Seoul National University;Seoul National University;Seoul National University,,46;46;46;46;46,72;72;72;72;72,-1;-1,asia,kr,n,3
241,ICLR,2017,Epitomic Variational Autoencoders,Serena Yeung;Anitha Kannan;Yann Dauphin;Li Fei-Fei,serena@cs.stanford.edu;akannan@fb.com;ynd@fb.com;feifeili@cs.stanford.edu,5;4;8,5;5;5,Reject,1,4,0.0,no,11/4/16,Stanford University;Facebook;Facebook;Stanford University,Unsupervised Learning,3;-1;-1;3,3;-1;-1;3,-1;-1,usa,usa,n,5
242,ICLR,2017,Layer Recurrent Neural Networks,Weidi Xie;Alison Noble;Andrew Zisserman,weidi.xie@eng.ox.ac.uk;alison.noble@eng.ox.ac.uk;az@robots.ox.ac.uk,7;6;5,4;4;5,Reject,4,5,0.0,no,11/4/16,University of Oxford;University of Oxford;University of Oxford,Deep learning;Computer vision,31;31;31,1;1;1,-1;-1,europe,uk,n,2
243,ICLR,2017,Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization,Junhyuk Oh;Satinder Singh;Honglak Lee;Pushmeet Kohli,junhyuk@umich.edu;baveja@umich.edu;honglak@umich.edu;pkohli@microsoft.com,4;7;5;3,3;5;4,Reject,2,6,0.0,no,11/4/16,University of Michigan;University of Michigan;University of Michigan;Microsoft,Reinforcement Learning;Deep learning,11;11;11;-1,21;21;21;-1,-1;-1,NAN,NAN,n,3;1
244,ICLR,2017,NEWSQA: A MACHINE COMPREHENSION DATASET,Adam Trischler;Tong Wang;Xingdi Yuan;Justin Harris;Alessandro Sordoni;Philip Bachman;Kaheer Suleman,adam.trischler@maluuba.com;tong.wang@maluuba.com;eric.yuan@maluuba.com;justin.harris@maluuba.com;alessandro.sordoni@maluuba.com;phil.bachman@maluuba.com;k.suleman@maluuba.com,6;6;6,4;4;3,Reject,3,5,0.0,no,11/4/16,Maluuba;Maluuba;Maluuba;Maluuba;Maluuba;Maluuba;Maluuba,Natural language processing;Deep learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
245,ICLR,2017,Coarse Pruning of Convolutional Neural Networks with Random Masks,Sajid Anwar;Wonyong Sung,sajid@dsp.snu.ac.kr;wysung@snu.ac.kr,6;4;5,3;4;4,Reject,0,0,0.0,no,11/4/16,Seoul National University;Seoul National University,,46;46,72;72,-1;-1,asia,kr,n,4
246,ICLR,2017,Universality in halting time,Levent Sagun;Thomas Trogdon;Yann LeCun,leventsagun@gmail.com;tom.trogdon@gmail.com;yann@cs.nyu.edu,5;5;2,4;3;4,Reject,3,4,0.0,no,11/4/16,Facebook;;New York University,Optimization,-1;-1;22,-1;-1;32,-1;-1,usa,usa,n,
247,ICLR,2017,Generating Interpretable Images with Controllable Structure,Scott Reed;A√§ron van den Oord;Nal Kalchbrenner;Victor Bapst;Matt Botvinick;Nando de Freitas,reedscot@google.com;avdnoord@google.com;nalk@google.com;vbapst@google.com;botvinick@google.com;nandodefreitas@google.com,7;5;6,3;3;3,Invite to Workshop Track,2,1,0.0,no,11/4/16,Google;Google;Google;Google;Google;Google,Deep learning;Computer vision;Multi-modal learning;Natural language processing,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
248,ICLR,2017,Representing inferential uncertainty in deep neural networks through sampling,Patrick McClure;Nikolaus Kriegeskorte,Patrick.McClure@mrc-cbu.cam.ac.uk;Nikolaus.Kriegeskorte@mrc-cbu.cam.ac.uk,4;4;5,4;4;4,Reject,1,5,0.0,no,11/4/16,University of Cambridge;University of Cambridge,Deep learning;Theory;Applications,67;67,4;4,-1;-1,europe,uk,n,11
249,ICLR,2017,Online Structure Learning for Sum-Product Networks with Gaussian Leaves,Wilson Hsu;Agastya Kalra;Pascal Poupart,wwhsu@uwaterloo.ca;a6kalra@uwaterloo.ca;ppoupart@uwaterloo.ca,6;4;4,3;2;1,Invite to Workshop Track,2,11,0.0,no,11/4/16,University of Waterloo;University of Waterloo;University of Waterloo,Unsupervised Learning;Deep learning,31;31;31,174;174;174,-1;-1,canada,ca,n,10
250,ICLR,2017,A Convolutional Encoder Model for Neural Machine Translation,Jonas Gehring;Michael Auli;David Grangier;Yann N. Dauphin,jgehring@fb.com;michaelauli@fb.com;grangier@fb.com;ynd@fb.com,7;6;6,3;5;4,Reject,4,5,0.0,no,11/4/16,Facebook;Facebook;Facebook;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
251,ICLR,2017,Reference-Aware Language Models,Zichao Yang;Phil Blunsom;Chris Dyer;Wang Ling,zichaoy@cs.cmu.edu;pblunsom@google.com;cdyer@google.com;lingwang@google.com,6;5;5,4;4;4,Reject,4,3,0.0,no,11/4/16,Carnegie Mellon University;Google;Google;Google,Natural language processing;Deep learning,1;-1;-1;-1,23;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
252,ICLR,2017,Deep Learning with Sets and Point Clouds,Siamak Ravanbakhsh;Jeff Schneider;Barnabas Poczos,mravanba@cs.cmu.edu;bapoczos@cs.cmu.edu;jeff.schneider@cs.cmu.edu,5;7;5,4;1;4,Invite to Workshop Track,2,7,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Deep learning;Structured prediction;Computer vision;Supervised Learning;Semi-Supervised Learning,1;1;1,23;23;23,-1;-1,usa,usa,n,
253,ICLR,2017,Exponential Machines,Alexander Novikov;Mikhail Trofimov;Ivan Oseledets,novikov@bayesgroup.ru;mikhail.trofimov@phystech.edu;i.oseledets@skoltech.ru,5;6;7;6,4;4;3;4,Invite to Workshop Track,4,8,0.0,no,11/4/16,Google;Moscow Institute of Physics and Technology;Skolkovo Institute of Science and Technology,Supervised Learning;Optimization,-1;-1;-1,-1;313;-1,-1;-1,europe,russia,y,
254,ICLR,2017,Adversarial examples in the physical world,Alexey Kurakin;Ian J. Goodfellow;Samy Bengio,kurakin@google.com;ian@openai.com;bengio@google.com,5;6;6,4;3;3,Invite to Workshop Track,2,3,0.0,no,11/2/16,Google;OpenAI;Google,Supervised Learning;Computer vision,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
255,ICLR,2017,Gated Multimodal Units for Information Fusion,John Arevalo;Thamar Solorio;Manuel Montes-y-G√≥mez;Fabio A. Gonz√°lez,jearevaloo@unal.edu.co;solorio@cs.uh.edu;smmontesg@inaoep.mx;fagonzalezo@unal.edu.co,6;7;4,3;5;4,Invite to Workshop Track,4,5,0.0,no,11/5/16,Universidad Nacional de Colombia;University of Houston;;Universidad Nacional de Colombia,Multi-modal learning;Applications;Supervised Learning,-1;149;-1;-1,-1;365;-1;-1,-1;-1,NAN,NAN,n,
256,ICLR,2017,Warped Convolutions: Efficient Invariance to Spatial Transformations,Joao F. Henriques;Andrea Vedaldi,joao@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk,6;7;6,5;4;4,Reject,5,6,0.0,no,11/4/16,University of Oxford;University of Oxford,,31;31,1;1,-1;-1,europe,uk,y,
257,ICLR,2017,Human perception in computer vision,Ron Dekel,ron.dekel@weizmann.ac.il,7;6;6,3;4;3,Reject,1,4,0.0,no,11/4/16,Weizmann Institute,Computer vision;Transfer Learning,92,-1,-1,NAN,NAN,n,2;1
258,ICLR,2017,Binary Paragraph Vectors,Karol Grzegorczyk;Marcin Kurdziel,kgr@agh.edu.pl;kurdziel@agh.edu.pl,6;5;6,2;5;3,Reject,1,5,0.0,no,11/4/16,"AGH University of Science and Technology, Krakow, Poland;AGH University of Science and Technology, Krakow, Poland",Natural language processing;Transfer Learning,-1;-1,708;708,-1;-1,NAN,NAN,n,6
259,ICLR,2017,Modularized Morphing of Neural Networks,Tao Wei;Changhu Wang;Chang Wen Chen,taowei@buffalo.edu;chw@microsoft.com;chencw@buffalo.edu,7;6;7;5,4;5;5;4,Invite to Workshop Track,1,5,0.0,no,11/4/16,"State University of New York, Buffalo;Microsoft;State University of New York, Buffalo",Deep learning;Computer vision,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1;10
260,ICLR,2017,NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ONLINE MODEL ADAPTION IN A CHANGING WORLD,Sahil Garg;Irina Rish;Guillermo Cecchi;Aurelie Lozano,sahilgar@usc.edu;rish@us.ibm.com;gcecchi@us.ibm.com;aclozano@us.ibm.com,7;5;5,4;3;4,Reject,1,4,0.0,no,11/4/16,University of Southern California;International Business Machines;International Business Machines;International Business Machines,Unsupervised Learning;Computer vision;Transfer Learning;Optimization;Applications,22;-1;-1;-1,60;-1;-1;-1,-1;-1,NAN,NAN,y,
261,ICLR,2017,Low-rank passthrough neural networks,Antonio Valerio Miceli Barone,amiceli@inf.ed.ac.uk,4;5;6,4;4,Reject,3,10,0.0,no,11/4/16,University of Edinburgh,Deep learning,31,27,-1,europe,uk,n,
262,ICLR,2017,Towards Understanding the Invertibility of Convolutional Neural Networks,Anna C. Gilbert;Yi Zhang;Kibok Lee;Yuting Zhang;Honglak Lee,annacg@umich.edu;yeezhang@umich.edu;kibok@umich.edu;yutingzh@umich.edu;honglak@umich.edu,5;7;4,4;3;4,Reject,2,3,1.0,no,11/4/16,University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan,Deep learning;Theory,11;11;11;11;11,21;21;21;21;21,-1;-1,usa,usa,y,
263,ICLR,2017,Recurrent Normalization Propagation,C√©sar Laurent;Nicolas Ballas;Pascal Vincent,cesar.laurent@umontreal.ca;nicolas.ballas@umontreal.ca;pascal.vincent@umontreal.ca,4;6;6,4;4;3,Invite to Workshop Track,3,3,0.0,no,11/4/16,University of Montreal;University of Montreal;University of Montreal,Deep learning;Optimization,92;92;92,103;103;103,-1;-1,canada,ca,n,3;5
264,ICLR,2017,Learning in Implicit Generative Models,Shakir Mohamed;Balaji Lakshminarayanan,shakir@google.com;balajiln@google.com,6;8;7,4;4;3,Invite to Workshop Track,0,5,1.0,no,11/4/16,Google;Google,Unsupervised Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,11;5;4
265,ICLR,2017,Intelligible Language Modeling with Input Switched Affine Networks,Jakob Foerster;Justin Gilmer;Jan Chorowski;Jascha Sohl-dickstein;David Sussillo,jakob.foerster@cs.ox.ac.uk;gilmer@google.com;jan.chorowski@cs.uni.wroc.pl;jaschasd@google.com;sussillo@google.com,6;7;6,4;3;4,Reject,1,1,0.0,no,11/5/16,University of Oxford;Google;University of Wroclaw;Google;Google,Natural language processing;Deep learning;Supervised Learning,31;-1;286;-1;-1,1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
266,ICLR,2017,Lifelong Perceptual Programming By Example,Alexander L. Gaunt;Marc Brockschmidt;Nate Kushman;Daniel Tarlow,t-algaun@microsoft.com;mabrocks@microsoft.com;nkushman@microsoft.com;dtarlow@microsoft.com,2;8;4,5;4;4,Invite to Workshop Track,1,8,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;Microsoft,Deep learning;Supervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
267,ICLR,2017,Alternating Direction Method of Multipliers for Sparse Convolutional Neural Networks,Farkhondeh Kiaee;Christian Gagn√©;and Mahdieh Abbasi,farkhondeh.kiaee.1@ulaval.ca;christian.gagne@gel.ulaval.ca;mahdieh.abbasi.1@ulaval.ca,7;7;6;5,3;5;4;3,Reject,1,7,1.0,no,11/4/16,Laval university;Laval university;Laval university,Deep learning;Computer vision;Optimization,-1;-1;-1,265;265;265,-1;-1,NAN,NAN,n,1
268,ICLR,2017,Sentence Ordering using Recurrent Neural Networks,Lajanugen Logeswaran;Honglak Lee;Dragomir Radev,llajan@umich.edu;honglak@eecs.umich.edu;radev@umich.edu,6;6;7,4;4;3,Reject,3,1,0.0,no,11/3/16,University of Michigan;University of Michigan;University of Michigan,Natural language processing;Deep learning;Applications,11;11;11,21;21;21,-1;-1,usa,usa,n,3
269,ICLR,2017,Towards an automatic Turing test: Learning to evaluate dialogue responses,Ryan Lowe;Michael Noseworthy;Iulian V. Serban;Nicolas Angelard-Gontier;Yoshua Bengio;Joelle Pineau,rlowe1@cs.mcgill.ca;michael.noseworthy@mail.mcgill.ca;julianserban@gmail.com;nicolas.angelard-gontier@mail.mcgill.ca;yoshua.umontreal@gmail.com;jpineau@cs.mcgill.ca,5;4;7,4;4;4,Invite to Workshop Track,4,5,0.0,no,11/5/16,McGill University;McGill University;University College London;McGill University;University of Montreal;McGill University,Natural language processing;Applications,92;92;31;92;92;92,42;42;-1;42;103;42,-1;-1,canada,ca,n,
270,ICLR,2017,Inference and Introspection in Deep Generative Models of Sparse Data,Rahul G. Krishnan;Matthew Hoffman,rahul@cs.nyu.edu;matthoffm@adobe.com,6;7;5;5,4;3;3;4,Reject,1,5,0.0,no,11/4/16,New York University;Adobe Systems,Unsupervised Learning;Deep learning,22;-1,32;-1,-1;-1,NAN,NAN,n,5
271,ICLR,2017,TreNet: Hybrid Neural Networks for Learning the Local Trend in Time Series,Tao Lin;Tian Guo;Karl Aberer,tao.lin@epfl.ch;tian.guo@epfl.ch;karl.aberer@epfl.ch,6;5;4,4;5;4,Reject,4,5,0.0,no,11/5/16,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
272,ICLR,2017,Compositional Kernel Machines,Robert Gens;Pedro Domingos,rcg@cs.washington.edu;pedrod@cs.washington.edu,5;5;6;5,3;4;4;4,Invite to Workshop Track,1,4,0.0,no,11/3/16,University of Washington;University of Washington,Computer vision;Supervised Learning,5;5,25;25,-1;-1,usa,usa,n,2
273,ICLR,2017,Introducing Active Learning for CNN under the light of Variational Inference,Melanie Ducoffe;Frederic Precioso,ducoffe@i3s.unice.fr;precioso@i3s.unice.fr,6;6;6,1;2;2,Reject,6,4,0.0,no,11/5/16,Universit√© C√¥te d'Azur;Universit√© C√¥te d'Azur,Deep learning;Supervised Learning;Optimization,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
274,ICLR,2017,L-SR1: A Second Order Optimization Method for Deep Learning,Vivek Ramamurthy;Nigel Duffy,vivek.ramamurthy@sentient.ai;nigel.duffy@sentient.ai,4;4;5,4;3;3,Reject,3,6,0.0,no,11/4/16,"Sentient Technologies, Inc.;Sentient Technologies, Inc.",,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
275,ICLR,2017,Adversarial examples for generative models,Jernej Kos;Ian Fischer;Dawn Song,jernej@kos.mx;iansf@google.com;dawnsong.travel@gmail.com,5;6;5,4;3;4,Reject,3,3,0.0,no,11/5/16,National University of Singapore;Google;University of California Berkeley,Computer vision;Unsupervised Learning,15;-1;-1,24;-1;10,-1;-1,usa,usa,n,5;4
276,ICLR,2017,Hierarchical compositional feature learning,Miguel Lazaro-Gredilla;Yi Liu;D. Scott Phoenix;Dileep George,miguel@vicarious.com;yi@vicarious.com;scott@vicarious.com;dileep@vicarious.com,5;5;4,4;4;4,Reject,1,3,0.0,no,11/3/16,Vicarious Inc.;Vicarious Inc.;Vicarious Inc.;Vicarious Inc.,Unsupervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
277,ICLR,2017,Unsupervised Perceptual Rewards for Imitation Learning,Pierre Sermanet;Kelvin Xu;Sergey Levine,sermanet@google.com;kelvinxx@google.com;slevine@google.com,4;6;6,4;4;5,Invite to Workshop Track,2,3,0.0,no,11/4/16,Google;Google;Google,Computer vision;Deep learning;Unsupervised Learning;Reinforcement Learning;Transfer Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
278,ICLR,2017,Submodular Sum-product Networks for Scene Understanding,Abram L. Friesen;Pedro Domingos,afriesen@cs.washington.edu;pedrod@cs.washington.edu,5;4;4,4;3;3,Reject,1,4,0.0,no,11/4/16,University of Washington;University of Washington,Computer vision;Structured prediction,5;5,25;25,-1;-1,usa,usa,y,10
279,ICLR,2017,Semi-Supervised Detection of Extreme Weather Events in Large Climate Datasets,Evan Racah;Christopher Beckham;Tegan Maharaj;Prabhat;Christopher Pal,eracah@lbl.gov;christopher.beckham@polymtl.ca;tegan.maharaj@polymtl.ca;prabhat@lbl.gov;christopher.pal@polymtl.ca,6;4;6,3;4;4,Reject,2,3,0.0,no,11/4/16,Lawrence Berkeley National Lab;Polytechnique Montreal;Polytechnique Montreal;Lawrence Berkeley National Lab;Polytechnique Montreal,Semi-Supervised Learning;Applications;Computer vision,-1;286;286;-1;286,-1;-1;-1;-1;-1,-1;-1,canada,ca,n,
280,ICLR,2017,Progressive Attention Networks for Visual Attribute Prediction,Paul Hongsuck Seo;Zhe Lin;Scott Cohen;Xiaohui Shen;Bohyung Han,hsseo@postech.ac.kr;zlin@adobe.com;scohen@adobe.com;xshen@adobe.com;bhhan@postech.ac.kr,7;4;6,4;5;3,Reject,2,5,0.0,no,11/3/16,POSTECH;Adobe Systems;Adobe Systems;Adobe Systems;POSTECH,Deep learning;Computer vision;Multi-modal learning,92;-1;-1;-1;92,104;-1;-1;-1;104,-1;-1,asia,kr,n,8
281,ICLR,2017,Fast Adaptation in Generative Models with Generative Matching Networks,Sergey Bartunov;Dmitry P. Vetrov,sbos.net@gmail.com;vetrovd@yandex.ru,4;5;7,4;3;4,Reject,2,4,0.0,no,11/4/16,Google;Higher School of Economics,Deep learning;Unsupervised Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,6;1;5
282,ICLR,2017,Classless Association using Neural Networks,Federico Raue;Sebastian Palacio;Andreas Dengel;Marcus Liwicki,federico.raue@dfki.de;sebastian.palacio@dfki.de;andreas.dengel@dfki.de;liwicki@cs.uni-kl.de,5;5;6,4;3;3,Reject,1,4,0.0,no,11/4/16,German Research Center for AI;German Research Center for AI;German Research Center for AI;TU Kaiserslautern,,-1;-1;-1;149,-1;-1;-1;-1,-1;-1,europe,de,n,
283,ICLR,2017,Recurrent Coevolutionary Feature Embedding Processes for Recommendation,Hanjun Dai*;Yichen Wang*;Rakshit Trivedi;Le Song,hanjundai@gatech.edu;yichen.wang@gatech.edu;rstrivedi@gatech.edu;lsong@cc.gatech.edu,6;6;6,4;4;3,Reject,4,4,0.0,no,11/4/16,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Deep learning;Applications,11;11;11;11,33;33;33;33,-1;-1,usa,usa,n,
284,ICLR,2017,Unsupervised Learning of State Representations for Multiple Tasks,Antonin Raffin;Sebastian H√∂fer;Rico Jonschkowski;Oliver Brock;Freek Stulp,antonin.raffin@ensta-paristech.fr;sebastian.hoefer@tu-berlin.de;rico.jonschkowski@tu-berlin.de;oliver.brock@tu-berlin.de;freek.stulp@dlr.de,6;5;6,4;4;3,Reject,2,1,0.0,no,11/4/16,ENSTA ParisTech;TU Berlin;TU Berlin;TU Berlin;German Aerospace Center (DLR),Reinforcement Learning;Unsupervised Learning,-1;92;92;92;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
285,ICLR,2017,A Neural Stochastic Volatility Model,Rui Luo;Xiaojun Xu;Weinan Zhang;Jun Wang,r.luo@cs.ucl.ac.uk;xuxj@apex.sjtu.edu.cn;wnzhang@apex.sjtu.edu.cn;j.wang@cs.ucl.ac.uk,6;5;5,4;4;3,Reject,3,1,0.0,no,11/4/16,University College London;Shanghai Jiao Tong University;Shanghai Jiao Tong University;University College London,Deep learning;Supervised Learning,31;46;46;31,-1;214;214;-1,-1;-1,europe,uk,n,5
286,ICLR,2017,Playing SNES in the Retro Learning Environment,Nadav Bhonker;Shai Rozenberg;Itay Hubara,nadavbh@tx.technion.ac.il;shairoz@tx.technion.ac.il;itayhubara@gmail.com,5;4;7,4;4;4,Reject,3,3,0.0,no,11/4/16,"Technion, Technion;Technion, Technion;Technion",Reinforcement Learning;Deep learning;Games,22;22;-1,-1;-1;-1,-1;-1,asia,in,n,
287,ICLR,2017,Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants,Randall Balestriero;Herve Glotin,randallbalestriero@gmail.com;glotin@univ-tln.fr,4;5;4,3;3;5,Reject,1,4,0.0,no,11/4/16,Rice University;CNRS university Toulon,Unsupervised Learning;Applications;Deep learning,92;-1,87;-1,-1;-1,NAN,NAN,n,
288,ICLR,2017,Boosting Image Captioning with Attributes,Ting Yao;Yingwei Pan;Yehao Li;Zhaofan Qiu;Tao Mei,tiyao@microsoft.com;v-yipan@microsoft.com;v-yehl@microsoft.com;v-zhqiu@microsoft.com;tmei@microsoft.com,4;5;6,5;4;5,Reject,3,3,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Computer vision;Applications,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;3
289,ICLR,2017,Recursive Regression with Neural Networks: Approximating the HJI PDE Solution,Vicen√ß Rubies Royo;Claire Tomlin,vrubies@berkeley.edu;tomlin@berkeley.edu,7;3;5,3;5;1,Invite to Workshop Track,0,4,0.0,no,11/4/16,University of California Berkeley;University of California Berkeley,Supervised Learning;Games;Theory,-1;-1,10;10,-1;-1,usa,usa,n,1
290,ICLR,2017,Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders,Nat Dilokthanakul;Pedro A. M. Mediano;Marta Garnelo;Matthew C.H. Lee;Hugh Salimbeni;Kai Arulkumaran;Murray Shanahan,n.dilokthanakul14@imperial.ac.uk;pmediano@imperial.ac.uk;m.garnelo-abellanas13@imperial.ac.uk;matthew.lee13@imperial.ac.uk;h.salimbeni15@imperial.ac.uk;kailash.arulkumaran13@imperial.ac.uk;m.shanahan@imperial.ac.uk,8;4;4,4;4;4,Reject,6,5,0.0,no,11/3/16,Imperial College London;Imperial College London;Imperial College London;Imperial College London;Imperial College London;Imperial College London;Imperial College London,Unsupervised Learning;Deep learning,31;31;31;31;31;31;31,8;8;8;8;8;8;8,-1;-1,europe,uk,n,5
291,ICLR,2017,Taming the waves: sine as activation function in deep neural networks,Giambattista Parascandolo;Heikki Huttunen;Tuomas Virtanen,giambattista.parascandolo@tut.fi;heikki.huttunen@tut.fi;tuomas.virtanen@tut.fi,4;4;4,4;4;4,Reject,1,5,0.0,no,11/4/16,Tampere University of Technology;Tampere University of Technology;Tampere University of Technology,Theory;Deep learning;Optimization;Supervised Learning,-1;-1;-1,552;552;552,-1;-1,NAN,NAN,n,1
292,ICLR,2017,Significance of Softmax-Based Features over Metric Learning-Based Features,Shota Horiguchi;Daiki Ikami;Kiyoharu Aizawa,horiguchi@hal.t.u-tokyo.ac.jp;ikami@hal.t.u-tokyo.ac.jp;aizawa@hal.t.u-tokyo.ac.jp,5;7;4,4;4;5,Reject,3,10,0.0,no,10/31/16,The University of Tokyo;The University of Tokyo;The University of Tokyo,Computer vision;Deep learning,46;46;46,39;39;39,-1;-1,NAN,NAN,n,2
293,ICLR,2017,Deep Generalized Canonical Correlation Analysis,Adrian Benton;Huda Khayrallah;Biman Gujral;Drew Reisinger;Sheng Zhang;Raman Arora,adrian@cs.jhu.edu;huda@jhu.edu;bgujral1@jhu.edu;reisinger@cogsci.jhu.edu;zsheng2@jhu.edu;arora@cs.jhu.edu,6;5;7,4;5;3,Reject,0,4,0.0,no,11/4/16,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,Unsupervised Learning;Deep learning;Multi-modal learning,46;46;46;46;46;46,17;17;17;17;17;17,-1;-1,usa,usa,n,
294,ICLR,2017,Learning Recurrent Span Representations for Extractive Question Answering,Kenton Lee;Tom Kwiatkowksi;Ankur Parikh;Dipanjan Das,kentonl@cs.washington.edu;tomkwiat@google.com;aparikh@google.com;dipanjand@google.com,7;6;6,4;5;3,Reject,1,1,0.0,no,11/4/16,University of Washington;Google;Google;Google,Natural language processing,5;-1;-1;-1,25;-1;-1;-1,-1;-1,NAN,NAN,n,3
295,ICLR,2017,GRAM: Graph-based Attention Model for Healthcare Representation Learning,Edward Choi;Mohammad Taha Bahadori;Le Song;Walter F. Stewart;Jimeng Sun,mp2893@gatech.edu;bahadori@gatech.edu;lsong@cc.gatech.edu;stewarwf@sutterhealth.org;jsun@cc.gatech.edu,6;6;6,4;4;3,Reject,2,6,0.0,no,11/4/16,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;;Georgia Institute of Technology,Deep learning;Applications,11;11;11;-1;11,33;33;33;-1;33,-1;-1,usa,usa,n,8;10
296,ICLR,2017,Improving Sampling from Generative Autoencoders with Markov Chains,Antonia Creswell;Kai Arulkumaran;Anil Anthony Bharath,ac2211@imperial.ac.uk;ka709@imperial.ac.uk;aab01@imperial.ac.uk,3;3;3,5;4;4,Reject,5,4,0.0,no,10/31/16,Imperial College London;Imperial College London;Imperial College London,Deep learning;Unsupervised Learning;Theory,31;31;31,8;8;8,-1;-1,europe,uk,y,5;4
297,ICLR,2017,Towards Principled Methods for Training Generative Adversarial Networks,Martin Arjovsky;Leon Bottou,martinarjovsky@gmail.com;leonb@fb.com,8;10;7,3;5;4,Accept (Oral),4,16,0.0,no,11/4/16,New York University;Facebook,,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1;5;4
298,ICLR,2017,Learning Disentangled Representations in Deep Generative Models,N. Siddharth;Brooks Paige;Alban Desmaison;Jan-Willem van de Meent;Frank Wood;Noah D. Goodman;Pushmeet Kohli;Philip H.S. Torr,nsid@robots.ox.ac.uk;brooks@robots.ox.ac.uk;alban@robots.ox.ac.uk;j.vandemeent@northeastern.edu;fwood@robots.ox.ac.uk;ngoodman@stanford.edu;pkohli@microsoft.com;philip.torr@eng.ox.ac.uk,6;6;5,5;4;3,Reject,2,4,0.0,no,11/4/16,University of Oxford;University of Oxford;University of Oxford;Northeastern University;University of Oxford;Stanford University;Microsoft;University of Oxford,Semi-Supervised Learning;Deep learning;Computer vision,31;31;31;15;31;3;-1;31,1;1;1;778;1;3;-1;1,-1;-1,europe,uk,n,10;5
299,ICLR,2017,Local minima in training of deep networks,Grzegorz Swirszcz;Wojciech Marian Czarnecki;Razvan Pascanu,swirszcz@google.com;lejlot@google.com;razp@google.com,5;5;3,3;4;5,Reject,3,4,0.0,no,11/4/16,Google;Google;Google,Theory;Deep learning;Supervised Learning;Optimization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,1
300,ICLR,2017,Compact Embedding of Binary-coded Inputs and Outputs using Bloom Filters,Joan Serr√†;Alexandros Karatzoglou,joan.serra@telefonica.com;alexandros.karatzoglou@telefonica.com,3;6;6,3;4;4,Reject,2,6,0.0,no,11/3/16,Telefonica Research;Telefonica Research,Applications;Deep learning;Unsupervised Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,10
301,ICLR,2017,RenderGAN: Generating Realistic Labeled Data,Leon Sixt;Benjamin Wild;Tim Landgraf,leon.sixt@fu-berlin.de;benjamin.wild@fu-berlin.de;tim.landgraf@fu-berlin.de,5;6;6,3;4;4,Invite to Workshop Track,3,6,0.0,no,11/4/16,Freie Universit√§t Berlin;Freie Universit√§t Berlin;Freie Universit√§t Berlin,Unsupervised Learning;Computer vision;Deep learning;Applications,286;286;286,-1;-1;-1,-1;-1,europe,de,n,2;5;4
302,ICLR,2017,BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL,Vincent Roger;Marius Bartcus;Faicel Chamroukhi;Herv√© Glotin,vincent-roger@etud.univ-tln.fr;marius.bartcus@gmail.com;faicel.chamroukhi@unicaen.fr;glotin@univ-tln.fr,5;4;5,3;3;5,Reject,2,0,0.0,no,11/4/16,CNRS university Toulon;;University of Caen Normandie;CNRS university Toulon,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;11
303,ICLR,2017,Tuning Recurrent Neural Networks with Reinforcement Learning,Natasha Jaques;Shixiang Gu;Richard E. Turner;Douglas Eck,jaquesn@mit.edu;sg717@cam.ac.uk;ret26@cam.ack.uk;deck@google.com,5;6;5,5;3;5,Invite to Workshop Track,7,5,1.0,no,11/4/16,Massachusetts Institute of Technology;University of Cambridge;University of Cambridge;Google,Deep learning;Reinforcement Learning;Structured prediction;Supervised Learning;Applications,9;67;67;-1,5;4;4;-1,-1;-1,NAN,NAN,n,1
304,ICLR,2017,An Analysis of Feature Regularization for Low-shot Learning,Zhuoyuan Chen;Han Zhao;Xiao Liu;Wei Xu,chenzhuoyuan@baidu.com;liuxiao12@baidu.com;wei.xu@baidu.com;han.zhao@cs.cmu.edu,5;6;6,4;3;3,Reject,3,4,0.0,no,11/4/16,Baidu;Baidu;Baidu;Carnegie Mellon University,Deep learning;Computer vision,-1;-1;-1;1,-1;-1;-1;23,-1;-1,usa,usa,n,
305,ICLR,2017,Gradients of Counterfactuals,Mukund Sundararajan;Ankur Taly;Qiqi Yan,mukunds@google.com;ataly@google.com;qiqiyan@google.com,3;3;5,4;4;4,Reject,0,4,0.0,no,11/4/16,Google;Google;Google,Deep learning;Computer vision;Theory,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
306,ICLR,2017,Encoding and Decoding Representations with Sum- and Max-Product Networks,Antonio Vergari;Robert Peharz;Nicola Di Mauro;Floriana Esposito,antonio.vergari@uniba.it;robert.peharz@medunigraz.at;nicola.dimauro@uniba.it;floriana.esposito@uniba.it,6;3;6,4;3;4,Reject,3,8,0.0,no,11/4/16,University of Bari;Medical University of Graz;University of Bari;University of Bari,,286;-1;286;286,110;452;110;110,-1;-1,europe,uk,y,1;5
307,ICLR,2017,Skip-graph: Learning graph embeddings with an encoder-decoder model,John Boaz Lee;Xiangnan Kong,jtlee@wpi.edu;xkong@wpi.edu,5;6;7,4;1;3,Reject,3,5,0.0,no,11/4/16,Worcester Polytechnic Institute;Worcester Polytechnic Institute,Unsupervised Learning;Deep learning,149;149,-1;-1,-1;-1,usa,usa,n,3;10
308,ICLR,2017,Information Dropout: learning optimal representations through noise,Alessandro Achille;Stefano Soatto,achille@cs.ucla.edu;soatto@cs.ucla.edu,4;6;6,4;4;4,Reject,2,3,0.0,no,11/4/16,"University of California, Los Angeles;University of California, Los Angeles",Theory;Deep learning,-1;-1,14;14,-1;-1,usa,usa,n,1;5
309,ICLR,2017,Deep unsupervised learning through spatial contrasting,Elad Hoffer;Itay Hubara;Nir Ailon,ehoffer@tx.technion.ac.il;itayh@tx.technion.ac.il;nailon@cs.technion.ac.il,5;6;7,4;4;4,Reject,3,3,0.0,no,10/19/16,"Technion, Technion;Technion, Technion;Technion, Technion",Unsupervised Learning;Deep learning;Computer vision,22;22;22,-1;-1;-1,-1;-1,NAN,NAN,n,
310,ICLR,2017,Dynamic Partition Models,Marc Goessling;Yali Amit,goessling@uchicago.edu,3;6;3,4;3;4,Reject,2,4,0.0,no,11/2/16,University of Chicago,,46,10,-1;-1,usa,usa,n,
311,ICLR,2017,End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension,Yang Yu;Wei Zhang;Bowen Zhou;Kazi Hasan;Mo Yu;Bing Xiang,yu@us.ibm.com;zhangwei@us.ibm.com;zhou@us.ibm.com;kshasan@us.ibm.com;yum@us.ibm.com;bingxia@us.ibm.com,4;5;6,3;3;3,Reject,3,1,0.0,no,11/4/16,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,Natural language processing;Deep learning;Supervised Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
312,ICLR,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Haoran Tang;Rein Houthooft;Davis Foote;Adam Stooke;Xi Chen;Yan Duan;John Schulman;Filip De Turck;Pieter Abbeel,hrtang.alex@berkeley.edu;rein.houthooft@ugent.be;djfoote@berkeley.edu;adam.stooke@berkeley.edu;peter@openai.com;rocky@openai.com;joschu@openai.com;filip.deturck@ugent.be;pieter@openai.com,6;4;7,4;3;4,Reject,4,4,0.0,no,11/5/16,University of California Berkeley;Ghent University;University of California Berkeley;University of California Berkeley;OpenAI;OpenAI;OpenAI;Ghent University;OpenAI,Deep learning;Reinforcement Learning;Games,-1;-1;-1;-1;-1;-1;-1;-1;-1,10;118;10;10;-1;-1;-1;118;-1,-1;-1,NAN,NAN,n,1;10
313,ICLR,2017,Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models,Ashwin K Vijayakumar;Michael Cogswell;Ramprasaath R. Selvaraju;Qing Sun;Stefan Lee;David Crandall;Dhruv Batra,ashwinkv@vt.edu;cogswell@vt.edu;ram21@vt.edu;sunqing@vt.edu;steflee@vt.edu;djcran@indiana.edu;dbatra@vt.edu,6;6;4,4;4;4,Reject,2,5,0.0,no,11/4/16,Virginia Tech;Virginia Tech;Virginia Tech;Virginia Tech;Virginia Tech;Indiana University;Virginia Tech,Deep learning;Computer vision;Natural language processing,67;67;67;67;67;67;67,-1;-1;-1;-1;-1;151;-1,-1;-1,usa,usa,n,3
314,ICLR,2017,Extrapolation and learning equations,Georg Martius;Christoph H. Lampert,gmartius@ist.ac.at;chl@ist.ac.at,7;3;6,4;4;3,Invite to Workshop Track,3,4,0.0,no,11/2/16,Institute of Science and Technology Austria;Institute of Science and Technology Austria,Supervised Learning;Deep learning;Structured prediction,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
315,ICLR,2017,Learning Python Code Suggestion with a Sparse Pointer Network,Avishkar Bhoopchand;Tim Rockt√§schel;Earl Barr;Sebastian Riedel,avishkar.bhoopchand.15@ucl.ac.uk;t.rocktaschel@cs.ucl.ac.uk;e.barr@cs.ucl.ac.uk;s.riedel@cs.ucl.ac.uk,6;6;5,4;4;4,Reject,4,5,0.0,no,11/3/16,University College London;University College London;University College London;University College London,,31;31;31;31,-1;-1;-1;-1,-1;-1,europe,uk,n,3
316,ICLR,2017,Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models,Xinyun Chen;Bo Li;Yevgeniy Vorobeychik,jungyhuk@gmail.com;bbbli@umich.edu;yevgeniy.vorobeychik@vanderbilt.edu,5;5;4,4;3;3,Reject,4,4,0.0,no,11/4/16,University of California Berkeley;University of Michigan;Vanderbilt University,Deep learning,-1;11;286,10;21;108,-1;-1,usa,usa,n,1;4
317,ICLR,2017,Representation Stability as a Regularizer for Improved Text Analytics Transfer Learning,Matthew Riemer;Elham Khabiri;Richard Goodwin,mdriemer@us.ibm.com;ekhabiri@us.ibm.com;rgoodwin@us.ibm.com,5;7;6,4;4;3,Reject,2,3,0.0,no,11/4/16,International Business Machines;International Business Machines;International Business Machines,Deep learning;Transfer Learning;Natural language processing,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,6;1
318,ICLR,2017,Exploring LOTS in Deep Neural Networks,Andras Rozsa;Manuel Gunther;Terrance E. Boult,andras.rozsa@yahoo.com;siebenkopf@googlemail.com;tboult@vast.uccs.edu,6;6;6,4;4;4,Reject,3,7,2.0,no,11/4/16,"University of Colorado, Colorado Springs;University of Colorado, Colorado Springs;University of Colorado, Colorado Springs",Deep learning;Computer vision,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
319,ICLR,2017,Development of JavaScript-based deep learning platform and application to distributed training,Masatoshi Hidaka;Ken Miura;Tatsuya Harada,hidaka@mi.t.u-tokyo.ac.jp;miura@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,6;4;7,4;2;3,Invite to Workshop Track,2,3,2.0,no,11/4/16,The University of Tokyo;The University of Tokyo;The University of Tokyo,Deep learning,46;46;46,39;39;39,-1;-1,NAN,NAN,n,8
320,ICLR,2017,Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM,Chun-Liang Li;Siamak Ravanbakhsh;Barnabas Poczos,chunlial@cs.cmu.edu;mravanba@cs.cmu.edu;bapoczos@cs.cmu.edu,5;5;6,5;4;4,Reject,3,5,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Deep learning;Unsupervised Learning,1;1;1,23;23;23,-1;-1,usa,usa,y,10;5
321,ICLR,2017,Out-of-class novelty generation: an experimental foundation,Mehdi Cherti;Bal√°zs K√©gl;Akƒ±n Kazak√ßƒ±,mehdicherti@gmail.com;balazskegl@gmail.com;akin.kazakci@mines-paristech.fr,7;6;4;5,4;3;4;3,Reject,3,4,0.0,no,11/5/16,Forschungszentrum Jülich;;Mines ParisTech,Deep learning;Unsupervised Learning,-1;-1;-1,-1;-1;265,-1;-1,NAN,NAN,n,5
322,ICLR,2017,End-to-End Learnable Histogram Filters,Rico Jonschkowski;Oliver Brock,rico.jonschkowski@tu-berlin.de;oliver.brock@tu-berlin.de,4;4;3,3;3;3,Reject,3,4,0.0,no,11/5/16,TU Berlin;TU Berlin,Deep learning;Unsupervised Learning,92;92,-1;-1,-1;-1,europe,de,n,
323,ICLR,2017,Character-aware Attention Residual Network for Sentence Representation,Xin Zheng;Zhenzhou Wu,xzheng008@e.ntu.edu.sg;zhenzhou.wu@sap.com,4;4;4,4;4;5,Reject,3,3,0.0,no,11/5/16,Nanyang Technological University;SAP,Deep learning,31;286,54;257,-1;-1,asia,in,n,8
324,ICLR,2017,ReasoNet: Learning to Stop Reading in Machine Comprehension,Yelong Shen;Po-Sen Huang;Jianfeng Gao;Weizhu Chen,yeshen@microsoft.com;pshuang@microsoft.com;jfgao@microsoft.com;wzchen@microsoft.com,5;5;6,3;3;5,Reject,4,2,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;Microsoft,Deep learning;Natural language processing,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,10
325,ICLR,2017,Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory,Yelong Shen*;Po-Sen Huang*;Ming-Wei Chang;Jianfeng Gao,yeshen@microsoft.com;pshuang@microsoft.com;minchang@microsoft.com;jfgao@microsoft.com,6;6;6,4;4;4,Reject,6,4,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;Microsoft,Deep learning;Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
326,ICLR,2017,Efficient iterative policy optimization,Nicolas Le Roux,nicolas@le-roux.name,3;7;5,2;3;4,Reject,1,3,0.0,no,11/4/16,0,,,,-1,NAN,NAN,y,
327,ICLR,2017,A hybrid network: Scattering and Convnet,Edouard Oyallon,edouard.oyallon@ens.fr,7;5;7,4;4;3,Reject,5,4,0.0,no,11/4/16,Ecole Normale Superieure,Computer vision;Unsupervised Learning;Deep learning,92,66,-1,europe,fr,n,
328,ICLR,2017,Cortical-Inspired Open-Bigram Representation for Handwritten Word Recognition,Th√©odore Bluche;Christopher Kermorvant;Claude Touzet;Herv√© Glotin,tb@a2ia.com;kermorvant@teklia.com;claude.touzet@univ-amu.fr;glotin@univ-tln.fr,5;4;7,5;4;5,Reject,2,3,0.0,no,11/4/16,A2iA SAS;TEKLIA;Aix Marseille Univ;CNRS university Toulon,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
329,ICLR,2017,Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space Matter?,Xue Bin Peng;Michiel van de Panne,xbpeng@cs.ubc.ca;van@cs.ubc.ca,6;6;6,4;4;3,Reject,2,3,0.0,no,11/2/16,University of British Columbia;University of British Columbia,Reinforcement Learning;Applications,67;67,36;36,-1;-1,canada,ca,n,
330,ICLR,2017,Learning to Discover Sparse Graphical Models,Eugene Belilovsky;Kyle Kastner;Gael Varoquaux;Matthew B. Blaschko,eugene.belilovsky@inria.fr;kyle.kastner@umontreal.ca;gael.varoquaux@inria.fr;matthew.blaschko@esat.kuleuven.be,6;7;5,3;3;2,Invite to Workshop Track,0,4,0.0,no,11/4/16,INRIA;University of Montreal;INRIA;KU Leuven,,-1;92;-1;149,-1;103;-1;40,-1;-1,europe,be,y,10
331,ICLR,2017,Efficient Communications in Training Large Scale Neural Networks,Linnan Wang;Wei Wu;George Bosilca;Richard Vuduc;Zenglin Xu,linnan.wang@gatech.edu;wwu12@vols.utk.edu;bosilca@icl.utk.edu;richie@cc.gatech.edu;zlxu@uestc.edu.cn,5;5,3;5,Reject,5,6,0.0,no,11/2/16,"Georgia Institute of Technology;University of Tennessee, Knoxville;University of Tennessee, Knoxville;Georgia Institute of Technology;University of Electronic Science and Technology of China",Applications;Deep learning,11;149;149;11;-1,33;-1;-1;33;933,-1;-1,NAN,NAN,n,
332,ICLR,2017,Semantic Noise Modeling for Better Representation Learning,Hyo-Eun Kim;Sangheum Hwang;Kyunghyun Cho,hekim@lunit.io;shwang@lunit.io;kyunghyun.cho@nyu.edu,4;3;2,4;4;4,Reject,1,7,0.0,no,11/2/16,Lunit Inc.;Lunit Inc.;New York University,Deep learning;Supervised Learning,-1;-1;22,-1;-1;32,-1;-1,usa,usa,n,1
333,ICLR,2017,Attentive Recurrent Comparators,Pranav Shyam;Ambedkar Dukkipati,pranavm.cs13@rvce.edu.in;ad@csa.iisc.ernet.in,4;5;3,5;2;5,Reject,0,0,0.0,no,11/5/16,"R V College of Engineering;Indian Institute of Science Bangalore., Indian institute of science, Bangalore",Deep learning;Computer vision,-1;-1,-1;247,-1;-1,NAN,NAN,n,8;11;1
334,ICLR,2017,Combating Deep Reinforcement Learning's Sisyphean Curse with Intrinsic Fear,Zachary C. Lipton;Jianfeng Gao;Lihong Li;Jianshu Chen;Li Deng,zlipton@cs.ucsd.edu;jfgao@microsoft.com;lihongli.cs@gmail.com;jianshuc@microsoft.com;deng@microsoft.com,5;4;4,2;3;4,Reject,2,5,0.0,no,11/3/16,"University of California, San Diego;Microsoft;Amazon;Microsoft;Microsoft",Deep learning;Reinforcement Learning;Applications,-1;-1;-1;-1;-1,41;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
335,ICLR,2017,Shift Aggregate Extract Networks,Francesco Orsini;Daniele Baracchi;Paolo Frasconi,francesco.orsini@kuleuven.be;daniele.baracchi@unifi.it;paolo.frasconi@unifi.it,5;5;3,3;3;2,Invite to Workshop Track,1,3,0.0,no,11/4/16,KU Leuven;Universit√† di Firenze;Universit√† di Firenze,Supervised Learning,149;-1;-1,40;-1;-1,-1;-1,NAN,NAN,n,10
336,ICLR,2017,Unsupervised Pretraining for Sequence to Sequence Learning,Prajit Ramachandran;Peter J. Liu;Quoc V. Le,prajitram@gmail.com;peterjliu@google.com;qvl@google.com,6;7;5,4;5;5,Reject,3,4,0.0,no,11/4/16,"University of Illinois, Urbana Champaign;Google;Google",Natural language processing;Deep learning;Semi-Supervised Learning;Transfer Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;1
337,ICLR,2017,Revisiting Batch Normalization For Practical Domain Adaptation,Yanghao Li;Naiyan Wang;Jianping Shi;Jiaying Liu;Xiaodi Hou,lyttonhao@pku.edu.cn;winsty@gmail.com;shijianping5000@gmail.com;liujiaying@pku.edu.cn;xiaodi.hou@gmail.com,4;6;5,4;3;4,Reject,1,7,1.0,no,11/4/16,Peking University;;;Peking University;TUSIMPLE LLC,,14;-1;-1;14;-1,29;-1;-1;29;-1,-1;-1,NAN,NAN,n,2;1
338,ICLR,2017,A Neural Knowledge Language Model,Sungjin Ahn;Heeyoul Choi;Tanel Parnamaa;Yoshua Bengio,sjn.ahn@gmail.com;heeyoul@gmail.com;tanel.parnamaa@gmail.com;yoshua.bengio@umontreal.ca,6;6;6,4;4;3,Reject,2,5,0.0,no,11/3/16,Rutgers University;Handong Global University;;University of Montreal,Natural language processing;Deep learning,22;-1;-1;92,-1;-1;-1;103,-1;-1,canada,ca,n,3;10
339,ICLR,2017,Dynamic Neural Turing Machine with Continuous and Discrete Addressing Schemes,Caglar Gulcehre;Sarath Chandar;Kyunghyun Cho;Yoshua Bengio,gulcehrc@iro.umontreal.ca;apsarathchandar@gmail.com;kyunghyun.cho@nyu.edu;yoshua.umontreal@gmail.com,6;4;7,4;4;4,Reject,3,6,0.0,no,11/4/16,University of Montreal;Polytechnique Montreal;New York University;University of Montreal,Deep learning;Natural language processing;Reinforcement Learning,92;286;22;92,103;-1;32;103,-1;-1,canada,ca,n,
340,ICLR,2017,Gated-Attention Readers for Text Comprehension,Bhuwan Dhingra;Hanxiao Liu;Zhilin Yang;William W. Cohen;Ruslan Salakhutdinov,bdhingra@cs.cmu.edu;hanxiaol@cs.cmu.edu;zhiliny@cs.cmu.edu;wcohen@cs.cmu.edu;rsalakhu@cs.cmu.edu,6;6;7,3;3,Reject,15,5,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Natural language processing;Deep learning;Supervised Learning,1;1;1;1;1,23;23;23;23;23,-1;-1,usa,usa,n,8
341,ICLR,2017,Deep Character-Level Neural Machine Translation By Learning Morphology,Shenjian Zhao;Zhihua Zhang,sword.york@gmail.com;zhzhang@math.pku.edu.cn,5;6;7,5;4;4,Reject,2,9,0.0,no,11/4/16,Shanghai Jiao Tong University;Peking University,Natural language processing;Deep learning,-1;14,-1;29,-1;-1,asia,cn,n,8;3
342,ICLR,2017,Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations,Philip Blair;Yuval Merhav;Joel Barry,pblair@basistech.com;yuval@basistech.com;joelb@basistech.com,5;8;6,3;4;3,Invite to Workshop Track,3,2,0.0,no,11/4/16,Northeastern University;Basistech;Basistech,Natural language processing;Applications,15;-1;-1,778;-1;-1,-1;-1,NAN,NAN,n,3;10
343,ICLR,2017,Adding Gradient Noise Improves Learning for Very Deep Networks,Arvind Neelakantan;Luke Vilnis;Quoc V. Le;Lukasz Kaiser;Karol Kurach;Ilya Sutskever;James Martens,arvind@cs.umass.edu;luke@cs.umass.edu;qvl@google.com;lukaszkaiser@google.com;kkurach@google.com;ilyasu@openai.com;jmartens@cs.toronto.edu,4;4;7,5;4;5,Reject,1,4,0.0,no,11/4/16,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;Google;Google;Google;OpenAI;University of Toronto",,15;15;-1;-1;-1;-1;22,166;166;-1;-1;-1;-1;22,-1;-1,canada,ca,n,
344,ICLR,2017,Knowledge Adaptation: Teaching to Adapt,Sebastian Ruder;Parsa Ghaffari;John G. Breslin,sebastian.ruder@insight-centre.org;parsa@aylien.com;john.breslin@insight-centre.org,6;7;5,4;3;4,Reject,2,6,0.0,no,11/3/16,Insight Centre for Data Analytics;Aylien;Insight Centre for Data Analytics,Natural language processing;Deep learning;Transfer Learning;Unsupervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
345,ICLR,2017,Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks,David Balduzzi;Brian McWilliams;Tony Butler-Yeoman,david.balduzzi@vuw.ac.nz;brian@disneyresearch.com;butlertony@ecs.vuw.ac.nz,3;7;7,4;3;2,Invite to Workshop Track,1,3,0.0,no,11/4/16,"Victoria University Wellington;Disney Research, Disney;Victoria University Wellington",Deep learning;Optimization;Theory;Supervised Learning,-1;-1;-1,362;-1;362,-1;-1,australasia,nz,y,1;9
346,ICLR,2017,On the Expressive Power of Deep Neural Networks,Maithra Raghu;Ben Poole;Jon Kleinberg;Surya Ganguli;Jascha Sohl-Dickstein,maithrar@gmail.com;benmpoole@gmail.com;kleinber@cs.cornell.edu;sganguli@stanford.edu;jaschasd@google.com,3;6;5,3;5;3,Reject,4,5,0.0,no,11/4/16,Cornell University;Google;Cornell University;Stanford University;Google,Theory;Deep learning,5;-1;5;3;-1,19;-1;19;3;-1,-1;-1,NAN,NAN,y,
347,ICLR,2017,The loss surface of residual networks: Ensembles and the role of batch normalization,Etai Littwin;Lior Wolf,etai.littwin@gmail.com;liorwolf@gmail.com,7;3;7,3;5;3,Reject,3,6,0.0,no,11/4/16,Tel Aviv University;Tel Aviv University,Deep learning;Theory,31;31,216;216,-1;-1,europe,il,y,
348,ICLR,2017,Understanding trained CNNs by indexing neuron selectivity,Ivet Rafegas;Maria Vanrell;Lu√≠s A. Alexandre,ivet.rafegas@uab.cat;maria.vanrell@uab.cat;lfbaa@ubi.pt,7;3;7,4;5;3,Reject,3,4,0.0,no,11/4/16,Universitat Autonoma de Barcelona;Universitat Autonoma de Barcelona;Universidade da Beira Interior,Computer vision;Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
349,ICLR,2017,Riemannian Optimization for Skip-Gram Negative Sampling,Alexander Fonarev;Alexey Grinchuk;Gleb Gusev;Pavel Serdyukov;Ivan Oseledets,newo@newo.su;oleksii.hrinchuk@skolkovotech.ru;gleb57@yandex-team.ru;pavser@yandex-team.ru;ioseledets@skoltech.ru,4;5;6,4;3;3,Reject,0,4,0.0,no,11/4/16,Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Yandex;Yandex;Skolkovo Institute of Science and Technology,Natural language processing;Unsupervised Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,europe,russia,n,3
350,ICLR,2017,Exploring the Application of Deep Learning for Supervised Learning Problems,Jose Rozanec;Gilad Katz;Eui Chul Richard Shin;Dawn Song,jmrozanec@gmail.com;giladk@berkeley.edu;ricshin@berkeley.edu;dawnsong@eecs.berkeley.edu,4;3;5,3;5;4,Reject,2,2,0.0,no,11/5/16,University of Buenos Aires;University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep learning;Supervised Learning,-1;-1;-1;-1,-1;10;10;10,-1;-1,usa,usa,n,6
351,ICLR,2017,A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs,Shayne Longpre;Sabeek Pradhan;Caiming Xiong;Richard Socher,slongpre@cs.stanford.edu;sabeekp@cs.stanford.edu;cxiong@salesforce.com;rsocher@salesforce.com,5;5;5,4;4;4,Reject,2,0,0.0,no,11/4/16,Stanford University;Stanford University;SalesForce.com;SalesForce.com,Natural language processing;Deep learning;Supervised Learning,3;3;-1;-1,3;3;-1;-1,-1;-1,NAN,NAN,n,3
352,ICLR,2017,LipNet: End-to-End Sentence-level Lipreading,Yannis M. Assael;Brendan Shillingford;Shimon Whiteson;Nando de Freitas,yannis.assael@cs.ox.ac.uk;brendan.shillingford@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk;nando.de.freitas@cs.ox.ac.uk,4;6;4,4;3;4,Reject,6,14,1.0,no,11/4/16,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Computer vision;Deep learning,31;31;31;31,1;1;1;1,-1;-1,europe,uk,n,
353,ICLR,2017,Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment,Arash Shahriari,arash.shahriari@csiro.au,3;3;4,3;4;4,Reject,2,3,0.0,no,11/4/16,CSIRO,Deep learning;Transfer Learning;Supervised Learning;Optimization,-1,-1,-1,asia,in,n,6;1
354,ICLR,2017,DeepRebirth: A General Approach for Accelerating Deep Neural Network Execution on Mobile Devices,Dawei Li;Xiaolong Wang;Deguang Kong;Mooi Choo Chuah,dal312@lehigh.edu;visionxiaolong@gmail.com;doogkong@gmail.com,4;4;4,4;4;4,Reject,0,6,0.0,no,11/4/16,Lehigh University;International Business Machines;;Lehigh University,,149;-1;-1,441;-1;-1,-1;-1,asia,in,n,
355,ICLR,2017,Modelling Relational Time Series using Gaussian Embeddings,Ludovic Dos Santos;Ali Ziat;Ludovic Denoyer;Benjamin Piwowarski;Patrick Gallinari,ludovic.dossantos@lip6.fr;ali.ziat@vedecom.fr;ludovic.denoyer@lip6.fr;benjamin.piwowarski@lip6.fr;patrick.gallinari@lip6.fr,4;4;4,3;5;4,Reject,2,0,0.0,no,11/3/16,LIP6;;LIP6;LIP6;LIP6,Applications;Deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,asia,ir,n,
356,ICLR,2017,Higher Order Recurrent Neural Networks,Rohollah Soltani;Hui Jiang,rsoltani@cse.yorku.ca;hj@cse.yorku.ca,4;6;3,4;4;4,Reject,3,0,0.0,no,11/5/16,York University;York University,Deep learning;Natural language processing,149;149,316;316,-1;-1,asia,kr,n,3
357,ICLR,2017,Multi-task learning with deep model based reinforcement learning,Asier Mujika,asierm@student.ethz.ch,2;4;4,5;4;4,Reject,1,3,0.0,no,11/4/16,Swiss Federal Institute of Technology,Reinforcement Learning;Deep learning;Games;Transfer Learning,-1,-1,-1,NAN,NAN,n,
358,ICLR,2017,Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units,Dan Hendrycks;Kevin Gimpel,dan@ttic.edu;kgimpel@ttic.edu,4;5;5,4;4;4,Reject,3,1,0.0,no,11/4/16,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,,-1;-1,380;380,-1;-1,NAN,NAN,n,
359,ICLR,2017,Iterative Refinement for Machine Translation,Roman Novak;Michael Auli;David Grangier,roman.novak@polytechnique.edu;michaelauli@fb.com;grangier@fb.com,5;5;7;4,3;5;3;4,Reject,0,0,0.0,no,11/2/16,Ecole polytechnique;Facebook;Facebook,Natural language processing,-1;-1;-1,116;-1;-1,-1;-1,NAN,NAN,n,8;3
360,ICLR,2017,Machine Solver for Physics Word Problems,Megan Leszczynski;Jose Moreira,mel255@cornell.edu;jmoreira@us.ibm.com,4;4;5,4;4;4,Reject,1,4,0.0,no,11/4/16,Cornell University;International Business Machines,,5;-1,19;-1,-1;-1,NAN,NAN,n,
361,ICLR,2017,b-GAN: Unified Framework of Generative Adversarial Networks,Masatosi Uehara;Issei Sato;Masahiro Suzuki;Kotaro Nakayama;Yutaka Matsuo,uehara-masatoshi136@g.ecc.u-tokyo.ac.jp;sato@k.u-tokyo.ac.jp;masa@weblab.t.u-tokyo.ac.jp;nakayama@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,5;6;4,3;4;3,Reject,0,4,0.0,no,11/5/16,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,Deep learning;Unsupervised Learning,46;46;46;46;46,39;39;39;39;39,-1;-1,NAN,NAN,n,5;4
362,ICLR,2017,Structured Sequence Modeling with Graph Convolutional Recurrent Networks,Youngjoo Seo;Micha√´l Defferrard;Pierre Vandergheynst;Xavier Bresson,youngjoo.seo@epfl.ch;michael.defferrard@epfl.ch;pierre.vandergheynst@epfl.ch;xavier.bresson@gmail.com,4;4;4,4;4;4,Reject,3,3,0.0,no,11/4/16,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Nanyang Technological University,Structured prediction,-1;-1;-1;31,-1;-1;-1;54,-1;-1,asia,sg,n,3;1;10
363,ICLR,2017,Revisiting Denoising Auto-Encoders,Luis Gonzalo Sanchez Giraldo,lgsanchez@cs.miami.edu,4;4;5,5;4;4,Reject,4,0,0.0,no,11/5/16,University of Miami,,-1,183,-1,usa,usa,n,
364,ICLR,2017,Revisiting Distributed Synchronous SGD,Jianmin Chen*;Xinghao Pan*;Rajat Monga;Samy Bengio;Rafal Jozefowicz,jmchen@google.com;xinghao@google.com;rajatmonga@google.com;bengio@google.com;rafal@openai.com,6;6;5,4;4;3,Reject,9,3,0.0,no,11/1/16,Google;Google;Google;Google;OpenAI,Optimization;Deep learning;Applications,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
365,ICLR,2017,Here's My Point: Argumentation Mining with Pointer Networks,Peter Potash;Alexey Romanov;Anna Rumshisky,ppotash@cs.uml.edu;aromanov@cs.uml.edu;arum@cs.uml.edu,4;5;5,3;4;4,Reject,2,5,0.0,no,11/4/16,"University of Massachusetts, Lowell;University of Massachusetts, Lowell;University of Massachusetts, Lowell",Natural language processing,149;149;149,166;166;166,-1;-1,usa,usa,n,
366,ICLR,2017,DyVEDeep: Dynamic Variable Effort Deep Neural Networks,Sanjay Ganapathy;Swagath Venkataramani;Balaraman Ravindran;Anand Raghunathan,sanjaygana@gmail.com;venkata0@purdue.edu;ravi@cse.iitm.ac.in;raghunathan@purdue.edu,6;7;6,3;3;4,Reject,1,3,0.0,no,11/4/16,Indian Institute of Technology Madras;Purdue University;Indian Institute of Technology Madras;Purdue University,,-1;22;-1;22,-1;70;472;70,-1;-1,usa,usa,pdf miss,
367,ICLR,2017,Improved Architectures for Computer Go,Tristan Cazenave,Tristan.Cazenave@dauphine.fr,3;7;4;3,4;5;4;4,Reject,2,0,0.0,no,11/3/16,Univerist√© Paris-Dauphine,Games;Supervised Learning;Deep learning,-1,-1,-1,NAN,NAN,n,
368,ICLR,2017,Deep Variational Canonical Correlation Analysis,Weiran Wang;Xinchen Yan;Honglak Lee;Karen Livescu,weiranwang@ttic.edu;xcyan@umich.edu;honglak@umich.edu;klivescu@ttic.edu,5;5;7,4;4;4,Reject,3,4,0.0,no,11/4/16,Toyota Technological Institute at Chicago;University of Michigan;University of Michigan;Toyota Technological Institute at Chicago,,-1;11;11;-1,380;21;21;380,-1;-1,NAN,NAN,n,1;5
369,ICLR,2017,Charged Point Normalization: An Efficient Solution to the Saddle Point Problem,Armen Aghajanyan,armen.ag@live.com,5;4;4,4;4;3,Invite to Workshop Track,6,3,0.0,no,10/18/16,Facebook,Deep learning;Computer vision;Optimization,-1,-1,-1,NAN,NAN,n,9
370,ICLR,2017,Multi-label learning with semantic embeddings,Liping Jing;MiaoMiao Cheng;Liu Yang;Alex Gittens;Michael W. Mahoney,lpjing@bjtu.edu.cn;15112085@bjtu.edu.cn;11112191@bjtu.edu.cn;gittens@icsi.berkeley.edu;mmahoney@stat.berkeley.edu,4;4;5,4;4;4,Reject,3,0,0.0,no,10/31/16,Beijing Jiaotong University;Beijing Jiaotong University;Beijing Jiaotong University;University of California Berkeley;University of California Berkeley,Supervised Learning,-1;-1;-1;-1;-1,-1;-1;-1;10;10,-1;-1,usa,usa,n,
371,ICLR,2017,Emergent Predication Structure in Vector Representations of Neural Readers,Hai Wang;Takeshi Onishi;Kevin Gimpel;David McAllester,haiwang@ttic.edu;tonishi@ttic.edu;kgimpel@ttic.edu;mcallester@ttic.edu,6;6;5,5;4;3,Reject,3,2,0.0,no,11/4/16,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,Natural language processing;Deep learning;Applications,-1;-1;-1;-1,380;380;380;380,-1;-1,NAN,NAN,n,8
372,ICLR,2017,An Actor-critic Algorithm for Learning Rate Learning,Chang Xu;Tao Qin;Gang Wang;Tie-Yan Liu,changxu@nbjl.nankai.edu.cn;taoqin@microsoft.com;wgzwp@nbjl.nankai.edu.cn;tie-yan.liu@microsoft.com,3;5;4,5;4;4,Reject,3,0,0.0,no,11/3/16,Nankai University;Microsoft;Nankai University;Microsoft,Deep learning;Reinforcement Learning,-1;-1;-1;-1,905;-1;905;-1,-1;-1,NAN,NAN,n,
373,ICLR,2017,Joint Multimodal Learning with Deep Generative Models,Masahiro Suzuki;Kotaro Nakayama;Yutaka Matsuo,masa@weblab.t.u-tokyo.ac.jp;k-nakayama@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,5;3;5,5;4;3,Reject,4,0,0.0,no,11/4/16,The University of Tokyo;The University of Tokyo;The University of Tokyo,,46;46;46,39;39;39,-1;-1,NAN,NAN,n,5
374,ICLR,2017,Energy-Based Spherical Sparse Coding,Bailey Kong;Charless C. Fowlkes,bhkong@ics.uci.edu;fowlkes@ics.uci.edu,5;5;6,4;4;4,Reject,3,3,0.0,no,11/5/16,"University of California, Irvine;University of California, Irvine",,-1;-1,99;99,-1;-1,usa,usa,n,
375,ICLR,2017,Improving Invariance and Equivariance Properties of Convolutional Neural Networks,Christopher Tensmeyer;Tony Martinez,tensmeyer@byu.edu;martinez@cs.byu.edu,4;5;4,4;3;5,Reject,3,1,0.0,no,11/5/16,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,Deep learning,92;92,192;192,-1;-1,asia,hk,n,
376,ICLR,2017,Efficient Softmax Approximation for GPUs,√âdouard Grave;Armand Joulin;Moustapha Ciss√©;David Grangier;Herv√© J√©gou,egrave@fb.com;ajoulin@fb.com;moustaphacisse@fb.com;grangier@fb.com;rvj@fb.com,7;6;7,3;5;4,Invite to Workshop Track,1,5,0.0,no,11/4/16,Facebook;Facebook;Facebook;Facebook;Facebook,Natural language processing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;10
377,ICLR,2017,The Preimage of Rectifier Network Activities,Stefan Carlsson;Hossein Azizpour;Ali Razavian,stefanc@kth.se;azizpour@kth.se;razavian@kth.se,4;4;4,4;5,Reject,2,1,0.0,no,11/4/16,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",,149;149;149,160;160;160,-1;-1,NAN,NAN,n,
378,ICLR,2017,Deep Convolutional Neural Network Design Patterns,Leslie N. Smith;Nicholay Topin,leslie.smith@nrl.navy.mil;ntopin@umbc.edu,3;3;4,4;4;3,Reject,2,1,0.0,no,11/4/16,US Naval Research Lab;Boston College,,-1;149,-1;212,-1;-1,usa,usa,n,
379,ICLR,2017,OMG: Orthogonal Method of Grouping With Application of K-Shot Learning,Haoqi Fan;Yu Zhang;Kris M. Kitani,haoqif@andrew.cmu.edu;kkitani@cs.cmu.edu,4;4;4,4;4;5,Reject,2,0,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University,,1;1,23;23,-1;-1,usa,usa,n,
380,ICLR,2017,Spatio-Temporal Abstractions in Reinforcement Learning Through Neural Encoding,Nir Baram;Tom Zahavy;Shie Mannor,nirb@campus.technion.ac.il;tomzahavy@campus.technion.ac.il;shie@ee.technion.ac.il,4;4;4,5;5;4,Reject,2,1,0.0,no,11/4/16,"Technion, Technion;Technion, Technion;Technion, Technion",Reinforcement Learning;Deep learning,22;22;22,-1;-1;-1,-1;-1,NAN,NAN,n,
381,ICLR,2017,Making Stochastic Neural Networks from Deterministic Ones,Kimin Lee;Jaehyung Kim;Song Chong;Jinwoo Shin,kiminlee@kaist.ac.kr;jaehyungkim@kaist.ac.kr;songchong@kaist.edu;jinwoos@kaist.ac.kr,5;6,5;4,Reject,7,3,0.0,no,11/4/16,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST;Korea Advanced Institute of Science and Technology,Deep learning;Multi-modal learning;Structured prediction,-1;-1;22;-1,88;88;88;88,-1;-1,NAN,NAN,y,
382,ICLR,2017,Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe,Hao Zhao;Ming Lu;Anbang Yao;Yurong Chen;Li Zhang,zhao-h13@mails.tsinghua.edu.cn;lu-m13@mails.tsinghua.edu.cn;anbang.yao@intel.com;yurong.chen@intel.com;chinazhangli@mail.tsinghua.edu.cn,3;3;3,5;3;2,Reject,3,3,0.0,no,11/4/16,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Intel;Intel;Tsinghua University, Tsinghua University",Semi-Supervised Learning,5;5;-1;-1;5,35;35;-1;-1;35,-1;-1,NAN,NAN,n,8
383,ICLR,2017,Generative Adversarial Parallelization,Daniel Jiwoong Im;He Ma;Chris Dongjoo Kim;Graham Taylor,daniel.im@aifounded.com;hma02@uoguelph.ca;ckim07@uoguelph.ca;gwtaylor@uoguelph.ca,4;4;4,3;4;4,Reject,2,4,0.0,no,11/5/16,Aifounded;University of Guelph;University of Guelph;University of Guelph,Unsupervised Learning,-1;286;286;286,-1;398;398;398,-1;-1,canada,ca,n,1;5;4
384,ICLR,2017,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,Jean Harb;Doina Precup,jharb@cs.mcgill.ca;dprecup@cs.mcgill.ca,4;4;3,4;5;5,Reject,3,0,0.0,no,11/5/16,McGill University;McGill University,Reinforcement Learning;Deep learning,92;92,42;42,-1;-1,canada,ca,n,
385,ICLR,2017,Discovering objects and their relations from entangled scene representations,David Raposo;Adam Santoro;David Barrett;Razvan Pascanu;Timothy Lillicrap;Peter Battaglia,draposo@google.com;adamsantoro@google.com;barrettdavid@google.com;razp@google.com;countzero@google.com;peterbattaglia@google.com,7;3;7,4;5;4,Invite to Workshop Track,0,5,0.0,no,11/4/16,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
386,ICLR,2017,Generalizable Features From Unsupervised Learning,Mehdi Mirza;Aaron Courville;Yoshua Bengio,memirzamo@gmail.com;aaron.courville@gmail.com;yoshua.umontreal@gmail.com,5;5;3,4;4;4,Invite to Workshop Track,2,0,0.0,no,11/4/16,Google;University of Montreal;University of Montreal,Unsupervised Learning;Deep learning,-1;92;92,-1;103;103,-1;-1,canada,ca,n,1
387,ICLR,2017,RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning,Yan Duan;John Schulman;Xi Chen;Peter L. Bartlett;Ilya Sutskever;Pieter Abbeel,rocky@openai.com;joschu@openai.com;peter@openai.com;peter@berkeley.edu;ilyasu@openai.com;pieter@openai.com,4;3;3,3;4;4,Reject,2,3,4.0,no,11/4/16,OpenAI;OpenAI;OpenAI;University of California Berkeley;OpenAI;OpenAI,Reinforcement Learning;Deep learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;10;-1;-1,-1;-1,NAN,NAN,n,
388,ICLR,2017,Opening the vocabulary of  neural language models with character-level word representations,Matthieu Labeau;Alexandre Allauzen,labeau@limsi.fr;allauzen@limsi.fr,3;2;4,4;5;4,Reject,8,0,0.0,no,11/4/16,LIMSI-CNRS / Universit√© Paris-Sud;LIMSI-CNRS / Universit√© Paris-Sud,Natural language processing;Deep learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
389,ICLR,2017,Multi-modal Variational Encoder-Decoders,Iulian V. Serban;Alexander G. Ororbia II;Joelle Pineau;Aaron Courville,julianserban@gmail.com;ago109@psu.edu;jpineau@cs.mcgill.ca;aaron.courville@umontreal.ca,3;4;4,4;5;4,Reject,14,5,0.0,no,11/4/16,University College London;Pennsylvania State University;McGill University;University of Montreal,Deep learning;Structured prediction;Natural language processing,31;31;92;92,-1;-1;42;103,-1;-1,canada,ca,n,10;3;5
390,ICLR,2017,Transformational Sparse Coding,Dimitrios C. Gklezakos;Rajesh P. N. Rao,gklezd@cs.washington.edu;rao@cs.washington.edu,5;4;4,4;4;4,Reject,7,3,0.0,no,11/4/16,University of Washington;University of Washington,Unsupervised Learning;Computer vision;Optimization,5;5,25;25,-1;-1,usa,usa,n,
391,ICLR,2017,Convolutional Neural Networks Generalization Utilizing the Data Graph Structure,Yotam Hechtlinger;Purvasha Chakravarti;Jining Qin,yhechtli@andrew.cmu.edu;pchakrav@andrew.cmu.edu;jiningq@andrew.cmu.edu,6;3;3,3;3,Reject,2,3,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Supervised Learning;Deep learning,1;1;1,23;23;23,-1;-1,usa,usa,n,1;10
392,ICLR,2017,Learning Approximate Distribution-Sensitive Data Structures,Zenna Tavares;Armando Solar-Lezama,zenna@mit.edu;asolar@csail.mit.edu,4;4;3,3;3;4,Reject,1,0,0.0,no,11/4/16,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Unsupervised Learning,9;9,5;5,-1;-1,usa,usa,n,
393,ICLR,2017,Sampling Generative Networks,Tom White,tom.white@vuw.ac.nz,5;5;6,4;3;3,Reject,6,3,0.0,no,11/2/16,Victoria University Wellington,Unsupervised Learning;Deep learning;Computer vision,-1,362,-1,australasia,nz,n,5;4
394,ICLR,2017,Collaborative Deep Embedding via Dual Networks,Yilei Xiong;Dahua Lin;Haoying Niu;JIefeng Cheng;Zhenguo Li,xy014@ie.cuhk.edu.hk;dhlin@ie.cuhk.edu.hk;niu.haoying@huawei.com;cheng.jiefeng@huawei.com;li.zhenguo@huawei.com,5;5;4,3;4;4,Reject,2,3,0.0,no,11/4/16,The Chinese University of Hong Kong;The Chinese University of Hong Kong;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,,286;286;-1;-1;-1,43;43;-1;-1;-1,-1;-1,NAN,NAN,n,
395,ICLR,2017,An Empirical Analysis of Deep Network Loss Surfaces,Daniel Jiwoong Im;Michael Tao;Kristin Branson,daniel.im@aifounded.com;mtao@dgp.toronto.edu;bransonk@janelia.hhmi.org,6;4;4,4;4;4,Reject,3,0,0.0,no,11/5/16,Aifounded;University of Toronto;HHMI Janelia Research Campus,Deep learning,-1;22;-1,-1;22;-1,-1;-1,NAN,NAN,n,
396,ICLR,2017,Parametric Exponential Linear Unit for Deep Convolutional Neural Networks,Ludovic Trottier;Philippe Gigu√®re;Brahim Chaib-draa,ludovic.trottier.1@ulaval.ca;philippe.giguere@ift.ulaval.ca;brahim.chaib-draa@ift.ulaval.ca,5;7;4;6,4;5;4;4,Reject,2,1,0.0,no,11/4/16,Laval university;Laval university;Laval university,,-1;-1;-1,265;265;265,-1;-1,NAN,NAN,n,
397,ICLR,2017,CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS,Makoto Nakatsuji;Hisashi Ito;Naruhiro Ikeda;Shota Sagara;Akihisa Fujita,nakatuji@nttr.co.jp;h-ito@nttr.co.jp;nikeda@nttr.co.jp;s-sagara@nttr.co.jp;akihisa@nttr.co.jp,4;4;4,4;4,Reject,1,0,0.0,no,11/5/16,Rensselaer Polytechnic Institute;;;;NTT Resonant Inc,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,asia,in,n,3
398,ICLR,2017,Multiagent System for Layer Free Network,Hiroki Kurotaki;Kotaro Nakayama;Yutaka Matsuo,kurotaki@weblab.t.u-tokyo.ac.jp;nakayama@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,3;1;2,3;5;5,Reject,2,0,0.0,no,11/4/16,The University of Tokyo;The University of Tokyo;The University of Tokyo,,46;46;46,39;39;39,-1;-1,NAN,NAN,n,
399,ICLR,2017,Boosted Residual Networks,Alan Mosca;George D. Magoulas,a.mosca@dcs.bbk.ac.uk;gmagoulas@dcs.bbk.ac.uk,3;4;3,5;5;5,Reject,2,0,0.0,no,11/4/16,Birkbeck;Birkbeck,,149;149,251;251,-1;-1,NAN,NAN,n,
400,ICLR,2017,Multi-view Generative Adversarial Networks,Micka√´l Chen;Ludovic Denoyer,mickael.chen@lip6.fr;ludovic.denoyer@lip6.fr,3;5;6,3;3;4,Reject,2,0,0.0,no,11/4/16,LIP6;LIP6,Deep learning;Supervised Learning,-1;-1,-1;-1,-1;-1,asia,ir,n,
401,ICLR,2017,Modular Multitask Reinforcement Learning with Policy Sketches,Jacob Andreas;Dan Klein;Sergey Levine,jda@cs.berkeley.edu;klein@cs.berkeley.edu;svlevine@eecs.berkeley.edu,4;5;3,5;5;4,Invite to Workshop Track,2,5,0.0,no,11/4/16,University of California Berkeley;University of California Berkeley;University of California Berkeley,Reinforcement Learning;Transfer Learning,-1;-1;-1,10;10;10,-1;-1,usa,usa,n,
402,ICLR,2017,Prototypical Networks for Few-shot Learning,Jake Snell;Kevin Swersky;Richard Zemel,jsnell@cs.toronto.edu;kswersky@twitter.com;zemel@cs.toronto.edu,5;6;4,3;4;5,Reject,1,3,0.0,no,11/5/16,University of Toronto;Twitter;University of Toronto,Deep learning;Transfer Learning,22;-1;22,22;-1;22,-1;-1,canada,ca,n,6;8
403,ICLR,2017,Towards Information-Seeking Agents,Philip Bachman;Alessandro Sordoni;Adam Trischler,phil.bachman@maluuba.com;alessandro.sordoni@maluuba.com;adam.trischler@maluuba.com,6;4;4,4;4;4,Reject,1,1,0.0,no,11/5/16,Maluuba;Maluuba;Maluuba,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
404,ICLR,2017,Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context,Shyam Upadhyay;Kai-Wei Chang;James Zou;Matt Taddy;Adam Kalai,upadhya3@illinois.edu;kwchang@virginia.edu;jamesz@stanford.edu;taddy@microsoft.com;adum@microsoft.com,4;4;5,3;4;3,Reject,2,3,0.0,no,11/4/16,"University of Illinois, Urbana Champaign;University of Virginia;Stanford University;Microsoft;Microsoft",Natural language processing,-1;46;3;-1;-1,-1;123;3;-1;-1,-1;-1,NAN,NAN,n,11;3
405,ICLR,2017,A Context-aware Attention Network for Interactive Question Answering,Huayu Li;Martin Renqiang Min;Yong Ge;Asim Kadav,hli38@uncc.edu;renqiang@nec-labs.com;yongge@email.arizona.edu;asim@nec-labs.com,5;4;4,3;4;4,Reject,3,3,0.0,no,11/4/16,"University of North Carolina, Charlotte;NEC-Labs;University of Arizona;NEC-Labs",Deep learning;Natural language processing;Applications,67;-1;149;-1,-1;-1;156;-1,-1;-1,NAN,NAN,n,8
406,ICLR,2017,Sequence to Sequence Transduction with Hard Monotonic Attention,Roee Aharoni;Yoav Goldberg,roee.aharoni@gmail.com;yoav.goldberg@gmail.com,5;5;4,4;3;5,Reject,5,0,0.0,no,11/4/16,Google;Bar-Ilan University,Natural language processing;Applications,-1;67,-1;489,-1;-1,europe,il,n,8
407,ICLR,2017,SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks,Armen Aghajanyan,armen.ag@live.com,3;4;4,5;5;5,Reject,7,2,0.0,no,10/18/16,Facebook,Deep learning;Optimization;Computer vision,-1,-1,-1,NAN,NAN,n,
408,ICLR,2017,Parallel Stochastic Gradient Descent with Sound Combiners,Saeed Maleki;Madanlal Musuvathi;Todd Mytkowicz;Yufei Ding,saemal@microsoft.com;madanm@microsoft.com;toddm@microsoft.com;yding8@ncsu.edu,4;6;4,5;4;5,Reject,3,3,0.0,no,11/4/16,Microsoft;Microsoft;Microsoft;SUN YAT-SEN UNIVERSITY,,-1;-1;-1;-1,-1;-1;-1;414,-1;-1,NAN,NAN,y,9
409,ICLR,2017,Inefficiency of stochastic gradient descent with larger mini-batches (and more learners),Onkar Bhardwaj;Guojing Cong,onkar.bhardwaj@gmail.com;gcong@us.ibm.com,6;4;5,4;4;3,Reject,4,3,0.0,no,11/4/16,International Business Machines;International Business Machines,Deep learning;Optimization,-1;-1,-1;-1,-1;-1,NAN,NAN,y,
410,ICLR,2017,The Power of Sparsity in Convolutional Neural Networks,Soravit Changpinyo;Mark Sandler;Andrey Zhmoginov,schangpi@usc.edu;sandler@google.com;azhmogin@google.com,7;5;4,3;4;4,Reject,6,3,0.0,no,11/4/16,University of Southern California;Google;Google,Deep learning;Supervised Learning,22;-1;-1,60;-1;-1,-1;-1,NAN,NAN,n,
411,ICLR,2017,The Variational Walkback Algorithm,Anirudh Goyal;Nan Rosemary Ke;Alex Lamb;Yoshua Bengio,anirudhgoyal9119@gmail.com;rosemary.nan.ke@gmail.com;lambalex@iro.umontreal.ca;yoshua.umontreal@gmail.com,4;5;4,4;5;5,Reject,2,1,0.0,no,11/4/16,University of Montreal;;University of Montreal;University of Montreal,Unsupervised Learning,-1;-1;92;92,-1;-1;103;103,-1;-1,canada,ca,n,10;1;5
412,ICLR,2017,Incremental Sequence Learning,Edwin D. de Jong,edwin.webmail@gmail.com,5;3;5,3;4;4,Reject,6,4,0.0,no,11/4/16,Utrecht University,Deep learning;Supervised Learning,149,86,-1,europe,nl,n,6;1;5
413,ICLR,2017,Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning,Dilin Wang;Qiang Liu,dilin.wang.gr@dartmouth.edu;qiang.liu@dartmouth.edu,4;4;4,3;4;3,Invite to Workshop Track,2,1,0.0,no,11/4/16,Dartmouth College;Dartmouth College,Unsupervised Learning,149;149,82;82,-1;-1,usa,usa,n,4
414,ICLR,2017,Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering,Liwen Zhang;John Winn;Ryota Tomioka,liwenz@cs.uchicago.edu;jwinn@microsoft.com;ryoto@microsoft.com,5;4;4,4;4;3,Reject,2,1,0.0,no,11/4/16,University of Chicago;Microsoft;Microsoft,Natural language processing;Supervised Learning;Deep learning,46;-1;-1,10;-1;-1,-1;-1,NAN,NAN,n,8
415,ICLR,2017,Recurrent Inference Machines for Solving Inverse Problems,Patrick Putzky;Max Welling,patrick.putzky@gmail.com;welling.max@gmail.com,5;4;7,4;4;3,Reject,2,3,0.0,no,11/4/16,"University of Amsterdam;University of California, Irvine",Optimization;Deep learning;Computer vision,92;-1,63;99,-1;-1,usa,usa,n,
416,ICLR,2017,Learning a Static Analyzer: A Case Study on a Toy Language,Manzil Zaheer;Jean-Baptiste Tristan;Michael L. Wick;Guy L. Steele Jr.,manzil.zaheer@cmu.edu;jean.baptiste.tristan@oracle.com;michael.wick@oracle.com;guy.steele@oracle.com,4;3;3,4;4;5,Reject,5,0,0.0,no,11/3/16,Carnegie Mellon University;Oracle;Oracle;Oracle,,1;-1;-1;-1,23;-1;-1;-1,-1;-1,NAN,NAN,n,3
417,ICLR,2017,The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning,Nikolas Wolfe;Aditya Sharma;Lukas Drude;Bhiksha Raj,nwolfe@cs.cmu.edu;adityasharma@cmu.edu;drude@nt.upb.de;bhiksha@cs.cmu.edu,3;3;3,4;4;4,Reject,7,1,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University;Paderborn University;Carnegie Mellon University,Theory;Deep learning,1;1;286;1,23;23;-1;23,-1;-1,usa,usa,n,1
418,ICLR,2017,Neural Machine Translation with Latent Semantic of Image and Text,Joji Toyama;Masanori Misono;Masahiro Suzuki;Kotaro Nakayama;Yutaka Matsuo,toyama@weblab.t.u-tokyo.ac.jp;misono@weblab.t.u-tokyo.ac.jp;masa@weblab.t.u-tokyo.ac.jp;k-nakayama@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,3;4;3,4;5;5,Reject,7,0,0.0,no,11/4/16,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,,46;46;46;46;46,39;39;39;39;39,-1;-1,NAN,NAN,n,8;3
419,ICLR,2017,CONTENT2VEC: SPECIALIZING JOINT REPRESENTATIONS OF PRODUCT IMAGES AND TEXT FOR THE TASK OF PRODUCT RECOMMENDATION,Thomas Nedelec;Elena Smirnova;Flavian Vasile,t.nedelec@criteo.com;e.smirnova@criteo.com;f.vasile@criteo.com,3;3;5,3;3;3,Reject,1,1,0.0,no,11/5/16,Criteo;Criteo;Criteo,Applications,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
420,ICLR,2017,Group Sparse CNNs for Question Sentence Classification with Answer Sets,Mingbo Ma;Liang Huang;Bing Xiang;Bowen Zhou,mam@oregonstate.edu;liang.huang@oregonstate.edu;bingxia@us.ibm.com;zhou@us.ibm.com,4;5;6,4;4;4,Reject,1,0,0.0,no,11/4/16,Oregon State University;Oregon State University;International Business Machines;International Business Machines,,67;67;-1;-1,316;316;-1;-1,-1;-1,NAN,NAN,n,
421,ICLR,2017,Multi-label learning with the RNNs for Fashion Search,Taewan Kim,taey.16@navercorp.com,4;3;3,4;4;3,Reject,3,0,0.0,no,11/5/16,NAVER,Computer vision;Deep learning;Supervised Learning;Applications,-1,-1,-1,europe,gr,n,2
422,ICLR,2017,A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks,Kazuma Hashimoto;Caiming Xiong;Yoshimasa Tsuruoka;Richard Socher,hassy@logos.t.u-tokyo.ac.jp;cxiong@salesforce.com;tsuruoka@logos.t.u-tokyo.ac.jp;rsocher@salesforce.com,6;3;5,4;4;4,Reject,3,3,0.0,no,11/4/16,The University of Tokyo;SalesForce.com;The University of Tokyo;SalesForce.com,Natural language processing;Deep learning,46;-1;46;-1,39;-1;39;-1,-1;-1,NAN,NAN,n,3
423,ICLR,2017,An Analysis of Deep Neural Network Models for Practical Applications,Alfredo Canziani;Adam Paszke;Eugenio Culurciello,canziani@purdue.edu;a.paszke@students.mimuw.edu.pl;euge@purdue.edu,4;4;5,3;3;4,Reject,3,5,0.0,no,11/4/16,"Purdue University;University of Washington, Seattle;Purdue University",Computer vision;Deep learning;Applications,22;5;22,70;25;70,-1;-1,usa,usa,n,2;1
424,ICLR,2017,Improving Stochastic Gradient Descent with Feedback,Jayanth Koushik;Hiroaki Hayashi,jkoushik@cs.cmu.edu;hiroakih@cs.cmu.edu,5;6;5,4;4;4,Reject,5,2,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University,Deep learning;Optimization,1;1,23;23,-1;-1,usa,usa,n,3
425,ICLR,2017,Understanding intermediate layers using linear classifier probes,Guillaume Alain;Yoshua Bengio,guillaume.alain.umontreal@gmail.com;yoshua.bengio@gmail.com,5;4;4,3;4;4,Reject,2,2,0.0,no,11/5/16,University of Montreal;University of Montreal,,-1;-1,-1;-1,-1;-1,asia,in,n,
426,ICLR,2017,Classify or Select: Neural Architectures for Extractive Document Summarization,Ramesh Nallapati;Bowen Zhou and Mingbo Ma,nallapati@us.ibm.com;zhou@us.ibm.com;mam@oregonstate.edu,6;4;4,4;4;4,Reject,7,3,0.0,no,11/4/16,International Business Machines;International Business Machines;Oregon State University,Natural language processing;Supervised Learning;Applications;Deep learning,-1;-1;67,-1;-1;316,-1;-1,usa,usa,n,
427,ICLR,2017,Joint Training of Ratings and Reviews with Recurrent Recommender Networks,Chao-Yuan Wu;Amr Ahmed;Alex Beutel;Alexander J. Smola,cywu@cs.utexas.edu;amra@google.com;alexbeutel@google.com;alex@smola.org,6;6;6,4;3;4,Reject,4,6,0.0,no,11/4/16,"University of Texas, Austin;Google;Google;Carnegie-Mellon University",,-1;-1;-1;1,-1;-1;-1;23,-1;-1,usa,usa,n,3
428,ICLR,2017,Divide and Conquer with Neural Networks,Alex Nowak;Joan Bruna,anv273@nyu.edu;bruna@cims.nyu.edu,4;4;3,2;4;2,Reject,4,1,0.0,no,11/4/16,New York University;New York University,Deep learning,22;22,32;32,-1;-1,usa,usa,n,1;10
429,ICLR,2017,Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce,Tom Zahavy;Alessandro Magnani;Abhinandan Krishnan;Shie Mannor,tomzahavy@tx.technion.ac.il;AMagnani@walmartlabs.com;AKrishnan@walmartlabs.com;shie@ee.technion.ac.il,5;5;4,4;4;4,Reject,2,2,0.0,no,11/4/16,"Technion, Technion;Walmart Labs;Walmart Labs;Technion, Technion",Multi-modal learning;Deep learning,22;-1;-1;22,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
430,ICLR,2017,Deep Symbolic Representation Learning for Heterogeneous Time-series Classification,Shengdong Zhang;Soheil Bahrampour;Naveen Ramakrishnan;Mohak Shah,zhangshengdongofgz@gmail.com;Soheil.Bahrampour@us.bosch.com;Naveen.Ramakrishnan@us.bosch.com;mohak@mohakshah.com,3;5;4,4;4;3,Reject,4,2,0.0,no,11/4/16,Bosch Research and Technology Center;Bosch;Bosch;Mohakshah,,-1;-1;-1;-1,-1;433;433;-1,-1;-1,NAN,NAN,n,
431,ICLR,2017,Enforcing constraints on outputs with unconstrained inference,Jay Yoon Lee;Michael L. Wick;Jean-Baptiste Tristan,lee.jayyoon@gmail.com;michael.wick@oracle.com;jean.baptiste.tristan@oracle.com,4;3;3,5;4;4,Reject,2,0,0.0,no,11/3/16,Carnegie Mellon University;Oracle;Oracle,Natural language processing;Structured prediction;Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
432,ICLR,2017,Sequence generation with a physiologically plausible model of handwriting and Recurrent Mixture Density Networks,Daniel Berio;Memo Akten;Frederic Fol Leymarie;Mick Grierson;R√©jean Plamondon,d.berio@gold.ac.uk;m.akten@ac.uk;ffl@gold.ac.uk;m.grierson@gold.ac.uk;rejean.plamondon@polymtl.ca,3;3;3,3;5;3,Reject,3,1,0.0,no,11/5/16,"Goldsmiths, University of London;;Goldsmiths, University of London;Goldsmiths, University of London;Polytechnique Montreal",Deep learning;Supervised Learning;Applications,286;-1;286;286;286,300;-1;300;300;-1,-1;-1,canada,ca,n,
433,ICLR,2017,Deep Neural Networks and the Tree of Life,Yan Wang;Kun He;John E. Hopcroft;Yu Sun,yanwang@hust.edu.cn;brooklet60@hust.edu.cn;jeh@cs.cornell.edu;ys646@cornell.edu,3;4;4,5;4;4,Reject,0,3,0.0,no,11/5/16,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Cornell University;Cornell University,Deep learning;Computer vision;Applications,-1;-1;5;5,48;48;19;19,-1;-1,usa,usa,n,2
434,ICLR,2017,Hierarchical Memory Networks,Sarath Chandar;Sungjin Ahn;Hugo Larochelle;Pascal Vincent;Gerald Tesauro;Yoshua Bengio,apsarathchandar@gmail.com;sjn.ahn@gmail.com;hugo@twitter.com;vincentp@iro.umontreal.ca;gtesauro@us.ibm.com;yoshua.bengio@umontreal.ca,5;5;4,3;5;4,Reject,3,3,0.0,no,11/4/16,Polytechnique Montreal;Rutgers University;Twitter;University of Montreal;International Business Machines;University of Montreal,Deep learning;Natural language processing,286;22;-1;92;-1;92,-1;-1;-1;103;-1;103,-1;-1,canada,ca,n,8
435,ICLR,2017,Near-Data Processing for Machine Learning,Hyeokjun Choe;Seil Lee;Hyunha Nam;Seongsik Park;Seijoon Kim;Eui-Young Chung;Sungroh Yoon,genesis1104@snu.ac.kr;lees231@dsl.snu.ac.kr;godqhr825@snu.ac.kr;pss015@snu.ac.kr;hokiespa@snu.ac.kr;eychung@yonsei.ac.kr;sryoon@snu.ac.kr,4;6;5,4;2;2,Reject,2,3,0.0,no,11/5/16,Seoul National University;Seoul National University;Seoul National University;Seoul National University;Seoul National University;Yonsei University;Seoul National University,,46;46;46;46;46;149;46,72;72;72;72;72;293;72,-1;-1,asia,kr,n,
436,ICLR,2017,Rotation Plane Doubly Orthogonal Recurrent Neural Networks,Zoe McCarthy;Andrew Bai;Xi Chen;Pieter Abbeel,zmccarthy@berkeley.edu;xiaoyang.bai@berkeley.edu;c.xi@berkeley.edu;pabbeel@berkeley.edu,4;4;5,4;4;3,Reject,0,0,0.0,no,11/5/16,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep learning;Theory,-1;-1;-1;-1,10;10;10;10,-1;-1,usa,usa,n,
437,ICLR,2017,FastText.zip: Compressing text classification models,Armand Joulin;Edouard Grave;Piotr Bojanowski;Matthijs Douze;Herve Jegou;Tomas Mikolov,ajoulin@fb.com;egrave@fb.com;bojanowski@fb.com;matthijs@fb.com;rvj@fb.com;tmikolov@fb.com,5;6;6,4;4;3,Reject,2,2,0.0,no,11/4/16,Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,Natural language processing;Supervised Learning;Applications,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
438,ICLR,2017,Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity,Yuandong Tian,yuandong@fb.com,4;8;4,3;4;4,Invite to Workshop Track,1,3,0.0,no,11/4/16,Facebook,Theory;Deep learning;Optimization,-1,-1,-1,NAN,NAN,y,1;9
439,ICLR,2017,Training Long Short-Term Memory With Sparsified Stochastic Gradient Descent,Maohua Zhu;Minsoo Rhu;Jason Clemons;Stephen W. Keckler;Yuan Xie,maohuazhu@ece.ucsb.edu;mrhu@nvidia.com;jclemons@nvidia.com;skeckler@nvidia.com;yuanxie@ece.ucsb.edu,4;5;4,4;3;4,Reject,2,0,0.0,no,11/4/16,UC Santa Barbara;NVIDIA;NVIDIA;NVIDIA;UC Santa Barbara,Optimization;Deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
440,ICLR,2017,Unsupervised Learning Using Generative Adversarial Training And Clustering,Vittal Premachandran;Alan L. Yuille,vittalp@jhu.edu;ayuille1@jhu.edu,3;3;3,4;5;4,Reject,0,0,0.0,no,11/5/16,Johns Hopkins University;Johns Hopkins University,,46;46,17;17,-1;-1,usa,usa,n,5;4
441,ICLR,2017,Inverse Problems in Computer Vision using  Adversarial  Imagination Priors,Hsiao-Yu Fish Tung;Katerina Fragkiadaki,htung@cs.cmu.edu;katef@cs.cmu.edu,3;5;6,4;3;3,Reject,0,0,0.0,no,11/4/16,Carnegie Mellon University;Carnegie Mellon University,Unsupervised Learning;Deep learning,1;1,23;23,-1;-1,usa,usa,n,2;10;4
442,ICLR,2017,Generative Adversarial Networks as Variational Training of Energy Based Models,Shuangfei Zhai;Yu Cheng;Rogerio Feris;Zhongfei Zhang,szhai2@binghamton.edu;chengyu@us.ibm.com;rsferis@us.ibm.com;zhongfei@cs.binghamton.edu,4;4;4,3;5;5,Reject,4,5,0.0,no,11/5/16,"State University of New York, Binghamton;International Business Machines;International Business Machines;State University of New York, Binghamton",,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;5;4
443,ICLR,2017,An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views,Ziyuan Lin;Jaakko Peltonen,ziyuan.lin@aalto.fi;jaakko.peltonen@uta.fi,4;4;4,4;4;4,Reject,2,0,0.0,no,11/5/16,Aalto University;University of Tampere,Unsupervised Learning,149;-1,228;296,-1;-1,europe,de,n,
444,ICLR,2017,Differentiable Canonical Correlation Analysis,Matthias Dorfer;Jan Schl√ºter;Gerhard Widmer,matthias.dorfer@jku.at;jan.schlueter@ofai.at;gerhard.widmer@jku.at,3;4;3,4;4;4,Reject,1,1,0.0,no,11/5/16,Johannes Kepler University Linz;Austrian Research Institute for Artificial Intelligence;Johannes Kepler University Linz,Multi-modal learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
445,ICLR,2017,Generative Adversarial Networks for Image Steganography,Denis Volkhonskiy;Boris Borisenko;Evgeny Burnaev,dvolkhonskiy@gmail.com;bborisenko@hse.ru;e.burnaev@skoltech.ru,5;6;4,3;4;3,Reject,2,3,0.0,no,11/4/16,Skolkovo Institute of Science and Technology;Higher School of Economics;Skolkovo Institute of Science and Technology,Computer vision;Deep learning;Unsupervised Learning;Applications;Supervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,europe,russia,n,5;4
446,ICLR,2017,A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games,Felix Leibfried;Nate Kushman;Katja Hofmann,felix.leibfried@gmail.com;nkushman@microsoft.com;katja.hofmann@microsoft.com,4;4;4,4;4;4,Reject,2,1,0.0,no,11/3/16,TAL Education Group;Microsoft;Microsoft,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
447,ICLR,2017,Wav2Letter: an End-to-End ConvNet-based Speech Recognition System,Ronan Collobert;Christian Puhrsch;Gabriel Synnaeve,locronan@fb.com;cpuhrsch@fb.com;gab@fb.com,6;7,4;5,Reject,7,1,0.0,no,11/4/16,Facebook;Facebook;Facebook,Deep learning;Speech;Structured prediction,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,2;10
448,ICLR,2017,Tree-Structured Variational Autoencoder,Richard Shin;Alexander A. Alemi;Geoffrey Irving;Oriol Vinyals,ricshin@cs.berkeley.edu;alemi@google.com;geoffreyi@google.com;vinyals@google.com,3;3;4,4;4;4,Reject,0,0,0.0,no,11/4/16,University of California Berkeley;Google;Google;Google,,-1;-1;-1;-1,10;-1;-1;-1,-1;-1,NAN,NAN,n,3;1;5
449,ICLR,2017,Transformation-based Models of Video Sequences,Joost van Amersfoort;Anitha Kannan;Marc'Aurelio Ranzato;Arthur Szlam;Du Tran;Soumith Chintala,joost@joo.st;akannan@fb.com;ranzato@fb.com;aszlam@fb.com;trandu@fb.com;soumith@fb.com,5;6;3,3;4;3,Reject,6,0,0.0,no,11/4/16,University of Oxford;Facebook;Facebook;Facebook;Facebook;Facebook,Computer vision;Unsupervised Learning,31;-1;-1;-1;-1;-1,1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
450,ICLR,2017,Nonparametrically Learning Activation Functions in Deep Neural Nets,Carson Eisenach;Zhaoran Wang;Han Liu,eisenach@princeton.edu;zhaoran@princeton.edu;hanliu@princeton.edu,7;6;5,5;4;4,Invite to Workshop Track,1,3,0.0,no,11/4/16,Princeton University;Princeton University;Princeton University,,46;46;46,7;7;7,-1;-1,usa,usa,y,1
451,ICLR,2017,Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning,Jeff Daily;Abhinav Vishnu;Charles Siegel,jeff.daily@pnnl.gov;abhinav.vishnu@pnnl.gov;charles.siegel@pnnl.gov,5;3;3,4;4;5,Reject,0,1,0.0,no,11/4/16,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
452,ICLR,2017,Rule Mining in Feature Space,Stefano Teso;Andrea Passerini,teso@disi.unitn.it;passerini@disi.unitn.it,4;3;4,4;4;4,Reject,0,0,0.0,no,11/4/16,University of Trento;University of Trento,Unsupervised Learning,149;149,236;236,-1;-1,europe,gr,n,
453,ICLR,2017,ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation,Adam Paszke;Abhishek Chaurasia;Sangpil Kim;Eugenio Culurciello,a.paszke@students.mimuw.edu.pl;aabhish@purdue.edu;sangpilkim@purdue.edu;euge@purdue.edu,4;4;5;3,4;4;4;4,Reject,9,0,0.0,no,11/4/16,"University of Washington, Seattle;Purdue University;Purdue University;Purdue University",Deep learning,5;22;22;22,25;70;70;70,-1;-1,usa,usa,n,2
454,ICLR,2017,Efficient Calculation of Polynomial Features on Sparse Matrices,Andrew Nystrom;John Hughes,awnystrom@gmail.com;jfh@cs.brown.edu,3;3;3,3;3;1,Reject,0,1,0.0,no,11/4/16,Google;Brown University,Supervised Learning,-1;92,-1;51,-1;-1,usa,usa,n,
455,ICLR,2017,Learning Word-Like Units from Joint Audio-Visual Analylsis,David Harwath;James R. Glass,dharwath@mit.edu;glass@mit.edu,6;5;5,4;5;4,Reject,1,1,0.0,no,11/4/16,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Speech;Computer vision;Deep learning;Multi-modal learning;Unsupervised Learning;Semi-Supervised Learning,9;9,5;5,-1;-1,usa,usa,n,
456,ICLR,2017,Rethinking Numerical Representations for Deep Neural Networks,Parker Hill;Babak Zamirai;Shengshuo Lu;Yu-Wei Chao;Michael Laurenzano;Mehrzad Samadi;Marios Papaefthymiou;Scott Mahlke;Thomas Wenisch;Jia Deng;Lingjia Tang;Jason Mars,parkerhh@umich.edu;zamirai@umich.edu;luss@umich.edu;ywchao@umich.edu;mlaurenz@umich.edu;mehrzads@umich.edu;marios@umich.edu;mahlke@umich.edu;twenisch@umich.edu;jiadeng@umich.edu;lingjia@umich.edu;profmars@umich.edu,6;5;5,3;5;2,Reject,2,3,0.0,no,11/4/16,University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan,Deep learning,11;11;11;11;11;11;11;11;11;11;11;11,21;21;21;21;21;21;21;21;21;21;21;21,-1;-1,usa,usa,n,
457,ICLR,2017,Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks,Emily Denton;Sam Gross;Rob Fergus,denton@cs.nyu.edu;sgross@fb.com;robfergus@fb.com,5;6;6,4;4;4,Reject,6,3,0.0,no,11/4/16,New York University;Facebook;Facebook,Deep learning;Semi-Supervised Learning;Computer vision,22;-1;-1,32;-1;-1,-1;-1,NAN,NAN,n,5;4
458,ICLR,2017,Neural Graph Machines: Learning Neural Networks Using Graphs,Thang D. Bui;Sujith Ravi;Vivek Ramavajjala,tdb40@cam.ac.uk;sravi@google.com;vramavaj@google.com,3;4;3,4;4;4,Reject,3,1,0.0,no,11/4/16,University of Cambridge;Google;Google,Semi-Supervised Learning;Natural language processing;Applications,67;-1;-1,4;-1;-1,-1;-1,NAN,NAN,n,10
459,ICLR,2017,Perception Updating Networks: On architectural constraints for interpretable video generative models,Eder Santana;Jose C Principe,edercsjr@gmail.com;principe@cnel.ufl.edu,4;4;4,3;4;4,Invite to Workshop Track,1,4,1.0,no,11/4/16,University of Florida;University of Florida,Structured prediction;Unsupervised Learning,149;149,135;135,-1;-1,usa,usa,n,10
460,ICLR,2017,DRAGNN: A Transition-Based Framework for Dynamically Connected Neural Networks,Lingpeng Kong;Chris Alberti;Daniel Andor;Ivan Bogatyy;David Weiss,lingpenk@cs.cmu.edu;chrisalberti@google.com;andor@google.com;bogatyy@google.com;djweiss@google.com,6;7;5,3;4;4,Reject,2,1,0.0,no,11/4/16,Carnegie Mellon University;Google;Google;Google;Google,Natural language processing;Deep learning;Multi-modal learning;Structured prediction,1;-1;-1;-1;-1,23;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;10
461,ICLR,2017,A Simple yet Effective Method to Prune Dense Layers of Neural Networks,Mohammad Babaeizadeh;Paris Smaragdis;Roy H. Campbell,mb2@illinois.edu.edu;paris@illinois.edu.edu;rhc@illinois.edu.edu,5;5;3,4;3;4,Reject,1,1,0.0,no,11/4/16,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,1
462,ICLR,2017,Beyond Fine Tuning: A Modular Approach to Learning on Small Data,Aryk Anderson;Kyle Shaffer;Artem Yankov;Court Corley;Nathan Hodas,aryk.anderson@eagles.ewu.edu;kyle.shaffer@pnnl.gov;artem.yankov@pnnl.gov;court@pnnl.gov;nathan.hodas@pnnl.gov,4;6;6,4;2;5,Reject,3,0,0.0,no,11/4/16,Eastern Washington University;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,Deep learning;Supervised Learning;Transfer Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
463,ICLR,2017,HFH: Homologically Functional Hashing for Compressing Deep Neural Networks,Lei Shi;Shikun Feng;Zhifan Zhu,shilei06@baidu.com;fengshikun01@baidu.com;zhuzhifan@baidu.com,5;6;4,5;4,Reject,1,2,0.0,no,11/4/16,Baidu;Baidu;Baidu,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8
464,ICLR,2017,Learning to Understand: Incorporating Local Contexts with Global Attention for Sentiment Classification,Zhigang Yuan;Yuting Hu;Yongfeng Huang,yuanzg14@mails.tsinghua.edu.cn;hu-yt12@mails.tsinghua.edu.cn;yfhuang@tsinghua.edu.cn,3;3;4,4;4;4,Reject,0,0,0.0,no,11/4/16,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Natural language processing;Deep learning;Applications,5;5;5,35;35;35,-1;-1,NAN,NAN,n,8
465,ICLR,2017,Multiplicative LSTM for sequence modelling,Ben Krause;Iain Murray;Steve Renals;Liang Lu,ben.krause@ed.ac.uk;i.murray@ed.ac.uk;s.renals@ed.ac.uk;llu@ttic.edu,4;4;6,4;5;4,Invite to Workshop Track,3,4,0.0,no,11/4/16,University of Edinburgh;University of Edinburgh;University of Edinburgh;Toyota Technological Institute at Chicago,Deep learning;Natural language processing;Unsupervised Learning,31;31;31;-1,27;27;27;380,-1;-1,NAN,NAN,n,
466,ICLR,2017,Tensorial Mixture Models,Or Sharir;Ronen Tamari;Nadav Cohen;Amnon Shashua,or.sharir@cs.huji.ac.il;ronent@cs.huji.ac.il;cohennadav@cs.huji.ac.il;shashua@cs.huji.ac.il,4;7;5,4;3;3,Reject,3,3,0.0,no,11/4/16,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Deep learning;Supervised Learning;Unsupervised Learning,67;67;67;67,186;186;186;186,-1;-1,europe,il,n,5
467,ICLR,2017,Neural Functional Programming,John K. Feser;Marc Brockschmidt;Alexander L. Gaunt;Daniel Tarlow,feser@csail.mit.edu;mabrocks@microsoft.com;t-algaun@microsoft.com;dtarlow@microsoft.com,5;4;7;5;6,3;3;2;2;3,Invite to Workshop Track,4,2,0.0,no,11/4/16,Massachusetts Institute of Technology;Microsoft;Microsoft;Microsoft,Supervised Learning,9;-1;-1;-1,5;-1;-1;-1,-1;-1,NAN,NAN,n,
468,ICLR,2017,Deep Error-Correcting Output Codes,Guoqiang Zhong;Yuchen Zheng;Peng Zhang;Mengqi Li;Junyu Dong,gqzhong@ouc.edu.cn;ouczyc@outlook.com;sdrzbruce@163.com;enri9615@outlook.com;dongjunyu@ouc.edu.cn,3;3;3,4;5;5,Reject,1,3,0.0,no,11/4/16,"University of Illinois, Urbana-Champaign;;163;;University of Illinois, Urbana-Champaign",,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,n,
469,ICLR,2017,Marginal Deep Architectures: Deep learning for Small and Middle Scale Applications,Yuchen Zheng;Guoqiang Zhong;Junyu Dong,ouczyc@outlook.com;gqzhong@ouc.edu.cn;dongjunyu@ouc.edu.cn,3;4;4,4;4;4,Reject,3,3,0.0,no,11/4/16,Ocean University of China;Ocean University of China;Ocean University of China,,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
470,ICLR,2017,Generative Paragraph Vector,Ruqing Zhang;Jiafeng Guo;Yanyan Lan;Jun Xu;Xueqi Cheng,zhangruqing@software.ict.ac.cn;guojiafeng@ict.ac.cn;lanyanyan@ict.ac.cn;junxu@ict.ac.cn;cxq@ict.ac.cn,4;3;2,4;4;5,Reject,1,0,0.0,no,11/4/16,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",Natural language processing;Deep learning;Unsupervised Learning;Supervised Learning,31;31;31;31;31,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
471,ICLR,2017,Simple Black-Box Adversarial Perturbations for Deep Networks,Nina Narodytska;Shiva Kasiviswanathan,n.narodytska@gmail.com;kaivisw@gmail.com,4;4;4,3;4;4,Reject,2,3,0.0,no,11/4/16,Samsung Research America;Samsung Research America,Computer vision;Deep learning,-1;-1,-1;-1,-1;-1,asia,in,n,2;4
472,ICLR,2017,Short and Deep: Sketching and Neural Networks,Amit Daniely;Nevena Lazic;Yoram Singer;Kunal Talwar,amitdaniely@google.com;nevena@google.com;singer@google.com;kunal@google.com,4;5;5,2;4;2,Invite to Workshop Track,5,4,0.0,no,11/4/16,Google;Google;Google;Google,Theory,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,
473,ICLR,2017,Cat2Vec: Learning Distributed Representation of Multi-field Categorical Data,Ying Wen;Jun Wang;Tianyao Chen;Weinan Zhang,ying.wen@cs.ucl.ac.uk;jun.wang@cs.ucl.ac.uk;tychen@apex.sjtu.edu.cn;wnzhang@apex.sjtu.edu.cn,4;5;4,4;5;4,Reject,2,0,0.0,no,11/4/16,University College London;University College London;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Unsupervised Learning;Deep learning;Applications,31;31;46;46,-1;-1;214;214,-1;-1,asia,cn,n,3
474,ICLR,2017,On Robust Concepts and Small Neural Nets,Amit Deshpande;Sushrut Karmalkar,amitdesh@microsoft.com;sushrutk@cs.utexas.edu,5;5;6,4;4;2,Invite to Workshop Track,3,3,0.0,no,11/4/16,"Microsoft;University of Texas, Austin",Theory,-1;-1,-1;-1,-1;-1,usa,usa,y,1
475,ICLR,2017,Identity Matters in Deep Learning,Moritz Hardt;Tengyu Ma,m@mrtz.org;tengyu@cs.princeton.edu,8;5;6,3;4;5,Accept (Poster),2,4,0.0,no,11/4/16,University of California - Berkeley;Princeton University,,-1;46,10;7,-1;-1,usa,usa,y,1
476,ICLR,2017,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,Forrest N. Iandola;Song Han;Matthew W. Moskewicz;Khalid Ashraf;William J. Dally;Kurt Keutzer,forresti@eecs.berkeley.edu;songhan@stanford.edu;moskewcz@eecs.berkeley.edu;kashraf@eecs.berkeley.edu;dally@stanford.edu;keutzer@eecs.berkeley.edu,7;5;7,3;4;4,Reject,3,3,0.0,no,11/4/16,University of California Berkeley;Stanford University;University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,Computer vision;Deep learning,-1;3;-1;-1;3;-1,10;3;10;10;3;10,-1;-1,usa,usa,n,
477,ICLR,2017,Non-linear Dimensionality Regularizer for Solving Inverse Problems,Ravi Garg;Anders Eriksson;Ian Reid,ravi.garg@adelaide.edu.au;anders.eriksson@qut.edu.au;ian.reid@adelaide.edu.au,4;3;4,4;5;4,Reject,0,2,0.0,no,11/4/16,The University of Adelaide;South China University of Technology;The University of Adelaide,Computer vision;Optimization;Structured prediction,67;-1;67,143;613;143,-1;-1,NAN,NAN,y,2
478,ICLR,2017,"ParMAC: distributed optimisation of nested functions, with application to binary autoencoders",Miguel A. Carreira-Perpinan;Mehdi Alizadeh,mcarreira-perpinan@ucmerced.edu;malizadeh@ucmerced.edu,4;5;6;6,2;4;4;4,Reject,1,5,0.0,no,11/4/16,University of California at Merced;University of California at Merced,Optimization;Deep learning,-1;-1,-1;-1,-1;-1,usa,usa,n,
479,ICLR,2017,Filling in the details: Perceiving from low fidelity visual input,Farahnaz A. Wick;Michael L. Wick;Marc Pomplun,fwick@cs.umb.edu;mwick@cs.umass.edu;mpomplun@gmail.com,4;6;5,3;4;5,Reject,3,4,0.0,no,11/3/16,"University of Massachusetts, Boston;University of Massachusetts, Amherst;University of Massachusetts, Boston",Deep learning;Computer vision;Semi-Supervised Learning,286;15;-1,166;166;-1,-1;-1,asia,in,n,5
480,ICLR,2017,Pedestrian Detection Based On Fast R-CNN and Batch Normalization ,Zhong-Qiu Zhao;Haiman Bian;Donghui Hu;Herve Glotin,z.zhao@hfut.edu.cn;bhm2164@163.com;hudh@hfut.edu.cn;h.glotin@gmail.com,3;3;2;3,5;5;5;5,Reject,0,0,0.0,no,11/3/16,South China University of Technology;163;South China University of Technology;CNRS university Toulon,,-1;-1;-1;-1,613;-1;613;-1,-1;-1,NAN,NAN,n,1
481,ICLR,2017,Ternary Weight Decomposition and Binary Activation Encoding for Fast and Compact Neural Network,Mitsuru Ambai;Takuya Matsumoto;Takayoshi Yamashita;Hironobu Fujiyoshi,manbai@d-itlab.co.jp;tmatsumoto@d-itlab.co.jp;yamashita@cs.chubu.ac.jp;hf@cs.chubu.ac.jp,6;5;4,3;3;4,Reject,1,0,0.0,no,11/2/16,"Denso IT Laboratory, Inc;;Chubu University;Chubu University",Deep learning,-1;-1;-1;-1,-1;-1;630;630,-1;-1,NAN,NAN,n,2
482,ICLR,2017,What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?,Jiedong Hao;Jing Dong;Wei Wang;Tieniu Tan,jiedong.hao@cripac.ia.ac.cn;jdong@nlpr.ia.ac.cn;wwang@nlpr.ia.ac.cn;tnt@nlpr.ia.ac.cn,3;6;3,5;4;5,Reject,4,0,0.0,no,11/3/16,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",Computer vision;Deep learning,31;31;31;31,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
483,ICLR,2017,Rectified Factor Networks for Biclustering,Djork-Arn√© Clevert;Thomas Unterthiner;Sepp Hochreiter,okko@bioinf.jku.at;unterthiner@bioinf.jku.at;hochreit@bioinf.jku.at,4;5;5,4;2;2,Reject,1,0,0.0,no,11/2/16,Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz,Deep learning;Unsupervised Learning;Applications,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
484,ICLR,2017,Vocabulary Selection Strategies for Neural Machine Translation,Gurvan L'Hostis;David Grangier;Michael Auli,gurvan.lhostis@polytechnique.edu;grangier@fb.com;michaelauli@fb.com,5;4;4;5,3;5;4;3,Reject,0,0,0.0,no,11/2/16,Ecole polytechnique;Facebook;Facebook,Natural language processing,-1;-1;-1,116;-1;-1,-1;-1,NAN,NAN,n,3
485,ICLR,2017,Learning Efficient Algorithms with Hierarchical Attentive Memory,Marcin Andrychowicz;Karol Kurach,marcin@openai.com;kkurach@google.com,3;5;5,4;5;4,Reject,2,0,0.0,no,11/1/16,OpenAI;Google,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,8
486,ICLR,2017,PREDICTION OF POTENTIAL HUMAN INTENTION USING SUPERVISED COMPETITIVE LEARNING,Masayoshi Ishikawa;Mariko Okude;Takehisa Nishida & Kazuo Muto,masayoshi.ishikawa.gv@hitachi.com;mariko.okude.uh@hitachi.com;takehisa.nishida.cu@hitachi.com;kazuo.muto.ny@hitachi.com,2;2;4,4;4;4,Reject,1,0,0.0,no,11/1/16,Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;Hitachi Ltd. R&D group,Computer vision;Deep learning;Supervised Learning;Applications,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
487,ICLR,2017,Conditional Image Synthesis With Auxiliary Classifier GANs,Augustus Odena;Christopher Olah;Jonathon Shlens,augustusodena@google.com;colah@google.com;shlens@google.com,3;6;6,4;5;4,Reject,3,5,0.0,no,11/1/16,Google;Google;Google,Deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
488,ICLR,2017,Learning to Protect Communications with Adversarial Neural Cryptography,Mart√≠n Abadi;David G. Andersen,abadi@google.com;dga@google.com,5;6;4,4;3;2,Reject,3,3,0.0,no,10/21/16,Google;Google,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,4
489,ICLR,2017,Surprisal-Driven Feedback in Recurrent Networks,Kamil Rocki,kmrocki@us.ibm.com,4;3;3,4;5;5,Reject,5,1,0.0,no,10/18/16,International Business Machines,Unsupervised Learning;Applications;Deep learning,-1,-1,-1,NAN,NAN,n,3;1
490,ICLR,2018,Certifying Some Distributional Robustness with Principled Adversarial Training,Aman Sinha;Hongseok Namkoong;John Duchi,amans@stanford.edu;hnamk@stanford.edu;jduchi@stanford.edu,9;9;9,5;4;4,Accept (Oral),0,14,3.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,adversarial training;distributionally robust optimization;deep learning;optimization;learning theory,5;5;5,3;3;3,-1;-1,usa,usa,y,4
491,ICLR,2018,Parametric Information Bottleneck to Optimize Stochastic Neural Networks,Thanh T. Nguyen;Jaesik Choi,thanhnguyen2792@gmail.com;jaesik@unist.ac.kr,4;6;4,4;4;4,Reject,0,0,0.0,yes,10/27/17,Ulsan National Institute of Science and Technology;Ulsan National Institute of Science and Technology,Information Bottleneck;Deep Neural Networks,-1;-1,-1;230,-1;-1,NAN,NAN,y,1
492,ICLR,2018,Towards Neural Phrase-based Machine Translation,Po-Sen Huang;Chong Wang;Sitao Huang;Dengyong Zhou;Li Deng,huang.person@gmail.com;chongw@google.com;shuang91@illinois.edu;dennyzhou@gmail.com;l.deng@ieee.org,6;6;8,3;4;5,Accept (Poster),0,3,0.0,yes,10/26/17,"Google;Google;University of Illinois, Urbana Champaign;Google;University of Waterloo",Neural Machine Translation;Sequence to Sequence;Sequence Modeling,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,asia,in,n,8;2;3
493,ICLR,2018,Weightless: Lossy Weight Encoding For Deep Neural Network Compression,Brandon Reagen;Udit Gupta;Robert Adolf;Michael Mitzenmacher;Alexander Rush;Gu-Yeon Wei;David Brooks,reagen@fas.harvard.edu;ugupta@g.harvard.edu;rdadolf@seas.harvard.edu;michaelm@eecs.harvard.edu;srush@seas.harvard.edu;gywei@g.harvard.edu;dbrooks@eecs.harvard.edu,6;6;4,4;4;4,Invite to Workshop Track,0,3,0.0,yes,10/27/17,Harvard University;Harvard University;Harvard University;Harvard University;Harvard University;Harvard University;Harvard University,Deep Neural Network;Compression;Sparsity,49;49;49;49;49;49;49,6;6;6;6;6;6;6,-1;-1,usa,usa,n,
494,ICLR,2018,Interactive Grounded Language Acquisition and Generalization in a 2D World,Haonan Yu;Haichao Zhang;Wei Xu,haonanyu@baidu.com;zhanghaichao@baidu.com;wei.xu@baidu.com,7;6;6,4;4;4,Accept (Poster),2,7,0.0,yes,10/27/17,Baidu;Baidu;Baidu,grounded language learning and generalization;zero-shot language learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,6;1
495,ICLR,2018,A Boo(n) for Evaluating Architecture Performance,Ondrej Bajgar;Rudolf Kadlec;and Jan Kleindienst,ondrej@bajgar.org;rudolf_kadlec@cz.ibm.com;jankle@cz.ibm.com,4;6;4,4;4;4,Reject,0,4,0.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines,evaluation;methodology,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
496,ICLR,2018,Countering Adversarial Images using Input Transformations,Chuan Guo;Mayank Rana;Moustapha Cisse;Laurens van der Maaten,cg563@cornell.edu;mayankrana@fb.com;moustaphacisse@fb.com;lvdmaaten@gmail.com,4;8;7,3;4;3,Accept (Poster),12,16,0.0,yes,10/27/17,Cornell University;Facebook;Facebook;Facebook,adversarial example;machine learning security;computer vision;image classification,5;-1;-1;-1,19;-1;-1;-1,-1;-1,NAN,NAN,n,4
497,ICLR,2018,A Neural Representation of Sketch Drawings,David Ha;Douglas Eck,hadavid@google.com;deck@google.com,8;8;5,4;4;4,Accept (Poster),0,3,0.0,yes,10/26/17,Google;Google,applications;image modelling;computer-assisted;drawing;art;creativity;dataset,-1;-1,-1;-1,-1;-1,NAN,NAN,n,5
498,ICLR,2018,The Kanerva Machine: A Generative Distributed Memory,Yan Wu;Greg Wayne;Alex Graves;Timothy Lillicrap,yanwu@google.com;gregwayne@google.com;gravesa@google.com;countzero@google.com,6;7;7,4;3;2,Accept (Poster),0,3,0.0,yes,10/27/17,Google;Google;Google;Google,memory;generative model;inference;neural network;hierarchical model,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,11;5
499,ICLR,2018,Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity,Tianyi Zhou;Jeff Bilmes,tianyi.david.zhou@gmail.com;bilmes@uw.edu,5;6;6,3;4;3,Accept (Poster),0,4,0.0,yes,10/27/17,"University of Washington;University of Washington, Seattle",machine teaching;deep learning;minimax;curriculum learning;submodular;diversity,8;8,25;25,-1;-1,NAN,NAN,y,
500,ICLR,2018,Multi-View Data Generation Without View Supervision,Mickael Chen;Ludovic Denoyer;Thierry Arti√®res,mickael.chen@lip6.fr;ludovic.denoyer@lip6.fr;thierry.artieres@lif.univ-mrs.fr,7;5;7,3;4;5,Accept (Poster),0,3,0.0,yes,10/27/17,"LIP6;LIP6;Ecole Centrale Marseille, Computer Science Lab  - Aix Marseille University, Marseille - CNRS, France",multi-view;adversarial learning;generative model,377;377;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
501,ICLR,2018,Towards Binary-Valued Gates for Robust LSTM Training ,Zhuohan Li;Di He;Fei Tian;Wei Chen;Tao Qin;Liwei Wang;Tie-Yan Liu,lizhuohan@pku.edu.cn;di_he@pku.edu.cn;fetia@microsoft.com;wche@microsoft.com;taoqin@microsoft.com;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,6;4;6,3;4;4,Reject,0,4,0.0,yes,10/26/17,Peking University;Peking University;Microsoft;Microsoft;Microsoft;Peking University;Microsoft,recurrent neural network;LSTM;long-short term memory network;machine translation;generalization,14;14;-1;-1;-1;14;-1,27;27;-1;-1;-1;27;-1,-1;-1,NAN,NAN,n,3;1
502,ICLR,2018,On the importance of single directions for generalization,Ari S. Morcos;David G.T. Barrett;Neil C. Rabinowitz;Matthew Botvinick,arimorcos@google.com;barrettdavid@google.com;ncr@google.com;botvinick@google.com,7;5;9,3;4;3,Accept (Poster),0,5,1.0,yes,10/27/17,Google;Google;Google;Google,generalization;analysis;deep learning;selectivity,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
503,ICLR,2018,Variational Continual Learning,Cuong V. Nguyen;Yingzhen Li;Thang D. Bui;Richard E. Turner,vcn22@cam.ac.uk;yl494@cam.ac.uk;tdb40@cam.ac.uk;ret26@cam.ac.uk,6;6;6,3;4;2,Accept (Poster),0,4,0.0,yes,10/27/17,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge,continual learning;online variational inference,82;82;82;82,2;2;2;2,-1;-1,europe,uk,n,5
504,ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Rajarshi Das;Shehzaad Dhuliawala;Manzil Zaheer;Luke Vilnis;Ishan Durugkar;Akshay Krishnamurthy;Alex Smola;Andrew McCallum,rajarshi@cs.umass.edu;sdhuliawala@cs.umass.edu;manzil@cmu.edu;luke@cs.umass.edu;ishand@cs.utexas.edu;akshay@cs.umass.edu;alex@smola.org;mccallum@cs.umass.edu,7;6;5,4;4;4,Accept (Poster),8,16,0.0,yes,10/27/17,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;Carnegie Mellon University;University of Massachusetts, Amherst;University of Texas, Austin;University of Massachusetts, Amherst;Carnegie-Mellon University;University of Massachusetts, Amherst",Knowledge Graphs;Reinforcement Learning;Query Answering,21;21;1;21;-1;21;1;21,191;191;24;191;-1;191;24;191,-1;-1,usa,usa,n,10
505,ICLR,2018,Learning to Represent Programs with Graphs,Miltiadis Allamanis;Marc Brockschmidt;Mahmoud Khademi,miallama@microsoft.com;mabrocks@microsoft.com;mkhademi@sfu.ca,8;8;8,4;4;4,Accept (Oral),0,10,0.0,yes,10/27/17,Microsoft;Microsoft;Simon Fraser University,programs;source code;graph neural networks,-1;-1;49,-1;-1;253,-1;-1,canada,ca,n,3;10
506,ICLR,2018,Variational image compression with a scale hyperprior,Johannes Ball√©;David Minnen;Saurabh Singh;Sung Jin Hwang;Nick Johnston,jballe@google.com;dminnen@google.com;saurabhsingh@google.com;sjhwang@google.com;nickj@google.com,7;7;7,4;5;5,Accept (Poster),1,9,1.0,yes,10/27/17,Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
507,ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Antoine Bosselut;Omer Levy;Ari Holtzman;Corin Ennis;Dieter Fox;Yejin Choi,antoineb@cs.washington.edu;omerlevy@cs.washington.edu;ahai@cs.washington.edu;corin123@uw.edu;fox@cs.washington.edu;yejin@cs.washington.edu,6;9;8,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,"University of Washington;University of Washington;University of Washington;University of Washington, Seattle;University of Washington;University of Washington",representation learning;memory networks;state tracking,8;8;8;8;8;8,25;25;25;25;25;25,-1;-1,usa,usa,n,8
508,ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Shuohang Wang;Mo Yu;Jing Jiang;Wei Zhang;Xiaoxiao Guo;Shiyu Chang;Zhiguo Wang;Tim Klinger;Gerald Tesauro;Murray Campbell,shwang.2014@phdis.smu.edu.sg;yum@us.ibm.com;jingjiang@smu.edu.sg;zhangwei@us.ibm.com;xiaoxiao.guo@ibm.com;shiyu.chang@ibm.com;zhigwang@us.ibm.com;tklinger@us.ibm.com;gtesauro@us.ibm.com;mcam@us.ibm.com,6;8;6,2;3;4,Accept (Poster),0,3,0.0,yes,10/27/17,Singapore Management University;International Business Machines;Singapore Management University;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,Question Answering;Deep Learning,67;-1;67;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
509,ICLR,2018,QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension,Adams Wei Yu;David Dohan;Minh-Thang Luong;Rui Zhao;Kai Chen;Mohammad Norouzi;Quoc V. Le,weiyu@cs.cmu.edu;ddohan@google.com;thangluong@google.com;rzhao@google.com;kaichen@google.com;mnorouzi@google.com;qvl@google.com,8;5;6,5;4;3,Accept (Poster),2,11,1.0,yes,10/27/17,Carnegie Mellon University;Google;Google;Google;Google;Google;Google,squad;stanford question answering dataset;reading comprehension;attention;text convolutions;question answering,1;-1;-1;-1;-1;-1;-1,24;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
510,ICLR,2018,Measuring the Intrinsic Dimension of Objective Landscapes,Chunyuan Li;Heerad Farkhoor;Rosanne Liu;Jason Yosinski,chunyuan.li@duke.edu;heerad@uber.com;rosanne@uber.com;jason@yosinski.com,7;7;6,3;4;2,Accept (Poster),0,4,0.0,yes,10/27/17,Duke University;Uber;Uber;University of Montreal,machine learning;neural networks;intrinsic dimension;random subspace;model understanding,39;-1;-1;125,17;-1;-1;108,-1;-1,canada,ca,n,1
511,ICLR,2018,Residual Loss Prediction: Reinforcement Learning With No Incremental Feedback,Hal Daum√© III;John Langford;Amr Sharaf,hal@umiacs.umd.edu;jl@hunch.net;amr@cs.umd.edu,7;7;6,5;2;4,Accept (Poster),0,10,2.0,yes,10/27/17,"University of Maryland, College Park;Microsoft;University of Maryland, College Park",Reinforcement Learning;Structured Prediction;Contextual Bandits;Learning Reduction,12;-1;12,69;-1;69,-1;-1,usa,usa,y,
512,ICLR,2018,Reinforcement Learning Algorithm Selection,Romain Laroche;Raphael Feraud,romain.laroche@gmail.com;raphael.feraud@orange.com,6;6;7,5;3;4,Accept (Poster),0,0,0.0,yes,10/26/17,Microsoft;General Electric,Reinforcement Learning;Multi-Armed Bandit;Algorithm Selection,-1;-1,-1;-1,-1;-1,NAN,NAN,y,
513,ICLR,2018,Feature Incay for Representation Regularization,Yuhui Yuan;Kuiyuan Yang;Jianyuan Guo;Jingdong Wang;Chao Zhang,yuyua@microsoft.com;kuiyuanyang@deepmotion.ai;1701214082@pku.edu.cn;jingdw@microsoft.com;chzhang@cis.pku.edu.cn,6;6;6,3;2;4,Invite to Workshop Track,0,3,1.0,yes,10/25/17,Microsoft;DeepMotion;Peking University;Microsoft;Peking University,feature norm;regularization;softmax loss;feature incay,-1;-1;14;-1;14,-1;-1;27;-1;27,-1;-1,asia,cn,n,
514,ICLR,2018,Zero-Shot Visual Imitation,Deepak Pathak;Parsa Mahmoudieh;Guanghao Luo;Pulkit Agrawal;Dian Chen;Yide Shentu;Evan Shelhamer;Jitendra Malik;Alexei A. Efros;Trevor Darrell,pathak@berkeley.edu;parsa.m@berkeley.edu;michaelluo@berkeley.edu;pulkitag@berkeley.edu;dianchen@berkeley.edu;fredshentu@berkeley.edu;shelhamer@cs.berkeley.edu;malik@eecs.berkeley.edu;efros@eecs.berkeley.edu;trevor@eecs.berkeley.edu,8;8;7,4;3;5,Accept (Oral),0,8,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,imitation;zero-shot;self-supervised;robotics;skills;navigation;manipulation;vizdoom;reinforcement,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,18;18;18;18;18;18;18;18;18;18,-1;-1,usa,usa,n,6
515,ICLR,2018,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game",Katrina Evtimova;Andrew Drozdov;Douwe Kiela;Kyunghyun Cho,kve216@nyu.edu;apd283@nyu.edu;dkiela@fb.com;kyunghyun.cho@nyu.edu,7;7;7,3;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,New York University;New York University;Facebook;New York University,emergent communication;multi-agent systems;multi-modal,21;21;-1;21,27;27;-1;27,-1;-1,usa,usa,n,3;1
516,ICLR,2018,Distributed Fine-tuning of Language Models on Private Data,Vadim Popov;Mikhail Kudinov;Irina Piontkovskaya;Petr Vytovtov;Alex Nevidomsky,v.popov@samsung.com;m.kudinov@samsung.com;p.irina@samsung.com;p.vytovtov@partner.samsung.com;a.nevidomsky@samsung.com,5;4;4,4;3;4,Accept (Poster),0,6,0.0,yes,10/24/17,Samsung;Samsung;Samsung;Samsung;Samsung,distributed training;federated learning;language modeling;differential privacy,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
517,ICLR,2018,Preliminary theoretical troubleshooting in Variational Autoencoder,Shiqi Liu;Qian Zhao;Xiangyong Cao;Deyu Meng;Zilu Ma;Tao Yu,liushiqi@stu.xjtu.edu.cn;dymeng@mail.xjtu.edu.cn;timmy.zhaoqian@gmail.com;460376821@qq.com;1030884089@qq.com;602077855@qq.com,5;3;2,4;4;4,Reject,0,5,0.0,yes,10/27/17,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;;;Tencent,variational autoencoder;information theory;noise modelling;representation learning;generative model;disentanglement,-1;-1;-1;-1;-1;-1,565;565;565;-1;-1;-1,-1;-1,asia,in,y,1;5
518,ICLR,2018,On the Convergence of Adam and Beyond,Sashank J. Reddi;Satyen Kale;Sanjiv Kumar,sashank@google.com;satyenkale@google.com;sanjivk@google.com,9;8;8,5;4;3,Accept (Oral),2,10,13.0,yes,10/27/17,Google;Google;Google,optimization;deep learning;adam;rmsprop,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,9
519,ICLR,2018,Spatially Transformed Adversarial Examples,Chaowei Xiao;Jun-Yan Zhu;Bo Li;Warren He;Mingyan Liu;Dawn Song,xiaocw@umich.edu;junyanzhu89@gmail.com;lxbosky@gmail.com;_w@eecs.berkeley.edu;mingyan@umich.edu;dawnsong.travel@gmail.com,7;9;7,4;5;4,Accept (Poster),7,13,1.0,yes,10/27/17,University of Michigan;Carnegie Mellon University;University of California Berkeley;University of California Berkeley;University of Michigan;University of California Berkeley,adversarial examples;spatial transformation,10;1;-1;-1;10;-1,21;24;18;18;21;18,-1;-1,usa,usa,n,8;4
520,ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,Roy Fox;Richard Shin;Sanjay Krishnan;Ken Goldberg;Dawn Song;Ion Stoica,roy.d.fox@gmail.com;shin.richard@gmail.com;sanjay@eecs.berkeley.edu;goldberg@berkeley.edu;dawnsong.travel@gmail.com;istoica@cs.berkeley.edu,6;6;6,3;1;2,Accept (Poster),0,8,0.0,yes,10/27/17,"University of California, Irvine;Microsoft;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley",Neural programming;Hierarchical Control,-1;-1;-1;-1;-1;-1,99;-1;18;18;18;18,-1;-1,usa,usa,n,
521,ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Xingjun Ma;Bo Li;Yisen Wang;Sarah M. Erfani;Sudanthi Wijewickrema;Grant Schoenebeck;Dawn Song;Michael E. Houle;James Bailey,xingjunm@student.unimelb.edu.au;crystalboli@berkeley.edu;wangys14@mails.tsinghua.edu.cn;sarah.erfani@unimelb.edu.au;sudanthi.wijewickrema@unimelb.edu.au;schoeneb@umich.edu;dawnsong.travel@gmail.com;meh@nii.ac.jp;baileyj@unimelb.edu.au,8;6;7,3;1;4,Accept (Oral),0,11,2.0,yes,10/24/17,"The University of Melbourne;University of California Berkeley;Tsinghua University, Tsinghua University;The University of Melbourne;The University of Melbourne;University of Michigan;University of California Berkeley;National Institute of Informatics;The University of Melbourne",Adversarial Subspace;Local Intrinsic Dimensionality;Deep Neural Networks,67;-1;5;67;67;10;-1;-1;67,32;18;30;32;32;21;18;-1;32,-1;-1,NAN,NAN,n,1;4
522,ICLR,2018,Generating Adversarial Examples with Adversarial Networks,Chaowei Xiao;Bo Li;Jun-Yan Zhu;Warren He;Mingyan Liu;Dawn Song,xiaocw@umich.edu;lxbosky@gmail.com;junyanz@berkeley.edu;_w@eecs.berkeley.edu;mingyan@umich.edu;dawnsong.travel@gmail.com,4;6;7,4;4;3,Reject,1,16,1.0,yes,10/27/17,University of Michigan;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Michigan;University of California Berkeley,adversarial examples;generative adversarial network;black-box attack,10;-1;-1;-1;10;-1,21;18;18;18;21;18,-1;-1,usa,usa,n,5;4
523,ICLR,2018,Decision Boundary Analysis of Adversarial Examples,Warren He;Bo Li;Dawn Song,_w@eecs.berkeley.edu;lxbosky@gmail.com;dawnsong.travel@gmail.com,6;6;6,3;2;3,Accept (Poster),0,4,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley,adversarial machine learning;supervised representation learning;decision regions;decision boundaries,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,4
524,ICLR,2018,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,Aleksander Wieczorek*;Mario Wieser*;Damian Murezzan;Volker Roth,aleksander.wieczorek@unibas.ch;mario.wieser@unibas.ch;d.murezzan@unibas.ch;volker.roth@unibas.ch,5;6;6;6,4;3;3;1,Accept (Poster),0,2,0.0,yes,10/27/17,University of Basel;University of Basel;University of Basel;University of Basel,Information Bottleneck;Deep Information Bottleneck;Deep Variational Information Bottleneck;Variational Autoencoder;Sparsity;Disentanglement;Interpretability;Copula;Mutual Information,377;377;377;377,95;95;95;95,-1;-1,europe,uk,n,
525,ICLR,2018,Demystifying MMD GANs,Miko≈Çaj Bi≈Ñkowski;Danica J. Sutherland;Michael Arbel;Arthur Gretton,mikbinkowski@gmail.com;dsuth@cs.ubc.ca;michael.n.arbel@gmail.com;arthur.gretton@gmail.com,4;7;6,4;4;2,Accept (Poster),1,6,0.0,yes,10/27/17,Imperial College London;University of British Columbia;University College London;University College London,gans;mmd;ipms;wgan;gradient penalty;unbiased gradients,-1;67;49;-1,-1;34;-1;-1,-1;-1,asia,in,y,5;4
526,ICLR,2018,Fix your classifier: the marginal value of training the last weight layer,Elad Hoffer;Itay Hubara;Daniel Soudry,elad.hoffer@gmail.com;itayhubara@gmail.com;daniel.soudry@gmail.com,6;6;6,4;5;3,Accept (Poster),2,4,3.0,yes,10/27/17,"Habana Labs (Intel);;Technion, Technion",,-1;-1;21,-1;-1;-1,-1;-1,NAN,NAN,n,
527,ICLR,2018,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,Yeming Wen;Paul Vicol;Jimmy Ba;Dustin Tran;Roger Grosse,wenyemin@cs.toronto.edu;pvicol@cs.toronto.edu;jimmy@psi.toronto.edu;trandustin@google.com;rgrosse@cs.toronto.edu,6;8;6,4;3;4,Accept (Poster),0,6,0.0,yes,10/27/17,University of Toronto;University of Toronto;University of Toronto;Google;University of Toronto,weight perturbation;reparameterization gradient;gradient variance reduction;evolution strategies;LSTM;regularization;optimization,21;21;21;-1;21,22;22;22;-1;22,-1;-1,canada,ca,y,11
528,ICLR,2018,Tree-to-tree Neural Networks for Program Translation,Xinyun Chen;Chang Liu;Dawn Song,xinyun.chen@berkeley.edu;liuchang@eecs.berkeley.edu;dawnsong.travel@gmail.com,6;4;4,4;3;4,Invite to Workshop Track,0,6,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley,,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,8
529,ICLR,2018,Towards Synthesizing Complex Programs From Input-Output Examples,Xinyun Chen;Chang Liu;Dawn Song,xinyun.chen@berkeley.edu;liuchang@eecs.berkeley.edu;dawnsong.travel@gmail.com,8;7;5,3;4;2,Accept (Poster),0,9,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley,,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,
530,ICLR,2018,A DIRT-T Approach to Unsupervised Domain Adaptation,Rui Shu;Hung Bui;Hirokazu Narui;Stefano Ermon,ruishu@stanford.edu;buih@google.com;hirokaz2@stanford.edu;ermon@cs.stanford.edu,8;7;7,4;4;2,Accept (Poster),0,5,0.0,yes,10/27/17,Stanford University;Google;Stanford University;Stanford University,domain adaptation;unsupervised learning;semi-supervised learning,5;-1;5;5,3;-1;3;3,-1;-1,usa,usa,y,5;4
531,ICLR,2018,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,Alon Brutzkus;Amir Globerson;Eran Malach;Shai Shalev-Shwartz,alonbrutzkus@mail.tau.ac.il;amir.globerson@gmail.com;eran.malach@mail.huji.ac.il;shais@cs.huji.ac.il,7;7;8,3;3;4,Accept (Poster),0,1,0.0,yes,10/27/17,Tel Aviv University;Tel Aviv University;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Deep Learning;Non-convex Optmization;Generalization;Learning Theory;Neural Networks,30;30;67;67,217;217;205;205,-1;-1,europe,il,y,1;9
532,ICLR,2018,NerveNet: Learning Structured Policy with Graph Neural Networks,Tingwu Wang;Renjie Liao;Jimmy Ba;Sanja Fidler,tingwuwang@cs.toronto.edu;rjliao@cs.toronto.edu;jimmy@psi.toronto.edu;fidler@cs.toronto.edu,7;6;7,3;3;3,Accept (Poster),0,7,0.0,yes,10/27/17,University of Toronto;University of Toronto;University of Toronto;University of Toronto,reinforcement learning;transfer learning;graph neural network,21;21;21;21,22;22;22;22,-1;-1,canada,ca,n,6;10
533,ICLR,2018,Matrix capsules with EM routing,Geoffrey E Hinton;Sara Sabour;Nicholas Frosst,geoffhinton@google.com;sasabour@google.com;frosst@google.com,7;6;4,3;3;2,Accept (Poster),10,10,22.0,yes,10/27/17,Google;Google;Google,Computer Vision;Deep Learning;Dynamic routing,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
534,ICLR,2018,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,Marco Ancona;Enea Ceolini;Cengiz √ñztireli;Markus Gross,marco.ancona@inf.ethz.ch;enea.ceolini@ini.uzh.ch;cengizo@inf.ethz.ch;grossm@inf.ethz.ch,7;6;7,3;5;4,Accept (Poster),0,3,0.0,yes,10/26/17,Swiss Federal Institute of Technology;University of Zurich;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep Neural Networks;Attribution methods;Theory of deep learning,-1;125;-1;-1,-1;136;-1;-1,-1;-1,NAN,NAN,y,8;1
535,ICLR,2018,Linearly Constrained Weights: Resolving the Vanishing Gradient Problem by Reducing Angle Bias,Takuro Kutsuna,kutsuna@mosk.tytlabs.co.jp,5;5;4,4;4;4,Reject,0,6,0.0,yes,10/24/17,Toyota Central R&D Labs. Inc.,vanishing gradient problem;multilayer perceptron;angle bias,-1,-1,-1,NAN,NAN,y,
536,ICLR,2018,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,Yuhuai Wu;Mengye Ren;Renjie Liao;Roger Grosse.,ywu@cs.toronto.edu;mren@cs.toronto.edu;rjliao@cs.toronto.edu;rgrosse@cs.toronto.edu,7;6;8,4;4;3,Accept (Poster),0,5,0.0,yes,10/27/17,University of Toronto;University of Toronto;University of Toronto;University of Toronto,meta-learning; optimization; short-horizon bias.,21;21;21;21,22;22;22;22,-1;-1,canada,ca,y,
537,ICLR,2018,Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks,Youngjin Kim;Minjung Kim;Gunhee Kim,youngjin.kim@vision.snu.ac.kr;minjung.kim1994@gmail.com;gunhee@snu.ac.kr,6;6;7,4;4;4,Accept (Poster),0,5,0.0,yes,10/26/17,Seoul National University;;Seoul National University,Generative Adversarial Networks;Memory Networks,39;-1;39,74;-1;74,-1;-1,asia,kr,n,5;4
538,ICLR,2018,Universal Agent for Disentangling Environments and Tasks,Jiayuan Mao;Honghua Dong;Joseph J. Lim,mjy14@mails.tsinghua.edu.cn;dhh14@mails.tsinghua.edu.cn;limjj@usc.edu,6;7;6,3;4;3,Accept (Poster),0,0,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Southern California",reinforcement learning;transfer learning,5;5;27,30;30;66,-1;-1,usa,usa,n,
539,ICLR,2018,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,Zhilin Yang;Zihang Dai;Ruslan Salakhutdinov;William W. Cohen,zhiliny@cs.cmu.edu;zander.dai@gmail.com;rsalakhu@cs.cmu.edu;wcohen@cs.cmu.edu,7;7;8,5;4;4,Accept (Oral),7,12,0.0,yes,10/27/17,Carnegie Mellon University;Google;Carnegie Mellon University;Carnegie Mellon University,,1;-1;1;1,24;-1;24;24,-1;-1,usa,usa,y,3
540,ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Mengye Ren;Eleni Triantafillou;Sachin Ravi;Jake Snell;Kevin Swersky;Joshua B. Tenenbaum;Hugo Larochelle;Richard S. Zemel,mren@cs.toronto.edu;eleni@cs.toronto.edu;sachinr@princeton.edu;jsnell@cs.toronto.edu;kswersky@google.com;jbt@mit.edu;hugolarochelle@google.com;zemel@cs.toronto.edu,6;6;6,5;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,University of Toronto;University of Toronto;Princeton University;University of Toronto;Google;Massachusetts Institute of Technology;Google;University of Toronto,Few-shot learning;semi-supervised learning;meta-learning,21;21;30;21;-1;8;-1;21,22;22;7;22;-1;5;-1;22,-1;-1,canada,ca,n,6
541,ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Thomas Unterthiner;Bernhard Nessler;Calvin Seward;G√ºnter Klambauer;Martin Heusel;Hubert Ramsauer;Sepp Hochreiter,unterthiner@bioinf.jku.at;nessler@bioinf.jku.at;seward@bioinf.jku.at;klambauer@bioinf.jku.at;mheusel@gmail.com;ramsauer@bioinf.jku.at;hochreit@bioinf.jku.at,5;7;7,4;3;2,Accept (Poster),6,4,0.0,yes,10/27/17,Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;;Johannes Kepler University Linz;Johannes Kepler University Linz,Deep Learning;Generative Adversarial Network;GAN;Generative Model;Potential Field,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;5;4
542,ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Dani Yogatama;Yishu Miao;Gabor Melis;Wang Ling;Adhiguna Kuncoro;Chris Dyer;Phil Blunsom,dyogatama@google.com;yishu.miao@cs.ox.ac.uk;melisgl@google.com;lingwang@google.com;akuncoro@google.com;cdyer@google.com;pblunsom@google.com,6;5;8,3;5;5,Accept (Poster),2,4,0.0,yes,10/27/17,Google;University of Oxford;Google;Google;Google;Google;Google,,-1;39;-1;-1;-1;-1;-1,-1;1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;1
543,ICLR,2018,Mitigating Adversarial Effects Through Randomization,Cihang Xie;Jianyu Wang;Zhishuai Zhang;Zhou Ren;Alan Yuille,cihangxie306@gmail.com;wjyouch@gmail.com;zhshuai.zhang@gmail.com;zhou.ren@snapchat.com;alan.l.yuille@gmail.com,6;7;6,4;4;3,Accept (Poster),5,4,0.0,yes,10/27/17,University of Southern California;;;Snap Inc.;Johns Hopkins University,adversarial examples,27;-1;-1;-1;57,66;-1;-1;-1;13,-1;-1,usa,usa,n,4
544,ICLR,2018,Learning Awareness Models,Brandon Amos;Laurent Dinh;Serkan Cabi;Thomas Roth√∂rl;Sergio G√≥mez Colmenarejo;Alistair Muldal;Tom Erez;Yuval Tassa;Nando de Freitas;Misha Denil,bamos@cs.cmu.edu;dinh.laurent@gmail.com;cabi@google.com;tcr@google.com;sergomez@google.com;alimuldal@google.com;etom@google.com;tassa@google.com;nandodefreitas@google.com;mdenil@google.com,7;4;4,4;4;5,Accept (Poster),0,7,0.0,yes,10/27/17,Carnegie Mellon University;Google;Google;Google;Google;Google;Google;Google;Google;Google,Awareness;Prediction;Seq2seq;Robots,1;-1;-1;-1;-1;-1;-1;-1;-1;-1,24;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
545,ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Peter J. Liu*;Mohammad Saleh*;Etienne Pot;Ben Goodrich;Ryan Sepassi;Lukasz Kaiser;Noam Shazeer,peterjliu@google.com;msaleh@google.com;epot@google.com;bgoodrich@google.com;rsepassi@google.com;lukaszkaiser@google.com;noam@google.com,7;8;7,5;3;4,Accept (Poster),0,5,1.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google,abstractive summarization;Transformer;long sequences;natural language processing;sequence transduction;Wikipedia;extractive summarization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
546,ICLR,2018,MaskGAN: Better Text Generation via Filling in the _______,William Fedus;Ian Goodfellow;Andrew M. Dai,liam.fedus@gmail.com;goodfellow@google.com;adai@google.com,7;7;7,4;3;5,Accept (Poster),0,8,0.0,yes,10/27/17,Google;Google;Google,Deep learning;GAN,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;5;4
547,ICLR,2018,Detecting Statistical Interactions from Neural Network Weights,Michael Tsang;Dehua Cheng;Yan Liu,tsangm@usc.edu;dehuache@usc.edu;yanliu.cs@usc.edu,7;7;7,4;4;5,Accept (Poster),0,7,0.0,yes,10/26/17,University of Southern California;University of Southern California;University of Southern California,statistical interaction detection;multilayer perceptron;generalized additive model,27;27;27,66;66;66,-1;-1,usa,usa,y,
548,ICLR,2018,Model-Ensemble Trust-Region Policy Optimization,Thanard Kurutach;Ignasi Clavera;Yan Duan;Aviv Tamar;Pieter Abbeel,thanard.kurutach@berkeley.edu;iclavera@berkeley.edu;rockyduan@eecs.berkeley.edu;avivt@berkeley.edu;pabbeel@cs.berkeley.edu,7;6;7,4;3;5,Accept (Poster),13,4,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,model-based reinforcement learning;model ensemble;reinforcement learning;model bias,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,
549,ICLR,2018,Compositional Obverter Communication Learning from Raw Visual Input,Edward Choi;Angeliki Lazaridou;Nando de Freitas,mp2893@gatech.edu;angeliki@google.com;nandodefreitas@google.com,9;3;6,4;4;3,Accept (Poster),0,7,0.0,yes,10/27/17,Georgia Institute of Technology;Google;Google,compositional language;obverter;multi-agent communication;raw pixel input,13;-1;-1,33;-1;-1,-1;-1,NAN,NAN,n,6
550,ICLR,2018,Quantitatively Evaluating GANs With Divergences Proposed for Training,Daniel Jiwoong Im;He Ma;Graham W. Taylor;Kristin Branson,daniel.im@aifounded.com;hma02@uoguelph.ca;gwtaylor@uoguelph.ca;kristinbranson@gmail.com,7;4;7,5;3;4,Accept (Poster),3,7,0.0,yes,10/27/17,Aifounded;University of Guelph;University of Guelph;Janelia Farm Research Campus- HHMI,Generative adversarial networks,-1;224;224;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;5;4
551,ICLR,2018,Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy,Asit Mishra;Debbie Marr,asit.k.mishra@intel.com;debbie.marr@intel.com,7;7;8,4;4;4,Accept (Poster),0,5,1.0,yes,10/27/17,Intel;Intel,Ternary;4-bits;low precision;knowledge distillation;knowledge transfer;model compression,-1;-1,-1;-1,-1;-1,NAN,NAN,n,2
552,ICLR,2018,Semi-parametric topological memory for navigation,Nikolay Savinov;Alexey Dosovitskiy;Vladlen Koltun,nikolay.savinov@inf.ethz.ch;adosovitskiy@gmail.com;vkoltun@gmail.com,7;3;7,5;4;4,Accept (Poster),0,11,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Google;Intel,deep learning;navigation;memory,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,10
553,ICLR,2018,Automatically Inferring Data Quality for Spatiotemporal Forecasting,Sungyong Seo;Arash Mohegh;George Ban-Weiss;Yan Liu,sungyons@usc.edu;mohegh@usc.edu;banweiss@usc.edu;yanliu.cs@usc.edu,6;6;8,3;4;4,Accept (Poster),0,9,0.0,yes,10/24/17,University of Southern California;University of Southern California;University of Southern California;University of Southern California,spatiotemporal data;graph convolutional network;data quality,27;27;27;27,66;66;66;66,-1;-1,usa,usa,n,10
554,ICLR,2018,"Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks",Pratik Chaudhari;Stefano Soatto,pratikac@ucla.edu;soatto@ucla.edu,8;5;6,5;4;4,Accept (Poster),0,6,0.0,yes,10/27/17,"University of California, Los Angeles;University of California, Los Angeles",sgd;variational inference;gradient noise;out-of-equilibrium,-1;-1,15;15,-1;-1,usa,usa,y,1
555,ICLR,2018,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning,Tianmin Shu;Caiming Xiong;Richard Socher,tianmin.shu@ucla.edu;cxiong@salesforce.com;richard@socher.org,6;6;6,4;3;3,Accept (Poster),0,5,0.0,yes,10/27/17,"University of California, Los Angeles;SalesForce.com;SalesForce.com",Hierarchical Policy;Interpretable Policy;Deep Reinforcement Learning;Multi-task Reinforcement Learning;Skill Acquisition;Language Grounding,-1;-1;-1,15;-1;-1,-1;-1,NAN,NAN,n,
556,ICLR,2018,Not-So-Random Features,Brian Bullins;Cyril Zhang;Yi Zhang,bbullins@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,7;6;4,3;5;5,Accept (Poster),0,6,0.0,yes,10/27/17,Princeton University;Princeton University;Princeton University,kernel learning;random features;online learning,30;30;30,7;7;7,-1;-1,usa,usa,y,1
557,ICLR,2018,Learning a Generative Model for Validity in Complex Discrete Structures,Dave Janz;Jos van der Westhuizen;Brooks Paige;Matt Kusner;Jos√© Miguel Hern√°ndez-Lobato,david.janz93@gmail.com;josvdwest@gmail.com;tbpaige@gmail.com;matt.kusner@gmail.com;jmh233@cam.ac.uk,6;7;7,4;3;3,Accept (Poster),0,11,0.0,yes,10/27/17,University of Cambridge;;University College London;University College London;University of Cambridge,Active learning;Reinforcement learning;Molecules,82;-1;49;49;82,2;-1;-1;-1;2,-1;-1,europe,uk,n,5
558,ICLR,2018,Learning to Multi-Task by Active Sampling,Sahil Sharma*;Ashutosh Kumar Jha*;Parikshit S Hegde;Balaraman Ravindran,sahil@cse.iitm.ac.in;me14b148@smail.iitm.ac.in;ee14b123@ee.iitm.ac.in;ravi@cse.iitm.ac.in,5;7;7,3;3;5,Accept (Poster),3,5,0.0,yes,10/27/17,Indian Institute of Technology Madras;Indian Institute of Technology Madras;Indian Institute of Technology Madras;Indian Institute of Technology Madras,Deep Reinforcement Learning,-1;-1;-1;-1,625;625;625;625,-1;-1,NAN,NAN,n,6
559,ICLR,2018,Consequentialist conditional cooperation in social dilemmas with imperfect information,Alexander Peysakhovich;Adam Lerer,alexpeys@gmail.com;alerer@fb.com,7;5;6,3;4;4,Accept (Poster),0,4,0.0,yes,10/17/17,Facebook;Facebook,deep reinforcement learning;cooperation;social dilemma;multi-agent systems,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
560,ICLR,2018,MGAN: Training Generative Adversarial Nets with Multiple Generators,Quan Hoang;Tu Dinh Nguyen;Trung Le;Dinh Phung,qhoang@umass.edu;tu.nguyen@deakin.edu.au;trung.l@deakin.edu.au;dinh.phung@deakin.edu.au,5;7;6,4;5;3,Accept (Poster),0,10,15.0,yes,10/25/17,"University of Massachusetts, Amherst;Deakin University;Deakin University;Deakin University",GANs;Mode Collapse;Mixture;Jensen-Shannon Divergence;Inception Score;Generator;Discriminator;CIFAR-10;STL-10;ImageNet,21;-1;-1;-1,191;334;334;334,-1;-1,asia,cn,n,1;5;4
561,ICLR,2018,Residual Connections Encourage Iterative Inference,Stanis≈Çaw Jastrzebski;Devansh Arpit;Nicolas Ballas;Vikas Verma;Tong Che;Yoshua Bengio,staszek.jastrzebski@gmail.com;devansharpit@gmail.com;ballas.n@gmail.com;vikasverma.iitm@gmail.com;tongcheprivate@gmail.com;yoshua.umontreal@gmail.com,6;5;7,3;5;4,Accept (Poster),0,5,0.0,yes,10/27/17,Jagiellonian University;SalesForce.com;Facebook;Aalto University;;University of Montreal,residual network;iterative inference;deep learning,-1;-1;-1;125;-1;125,695;-1;-1;190;-1;108,-1;-1,canada,ca,n,1
562,ICLR,2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,Rudy Bunel;Matthew Hausknecht;Jacob Devlin;Rishabh Singh;Pushmeet Kohli,rudy@robots.ox.ac.uk;mahauskn@microsoft.com;jacobdevlin@google.com;risin@microsoft.com;pushmeet@google.com,5;6;7,3;3;3,Accept (Poster),0,5,2.0,yes,10/26/17,University of Oxford;Microsoft;Google;Microsoft;Google,Program Synthesis;Reinforcement Learning;Language Model,39;-1;-1;-1;-1,1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
563,ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Guneet S. Dhillon;Kamyar Azizzadenesheli;Zachary C. Lipton;Jeremy D. Bernstein;Jean Kossaifi;Aran Khanna;Animashree Anandkumar,guneetdhillon@utexas.edu;kazizzad@uci.edu;zlipton@cmu.edu;bernstein@caltech.edu;jean.kossaifi@gmail.com;arankhan@amazon.com;animakumar@gmail.com,6;7;6,3;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,"University of Texas, Austin;University of California, Irvine;Carnegie Mellon University;California Institute of Technology;NVIDIA;Amazon;California Institute of Technology",,-1;-1;1;125;-1;-1;125,-1;99;24;3;-1;-1;3,-1;-1,usa,usa,n,1;4
564,ICLR,2018,Online Learning Rate Adaptation with Hypergradient Descent,Atilim Gunes Baydin;Robert Cornish;David Martinez Rubio;Mark Schmidt;Frank Wood,gunes@robots.ox.ac.uk;rcornish@robots.ox.ac.uk;david.martinez2@wadh.ox.ac.uk;schmidtm@cs.ubc.ca;fwood@robots.ox.ac.uk,6;7;7,4;3;4,Accept (Poster),1,8,0.0,yes,10/27/17,University of Oxford;University of Oxford;University of Oxford;University of British Columbia;University of Oxford,,39;39;39;67;39,1;1;1;34;1,-1;-1,europe,uk,n,9
565,ICLR,2018,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,Vitchyr Pong*;Shixiang Gu*;Murtaza Dalal;Sergey Levine,vitchyr@berkeley.edu;sg717@cam.ac.uk;mdalal@berkeley.edu;svlevine@eecs.berkeley.edu,7;4;7,4;4;3,Accept (Poster),0,3,2.0,yes,10/27/17,University of California Berkeley;University of Cambridge;University of California Berkeley;University of California Berkeley,model-based reinforcement learning;model-free reinforcement learning;temporal difference learning;predictive learning;predictive models;optimal control;off-policy reinforcement learning;deep learning;deep reinforcement learning;q learning,-1;82;-1;-1,18;2;18;18,-1;-1,usa,usa,n,
566,ICLR,2018,Generative Models of Visually Grounded Imagination,Ramakrishna Vedantam;Ian Fischer;Jonathan Huang;Kevin Murphy,vrama@gatech.edu;iansf@google.com;jonathanhuang@google.com;murphyk@gmail.com,7;7;7,3;4;3,Accept (Poster),0,6,0.0,yes,10/27/17,Georgia Institute of Technology;Google;Google;Google,variational autoencoders;generative models;language;vision;abstraction;compositionality;hierarchy,13;-1;-1;-1,33;-1;-1;-1,-1;-1,NAN,NAN,n,5
567,ICLR,2018,Spherical CNNs,Taco S. Cohen;Mario Geiger;Jonas K√∂hler;Max Welling,taco.cohen@gmail.com;geiger.mario@gmail.com;jonas.koehler.ks@gmail.com;m.welling@uva.nl,8;7;9,4;3;4,Accept (Oral),0,7,3.0,yes,10/27/17,University of Amsterdam;;;University of Amsterdam,deep learning;equivariance;convolution;group convolution;3D;vision;omnidirectional;shape recognition;molecular energy regression,-1;-1;-1;125,-1;-1;-1;59,-1;-1,europe,nl,n,1
568,ICLR,2018,Neural Speed Reading via Skim-RNN,Minjoon Seo;Sewon Min;Ali Farhadi;Hannaneh Hajishirzi,minjoon@cs.washington.edu;shmsw25@snu.ac.kr;ali@cs.washington.edu;hannaneh@washington.edu,7;7;8,3;3;3,Accept (Poster),3,10,0.0,yes,10/27/17,University of Washington;Seoul National University;University of Washington;University of Washington,Natural Language Processing;RNN;Inference Speed,8;39;8;8,25;74;25;25,-1;-1,usa,usa,n,3
569,ICLR,2018,On Unifying Deep Generative Models,Zhiting Hu;Zichao Yang;Ruslan Salakhutdinov;Eric P. Xing,zhitinghu@gmail.com;yangtze2301@gmail.com;rsalakhu@cs.cmu.edu;epxing@cs.cmu.edu,7;6;7,4;4;3,Accept (Poster),0,4,0.0,yes,10/27/17,"University of California, San Diego;;Carnegie Mellon University;Carnegie Mellon University",deep generative models;generative adversarial networks;variational autoencoders;variational inference,-1;-1;1;1,31;-1;24;24,-1;-1,usa,usa,y,5;4
570,ICLR,2018,Cascade Adversarial Machine Learning Regularized with a Unified Embedding,Taesik Na;Jong Hwan Ko;Saibal Mukhopadhyay,taesik.na@gatech.edu;jonghwan.ko@gatech.edu;saibal.mukhopadhyay@ece.gatech.edu,6;6;5,4;4;4,Accept (Poster),0,5,0.0,yes,10/24/17,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,adversarial machine learning;embedding;regularization;adversarial attack,13;13;13,33;33;33,-1;-1,usa,usa,n,4
571,ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Cathy Wu;Aravind Rajeswaran;Yan Duan;Vikash Kumar;Alexandre M Bayen;Sham Kakade;Igor Mordatch;Pieter Abbeel,cathywu@eecs.berkeley.edu;aravraj@cs.washington.edu;rockyduan@eecs.berkeley.edu;vikash@cs.washington.edu;bayen@berkeley.edu;sham@cs.washington.edu;igor.mordatch@gmail.com;pabbeel@cs.berkeley.edu,7;8;6,4;3;4,Accept (Oral),0,4,2.0,yes,10/27/17,University of California Berkeley;University of Washington;University of California Berkeley;University of Washington;University of California Berkeley;University of Washington;University of Washington;University of California Berkeley,reinforcement learning;policy gradient;variance reduction;baseline;control variates,-1;8;-1;8;-1;8;8;-1,18;25;18;25;18;25;25;18,-1;-1,usa,usa,y,
572,ICLR,2018,Lifelong Learning with Dynamically Expandable Networks,Jaehong Yoon;Eunho Yang;Jeongtae Lee;Sung Ju Hwang,mmvc98@unist.ac.kr;eunhoy@kaist.ac.kr;jtlee@unist.ac.kr;sjhwang82@kaist.ac.kr,7;6;8,3;3;2,Accept (Poster),0,4,0.0,yes,10/27/17,Ulsan National Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Ulsan National Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Transfer learning;Lifelong learning;Selective retraining;Dynamic network expansion,-1;-1;-1;-1,230;95;230;95,-1;-1,NAN,NAN,n,
573,ICLR,2018,A Simple Neural Attentive Meta-Learner,Nikhil Mishra;Mostafa Rohaninejad;Xi Chen;Pieter Abbeel,nmishra@berkeley.edu;rohaninejadm@berkeley.edu;adslcx@gmail.com;pabbeel@gmail.com,7;6;6,4;3;3,Accept (Poster),1,7,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;covariant.ai;covariant.ai,meta-learning;few-shot learning,-1;-1;-1;-1,18;18;-1;-1,-1;-1,NAN,NAN,n,6;8;1
574,ICLR,2018,Emergence of grid-like representations by training recurrent neural networks to perform spatial localization,Christopher J. Cueva;Xue-Xin Wei,ccueva@gmail.com;weixxpku@gmail.com,8;9;8,4;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,Columbia University;Columbia University,recurrent neural network;grid cell;neural representation of space,21;-1,14;-1,-1;-1,asia,in,n,
575,ICLR,2018,Certified Defenses against Adversarial Examples ,Aditi Raghunathan;Jacob Steinhardt;Percy Liang,aditir@stanford.edu;jsteinhardt@cs.stanford.edu;pliang@cs.stanford.edu,8;8;5,4;4;3,Accept (Poster),4,5,1.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,adversarial examples;certificate of robustness;convex relaxations,5;5;5,3;3;3,-1;-1,usa,usa,n,4
576,ICLR,2018,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,Angeliki Lazaridou;Karl Moritz Hermann;Karl Tuyls;Stephen Clark,angeliki@google.com;kmh@google.com;karltuyls@google.com;clarkstephen@google.com,7;9;5,4;5;4,Accept (Oral),0,6,0.0,yes,10/27/17,Google;Google;Google;Google,disentanglement;communication;emergent language;compositionality;multi-agent,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
577,ICLR,2018,Unsupervised Representation Learning by Predicting Image Rotations,Spyros Gidaris;Praveer Singh;Nikos Komodakis,spyros.gidaris@enpc.fr;praveer.singh@enpc.fr;nikos.komodakis@enpc.fr,6;6;6,5;4;3,Accept (Poster),0,7,0.0,yes,10/27/17,ENPC;ENPC;ENPC,Unsupervised representation learning,-1;-1;-1,-1;-1;-1,-1;-1,europe,ch,n,2
578,ICLR,2018,Learn to Pay Attention,Saumya Jetley;Nicholas A. Lord;Namhoon Lee;Philip H. S. Torr,saumya.jetley@stx.ox.ac.uk;nicklord@robots.ox.ac.uk;namhoon.lee@eng.ox.ac.uk;philip.torr@eng.ox.ac.uk,5;6;6,4;4;4,Accept (Poster),6,8,0.0,yes,10/27/17,University of Oxford;University of Oxford;University of Oxford;University of Oxford,deep learning;attention-aware representations;image classification;weakly supervised segmentation;domain shift;classifier generalisation;robustness to adversarial attack,39;39;39;39,1;1;1;1,-1;-1,europe,uk,n,8;2;4
579,ICLR,2018,Auto-Encoding Sequential Monte Carlo,Tuan Anh Le;Maximilian Igl;Tom Rainforth;Tom Jin;Frank Wood,tuananh@robots.ox.ac.uk;maximilian.igl@gmail.com;twgr@robots.ox.ac.uk;tom@jin.me.uk;fwood@robots.ox.ac.uk,7;3;7,3;2;4,Accept (Poster),0,7,0.0,yes,10/27/17,University of Oxford;;University of Oxford;University of Oxford;University of Oxford,Variational Autoencoders;Inference amortization;Model learning;Sequential Monte Carlo;ELBOs,39;-1;39;39;39,1;-1;1;1;1,-1;-1,europe,uk,y,1;5
580,ICLR,2018,Divide-and-Conquer Reinforcement Learning,Dibya Ghosh;Avi Singh;Aravind Rajeswaran;Vikash Kumar;Sergey Levine,dibya.ghosh@berkeley.edu;avisingh@cs.berkeley.edu;aravraj@cs.washington.edu;vikash@cs.washington.edu;svlevine@eecs.berkeley.edu,7;7;4,4;4;4,Accept (Poster),0,4,1.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of Washington;University of Washington;University of California Berkeley,deep reinforcement learning;reinforcement learning;policy gradients;model-free,-1;-1;8;8;-1,18;18;25;25;18,-1;-1,usa,usa,n,
581,ICLR,2018,SMASH: One-Shot Model Architecture Search through HyperNetworks,Andrew Brock;Theo Lim;J.M. Ritchie;Nick Weston,ajb5@hw.ac.uk;t.lim@hw.ac.uk;j.m.ritchie@hw.ac.uk;nick.weston@renishaw.com,7;7;6,3;4;2,Accept (Poster),0,2,0.0,yes,9/29/17,Heriot-Watt University;Heriot-Watt University;Heriot-Watt University;Renishaw,meta-learning;architecture search;deep learning;computer vision,224;224;224;-1,363;363;363;-1,-1;-1,NAN,NAN,n,
582,ICLR,2018,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,Erin Grant;Chelsea Finn;Sergey Levine;Trevor Darrell;Thomas Griffiths,eringrant@berkeley.edu;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu;trevor@eecs.berkeley.edu;tom_griffiths@berkeley.edu,6;7;7,3;3;3,Accept (Poster),1,8,0.0,yes,10/26/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,meta-learning;learning to learn;hierarchical Bayes;approximate Bayesian methods,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,6;11
583,ICLR,2018,Neural Sketch Learning for Conditional Program Generation,Vijayaraghavan Murali;Letao Qi;Swarat Chaudhuri;Chris Jermaine,vijay@rice.edu;letao.qi@rice.edu;swarat@rice.edu;cmj4@rice.edu,7;8;7,2;4;3,Accept (Oral),0,4,0.0,yes,10/27/17,Rice University;Rice University;Rice University;Rice University,Program generation;Source code;Program synthesis;Deep generative models,95;95;95;95,86;86;86;86,-1;-1,australasia,au,n,
584,ICLR,2018,Synthetic and Natural Noise Both Break Neural Machine Translation,Yonatan Belinkov;Yonatan Bisk,belinkov@mit.edu;ybisk@yonatanbisk.com,7;7;8,4;4;4,Accept (Oral),0,7,0.0,yes,10/27/17,Massachusetts Institute of Technology;SK Telecom,neural machine translation;characters;noise;adversarial examples;robust training,8;-1,5;-1,-1;-1,NAN,NAN,n,3
585,ICLR,2018,Policy Optimization by Genetic Distillation ,Tanmay Gangwani;Jian Peng,gangwan2@illinois.edu;jianpeng@illinois.edu,8;6;3,5;4;4,Accept (Poster),0,9,0.0,yes,10/27/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Genetic algorithms;deep reinforcement learning;imitation learning,-1;-1,-1;-1,-1;-1,usa,usa,n,
586,ICLR,2018,Active Neural Localization,Devendra Singh Chaplot;Emilio Parisotto;Ruslan Salakhutdinov,chaplot@cs.cmu.edu;eparisot@andrew.cmu.edu;rsalakhu@cs.cmu.edu,6;8;7,4;5;4,Accept (Poster),0,4,1.0,yes,10/25/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1,24;24;24,-1;-1,usa,usa,n,
587,ICLR,2018,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,Evan Zheran Liu;Kelvin Guu;Panupong Pasupat;Tianlin Shi;Percy Liang,evzliu@gmail.com;kguu@stanford.edu;ppasupat@cs.stanford.edu;tianlins@cs.stanford.edu;pliang@cs.stanford.edu,7;6;7,4;3;3,Accept (Poster),0,8,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,reinforcement learning;sparse rewards;web;exploration,5;5;5;5;5,3;3;3;3;3,-1;-1,usa,usa,n,
588,ICLR,2018,Training GANs with Optimism,Constantinos Daskalakis;Andrew Ilyas;Vasilis Syrgkanis;Haoyang Zeng,costis@mit.edu;ailyas@mit.edu;vasy@microsoft.com;haoyangz@mit.edu,7;8;6,4;4;4,Accept (Poster),3,6,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Microsoft;Massachusetts Institute of Technology,GANs;Optimistic Mirror Decent;Cycling;Last Iterate Convergence;Optimistic Adam,8;8;-1;8,5;5;-1;5,-1;-1,usa,usa,y,1;5;4
589,ICLR,2018,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs",Sanjeev Arora;Mikhail Khodak;Nikunj Saunshi;Kiran Vodrahalli,arora@cs.princeton.edu;mkhodak@princeton.edu;nsaunshi@cs.princeton.edu;kiran.vodrahalli@columbia.edu,7;7;6,3;1;4,Accept (Poster),0,6,0.0,yes,10/27/17,Princeton University;Princeton University;Princeton University;Columbia University,theory;LSTM;unsupervised learning;word embeddings;compressed sensing;sparse recovery;document representation;text classification,30;30;30;21,7;7;7;14,-1;-1,usa,usa,y,1
590,ICLR,2018,Scalable Private Learning with PATE,Nicolas Papernot;Shuang Song;Ilya Mironov;Ananth Raghunathan;Kunal Talwar;Ulfar Erlingsson,ngp5056@cse.psu.edu;shs037@eng.ucsd.edu;mironov@google.com;pseudorandom@google.com;kunal@google.com;ulfar@google.com,6;6;7,1;4;3,Accept (Poster),0,3,0.0,yes,10/27/17,"Pennsylvania State University;University of California, San Diego;Google;Google;Google;Google",privacy;differential privacy;machine learning;deep learning,39;-1;-1;-1;-1;-1,-1;31;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
591,ICLR,2018,Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,Carlos Riquelme;George Tucker;Jasper Snoek,rikel@google.com;gjt@google.com;jsnoek@google.com,5;7;6,5;4;4,Accept (Poster),0,9,0.0,yes,10/27/17,Google;Google;Google,exploration;Thompson Sampling;Bayesian neural networks;bandits;reinforcement learning;variational inference;Monte Carlo,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11
592,ICLR,2018,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,Yujun Lin;Song Han;Huizi Mao;Yu Wang;Bill Dally,yujunlin@stanford.edu;songhan@stanford.edu;huizi@stanford.edu;yu-wang@mail.tsinghua.edu.cn;dally@stanford.edu,7;6;7,4;5;4,Accept (Poster),6,24,6.0,yes,10/27/17,"Stanford University;Stanford University;Stanford University;Tsinghua University, Tsinghua University;Stanford University",distributed training,5;5;5;5;5,3;3;3;30;3,-1;-1,usa,usa,n,3
593,ICLR,2018,The power of deeper networks for expressing natural functions,David Rolnick;Max Tegmark,drolnick@mit.edu;tegmark@mit.edu,7;6;6,4;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology,expressivity of neural networks;depth of neural networks;universal approximators;function approximation;deep learning,8;8,5;5,-1;-1,usa,usa,y,1
594,ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Yi Zhou;Zimo Li;Shuangjiu Xiao;Chong He;Zeng Huang;Hao Li,zhou859@usc.edu;zimoli@usc.edu;xsjiu99@sjtu.edu.cn;sal@sjtu.edu.cn;zenghuang@usc.edu;hao@hao-li.com,7;7;6,3;5;5,Accept (Poster),0,1,0.0,yes,10/27/17,University of Southern California;University of Southern California;Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of Southern California;Hao-li,motion synthesis;motion prediction;human pose;human motion;recurrent networks;lstm,27;27;39;39;27;-1,66;66;188;188;66;-1,-1;-1,NAN,NAN,n,
595,ICLR,2018,A Hierarchical Model for Device Placement,Azalia Mirhoseini;Anna Goldie;Hieu Pham;Benoit Steiner;Quoc V. Le;Jeff Dean,azalia@google.com;agoldie@google.com;hyhieu@cmu.edu;bsteiner@google.com;qvl@google.com;jeff@google.com,5;5;8,4;4;5,Accept (Poster),0,6,1.0,yes,10/27/17,Google;Google;Carnegie Mellon University;Google;Google;Google,deep learning;device placement;policy gradient optimization,-1;-1;1;-1;-1;-1,-1;-1;24;-1;-1;-1,-1;-1,NAN,NAN,n,2;3;10
596,ICLR,2018,Improving GANs Using Optimal Transport,Tim Salimans;Han Zhang;Alec Radford;Dimitris Metaxas,tim@openai.com;han.zhang@cs.rutgers.edu;alec@openai.com;dnm@cs.rutgers.edu,8;6;6,4;2;3,Accept (Poster),0,4,0.0,yes,10/26/17,OpenAI;Rutgers University;OpenAI;Rutgers University,GAN;generative modeling;adversarial;optimal transport,-1;30;-1;30,-1;-1;-1;-1,-1;-1,usa,usa,n,5;4
597,ICLR,2018,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,Yanshuai Cao;Gavin Weiguang Ding;Kry Yik-Chau Lui;Ruitong Huang,yanshuai.cao@borealisai.com;gavin.ding@borealisai.com;yikchau.y.lui@borealisai.com;ruitong.huang@borealisai.com,6;7;4,3;4;3,Accept (Poster),0,5,1.0,yes,10/27/17,Borealis AI;Borealis AI;Borealis AI;Borealis AI,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,5;4
598,ICLR,2018,Hierarchical Density Order Embeddings,Ben Athiwaratkun;Andrew Gordon Wilson,pa338@cornell.edu;andrew@cornell.edu,4;6;8,3;4;5,Accept (Poster),0,5,1.0,yes,10/27/17,Cornell University;Cornell University,embeddings;word embeddings;probabilistic embeddings;hierarchical representation;probabilistic representation;order embeddings;wordnet;hyperlex,5;5,19;19,-1;-1,usa,usa,n,3;10
599,ICLR,2018,Stabilizing Adversarial Nets with Prediction Methods,Abhay Yadav;Sohil Shah;Zheng Xu;David Jacobs;Tom Goldstein,jaiabhay@cs.umd.edu;sohilas@umd.edu;xuzh@cs.umd.edu;djacobs@umiacs.umd.edu;tomg@cs.umd.edu,4;9;7,4;4;4,Accept (Poster),0,15,0.0,yes,10/27/17,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",adversarial networks;optimization,12;12;12;12;12,69;69;69;69;69,-1;-1,usa,usa,y,1;4
600,ICLR,2018,Boosting the Actor with Dual Critic,Bo Dai;Albert Shaw;Niao He;Lihong Li;Le Song,bohr.dai@gmail.com;ashaw596@gatech.edu;niaohe@illinois.edu;lihongli.cs@gmail.com;lsong@cc.gatech.edu,7;6;5,4;3;4,Accept (Poster),0,4,0.0,yes,10/27/17,"Google;Georgia Institute of Technology;University of Illinois, Urbana Champaign;Amazon;Georgia Institute of Technology",reinforcement learning;actor-critic algorithm;Lagrangian duality,-1;13;-1;-1;13,-1;33;-1;-1;33,-1;-1,usa,usa,y,
601,ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Andrew Michael Saxe;Yamini Bansal;Joel Dapello;Madhu Advani;Artemy Kolchinsky;Brendan Daniel Tracey;David Daniel Cox,asaxe@fas.harvard.edu;ybansal@g.harvard.edu;dapello@g.harvard.edu;madvani@fas.harvard.edu;artemyk@gmail.com;tracey.brendan@gmail.com;davidcox@fas.harvard.edu,6;7;7,2;3;3,Accept (Poster),7,8,2.0,yes,10/27/17,Harvard University;Harvard University;Harvard University;Harvard University;Santa Fe Institute;;Harvard University,information bottleneck;deep learning;deep linear networks,49;49;49;49;-1;-1;49,6;6;6;6;-1;-1;6,-1;-1,usa,usa,n,1
602,ICLR,2018,Syntax-Directed Variational Autoencoder for Structured Data,Hanjun Dai;Yingtao Tian;Bo Dai;Steven Skiena;Le Song,hanjundai@gatech.edu;yittian@cs.stonybrook.edu;bohr.dai@gmail.com;skiena@cs.stonybrook.edu;lsong@cc.gatech.edu,3;5;7,2;1;3,Accept (Poster),0,11,0.0,yes,10/27/17,"Georgia Institute of Technology;State University of New York, Stony Brook;Google;State University of New York, Stony Brook;Georgia Institute of Technology",generative model for structured data;syntax-directed generation;molecule and program optimization;variational autoencoder,13;-1;-1;-1;13,33;-1;-1;-1;33,-1;-1,usa,usa,n,1;5
603,ICLR,2018,Do GANs learn the distribution? Some Theory and Empirics,Sanjeev Arora;Andrej Risteski;Yi Zhang,arora@cs.princeton.edu;risteski@cs.princeton.edu;y.zhang@cs.princeton.edu,7;6;7,4;4;3,Accept (Poster),0,4,0.0,yes,10/27/17,Princeton University;Princeton University;Princeton University,Generative Adversarial Networks;mode collapse;birthday paradox;support size estimation,30;30;30,7;7;7,-1;-1,usa,usa,y,1;5;4
604,ICLR,2018,TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING,Wen Sun;J. Andrew Bagnell;Byron Boots,wensun@cs.cmu.edu;dbagnell@cs.cmu.edu;bboots@cc.gatech.edu,7;6;3,3;4;5,Accept (Poster),0,5,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Georgia Institute of Technology,Imitation Learning;Reinforcement Learning,1;1;13,24;24;33,-1;-1,usa,usa,y,
605,ICLR,2018,Understanding Deep Neural Networks with Rectified Linear Units,Raman Arora;Amitabh Basu;Poorya Mianjy;Anirbit Mukherjee,arora@cs.jhu.edu;basu.amitabh@jhu.edu;mianjy@jhu.edu;amukhe14@jhu.edu,6;6;7,4;5;4,Accept (Poster),0,0,0.0,yes,10/27/17,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,expressive power;benefits of depth;empirical risk minimization;global optimality;computational hardness;combinatorial optimization,57;57;57;57,13;13;13;13,-1;-1,usa,usa,y,1
606,ICLR,2018,Deep Neural Networks as Gaussian Processes,Jaehoon Lee;Yasaman Bahri;Roman Novak;Samuel S. Schoenholz;Jeffrey Pennington;Jascha Sohl-Dickstein,jaehlee@google.com;yasamanb@google.com;romann@google.com;schsam@google.com;jpennin@google.com;jaschasd@google.com,4;6;7,4;4;3,Accept (Poster),0,8,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,Gaussian process;Bayesian regression;deep networks;kernel methods,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,11
607,ICLR,2018,Deep Complex Networks,Chiheb Trabelsi;Olexa Bilaniuk;Ying Zhang;Dmitriy Serdyuk;Sandeep Subramanian;Joao Felipe Santos;Soroush Mehri;Negar Rostamzadeh;Yoshua Bengio;Christopher J Pal,chiheb.trabelsi@polymtl.ca;olexa.bilaniuk@umontreal.ca;ying.zhang@umontreal.ca;serdyuk@iro.umontreal.ca;sandeep.subramanian.1@umontreal.ca;jfsantos@emt.inrs.ca;soroush.mehri@microsoft.com;negar@elementai.com;yoshua.bengio@umontreal.ca;christopher.pal@polymtl.ca,7;8;4,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,Polytechnique Montreal;University of Montreal;University of Montreal;University of Montreal;University of Montreal;Institut national de la recherche scientifique;Microsoft;Element AI;University of Montreal;Polytechnique Montreal,deep learning;complex-valued neural networks,377;125;125;125;125;-1;-1;-1;125;377,-1;108;108;108;108;-1;-1;-1;108;-1,-1;-1,canada,ca,n,2
608,ICLR,2018,Non-Autoregressive Neural Machine Translation,Jiatao Gu;James Bradbury;Caiming Xiong;Victor O.K. Li;Richard Socher,jiataogu@eee.hku.hk;james.bradbury@salesforce.com;cxiong@salesforce.com;vli@eee.hku.hk;rsocher@salesforce.com,7;7;6,4;4;4,Accept (Poster),2,3,0.0,yes,10/27/17,The University of Hong Kong;SalesForce.com;SalesForce.com;The University of Hong Kong;SalesForce.com,machine translation;non-autoregressive;transformer;fertility;nmt,95;-1;-1;95;-1,40;-1;-1;40;-1,-1;-1,NAN,NAN,n,8;3
609,ICLR,2018,Depthwise Separable Convolutions for Neural Machine Translation,Lukasz Kaiser;Aidan N. Gomez;Francois Chollet,lukaszkaiser@google.com;aidan.n.gomez@gmail.com;fchollet@google.com,5;7;7,4;4;3,Accept (Poster),0,4,0.0,yes,10/27/17,Google;;Google,convolutions;neural machine translation,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
610,ICLR,2018,Learning a neural response metric for retinal prosthesis,Nishal P Shah;Sasidhar Madugula;EJ Chichilnisky;Yoram Singer;Jonathon Shlens,nishalps@stanford.edu;sasidhar@stanford.edu;ej@stanford.edu;singer@google.com;shlens@google.com,5;6;7,4;3;4,Accept (Poster),0,0,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University;Google;Google,Metric learning;Computational Neuroscience;Retina;Neural Prosthesis,5;5;5;-1;-1,3;3;3;-1;-1,-1;-1,NAN,NAN,n,5
611,ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Gabriel Barth-Maron;Matthew W. Hoffman;David Budden;Will Dabney;Dan Horgan;Dhruva TB;Alistair Muldal;Nicolas Heess;Timothy Lillicrap,gabrielbm@google.com;mwhoffman@google.com;budden@google.com;wdabney@google.com;horgan@google.com;dhruvat@google.com;alimuldal@google.com;heess@google.com;countzero@google.com,9;6;5,4;5;4,Accept (Poster),2,6,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google;Google;Google,policy gradient;continuous control;actor critic;reinforcement learning,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
612,ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Ashwin Kalyan;Abhishek Mohta;Oleksandr Polozov;Dhruv Batra;Prateek Jain;Sumit Gulwani,ashwinkv@gatech.edu;t-abmoht@microsoft.com;polozov@microsoft.com;dbatra@gatech.edu;prajain@microsoft.com;sumitg@microsoft.com,6;6;8,3;4;3,Accept (Poster),0,5,0.0,yes,10/27/17,Georgia Institute of Technology;Microsoft;Microsoft;Georgia Institute of Technology;Microsoft;Microsoft,Program synthesis;deductive search;deep learning;program induction;recurrent neural networks,13;-1;-1;13;-1;-1,33;-1;-1;33;-1;-1,-1;-1,NAN,NAN,n,1
613,ICLR,2018,Learning an Embedding Space for Transferable Robot Skills,Karol Hausman;Jost Tobias Springenberg;Ziyu Wang;Nicolas Heess;Martin Riedmiller,hausmankarol@gmail.com;springenberg@google.com;ziyu@google.com;heess@google.com;riedmiller@google.com,7;7;7,4;4;5,Accept (Poster),0,6,0.0,yes,10/27/17,Google;Google;Google;Google;Google,Deep Reinforcement Learning;Variational Inference;Control;Robotics,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
614,ICLR,2018,Multi-Mention Learning for Reading Comprehension with Neural Cascades,Swabha Swayamdipta;Ankur P. Parikh;Tom Kwiatkowski,swabha@cs.cmu.edu;aparikh@google.com;tomkwiat@google.com,7;5;6,4;4;4,Accept (Poster),0,6,0.0,yes,10/27/17,Carnegie Mellon University;Google;Google,reading comprehension;multi-loss;question answering;scalable;TriviaQA;feed-forward;latent variable;attention,1;-1;-1,24;-1;-1,-1;-1,NAN,NAN,n,8
615,ICLR,2018,Learning Differentially Private Recurrent Language Models,H. Brendan McMahan;Daniel Ramage;Kunal Talwar;Li Zhang,mcmahan@google.com;dramage@google.com;kunal@google.com;liqzhang@google.com,7;7;8,4;2;4,Accept (Poster),0,3,0.0,yes,10/27/17,Google;Google;Google;Google,differential privacy;LSTMs;language models;privacy,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,3
616,ICLR,2018,Learning Approximate Inference Networks for Structured Prediction,Lifu Tu;Kevin Gimpel,lifu@ttic.edu;kgimpel@ttic.edu,7;5;9,5;3;4,Accept (Poster),0,5,0.0,yes,10/27/17,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,Approximate Inference Networks;Structured Prediction;Multi-Label Classification;Sequence Labeling,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
617,ICLR,2018,Emergent Communication through Negotiation,Kris Cao;Angeliki Lazaridou;Marc Lanctot;Joel Z Leibo;Karl Tuyls;Stephen Clark,kc391@cam.ac.uk;angeliki@google.com;lanctot@google.com;jzl@google.com;karltuyls@google.com;clarkstephen@google.com,6;7;5,3;4;4,Accept (Poster),7,5,0.0,yes,10/27/17,University of Cambridge;Google;Google;Google;Google;Google,multi-agent learning;reinforcement learning;game theory;emergent communication,82;-1;-1;-1;-1;-1,2;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
618,ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Florian Tram√®r;Alexey Kurakin;Nicolas Papernot;Ian Goodfellow;Dan Boneh;Patrick McDaniel,tramer@cs.stanford.edu;alexey@kurakin.me;ngp5056@cse.psu.edu;goodfellow@google.com;dabo@cs.stanford.edu;mcdaniel@cse.psu.edu,6;6;6,2;4;4,Accept (Poster),0,4,1.0,yes,10/27/17,Stanford University;Google;Pennsylvania State University;Google;Stanford University;Pennsylvania State University,Adversarial Examples;Adversarial Training;Attacks;Defenses;ImageNet,5;-1;39;-1;5;39,3;-1;-1;-1;3;-1,-1;-1,usa,usa,y,4
619,ICLR,2018,Maximum a Posteriori Policy Optimisation,Abbas Abdolmaleki;Jost Tobias Springenberg;Yuval Tassa;Remi Munos;Nicolas Heess;Martin Riedmiller,abbas.abdolmaleky@gmail.com;springenberg@google.com;heess@google.com;tassa@google.com;munos@google.com,7;6;5,5;1;4,Accept (Poster),4,5,2.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,Reinforcement Learning;Variational Inference;Control,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
620,ICLR,2018,Global Optimality Conditions for Deep Neural Networks,Chulhee Yun;Suvrit Sra;Ali Jadbabaie,chulheey@mit.edu;suvrit@mit.edu;jadbabai@mit.edu,5;7;8,5;4;5,Accept (Poster),0,3,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,deep linear neural networks;global optimality;deep learning,8;8;8,5;5;5,-1;-1,usa,usa,y,1;9
621,ICLR,2018,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,Benjamin Eysenbach;Shixiang Gu;Julian Ibarz;Sergey Levine,eysenbach@google.com;sg717@cam.ac.uk;julianibarz@google.com;slevine@google.com,7;6;5;7,4;5;4;4,Accept (Poster),0,10,0.0,yes,10/27/17,Google;University of Cambridge;Google;Google,manual reset;continual learning;reinforcement learning;safety,-1;82;-1;-1,-1;2;-1;-1,-1;-1,NAN,NAN,y,
622,ICLR,2018,Sensitivity and Generalization in Neural Networks: an Empirical Study,Roman Novak;Yasaman Bahri;Daniel A. Abolafia;Jeffrey Pennington;Jascha Sohl-Dickstein,romann@google.com;yasamanb@google.com;danabo@google.com;jpennin@google.com;jaschasd@google.com,8;5;4,4;3;5,Accept (Poster),0,9,4.0,yes,10/27/17,Google;Google;Google;Google;Google,generalization;complexity;experimental study;linear regions;Jacobian,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
623,ICLR,2018,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,Forough Arabshahi;Sameer Singh;Animashree Anandkumar,farabsha@uci.edu;sameer@uci.edu;animakumar@gmail.com,6;8;5,4;3;4,Accept (Poster),0,7,0.0,yes,10/27/17,"University of California, Irvine;University of California, Irvine;California Institute of Technology",symbolic reasoning;mathematical equations;recursive neural networks;neural programing,-1;-1;125,99;99;3,-1;-1,usa,usa,n,1
624,ICLR,2018,Dynamic Neural Program Embeddings for Program Repair,Ke Wang;Rishabh Singh;Zhendong Su,kbwang@ucdavis.edu;risin@microsoft.com;su@cs.ucdavis.edu,6;7;7,2;3;4,Accept (Poster),0,8,0.0,yes,10/27/17,"University of California, Davis;Microsoft;University of California, Davis",Program Embedding;Program Semantics;Dynamic Traces,-1;-1;-1,54;-1;54,-1;-1,usa,usa,n,
625,ICLR,2018,Generating Natural Adversarial Examples,Zhengli Zhao;Dheeru Dua;Sameer Singh,zhengliz@uci.edu;ddua@uci.edu;sameer@uci.edu,6;7;6,3;4;3,Accept (Poster),3,5,0.0,yes,10/27/17,"University of California, Irvine;University of California, Irvine;University of California, Irvine",adversarial examples;generative adversarial networks;interpretability;image classification;textual entailment;machine translation,-1;-1;-1,99;99;99,-1;-1,usa,usa,n,3;5;4
626,ICLR,2018,mixup: Beyond Empirical Risk Minimization,Hongyi Zhang;Moustapha Cisse;Yann N. Dauphin;David Lopez-Paz,hongyiz@mit.edu;moustaphacisse@fb.com;ynd@fb.com;dlp@fb.com,6;7;6,4;4;4,Accept (Poster),1,6,0.0,yes,10/27/17,Massachusetts Institute of Technology;Facebook;Facebook;Facebook,empirical risk minimization;vicinal risk minimization;generalization;data augmentation;image classification;generative adversarial networks;adversarial examples;random labels,8;-1;-1;-1,5;-1;-1;-1,-1;-1,NAN,NAN,n,1;5;4
627,ICLR,2018,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,Will Grathwohl;Dami Choi;Yuhuai Wu;Geoff Roeder;David Duvenaud,wgrathwohl@cs.toronto.edu;choidami@cs.toronto.edu;ywu@cs.toronto.edu;roeder@cs.toronto.edu;duvenaud@cs.toronto.edu,8;7;6,4;3;2,Accept (Poster),0,11,0.0,yes,10/27/17,University of Toronto;University of Toronto;University of Toronto;University of Toronto;University of Toronto,optimization;machine learning;variational inference;reinforcement learning;gradient estimation;deep learning;discrete optimization,21;21;21;21;21,22;22;22;22;22,-1;-1,canada,ca,n,
628,ICLR,2018,"Don't Decay the Learning Rate, Increase the Batch Size",Samuel L. Smith;Pieter-Jan Kindermans;Chris Ying;Quoc V. Le,slsmith@google.com;pikinder@google.com;chrisying@google.com;qvl@google.com,6;7;6,4;4;4,Accept (Poster),2,6,0.0,yes,10/27/17,Google;Google;Google;Google,batch size;learning rate;simulated annealing;large batch training;scaling rules;stochastic gradient descent;sgd;imagenet;optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
629,ICLR,2018,Fidelity-Weighted Learning,Mostafa Dehghani;Arash Mehrjou;Stephan Gouws;Jaap Kamps;Bernhard Sch√∂lkopf,dehghani@uva.nl;amehrjou@tuebingen.mpg.de;sgouws@google.com;kamps@uva.nl;bs@tuebingen.mpg.de,7;5;6,4;4;3,Accept (Poster),0,8,0.0,yes,10/27/17,University of Amsterdam;Max-Planck Institute;Google;University of Amsterdam;Max-Planck Institute,fidelity-weighted learning;semisupervised learning;weakly-labeled data;teacher-student,125;-1;-1;125;-1,59;-1;-1;59;-1,-1;-1,NAN,NAN,n,3
630,ICLR,2018,Emergent Complexity via Multi-Agent Competition,Trapit Bansal;Jakub Pachocki;Szymon Sidor;Ilya Sutskever;Igor Mordatch,tbansal@cs.umass.edu;jakub@openai.com;szymon@openai.com;ilyasu@openai.com;mordatch@openai.com,3;9;7,3;5;4,Accept (Poster),0,5,0.0,yes,10/27/17,"University of Massachusetts, Amherst;OpenAI;OpenAI;OpenAI;OpenAI",multi-agent systems;multi-agent competition;self-play;deep reinforcement learning,21;-1;-1;-1;-1,191;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
631,ICLR,2018,A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks,Behnam Neyshabur;Srinadh Bhojanapalli;Nathan Srebro,bneyshabur@ttic.edu;srinadh@ttic.edu;nati@ttic.edu,9;6;7,4;3;4,Accept (Poster),0,0,0.0,yes,10/27/17,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,Neural Networks;Generalization;PAC-Bayes;Sharpness,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,1
632,ICLR,2018,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,Anubhav Ashok;Nicholas Rhinehart;Fares Beainy;Kris M. Kitani,anubhava@andrew.cmu.edu;nrhineha@cs.cmu.edu;fares.beainy@volvo.com;kkitani@cs.cmu.edu,5;9;4,4;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Volvo Trucks;Carnegie Mellon University,Deep learning;Neural networks;Model compression,1;1;-1;1,24;24;-1;24,-1;-1,usa,usa,n,6;2
633,ICLR,2018,AmbientGAN: Generative models from lossy measurements,Ashish Bora;Eric Price;Alexandros G. Dimakis,ashish.bora@utexas.edu;ecprice@cs.utexas.edu;dimakis@austin.utexas.edu,7;7;8,4;4;4,Accept (Oral),0,2,1.0,yes,10/27/17,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Generative models;Adversarial networks;Lossy measurements,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,y,5;4
634,ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Marlos C. Machado;Clemens Rosenbaum;Xiaoxiao Guo;Miao Liu;Gerald Tesauro;Murray Campbell,machado@ualberta.ca;crosenbaum@umass.edu;xiaoxiao.guo@ibm.com;miao.liu1@ibm.com;gtesauro@us.ibm.com;mcam@us.ibm.com,6;9;7,3;5;4,Accept (Poster),0,3,0.0,yes,10/27/17,"University of Alberta;University of Massachusetts, Amherst;International Business Machines;International Business Machines;International Business Machines;International Business Machines",reinforcement learning;options;successor representation;proto-value functions;Atari;Arcade Learning Environment,95;21;-1;-1;-1;-1,119;191;-1;-1;-1;-1,-1;-1,NAN,NAN,n,10
635,ICLR,2018,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,Sandeep Subramanian;Adam Trischler;Yoshua Bengio;Christopher J Pal,sandeep.subramanian.1@umontreal.ca;adam.trischler@microsoft.com;yoshua.umontreal@gmail.com;christopher.pal@polymtl.ca,8;8;4,5;5;5,Accept (Poster),1,15,0.0,yes,10/27/17,University of Montreal;Microsoft;University of Montreal;Polytechnique Montreal,distributed sentence representations;multi-task learning,125;-1;125;377,108;-1;108;-1,-1;-1,canada,ca,n,6;3
636,ICLR,2018,Communication Algorithms via Deep Learning,Hyeji Kim;Yihan Jiang;Ranvir B. Rana;Sreeram Kannan;Sewoong Oh;Pramod Viswanath,hyejikim@illinois.edu;yihanrogerjiang@gmail.com;rbrana2@illinois.edu;ksreeram@uw.edu;sewoong79@gmail.com;pramodv@illinois.edu,2;6;9,4;4;5,Accept (Poster),8,18,1.0,yes,10/27/17,"University of Illinois, Urbana Champaign;;University of Illinois, Urbana Champaign;University of Washington, Seattle;University of Washington;University of Illinois, Urbana Champaign",coding theory;recurrent neural network;communication,-1;-1;-1;8;8;-1,-1;-1;-1;25;25;-1,-1;-1,usa,usa,n,1
637,ICLR,2018,Variational Inference of Disentangled Latent Concepts from Unlabeled Observations,Abhishek Kumar;Prasanna Sattigeri;Avinash Balakrishnan,abhishk@us.ibm.com;psattig@us.ibm.com;avinash.bala@us.ibm.com,6;7;7,5;4;4,Accept (Poster),0,9,0.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines,disentangled representations;variational inference,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
638,ICLR,2018,Variational Message Passing with Structured Inference Networks,Wu Lin;Nicolas Hubacher;Mohammad Emtiyaz Khan,wlin2018@cs.ubc.ca;nicolas.hubacher@outlook.com;emtiyaz@gmail.com,7;7;7,3;4;2,Accept (Poster),0,6,0.0,yes,10/27/17,University of British Columbia;;RIKEN,Variational Inference;Variational Message Passing;Variational Auto-Encoder;Graphical Models;Structured Models;Natural Gradients,67;-1;-1,34;-1;-1,-1;-1,NAN,NAN,y,10;5
639,ICLR,2018,On the insufficiency of existing momentum schemes for Stochastic Optimization,Rahul Kidambi;Praneeth Netrapalli;Prateek Jain;Sham M. Kakade,rkidambi@uw.edu;praneeth@microsoft.com;prajain@microsoft.com;sham@cs.washington.edu,7;7;8,4;3;5,Accept (Oral),0,4,5.0,yes,10/27/17,"University of Washington, Seattle;Microsoft;Microsoft;University of Washington",Stochastic Gradient Descent;Deep Learning;Momentum;Acceleration;Heavy Ball;Nesterov Acceleration;Stochastic Optimization;SGD;Accelerated Stochastic Gradient Descent,8;-1;-1;8,25;-1;-1;25,-1;-1,usa,usa,y,1
640,ICLR,2018,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,Murat Kocaoglu;Christopher Snyder;Alexandros G. Dimakis;Sriram Vishwanath,mkocaoglu@utexas.edu;22csnyder@gmail.com;dimakis@austin.utexas.edu;sriram@austin.utexas.edu,6;7;9,3;3;3,Accept (Poster),0,5,2.0,yes,10/27/17,"University of Texas, Austin;University of Texas, Galveston;University of Texas, Austin;University of Texas, Austin",causality;structural causal models;GANs;conditional GANs;BEGAN;adversarial training,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,y,10;5;4
641,ICLR,2018,Unsupervised Neural Machine Translation,Mikel Artetxe;Gorka Labaka;Eneko Agirre;Kyunghyun Cho,mikel.artetxe@ehu.eus;gorka.labaka@ehu.eus;e.agirre@ehu.eus;kyunghyun.cho@nyu.edu,6;5;7,4;4;5,Accept (Poster),0,12,0.0,yes,10/27/17,University of the Basque Country;University of the Basque Country;University of the Basque Country;New York University,neural machine translation;unsupervised learning,-1;-1;-1;21,613;613;613;27,-1;-1,usa,usa,n,8;3
642,ICLR,2018,Understanding image motion with group representations ,Andrew Jaegle;Stephen Phillips;Daphne Ippolito;Kostas Daniilidis,ajaegle@upenn.edu;stephi@seas.upenn.edu;daphnei@seas.upenn.edu;kostas@seas.upenn.edu,7;5;4,3;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,vision;motion;recurrent neural networks;self-supervised learning;unsupervised learning;group theory,15;15;15;15,10;10;10;10,-1;-1,usa,usa,n,
643,ICLR,2018,Deep Learning with Logged Bandit Feedback,Thorsten Joachims;Adith Swaminathan;Maarten de Rijke,tj@cs.cornell.edu;adswamin@microsoft.com;derijke@uva.nl,7;8;6,4;3;3,Accept (Poster),0,6,0.0,yes,10/27/17,Cornell University;Microsoft;University of Amsterdam,Batch Learning from Bandit Feedback;Counterfactual Learning,5;-1;125,19;-1;59,-1;-1,europe,nl,y,
644,ICLR,2018,FearNet: Brain-Inspired Model for Incremental Learning,Ronald Kemker;Christopher Kanan,rmk6217@rit.edu;kanan@rit.edu,7;7;6,2;4;2,Accept (Poster),0,5,0.0,yes,10/27/17,Rochester Institute of Technology;Rochester Institute of Technology,Incremental Learning;Lifelong Learning;Supervised Learning;Catastrophic Forgetting;Brain-Inspired;Neural Networks,125;125,666;666,-1;-1,usa,usa,n,5
645,ICLR,2018,On the Discrimination-Generalization Tradeoff in GANs,Pengchuan Zhang;Qiang Liu;Dengyong Zhou;Tao Xu;Xiaodong He,penzhan@microsoft.com;qiang.liu@dartmouth.edu;dennyzhou@google.com;tax313@lehigh.edu;xiaohe@microsoft.com,6;3;7,4;4;4,Accept (Poster),0,9,0.0,yes,10/27/17,Microsoft;Dartmouth College;Google;Lehigh University;Microsoft,generative adversarial network;discrimination;generalization,-1;162;-1;224;-1,-1;89;-1;533;-1,-1;-1,NAN,NAN,y,1;5;4
646,ICLR,2018,Learning Latent Permutations with Gumbel-Sinkhorn Networks,Gonzalo Mena;David Belanger;Scott Linderman;Jasper Snoek,gem2131@columbia.edu;dbelanger@google.com;scott.linderman@gmail.com;jsnoek@google.com,8;7;6,4;4;2,Accept (Poster),0,6,0.0,yes,10/27/17,Columbia University;Google;Stanford University;Google,Permutation;Latent;Sinkhorn;Inference;Optimal Transport;Gumbel;Softmax;Sorting,21;-1;5;-1,14;-1;3;-1,-1;-1,NAN,NAN,y,
647,ICLR,2018,Towards Deep Learning Models Resistant to Adversarial Attacks,Aleksander Madry;Aleksandar Makelov;Ludwig Schmidt;Dimitris Tsipras;Adrian Vladu,madry@mit.edu;amakelov@mit.edu;ludwigs@mit.edu;tsipras@mit.edu;avladu@mit.edu,7;6;7,4;3;4,Accept (Poster),3,6,1.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial examples;robust optimization;ML security,8;8;8;8;8,5;5;5;5;5,-1;-1,usa,usa,n,4
648,ICLR,2018,Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking,Aleksandar Bojchevski;Stephan G√ºnnemann,a.bojchevski@in.tum.de;guennemann@in.tum.de,7;6;7,4;4;3,Accept (Poster),2,5,0.0,yes,10/27/17,Technical University Munich;Technical University Munich,node embeddings;graphs;unsupervised learning;inductive learning;uncertainty;deep learning,-1;-1,-1;-1,-1;-1,NAN,NAN,y,10
649,ICLR,2018,Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data,William Falcon;Henning Schulzrinne,waf2107@columbia.edu;hgs@cs.columbia.edu,6;7;6,4;5;3,Accept (Poster),0,14,1.0,yes,10/27/17,Columbia University;Columbia University,Recurrent Neural Networks;RNN;LSTM;Mobile Device;Sensors,21;21,14;14,-1;-1,usa,usa,n,
650,ICLR,2018,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,Kimin Lee;Honglak Lee;Kibok Lee;Jinwoo Shin,kiminlee@kaist.ac.kr;honglak@eecs.umich.edu;kibok@umich.edu;jinwoos@kaist.ac.kr,6;7;6,4;3;3,Accept (Poster),0,4,0.0,yes,10/27/17,Korea Advanced Institute of Science and Technology;University of Michigan;University of Michigan;Korea Advanced Institute of Science and Technology,,-1;10;10;-1,95;21;21;95,-1;-1,NAN,NAN,n,5
651,ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Christian Buck;Jannis Bulian;Massimiliano Ciaramita;Wojciech Gajewski;Andrea Gesmundo;Neil Houlsby;Wei Wang.,cbuck@google.com;jbulian@google.com;massi@google.com;wgaj@google.com;agesmundo@google.com;neilhoulsby@google.com;wangwe@google.com,7;6;8,5;4;3,Accept (Oral),0,5,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google,machine translation;paraphrasing;question answering;reinforcement learning;agents,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
652,ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Robert Torfason;Fabian Mentzer;Eirikur Agustsson;Michael Tschannen;Radu Timofte;Luc Van Gool,robertto@student.ethz.ch;mentzerf@vision.ee.ethz.ch;aeirikur@vision.ee.ethz.ch;michaelt@nari.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,6;9;6,4;5;3,Accept (Poster),0,3,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
653,ICLR,2018,The Implicit Bias of Gradient Descent on Separable Data,Daniel Soudry;Elad Hoffer;Mor Shpigel Nacson;Nathan Srebro,daniel.soudry@gmail.com;elad.hoffer@gmail.com;mor.shpigel@gmail.com;nati@ttic.edu,5;7;8,5;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,"Technion, Technion;Habana Labs (Intel);Technion, Technion;Toyota Technological Institute at Chicago",gradient descent;implicit regularization;generalization;margin;logistic regression;loss functions;optimization;exponential tail;cross-entropy,21;-1;21;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
654,ICLR,2018,Distributed Prioritized Experience Replay,Dan Horgan;John Quan;David Budden;Gabriel Barth-Maron;Matteo Hessel;Hado van Hasselt;David Silver,horgan@google.com;johnquan@google.com;budden@google.com;gabrielbm@google.com;mtthss@google.com;hado@google.com;davidsilver@google.com,9;7;6,4;4;3,Accept (Poster),0,6,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google,deep learning;reinforcement learning;distributed systems,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
655,ICLR,2018,Learning One-hidden-layer Neural Networks with Landscape Design,Rong Ge;Jason D. Lee;Tengyu Ma,rongge@cs.duke.edu;jasondlee88@gmail.com;tengyuma@cs.stanford.edu,6;9;7,3;3;3,Accept (Poster),0,4,1.0,yes,10/27/17,Duke University;Princeton University;Stanford University,theory;non-convex optimization;loss surface,39;30;5,17;7;3,-1;-1,usa,usa,y,1
656,ICLR,2018,Learning to cluster in order to transfer across domains and tasks,Yen-Chang Hsu;Zhaoyang Lv;Zsolt Kira,yenchang.hsu@gatech.edu;zhaoyang.lv@gatech.edu;zkira@gatech.edu,7;5;9,4;4;5,Accept (Poster),2,6,0.0,yes,10/20/17,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,transfer learning;similarity prediction;clustering;domain adaptation;unsupervised learning;computer vision;deep learning;constrained clustering,13;13;13,33;33;33,-1;-1,usa,usa,n,6
657,ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Dipankar Das;Naveen Mellempudi;Dheevatsa Mudigere;Dhiraj Kalamkar;Sasikanth Avancha;Kunal Banerjee;Srinivas Sridharan;Karthik Vaidyanathan;Bharat Kaul;Evangelos Georganas;Alexander Heinecke;Pradeep Dubey;Jesus Corbal;Nikita Shustrov;Roma Dubtsov;Evarist Fomenko;Vadim Pirogov,dipankar.das@intel.com;naveen.k.mellempudi@intel.com;dheevatsa.mudigere@intel.com;dhiraj.d.kalamkar@intel.com;sasikanth.avancha@intel.com;kunal.banerjee@intel.com;srinivas.sridharan@intel.com;karthikeyan.vaidyanathan@intel.com;bharat.kaul@intel.com;evangelos.georganas@intel.com;alexander.heinecke@intel.com;pradeep.dubey@intel.com;jesus.corbal@intel.com;nikita.a.shustrov@intel.com;roman.s.dubtsov@intel.com;evarist.m.fomenko@intel.com;vadim.o.pirogov@intel.com,7;7;6,4;3;3,Accept (Poster),0,4,0.0,yes,10/27/17,Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel;Intel,deep learning training;reduced precision;imagenet;dynamic fixed point,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
658,ICLR,2018,Generative networks as inverse problems with Scattering transforms,Tom√°s Angles;St√©phane Mallat,tomas.angles@ens.fr;stephane.mallat@ens.fr,7;8;6,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,Ecole Normale Superieure;Ecole Normale Superieure,Unsupervised Learning;Inverse Problems;Convolutional Networks;Generative Models;Scattering Transform,95;95,-1;-1,-1;-1,europe,fr,n,5;4
659,ICLR,2018,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,Feiwen Zhu;Jeff Pool;Michael Andersch;Jeremy Appleyard;Fung Xie,mzhu@nvidia.com;jpool@nvidia.com;mandersch@nvidia.com;jappleyard@nvidia.com;ftse@nvidia.com,6;6;6,2;4;2,Accept (Poster),0,5,0.0,yes,10/27/17,NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA,Sparsity;Pruning;Compression;RNN;LSTM;Persistent;RF-Resident;GPU,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
660,ICLR,2018,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,Seyed-Mohsen Moosavi-Dezfooli;Alhussein Fawzi;Omar Fawzi;Pascal Frossard;Stefano Soatto,seyed.moosavi@epfl.ch;fawzi@cs.ucla.edu;omar.fawzi@ens-lyon.fr;pascal.frossard@epfl.ch;soatto@cs.ucla.edu,6;5;7,4;3;3,Accept (Poster),0,3,0.0,yes,10/26/17,"Swiss Federal Institute of Technology Lausanne;University of California, Los Angeles;Ecole Normale Sup√©rieure de Lyon;Swiss Federal Institute of Technology Lausanne;University of California, Los Angeles",Universal perturbations;robustness;curvature,-1;-1;162;-1;-1,-1;15;182;-1;15,-1;-1,usa,usa,y,1
661,ICLR,2018,Deep Learning as a Mixed Convex-Combinatorial Optimization Problem,Abram L. Friesen;Pedro Domingos,afriesen@cs.washington.edu;pedrod@cs.washington.edu,7;7;7,4;4;3,Accept (Poster),0,2,0.0,yes,10/27/17,University of Washington;University of Washington,hard-threshold units;combinatorial optimization;target propagation;straight-through estimation;quantization,8;8,25;25,-1;-1,usa,usa,y,9
662,ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Maruan Al-Shedivat;Trapit Bansal;Yura Burda;Ilya Sutskever;Igor Mordatch;Pieter Abbeel,alshedivat@cs.cmu.edu;tbansal@cs.umass.edu;yburda@openai.com;ilyasu@openai.com;mordatch@openai.com;pabbeel@cs.berkeley.edu,8;7;9,4;4;2,Accept (Oral),0,4,3.0,yes,10/27/17,"Carnegie Mellon University;University of Massachusetts, Amherst;OpenAI;OpenAI;OpenAI;University of California Berkeley",reinforcement learning;nonstationarity;meta-learning;transfer learning;multi-agent,1;21;-1;-1;-1;-1,24;191;-1;-1;-1;18,-1;-1,usa,usa,n,6;4
663,ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Aidan N. Gomez;Sicong Huang;Ivan Zhang;Bryan M. Li;Muhammad Osama;Lukasz Kaiser,aidan.n.gomez@gmail.com;huang@cs.toronto.edu;ivan@for.ai;bryan@for.ai;osama@for.ai;lukaszkaiser@google.com,7;7;8,4;1;4,Accept (Poster),0,5,0.0,yes,10/27/17,University of Toronto;University of Toronto;;University of Edinburgh;;Google,,-1;21;-1;30;-1;-1,-1;22;-1;27;-1;-1,-1;-1,NAN,NAN,y,1;5
664,ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Arthur Szlam;Rob Fergus,sainbar@cs.nyu.edu;zlin@fb.com;kostrikov@cs.nyu.edu;gab@fb.com;aszlam@fb.com;fergus@cs.nyu.edu,8;5;8,4;3;4,Accept (Poster),0,2,0.0,yes,10/27/17,New York University;Facebook;New York University;Facebook;Facebook;New York University,self-play;automatic curriculum;intrinsic motivation;unsupervised learning;reinforcement learning,21;-1;21;-1;-1;21,27;-1;27;-1;-1;27,-1;-1,usa,usa,n,
665,ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Zhilin Yang;Saizheng Zhang;Jack Urbanek;Will Feng;Alexander Miller;Arthur Szlam;Douwe Kiela;Jason Weston,zhiliny@cs.cmu.edu;saizheng.zhang@umontreal.ca;jju@fb.com;willfeng@fb.com;ahm@fb.com;aszlam@fb.com;dkiela@fb.com;jase@fb.com,7;7;8,4;4;5,Accept (Poster),0,4,0.0,yes,10/27/17,Carnegie Mellon University;University of Montreal;Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,,1;125;-1;-1;-1;-1;-1;-1,24;108;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
666,ICLR,2018,Gradient Estimators for Implicit Models,Yingzhen Li;Richard E. Turner,yl494@cam.ac.uk;ret26@cam.ac.uk,7;7;6,2;4;2,Accept (Poster),1,9,1.0,yes,10/27/17,University of Cambridge;University of Cambridge,Implicit Models;Approximate Inference;Deep Learning,82;82,2;2,-1;-1,europe,uk,n,6;5;4
667,ICLR,2018, Neural Map: Structured Memory for Deep Reinforcement Learning,Emilio Parisotto;Ruslan Salakhutdinov,eparisot@andrew.cmu.edu;rsalakhu@cs.cmu.edu,7;9;6,4;5;5,Accept (Poster),0,9,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University,deep reinforcement learning;deep learning;memory,1;1,24;24,-1;-1,usa,usa,n,
668,ICLR,2018,Memory-based Parameter Adaptation,Pablo Sprechmann;Siddhant M. Jayakumar;Jack W. Rae;Alexander Pritzel;Adria Puigdomenech Badia;Benigno Uria;Oriol Vinyals;Demis Hassabis;Razvan Pascanu;Charles Blundell,psprechmann@google.com;sidmj@google.com;jwrae@google.com;apritzel@google.com;adriap@google.com;buria@google.com;vinyals@google.com;dhcontact@google.com;razp@google.com;cblundell@google.com,6;6;8,4;5;4,Accept (Poster),1,13,1.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
669,ICLR,2018,Model compression via distillation and quantization,Antonio Polino;Razvan Pascanu;Dan Alistarh,antonio.polino1@gmail.com;razp@google.com;d.alistarh@gmail.com,7;6;8,2;4;5,Accept (Poster),0,13,3.0,yes,10/27/17,ETH Zurich;Google;Institute of Science and Technology Austria,quantization;distillation;model compression,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8
670,ICLR,2018,Learning Wasserstein Embeddings,Nicolas Courty;R√©mi Flamary;M√©lanie Ducoffe,ncourty@irisa.fr;remi.flamary@unice.fr;ducoffe@i3s.unice.fr,7;7;7,3;3;4,Accept (Poster),0,10,0.0,yes,10/26/17,IRISA;Universit√© C√¥te d'Azur;Universit√© C√¥te d'Azur,Wasserstein distance;metric embedding;Siamese architecture,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8;5
671,ICLR,2018,Loss-aware Weight Quantization of Deep Networks,Lu Hou;James T. Kwok,lhouab@cse.ust.hk;jamesk@cse.ust.hk,8;6;6,3;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,deep learning;network quantization,-1;-1,44;44,-1;-1,NAN,NAN,y,
672,ICLR,2018,Kernel Implicit Variational Inference,Jiaxin Shi;Shengyang Sun;Jun Zhu,shijx15@mails.tsinghua.edu.cn;ssy@cs.toronto.edu;dcszj@tsinghua.edu.cn,5;7;7,4;3;4,Accept (Poster),0,7,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;University of Toronto;Tsinghua University, Tsinghua University",Variational inference;Bayesian neural networks;Implicit distribution,5;21;5,30;22;30,-1;-1,NAN,NAN,y,8;11
673,ICLR,2018,Adversarial Dropout Regularization,Kuniaki Saito;Yoshitaka Ushiku;Tatsuya Harada;Kate Saenko,k-saito@mi.t.u-tokyo.ac.jp;ushiku@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp;saenko@bu.edu,5;7;8,4;3;5,Accept (Poster),0,11,0.0,yes,10/27/17,The University of Tokyo;The University of Tokyo;The University of Tokyo;Boston University,domain adaptation;computer vision;generative models,57;57;57;82,45;45;45;70,-1;-1,europe,it,n,2;4
674,ICLR,2018,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization,Adam C. Earle;Andrew M. Saxe;Benjamin Rosman,adam.earle@ymail.com;asaxe@fas.harvard.edu;benjros@gmail.com,6;5;7,2;2;3,Accept (Poster),0,5,0.0,yes,10/27/17,University of the Witwatersrand;Harvard University;University of the Witwatersrand,Reinforcement Learning;Hierarchy;Subtask Discovery;Linear Markov Decision Process,-1;49;-1,-1;6;293,-1;-1,NAN,NAN,n,
675,ICLR,2018,A Scalable Laplace Approximation for Neural Networks,Hippolyt Ritter;Aleksandar Botev;David Barber,j.ritter@cs.ucl.ac.uk;botevmg@gmail.com;d.barber@cs.ucl.ac.uk,9;6;6,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,University College London;DeepMind;University College London,deep learning;neural networks;laplace approximation;bayesian deep learning,49;-1;49,-1;-1;-1,-1;-1,europe,uk,n,4
676,ICLR,2018,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,Gregory Farquhar;Tim Rockt√§schel;Maximilian Igl;Shimon Whiteson,gregory.farquhar@cs.ox.ac.uk;tim.rocktaeschel@gmail.com;maximilian.igl@gmail.com;shimon.whiteson@gmail.com,4;8;5,5;5;3,Accept (Poster),3,5,0.0,yes,10/27/17,University of Oxford;Facebook AI Research;;University of Oxford,reinforcement learning;deep learning;planning,39;-1;-1;39,1;-1;-1;1,-1;-1,europe,uk,n,
677,ICLR,2018,Training wide residual networks for deployment using a single bit for each weight,Mark D. McDonnell,mark.mcdonnell@unisa.edu.au,6;6;6,4;3;4,Accept (Poster),0,8,0.0,yes,10/26/17,University of South Australia,wide residual networks;model compression;quantization;1-bit weights,-1,248,-1,NAN,NAN,n,
678,ICLR,2018,Can Neural Networks Understand Logical Entailment?,Richard Evans;David Saxton;David Amos;Pushmeet Kohli;Edward Grefenstette,richardevans@google.com;saxton@google.com;davidamos@google.com;pushmeet@google.com;etg@google.com,7;7;4,3;3;4,Accept (Poster),6,3,0.0,yes,10/27/17,Google;Google;Google;Google;Google,structure;neural networks;logic;dataset,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
679,ICLR,2018,Learning Sparse Neural Networks through L_0 Regularization,Christos Louizos;Max Welling;Diederik P. Kingma,c.louizos@uva.nl;m.welling@uva.nl;dpkingma@openai.com,6;6;7,3;3;4,Accept (Poster),0,5,0.0,yes,10/27/17,University of Amsterdam;University of Amsterdam;OpenAI,Sparsity;compression;hard and soft attention.,125;125;-1,59;59;-1,-1;-1,NAN,NAN,n,1
680,ICLR,2018,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,Alexandre P√©r√©;S√©bastien Forestier;Olivier Sigaud;Pierre-Yves Oudeyer,alexandre.pere@inria.fr;sebastien.forestier@inria.fr;olivier.sigaud@upmc.fr;pierre-yves.oudeyer@inria.fr,7;6;7,4;2;4,Accept (Poster),0,6,0.0,yes,10/26/17,"INRIA;INRIA;Computer Science Lab  - Pierre and Marie Curie University, Paris, France;INRIA",exploration; autonomous goal setting; diversity; unsupervised learning; deep neural network,-1;-1;-1;-1,-1;-1;123;-1,-1;-1,europe,gr,n,
681,ICLR,2018,Learning From Noisy Singly-labeled Data,Ashish Khetan;Zachary C. Lipton;Animashree Anandkumar,khetan2@illinois.edu;zlipton@cmu.edu;anima@amazon.com,7;6;7,4;3;4,Accept (Poster),0,8,1.0,yes,10/27/17,"University of Illinois, Urbana Champaign;Carnegie Mellon University;Amazon",crowdsourcing;noisy annotations;deep leaerning,-1;1;-1,-1;24;-1,-1;-1,NAN,NAN,y,1
682,ICLR,2018,SEARNN: Training RNNs with global-local losses,R√©mi Leblond;Jean-Baptiste Alayrac;Anton Osokin;Simon Lacoste-Julien,remi.leblond@inria.fr;jean-baptiste.alayrac@inria.fr;aosokin@hse.ru;slacoste@iro.umontreal.ca,8;5;7,4;5;3,Accept (Poster),0,12,0.0,yes,10/27/17,INRIA;INRIA;Higher School of Economics;University of Montreal,Structured prediction;RNNs,-1;-1;-1;125,-1;-1;-1;108,-1;-1,canada,ca,n,3
683,ICLR,2018,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",Tero Karras;Timo Aila;Samuli Laine;Jaakko Lehtinen,tkarras@nvidia.com;taila@nvidia.com;slaine@nvidia.com;jlehtinen@nvidia.com,8;1;8,4;4;4,Accept (Oral),2,5,4.0,yes,10/27/17,NVIDIA;NVIDIA;NVIDIA;NVIDIA,generative adversarial networks;unsupervised learning;hierarchical methods,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
684,ICLR,2018,Graph Attention Networks,Petar Veliƒçkoviƒá;Guillem Cucurull;Arantxa Casanova;Adriana Romero;Pietro Li√≤;Yoshua Bengio,petar.velickovic@cst.cam.ac.uk;gcucurull@gmail.com;ar.casanova.8@gmail.com;adriana.romsor@gmail.com;pietro.lio@cst.cam.ac.uk;yoshua.umontreal@gmail.com,6;7;5,4;5;4,Accept (Poster),13,5,0.0,yes,10/26/17,University of Cambridge;Blue Prism;Polytechnique Montreal;Facebook;University of Cambridge;University of Montreal,Deep Learning;Graph Convolutions;Attention;Self-Attention,82;-1;377;-1;82;125,2;-1;-1;-1;2;108,-1;-1,canada,ca,n,8;10
685,ICLR,2018,i-RevNet: Deep Invertible Networks,J√∂rn-Henrik Jacobsen;Arnold W.M. Smeulders;Edouard Oyallon,joern.jacobsen@bethgelab.org;a.w.m.smeulders@uva.nl;edouard.oyallon@ens.fr,8;9;8,4;4;4,Accept (Poster),0,9,7.0,yes,10/27/17,"Centre for Integrative Neuroscience, AG Bethge;University of Amsterdam;Ecole Normale Superieure",,-1;125;95,-1;59;-1,-1;-1,europe,fr,n,
686,ICLR,2018,On the regularization of Wasserstein GANs,Henning Petzka;Asja Fischer;Denis Lukovnikov,henning.petzka@iais.fraunhofer.de;asja.fischer@gmail.com;lukovnik@cs.uni-bonn.de,7;2;6,4;2;5,Accept (Poster),0,8,0.0,yes,10/27/17,Fraunhofer IIS;Institute for Cognitive Neuroscience/ Inst. for Neuroinformatics;University of Bonn,,-1;-1;125,-1;-1;100,-1;-1,europe,uk,y,5;4
687,ICLR,2018,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks,Krzysztof Choromanski;Carlton Downey;Byron Boots,kchoro@google.com;cmdowney@cs.cmu.edu;bboots@cc.gatech.edu,4;8;7,5;4;2,Accept (Poster),0,0,0.0,yes,10/27/17,Google;Carnegie Mellon University;Georgia Institute of Technology,recurrent neural networks;orthogonal random features;predictive state representations,-1;1;13,-1;24;33,-1;-1,usa,usa,y,3;1
688,ICLR,2018,Adaptive Quantization of Neural Networks,Soroosh Khoram;Jing Li,khoram@wisc.edu;jli@ece.wisc.edu,6;6;6,4;4;3,Accept (Poster),0,4,1.0,yes,10/27/17,University of Southern California;University of Southern California,Deep Neural Networks;Model Quantization;Model Compression,27;27,66;66,-1;-1,usa,usa,n,
689,ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Vivien Seguy;Bharath Bhushan Damodaran;Remi Flamary;Nicolas Courty;Antoine Rolet;Mathieu Blondel,vivienseguy@gmail.com;bharath-bhushan.damodaran@irisa.fr;remi.flamary@unice.fr;courty@univ-ubs.fr;antoine.rolet@iip.ist.i.kyoto-u.ac.jp;mblondel@gmail.com,7;6;6;8,3;3;3;3,Accept (Poster),0,8,1.0,yes,10/27/17,Kyoto University;IRISA;Universit√© C√¥te d'Azur;University of Bretagne Sud;Kyoto University;Google,optimal transport;Wasserstein;domain adaptation;generative models;Monge map;optimal mapping,-1;-1;-1;-1;162;-1,-1;-1;-1;-1;74;-1,-1;-1,NAN,NAN,y,1;5
690,ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Shiv Shankar*;Vihari Piratla*;Soumen Chakrabarti;Siddhartha Chaudhuri;Preethi Jyothi;Sunita Sarawagi,shivshankariitb@gmail.com;viharipiratla@gmail.com;soumen@cse.iitb.ac.in;sidch@cse.iitb.ac.in;pjyothi@cse.iitb.ac.in;sunita@iitb.ac.in,7;7;8;7,5;4;4;5,Accept (Poster),0,7,0.0,yes,10/27/17,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay,domain generalization;domain adaptation;adversarial learning;adversarial examples,-1;-1;-1;-1;-1;-1,367;367;367;367;367;367,-1;-1,NAN,NAN,n,11;1;4
691,ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,Hao Liu*;Yihao Feng*;Yi Mao;Dengyong Zhou;Jian Peng;Qiang Liu,uestcliuhao@gmail.com;yihao@cs.utexas.edu;maoyi@microsoft.com;dennyzhou@google.com;jianpeng@illinois.edu;lqiang@cs.utexas.edu,7;7;7,3;3;4,Accept (Poster),3,9,1.0,yes,10/27/17,"University of Electronic Science and Technology of China;University of Texas, Austin;Microsoft;Google;University of Illinois, Urbana Champaign;University of Texas, Austin",reinforcement learning;control variates;sample efficiency;variance reduction,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,usa,usa,y,
692,ICLR,2018,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,Tao Shen;Tianyi Zhou;Guodong Long;Jing Jiang;Chengqi Zhang,tao.shen@student.uts.edu.au;tianyizh@uw.edu;guodong.long@uts.edu.au;jing.jiang@uts.edu.au;chengqi.zhang@uts.edu.au,6;9;6,4;4;4,Accept (Poster),0,7,3.0,yes,10/27/17,"University of Technology Sydney;University of Washington, Seattle;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney",deep learning;attention mechanism;sequence modeling;natural language processing;sentence embedding,67;8;67;67;67,216;25;216;216;216,-1;-1,australasia,au,n,8;3
693,ICLR,2018,Generalizing Hamiltonian Monte Carlo with Neural Networks,Daniel Levy;Matt D. Hoffman;Jascha Sohl-Dickstein,danilevy@cs.stanford.edu;mhoffman@google.com;jaschasd@google.com,7;6;8,4;3;2,Accept (Poster),0,13,0.0,yes,10/26/17,Stanford University;Google;Google,markov;chain;monte;carlo;sampling;posterior;deep;learning;hamiltonian;mcmc,5;-1;-1,3;-1;-1,-1;-1,NAN,NAN,n,5
694,ICLR,2018,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs,W. James Murdoch;Peter J. Liu;Bin Yu,jmurdoch@berkeley.edu;peterjliu@google.com;binyu@berkeley.edu,7;7;7,3;4;2,Accept (Oral),0,8,1.0,yes,10/27/17,University of California Berkeley;Google;University of California Berkeley,interpretability;LSTM;natural language processing;sentiment analysis;interactions,-1;-1;-1,18;-1;18,-1;-1,usa,usa,n,
695,ICLR,2018,Temporally Efficient Deep Learning with Spikes,Peter O'Connor;Efstratios Gavves;Matthias Reisser;Max Welling,peter.ed.oconnor@gmail.com;e.gavves@uva.nl;reisser.matthias@gmail.com;m.welling@uva.nl,7;6;8,5;4;4,Accept (Poster),0,1,1.0,yes,10/27/17,"University of Amsterdam;University of Amsterdam;Qualcomm Inc, QualComm;University of Amsterdam",online learning;spiking networks;deep learning;temporal,-1;125;-1;125,-1;59;-1;59,-1;-1,europe,nl,n,
696,ICLR,2018,Learning Deep Mean Field Games for Modeling Large Population Behavior,Jiachen Yang;Xiaojing Ye;Rakshit Trivedi;Huan Xu;Hongyuan Zha,yjiachen@gmail.com;xye@gsu.edu;rstrivedi@gatech.edu;huan.xu@isye.gatech.edu;zha@cc.gatech.edu,8;8;10,4;3;5,Accept (Oral),0,6,0.0,yes,10/27/17,Georgia Institute of Technology;SUN YAT-SEN UNIVERSITY;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,mean field games;reinforcement learning;Markov decision processes;inverse reinforcement learning;deep learning;inverse optimal control;computational social science;population modeling,13;-1;13;13;13,33;352;33;33;33,-1;-1,usa,usa,n,1
697,ICLR,2018,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,Pouya Samangouei;Maya Kabkab;Rama Chellappa,pouya@umiacs.umd.edu;mayak@umiacs.umd.edu;rama@umiacs.umd.edu,6;6;8,3;3;4,Accept (Poster),1,12,0.0,yes,10/27/17,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",,12;12;12,69;69;69,-1;-1,usa,usa,y,5;4
698,ICLR,2018,Learning from Between-class Examples for Deep Sound Recognition,Yuji Tokozume;Yoshitaka Ushiku;Tatsuya Harada,tokozume@mi.t.u-tokyo.ac.jp;ushiku@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,9;4;8,4;4;4,Accept (Poster),0,9,2.0,yes,10/27/17,The University of Tokyo;The University of Tokyo;The University of Tokyo,sound recognition;supervised learning;feature learning,57;57;57,45;45;45,-1;-1,NAN,NAN,n,
699,ICLR,2018,META LEARNING SHARED HIERARCHIES,Kevin Frans;Jonathan Ho;Xi Chen;Pieter Abbeel;John Schulman,kevinfrans2@gmail.com;jonathanho@berkeley.edu;c.xi@eecs.berkeley.edu;pabbeel@cs.berkeley.edu;joschu@openai.com,6;4;7,3;4;3,Accept (Poster),0,13,0.0,yes,10/27/17,OpenAI;University of California Berkeley;University of California Berkeley;University of California Berkeley;OpenAI,hierarchal reinforcement learning;meta-learning,-1;-1;-1;-1;-1,-1;18;18;18;-1,-1;-1,NAN,NAN,n,
700,ICLR,2018,Stochastic Variational Video Prediction,Mohammad Babaeizadeh;Chelsea Finn;Dumitru Erhan;Roy H. Campbell;Sergey Levine,mb2@uiuc.edu;cbfinn@eecs.berkeley.edu;dumitru@google.com;rhc@illinois.edu;svlevine@eecs.berkeley.edu,7;7;7,5;4;4,Accept (Poster),0,9,0.0,yes,10/27/17,"University of Illinois, Urbana-Champaign;University of California Berkeley;Google;University of Illinois, Urbana Champaign;University of California Berkeley",video prediction;stochastic prediction;variational inference;unsupervised learning,-1;-1;-1;-1;-1,-1;18;-1;-1;18,-1;-1,usa,usa,n,
701,ICLR,2018,An efficient framework for learning sentence representations,Lajanugen Logeswaran;Honglak Lee,llajan@umich.edu;honglak@eecs.umich.edu,6;8;6,5;4;4,Accept (Poster),8,2,1.0,yes,10/27/17,University of Michigan;University of Michigan,sentence;embeddings;unsupervised;representations;learning;efficient,10;10,21;21,-1;-1,usa,usa,n,3
702,ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Tsui-Wei Weng*;Huan Zhang*;Pin-Yu Chen;Jinfeng Yi;Dong Su;Yupeng Gao;Cho-Jui Hsieh;Luca Daniel,twweng@mit.edu;ecezhang@ucdavis.edu;pin-yu.chen@ibm.com;jinfengyi.ustc@gmail.com;dong.su@ibm.com;yupeng.gao@ibm.com;chohsieh@ucdavis.edu;dluca@mit.edu,7;7;7,3;3;1,Accept (Poster),0,7,2.0,yes,10/27/17,"Massachusetts Institute of Technology;University of California, Davis;International Business Machines;JD AI Research;International Business Machines;International Business Machines;University of California, Davis;Massachusetts Institute of Technology",robustness;adversarial machine learning;neural network;extreme value theory;adversarial example;adversarial perturbation,8;-1;-1;-1;-1;-1;-1;8,5;54;-1;-1;-1;-1;54;5,-1;-1,usa,usa,y,8;1;4
703,ICLR,2018,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,Jacob Buckman;Aurko Roy;Colin Raffel;Ian Goodfellow,buckman@google.com;aurkor@google.com;craffel@google.com;goodfellow@google.com,6;6;6,2;4;4,Accept (Poster),3,4,0.0,yes,10/27/17,Google;Google;Google;Google,Adversarial examples;robust neural networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;4
704,ICLR,2018,Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings,Kangwook Lee;Hoon Kim;Changho Suh,kw1jjang@gmail.com;gnsrla12@kaist.ac.kr;chsuh@kaist.ac.kr,6;6;3,3;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,University of Southern California;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,27;-1;-1,66;95;95,-1;-1,NAN,NAN,n,
705,ICLR,2018,Interpretable Counting for Visual Question Answering,Alexander Trott;Caiming Xiong;Richard Socher,atrott@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,6;7;7,3;4;4,Accept (Poster),0,5,1.0,yes,10/27/17,SalesForce.com;SalesForce.com;SalesForce.com,Counting;VQA;Object detection,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
706,ICLR,2018,Hierarchical Representations for Efficient Architecture Search,Hanxiao Liu;Karen Simonyan;Oriol Vinyals;Chrisantha Fernando;Koray Kavukcuoglu,hanxiaol@cs.cmu.edu;simonyan@google.com;vinyals@google.com;chrisantha@google.com;korayk@google.com,6;6;8,3;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,Carnegie Mellon University;Google;Google;Google;Google,deep learning;architecture search,1;-1;-1;-1;-1,24;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
707,ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Gao Huang;Danlu Chen;Tianhong Li;Felix Wu;Laurens van der Maaten;Kilian Weinberger,gh349@cornell.edu;taineleau@gmail.com;lth14@mails.tsinghua.edu.cn;fw245@cornell.edu;lvdmaaten@fb.com;kqw4@cornell.edu,8;7;10,4;4;4,Accept (Oral),0,3,2.0,yes,10/27/17,"Cornell University;;Tsinghua University, Tsinghua University;Cornell University;Facebook;Cornell University",efficient learning;budgeted learning;deep learning;image classification;convolutional networks,5;-1;5;5;-1;5,19;-1;30;19;-1;19,-1;-1,usa,usa,n,
708,ICLR,2018,Sobolev GAN,Youssef Mroueh;Chun-Liang Li;Tom Sercu;Anant Raj;Yu Cheng,mroueh@us.ibm.com;chunlial@cs.cmu.edu;tom.sercu1@ibm.com;anant.raj@tuebingen.mpg.de;chengyu@us.ibm.com,8;6;6;7,4;3;4;3,Accept (Poster),0,16,0.0,yes,10/27/17,International Business Machines;Carnegie Mellon University;International Business Machines;Max-Planck Institute;International Business Machines,GAN theory;Integral Probability Metrics;elliptic PDE and diffusion;GAN for discrete sequences;semi-supervised learning.,-1;1;-1;-1;-1,-1;24;-1;-1;-1,-1;-1,NAN,NAN,y,5;4
709,ICLR,2018,Compositional Attention Networks for Machine Reasoning,Drew A. Hudson;Christopher D. Manning,dorarad@cs.stanford.edu;manning@cs.stanford.edu,7;7;6,4;3;4,Accept (Poster),3,7,1.0,yes,10/27/17,Stanford University;Stanford University,Deep Learning;Reasoning;Memory;Attention;VQA;CLEVR;Recurrent Neural Networks;Module Networks;Compositionality,5;5,3;3,-1;-1,usa,usa,n,8;1
710,ICLR,2018,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering,Caiming Xiong;Victor Zhong;Richard Socher,cxiong@salesforce.com;richard@socher.org;victor@victorzhong.com,7;6;8,4;4;2,Accept (Poster),1,13,0.0,yes,10/27/17,SalesForce.com;SalesForce.com;University of Washington,question answering;deep learning;natural language processing;reinforcement learning,-1;-1;8,-1;-1;25,-1;-1,usa,usa,n,8
711,ICLR,2018,Empirical Risk Landscape Analysis for Understanding Deep Neural Networks,Pan Zhou;Jiashi Feng,pzhou@u.nus.edu;elefjia@nus.edu.sg;panzhou3@gmail.com,3;7;7,3;3;3,Accept (Poster),0,3,0.0,yes,10/23/17,National University of Singapore;National University of Singapore,Deep Learning Analysis;Deep Learning Theory;Empirical Risk;Landscape Analysis;Nonconvex Optimization,15;15;-1,22;22;-1,-1;-1,asia,in,y,1;9
712,ICLR,2018,Monotonic Chunkwise Attention,Chung-Cheng Chiu*;Colin Raffel*,chungchengc@google.com;craffel@gmail.com,7;6;8,5;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,Google;Google,attention;sequence-to-sequence;speech recognition;document summarization,-1;-1,-1;-1,-1;-1,asia,in,n,8
713,ICLR,2018,Compressing Word Embeddings via Deep Compositional Code Learning,Raphael Shu;Hideki Nakayama,shu@nlab.ci.i.u-tokyo.ac.jp;nakayama@ci.i.u-tokyo.ac.jp,8;6;7,4;4;4,Accept (Poster),0,8,0.0,yes,10/27/17,The University of Tokyo;The University of Tokyo,natural language processing;word embedding;compression;deep learning,57;57,45;45,-1;-1,NAN,NAN,n,2;3
714,ICLR,2018,A Framework for the Quantitative Evaluation of Disentangled Representations,Cian Eastwood;Christopher K. I. Williams,s1668298@ed.ac.uk;ckiw@inf.ed.ac.uk,7;6;6,5;5;4,Accept (Poster),0,4,0.0,yes,10/27/17,University of Edinburgh;University of Edinburgh,,30;30,27;27,-1;-1,europe,uk,n,
715,ICLR,2018,Adaptive Dropout with Rademacher Complexity Regularization,Ke Zhai;Huan Wang,zhaikedavy@gmail.com;joyousprince@gmail.com,6;6;7,3;3;5,Accept (Poster),0,17,1.0,yes,10/26/17,Microsoft;Salesforce Research,model complexity;regularization;deep learning;model generalization;adaptive dropout,-1;-1,-1;-1,-1;-1,asia,in,y,1
716,ICLR,2018,An Online Learning Approach to Generative Adversarial Networks,Paulina Grnarova;Kfir Y Levy;Aurelien Lucchi;Thomas Hofmann;Andreas Krause,paulina.grnarova@inf.ethz.ch;yehuda.levy@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch;thomas.hofmann@inf.ethz.ch;krausea@ethz.ch,7;8;5,4;5;4,Accept (Poster),0,8,0.0,yes,10/26/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Generative Adversarial Networks;GANs;online learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;5;4
717,ICLR,2018,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning,Justin Fu;Katie Luo;Sergey Levine,justinjfu@eecs.berkeley.edu;katieluo@berkeley.edu;svlevine@eecs.berkeley.edu,6;6;7,4;2;3,Accept (Poster),4,11,1.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley,inverse reinforcement learning;deep reinforcement learning,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,4
718,ICLR,2018,Variational Network Quantization,Jan Achterhold;Jan Mathias Koehler;Anke Schmeink;Tim Genewein,mail@janachterhold.de;jan.koehler@de.bosch.com;anke.schmeink@rwth-aachen.de;tim.genewein@gmail.com,7;7;7,5;4;3,Accept (Poster),1,5,1.0,yes,10/27/17,Max-Planck Institute;Bosch;RWTH Aachen University;Google,Network compression;variational inferene;ternary network;Bayesian neural network;weight quantization;weight sharing,-1;-1;125;-1,-1;367;79;-1,-1;-1,NAN,NAN,n,11
719,ICLR,2018,Identifying Analogies Across Domains,Yedid Hoshen;Lior Wolf,yedidh@fb.com;wolf@fb.com,7;5;4,4;4;3,Accept (Poster),0,8,0.0,yes,10/27/17,Facebook;Facebook,unsupervised mapping;cross domain mapping,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
720,ICLR,2018,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,Xiang Wei;Boqing Gong;Zixia Liu;Wei Lu;Liqiang Wang,yqweixiang@knights.ucf.edu;boqinggo@outlook.com;zixia@knights.ucf.edu;luwei@bjtu.edu.cn;lwang@cs.ucf.edu,4;6;7,4;5;4,Accept (Poster),16,11,0.0,yes,10/27/17,University of Central Florida;International Computer Science Institute;University of Central Florida;Beijing Jiaotong University;University of Central Florida,GAN;WGAN,67;-1;67;-1;67,-1;-1;-1;854;-1,-1;-1,usa,usa,n,5;4
721,ICLR,2018,Unbiased Online Recurrent Optimization,Corentin Tallec;Yann Ollivier,corentin.tallec@polytechnique.edu;yann@yann-ollivier.org,6;7;8,4;4;5,Accept (Poster),0,5,0.0,yes,10/27/17,Ecole polytechnique;Facebook,RNN,-1;-1,115;-1,-1;-1,NAN,NAN,n,1;10
722,ICLR,2018,Can recurrent neural networks warp time?,Corentin Tallec;Yann Ollivier,corentin.tallec@polytechnique.edu;yol@fb.com,8;8;8,4;4;4,Accept (Poster),0,9,0.0,yes,10/27/17,Ecole polytechnique;Facebook,RNN,-1;-1,115;-1,-1;-1,NAN,NAN,n,1
723,ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Dmitriy Serdyuk;Nan Rosemary Ke;Alessandro Sordoni;Adam Trischler;Chris Pal;Yoshua Bengio,serdyuk.dmitriy@gmail.com;rosemary.nan.ke@gmail.com;alessandro.sordoni@gmail.com;adam.trischler@microsoft.com;chris.j.pal@gmail.com;yoshua.umontreal@gmail.com,6;7;8,4;4;4,Accept (Poster),0,10,0.0,yes,10/27/17,Google;;Microsoft;Microsoft;Polytechnique Montreal;University of Montreal,generative rnns;long term dependencies;speech recognition;image captioning,-1;-1;-1;-1;377;125,-1;-1;-1;-1;-1;108,-1;-1,canada,ca,n,5
724,ICLR,2018,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,Chris Donahue;Zachary C. Lipton;Akshay Balsubramani;Julian McAuley,cdonahue@ucsd.edu;zlipton@cmu.edu;abalsubr@stanford.edu;jmcauley@cs.ucsd.edu,6;6;7,4;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,"University of California, San Diego;Carnegie Mellon University;Stanford University;University of California, San Diego",disentangled representations;generative adversarial networks;generative modeling;image synthesis,-1;1;5;-1,31;24;3;31,-1;-1,usa,usa,n,5;4
725,ICLR,2018,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,Yaguang Li;Rose Yu;Cyrus Shahabi;Yan Liu,yaguang@usc.edu;rose@caltech.edu;shahabi@usc.edu;yanliu.cs@usc.edu,5;4;9,3;5;5,Accept (Poster),0,4,1.0,yes,10/27/17,University of Southern California;California Institute of Technology;University of Southern California;University of Southern California,Traffic prediction;spatiotemporal forecasting;diffusion;graph convolution;random walk;long-term forecasting,27;125;27;27,66;3;66;66,-1;-1,usa,usa,n,10
726,ICLR,2018,PixelNN: Example-based Image Synthesis,Aayush Bansal;Yaser Sheikh;Deva Ramanan,aayushb@cs.cmu.edu;yaser@cs.cmu.edu;deva@cs.cmu.edu,8;6;7,4;4;3,Accept (Poster),0,3,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,conditional image synthesis;nearest neighbors,1;1;1,24;24;24,-1;-1,usa,usa,n,5
727,ICLR,2018,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,Jianbo Ye;Xin Lu;Zhe Lin;James Z. Wang,jxy198@ist.psu.edu;xinl@adobe.com;zlin@adobe.com;jwang@ist.psu.edu,5;7;6,5;3;5,Accept (Poster),0,6,1.0,yes,10/25/17,Pennsylvania State University;Adobe Systems;Adobe Systems;Pennsylvania State University,model pruning;batch normalization;convolutional neural network;ISTA,39;-1;-1;39,-1;-1;-1;-1,-1;-1,usa,usa,n,10
728,ICLR,2018,A Deep Reinforced Model for Abstractive Summarization,Romain Paulus;Caiming Xiong;Richard Socher,rpaulus@salesforce.com;cxiong@salesforce.com;richard@socher.org,8;7;6,3;5;4,Accept (Poster),0,3,0.0,yes,10/27/17,SalesForce.com;SalesForce.com;SalesForce.com,deep learning;natural language processing;reinforcement learning;text summarization;sequence generation,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8
729,ICLR,2018,The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings,Tomer Galanti;Lior Wolf;Sagie Benaim,tomer22g@gmail.com;liorwolf@gmail.com;sagiebenaim@gmail.com,7;7;6,4;2;4,Accept (Poster),0,6,0.0,yes,10/27/17,Tel Aviv University;Tel Aviv University;Tel Aviv University,Unsupervised learning;cross-domain mapping;Kolmogorov complexity;Occam's razor,-1;30;30,-1;217;217,-1;-1,europe,il,n,
730,ICLR,2018,Emergent Translation in Multi-Agent Communication,Jason Lee;Kyunghyun Cho;Jason Weston;Douwe Kiela,jason@cs.nyu.edu;kyunghyun.cho@nyu.edu;jase@fb.com;dkiela@fb.com,8;7;5,5;3;5,Accept (Poster),0,5,0.0,yes,10/27/17,New York University;New York University;Facebook;Facebook,,21;21;-1;-1,27;27;-1;-1,-1;-1,NAN,NAN,n,3
731,ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Scott Reed;Yutian Chen;Thomas Paine;A√§ron van den Oord;S. M. Ali Eslami;Danilo Rezende;Oriol Vinyals;Nando de Freitas,reedscot@google.com;yutianc@google.com;tpaine@google.com;avdnoord@google.com;aeslami@google.com;danilor@google.com;vinyals@google.com;nandodefreitas@google.com,6;7;6,5;4;4,Accept (Poster),1,1,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google;Google,few-shot learning;density models;meta learning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;8
732,ICLR,2018,Kronecker-factored Curvature Approximations for Recurrent Neural Networks,James Martens;Jimmy Ba;Matt Johnson,james.martens@gmail.com;jimmy@psi.toronto.edu;mattjj@csail.mit.edu,7;5;7,4;4;3,Accept (Poster),1,9,0.0,yes,10/27/17,Google;University of Toronto;Massachusetts Institute of Technology,optimization;K-FAC;natural gradient;recurrent neural networks,-1;21;8,-1;22;5,-1;-1,usa,usa,y,10
733,ICLR,2018,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,Lior Fox;Leshem Choshen;Yonatan Loewenstein,lior.fox@mail.huji.ac.il;leshem.choshen@mail.huji.ac.il;yonatan.loewenstein@mail.huji.ac.il,7;6;6,3;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Reinforcement Learning;Exploration;Model-Free,67;67;67,205;205;205,-1;-1,europe,il,n,1
734,ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Audrunas Gruslys;Will Dabney;Mohammad Gheshlaghi Azar;Bilal Piot;Marc Bellemare;Remi Munos,audrunas@google.com;wdabney@google.com;mazar@google.com;piot@google.com;bellemare@google.com;munos@google.com,7;7;7,4;2;4,Accept (Poster),0,6,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,reinforcement learning;policy gradient;distributional reinforcement learning;distributed computing,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
735,ICLR,2018,Gaussian Process Behaviour in Wide Deep Neural Networks,Alexander G. de G. Matthews;Jiri Hron;Mark Rowland;Richard E. Turner;Zoubin Ghahramani,am554@cam.ac.uk;jh2084@cam.ac.uk;mr504@cam.ac.uk;ret26@cam.ac.uk;zoubin@eng.cam.ac.uk,6;6;6,4;4;4,Accept (Poster),0,3,1.0,yes,10/27/17,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge,Gaussian Processes;Bayesian Deep Learning;Theory of Deep Neural Networks,82;82;82;82;82,2;2;2;2;2,-1;-1,europe,uk,y,11;9
736,ICLR,2018,On the Expressive Power of Overlapping Architectures of Deep Learning,Or Sharir;Amnon Shashua,or.sharir@cs.huji.ac.il;shashua@cs.huji.ac.il,6;8;6,4;3;4,Accept (Poster),0,3,0.0,yes,10/27/17,Hebrew University of Jerusalem;Hebrew University of Jerusalem,Deep Learning;Expressive Efficiency;Overlapping;Receptive Fields,67;67,205;205,-1;-1,europe,il,y,
737,ICLR,2018,An image representation based convolutional network for DNA classification,Bojian Yin;Marleen Balvert;Davide Zambrano;Alexander Schoenhuth;Sander Bohte,yinbojian93@gmail.com;m.balvert@cwi.nl;d.zambrano@cwi.nl;a.schoenhuth@cwi.nl;s.m.bohte@cwi.nl,7;7;7,5;3;5,Accept (Poster),0,11,0.0,yes,10/27/17,Centrum Wiskunde & Informatica;Centrum voor Wiskunde en Informatica;Centrum voor Wiskunde en Informatica;Centrum voor Wiskunde en Informatica;Centrum Wiskunde & Informatica,DNA sequences;Hilbert curves;Convolutional neural networks;chromatin structure,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
738,ICLR,2018,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,Yoav Levine;David Yakira;Nadav Cohen;Amnon Shashua,yoavlevine@cs.huji.ac.il;davidyakira@cs.huji.ac.il;cohennadav@cs.huji.ac.il;shashua@cs.huji.ac.il,6;7;8;6,4;3;5;2,Accept (Poster),0,6,0.0,yes,10/26/17,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,deep learning;quantum entanglement;quantum physics;many body physics;data correlations;inductive bias;tensor networks,67;67;67;67,205;205;205;205,-1;-1,europe,il,n,10
739,ICLR,2018,Critical Percolation as a Framework to Analyze the Training of Deep Networks,Zohar Ringel;Rodrigo Andrade de Bem,zoharahoz@gmail.com;rodrigo.bem@gmail.com,7;7;6,3;3;1,Accept (Poster),0,3,0.0,yes,10/26/17,Hebrew University of Jerusalem;University of Oxford,Deep Convolutional Networks;Loss function landscape;Graph Structured Data;Training Complexity;Theory of deep learning;Percolation theory;Anderson Localization,67;-1,205;-1,-1;-1,asia,in,n,10
740,ICLR,2018,Parallelizing Linear Recurrent Neural Nets Over Sequence Length,Eric Martin;Chris Cundy,eric@ericmart.in;chris.j.cundy@gmail.com,6;7;7,3;2;4,Accept (Poster),0,3,0.0,yes,10/27/17,California Institute of Technology;Stanford University,rnn;sequence;parallel;qrnn;sru;gilr;gilr-lstm,125;5,3;3,-1;-1,usa,usa,n,
741,ICLR,2018,Guide Actor-Critic for Continuous Control,Voot Tangkaratt;Abbas Abdolmaleki;Masashi Sugiyama,voot.tangkaratt@riken.jp;abbas.a@ua.pt;masashi.sugiyama@riken.jp,6;4;7,2;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,RIKEN;;RIKEN,Reinforcement learning;actor-critic;continuous control,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
742,ICLR,2018,Multi-Task Learning for Document Ranking and Query Suggestion,Wasi Uddin Ahmad;Kai-Wei Chang;Hongning Wang,wasiahmad@cs.ucla.edu;kwchang@cs.ucla.edu;hw5x@virginia.edu,4;6;7,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,"University of California, Los Angeles;University of California, Los Angeles;University of Virginia",Multitask Learning;Document Ranking;Query Suggestion,-1;-1;57,15;15;113,-1;-1,usa,usa,n,
743,ICLR,2018,Hyperparameter optimization: a spectral approach,Elad Hazan;Adam Klivans;Yang Yuan,ehazan@cs.princeton.edu;klivans@cs.utexas.edu;yangyuan@cs.cornell.edu,6;6;9,4;3;5,Accept (Poster),0,3,0.0,yes,10/27/17,"Princeton University;University of Texas, Austin;Cornell University",Hyperparameter Optimization;Fourier Analysis;Decision Tree;Compressed Sensing,30;-1;5,7;-1;19,-1;-1,usa,usa,y,11
744,ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Wei Ping;Kainan Peng;Andrew Gibiansky;Sercan O. Arik;Ajay Kannan;Sharan Narang;Jonathan Raiman;John Miller,pingwei01@baidu.com;pengkainan@baidu.com;gibianskyandrew@baidu.com;sercanarik@baidu.com;kannanajay@baidu.com;sharan@baidu.com;raiman@openai.com;miller_john@berkeley.edu,7;6;6,4;5;3,Accept (Poster),0,4,0.0,yes,10/24/17,Baidu;Baidu;Baidu;Baidu;Baidu;Baidu;OpenAI;University of California Berkeley,2000-Speaker Neural TTS;Monotonic Attention;Speech Synthesis,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;18,-1;-1,usa,usa,n,8
745,ICLR,2018,Divide and Conquer Networks,Alex Nowak;David Folqu√©;Joan Bruna,alexnowakvila@gmail.com;david.folque@gmail.com;bruna@cims.nyu.edu,6;7;7,3;3;3,Accept (Poster),0,2,0.0,yes,10/27/17,New York University;;New York University,Neural Networks;Combinatorial Optimization;Algorithms,-1;-1;21,-1;-1;27,-1;-1,usa,usa,n,1
746,ICLR,2018,When is a Convolutional Filter Easy to Learn?,Simon S. Du;Jason D. Lee;Yuandong Tian,ssdu@cs.cmu.edu;jasonlee@marshall.usc.edu;yuandong@fb.com,6;9;8,3;4;3,Accept (Poster),0,5,0.0,yes,10/25/17,Carnegie Mellon University;University of Southern California;Facebook,deep learning;convolutional neural network;non-convex optimization;convergence analysis,1;27;-1,24;66;-1,-1;-1,NAN,NAN,y,1;9
747,ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Uri Shaham;Kelly Stanton;Henry Li;Ronen Basri;Boaz Nadler;Yuval Kluger,uri.shaham@yale.edu;kelly.stanton@yale.edu;henry.li@yale.edu;ronen.basri@gmail.com;boaz.nadler@gmail.com;yuval.kluger@yale.edu,6;4;7,3;4;5,Accept (Poster),2,7,1.0,yes,10/26/17,Yale University;Yale University;Yale University;Weizmann Institute;;Yale University,unsupervised learning;spectral clustering;siamese networks,82;82;82;95;-1;82,12;12;12;-1;-1;12,-1;-1,europe,fi,y,1;10
748,ICLR,2018,Boundary Seeking GANs,R Devon Hjelm;Athul Paul Jacob;Adam Trischler;Gerry Che;Kyunghyun Cho;Yoshua Bengio,erroneus@gmail.com;apjacob@uwaterloo.ca;adam.trischler@microsoft.com;tong.che@umontreal.ca;kyunghyun.cho@nyu.edu;yoshua.bengio@umontreal.ca,7;7;4,4;3;3,Accept (Poster),0,12,0.0,yes,10/27/17,Microsoft;University of Waterloo;Microsoft;University of Montreal;New York University;University of Montreal,Generative adversarial networks;generative learning;deep learning;neural networks;adversarial learning;discrete data,-1;30;-1;125;21;125,-1;207;-1;108;27;108,-1;-1,canada,ca,y,3;5;4
749,ICLR,2018,Natural Language Inference over Interaction Space,Yichen Gong;Heng Luo;Jian Zhang,yichen.gong@nyu.edu;heng.luo@hobot.cc;jian.zhang@hobot.cc,5;6;6,5;4;4,Accept (Poster),0,7,2.0,yes,10/19/17,New York University;Horizon Robotics Inc.;Horizon Robotics Inc.,natural language inference;attention;SoTA;natural language understanding,21;-1;-1,27;-1;-1,-1;-1,NAN,NAN,n,8;3
750,ICLR,2018,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,Shiyu Liang;Yixuan Li;R. Srikant,sliang26@illinois.edu;yli@cs.cornell.edu;rsrikant@illinois.edu;liangshiyu@icloud.com;yl2363@cornell.edu,6;6;9,4;3;3,Accept (Poster),0,6,1.0,yes,10/27/17,"University of Illinois, Urbana Champaign;Cornell University;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Cornell University",Neural networks;out-of-distribution detection,-1;5;-1;-1;5,-1;19;-1;-1;19,-1;-1,usa,usa,y,
751,ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Bo Zong;Qi Song;Martin Renqiang Min;Wei Cheng;Cristian Lumezanu;Daeki Cho;Haifeng Chen,bzong@nec-labs.com;qsong@nec-labs.com;renqiang@nec-labs.com;weicheng@nec-labs.com;lume@nec-labs.com;dkcho@nec-labs.com;haifeng@nec-labs.com,8;8;8,5;4;4,Accept (Poster),0,8,0.0,yes,10/27/17,NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs,Density estimation;unsupervised anomaly detection;high-dimensional data;Deep autoencoder;Gaussian mixture modeling;latent low-dimensional space,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
752,ICLR,2018,Smooth Loss Functions for Deep Top-k Classification,Leonard Berrada;Andrew Zisserman;M. Pawan Kumar,lberrada@robots.ox.ac.uk;az@robots.ox.ac.uk;pawan@robots.ox.ac.uk,6;7;8,5;4;4,Accept (Poster),0,4,0.0,yes,10/27/17,University of Oxford;University of Oxford;University of Oxford,,39;39;39,1;1;1,-1;-1,europe,uk,y,2
753,ICLR,2018,Active Learning for Convolutional Neural Networks: A Core-Set Approach,Ozan Sener;Silvio Savarese,ozansener@cs.stanford.edu;ssilvio@stanford.edu,7;7;7,4;4;3,Accept (Poster),0,10,2.0,yes,10/27/17,Stanford University;Stanford University,Active Learning;Convolutional Neural Networks;Core-Set Selection,5;5,3;3,-1;-1,usa,usa,y,
754,ICLR,2018,Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference,Sebastian Nowozin,sebastian.nowozin@microsoft.com,7;6;7,4;3;3,Accept (Poster),2,6,1.0,yes,10/27/17,Microsoft,variational inference;approximate inference;generative models,-1,-1,-1,NAN,NAN,y,1;5
755,ICLR,2018,Unsupervised Machine Translation Using Monolingual Corpora Only,Guillaume Lample;Alexis Conneau;Ludovic Denoyer;Marc'Aurelio Ranzato,glample@fb.com;aconneau@fb.com;ludovic.denoyer@lip6.fr;ranzato@fb.com,8;7;7,5;5;4,Accept (Poster),3,8,0.0,yes,10/27/17,Facebook;Facebook;LIP6;Facebook,unsupervised;machine translation;adversarial,-1;-1;377;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
756,ICLR,2018,Word translation without parallel data,Guillaume Lample;Alexis Conneau;Marc'Aurelio Ranzato;Ludovic Denoyer;Herv√© J√©gou,glample@fb.com;aconneau@fb.com;ranzato@fb.com;ludovic.denoyer@upmc.fr;rvj@fb.com,9;3;8,4;5;3,Accept (Poster),2,10,0.0,yes,10/11/17,"Facebook;Facebook;Facebook;Computer Science Lab  - Pierre and Marie Curie University, Paris, France;Facebook",unsupervised learning;machine translation;multilingual embeddings;parallel dictionary induction;adversarial training,-1;-1;-1;-1;-1,-1;-1;-1;123;-1,-1;-1,NAN,NAN,n,3;4
757,ICLR,2018,Wavelet Pooling for Convolutional Neural Networks,Travis Williams;Robert Li,tlwilli3@aggies.ncat.edu;eeli@ncat.edu,7;9;4,4;3;4,Accept (Poster),0,5,3.0,yes,10/27/17,North Carolina A&T State University;North Carolina A&T State University,Pooling;Wavelet;CNN;Neural Network;Deep Learning;Classification;Machine Learning;Object Recognition,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
758,ICLR,2018,WRPN: Wide Reduced-Precision Networks,Asit Mishra;Eriko Nurvitadhi;Jeffrey J Cook;Debbie Marr,asit.k.mishra@intel.com;eriko.nurvitadhi@intel.com;jeffrey.j.cook@intel.com;debbie.marr@intel.com,5;9;5,3;4;4,Accept (Poster),0,8,0.0,yes,10/27/17,Intel;Intel;Intel;Intel,Low precision;binary;ternary;4-bits networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
759,ICLR,2018,Skip Connections Eliminate Singularities,Emin Orhan;Xaq Pitkow,aeminorhan@gmail.com;xaq@rice.edu,8;8;6,3;3;4,Accept (Poster),0,4,0.0,yes,10/27/17,New York University;Rice University,deep learning;optimization;skip connections,21;95,27;86,-1;-1,australasia,au,n,
760,ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,William Fedus*;Mihaela Rosca*;Balaji Lakshminarayanan;Andrew M. Dai;Shakir Mohamed;Ian Goodfellow,liam.fedus@gmail.com;mihaelacr@google.com;balajiln@google.com;adai@google.com;shakir@google.com;goodfellow@google.com,8;4;7,5;4;3,Accept (Poster),6,7,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,Deep learning;GAN,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;5;4
761,ICLR,2018,YellowFin and the Art of Momentum Tuning,Jian Zhang;Ioannis Mitliagkas;Christopher Re,zjian@cs.stanford.edu;ioannis@iro.umontreal.ca;chrismre@cs.stanford.edu,4;4;6,3;5;1,Reject,0,11,0.0,yes,10/27/17,Stanford University;University of Montreal;Stanford University,adaptive optimizer;momentum;hyperparameter tuning,5;125;5,3;108;3,-1;-1,usa,usa,y,3
762,ICLR,2018,HexaConv,Emiel Hoogeboom;Jorn W.T. Peters;Taco S. Cohen;Max Welling,e.hoogeboom@gmail.com;jornpeters@gmail.com;taco.cohen@gmail.com;welling.max@gmail.com,7;7;7,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,"University of Amsterdam;University of Amsterdam;;University of California, Irvine",hexagonal;group;symmetry;representation learning;rotation;equivariance;invariance,125;125;-1;-1,59;59;-1;99,-1;-1,usa,usa,n,
763,ICLR,2018,Few-Shot Learning with Graph Neural Networks,Victor Garcia Satorras;Joan Bruna Estrach,vgsatorras@gmail.com;bruna@cims.nyu.edu,7;7;7,4;4;4,Accept (Poster),0,13,0.0,yes,10/27/17,University of Amsterdam;New York University,,-1;21,-1;27,-1;-1,usa,usa,n,6;10
764,ICLR,2018,Proximal Backpropagation,Thomas Frerix;Thomas M√∂llenhoff;Michael Moeller;Daniel Cremers,thomas.frerix@tum.de;thomas.moellenhoff@in.tum.de;michael.moeller@uni-siegen.de;cremers@tum.de,6;5;7,4;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,Technical University Munich;Technical University Munich;University of Siegen;Technical University Munich,,-1;-1;377;-1,-1;-1;431;-1,-1;-1,NAN,NAN,y,1
765,ICLR,2018,Wasserstein Auto-Encoders,Ilya Tolstikhin;Olivier Bousquet;Sylvain Gelly;Bernhard Schoelkopf,iliya.tolstikhin@gmail.com;obousquet@gmail.com;sylvain.gelly@gmail.com;bs@tuebingen.mpg.de,8;8;8,3;3;4,Accept (Oral),0,9,8.0,yes,10/27/17,Google;Google;Google;Max-Planck Institute,auto-encoder;generative models;GAN;VAE;unsupervised learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;5;4
766,ICLR,2018,The High-Dimensional Geometry of Binary Neural Networks,Alexander G. Anderson;Cory P. Berg,aga@berkeley.edu;cberg500@berkeley.edu,7;4;7,4;3;4,Accept (Poster),0,8,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley,Binary Neural Networks;Neural Network Visualization,-1;-1,18;18,-1;-1,usa,usa,y,1
767,ICLR,2018,Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties,Yi Zhou;Yingbin Liang,zhou.1172@osu.edu;liang.889@osu.edu,7;7;6,3;5;4,Accept (Poster),0,6,0.0,yes,10/27/17,Ohio State University;Ohio State University,neural networks;critical points;analytical form;landscape,57;57,70;70,-1;-1,usa,usa,y,
768,ICLR,2018,Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation,Xu He;Herbert Jaeger,x.he@jacobs-university.de;h.jaeger@jacobs-university.de,7;7;7,5;3;3,Accept (Poster),0,4,0.0,yes,10/27/17,Jacobs University Bremen;Jacobs University Bremen,Catastrophic Interference;Conceptor;Backpropagation;Continual Learning;Lifelong Learning,377;377,-1;-1,-1;-1,europe,de,n,
769,ICLR,2018,Self-ensembling for visual domain adaptation,Geoff French;Michal Mackiewicz;Mark Fisher,g.french@uea.ac.uk;m.mackiewicz@uea.ac.uk;m.fisher@uea.ac.uk,7;7;7,4;3;5,Accept (Poster),1,5,2.0,yes,10/27/17,University of East Anglia;University of East Anglia;University of East Anglia,deep learning;neural networks;domain adaptation;images;visual;computer vision,-1;-1;-1,188;188;188,-1;-1,NAN,NAN,n,
770,ICLR,2018,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,Manuel Molano-Mazon;Arno Onken;Eugenio Piasini*;Stefano Panzeri*,manuel.molano@iit.it;aonken@inf.ed.ac.uk;epiasini@sas.upenn.edu;stefano.panzeri@iit.it,8;4;6,5;4;3,Accept (Poster),1,4,0.0,yes,10/27/17,Istituto Italiano di Tecnologia;University of Edinburgh;University of Pennsylvania;Istituto Italiano di Tecnologia,GANs;Wasserstein-GANs;convolutional networks;neuroscience;spike train patterns;spike train analysis,-1;30;15;-1,-1;27;10;-1,-1;-1,NAN,NAN,n,5;4
771,ICLR,2018,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation,Pietro Morerio;Jacopo Cavazza;Vittorio Murino,pietro.morerio@iit.it;jacopo.cavazza@iit.it;vittorio.murino@iit.it,6;7;8,5;5;4,Accept (Poster),0,5,1.0,yes,10/27/17,Istituto Italiano di Tecnologia;Istituto Italiano di Tecnologia;Istituto Italiano di Tecnologia,unsupervised domain adaptation;entropy minimization;image classification;deep transfer learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
772,ICLR,2018,Activation Maximization Generative Adversarial Nets,Zhiming Zhou;Han Cai;Shu Rong;Yuxuan Song;Kan Ren;Weinan Zhang;Jun Wang;Yong Yu,heyohai@apex.sjtu.edu.cn;hcai@apex.sjtu.edu.cn;shu.rong@yitu-inc.com;songyuxuan@apex.sjtu.edu.cn;kren@apex.sjtu.edu.cn;wnzhang@sjtu.edu.cn;j.wang@cs.ucl.ac.uk;yyu@apex.sjtu.edu.cn,5;7;8,4;4;4,Accept (Poster),3,5,0.0,yes,10/27/17,Shanghai Jiao Tong University;Shanghai Jiao Tong University;YiTu Technology co. ltd;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;University College London;Shanghai Jiao Tong University,Generative Adversarial Nets;GANs;Evaluation Metrics;Generative Model;Deep Learning;Adversarial Learning;Inception Score;AM Score,39;39;-1;39;39;39;49;39,188;188;-1;188;188;188;-1;188,-1;-1,asia,cn,y,5;4
773,ICLR,2018,Efficient Sparse-Winograd Convolutional Neural Networks,Xingyu Liu;Jeff Pool;Song Han;William J. Dally,xyl@stanford.edu;jpool@nvidia.com;songhan@stanford.edu;dally@stanford.edu,7;7;8,3;4;4,Accept (Poster),0,6,1.0,yes,10/26/17,Stanford University;NVIDIA;Stanford University;Stanford University,deep learning;convolutional neural network;pruning,5;-1;5;5,3;-1;3;3,-1;-1,usa,usa,n,
774,ICLR,2018,Neural Language Modeling by Jointly Learning Syntax and Lexicon,Yikang Shen;Zhouhan Lin;Chin-wei Huang;Aaron Courville,yikang.shn@gmail.com;lin.zhouhan@gmail.com;chin-wei.huang@umontreal.ca;aaron.courville@gmail.com,7;8;7,3;4;4,Accept (Poster),2,5,7.0,yes,10/27/17,University of Montreal;Shanghai Jiao Tong University;University of Montreal;University of Montreal,Language model;unsupervised parsing,125;39;125;125,108;188;108;108,-1;-1,canada,ca,n,3
775,ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Aviv Tamar;Khashayar Rohanimanesh;Yinlam Chow;Chris Vigorito;Ben Goodrich;Michael Kahane;Derik Pridmore,avivt@berkeley.edu;khash@osaro.com;yldick.chow@gmail.com;chris@osaro.com;ben@osaro.com;mk@osaro.com;derik@osaro.com,6;4;6,4;3;4,Accept (Poster),0,1,0.0,yes,10/27/17,University of California Berkeley;Osaro Inc.;Google;Osaro Inc.;Osaro Inc.;Osaro Inc.;Osaro Inc.,multi-modal imitation learning;deep learning;generative models;stochastic neural networks,-1;-1;-1;-1;-1;-1;-1,18;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,8
776,ICLR,2018,Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks,Shankar Krishnan;Ying Xiao;Rif. A. Saurous,skrishnan@google.com;yingxiao@google.com;rif@google.com,6;6;6,4;3;3,Accept (Poster),1,9,0.0,yes,10/27/17,Google;Google;Google,Deep Learning;Optimization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
777,ICLR,2018,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,Artemij Amiranashvili;Alexey Dosovitskiy;Vladlen Koltun;Thomas Brox,amiranas@cs.uni-freiburg.de;adosovitskiy@gmail.com;vkoltun@gmail.com;brox@cs.uni-freiburg.de,7;7;7,4;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,Universit√§t Freiburg;Google;Intel;Universit√§t Freiburg,deep learning;reinforcement learning;temporal difference,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,10
778,ICLR,2018,All-but-the-Top: Simple and Effective Postprocessing for Word Representations,Jiaqi Mu;Pramod Viswanath,jiaqimu2@illinois.edu;pramodv@illinois.edu,6;7;7,5;4;4,Accept (Poster),0,3,0.0,yes,10/26/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1,-1;-1,-1;-1,usa,usa,y,3
779,ICLR,2018,Spectral Normalization for Generative Adversarial Networks,Takeru Miyato;Toshiki Kataoka;Masanori Koyama;Yuichi Yoshida,miyato@preferred.jp;kataoka@preferred.jp;koyama.masanori@gmail.com;yyoshida@nii.ac.jp,7;8;7,4;3;2,Accept (Oral),8,15,4.0,yes,10/23/17,"Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.;National Institute of Informatics",Generative Adversarial Networks;Deep Generative Models;Unsupervised Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
780,ICLR,2018,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,Wieland Brendel *;Jonas Rauber *;Matthias Bethge,wieland.brendel@bethgelab.org;jonas.rauber@bethgelab.org;matthias.bethge@bethgelab.org,7;7;8,4;4;3,Accept (Poster),2,9,0.0,yes,10/27/17,"Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge",adversarial attacks;adversarial examples;adversarials;robustness;security,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,2;4
781,ICLR,2018,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,Sjoerd van Steenkiste;Michael Chang;Klaus Greff;J√ºrgen Schmidhuber,sjoerd@idsia.ch;mbchang@berkeley.edu;klaus@idsia.ch;juergen@idsia.ch,8;7;7,5;4;3,Accept (Poster),0,6,0.0,yes,10/27/17,IDSIA;University of California Berkeley;IDSIA;IDSIA,Common-sense Physical Reasoning;Intuitive Physics;Representation Learning;Model building,-1;-1;-1;-1,-1;18;-1;-1,-1;-1,asia,in,n,
782,ICLR,2018,cGANs with Projection Discriminator,Takeru Miyato;Masanori Koyama,miyato@preferred.jp;koyama.masanori@gmail.com,6;7;6,4;5;4,Accept (Poster),0,9,1.0,yes,10/27/17,"Preferred Networks, Inc.;Preferred Networks, Inc.",Generative Adversarial Networks;GANs;conditional GANs;Generative models;Projection,-1;-1,-1;-1,-1;-1,NAN,NAN,n,5
783,ICLR,2018,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models,Jesse Engel;Matthew Hoffman;Adam Roberts,jesseengel@google.com;mhoffman@google.com;adarob@google.com,7;7;7,4;3;3,Accept (Poster),0,4,0.0,yes,10/27/17,Google;Google;Google,VAE;GAN;generative networks;conditional generation;latent-variable models,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,6;5
784,ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Wei Wen;Yuxiong He;Samyam Rajbhandari;Minjia Zhang;Wenhan Wang;Fang Liu;Bin Hu;Yiran Chen;Hai Li,wei.wen@duke.edu;yuxhe@microsoft.com;samyamr@microsoft.com;minjiaz@microsoft.com;wenhanw@microsoft.com;fangliu@microsoft.com;binhu@microsoft.com;yiran.chen@duke.edu;hai.li@duke.edu,7;6;7,4;4;4,Accept (Poster),1,6,1.0,yes,10/1/17,Duke University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Duke University;Duke University,Sparsity;Model Compression;Acceleration;LSTMs;Recurrent Neural Networks;Structural Learning,39;-1;-1;-1;-1;-1;-1;39;39,17;-1;-1;-1;-1;-1;-1;17;17,-1;-1,europe,se,n,3
785,ICLR,2018,Coupled Ensembles of Neural Networks,Anuvabh Dutt;Denis Pellerin;Georges Qu√©not,anuvabh.dutt@univ-grenoble-alpes.fr;denis.pellerin@gipsa-lab.grenoble-inp.fr;georges.quenot@imag.fr,6;6;6,4;4;4,Reject,0,4,0.0,yes,10/3/17,University of Grenoble-Alpes;Grenoble Institute of Technology;French National Center for Scientific Research,Ensemble learning;neural networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
786,ICLR,2018,Exploring Sentence Vectors Through Automatic Summarization,Adly Templeton;Jugal Kalita,at7@williams.edu;jkalita@uccs.edu,2;2;3,5;5;5,Reject,0,0,0.0,yes,10/10/17,"Williams College;University of Colorado, Colorado Springs",Sentence Vectors;Vector Semantics;Automatic Summarization,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
787,ICLR,2018,Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates,Leslie N. Smith;Nicholay Topin,leslie.smith@nrl.navy.mil;ntopin1@umbc.edu,4;4;4,3;4;3,Reject,2,4,0.0,yes,10/11/17,US Naval Research Lab;Boston College,Deep Learning;machine learning,-1;224,-1;309,-1;-1,usa,usa,n,1
788,ICLR,2018,DOUBLY STOCHASTIC ADVERSARIAL AUTOENCODER,Mahdi Azarafrooz,mazarafrooz@cylance.com,3;3;2,4;5;5,Reject,0,3,0.0,yes,10/12/17,Cylance,Generative adversarial Networks;Deep Generative models;Kernel Methods,-1,-1,-1,NAN,NAN,y,5;4
789,ICLR,2018,Incremental Learning through Deep Adaptation,Amir Rosenfeld;John K. Tsotsos,amir.rosenfeld@gmail.com,6;4;5,4;4;4,Reject,0,3,0.0,yes,10/13/17,0,Transfer Learning;Learning without forgetting;Multitask Learning,,,-1;-1,NAN,NAN,n,6
790,ICLR,2018,Spontaneous Symmetry Breaking in Deep Neural Networks,Ricky Fok;Aijun An;Xiaogang Wang,ricky.fok3@gmail.com,3;3;3,4;3;3,Reject,0,0,0.0,yes,10/18/17,York University,deep learning;physics;field theory,162,350,-1;-1,asia,kr,y,1
791,ICLR,2018,Distributed non-parametric deep and wide networks,Biswa Sengupta;Yu Qian,biswasengupta@yahoo.com;yu.qian@cortexica.com,3;3;3,4;5;4,Reject,0,0,0.0,yes,10/18/17,Imperial College London;Cortexica Vision Systems,,49;-1,8;-1,-1;-1,NAN,NAN,n,
792,ICLR,2018,Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks,Thilo Strauss;Markus Hanselmann;Andrej Junginger;Holger Ulmer,thilo.strauss@etas.com;markus.hanselmann@etas.com;andrej.junginger@etas.com;holger.ulmer@etas.com,7;5;4,3;3;4,Reject,0,4,0.0,yes,10/18/17,ETAS GmbH;ETAS GmbH;ETAS GmbH;ETAS GmbH,Ensemble Method;Adversarial Perturbations;Deep Neural Networks;Defense;Attack,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
793,ICLR,2018,Learning Less-Overlapping Representations,Hongbao Zhang;Pengtao Xie;Eric Xing,hongbao.zhang@petuum.com;pengtaox@cs.cmu.edu;eric.xing@petuum.com,5;4;3,4;4;5,Reject,0,0,0.0,yes,10/19/17,Petuum Inc.;Carnegie Mellon University;Petuum Inc.,Less-overlapness;regularization;near-orthogonality;sparsity,-1;1;-1,-1;24;-1,-1;-1,NAN,NAN,n,1
794,ICLR,2018,Reward Design in Cooperative Multi-agent Reinforcement Learning for Packet Routing,Hangyu Mao;Zhibo Gong;Zhen Xiao,pku.hy.mao@gmail.com;gongzhibo@huawei.com;gtxaio@gmail.com,5;2;5,3;4;2,Reject,0,3,0.0,yes,10/19/17,Peking University;Huawei Technologies Ltd.;Peking University,Reward Design;Cooperative Multi-agent Reinforcement Learning;Packet Routing,14;-1;-1,27;-1;-1,-1;-1,asia,in,n,
795,ICLR,2018,Iterative temporal differencing with fixed random feedback alignment support spike-time dependent plasticity in vanilla backpropagation for deep learning,Aras Dargazany;Kunal Mankodiya,arasdar@uri.edu,3;2;2,4;5;5,Reject,0,0,0.0,yes,10/19/17,University of Rhode Island,Iterative temporal differencing;feedback alignment;spike-time dependent plasticity;vanilla backpropagation;deep learning,-1,-1,-1;-1,NAN,NAN,n,
796,ICLR,2018,Reinforcement Learning via Replica Stacking of Quantum Measurements for the Training of Quantum Boltzmann Machines,Anna Levit; Daniel Crawford;Navid Ghadermarzy;Jaspreet S. Oberoi;Ehsan Zahedinejad;Pooya Ronagh,anna.levit@1qbit.com;daniel.crawford@1qbit.com;navid.ghadermarzy@1qbit.com;jaspreet.oberoi@1qbit.com;ehsan.zahedinejad@1qbit.com;pooya.ronagh@1qbit.com,4;6;4,3;4;3,Reject,0,4,0.0,yes,10/19/17,1Qbit Information Technology;1Qbit Information Technology;1Qbit Information Technology;1Qbit Information Technology;1Qbit Information Technology;1Qbit Information Technology,Quantum Annealing;Reinforcement Learning;Boltzmann Machines;Markov Chain Monte Carlo,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
797,ICLR,2018,Pixel Deconvolutional Networks,Hongyang Gao;Hao Yuan;Zhengyang Wang;Shuiwang Ji,hongyang.gao@wsu.edu;hao.yuan@wsu.edu;zwang6@eecs.wsu.edu;sji@eecs.wsu.edu,5;5;6,5;4;4,Reject,0,3,0.0,yes,10/19/17,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Deep Learning;Deconvolutional Layer;Pixel CNN,-1;-1;-1;-1,352;352;352;352,-1;-1,NAN,NAN,n,2;5
798,ICLR,2018,Building effective deep neural networks one feature at a time,Martin Mundt;Tobias Weis;Kishore Konda;Visvanathan Ramesh,mundt@fias.uni-frankfurt.de;weis@ccc.cs.uni-frankfurt.de;kishore.konda@insofe.edu.in;ramesh@fias.uni-frankfurt.de,4;8;5,5;4;4,Reject,2,5,0.0,yes,10/19/17,Goethe University;Goethe University;;Goethe University,convolution neural networks;architecture search;meta-learning;representational capacity,224;224;-1;224,293;293;-1;293,-1;-1,NAN,NAN,n,
799,ICLR,2018,Adversary A3C for Robust Reinforcement Learning,Zhaoyuan Gu;Zhenzhong Jia;Howie Choset,guzhaoyuan14@gmail.com;zhenzhong.jia@gmail.com;choset@cs.cmu.edu,4;4;4,4;4;4,Reject,0,0,0.0,yes,10/20/17,Tsinghua University;;Carnegie Mellon University,Adversary;Robust;Reinforcement Learning;A3C,-1;-1;1,-1;-1;24,-1;-1,usa,usa,n,4
800,ICLR,2018,Deep Function Machines: Generalized Neural Networks for Topological Layer Expression,William H. Guss,wguss@cs.cmu.edu,7;3;4,1;4;3,Reject,0,3,0.0,yes,10/20/17,Carnegie Mellon University,deep learning theory;infinite neural networks;topology,1,24,-1,usa,usa,y,2;1
801,ICLR,2018,Enhance Word Representation for Out-of-Vocabulary on Ubuntu Dialogue Corpus,JIANXIONG DONG;Jim Huang,jdongca2003@gmail.com;ccjimhuang@gmail.com,6;3;5,3;5;4,Reject,0,15,0.0,yes,10/20/17,"Concordia University, Montreal;Amazon",next utterance selection;ubuntu dialogue corpus;out-of-vocabulary;word representation,-1;-1,-1;-1,-1;-1,asia,in,n,
802,ICLR,2018,On Optimality Conditions for Auto-Encoder Signal Recovery,Devansh Arpit;Yingbo Zhou;Hung Q. Ngo;Nils Napp;Venu Govindaraju,devansharpit@gmail.com;zybzmhhj@gmail.com;hungngo@buffalo.edu;nnapp@buffalo.edu;venu@cubs.buffalo.edu,4;5;5,3;4;4,Reject,0,3,0.0,yes,10/20/17,"SalesForce.com;SalesForce.com;State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo",Auto Encoder;Signal Recovery;Sparse Coding,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
803,ICLR,2018,Multi-label Learning for Large Text Corpora using Latent Variable Model with Provable Gurantees,Sayantan Dasgupta,sayandg@umich.edu,4;3;4,5;4;5,Reject,0,0,0.0,yes,10/21/17,University of Michigan,Spectral Method;Multi-label Learning;Tensor Factorisation,10,21,-1,usa,usa,y,1
804,ICLR,2018,Egocentric Spatial Memory Network,Mengmi Zhang;Keng Teck Ma;Joo Hwee Lim;Shih-Cheng Yen;Qi Zhao;Jiashi Feng,a0091624@u.nus.edu;makt@i2r.a-star.edu.sg;joohwee@i2r.a-star.edu.sg;shihcheng@nus.edu.sg;qzhao@cs.umn.edu;elefjia@nus.edu.sg,5;3;4,4;4;4,Reject,0,0,0.0,yes,10/21/17,"National University of Singapore;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;National University of Singapore;University of Minnesota, Minneapolis;National University of Singapore",spatial memory;egocentric vision;deep neural network;navigation,15;-1;-1;15;67;15,22;-1;-1;22;56;22,-1;-1,asia,sg,n,
805,ICLR,2018,Entropy-SGD optimizes the prior of a PAC-Bayes bound: Data-dependent PAC-Bayes priors via differential privacy,Gintare Karolina Dziugaite;Daniel M. Roy,gkd22@cam.ac.uk;droy@utstat.toronto.edu,6;6;6,3;3;3,Reject,0,13,0.0,yes,10/21/17,University of Cambridge;University of Toronto,generalization error;neural networks;statistical learning theory;PAC-Bayes theory,82;21,2;22,-1;-1,canada,ca,y,1
806,ICLR,2018,Decoupling the Layers in Residual Networks,Ricky Fok;Aijun An;Zana Rashidi;Xiaogang Wang,ricky.fok3@gmail.com;aan@cse.yorku.ca;rashidi.zana@gmail.com;stevenw@mathstat.yorku.ca,6;7;6,3;3;3,Accept (Poster),0,22,0.0,yes,10/21/17,York University;York University;York University;York University,Warped residual networks;residual networks,162;162;162;162,350;350;350;350,-1;-1,asia,kr,y,1
807,ICLR,2018,ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES,Mehran Taghipour-Gorjikolaie;Seyyed Mohammad Razavi;Javad Sadri,mehran.tg.88@gmail.com;razavism@gmail.com;j_sadri@encs.concordia.ca,1;3;2,5;4;3,Reject,0,0,0.0,yes,10/21/17,"University of Birjand;;Concordia University, Montreal",Classification;Feature Combination;Feature Mapping;Feed-Forward Neural Network;Genetic Algorithm;Linear Transfer Function;Non-Linear Transfer Function,-1;-1;377,-1;-1;560,-1;-1,NAN,NAN,n,
808,ICLR,2018,Thinking like a machine ‚Äî generating visual rationales through latent space optimization,Jarrel Seah;Jennifer Tang;Andy Kitchen;Jonathan Seah,jarrelscy@gmail.com,4;8;7,3;2;4,Reject,0,10,0.0,yes,10/21/17,Alfred Health,interpretability;generative adversarial networks,-1,-1,-1;-1,NAN,NAN,n,1;5
809,ICLR,2018,AANN: Absolute Artificial Neural Network,Animesh Karnewar,animeshsk3@gmail.com,2;3;6,3;5;4,Reject,0,2,0.0,yes,10/21/17,0,Neural Network architecture;Learned representation space;absolute valued function;bidirectional neuron,,,-1,NAN,NAN,n,
810,ICLR,2018,Dependent Bidirectional RNN with Extended-long Short-term Memory,Yuanhang Su;Yuzhong Huang;C.-C. Jay Kuo,yuanhans@usc.edu;yuzhongh@usc.edu;cckuo@sipi.usc.edu,3;4;4,4;4;4,Reject,0,10,1.0,yes,10/22/17,University of Southern California;University of Southern California;University of Southern California,RNN;memory;LSTM;GRU;BRNN;encoder-decoder;Natural language processing,27;27;27,66;66;66,-1;-1,usa,usa,n,
811,ICLR,2018,Make SVM great again with Siamese kernel for  few-shot learning,Bence Tilk,bence.tilk@gmail.com,5;3;4,4;4;5,Reject,0,3,0.0,yes,10/22/17,0,SVM;siamese network;one-shot learning;few-shot learning,,,-1,NAN,NAN,n,6;1
812,ICLR,2018,Some Considerations on Learning to Explore via Meta-Reinforcement Learning,Bradly Stadie;Ge Yang;Rein Houthooft;Xi Chen;Yan Duan;Yuhuai Wu;Pieter Abbeel;Ilya Sutskever,bstadie@berkeley.edu;yangge1987@gmail.com;rein.hh@gmail.com;adslcx@gmail.com;dementrock@gmail.com;ywu@cs.toronto.edu;pabbeel@gmail.com;ilyasu@openai.com,7;6;4,4;5;4,Invite to Workshop Track,0,8,0.0,yes,10/22/17,University of California Berkeley;;;covariant.ai;University of California Berkeley;University of Toronto;covariant.ai;OpenAI,reinforcement learning;rl;exploration;meta learning;meta reinforcement learning;curiosity,-1;-1;-1;-1;-1;21;-1;-1,18;-1;-1;-1;18;22;-1;-1,-1;-1,NAN,NAN,n,
813,ICLR,2018,Learning non-linear transform with discriminative and minimum information loss priors,Dimche Kostadinov;Slava Voloshynovskiy,dimche.kostadinov@unige.ch;svolos@unige.ch,5;4;5,2;2;1,Reject,0,6,0.0,yes,10/22/17,"University of Geneva, Switzerland;University of Geneva, Switzerland",transform learning;sparse representation;discrimininative prior;information preservation;discrimination power,-1;-1,130;130,-1;-1,NAN,NAN,y,
814,ICLR,2018,Continuous Convolutional Neural Networks for Image Classification,Vitor Guizilini;Fabio Ramos,vitor.guizilini@sydney.edu.au;fabio.ramos@sydney.edu.au,5;6;4,3;2;4,Reject,1,6,0.0,yes,10/22/17,University of Sydney;University of Sydney,convolutional neural networks;image classification;deep learning;feature representation;hilbert maps;reproducing kernel hilbert space,67;67,61;61,-1;-1,europe,uk,n,9
815,ICLR,2018,Learning Representations and Generative Models for 3D Point Clouds,Panos Achlioptas;Olga Diamanti;Ioannis Mitliagkas;Leonidas Guibas,optas@cs.stanford.edu;diamanti@stanford.edu;ioannis@iro.umontreal.ca;guibas@cs.stanford.edu,6;8;5,5;5;4,Invite to Workshop Track,0,10,0.0,yes,10/23/17,Stanford University;Stanford University;University of Montreal;Stanford University,representation learning;auto-encoders;3D point clouds;generative models;GANs;Gaussian Mixture Models,5;5;125;5,3;3;108;3,-1;-1,usa,usa,n,1;5
816,ICLR,2018,Siamese Survival Analysis with Competing Risks,Anton Nemchenko;Kartik Ahuja;Mihaela Van Der Schaar,santon834@g.ucla.edu;ahujak@ucla.edu;mihaela@ee.ucla.edu,4;4;4,4;4;5,Reject,0,5,0.0,yes,10/23/17,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",survival analysis;competing risks;siamese neural networks,-1;-1;-1,15;15;15,-1;-1,usa,usa,n,
817,ICLR,2018,Training and Inference with Integers in Deep Neural Networks,Shuang Wu;Guoqi Li;Feng Chen;Luping Shi,wus15@mails.tsinghua.edu.cn;liguoqi@mail.tsinghua.edu.cn;chenfeng@mail.tsinghua.edu.cn;lpshi@mail.tsinghua.edu.cn,7;7;8,4;3;4,Accept (Oral),0,3,5.0,yes,10/23/17,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",quantization;training;bitwidth;ternary weights,5;5;5;5,30;30;30;30,-1;-1,NAN,NAN,n,
818,ICLR,2018,Associative Conversation Model: Generating Visual Information from Textual Information,Yoichi Ishibashi;Hisashi Miyamori,g1445539@cc.kyoto-su.ac.jp;miya@cc.kyoto-su.ac.jp,4;3;3,5;4;5,Reject,0,1,0.0,yes,10/23/17,Meiji University;Meiji University,conversation model;multimodal embedding;attention mechanism;natural language processing;encoder-decoder model,-1;-1,978;978,-1;-1,asia,jp,n,3
819,ICLR,2018,The Principle of Logit Separation,Gil Keren;Sivan Sabato;Bj√∂rn Schuller,cruvadom@gmail.com;sivan.sabato@gmail.com;bjoern.schuller@imperial.ac.uk,6;3;4,3;4;4,Reject,0,2,0.0,yes,10/23/17,University of Passau;Ben Gurion University of the Negev;Imperial College London,,-1;162;49,-1;627;8,-1;-1,europe,uk,n,
820,ICLR,2018,Improving image generative models with human interactions,Andrew Kyle Lampinen;David So;Douglas Eck;Fred Bertsch,lampinen@stanford.edu;davidso@google.com;deck@google.com;fredbertsch@google.com,4;5;4,5;3;4,Reject,0,3,0.0,yes,10/23/17,Stanford University;Google;Google;Google,human in the loop;GANs;generative adversarial networks;image generative models;computer vision,5;-1;-1;-1,3;-1;-1;-1,-1;-1,NAN,NAN,n,1;5
821,ICLR,2018,Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling,Boris Ginsburg;Igor Gitman;Yang You,bginsburg@nvidia.com;igitman@andrew.cmu.edu;youyang@cs.berkeley.edu,5;4;5,3;4;5,Reject,0,3,0.0,yes,10/24/17,NVIDIA;Carnegie Mellon University;University of California Berkeley,large batch;LARS;adaptive rate scaling,-1;1;-1,-1;24;18,-1;-1,usa,usa,n,
822,ICLR,2018,ResBinNet: Residual Binary Neural Network,Mohammad Ghasemzadeh;Mohammad Samragh;Farinaz Koushanfar,mghasemzadeh@ucsd.edu;msamragh@ucsd.edu;farinaz@ucsd.edu,4;4;4,4;4;4,Reject,2,0,0.0,yes,10/24/17,"University of California, San Diego;University of California, San Diego;University of California, San Diego",Binary Neural Networks;Residual Binarization;Deep Learning,-1;-1;-1,31;31;31,-1;-1,usa,usa,n,9
823,ICLR,2018,Exponentially vanishing sub-optimal local minima in multilayer neural networks,Daniel Soudry;Elad Hoffer,daniel.soudry@gmail.com;elad.hoffer@gmail.com,5;7;6,3;2;3,Invite to Workshop Track,0,5,0.0,yes,10/24/17,"Technion, Technion;Habana Labs (Intel)",neural networks;theory;optimization;local minima;loss landscape,21;-1,-1;-1,-1;-1,NAN,NAN,y,1
824,ICLR,2018,A New Method of Region Embedding for Text Classification,chao qiao;bo huang;guocheng niu;daren li;daxiang dong;wei he;dianhai yu;hua wu,chao.qiao@outlook.com;bohuang0321@gmail.com;niuguocheng@baidu.com;lidaren@baidu.com;dongdaxiang@baidu.com;hewei06@baidu.com;yudianhai@baidu.com;wu_hua@baidu.com,6;6;6,4;5;3,Accept (Poster),4,18,0.0,yes,10/24/17,Baidu;Zhihu;Baidu;Baidu;Baidu;Baidu;Baidu;Baidu,region embedding;local context unit;text classification,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
825,ICLR,2018,Predicting Auction Price of Vehicle License Plate with Deep Recurrent Neural Network,Vinci Chow,vincichow@cuhk.edu.hk,6;4;4,5;4;4,Reject,0,3,0.0,yes,10/24/17,The Chinese University of Hong Kong,price predictions;expert system;recurrent neural networks;deep learning;natural language processing,377,40,-1,NAN,NAN,n,3
826,ICLR,2018,Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures,Ding Liu;Shi-Ju Ran;Peter Wittek;Cheng Peng;Raul Bl√°zquez Garc√≠a;Gang Su;Maciej Lewenstein,dingliu_thu@126.com;shi-ju.ran@icfo.eu;peter.wittek@icfo.eu;pengcheng12@mails.ucas.ac.cn;raulbzga@gmail.com;gsu@ucas.ac.cn;maciej.lewenstein@icfo.eu,6;4;3,3;3;2,Reject,0,3,0.0,yes,10/24/17,126;ICFO-Institut de Ciencies Fotoniques;ICFO-Institut de Ciencies Fotoniques;Chinese Academy of Sciences;;Chinese Academy of Sciences;ICFO-Institut de Ciencies Fotoniques,quantum machine learning;tensor network;quantum information,-1;-1;-1;30;-1;30;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;1
827,ICLR,2018,Learning to play slot cars and Atari 2600 games in just minutes,Lionel Cordesses;Omar Bentahar;Julien Page,lionel.cordesses@renault.com;omar.bentahar@renault.com;ju.page@hotmail.com,3;2;3,2;5;1,Reject,0,4,0.0,yes,10/24/17,"Blaise Pascal University, France;Renault;Renault",Artificial Intelligence;Signal processing;Philosophy;Analogy;ALE;Slot Car,-1;-1;-1,565;-1;-1,-1;-1,asia,in,n,1
828,ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Pieter-Jan Kindermans;Kristof T. Sch√ºtt;Maximilian Alber;Klaus-Robert M√ºller;Dumitru Erhan;Been Kim;Sven D√§hne,pikinder@google.com;kristof.schuett@tu-berlin.de;maximilian.aber@tu-berlin.de;klaus-robert.mueller@tu-berlin.de;dumitru@google.com;beenkim@google.com;sven.daehne@tu-berlin.de,8;8;6,3;4;4,Accept (Poster),3,5,0.0,yes,10/24/17,Google;TU Berlin;TU Berlin;TU Berlin;Google;Google;TU Berlin,machine learning;interpretability;deep learning,-1;125;125;125;-1;-1;125,-1;-1;-1;-1;-1;-1;-1,-1;-1,europe,de,n,1
829,ICLR,2018,Memory Augmented Control Networks,Arbaaz Khan;Clark Zhang;Nikolay Atanasov;Konstantinos Karydis;Vijay Kumar;Daniel D. Lee,arbaazk@seas.upenn.edu;clarkz@seas.upenn.edu;natanasov@ucsd.edu;konstantinos.karydis@ucr.edu;vijay.kumar@seas.upenn.edu;ddlee@seas.upenn.edu,4;6;9,5;2;4,Accept (Poster),0,6,0.0,yes,10/24/17,"University of Pennsylvania;University of Pennsylvania;University of California, San Diego;University of California, Riverside;University of Pennsylvania;University of Pennsylvania",planning;memory networks;deep learning;robotics,15;15;-1;-1;15;15,10;10;31;197;10;10,-1;-1,usa,usa,n,
830,ICLR,2018,Trace norm regularization and faster inference for embedded speech recognition RNNs,Markus Kliegl;Siddharth Goyal;Kexin Zhao;Kavya Srinet;Mohammad Shoeybi,mkliegl@gmail.com;goyalsiddharth@baidu.com;zhaokexin01@baidu.com;srinetkavya@baidu.com;shoeybim@gmail.com,4;5;5,3;5;3,Reject,0,5,0.0,yes,10/24/17,Baidu;Baidu;Baidu;Baidu;NVIDIA,LVCSR;speech recognition;embedded;low rank factorization;RNN;GRU;trace norm,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
831,ICLR,2018,Exploring the Hidden Dimension in Accelerating Convolutional Neural Networks,Zhihao Jia;Sina Lin;Charles R. Qi;Alex Aiken,zhihao@cs.stanford.edu;silin@microsoft.com;rqi@stanford.edu;aiken@cs.stanford.edu,4;5;7,5;4;4,Reject,0,6,0.0,yes,10/25/17,Stanford University;Microsoft;Stanford University;Stanford University,Parallelism of Convolutional Neural Networks;Accelerating Convolutional Neural Networks,5;-1;5;5,3;-1;3;3,-1;-1,usa,usa,n,
832,ICLR,2018,Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions,Nadav Cohen;Ronen Tamari;Amnon Shashua,cohennadav@ias.edu;ronent@cs.huji.ac.il;shashua@cs.huji.ac.il,7;9;8,4;4;3,Accept (Oral),0,3,0.0,yes,10/25/17,"Institue for Advanced Study, Princeton;Hebrew University of Jerusalem;Hebrew University of Jerusalem",Deep Learning;Expressive Efficiency;Dilated Convolutions;Tensor Decompositions,-1;67;67,-1;205;205,-1;-1,europe,il,y,1
833,ICLR,2018,Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification,Chong Wang;Xipeng Lan;Yangang Zhang,chongwang.nlpr@gmail.com;xipeng.lan@gmail.com;caveman1984@gmail.com,3;5;3,4;5;4,Reject,0,0,0.0,yes,10/25/17,Beijing Orion Star Technology Co;;Beijing Orion Star Technology Co,distill;transfer;classification;alignment;verification,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,n,2
834,ICLR,2018,Distribution Regression Network,Connie Kou;Hwee Kuan Lee;Teck Khim Ng,koukl@comp.nus.edu.sg;leehk@bii.a-star.edu.sg;ngtk@comp.nus.edu.sg,5;7;7,4;2;4,Reject,0,5,0.0,yes,10/25/17,National University of Singapore;A*STAR;National University of Singapore,distribution regression;supervised learning;regression analysis,15;-1;15,22;-1;22,-1;-1,asia,sg,n,
835,ICLR,2018,Graph Classification with 2D Convolutional Neural Networks,Antoine J.-P. Tixier;Giannis Nikolentzos;Polykarpos Meladianos;Michalis Vazirgiannis,antoine.tixier-1@colorado.edu;giannisnik@hotmail.com;p.meladianos@gmail.com;mvazirg@lix.polytechnique.fr,3;4;7,5;3;3,Reject,0,0,0.0,yes,10/25/17,"University of Colorado, Boulder;Ecole polytechnique;;Ecole Polytechnique, France",graph classification;convolutional neural networks;2D CNN;representation,57;-1;-1;-1,100;115;-1;-1,-1;-1,NAN,NAN,n,10
836,ICLR,2018,Unsupervised Deep Structure Learning by Recursive Dependency Analysis,Raanan Y. Yehezkel Rohekar;Guy Koren;Shami Nisimov;Gal Novik,raanan.y.yehezkel.rohekar@intel.com;guy.koren@intel.com;shami.nisimov@intel.com;gal.novik@intel.com,4;5;5,4;2;3,Reject,0,3,0.0,yes,10/25/17,Intel;Intel;Intel;Intel,unsupervised learning;structure learning;deep belief networks;probabilistic graphical models;Bayesian networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,10;1;5
837,ICLR,2018,Dynamic Integration of Background Knowledge in Neural NLU Systems,Dirk Weissenborn;Tomas Kocisky;Chris Dyer,dirk.weissenborn@dfki.de;tkocisky@google.com;cdyer@google.com,5;5;6,3;4;4,Reject,0,4,0.0,yes,10/25/17,German Research Center for AI;Google;Google,natural language processing;background knowledge;word embeddings;question answering;natural language inference,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
838,ICLR,2018,Post-training for Deep Learning,Thomas Moreau;Julien Audiffren,thomas.moreau@cmla.ens-cachan.fr;julien.audiffren@cmla.ens-cachan.fr,5;3;4,4;5;4,Reject,1,3,0.0,yes,10/25/17,ENS Paris-Saclay;ENS Paris-Saclay,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
839,ICLR,2018,Image Segmentation by Iterative Inference from Conditional Score Estimation,Adriana Romero;Michal Drozdzal;Akram Erraqabi;Simon J√©gou;Yoshua Bengio,adriana.romsor@gmail.com;michal.drozdzal@gmail.com;akram.er-raqabi@umontreal.ca;simon.jegou@gmail.com;yoshua.umontreal@gmail.com,5;4;4,5;4;4,Reject,0,0,0.0,yes,10/25/17,Facebook;Facebook;University of Montreal;;University of Montreal,semantic segmentation;conditional denoising autoencoders;iterative inference,-1;-1;125;-1;125,-1;-1;108;-1;108,-1;-1,canada,ca,n,2
840,ICLR,2018,Towards Safe Deep Learning: Unsupervised Defense Against Generic Adversarial Attacks,Bita Darvish Rouhani;Mohammad Samragh;Tara Javidi;Farinaz Koushanfar,bita@ucsd.edu;msamragh@ucsd.edu;tjavidi@ucsd.edu;farinaz@ucsd.edu,5;7;3,3;3;5,Reject,0,5,0.0,yes,10/25/17,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",Adversarial Attacks;Unsupervised Defense;Deep Learning,-1;-1;-1;-1,31;31;31;31,-1;-1,usa,usa,n,1;4
841,ICLR,2018,GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks,Alessandro Bay;Biswa Sengupta,alessandro.bay@cortexica.com;biswasengupta@yahoo.com,5;4;5,2;4;4,Invite to Workshop Track,0,3,0.0,yes,10/25/17,Cortexica Vision Systems;Imperial College London,,-1;49,-1;8,-1;-1,europe,uk,n,2;10
842,ICLR,2018,Hybed: Hyperbolic Neural Graph Embedding,Benjamin Paul Chamberlain;James R Clough;Marc Peter Deisenroth,benjamin.chamberlain@gmail.com;james.clough@kcl.ac.uk;m.deisenroth@imperial.ac.uk,4;7;5;4,3;2;3;3,Reject,0,16,0.0,yes,10/25/17,Twitter;King's College London;Imperial College London,embeddings;hyperbolic space;neural networks;geometry,-1;162;49,-1;36;8,-1;-1,europe,uk,n,3;10
843,ICLR,2018,Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks,Michael O. Vertolli;Jim Davies,michaelvertolli@gmail.com;jim@jimdavies.org,5;5;6,3;3;3,Reject,0,3,0.0,yes,10/25/17,Carleton University;Carleton University,generative adversarial networks;gans;deep learning;image modeling;image generation;energy based models,224;-1,545;-1,-1;-1,asia,in,n,5;4
844,ICLR,2018,Regularizing and Optimizing LSTM Language Models,Stephen Merity;Nitish Shirish Keskar;Richard Socher,smerity@smerity.com;keskar.nitish@u.northwestern.edu;richard@socher.org,7;7;7,4;4;5,Accept (Poster),0,3,0.0,yes,10/25/17,Smerity;Northwestern University;SalesForce.com,language model;LSTM;regularization;optimization;ASGD;dropconnect,-1;49;-1,-1;20;-1,-1;-1,NAN,NAN,n,3
845,ICLR,2018,Dynamic Evaluation of Neural Sequence Models,Ben Krause;Emmanuel Kahembwe;Iain Murray;Steve Renals,ben.krause@ed.ac.uk;e.kahembwe@ed.ac.uk;i.murray@ed.ac.uk;s.renals@ed.ac.uk,7;7;3,4;4;3,Reject,0,4,0.0,yes,10/25/17,University of Edinburgh;University of Edinburgh;University of Edinburgh;University of Edinburgh,sequence modelling;language;recurrent neural networks;adaptation,30;30;30;30,27;27;27;27,-1;-1,europe,uk,n,
846,ICLR,2018,Taking Apart Autoencoders: How do They Encode Geometric Shapes ?,Alasdair Newson;Andres Almansa;Yann Gousseau;Said Ladjal,alasdairnewson@gmail.com;andres.almansa@parisdescartes.fr;yann.gousseau@telecom-paristech.fr;said.ladjal@telecom-paristech.fr,4;4;4,5;4;3,Reject,0,4,0.0,yes,10/25/17,T√©l√©com ParisTech;University Paris Descartes;T√©l√©com ParisTech;T√©l√©com ParisTech,autoencoders;CNN;image synthesis;latent space,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,8;5
847,ICLR,2018,Diffusing Policies : Towards Wasserstein Policy Gradient Flows,Pierre H. Richemond;Brendan Maginnis,phr17@imperial.ac.uk;b.maginnis@imperial.ac.uk,4;5;4,3;3;4,Reject,0,3,0.0,yes,10/25/17,Imperial College London;Imperial College London,Optimal transport;policy gradients;entropy regularization;reinforcement learning;heat equation;Wasserstein;JKO;gradient flows,49;49,8;8,-1;-1,europe,uk,n,
848,ICLR,2018,"To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression",Michael H. Zhu;Suyog Gupta,mhzhu@cs.stanford.edu;suyoggupta@google.com,5;5;5,4;4;5,Invite to Workshop Track,1,2,0.0,yes,10/25/17,Stanford University;Google,pruning;model sparsity;model compression;deep learning,5;-1,3;-1,-1;-1,NAN,NAN,n,
849,ICLR,2018,Training Deep AutoEncoders for Recommender Systems,Oleksii Kuchaiev;Boris Ginsburg,kuchaev@gmail.com;boris.ginsburg@gmail.com,4;3;6,5;4;4,Reject,1,3,0.0,yes,10/25/17,NVIDIA;NVIDIA,autoencoder;recommendations;collaborative filtering;selu,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
850,ICLR,2018,Neural Networks with Block Diagonal Inner Product Layers,Amy Nesky;Quentin Stout,anesky@umich.edu;qstout@umich.edu,5;6;4,4;4;3,Reject,2,4,0.0,yes,10/26/17,University of Michigan;University of Michigan,Deep Learning;Neural Networks,10;10,21;21,-1;-1,usa,usa,n,
851,ICLR,2018,Balanced and Deterministic Weight-sharing Helps Network Performance,Oscar Chang;Hod Lipson,oscar.chang@columbia.edu;hod.lipson@columbia.edu,4;4;4,4;4;4,Reject,0,0,0.0,yes,10/26/17,Columbia University;Columbia University,Weight-sharing;Weight sharing;Weight tying;neural networks;entropy;hash function;hash table;balance;sparse;sparsity;hashednets,21;21,14;14,-1;-1,usa,usa,n,
852,ICLR,2018,Learning Discrete Weights Using the Local Reparameterization Trick,Oran Shayer;Dan Levi;Ethan Fetaya,oran.sh@gmail.com;dan.levi@gm.com;ethanf@cs.toronto.edu,6;7;6,4;3;3,Accept (Poster),0,1,0.0,yes,10/26/17,General Motors;General Motors;University of Toronto,deep learning;discrete weight network,-1;-1;21,-1;-1;22,-1;-1,canada,ca,n,2
853,ICLR,2018,End-to-End Abnormality Detection in Medical Imaging,Dufan Wu;Kyungsang Kim;Bin Dong;Quanzheng Li,dwu6@mgh.harvard.edu;kkim24@mgh.harvard.edu;dongbin@math.pku.edu.cn;li.quanzheng@mgh.harvard.edu,4;5;6,4;4;3,Reject,0,0,0.0,yes,10/26/17,Harvard University;Harvard University;Peking University;Harvard University,End-to-End training;deep neural networks;medical imaging;image reconstruction,49;49;14;49,6;6;27;6,-1;-1,usa,usa,n,2
854,ICLR,2018,Understanding Deep Learning Generalization by Maximum Entropy,Guanhua Zheng;Jitao Sang;Changsheng Xu,zhenggh@mail.ustc.edu.cn;jtsang@bjtu.edu.cn;csxu@nlpr.ia.ac.cn,2;3;6,3;3;2,Reject,0,0,0.0,yes,10/26/17,"University of Science and Technology of China;Beijing Jiaotong University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",generalization;maximum entropy;deep learning,-1;-1;30,132;854;-1,-1;-1,NAN,NAN,n,8;1
855,ICLR,2018,Compact Encoding of Words for Efficient Character-level Convolutional Neural Networks Text Classification,Wemerson Marinho;Luis Marti;Nayat Sanchez-pi,wemerson_marinho@id.uff.br;lmarti@ic.uff.br;nayat@ime.uerj.br,4;3;2,5;5;5,Reject,0,12,0.0,yes,10/26/17,"Institute of Computing, UFF;Institute of Computing, UFF;Universidade do Estado do Rio de Janeiro",Character Level Convolutional Networks;Text Classification;Word Compressing,377;377;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
856,ICLR,2018,Rotational Unit of Memory ,Rumen Dangovski;Li Jing;Marin Soljacic,rumenrd@mit.edu;ljing@mit.edu;soljacic@mit.edu,4;6;5,4;3;4,Invite to Workshop Track,0,11,0.0,yes,10/26/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,RNN;unitary approach;associative memory;language modeling,8;8;8,5;5;5,-1;-1,usa,usa,n,8;3
857,ICLR,2018,Style Memory: Making a Classifier Network Generative,Rey Wiyatno;Jeff Orchard,rrwiyatn@uwaterloo.ca;jorchard@uwaterloo.ca,3;3;4,5;5;3,Reject,0,4,0.0,yes,10/26/17,University of Waterloo;University of Waterloo,neural networks;autoencoder;generative;feed-back,30;30,207;207,-1;-1,canada,ca,n,5
858,ICLR,2018,CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble Behavior,Xiang Zhang;Nishant Vishwamitra;Hongxin Hu;Feng Luo,xzhang7@clemson.edu;nvishwa@clemson.edu;luofeng@clemson.edu;hongxih@clemson.edu,4;5;4,5;4;5,Reject,4,11,0.0,yes,10/26/17,Clemson University;Clemson University;Clemson University;Clemson University,CNN;ensemble;image recognition,162;162;162;162,-1;-1;-1;-1,-1;-1,canada,ca,n,
859,ICLR,2018,Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy,Hanzhang Hu;Debadeepta Dey;Martial Hebert;J. Andrew Bagnell,hanzhang@cs.cmu.edu;dedey@microsoft.com;hebert@ri.cmu.edu;dbagnell@ri.cmu.edu,7;5;5,2;3;4,Reject,0,0,0.0,yes,10/26/17,Carnegie Mellon University;Microsoft;Carnegie Mellon University;Carnegie Mellon University,anytime;neural network;adaptive prediction;budgeted prediction,1;-1;1;1,24;-1;24;24,-1;-1,usa,usa,n,
860,ICLR,2018,Adversarial Policy Gradient for Alternating Markov Games,Chao Gao;Martin Mueller;Ryan Hayward,cgao3@ualberta.ca;mmueller@ualberta.ca;hayward@ualberta.ca,5;5;5,2;4;4,Invite to Workshop Track,0,6,0.0,yes,10/26/17,University of Alberta;University of Alberta;University of Alberta,,95;95;95,119;119;119,-1;-1,canada,ca,n,4
861,ICLR,2018,THE EFFECTIVENESS OF A TWO-LAYER NEURAL NETWORK FOR RECOMMENDATIONS,Oleg Rybakov;Vijai Mohan;Avishkar Misra;Scott LeGrand;Rejith Joseph;Kiuk Chung;Siddharth Singh;Qian You;Eric Nalisnick;Leo Dirac;Runfei Luo,rybakovo@amazon.com;vijaim@amazon.com;avishkar@gmail.com;slegrand@a9.com;rgeorgej@amazon.com;kiuk@amazon.com;singsidd@amazon.com;qian.you@snapchat.com;enalisni@uci.edu;leodirac@amazon.com;rluo@pstat.ucsb.edu,6;6;7,3;4;3,Invite to Workshop Track,0,4,0.0,yes,10/26/17,"Amazon;Amazon;;A9;Amazon;Amazon;Amazon;Snap Inc.;University of California, Irvine;Amazon;UC Santa Barbara",Recommender systems;deep learning;personalization,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;99;-1;-1,-1;-1,NAN,NAN,n,
862,ICLR,2018,Normalized Direction-preserving Adam,Zijun Zhang;Lin Ma;Zongpeng Li;Chuan Wu,zijun.zhang@ucalgary.ca;linmawhu@gmail.com;zongpeng@ucalgary.ca;cwu@cs.hku.hk,5;5;4,4;5;4,Reject,2,9,0.0,yes,10/26/17,University of Calgary;;University of Calgary;The University of Hong Kong,optimization;generalization;Adam;SGD,162;-1;162;95,210;-1;210;40,-1;-1,NAN,NAN,n,1;9
863,ICLR,2018,Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior,Charles H. Martin;Michael W. Mahoney,charles@calculationconsulting.com;mmahoney@stat.berkeley.edu,3;6;7,3;5;4,Reject,0,9,0.0,yes,10/26/17,Calculationconsulting;University of California Berkeley,,-1;-1,-1;18,-1;-1,usa,usa,n,1
864,ICLR,2018,Learning Non-Metric Visual Similarity for Image Retrieval,Noa Garcia;George Vogiatzis,garciadn@aston.ac.uk;g.vogiatzis@aston.ac.uk,7;4;3,5;4;5,Reject,0,4,0.0,yes,10/26/17,Aston University;Aston University,image retrieval;visual similarity;non-metric learning,82;82,358;358,-1;-1,europe,fi,n,
865,ICLR,2018,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,V√≠ctor Campos;Brendan Jou;Xavier Gir√≥-i-Nieto;Jordi Torres;Shih-Fu Chang,victor.campos@bsc.es;bjou@google.com;xavier.giro@upc.edu;jordi.torres@bsc.es;shih.fu.chang@columbia.edu,6;6;6,4;4;4,Accept (Poster),1,6,0.0,yes,10/26/17,Barcelona Supercomputing Center;Google;Universitat Polit√®cnica de Catalunya;Barcelona Supercomputing Center;Columbia University,recurrent neural networks;dynamic learning;conditional computation,-1;-1;-1;-1;21,-1;-1;-1;-1;14,-1;-1,usa,usa,n,10
866,ICLR,2018,Iterative Deep Compression : Compressing Deep Networks for Classification and Semantic Segmentation,Sugandha Doda;Vitor Fortes Rey;Dr. Nadereh Hatami;Prof. Dr. Paul Lukowicz,sugandhadoda672@gmail.com;vitor.fortes@dfki.uni-kl.de;nadereh.hatamimazinani@de.bosch.com,6;4;5,4;4;4,Reject,0,6,0.0,yes,10/26/17,Bosch;TU Kaiserslautern;Bosch;University of Kaiserslautern,,-1;162;-1,-1;-1;367,-1;-1,NAN,NAN,n,2;3
867,ICLR,2018,Do Deep Reinforcement Learning Algorithms really Learn to Navigate?,Shurjo Banerjee;Vikas Dhiman;Brent Griffin;Jason J. Corso,shurjo@umich.edu;dhiman@umich.edu;griffb@umich.edu;jjcorso@umich.edu,7;3;3,4;5;4,Reject,0,4,0.0,yes,10/26/17,University of Michigan;University of Michigan;University of Michigan;University of Michigan,deep reinforcement learning;navigation;path-planning;mapping,10;10;10;10,21;21;21;21,-1;-1,usa,usa,n,
868,ICLR,2018,Adversarial Learning for Semi-Supervised Semantic Segmentation,Wei-Chih Hung;Yi-Hsuan Tsai;Yan-Ting Liou;Yen-Yu Lin;Ming-Hsuan Yang,whung8@ucmerced.edu;ytsai@nec-labs.com;lyt@csie.ntu.edu.tw;yylin@citi.sinica.edu.tw;mhyang@ucmerced.edu,5;5;5,5;4;4,Reject,5,6,0.0,yes,10/26/17,University of California at Merced;NEC-Labs;Nanyang Technological University;National Tsing Hua University;University of California at Merced,semantic segmentation;adversarial learning;semi-supervised learning;self-taught learning,-1;-1;39;224;-1,-1;-1;52;323;-1,-1;-1,usa,usa,n,2;4
869,ICLR,2018,Towards Interpretable Chit-chat: Open Domain Dialogue Generation with Dialogue Acts,Wei Wu;Can Xu;Yu Wu;Zhoujun Li,wuwei@microsoft.com;can.xu@microsoft.com;wumark@126.com;lizj@buaa.edu.cn,7;4;7,3;5;4,Reject,0,9,0.0,yes,10/26/17,Microsoft;Microsoft;126;Beihang University,dialogue generation;dialogue acts;open domain conversation;supervised learning;reinforcement learning,-1;-1;-1;95,-1;-1;-1;658,-1;-1,asia,cn,n,
870,ICLR,2018,PDE-Net: Learning PDEs from Data,Zichao Long;Yiping Lu;Xianzhong Ma;Bin Dong,zlong@pku.edu.cn;luyiping9712@pku.edu.cn;xianzhongma@pku.edu.cn;dongbin@math.pku.edu.cn,7;8;5,4;4;4,Invite to Workshop Track,0,4,0.0,yes,10/26/17,Peking University;Peking University;Peking University;Peking University,deep convolution network;partial differential equation;physical laws,14;14;14;14,27;27;27;27,-1;-1,asia,cn,y,2;1
871,ICLR,2018,Unleashing the Potential of CNNs for Interpretable Few-Shot Learning,Boyang Deng;Qing Liu;Siyuan Qiao;Alan Yuille,billydeng@buaa.edu.cn;qingliu@jhu.edu;siyuan.qiao@jhu.edu;alan.yuille@jhu.edu,5;7;4,4;4;5,Reject,0,8,0.0,yes,10/26/17,Beihang University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,Few-Shot Learning;Neural Network Understanding;Visual Concepts,95;57;57;57,658;13;13;13,-1;-1,usa,usa,n,6;2
872,ICLR,2018,Clipping Free Attacks Against Neural Networks,Boussad ADDAD,boussad.addad@thalesgroup.com;boussad83@yahoo.fr,3;4;5,3;3;2,Reject,0,4,0.0,yes,10/26/17,Thalesgroup;Thales,Adversarial examples;Neural Networks;Clipping,-1;-1,-1;-1,-1,NAN,NAN,n,2;3;4
873,ICLR,2018,Noisy Networks For Exploration,Meire Fortunato;Mohammad Gheshlaghi Azar;Bilal Piot;Jacob Menick;Matteo Hessel;Ian Osband;Alex Graves;Volodymyr Mnih;Remi Munos;Demis Hassabis;Olivier Pietquin;Charles Blundell;Shane Legg,meirefortunato@google.com;mazar@google.com;piot@google.com;jmenick@google.com;mtthss@google.com;iosband@google.com;gravesa@google.com;vmnih@google.com;munos@google.com;dhcontact@google.com;pietquin@google.com;cblundell@google.com;legg@google.com,5;7;6,3;4;4,Accept (Poster),1,10,0.0,yes,10/26/17,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Deep Reinforcement Learning;Exploration;Neural Networks,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
874,ICLR,2018,The Set Autoencoder: Unsupervised Representation Learning for Sets,Malte Probst,malte.probst@honda-ri.de,4;5;5,5;4;4,Reject,0,2,0.0,yes,10/26/17,Honda Research Institute,set;unsupervised learning;representation learning,-1,-1,-1,NAN,NAN,n,8;3
875,ICLR,2018,Learning to Count Objects in Natural Images for Visual Question Answering,Yan Zhang;Jonathon Hare;Adam Pr√ºgel-Bennett,yz5n12@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,6;6;4,3;3;4,Accept (Poster),0,12,1.0,yes,10/26/17,University of Southampton;University of Southampton;University of Southampton,visual question answering;vqa;counting,224;224;224,126;126;126,-1;-1,europe,uk,n,8
876,ICLR,2018,Sensor Transformation Attention Networks,Stefan Braun;Daniel Neil;Enea Ceolini;Jithendar Anumula;Shih-Chii Liu,brauns@ethz.ch;daniel.l.neil@gmail.com;enea.ceolini@ini.uzh.ch;anumula@ini.uzh.ch;shih@ini.ethz.ch,7;4;3,4;4;4,Reject,0,1,0.0,yes,10/26/17,Swiss Federal Institute of Technology;;University of Zurich;University of Zurich;Swiss Federal Institute of Technology,attention;sensor-selection;multi-sensor;natural noise,-1;-1;125;125;-1,-1;-1;136;136;-1,-1;-1,NAN,NAN,n,8
877,ICLR,2018,CAYLEYNETS: SPECTRAL GRAPH CNNS WITH COMPLEX RATIONAL FILTERS,Ron Levie;Federico Monti;Xavier Bresson;Michael M. Bronstein,ronlevie@gmail.com;federico.monti@usi.ch;xavier.bresson@gmail.com;michael.bronstein@gmail.com,6;4;8,3;3;3,Reject,0,15,0.0,yes,10/26/17,University of Munich;Universit√† della Svizzera Italiana;Nanyang Technological University;Twitter,Deep Learning;Spectral Graph Convolutional Neural Networks,-1;162;39;-1,-1;-1;52;-1,-1;-1,asia,in,y,10
878,ICLR,2018,Convolutional Normalizing Flows,Guoqing Zheng;Yiming Yang;Jaime Carbonell,gzheng@cs.cmu.edu;yiming@cs.cmu.edu;jgc@cs.cmu.edu,3;5;3,5;4;4,Reject,2,4,0.0,yes,10/26/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1,24;24;24,-1;-1,usa,usa,n,11
879,ICLR,2018,Baseline-corrected space-by-time non-negative matrix factorization for decoding single trial population spike trains,Arezoo Alizadeh;Marion Mutter;Thomas M√ºnch;Arno Onken;Stefano Panzeri,arezoo.alizadehkhajehiem@iit.it;marion.mutter@gmx.de;thomas.muench@cin.uni-tuebingen.de;aonken@inf.ed.ac.uk;stefano.panzeri@iit.it,4;6;6,4;3;3,Reject,0,3,0.0,yes,10/26/17,Istituto Italiano di Tecnologia;;University of Tuebingen;University of Edinburgh;Istituto Italiano di Tecnologia,Space-by-time non-negative matrix factorization;dimensionality reduction;baseline correction;neuronal decoding;mutual information,-1;-1;125;30;-1,-1;-1;94;27;-1,-1;-1,NAN,NAN,n,5
880,ICLR,2018,DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images,Taihong Xiao;Jiapeng Hong;Jinwen Ma,xiaotaihong@pku.edu.cn;jphong@pku.edu.cn;jwma@math.pku.edu.cn,4;5;6,4;4;5,Invite to Workshop Track,1,9,0.0,yes,10/26/17,Peking University;Peking University;Peking University,disentangled representations;multi-attribute images;generative adversarial networks,14;14;14,27;27;27,-1;-1,asia,cn,y,4
881,ICLR,2018,Avoiding Catastrophic States with Intrinsic Fear,Zachary C. Lipton;Kamyar Azizzadenesheli;Abhishek Kumar;Lihong Li;Jianfeng Gao;Li Deng,zlipton@cmu.edu;kazizzad@uci.edu;abkumar@ucsd.edu;lihongli.cs@gmail.com;jfgao@microsoft.com;l.deng@ieee.org,5;5;7,4;5;3,Reject,1,12,0.0,yes,10/26/17,"Carnegie Mellon University;University of California, Irvine;University of California, San Diego;Amazon;Microsoft;University of Waterloo",reinforcement learning;safe exploration;dqn,1;-1;-1;-1;-1;-1,24;99;31;-1;-1;-1,-1;-1,asia,in,n,
882,ICLR,2018,DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer,Joseph Suarez;Justin Johnson;Fei-Fei Li,joseph15@stanford.edu;jcjohns@cs.stanford.edu;feifeili@cs.stanford.edu,5;5;6,2;2;2,Reject,0,6,0.0,yes,10/26/17,Stanford University;Stanford University;Stanford University,CLEVR;VQA;Visual Question Answering;Neural Programmer,5;5;5,3;3;3,-1;-1,usa,usa,n,
883,ICLR,2018,Espresso: Efficient Forward Propagation for Binary Deep Neural Networks,Fabrizio Pedersoli;George Tzanetakis;Andrea Tagliasacchi,fpeder@uvic.ca;gtzan@uvic.ca;ataiya@uvic.ca,6;7;7,3;4;1,Accept (Poster),0,0,0.0,yes,10/26/17,University of Victoria;University of Victoria;University of Victoria,binary deep neural networks;optimized implementation;bitwise computations,162;162;162,346;346;346,-1;-1,europe,cy,n,
884,ICLR,2018,LatentPoison -- Adversarial Attacks On The Latent Space,Antonia Creswell;Biswa Sengupta;Anil A. Bharath,ac2211@ic.ac.uk;b.sengupta@imperial.ac.uk;a.bharath@imperial.ac.uk,5;3;4,3;4;4,Reject,0,3,0.0,yes,10/26/17,Imperial College London;Imperial College London;Imperial College London,adversarial attacks;security;auto-encoder,49;49;49,8;8;8,-1;-1,europe,uk,n,5;4
885,ICLR,2018,PACT: Parameterized Clipping Activation for Quantized Neural Networks,Jungwook Choi;Zhuo Wang;Swagath Venkataramani;Pierce I-Jen Chuang;Vijayalakshmi Srinivasan;Kailash Gopalakrishnan,choij@us.ibm.com,5;5;5,4;5;4,Reject,0,8,0.0,yes,10/26/17,International Business Machines,deep learning;quantized deep neural network;activation quantization,-1,-1,-1;-1,NAN,NAN,n,
886,ICLR,2018,Understanding Grounded Language Learning Agents,Felix Hill;Karl Moritz Hermann;Phil Blunsom;Stephen Clark,felixhill@google.com;kmh@google.com;pblunsom@google.com;clarkstephen@google.com,4;5;7,5;3;4,Reject,0,6,0.0,yes,10/26/17,Google;Google;Google;Google,Language AI Learning Reinforcement Deep,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
887,ICLR,2018,APPLICATION OF DEEP CONVOLUTIONAL NEURAL NETWORK TO PREVENT ATM FRAUD BY FACIAL DISGUISE IDENTIFICATION,Suraj Nandkishor Kothawade;Sumit Baburao Tamgale,kothawadesuraj@sggs.ac.in;tamgalesumit@sggs.ac.in,1;2;3,5;4;5,Reject,0,0,0.0,yes,10/26/17,Shri Guruji Gobind Singhji Institute of Engineering and Technology;Shri Guruji Gobind Singhji Institute of Engineering and Technology,Deep Convolutional Neural Network;Disguised Face Identification;Fraudulent Transaction;ATM;Impersonation;,-1;-1,-1;-1,-1;-1,asia,in,n,
888,ICLR,2018,Discrete Sequential Prediction of Continuous Actions for Deep RL,Luke Metz;Julian Ibarz;Navdeep Jaitly;James Davidson,lmetz@google.com;julianibarz@google.com;njaitly@google.com;jcdavidson@google.com,7;5;4,5;1;5,Reject,0,4,0.0,yes,10/26/17,Google;Google;Google;Google,Reinforcement learning;continuous control;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
889,ICLR,2018,An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems.,Yiping Song;Rui Yan;Cheng-Te Li;Jian-Yun Nie;Ming Zhang;Dongyan Zhao,songyiping@pku.edu.cn;ruiyan@pku.edu.cn;chengte@mail.ncku.edu.tw;nie@iro.umontreal.ca;mzhang_cs@pku.edu.cn;zhaody@pku.edu.cn,5;5;6,3;3;3,Reject,0,0,1.0,yes,10/26/17,Peking University;Peking University;Peking University;University of Montreal;Peking University;Peking University,conversation systems;retrieval method;generation method,14;14;14;125;14;14,27;27;27;108;27;27,-1;-1,asia,cn,n,8;3;5
890,ICLR,2018,Multi-Advisor Reinforcement Learning,Romain Laroche;Mehdi Fatemi;Joshua Romoff;Harm van Seijen,romain.laroche@gmail.com;mehdi.fatemi@microsoft.com;joshua.romoff@mail.mcgill.ca;havansei@microsoft.com,4;4;4,4;4;5,Reject,0,1,0.0,yes,10/26/17,Microsoft;Microsoft;McGill University;Microsoft,Reinforcement Learning,-1;-1;95;-1,-1;-1;42;-1,-1;-1,NAN,NAN,y,
891,ICLR,2018,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,Glen Berseth;Cheng Xie;Paul Cernek;Michiel Van de Panne,gberseth@gmail.com;cheng.k.xie@gmail.com;pcernek@cs.ubc.ca;van@cs.ubc.ca,7;7;5,4;4;3,Accept (Poster),0,6,0.0,yes,10/26/17,University of California Berkeley;University of Toronto;University of British Columbia;University of British Columbia,Reinforcement Learning;Distillation;Transfer Learning;Continual Learning,-1;21;67;67,18;22;34;34,-1;-1,canada,ca,n,6
892,ICLR,2018,UNSUPERVISED METRIC LEARNING VIA NONLINEAR FEATURE SPACE TRANSFORMATIONS,Pin Zhang;Bibo Shi;JundongLiu,pz335412@ohio.edu;bibo.shi@duke.edu;liuj1@ohio.edu,6;4;4,4;5;4,Reject,0,0,0.0,yes,10/26/17,Ohio University;Duke University;Ohio University,Metric Learning;K-means;CPD;Clustering,377;39;377,627;17;627,-1;-1,asia,jp,n,
893,ICLR,2018,Learning Deep Generative Models With Discrete Latent Variables,Hengyuan Hu;Ruslan Salakhutdinov,hengyuah@andrew.cmu.edu;rsalakhu@cs.cmu.edu,4;5;4,4;4;4,Reject,2,3,0.0,yes,10/26/17,Carnegie Mellon University;Carnegie Mellon University,deep generative models;deep learning,1;1,24;24,-1;-1,usa,usa,n,10;5
894,ICLR,2018,Novelty Detection with GAN,Mark Kliger;Shachar Fleishman,mark.kliger@gmail.com;shacharfl@gmail.com,4;5;6,4;4;4,Reject,0,3,0.0,yes,10/26/17,University of Michigan;Scientific Computing and Imaging Institute,novelty detection;GAN;feature matching;semi-supervised,-1;-1,-1;-1,-1;-1,asia,in,y,5;4
895,ICLR,2018,A Self-Organizing Memory Network,Callie Federer;Joel Zylberberg,callie.federer@ucdenver.edu;joel.zylberberg@ucdenver.edu,3;4;4,2;4;4,Reject,0,0,0.0,yes,10/26/17,"University of Colorado, Denver;University of Colorado, Denver",Working Memory;Learning Rules;Stimulus Representations,-1;-1,286;286,-1;-1,usa,usa,n,
896,ICLR,2018,The Cramer Distance as a Solution to Biased Wasserstein Gradients,Marc G. Bellemare;Ivo Danihelka;Will Dabney;Shakir Mohamed;Balaji Lakshminarayanan;Stephan Hoyer;Remi Munos,bellemare@google.com;danihelka@google.com;shakir@google.com;balajiln@google.com;shoyer@google.com;munos@google.com,5;4;7,3;5;2,Reject,1,4,0.0,yes,10/26/17,Google;Google;Google;Google;Google;Google,Probability metrics;Wasserstein metric;stochastic gradient descent;GANs,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,8;5;4
897,ICLR,2018,DEEP DENSITY NETWORKS AND UNCERTAINTY IN RECOMMENDER SYSTEMS,Yoel Zeldes;Stavros Theodorakis;Efrat Solodnik;Aviv Rotman;Gil Chamiel;Dan Friedman,yoel.z@taboola.com;sth@deeplab.ai;efrat.s@taboola.com;aviv.r@taboola.com;gil.c@taboola.com;dan.f@taboola.com,4;3;4,5;4;3,Reject,0,0,0.0,yes,10/26/17,Taboola;DeepLab;Taboola;Taboola;Taboola;Taboola,deep learning;recommendation system;uncertainty;context-based and collaborative filtering,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
898,ICLR,2018,PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training,Meng Li;Liangzhen Lai;Naveen Suda;Vikas Chandra;David Z. Pan,meng_li@utexas.edu;liangzhen.lai@arm.com;naveen.suda@arm.com;vikas.chandra@arm.com;dpan@ece.utexas.edu,6;5;3,5;3;3,Reject,1,0,0.0,yes,10/26/17,"University of Texas, Austin;arm;arm;arm;University of Texas, Austin",Privacy-preserving deep learning;Neural network training,-1;57;57;57;-1,-1;244;244;244;-1,-1;-1,usa,usa,n,
899,ICLR,2018,Simple Fast Convolutional Feature Learning,David Mac√™do;Cleber Zanchettin;Teresa Ludermir,dlm@cin.ufpe.br;cz@cin.ufpe.br;tbl@cin.ufpe.br,3;3;2,4;4;4,Reject,0,5,0.0,yes,10/26/17,"Universidade Federal de Pernambuco, Federal University of Pernambuco;Universidade Federal de Pernambuco, Federal University of Pernambuco;Universidade Federal de Pernambuco, Federal University of Pernambuco",Feature Learning;Convolutional Neural Networks;Visual Recognition,-1;-1;-1,958;958;958,-1;-1,NAN,NAN,n,
900,ICLR,2018,Enhancing Batch Normalized Convolutional Networks using Displaced Rectifier Linear Units: A Systematic Comparative Study,David Mac√™do;Cleber Zanchettin;Adriano L. I. Oliveira;Teresa Ludermir,dlm@cin.ufpe.br;cz@cin.ufpe.br;alio@cin.ufpe.br;tbl@cin.ufpe.br,3;4;5,5;4;5,Reject,0,4,0.0,yes,10/26/17,"Universidade Federal de Pernambuco, Federal University of Pernambuco;Universidade Federal de Pernambuco, Federal University of Pernambuco;Universidade Federal de Pernambuco, Federal University of Pernambuco;Universidade Federal de Pernambuco, Federal University of Pernambuco",Batch Normalized;Convolutional Neural Networks;Displaced Rectifier Linear Unit;Comparative Study,-1;-1;-1;-1,958;958;958;958,-1;-1,NAN,NAN,n,8;2
901,ICLR,2018,ANALYSIS ON GRADIENT PROPAGATION IN BATCH NORMALIZED RESIDUAL NETWORKS,Abhishek Panigrahi;Yueru Chen;C.-C. Jay Kuo,abhishekpanigrahi@iitkgp.ac.in;yueruche@usc.edu;cckuo@sipi.usc.edu,4;1;4,4;5;5,Reject,0,0,0.0,yes,10/26/17,Indian Institute of Technology Kharagpur;University of Southern California;University of Southern California,Batch normalization;gradient backpropagation;Residual network;wide residual network,-1;27;27,506;66;66,-1;-1,usa,usa,n,
902,ICLR,2018,Deterministic Policy Imitation Gradient Algorithm,Fumihiro Sasaki;Atsuo Kawaguchi,fumihiro.fs.sasaki@nts.ricoh.co.jp;atsuo.kawaguchi@nts.ricoh.co.jp,6;5;5,4;4;3,Reject,0,3,0.0,yes,10/26/17,"Ricoh Company, Ltd.;Ricoh Company, Ltd.",Imitation Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,5;4
903,ICLR,2018,Data augmentation instead of explicit regularization,Alex Hern√°ndez-Garc√≠a;Peter K√∂nig,alexhg15@gmail.com;pkoenig@uos.de,5;5;5,4;4;4,Reject,0,5,0.0,yes,9/25/19,University of Montreal;Universität Osnabrück,deep learning;data augmentation;regularization,-1;377,-1;-1,m;m,europe,de,n,1
904,ICLR,2018,Neural Clustering By Predicting And Copying Noise,Sam Coope;Andrej Zukov-Gregoric;Yoram Bachrach,sam@digitalgenius.com;andrej@digitalgenius.com;yoram@digitalgenius.com,5;5;5,4;3;4,Reject,3,4,0.0,yes,10/26/17,DigitalGenius Ltd.;DigitalGenius Ltd.;DigitalGenius Ltd.,unsupervised learning;clustering;deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
905,ICLR,2018,Generative Adversarial Networks using Adaptive Convolution,Nhat M. Nguyen;Nilanjan Ray,nmnguyen@ualberta.ca;nray1@ualberta.ca,4;4;4,5;4;5,Reject,0,0,0.0,yes,10/26/17,University of Alberta;University of Alberta,Generative Adversarial Networks;Unsupervised Learning;GANs,95;95,119;119,-1;-1,canada,ca,n,5
906,ICLR,2018,Deep Rewiring: Training very sparse deep networks,Guillaume Bellec;David Kappel;Wolfgang Maass;Robert Legenstein,bellec@igi.tugraz.at;kappel@igi.tugraz.at;maass@igi.tugraz.at;legenstein@igi.tugraz.at,8;5;6,4;5;4,Accept (Poster),0,0,1.0,yes,10/26/17,Graz University of Technology;Graz University of Technology;Graz University of Technology;Graz University of Technology,deep learning;pruning;LSTM;convolutional networks;recurrent neural network;sparse networks;neuromorphic hardware;energy efficient computing;low memory hardware;stochastic differential equation;fokker-planck equation,95;95;95;95,443;443;443;443,-1;-1,europe,cz,y,1
907,ICLR,2018,Network Iterative Learning for Dynamic Deep Neural Networks via Morphism,Tao Wei;Changhu Wang;Chang Wen Chen,taowei@buffalo.edu;wangchanghu@toutiao.com;chencw@buffalo.edu,7;5;5,4;2;3,Reject,0,0,0.0,yes,10/26/17,"State University of New York, Buffalo;Toutiao AI Lab;State University of New York, Buffalo",Network Iterative Learning;Morphism,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
908,ICLR,2018,Generalized Graph Embedding Models,Qiao Liu;Xiaohui Yang;Rui Wan;Shouzhong Tu;Zufeng Wu,qliu@uestc.edu.cn;yangxhui@uestc.std.edu.cn;rwan@uestc.std.edu.cn;tusz11@mails.tsinghua.edu.cn;wuzufeng@uestc.edu.cn,6;4;3,4;4;4,Reject,0,0,0.0,yes,10/26/17,"University of Electronic Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China;Tsinghua University, Tsinghua University;University of Electronic Science and Technology of China",representation learning;knowledge graphs;relational inference;link prediction;multi-label classification;knowledge base completion,-1;-1;-1;5;-1,843;132;132;30;843,-1;-1,NAN,NAN,n,10
909,ICLR,2018,Discriminative k-shot learning using probabilistic models,Matthias Bauer;Mateo Rojas-Carulla;Jakub Bart≈Çomiej ≈öwiƒÖtkowski;Bernhard Sch√∂lkopf;Richard E. Turner,msb55@cam.ac.uk;mrojascarulla@gmail.com;kuba.swiatkowski@gmail.com;bs@tuebingen.mpg.de;ret26@cam.ac.uk,5;5;5,3;3;3,Reject,0,4,0.0,yes,10/26/17,University of Cambridge;;NoMagic;Max-Planck Institute;University of Cambridge,discriminative k-shot learning;probabilistic inference,82;-1;-1;-1;82,2;-1;-1;-1;2,-1;-1,europe,uk,n,
910,ICLR,2018,Link Weight Prediction with Node Embeddings,Yuchen Hou;Lawrence B. Holder,yuchen.hou@wsu.edu;holder@wsu.edu,3;3;4,4;5;3,Reject,0,0,0.0,yes,10/26/17,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1,352;352,-1;-1,NAN,NAN,n,3;10
911,ICLR,2018,Learning Independent Causal Mechanisms,Giambattista Parascandolo;Mateo Rojas Carulla;Niki Kilbertus;Bernhard Schoelkopf,gparascandolo@tue.mpg.de;mrojascarulla@gmail.com;nkilbertus@tue.mpg.de;bs@tue.mpg.de,6;5;5,4;4;4,Reject,0,6,0.0,yes,10/26/17,Max-Planck Institute;;Max-Planck Institute;Max-Planck Institute,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
912,ICLR,2018,DNN Feature Map Compression using Learned Representation over GF(2),Denis A. Gudovskiy;Alec Hodgkinson;Luca Rigazio,denis.gudovskiy@us.panasonic.com;alec.hodgkinson@us.panasonic.com;luca.rigazio@us.panasonic.com,7;5;4,3;4;4,Reject,0,4,0.0,yes,10/26/17,Panasonic Corp;Panasonic Corp;Panasonic Corp,feature map;representation;compression;quantization;finite-field,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,2
913,ICLR,2018,A Bayesian Perspective on Generalization and Stochastic Gradient Descent,Samuel L. Smith and Quoc V. Le,slsmith@google.com;qvl@google.com,3;7;7,4;4;3,Accept (Poster),2,12,0.0,yes,10/26/17,Google;Google,generalization;stochastic gradient descent;stochastic differential equations;scaling rules;large batch training;bayes theorem;batch size,-1;-1,-1;-1,-1;-1,NAN,NAN,n,11;1
914,ICLR,2018,Mixed Precision Training,Paulius Micikevicius;Sharan Narang;Jonah Alben;Gregory Diamos;Erich Elsen;David Garcia;Boris Ginsburg;Michael Houston;Oleksii Kuchaiev;Ganesh Venkatesh;Hao Wu,pauliusm@nvidia.com;sharan@baidu.com;alben@nvidia.com;gdiamos@baidu.com;eriche@google.com;dagarcia@nvidia.com;bginsburg@nvidia.com;mhouston@nvidia.com;okuchaiev@nvidia.com;gavenkatesh@nvidia.com;skyw@nvidia.com,8;5;7,4;3;4,Accept (Poster),0,6,0.0,yes,10/26/17,NVIDIA;Baidu;NVIDIA;Baidu;Google;NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA,Half precision;float16;Convolutional neural networks;Recurrent neural networks,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
915,ICLR,2018,Multiscale Hidden Markov Models For Covariance Prediction,Jo√£o Sedoc;Jordan Rodu;Dean Foster;Lyle Ungar,joao@cis.upenn.edu;jsr6q@virginia.edu;dean@foster.net;ungar@cis.upenn.edu,5;6;6,3;4;4,Reject,0,3,0.0,yes,10/26/17,University of Pennsylvania;University of Virginia;;University of Pennsylvania,multiscale models;hidden Markov model;covariance prediction,15;57;-1;15,10;113;-1;10,-1;-1,usa,usa,n,5
916,ICLR,2018,Latent Topic Conversational Models,Tsung-Hsien Wen;Minh-Thang Luong,thw28@cam.ac.uk;thangluong@google.com,4;5;6,3;4;4,Reject,0,8,0.0,yes,10/26/17,University of Cambridge;Google,conversational modeling;dialogue;chitchat;open-domain dialogue;topic model;neural variational inference;human evaluation;latent variable model;gaussian reparameterisation trick,82;-1,2;-1,-1;-1,NAN,NAN,n,
917,ICLR,2018,Recurrent Auto-Encoder Model for Multidimensional Time Series Representation,Timothy Wong;Zhiyuan Luo,timothy.wong@centrica.com;zhiyuan.luo@cs.rhul.ac.uk,2;2;4,4;5;4,Reject,0,4,0.0,yes,10/26/17,"Royal Holloway, University of London;Royal Holloway, University of London",recurrent autoencoder;seq2seq;rnn;multidimensional time series;clustering;sensor;signal analysis;industrial application,125;125,195;195,-1;-1,europe,uk,n,
918,ICLR,2018,Sparse-Complementary Convolution for Efficient Model Utilization on CNNs,Chun-Fu (Richard) Chen;Jinwook Oh;Quanfu Fan;Marco Pistoia;Gwo Giun (Chris) Lee,chenrich@us.ibm.com;ohj@us.ibm.com;qfan@us.ibm.com;pistoia@us.ibm.com;clee@mail.ncku.edu.tw,6;5;5,5;4;4,Reject,0,5,0.0,yes,10/26/17,International Business Machines;International Business Machines;International Business Machines;International Business Machines;Peking University,CNN;sparse convolution;sparse kernel;sparsity;model utilization;image classification,-1;-1;-1;-1;14,-1;-1;-1;-1;27,-1;-1,asia,cn,n,
919,ICLR,2018,Achieving morphological agreement with Concorde,Daniil Polykovskiy;Dmitry Soloviev,daniil.polykovskiy@gmail.com;d.soloviev@corp.mail.ru,2;5;6,5;4;5,Reject,0,0,0.0,yes,10/26/17,Insilico Medicine;Mail.ru Group,NLP;morphology;seq2seq,-1;-1,-1;-1,-1;-1,asia,in,n,
920,ICLR,2018,Discrete-Valued Neural Networks Using Variational Inference,Wolfgang Roth;Franz Pernkopf,roth@tugraz.at;pernkopf@tugraz.at,6;5;5,1;4;4,Reject,0,3,0.0,yes,10/27/17,Graz University of Technology;Graz University of Technology,low-precision;neural networks;resource efficient;variational inference;Bayesian,95;95,443;443,-1;-1,europe,cz,n,11
921,ICLR,2018,Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs),Brad Carlile;Guy Delamarter;Paul Kinney;Akiko Marti;Brian Whitney,bradcarlile@yahoo.com;info@aiperf.com,4;5;3,4;4;4,Reject,3,1,0.0,yes,10/27/17,AI Perf Eng;Aiperf,Deep learning;Theory,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
922,ICLR,2018,Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features,Luis Armona;Jos√© P. Gonz√°lez-Brenes;Ralph Edezhath,luisarmona@gmail.com;jgonzalez@chegg.com;ralph.angelus@gmail.com,7;2;7,3;2;5,Reject,0,6,0.0,yes,10/27/17,"Stanford University;Chegg;University of California, Davis",unsupervised learning;supervised learning;knowledge representation;deep learning,5;-1;-1,3;-1;-1,-1;-1,asia,in,y,
923,ICLR,2018,Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs,Jean Maillard;Stephen Clark;Dani Yogatama,jean@maillard.it;sc609@cam.ac.uk;dyogatama@google.com,5;6;4,4;4;4,Reject,0,0,0.0,yes,10/27/17,Facebook;University of Cambridge;Google,hierarchical;tree-lstm;treelstm;syntax;composition,-1;82;-1,-1;2;-1,-1;-1,NAN,NAN,n,8;3
924,ICLR,2018,COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS,Anuroop Sriram;Heewoo Jun;Sanjeev Satheesh;Adam Coates,anuroop.sriram@gmail.com;junheewoo@baidu.com;sanjeevsatheesh@baidu.com;adamcoates@baidu.com,5;6;5,5;5;5,Invite to Workshop Track,0,0,0.0,yes,10/27/17,Facebook;Baidu;Baidu;Baidu,Sequence-to-Sequence Models;Speech Recognition;Language Models,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;8;1
925,ICLR,2018,Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum,Omer Levy;Kenton Lee;Nicholas FitzGerald;Luke Zettlemoyer,omerlevy@gmail.com;kentonl@cs.washington.edu;nfitz@cs.washington.edu;lsz@cs.washington.edu,6;5;7,4;5;3,Reject,8,5,0.0,yes,10/27/17,Tel Aviv University;University of Washington;University of Washington;University of Washington,,30;8;8;8,217;25;25;25,-1;-1,usa,usa,n,3
926,ICLR,2018,AUTOMATED DESIGN USING NEURAL NETWORKS AND GRADIENT DESCENT,Oliver Hennigh,loliverhennigh101@gmail.com,5;7;4,4;4;5,Invite to Workshop Track,0,0,0.0,yes,10/27/17,0,Deep Learning;Automated Design;Gradient Descent,,,-1,NAN,NAN,n,
927,ICLR,2018,Tensor Contraction & Regression Networks,Jean Kossaifi;Zack Chase Lipton;Aran Khanna;Tommaso Furlanello;Anima Anandkumar,jean.kossaifi@gmail.com;zlipton@cmu.edu;arankhan@amazon.com;tfurlanello@gmail.com;animakumar@gmail.com,4;6;4,4;4;3,Reject,0,5,0.0,yes,10/27/17,NVIDIA;Carnegie Mellon University;Amazon;;California Institute of Technology,tensor contraction;tensor regression;network compression;deep neural networks,-1;1;-1;-1;125,-1;24;-1;-1;3,-1;-1,usa,usa,n,
928,ICLR,2018,Fixing Weight Decay Regularization in Adam,Ilya Loshchilov;Frank Hutter,ilya.loshchilov@gmail.com;fh@cs.uni-freiburg.de,7;4;8,4;4;3,Reject,0,18,1.0,yes,10/27/17,University of Freiburg;University of Freiburg,Adam;Adaptive Gradient Methods;weight decay;L2 regularization,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
929,ICLR,2018,Exploring the Space of Black-box Attacks on Deep Neural Networks,Arjun Nitin Bhagoji;Warren He;Bo Li;Dawn Song,abhagoji@princeton.edu;_w@eecs.berkeley.edu;lxbosky@gmail.com;dawnsong@gmail.com,5;6;7,4;3;4,Reject,3,6,0.0,yes,10/27/17,Princeton University;University of California Berkeley;University of California Berkeley;University of California Berkeley,adversarial machine learning;black-box attacks,30;-1;-1;-1,7;18;18;18,-1;-1,usa,usa,n,4
930,ICLR,2018,Code Synthesis with Priority Queue Training,Daniel A. Abolafia;Quoc V. Le;Mohammad Norouzi,danabo@google.com;qvl@google.com;mnorouzi@google.com,6;5;6,4;3;4,Reject,0,8,2.0,yes,10/27/17,Google;Google;Google,code synthesis;program synthesis;genetic algorithm;reinforcement learning;policy gradient;reinforce;priority queue;topk buffer;bf;code golf;rnn,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
931,ICLR,2018,Implicit Causal Models for Genome-wide Association Studies,Dustin Tran;David M. Blei,dustin@cs.columbia.edu;david.blei@columbia.edu,5;6;6,5;5;5,Accept (Poster),0,12,0.0,yes,10/27/17,Columbia University;Columbia University,,21;21,14;14,-1;-1,usa,usa,y,11;5
932,ICLR,2018,Learning what to learn in a neural program,Richard Shin;Dawn Song,ricshin@berkeley.edu;dawnsong.travel@gmail.com,5;4;5,4;4;2,Reject,3,3,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley,,-1;-1,18;18,-1;-1,usa,usa,n,1
933,ICLR,2018,Generative Models for Alignment and Data Efficiency in Language,Dustin Tran;Yura Burda;Ilya Sutskever,dustin@cs.columbia.edu;yburda@openai.com;ilyasu@openai.com,5;4;2,3;3;3,Reject,0,0,0.0,yes,10/27/17,Columbia University;OpenAI;OpenAI,,21;-1;-1,14;-1;-1,-1;-1,NAN,NAN,n,3
934,ICLR,2018,Maintaining cooperation in complex social dilemmas using deep reinforcement learning,Alexander Peysakhovich;Adam Lerer,alex.peys@gmail.com;alerer@fb.com,4;4;3,4;4;5,Reject,0,15,0.0,yes,10/27/17,Facebook;Facebook,reinforcement learning;cooperation;social dilemmas;game theory,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
935,ICLR,2018,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN,Xu Chen;Jiang Wang;Hao Ge,chenxugz@gmail.com;wangjiangb@gmail.com;haoge2013@u.northwestern.edu,7;6;7,4;4;3,Accept (Poster),0,14,0.0,yes,10/27/17,Northwestern University;;Northwestern University,GAN;Primal-Dual Subgradient;Mode Collapse;Saddle Point,-1;-1;49,-1;-1;20,-1;-1,usa,usa,y,1;5;4;9
936,ICLR,2018,Stochastic Training of Graph Convolutional Networks,Jianfei Chen;Jun Zhu,chenjian14@mails.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,3;4;7,4;4;3,Reject,0,9,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Graph convolutional networks;stochastic gradient descent;variance reduction;control variate,5;5,30;30,-1;-1,NAN,NAN,y,10
937,ICLR,2018,Transformation Autoregressive Networks,Junier Oliva;Avinava Dubey;Barnab√°s P√≥czos;Eric P. Xing;Jeff Schneider,joliva@cs.cmu.edu;akdubey@cs.cmu.edu;bapoczos@cs.cmu.edu;epxing@cs.cmu.edu;schneide@cs.cmu.edu,5;5;8,3;2;4,Reject,0,6,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,density estimation;autoregressive models;RNNs,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,n,
938,ICLR,2018,SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning,Xiaojun Xu;Chang Liu;Dawn Song,xuxiaojun1005@gmail.com;liuchang@eecs.berkeley.edu;dawnsong@cs.berkeley.edu,4;7;5,5;4;5,Reject,0,10,0.0,yes,10/27/17,"University of Illinois, Urbana Champaign;University of California Berkeley;University of California Berkeley",,-1;-1;-1,-1;18;18,-1;-1,usa,usa,n,8;3;10
939,ICLR,2018,Nearest Neighbour Radial Basis Function Solvers for Deep Neural Networks,Benjamin J. Meyer;Ben Harwood;Tom Drummond,benjamin.meyer@monash.edu;ben.harwood@monash.edu;tom.drummond@monash.edu,5;3;4,4;4;4,Reject,0,3,0.0,yes,10/27/17,Monash University;Monash University;Monash University,,82;82;82,80;80;80,-1;-1,australasia,au,n,
940,ICLR,2018,Deep Learning Inferences with Hybrid Homomorphic Encryption,Anthony Meehan;Ryan K L Ko;Geoff Holmes,anthonymeehan@anthonymeehan.com;ryan.ko@waikato.ac.nz;geoff@waikato.ac.nz,4;4;4,4;5;5,Reject,0,4,0.0,yes,10/27/17,The University of Adelaide;The University of Waikato;The University of Waikato,deep learning;homomorphic encryption;hybrid homomorphic encryption;privacy preserving;representation learning;neural networks,95;377;377,134;393;393,-1;-1,NAN,NAN,n,
941,ICLR,2018,Adversarial reading networks for machine comprehension,Quentin Grail;Julien Perez,julien.perez@naverlabs.com,4;5;5,5;5;4,Reject,0,1,0.0,yes,10/27/17,Naver Labs Europe,machine reading;adversarial training,-1,-1,-1;-1,NAN,NAN,n,8;3;4
942,ICLR,2018,Log-DenseNet: How to Sparsify a DenseNet,Hanzhang Hu;Debadeepta Dey;Allie Del Giorno;Martial Hebert;J. Andrew Bagnell,hanzhang@cs.cmu.edu;dedey@microsoft.com;adelgior@ri.cmu.edu;hebert@ri.cmu.edu;dbagnell@ri.cmu.edu,6;6;5,4;4;4,Reject,0,0,0.0,yes,10/27/17,Carnegie Mellon University;Microsoft;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,DenseNet;sparse shortcut connections;network architecture;scene parsing;image classification,1;-1;1;1;1,24;-1;24;24;24,-1;-1,usa,usa,y,2
943,ICLR,2018,Contextual memory bandit for pro-active dialog engagement,julien perez;Tomi Silander,julien.perez@naverlabs.com,2;3;3,5;4;4,Reject,0,0,0.0,yes,10/27/17,Naver Labs Europe,contextual bandit;memory network;proactive dialog engagement,-1,-1,-1;-1,NAN,NAN,n,8
944,ICLR,2018,Sequence Transfer Learning for Neural Decoding,Venkatesh Elango*;Aashish N Patel*;Kai J Miller;Vikash Gilja,velango@eng.ucsd.edu;anp054@eng.ucsd.edu;kai.miller@stanford.edu;vgilja@eng.ucsd.edu,4;6;3,5;5;4,Reject,0,5,0.0,yes,10/27/17,"University of California, San Diego;University of California, San Diego;Stanford University;University of California, San Diego",Transfer Learning;Applications;Neural decoding,-1;-1;5;-1,31;31;3;31,-1;-1,usa,usa,n,6
945,ICLR,2018,Unbiased scalable softmax optimization,Francois Fagan;Garud Iyengar,ff2316@columbia.edu;garud@ieor.columbia.edu,5;5;5,4;3;4,Reject,0,4,0.0,yes,10/27/17,Columbia University;Columbia University,softmax;optimization;implicit sgd,21;21,14;14,-1;-1,usa,usa,y,3
946,ICLR,2018,BLOCK-DIAGONAL HESSIAN-FREE OPTIMIZATION FOR TRAINING NEURAL NETWORKS,Huishuai Zhang;Caiming Xiong;James Bradbury;Richard Socher,hzhan23@syr.edu;cxiong@salesforce.com;james.bradbury@salesforce.com;richard@socher.org,6;4;6,4;4;4,Reject,0,4,0.0,yes,10/27/17,Syracuse University;SalesForce.com;SalesForce.com;SalesForce.com,deep learning;second-order optimization;hessian free,224;-1;-1;-1,275;-1;-1;-1,-1;-1,NAN,NAN,n,1
947,ICLR,2018,Polar Transformer Networks,Carlos Esteves;Christine Allen-Blanchette;Xiaowei Zhou;Kostas Daniilidis,machc@seas.upenn.edu;allec@seas.upenn.edu;xiaowz@seas.upenn.edu;kostas@seas.upenn.edu,7;7;8,4;4;3,Accept (Poster),0,5,2.0,yes,10/27/17,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,equivariance;invariance;canonical coordinates,15;15;15;15,10;10;10;10,-1;-1,usa,usa,n,8
948,ICLR,2018,Softmax Q-Distribution Estimation for Structured Prediction: A Theoretical Interpretation for RAML,Xuezhe Ma;Pengcheng Yin;Jingzhou Liu;Graham Neubig;Eduard Hovy,xuezhem@cs.cmu.edu;pcyin@cs.cmu.edu;liujingzhou@cs.cmu.edu;gneubig@cs.cmu.edu;hovy@cs.cmu.edu,5;5;6,2;4;3,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,structured prediction;RAML;theory;Bayes decision rule;reward function,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,y,3;11;1
949,ICLR,2018,Learning to Optimize Neural Nets,Ke Li;Jitendra Malik,ke.li@eecs.berkeley.edu;jitendram@google.com,5;6;6,3;4;3,Reject,0,3,0.0,yes,10/27/17,University of California Berkeley;Google,Learning to learn;meta-learning;reinforcement learning;optimization,-1;-1,18;-1,-1;-1,NAN,NAN,n,
950,ICLR,2018,Character Level Based Detection of DGA Domain Names,Bin Yu;Jie Pan;Jiaming Hu;Anderson Nascimento;Martine De Cock,biny@infoblox.com;jiep@uw.edu;huj22@uw.edu;andclay@uw.edu;mdecock@uw.edu,7;5;4,4;3;4,Reject,0,4,0.0,yes,10/27/17,"Infoblox;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle",deep neural networks;short text classification;cybersecurity;domain generation algorithms;malicious domain names,-1;8;8;8;8,-1;25;25;25;25,-1;-1,NAN,NAN,n,
951,ICLR,2018,Data Augmentation by Pairing Samples for Images Classification,Hiroshi Inoue,inouehrs@jp.ibm.com,4;5;6,5;4;4,Reject,1,20,0.0,yes,10/27/17,International Business Machines,Data augmentation;Image classification,-1,-1,m,NAN,NAN,n,
952,ICLR,2018,Weighted Transformer Network for Machine Translation,Karim Ahmed;Nitish Shirish Keskar;Richard Socher,karim.mmm@gmail.com;keskar.nitish@u.northwestern.edu;richard@socher.org,9;4;6,4;4;5,Reject,2,5,0.0,yes,10/27/17,Cornell University;Northwestern University;SalesForce.com,transformer;branching;attention;machine translation,-1;49;-1,-1;20;-1,-1;-1,NAN,NAN,n,8;3
953,ICLR,2018,Principled Hybrids of Generative and Discriminative Domain Adaptation,Han Zhao;Zhenyao Zhu;Junjie Hu;Adam Coates;Geoff Gordon,han.zhao@cs.cmu.edu;zhenyaozhu@baidu.com;junjieh@cmu.edu;adamcoates@baidu.com;ggordon@cs.cmu.edu,6;5;5,3;4;4,Reject,0,5,0.0,yes,10/27/17,Carnegie Mellon University;Baidu;Carnegie Mellon University;Baidu;Carnegie Mellon University,domain adaptation;neural networks;generative models;discriminative models,1;-1;1;-1;1,24;-1;24;-1;24,-1;-1,usa,usa,n,1;5
954,ICLR,2018,Integrating Episodic Memory into a Reinforcement Learning Agent Using Reservoir Sampling,Kenny J. Young;Shuo Yang;Richard S. Sutton,kjyoung@ualberta.ca;rsutton@ualberta.ca;s-yan14@mails.tsinghua.edu.cn,4;4;4,4;3;3,Reject,0,4,0.0,yes,10/27/17,"University of Alberta;University of Alberta;Tsinghua University, Tsinghua University",reinforcement learning;external memory;deep learning;policy gradient;online learning,95;95;5,119;119;30,-1;-1,NAN,NAN,y,
955,ICLR,2018,Relational Multi-Instance Learning for Concept Annotation from Medical Time Series,Sanjay Purushotham;Zhengping Che;Bo Jiang;Tanachat Nilanon;Yan Liu,spurusho@usc.edu;zche@usc.edu;boj@usc.edu;nilanon@usc.edu;yanliu.cs@usc.edu,6;3;3,4;3;5,Reject,0,3,0.0,yes,10/27/17,University of Southern California;University of Southern California;University of Southern California;University of Southern California;University of Southern California,Multi-instance learning;Medical Time Series;Concept Annotation,27;27;27;27;27,66;66;66;66;66,-1;-1,usa,usa,n,8;3
956,ICLR,2018,VOCABULARY-INFORMED VISUAL FEATURE AUGMENTATION FOR ONE-SHOT LEARNING,jianqi ma;hangyu lin;yinda zhang;yanwei fu;xiangyang xue,14302010017@fudan.edu.cn;16210240036@fudan.edu.cn;yindaz@cs.princeton.edu;y.fu@qmul.ac.uk,4;6;5,3;4;4,Reject,0,0,0.0,yes,10/27/17,Fudan University;Fudan University;Princeton University;Queen Mary University London,vocabulary-informed learning;data augmentation,67;67;30;-1,116;116;7;-1,-1;-1,europe,uk,n,
957,ICLR,2018,Understanding Local Minima in Neural Networks by Loss Surface Decomposition,Hanock Kwak;Byoung-Tak Zhang,hnkwak@bi.snu.ac.kr;btzhang@bi.snu.ac.kr,4;5;4,4;4;4,Reject,0,0,0.0,yes,10/27/17,Seoul National University;Seoul National University,neural network;local minima;global minima;saddle point;optimization;loss surface;rectified linear unit;loss surface decomposition;gradient descent,39;39,74;74,-1;-1,asia,kr,y,1
958,ICLR,2018,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,Dongsoo Lee;Daehyun Ahn;Taesu Kim;Pierce I. Chuang;Jae-Joon Kim,dslee3@gmail.com;daehyun.ahn@postech.ac.kr;taesukim@postech.ac.kr;pchuang@us.ibm.com;jaejoon@postech.ac.kr,6;6;7,4;4;3,Accept (Poster),0,4,0.0,yes,10/27/17,Samsung;POSTECH;POSTECH;International Business Machines;POSTECH,pruning;sparse matrix;memory footprint;model size;model compression,-1;125;125;-1;125,-1;137;137;-1;137,-1;-1,asia,kr,n,
959,ICLR,2018,Toward learning better metrics for sequence generation training with policy gradient,Joji Toyama;Yusuke Iwasawa;Kotaro Nakayama;Yutaka Matsuo,toyama@weblab.t.u-tokyo.ac.jp;iwasawa@weblab.t.u-tokyo.ac.jp;nakayama@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,7;4;7,1;3;3,Reject,0,7,0.0,yes,10/27/17,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,sequence generation;reinforcement learning;unsupervised learning;RNN,57;57;57;57,45;45;45;45,-1;-1,NAN,NAN,n,5;4
960,ICLR,2018,Classifier-to-Generator Attack: Estimation of Training Data Distribution from Classifier,Kosuke Kusano;Jun Sakuma,cocuh@mdl.cs.tsukuba.ac.jp;jun@cs.tsukuba.ac.jp,7;4;4,3;3;3,Reject,0,4,0.0,yes,10/27/17,The University of Tsukuba;The University of Tsukuba,Security;Privacy;Model Publication;Generative Adversarial Networks,95;95,468;468,-1;-1,NAN,NAN,n,2;5;4
961,ICLR,2018,Large scale distributed neural network training through online distillation,Rohan Anil;Gabriel Pereyra;Alexandre Passos;Robert Ormandi;George E. Dahl;Geoffrey E. Hinton,rohananil@google.com;pereyra@google.com;apassos@google.com;ormandi@google.com;gdahl@google.com;geoffhinton@google.com,8;4;6,4;3;3,Accept (Poster),0,6,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,distillation;distributed training;neural networks;deep learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
962,ICLR,2018,Better Generalization by Efficient Trust Region Method,Xuanqing Liu;Jason D. Lee;Cho-Jui Hsieh,xqliu@ucdavis.edu;jasondlee88@gmail.com;chohsieh@ucdavis.edu,6;5;6,5;2;3,Reject,0,3,0.0,yes,10/27/17,"University of California, Davis;Princeton University;University of California, Davis",,-1;30;-1,54;7;54,-1;-1,usa,usa,y,1;9
963,ICLR,2018,Enhancing the Transferability of Adversarial Examples with Noise Reduced Gradient,Lei Wu;Zhanxing Zhu;Cheng Tai;Weinan E,leiwu@pku.edu.cn;zhanxing.zhu@pku.edu.cn;chengt@math.princeton.edu;weinan@math.princeton.edu,4;5;5,4;3;4,Reject,0,0,0.0,yes,10/27/17,Peking University;Peking University;Princeton University;Princeton University,black-box attack;adversarial example;deep learning;transferability,14;14;30;30,27;27;7;7,-1;-1,usa,usa,n,4
964,ICLR,2018,Discovering Order in Unordered Datasets: Generative Markov Networks,Yao-Hung Hubert Tsai;Han Zhao;Nebojsa Jojic;Ruslan Salakhutdinov,yaohungt@cs.cmu.edu;han.zhao@cs.cmu.edu;jojic@microsoft.com;rsalakhu@cs.cmu.edu,4;4;4,4;4;4,Reject,0,3,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Microsoft;Carnegie Mellon University,Markov chain;discovering orders;generative model;one-shot,1;1;-1;1,24;24;-1;24,-1;-1,usa,usa,n,5
965,ICLR,2018,Kronecker Recurrent Units,Cijo Jose;Moustapha Cisse;Francois Fleuret,cijo.jose@idiap.ch;moustaphacisse@fb.com;francois.fleuret@idiap.ch,6;5;7,5;4;3,Invite to Workshop Track,0,1,0.0,yes,10/27/17,Idiap Research Institute;Facebook;Idiap Research Institute,Recurrent neural network;Vanishing and exploding gradients;Parameter efficiency;Kronecker matrices;Soft unitary constraint,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
966,ICLR,2018,Characterizing Sparse Connectivity Patterns in Neural Networks,Sourya Dey;Kuan-Wen Huang;Peter A. Beerel;Keith M. Chugg,souryade@usc.edu;kuanwenh@usc.edu;pabeerel@usc.edu;chugg@usc.edu,4;5;4,3;3;3,Reject,0,5,0.0,yes,10/27/17,University of Southern California;University of Southern California;University of Southern California;University of Southern California,Machine learning;Neural networks;Sparse neural networks;Pre-defined sparsity;Scatter;Connectivity patterns;Adjacency matrix;Parameter Reduction;Morse code,27;27;27;27,66;66;66;66,-1;-1,usa,usa,n,1
967,ICLR,2018,Multi-level Residual Networks from Dynamical Systems View,Bo Chang;Lili Meng;Eldad Haber;Frederick Tung;David Begert,bchang@stat.ubc.ca;lilimeng1103@gmail.com;haber@math.ubc.ca;ftung@sfu.ca;david@xtract.ai,7;7;7,4;3;4,Accept (Poster),0,5,0.0,yes,10/27/17,University of British Columbia;University of British Columbia;University of British Columbia;Simon Fraser University;Xtract Technologies Inc,residual networks;dynamical systems,67;67;67;49;-1,34;34;34;253;-1,-1;-1,asia,in,n,2;3
968,ICLR,2018,Pointing Out SQL Queries From Text,Chenglong Wang;Marc Brockschmidt;Rishabh Singh,clwang@cs.washington.edu;mabrocks@microsoft.com;risin@microsoft.com,4;3;7,4;4;4,Reject,0,3,0.0,yes,10/27/17,University of Washington;Microsoft;Microsoft,Program Synthesis;Semantic Parsing;WikiTable;SQL;Pointer Network,8;-1;-1,25;-1;-1,-1;-1,NAN,NAN,n,8;3
969,ICLR,2018,Learning Graph Convolution Filters from Data Manifold,Guokun Lai;Hanxiao Liu;Yiming Yang,guokun@cs.cmu.edu;hanxiaol@cs.cmu.edu;yiming@cs.cmu.edu,4;6;5,5;4;3,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Label Propagation;Depthwise separable convolution;Graph and geometric convolution,1;1;1,24;24;24,-1;-1,usa,usa,n,2;10
970,ICLR,2018,Interpreting Deep Classification Models With Bayesian Inference,Hanshu Yan;Jiashi Feng,eleyanh@nus.edu.sg;elefjia@nus.edu.sg,3;5;3,3;3;4,Reject,0,0,0.0,yes,10/27/17,National University of Singapore;National University of Singapore,,15;15,22;22,-1;-1,asia,sg,n,11;5
971,ICLR,2018,Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization,Ozsel Kilinc;Ismail Uysal,ozsel@mail.usf.edu;iuysal@usf.edu,6;7;7,5;4;3,Accept (Poster),2,9,0.0,yes,10/27/17,University of South Florida;University of South Florida,representation learning;unsupervised clustering;pseudo supervision;graph-based activity regularization;auto-clustering output layer,224;224,255;255,-1;-1,usa,usa,n,10
972,ICLR,2018,Parametric Manifold Learning Via Sparse Multidimensional Scaling,Gautam Pai;Ronen Talmon;Ron Kimmel,paigautam@cs.technion.ac.il;ronen@ef.technion.ac.il;ron@cs.technion.ac.il,5;4;3,5;4;4,Reject,0,3,0.0,yes,10/27/17,"Technion, Technion;Technion, Technion;Technion, Technion",Manifold Learning;Non-linear Dimensionality Reduction;Neural Networks;Unsupervised Learning,21;21;21,-1;-1;-1,-1;-1,NAN,NAN,n,1
973,ICLR,2018,Fast and Accurate Inference with Adaptive Ensemble Prediction for Deep Networks,Hiroshi Inoue,inouehrs@jp.ibm.com,6;5;5,3;4;4,Reject,0,3,0.0,yes,10/27/17,International Business Machines,ensemble;confidence level,-1,-1,m,NAN,NAN,n,1
974,ICLR,2018,Counterfactual Image Networks,Deniz Oktay;Carl Vondrick;Antonio Torralba,denizokt@mit.edu;vondrick@google.com;torralba@mit.edu,4;5;4,4;4;4,Reject,0,1,0.0,yes,10/27/17,Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,computer vision;image segmentation;generative models;adversarial networks;unsupervised learning,8;-1;8,5;-1;5,-1;-1,usa,usa,n,2;5
975,ICLR,2018,Massively Parallel Hyperparameter Tuning,Lisha Li;Kevin Jamieson;Afshin Rostamizadeh;Katya Gonina;Moritz Hardt;Benjamin Recht;Ameet Talwalkar,lishal@cs.ucla.edu;jamieson@cs.washington.edu;rostami@google.com;kgonina@google.com;hardt@berkeley.edu;brecht@berkeley.edu;talwalkar@cmu.edu,5;6;5,5;3;5,Reject,0,5,0.0,yes,9/27/18,"University of California, Los Angeles;University of Washington;Google;Google;University of California Berkeley;University of California Berkeley;Carnegie Mellon University",parallel hyperparameter tuning;deep learning,-1;8;-1;-1;-1;-1;1,15;25;-1;-1;18;18;24,-1;-1,usa,usa,n,
976,ICLR,2018,Hallucinating brains with artificial brains,Peiye Zhuang;Alexander G. Schwing;Oluwasanmi Koyejo,py_zhuang@bupt.edu.cn;aschwing@illinois.edu;sanmi@illinois.edu,8;6;5,5;4;3,Reject,0,4,0.0,yes,10/27/17,"Beijing University of Post and Telecommunication;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",3D fMRI data;Deep Learning;Generative Adversarial Network;Classification,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,5;4
977,ICLR,2018,Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks,Brenden Lake;Marco Baroni,brenden@nyu.edu;marco.baroni@unitn.it,6;7;6,3;4;5,Invite to Workshop Track,0,3,0.0,yes,10/27/17,New York University;University of Trento,sequence-to-sequence recurrent networks;compositionality;systematicity;generalization;language-driven navigation,21;125,27;258,-1;-1,europe,gr,n,3;1;6
978,ICLR,2018,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,Hsin-Yuan Huang;Chenguang Zhu;Yelong Shen;Weizhu Chen,momohuang@gmail.com;chezhu@microsoft.com;yeshen@microsoft.com;wzchen@microsoft.com,7;8;7,5;3;4,Accept (Poster),4,17,3.0,yes,10/27/17,California Institute of Technology;Microsoft;Microsoft;Microsoft,Attention Mechanism;Machine Comprehension;Natural Language Processing;Deep Learning,125;-1;-1;-1,3;-1;-1;-1,-1;-1,NAN,NAN,n,8;1;4
979,ICLR,2018,Multi-task Learning on MNIST Image Datasets,Po-Chen Hsieh;Chia-Ping Chen,st70712@gmail.com;cpchen@cse.nsysu.edu.tw,5;4;5,4;5;3,Reject,0,15,0.0,yes,10/27/17,Purdue University;SUN YAT-SEN UNIVERSITY,multi-task learning;MNIST;image recognition,-1;-1,-1;352,-1;-1,NAN,NAN,n,
980,ICLR,2018,A closer look at the word analogy problem,Siddharth Krishna Kumar,siddharthkumar@upwork.com,2;3;3,5;4;4,Reject,0,0,0.0,yes,10/27/17,Upwork,word2vec;glove;word analogy;word relationships;word vectors,-1,-1,-1,NAN,NAN,n,5
981,ICLR,2018,Learning Deep ResNet Blocks Sequentially using Boosting Theory,Furong Huang;Jordan T. Ash;John Langford;Robert E. Schapire,furongh@cs.umd.edu;jordantash@gmail.com;jcl@microsoft.com;schapire@microsoft.com,5;4;5,4;4;3,Reject,0,7,0.0,yes,10/27/17,"University of Maryland, College Park;Microsoft;Microsoft;Microsoft",residual network;boosting theory;training error guarantee,12;-1;-1;-1,69;-1;-1;-1,-1;-1,NAN,NAN,y,1
982,ICLR,2018,A Flexible Approach to Automated RNN Architecture Generation,Martin Schrimpf;Stephen Merity;James Bradbury;Richard Socher,msch@mit.edu;smerity@smerity.com;james.bradbury@salesforce.com;richard@socher.org,6;4;5,4;4;4,Invite to Workshop Track,0,9,0.0,yes,10/27/17,Massachusetts Institute of Technology;Smerity;SalesForce.com;SalesForce.com,reinforcement learning;architecture search;ranking function;recurrent neural networks;recursive neural networks,8;-1;-1;-1,5;-1;-1;-1,-1;-1,NAN,NAN,n,3
983,ICLR,2018,Large Scale Multi-Domain Multi-Task Learning with MultiModel,Lukasz Kaiser;Aidan N. Gomez;Noam Shazeer;Ashish Vaswani;Niki Parmar;Llion Jones;Jakob Uszkoreit,lukaszkaiser@google.com;aidan.n.gomez@gmail.com;noam@google.com;avaswani@google.com;nikip@google.com;llion@google.com;usz@google.com,6;3;6,3;5;4,Reject,0,6,0.0,yes,10/27/17,Google;;Google;Google;Google;Google;Google,multi-task learning;transfer learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;8
984,ICLR,2018,Learning Generative Models with Locally Disentangled Latent Factors,Brady Neal;Alex Lamb;Sherjil Ozair;Devon Hjelm;Aaron Courville;Yoshua Bengio;Ioannis Mitliagkas,nealb@seas.upenn.edu;alex6200@gmail.com;sherjilozair@gmail.com;erroneus@gmail.com;aaron.courville@gmail.com;yoshua.umontreal@gmail.com;imitliagkas@gmail.com,4;6;3,4;3;4,Reject,0,3,0.0,yes,10/27/17,University of Pennsylvania;;Google;Microsoft;University of Montreal;University of Montreal;University of Montreal,Generative Models;Hierarchical Models;Latent Variable Models,15;-1;-1;-1;125;125;125,10;-1;-1;-1;108;108;108,-1;-1,canada,ca,n,5
985,ICLR,2018,Towards Reverse-Engineering Black-Box Neural Networks,Seong Joon Oh;Max Augustin;Mario Fritz;Bernt Schiele,joon@mpi-inf.mpg.de;maxaug@mpi-inf.mpg.de;mfritz@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de,7;7;5,3;4;4,Accept (Poster),0,8,0.0,yes,10/27/17,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,black box;security;privacy;attack;metamodel;adversarial example;reverse-engineering;machine learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
986,ICLR,2018,A Deep Predictive Coding Network for Learning Latent Representations,Shirin Dora;Cyriel Pennartz;Sander Bohte,shirin.dora@gmail.com;c.m.a.pennartz@uva.nl;s.m.bohte@cwi.nl,4;3;3,4;4;5,Reject,0,0,0.0,yes,10/27/17,University of Amsterdam;University of Amsterdam;Centrum voor Wiskunde en Informatica,Predictive coding;deep neural network;generative model;unsupervised learning;learning latent representations,125;125;-1,59;59;-1,-1;-1,NAN,NAN,n,5
987,ICLR,2018,On Batch Adaptive Training for Deep Learning: Lower Loss and Larger Step Size,Runyao Chen;Kun Wu;Ping Luo,chenrunyao14@mails.ucas.ac.cn;WuKun14@mails.ucas.ac.cn;luop@ict.ac.cn,5;5;4,3;4;3,Reject,0,4,0.0,yes,10/27/17,"Chinese Academy of Sciences;Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",deep learning;optimization,30;30;30,-1;-1;-1,-1;-1,NAN,NAN,n,3
988,ICLR,2018,Training with Growing Sets: A Simple Alternative to Curriculum Learning and Self Paced Learning,Melike Nur Mermer;Mehmet Fatih Amasyali,melike.mermer@izu.edu.tr;mfatih@ce.yildiz.edu.tr,4;6;4,4;3;4,Reject,0,3,0.0,yes,10/27/17,Yildiz Technical University;Yildiz Technical University,Neural networks;Curriculum learning;Self paced learning,-1;-1,-1;904,-1;-1,europe,tr,y,
989,ICLR,2018,Learning to Mix n-Step Returns: Generalizing Lambda-Returns for Deep Reinforcement Learning,Sahil Sharma;Girish Raguvir J *;Srivatsan Ramesh *;Balaraman Ravindran,sahil@cse.iitm.ac.in;girishraguvir@gmail.com;sriramesh4@gmail.com;ravi@cse.iitm.ac.in,5;6;5,3;4;4,Reject,0,3,0.0,yes,10/27/17,Indian Institute of Technology Madras;;;Indian Institute of Technology Madras,Reinforcement Learning;Lambda-Returns,-1;-1;-1;-1,625;-1;-1;625,-1;-1,NAN,NAN,n,1
990,ICLR,2018,Piecewise Linear Neural Networks verification: A comparative study,Rudy Bunel;Ilker Turkaslan;Philip H.S. Torr;Pushmeet Kohli;M. Pawan Kumar,rudy@robots.ox.ac.uk;ilker.turkaslan@lmh.ox.ac.uk;philip.torr@eng.ox.ac.uk;pushmeet@google.com;pawan@robots.ox.ac.uk,6;5;3,3;4;5,Reject,0,7,0.0,yes,10/27/17,University of Oxford;University of Oxford;University of Oxford;Google;University of Oxford,Verification;SMT solver;Mixed Integer Programming;Neural Networks,39;39;39;-1;39,1;1;1;-1;1,-1;-1,europe,uk,n,1
991,ICLR,2018,Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms,Tom Zahavy;Bingyi Kang;Alex Sivak;Jiashi Feng;Huan Xu;Shie Mannor,tomzahavy@gmail.com;bingykang@gmail.com;silex@campus.technion.ac.il;jshfeng@gmail.com;huan.xu@isye.gatech.edu;shiemannor@gmail.com,4;4;8,3;5;4,Invite to Workshop Track,0,10,0.0,yes,10/27/17,"DeepMind;;Technion, Technion;National University of Singapore;Georgia Institute of Technology;Technion, Technion",Robustness;Generalization;Deep Learning;Adversarial Learning,-1;-1;21;15;13;21,-1;-1;-1;22;33;-1,-1;-1,NAN,NAN,y,1;4
992,ICLR,2018,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks,Josh Fromm;Matthai Philipose;Shwetak Patel,jwfromm@uw.edu;matthaip@microsoft.com;shwetak@cs.washington.edu,6;5;4,4;4;4,Reject,0,8,0.0,yes,10/27/17,"University of Washington, Seattle;Microsoft;University of Washington",Deep Learning;Computer Vision;Approximation,8;-1;8,25;-1;25,-1;-1,usa,usa,n,
993,ICLR,2018,Residual Gated Graph ConvNets,Xavier Bresson;Thomas Laurent,xbresson@ntu.edu.sg;tlaurent@lmu.edu,7;3;6,4;4;3,Reject,0,5,0.0,yes,10/27/17,Nanyang Technological University;Loyola Marymount University,graph neural networks;ConvNets;RNNs;pattern matching;semi-supervised clustering,39;-1,52;-1,-1;-1,NAN,NAN,n,10;1;5
994,ICLR,2018,WHAT ARE GANS USEFUL FOR?,Pablo M. Olmos;Briland Hitaj;Paolo Gasti;Giuseppe Ateniese;Fernando Perez-Cruz,olmos@tsc.uc3m.es;bhitaj@stevens.edu;pgasti@nyit.edu;gatenies@stevens.edu;fernando.perezcruz@sdsc.ethz.ch,3;3;3,5;4;5,Reject,0,0,0.0,yes,10/27/17,Universidad Carlos III de Madrid;Stevens Institute of Technology;New York Institute of Technology;Stevens Institute of Technology;Swiss Federal Institute of Technology,Generative Modeling;Generative Adversarial Networks;Density Estimation,-1;162;-1;162;-1,-1;512;-1;512;-1,-1;-1,NAN,NAN,n,5
995,ICLR,2018,Learning objects from pixels,David Saxton,saxton@google.com,3;4;4,4;3;4,Reject,0,0,0.0,yes,10/27/17,Google,objects;unsupervised;reinforcement learning;atari,-1,-1,-1,NAN,NAN,n,8;1;10
996,ICLR,2018,Learning to Compute Word Embeddings On the Fly,Dzmitry Bahdanau;Tom Bosc;Stanis≈Çaw Jastrzƒôbski;Edward Grefenstette;Pascal Vincent;Yoshua Bengio,dimabgv@gmail.com;bosc.tom@gmail.com;staszek.jastrzebski@gmail.com;etg@google.com;pascal.vincent@umontreal.ca;yoshua.umontreal@gmail.com,5;7;5,4;3;4,Reject,0,1,0.0,yes,10/27/17,Element AI;University of Montreal;Jagiellonian University;Google;University of Montreal;University of Montreal,NLU;word embeddings;representation learning,-1;125;-1;-1;125;125,-1;108;695;-1;108;108,-1;-1,canada,ca,n,3
997,ICLR,2018,SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs,Chi-Chun Chuang;Zheng-Xin Weng;Shan-Hung Wu,ccchuang@datalab.cs.nthu.edu.tw;zxweng@datalab.cs.nthu.edu.tw;shwu@cs.nthu.edu.tw,5;4;7,3;5;3,Reject,0,3,0.0,yes,10/27/17,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University,RNNs;GANs;Variational RNNs;Sketch RNNs,224;224;224,323;323;323,-1;-1,asia,tw,n,5
998,ICLR,2018,On the Construction and Evaluation of Color Invariant Networks,Konrad Groh,konrad.groh@de.bosch.com,4;3;3,4;4;4,Reject,0,0,0.0,yes,10/27/17,Bosch,deep learning;invariance;data set;evaluation,-1,367,-1,NAN,NAN,n,1
999,ICLR,2018,The Mutual Autoencoder: Controlling Information in Latent Code Representations,Mary Phuong;Max Welling;Nate Kushman;Ryota Tomioka;Sebastian Nowozin,bphuong@ist.ac.at;m.welling@uva.nl;nkushman@microsoft.com;ryoto@microsoft.com;sebastian.nowozin@microsoft.com,4;5;4,5;4;4,Reject,0,1,0.0,yes,10/27/17,Institute of Science and Technology Austria;University of Amsterdam;Microsoft;Microsoft;Microsoft,,-1;125;-1;-1;-1,-1;59;-1;-1;-1,-1;-1,NAN,NAN,y,1;5
1000,ICLR,2018,Avoiding degradation in deep feed-forward networks by phasing out skip-connections,Ricardo Pio Monti;Sina Tootoonian;Robin Cao,r.monti@ucl.ac.uk;sina@gatsby.ucl.ac.uk;robin.cao@ucl.ac.uk,6;6;6,4;4;5,Reject,4,9,1.0,yes,10/27/17,University College London;University College London;University College London,optimization;vanishing gradients;shattered gradients;skip-connections,49;49;49,-1;-1;-1,-1;-1,europe,uk,n,
1001,ICLR,2018,Capturing Human Category Representations by Sampling in Deep Feature Spaces,Joshua Peterson;Krishan Aghi;Jordan Suchow;Alexander Ku;Tom Griffiths,peterson.c.joshua@gmail.com;kaghi@berkeley.edu;suchow@berkeley.edu;alexku@berkeley.edu;tom_griffiths@berkeley.edu,6;5;5,4;5;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,category representations;psychology;cognitive science;deep neural networks,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,2;1;5
1002,ICLR,2018,Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks,Jinsung Yoon;William R. Zame;Mihaela van der Schaar,jsyoon0823@gmail.com;zame@econ.ucla.edu;mihaela.vanderschaar@oxford-man.ox.ac.uk,8;6;7,4;3;4,Accept (Poster),0,6,0.0,yes,10/27/17,"Google;University of California, Los Angeles;University of Oxford",Active Sensing;Timely Prediction;Irregular Sampling;Missing Data,-1;-1;39,-1;15;1,-1;-1,europe,uk,n,
1003,ICLR,2018,"Universality, Robustness, and Detectability of Adversarial Perturbations under Adversarial Training",Jan Hendrik Metzen,janhendrik.metzen@de.bosch.com,3;6;6,4;3;3,Reject,2,3,0.0,yes,10/27/17,Bosch,adversarial examples;adversarial training;universal perturbations;safety;deep learning,-1,367,-1,NAN,NAN,n,4
1004,ICLR,2018,Autoregressive Generative Adversarial Networks,Yasin Yazici;Kim-Hui Yap;Stefan Winkler,yasin001@e.ntu.edu.sg;ekhyap@ntu.edu.sg;stefan.winkler@adsc.com.sg,5;3;5,4;5;5,Invite to Workshop Track,0,3,0.0,yes,10/27/17,Nanyang Technological University;Nanyang Technological University;Advanced Digital Sciences Center,Generative Adversarial Networks;Latent Space Modeling,39;39;-1,52;52;-1,-1;-1,NAN,NAN,n,5;4
1005,ICLR,2018,"Learning to Select: Problem, Solution, and Applications",Heechang Ryu;Donghyun Kim;Hayong Shin,rhc93@kaist.ac.kr;dhk618@kaist.ac.kr;hyshin@kaist.ac.kr,4;4;4,4;4;5,Reject,0,0,0.0,yes,10/27/17,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Selection Problem;Job Dispatching;Convolution Neural Network,-1;-1;-1,95;95;95,-1;-1,NAN,NAN,n,10
1006,ICLR,2018,Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update,Su Young Lee;Sungik Choi;Sae-Young Chung,sy9424@kaist.ac.kr;si_choi@kaist.ac.kr;schung@kaist.ac.kr,4;6;5,4;4;4,Reject,0,15,0.0,yes,10/27/17,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Deep Learning;Reinforcement Learning,-1;-1;-1,95;95;95,-1;-1,NAN,NAN,y,
1007,ICLR,2018,Policy Gradient For Multidimensional Action Spaces: Action Sampling and Entropy Bonus,Vuong Ho Quan;Yiming Zhang;Kenny Song;Xiao-Yue Gong;Keith W. Ross,quan.hovuong@gmail.com;yiming.zhang@nyu.edu;kenny.song@nyu.edu;xygong@mit.edu;keithwross@nyu.edu,6;5;5,3;4;5,Reject,0,4,0.0,yes,10/27/17,"University of California, San Diego;New York University;New York University;Massachusetts Institute of Technology;New York University",deep reinforcement learning;policy gradient;multidimensional action space;entropy bonus;entropy regularization;discrete action space,-1;21;21;8;21,-1;27;27;5;27,-1;-1,usa,usa,y,
1008,ICLR,2018,GENERATIVE LOW-SHOT NETWORK EXPANSION,Adi Hayat;Mark Kliger;Shachar Fleishman;Daniel Cohen-Or,adi.hayat3@gmail.com;mark.kliger@gmail.com;shacharfl@gmail.com;cohenor@gmail.com,6;4;4,4;3;4,Reject,0,3,0.0,yes,10/27/17,Tel Aviv University;;;Tel Aviv University,Low-Shot Learning;class incremental learning;Network expansion;Generative model;Distillation,30;-1;-1;30,217;-1;-1;217,-1;-1,europe,il,n,5
1009,ICLR,2018,Cheap DNN Pruning with Performance Guarantees ,Konstantinos Pitas;Mike Davies;Pierre Vandergheynst,konstantinos.pitas@epfl.ch;mike.davies@ed.ac.uk;pierre.vandergheynst@epfl.ch,6;5;5,3;3;4,Reject,0,4,0.0,yes,10/27/17,Swiss Federal Institute of Technology Lausanne;University of Edinburgh;Swiss Federal Institute of Technology Lausanne,pruning;generalisation error;DC optimisation,-1;30;-1,-1;27;-1,-1;-1,NAN,NAN,y,
1010,ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Chen Xu;Jianqiang Yao;Zhouchen Lin;Wenwu Ou;Yuanbin Cao;Zhirong Wang;Hongbin Zha,xuen@pku.edu.cn;tianduo@taobao.com;zlin@pku.edu.cn;santong.oww@taobao.com;lingzun.cyb@alibaba-inc.com;qingfeng@taobao.com;zha@cis.pku.edu.cn,8;7;7,4;4;2,Accept (Poster),0,12,0.0,yes,10/27/17,Peking University;Taobao;Peking University;Taobao;Alibaba Group;Taobao;Peking University,Alternating Minimization;Quantized Recurrent Neural Network;Binary Search Tree,14;-1;14;-1;-1;-1;14,27;-1;27;-1;-1;-1;27,-1;-1,asia,cn,n,3
1011,ICLR,2018,Learning to Generate Filters for Convolutional Neural Networks,Wei Shen;Rujie Liu,shenwei@cn.fujitsu.com;rjliu@cn.fujitsu.com,4;5;4,4;4;5,Reject,2,0,0.0,yes,10/27/17,Fujitsu Laboratories Ltd.;Fujitsu Laboratories Ltd.,filter generation;meta-learning;filter repository;image classification;dynamic generation,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1012,ICLR,2018,Theoretical properties of the global optimizer of two-layer Neural Network,Digvijay Boob;Guanghui Lan,digvijaybb40@gatech.edu;george.lan@isye.gatech.edu,4;7;7,5;5;4,Reject,4,6,0.0,yes,10/27/17,Georgia Institute of Technology;Georgia Institute of Technology,Non-convex optimization;Two-layer Neural Network;global optimality;first-order optimality,13;13,33;33,-1;-1,usa,usa,y,
1013,ICLR,2018,Regularization for Deep Learning: A Taxonomy,Jan Kukaƒçka;Vladimir Golkov;Daniel Cremers,jan.kukacka@tum.de;vladimir.golkov@tum.de;cremers@tum.de,5;4;4,5;4;5,Reject,0,4,0.0,yes,10/27/17,Technical University Munich;Technical University Munich;Technical University Munich,neural networks;deep learning;regularization;data augmentation;network architecture;loss function;dropout;residual learning;optimization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1014,ICLR,2018,Kernel Graph Convolutional Neural Nets,Giannis Nikolentzos;Polykarpos Meladianos;Antoine J-P Tixier;Konstantinos Skianis;Michalis Vazirgiannis,giannisnik@hotmail.com;pmeladianos@aueb.gr;antoine.tixier-1@colorado.edu;kskianis@lix.polytechnique.fr;mvazirg@lix.polytechnique.fr,5;5;4,5;4;5,Reject,0,0,0.0,yes,10/27/17,"Ecole polytechnique;Athens University of Economics and Business;University of Colorado, Boulder;Ecole Polytechnique, France;Ecole Polytechnique, France",,-1;-1;57;-1;-1,115;565;100;-1;-1,-1;-1,NAN,NAN,n,10
1015,ICLR,2018,Improving Search Through A3C Reinforcement Learning Based Conversational Agent,Milan Aggarwal;Aarushi Arora;Shagun Sodhani;Balaji Krishnamurthy,milan.ag1994@gmail.com;aarushi.arora043@gmail.com;sshagunsodhani@gmail.com;kbalaji@adobe.com,5;2;3,4;5;5,Reject,0,7,0.0,yes,10/27/17,Indian Institute of Technology (IIT) Delhi;;Facebook;Adobe Systems,Subjective search;Reinforcement Learning;Conversational Agent;Virtual user model;A3C;Context aggregation,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1016,ICLR,2018,Now I Remember! Episodic Memory For Reinforcement Learning,Ricky Loynd;Matthew Hausknecht;Lihong Li;Li Deng,riloynd@microsoft.com;mahauskn@microsoft.com;lihongli.cs@gmail.com;l.deng@ieee.org,4;4;4,5;4;5,Reject,0,0,0.0,yes,10/27/17,Microsoft;Microsoft;Amazon;University of Waterloo,Reinforcement learning;Deep learning;Episodic memory,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,
1017,ICLR,2018,An Out-of-the-box Full-network Embedding for Convolutional Neural Networks,Dario Garcia-Gasulla;Armand Vilalta;Ferran Par√©s;Jonatan Moreno;Eduard Ayguad√©;Jes√∫s Labarta;Ulises Cort√©s;Toyotaro Suzumura,dario.garcia@bsc.es;armand.vilalta@bsc.es;ferran.pares@bsc.es;jonatan.moreno@bsc.es;eduard.ayguade@bsc.es;jesus.labarta@bsc.es;ia@cs.upc.edu;suzumurat@gmail.com,3;4;4,4;5;5,Reject,0,0,0.0,yes,10/27/17,Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing;Universitat Polit√®cnica de Catalunya;IBM Center,Embedding spaces;feature extraction;transfer learning.,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,asia,in,n,6
1018,ICLR,2018,Parameter Space Noise for Exploration,Matthias Plappert;Rein Houthooft;Prafulla Dhariwal;Szymon Sidor;Richard Y. Chen;Xi Chen;Tamim Asfour;Pieter Abbeel;Marcin Andrychowicz,matthiasplappert@me.com;rein.houthooft@openai.com;prafulla@openai.com;szymon@openai.com;richardchen@openai.com;peter@openai.com;asfour@kit.edu;pabbeel@cs.berkeley.edu;marcin@openai.com,6;7;7,4;4;5,Accept (Poster),0,8,0.0,yes,10/27/17,OpenAI;OpenAI;OpenAI;OpenAI;OpenAI;OpenAI;Karlsruhe Institute of Technology;University of California Berkeley;OpenAI,reinforcement learning;exploration;parameter noise,-1;-1;-1;-1;-1;-1;162;-1;-1,-1;-1;-1;-1;-1;-1;133;18;-1,-1;-1,NAN,NAN,n,
1019,ICLR,2018,Global Convergence of Policy Gradient Methods for Linearized  Control Problems,Maryam Fazel;Rong Ge;Sham M. Kakade;Mehran Mesbahi,mfazel@uw.edu;rongge@cs.duke.edu;sham@cs.washington.edu;mesbahi@aa.washington.edu,6;5;5,4;3;3,Reject,0,3,0.0,yes,10/27/17,"University of Washington, Seattle;Duke University;University of Washington;University of Washington",linear quadratic regulator;policy gradient;natural gradient;reinforcement learning;non-convex optimization,8;39;8;8,25;17;25;25,-1;-1,usa,usa,y,1;9
1020,ICLR,2018,A Bayesian Nonparametric Topic Model with Variational Auto-Encoders,Xuefei Ning;Yin Zheng;Zhuxi Jiang;Yu Wang;Huazhong Yang;Junzhou Huang,foxdoraame@gmail.com;yzheng3xg@gmail.com;zjiang9310@gmail.com;yu-wang@mail.tsinghua.edu.cn;yanghz@tsinghua.edu.cn;joehhuang@tencent.com,7;3;5,4;4;2,Reject,0,8,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;Tencent AI Lab;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tencent AI Lab",topic model;Bayesian nonparametric;variational auto-encoder;document modeling,5;-1;-1;5;5;-1,30;-1;-1;30;30;-1,-1;-1,NAN,NAN,n,11;5
1021,ICLR,2018,DropMax: Adaptive Stochastic Softmax,Hae Beom Lee;Juho Lee;Eunho Yang;Sung Ju Hwang,hblee@unist.ac.kr;stonecold@postech.ac.kr;yangeh@gmail.com;sjhwang82@gmail.com,6;6;4,3;4;3,Invite to Workshop Track,0,8,0.0,yes,10/27/17,Ulsan National Institute of Science and Technology;POSTECH;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;125;-1;-1,230;137;95;95,-1;-1,NAN,NAN,n,
1022,ICLR,2018,Graph Partition Neural Networks for Semi-Supervised Classification,Renjie Liao;Marc Brockschmidt;Daniel Tarlow;Alexander Gaunt;Raquel Urtasun;Richard S. Zemel,rjliao@cs.toronto.edu;mabrocks@microsoft.com;dtarlow@google.com;algaunt@microsoft.com;urtasun@cs.toronto.edu;zemel@cs.toronto.edu,6;5;6,3;3;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,University of Toronto;Microsoft;Google;Microsoft;University of Toronto;University of Toronto,,21;-1;-1;-1;21;21,22;-1;-1;-1;22;22,-1;-1,canada,ca,n,10
1023,ICLR,2018,Semi-supervised Outlier Detection using Generative And Adversary Framework,Jindong Gu;Matthias Schubert;Volker Tresp,jindong.gu@siemens.com;schubert@dbs.ifi.lmu.de;volker.tresp@siemens.com,4;4;3,3;4;5,Reject,0,4,0.0,yes,10/27/17,Siemens Corporate Research;Institut f√ºr Informatik;Siemens Corporate Research,Semi-supervised Learning;Generative And Adversary Framework;One-class classification;Outlier detection,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
1024,ICLR,2018,Deep Asymmetric Multi-task Feature Learning,Hae Beom Lee;Eunho Yang;Sung Ju Hwang,hblee@unist.ac.kr;yangeh@gmail.com;sjhwang@unist.ac.kr,6;3;5,4;4;4,Reject,0,0,0.0,yes,10/27/17,Ulsan National Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Ulsan National Institute of Science and Technology,,-1;-1;-1,230;95;230,-1;-1,NAN,NAN,n,
1025,ICLR,2018,Cross-Corpus Training with TreeLSTM for the Extraction of Biomedical Relationships from Text,Legrand Jo√´l;Yannick Toussaint;Chedy Ra√Øssi;Adrien Coulet,joel.legrand@loria.fr;yannick.toussaint@loria.fr;chedy.raissi@inria.fr;adrien.coulet@loria.fr,4;5;3,4;4;5,Invite to Workshop Track,0,0,0.0,yes,10/27/17,University of Lorraine;University of Lorraine;INRIA;University of Lorraine,Relationships Extraction;Deep Learning;TreeLSTM;NLP,-1;-1;-1;-1,535;535;-1;535,-1;-1,NAN,NAN,n,
1026,ICLR,2018,Learning to navigate by distilling visual information and natural language instructions,Abhishek Sinha;Akilesh B;Mausoom Sarkar;Balaji Krishnamurthy,abhsinha@adobe.com;akb@adobe.com;msarkar@adobe.com;kbalaji@adobe.com,4;4;5,4;5;3,Reject,0,16,0.0,yes,10/27/17,Adobe Systems;Adobe Systems;Adobe Systems;Adobe Systems,Deep reinforcement learning;Computer Vision;Multi-modal fusion;Language Grounding,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;8;1;6
1027,ICLR,2018,Statestream: A toolbox to explore layerwise-parallel deep neural networks,Volker Fischer,volker.fischer@de.bosch.com,3;5;5,4;4;3,Reject,0,3,0.0,yes,10/27/17,Bosch,model-parallel;parallelization;software platform,-1,367,-1,NAN,NAN,n,10
1028,ICLR,2018,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,Yiping Lu;Aoxiao Zhong;Quanzheng Li;Bin Dong,luyiping9712@pku.edu.cn;zhongaoxiao@gmail.com;quanzhengli5@gmail.com;dongbin@math.pku.edu.cn,7;6;5;5,4;1;3;1,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Peking University;;;Peking University,deep convolutional network;residual network;dynamic system;stochastic dynamic system;modified equation,14;-1;-1;14,27;-1;-1;27,-1;-1,asia,cn,n,1
1029,ICLR,2018,Training RNNs as Fast as CNNs,Tao Lei;Yu Zhang;Yoav Artzi,tao@asapp.com;yzhang87@csail.mit.edu;yoav@cs.cornell.edu,7;8;4,4;5;5,Reject,8,10,0.0,yes,10/27/17,ASAPP Inc.;Massachusetts Institute of Technology;Cornell University,recurrent neural networks;natural language processing,-1;8;5,-1;5;19,-1;-1,usa,usa,n,3
1030,ICLR,2018,Revisiting Bayes by Backprop,Meire Fortunato;Charles Blundell;Oriol Vinyals,meirefortunato@google.com;cblundell@google.com;vinyals@google.com,5;6;6,4;4;5,Reject,0,5,0.0,yes,10/27/17,Google;Google;Google,Bayesian;Deep Learning;Recurrent Neural Networks;LSTM,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11;3
1031,ICLR,2018,PARAMETRIZED DEEP Q-NETWORKS LEARNING: PLAYING ONLINE BATTLE ARENA WITH DISCRETE-CONTINUOUS HYBRID ACTION SPACE,Jiechao Xiong;Qing Wang;Zhuoran Yang;Peng Sun;Yang Zheng;Lei Han;Haobo Fu;Xiangru Lian;Carson Eisenach;Haichuan Yang;Emmanuel Ekwedike;Bei Peng;Haoyue Gao;Tong Zhang;Ji Liu;Han Liu,jcxiong@tencent.com;drwang@tencent.com;pythonsun@tencent.com;zakzheng@tencent.com;lxhan@tencent.com;haobofu@tencent.com;tongzhang@tongzhang-ml.org;ji.liu.uwisc@gmail.com,5;5;4,4;3;4,Reject,0,0,0.0,yes,10/27/17,Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Google;Princeton University,Deep reinforcement learning;Hybrid action space;DQN;DDPG,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,asia,in,n,
1032,ICLR,2018,Towards Building Affect sensitive Word Distributions,Kushal Chawla;Sopan Khosla;Niyati Chhaya;Kokil Jaidka,kchawla@adobe.com;skhosla@adobe.com;nchhaya@adobe.com;jaidka@sas.upenn.edu,6;4;4,3;5;4,Reject,0,4,0.0,yes,10/27/17,Adobe Systems;Adobe Systems;Adobe Systems;University of Pennsylvania,Affect lexicon;word embeddings;Word2Vec;GloVe;WordNet;joint learning;sentiment analysis;word similarity;outlier detection;affect prediction,-1;-1;-1;15,-1;-1;-1;10,-1;-1,usa,usa,n,3
1033,ICLR,2018,Unsupervised Learning of Entailment-Vector Word Embeddings,James Henderson,james.henderson@idiap.ch,3;7;3,5;3;5,Reject,0,3,0.0,yes,10/27/17,Idiap Research Institute,word embeddings;natural language semantics;entailment;unsupervised learning;distributional semantics,-1,-1,-1,NAN,NAN,n,3
1034,ICLR,2018,Overcoming the vanishing gradient problem in plain recurrent networks,Yuhuang Hu;Adrian Huber;Shih-Chii Liu,yuhuang.hu@ini.uzh.ch;huberad@ini.uzh.ch;shih@ini.uzh.ch,4;2;7,5;4;4,Reject,0,5,0.0,yes,10/27/17,University of Zurich;University of Zurich;University of Zurich,vanishing gradient descent;recurrent neural networks;identity mapping,125;125;125,136;136;136,-1;-1,europe,ch,n,
1035,ICLR,2018,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,Yaniv Taigman;Lior Wolf;Adam Polyak;Eliya Nachmani,yaniv@fb.com;wolf@fb.com;adampolyak@fb.com;enk100@gmail.com,8;5;6,4;4;4,Accept (Poster),1,6,0.0,yes,10/27/17,Facebook;Facebook;Facebook;Facebook,Voice Synthesis;Multi-Speaker;Differentiable Memory;Text-to-Speech,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
1036,ICLR,2018,Graph Topological Features via GAN,Weiyi Liu;Hal Cooper;Min-Hwan Oh,weiyiliu@us.ibm.com;hal.cooper@columbia.edu;m.oh@columbia.edu,3;4;4,4;4;5,Reject,0,0,0.0,yes,10/27/17,International Business Machines;Columbia University;Columbia University,graph topology;GAN;network science;hierarchical learning,-1;21;21,-1;14;14,-1;-1,usa,usa,n,10;5;4
1037,ICLR,2018,Improve Training Stability of Semi-supervised Generative Adversarial Networks with Collaborative Training,Dalei Wu;Xiaohua Liu,daleiwu@gmail.com;dalei.wu@huawei.com;liuxh3@huawei.com,3;2;3,4;4;5,Reject,0,0,0.0,yes,10/27/17,Huawei Technologies Ltd.;Huawei Technologies Ltd.,generative adversarial training;semi-supervised training;collaborative training,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,5;4
1038,ICLR,2018,Disentangled activations in deep networks,Mikael K√•geb√§ck;Olof Mogren,kageback@chalmers.se;olof@mogren.one,6;5;4,3;4;3,Reject,0,3,0.0,yes,10/27/17,Chalmers University;RISE Research Institutes of Sweden,representation learning;disentanglement;regularization,-1;-1,240;-1,-1;-1,NAN,NAN,n,
1039,ICLR,2018,On the State of the Art of Evaluation in Neural Language Models,G√°bor Melis;Chris Dyer;Phil Blunsom,melisgl@google.com;cdyer@cs.cmu.edu;phil.blunsom@cs.ox.ac.uk,7;5;8,2;5;3,Accept (Poster),0,16,0.0,yes,10/27/17,Google;Carnegie Mellon University;University of Oxford,rnn;language modelling,-1;1;39,-1;24;1,-1;-1,europe,uk,n,3
1040,ICLR,2018,Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees,Eleanor Quint;Garrett Wirka;Jacob Williams;Stephen Scott;N.V. Vinodchandran,pquint@cse.unl.edu;gwirka@cse.unl.edu;jwilliam@cse.unl.edu;sscott@cse.unl.edu;vinod@cse.unl.edu,3;4;5,5;4;4,Reject,0,2,0.0,yes,10/27/17,"University of Nebraska, Lincoln;University of Nebraska, Lincoln;University of Nebraska, Lincoln;University of Nebraska, Lincoln;University of Nebraska, Lincoln",interpretable classification;decision trees;deep learning;variational autoencoder,224;224;224;224;224,337;337;337;337;337,-1;-1,NAN,NAN,n,5
1041,ICLR,2018,Zero-shot Cross Language Text Classification,Dan Svenstrup;Jonas Meinertz Hansen;Ole Winther,dsve@dtu.dk;jonas@meinertz.org;olwi@dtu.dk,4;2;3,3;4;4,Reject,0,0,0.0,yes,10/27/17,Technical University of Denmark;;Technical University of Denmark,Cross Language Text Classification;Neural Networks;Machine Learning,-1;-1;-1,153;-1;153,-1;-1,NAN,NAN,n,
1042,ICLR,2018,Long Term Memory Network for Combinatorial Optimization Problems,Hazem A. A. Nomer;Abdallah Aboutahoun;Ashraf Elsayed,hazemahmed@alexu.edu.eg;abdallah_aboutahoun@alexu.edu.eg;ashraf.elsayed@alexu.edu.eg,4;4;3,1;2;4,Reject,3,0,0.0,yes,10/27/17,Alexandria University;Alexandria University;Alexandria University,Memory Networks;Combinatorial Optimization;Binary LP,-1;-1;-1,896;896;896,-1;-1,NAN,NAN,n,
1043,ICLR,2018,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,Mikolaj Binkowski;Gautier Marti;Philippe Donnat,mikbinkowski@gmail.com;gautier.marti@gmail.com;pdonnat@helleborecapital.com,4;5;5,5;3;4,Reject,0,1,0.0,yes,10/27/17,Imperial College London;;TAL Education Group,neural networks;convolutional neural networks;time series;asynchronous data;regression,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1044,ICLR,2018,Towards Unsupervised Classification with Deep Generative Models,Dimitris Kalatzis;Konstantia Kotta;Ilias Kalamaras;Anastasios Vafeiadis;Andrew Rawstron;Dimitris Tzovaras;Kostas Stamatopoulos,dkal@iti.gr;ntina_kotta@yahoo.com;kalamar@iti.gr;anasvaf@iti.gr;a.c.rawstron@leeds.ac.uk;dimitrios.tzovaras@iti.gr;kostas.stamatopoulos@gmail.com,4;4;4,4;4;5,Reject,0,1,0.0,yes,10/27/17,CERTH/ITI;;CERTH/ITI;CERTH/ITI;University of Leeds;CERTH/ITI;CERTH,variational inference;vae;variational autoencoders;generative modeling;representation learning;classification,-1;-1;-1;-1;224;-1;-1,-1;-1;-1;-1;139;-1;-1,-1;-1,asia,in,n,5
1045,ICLR,2018,Topic-Based Question Generation,Wenpeng Hu;Bing Liu;Rui Yan;Dongyan Zhao;Jinwen Ma,wenpeng.hu@pku.edu.cn;liub@cs.uic.edu;ruiyan@pku.edu.cn;zhaody@pku.edu.cn;jwma@math.pku.edu.cn,3;4;8,5;4;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,"Peking University;University of Illinois, Chicago;Peking University;Peking University;Peking University",,14;-1;14;14;14,27;-1;27;27;27,-1;-1,asia,cn,n,
1046,ICLR,2018,Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization,Hang Wu,hwu340@gatech.edu;hangwu@gatech.edu,4;5;7,4;5;3,Reject,0,6,0.0,yes,10/27/17,Georgia Institute of Technology;Georgia Institute of Technology,Counterfactual Inference;Off-Policy Learning;Variance Regularization,13;13,33;33,-1,usa,usa,y,1
1047,ICLR,2018,Lifelong Learning with Output Kernels,Keerthiram Murugesan;Jaime Carbonell,kmuruges@cs.cmu.edu;jgc@cs.cmu.edu,3;2;4,4;5;4,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University,multitask learning;lifelong learning;online learning,1;1,24;24,-1;-1,usa,usa,n,1
1048,ICLR,2018,Deep Continuous Clustering,Sohil Atul Shah;Vladlen Koltun,sohilas@umd.edu;vkoltun@gmail.com,6;3;7,3;5;4,Reject,0,10,0.0,yes,10/27/17,"University of Maryland, College Park;Intel",clustering;dimensionality reduction,12;-1,69;-1,-1;-1,NAN,NAN,n,
1049,ICLR,2018,Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks,Xu Sun;Bingzhen Wei;Xuancheng Ren;Shuming Ma,xusun@pku.edu.cn;weibz@pku.edu.cn;renxc@pku.edu.cn;shumingma@pku.edu.cn,4;4;3,5;3;4,Reject,0,1,0.0,yes,10/27/17,Peking University;Peking University;Peking University;Peking University,label embedding;deep learning;label representation;computer vision;natural language processing,14;14;14;14,27;27;27;27,-1;-1,asia,cn,n,
1050,ICLR,2018,Semantic Code Repair using Neuro-Symbolic Transformation Networks,Jacob Devlin;Jonathan  Uesato;Rishabh Singh;Pushmeet Kohli,jacobdevlin@google.com;juesato@gmail.com;risin@microsoft.com;pushmeet@google.com,4;6;6,4;4;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Google;Google;Microsoft;Google,semantic program repair;neural program embeddings;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
1051,ICLR,2018,Simple and efficient architecture search for Convolutional Neural Networks,Thomas Elsken;Jan Hendrik Metzen;Frank Hutter,thomas.elsken@de.bosch.com;janhendrik.metzen@de.bosch.com;fh@cs.uni-freiburg.de,6;5;4,4;5;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Bosch;Bosch;Universit√§t Freiburg,Deep Learning;Hyperparameter Optimization;Architecture Search;Convolutional Neural Networks;Network Morphism;Network Transformation;SGDR;Cosine annealing;hill climbing,-1;-1;-1,367;367;-1,-1;-1,NAN,NAN,n,
1052,ICLR,2018,Natural Language Inference with External Knowledge,Qian Chen;Xiaodan Zhu;Zhen-Hua Ling;Diana Inkpen,cq1231@mail.ustc.edu.cn;xiaodan.zhu@queensu.ca;zhling@ustc.edu.cn;diana.inkpen@uottawa.ca,6;5;3;7,5;4;5;4,Invite to Workshop Track,3,4,0.0,yes,10/27/17,University of Science and Technology of China;Queens University;University of Science and Technology of China;University of Ottawa,natural language inference;external knowledge;state of the art,-1;224;-1;224,132;261;132;233,-1;-1,australasia,nz,n,3
1053,ICLR,2018,AirNet: a machine learning dataset for air quality forecasting,Songgang Zhao;Xingyuan Yuan;Da Xiao;Jianyuan Zhang;Zhouyuan Li,gfgkmn@gmail.com;yuan@caiyunapp.com;xiaoda99@gmail.com;littletree@caiyunapp.com;joeyzhouyuanli@caiyunapp.com,5;4;4,4;4;4,Reject,0,4,0.0,yes,10/27/17,beihang university;ColorfulClouds Tech.;;ColorfulClouds Tech.;ColorfulClouds Tech.,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1054,ICLR,2018,Recursive Binary Neural Network Learning Model  with 2-bit/weight Storage Requirement,Tianchan Guan;Xiaoyang Zeng;Mingoo Seok,tg2569@columbia.edu;xyzeng@fudan.edu;ms4415@columbia.edu,6;7;5,3;4;3,Reject,0,3,0.0,yes,10/27/17,Columbia University;Fudan University;Columbia University,,21;67;21,14;116;14,-1;-1,usa,usa,n,
1055,ICLR,2018,Learning Dynamic State Abstractions for Model-Based Reinforcement Learning,Lars Buesing;Theophane Weber;Sebastien Racaniere;S. M. Ali Eslami;Danilo Rezende;David Reichert;Fabio Viola;Frederic Besse;Karol Gregor;Demis Hassabis;Daan Wierstra,lbuesing@google.com;theophane@google.com;sracaniere@google.com;aeslami@google.com;danilor@google.com;reichert@google.com;fviola@google.com;fbesse@google.com;demishassabis@google.com;wierstra@google.com,6;5;8,4;4;4,Reject,0,6,1.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,generative models;probabilistic modelling;reinforcement learning;state-space models;planning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1056,ICLR,2018,Towards Effective GANs for Data Distributions with Diverse Modes,Sanchit Agrawal;Gurneet Singh;Mitesh Khapra,sanchit@cse.iitm.ac.in;garry@cse.iitm.ac.in;miteshk@cse.iitm.ac.in,6;4;4,5;3;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,Indian Institute of Technology Madras;Indian Institute of Technology Madras;Indian Institute of Technology Madras,generative adversarial networks;GANs;deep learning;unsupervised learning;generative models;adversarial learning,-1;-1;-1,625;625;625,-1;-1,NAN,NAN,n,1;5;4
1057,ICLR,2018,Unsupervised Adversarial Anomaly  Detection using One-Class Support Vector Machines,Prameesha Sandamal Weerasinghe;Tansu Alpcan;Sarah Monazam Erfani;Christopher Leckie,pweerasinghe@student.unimelb.edu.au;tansu.alpcan@unimelb.edu.au;sarah.erfani@unimelb.edu.au;caleckie@unimelb.edu.au,4;4;4,4;4;4,Reject,0,0,0.0,yes,10/27/17,The University of Melbourne;The University of Melbourne;The University of Melbourne;The University of Melbourne,anomaly detection;one class support vector machine;adversarial learning,67;67;67;67,32;32;32;32,-1;-1,NAN,NAN,y,4
1058,ICLR,2018,Estimation of cross-lingual news similarities using text-mining methods,Zhouhao Wang;Enda Liu;Hiroki Sakaji;Tomoki Ito;Kiyoshi Izumi;Kota Tsubouchi;Tatsuo Yamashita,wangzhouhao94@gmail.com;m2015eliu@socsim.org;sakaji@sys.t.u-tokyo.ac.jp;m2015titoh@socsim.org;izumi@sys.t.u-tokyo.ac.jp;ktsubouc@yahoo-corp.jp;tayamash@yahoo-corp.jp,2;6;2,5;4;4,Reject,0,0,0.0,yes,10/27/17,The University of Tokyo;;The University of Tokyo;;The University of Tokyo;;Yahoo,,-1;-1;57;-1;57;-1;-1,-1;-1;45;-1;45;-1;-1,-1;-1,asia,in,n,
1059,ICLR,2018,Data-driven Feature Sampling for Deep Hyperspectral Classification and Segmentation,William M. Severa;Jerilyn A. Timlin;Suraj Kholwadwala;Conrad D. James;James B. Aimone,wmsever@sandia.gov;jatimli@sandia.gov;skholwadwala@gmail.com;cdjame@sandia.gov;jbaimon@sandia.gov,3;6;4,5;5;5,Reject,0,0,0.0,yes,10/27/17,Sandia National Laboratories;Sandia National Laboratories;;Sandia National Laboratories;Sandia National Laboratories,Applied deep learning;Image segmentation;Hyperspectral Imaging;Feature sampling,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
1060,ICLR,2018,Grouping-By-ID: Guarding Against Adversarial Domain Shifts,Christina Heinze-Deml;Nicolai Meinshausen,heinzedeml@stat.math.ethz.ch;meinshausen@stat.math.ethz.ch,7;4;5,3;5;4,Reject,0,4,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,supervised representation learning;causality;interpretability;transfer learning,-1;-1,-1;-1,-1;-1,NAN,NAN,y,6;10;7;4
1061,ICLR,2018,"MACH: Embarrassingly parallel $K$-class classification in $O(d\log{K})$ memory and $O(K\log{K} + d\log{K})$ time, instead of $O(Kd)$",Qixuan Huang;Anshumali Shrivastava;Yiqiu Wang,qh5@rice.edu;anshumali@rice.edu;yiqiu.wang@rice.edu,6;6;6,4;4;4,Reject,0,7,0.0,yes,10/27/17,Rice University;Rice University;Rice University,Extreme Classification;Large-scale learning;hashing;GPU;High Performance Computing,95;95;95,86;86;86,-1;-1,australasia,au,n,
1062,ICLR,2018,SHADE: SHAnnon DEcay Information-Based Regularization for Deep Learning,Michael Blot;Thomas Robert;Nicolas Thome;Matthieu Cord,michael.blot@lip6.fr;thomas.robert@lip6.fr;nicolas.thome@lip6.fr;matthieu.cord@lip6.fr,4;5;7;4,3;4;3;3,Reject,0,7,0.0,yes,10/27/17,LIP6;LIP6;LIP6;LIP6,,377;377;377;377,-1;-1;-1;-1,-1;-1,asia,ir,n,1
1063,ICLR,2018,Lifelong Generative Modeling,Jason Ramapuram;Magda Gregorova;Alexandros Kalousis,jason.ramapuram@etu.unige.ch;magda.gregorova@unige.ch;alexandros.kalousis@hesge.ch,9;4;4,5;5;2,Reject,0,4,0.0,yes,10/27/17,"University of Geneva, Switzerland;University of Geneva, Switzerland;University of Applied Sciences Western Switzerland",Lifelong;Generative Modeling;Variational Autoencoder;VAE;Catastrophic Interference,-1;-1;-1,130;130;-1,-1;-1,NAN,NAN,n,6;5
1064,ICLR,2018,A Self-Training Method for Semi-Supervised GANs,Alan Do-Omri;Dalei Wu;Xiaohua Liu,alan.do-omri@mail.mcgill.ca;daleiwu@gmail.com;liuxiaohua3@huawei.com,3;4;3,5;4;4,Reject,0,4,0.0,yes,10/27/17,McGill University;;Huawei Technologies Ltd.,self-training;generative adversarial networks;semi-supervised,95;-1;-1,42;-1;-1,-1;-1,NAN,NAN,n,5;4
1065,ICLR,2018,Neighbor-encoder,Chin-Chia Michael Yeh;Yan Zhu;Evangelos E. Papalexakis;Abdullah Mueen;Eamonn Keogh,myeh003@ucr.edu;yzhu015@ucr.edu;epapalex@cs.ucr.edu;mueen@unm.edu;eamonn@cs.ucr.edu,5;6;4,5;4;4,Reject,0,3,2.0,yes,10/27/17,"University of California, Riverside;University of California, Riverside;University of California, Riverside;University of New Mexico;University of California, Riverside",unsupervised learning;representation learning;autoencoder,-1;-1;-1;377;-1,197;197;197;-1;197,-1;-1,usa,usa,n,1
1066,ICLR,2018,Benefits of Depth for Long-Term Memory of Recurrent Networks,Yoav Levine;Or Sharir;Amnon Shashua,yoavlevine@cs.huji.ac.il;or.sharir@cs.huji.ac.il;shashua@cs.huji.ac.il,5;7;6,2;3;3,Invite to Workshop Track,0,6,0.0,yes,10/27/17,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,recurrent neural networks;deep networks;correlations;long term memory;tensor networks;tensor analysis,67;67;67,205;205;205,-1;-1,europe,il,y,1
1067,ICLR,2018,A Neural Method for Goal-Oriented Dialog Systems to interact with Named Entities,Janarthanan Rajendran;Jatin Ganhotra;Xiaoxiao Guo;Mo Yu;Satinder Singh,rjana@umich.edu;jatinganhotra@us.ibm.com;xiaoxiao.guo@ibm.com;yum@us.ibm.com;baveja@umich.edu,6;4;3,3;3;3,Reject,0,4,0.0,yes,10/27/17,University of Michigan;International Business Machines;International Business Machines;International Business Machines;University of Michigan,Named Entities;Neural methods;Goal oriented dialog,10;-1;-1;-1;10,21;-1;-1;-1;21,-1;-1,usa,usa,n,
1068,ICLR,2018,Loss Functions for Multiset Prediction,Sean Welleck;Zixin Yao;Yu Gai;Jialin Mao;Zheng Zhang;Kyunghyun Cho,wellecks@nyu.edu;zy566@nyu.edu;yg1246@nyu.edu;jm5830@nyu.edu;zz@nyu.edu;kyunghyun.cho@nyu.edu,5;7;4,4;3;3,Reject,0,3,0.0,yes,10/27/17,New York University;New York University;New York University;New York University;New York University;New York University,machine learning;deep learning;structured prediction;sequential prediction,21;21;21;21;21;21,27;27;27;27;27;27,-1;-1,usa,usa,n,
1069,ICLR,2018,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction,Da Xiao;Jo-Yu Liao;Xingyuan Yuan,xiaoda99@gmail.com;liaoruoyu@caiyunapp.com;yuan@caiyunapp.com,3;7;7,4;4;4,Accept (Poster),0,10,0.0,yes,10/27/17,Beijing University of Posts and Telecommunications;ColorfulClouds Tech.;ColorfulClouds Tech.,neural programming;Neural Programmer-Interpreter,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
1070,ICLR,2018,Efficiently applying attention to sequential data with the Recurrent Discounted Attention unit,Brendan Maginnis;Pierre Richemond,brendan.maginnis@gmail.com;pierre.richemond@gmail.com,4;6;3,5;4;4,Reject,0,0,0.0,yes,10/27/17,Imperial College London;Imperial College London,RNNs,49;49,8;8,-1;-1,europe,uk,n,8
1071,ICLR,2018,Comparison of Paragram and GloVe Results for Similarity Benchmarks,Jakub Dutkiewicz;Czes≈Çaw Jƒôdrzejek,jakub.dutkiewicz@put.poznan.pl;czeslaw.jedrzejek@put.poznan.pl,2;4;3,4;5;4,Reject,0,1,0.0,yes,10/27/17,Poznan University of Technology;Poznan University of Technology,language models;vector spaces;word embedding;similarity,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
1072,ICLR,2018,Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games,Dino S. Ratcliffe;Luca Citi;Sam Devlin;Udo Kruschwitz,d.ratcliffe@qmul.ac.uk;lciti@essex.ac.uk;sam.devlin@york.ac.uk;udo@essex.ac.uk,3;2;4,3;4;5,Reject,0,0,0.0,yes,10/27/17,Queen Mary University London;University of Essex;University of York;University of Essex,Deep Reinforcement Learning;Domain Adaptation;Adversarial Networks,-1;224;224;224,-1;280;137;280,-1;-1,europe,uk,n,10
1073,ICLR,2018,Flexible Prior Distributions for Deep Generative Models,Yannic Kilcher;Aurelien Lucchi;Thomas Hofmann,yannic.kilcher@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch;thomas.hofmann@inf.ethz.ch,6;6;5,4;3;4,Reject,0,3,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep Generative Models;GANs,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1;5
1074,ICLR,2018,Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures,Ruo-Chun Tzeng;Shan-Hung Wu,rctzeng@datalab.cs.nthu.edu.tw;shwu@cs.nthu.edu.tw,7;4;4,3;4;4,Reject,1,4,0.0,yes,10/27/17,National Tsing Hua University;National Tsing Hua University,graph embedding;CNN,224;224,323;323,-1;-1,asia,tw,n,10
1075,ICLR,2018,Lifelong Learning by Adjusting Priors,Ron Amit;Ron Meir,ronamit@campus.technion.ac.il;rmeir@ee.technion.ac.il,6;6;6,4;4;4,Reject,0,9,0.0,yes,10/27/17,"Technion, Technion;Technion, Technion",Lifelong learning;Transfer learning;PAC-Bayes theory,21;21,-1;-1,-1;-1,NAN,NAN,y,6;1
1076,ICLR,2018,A Simple Fully Connected Network for Composing Word Embeddings from Characters,Michael Traynor;Thomas Trappenberg,mike.sk.traynor@gmail.com;trappenberg@gmail.com,3;5;4,4;4;5,Reject,0,0,0.0,yes,10/27/17,Dalhousie University;Dalhousie University,natural language processing;word embeddings;language models;neural network;deep learning;sparsity;dropout,224;-1,289;-1,-1;-1,asia,in,n,3
1077,ICLR,2018,"Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",Lukas Balles;Philipp Hennig,lukas.balles@tuebingen.mpg.de;ph@tue.mpg.de,4;4;6,4;4;3,Reject,1,6,0.0,yes,10/27/17,Max-Planck Institute;Max-Planck Institute,Stochastic Optimization;Deep Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,y,
1078,ICLR,2018,Censoring Representations with Multiple-Adversaries over Random Subspaces,Yusuke Iwasawa;Kotaro Nakayama;Yutaka Matsuo,iwasawa@weblab.t.u-tokyo.ac.jp;nakayama@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,6;5;6,3;4;4,Reject,0,5,0.0,yes,10/27/17,The University of Tokyo;The University of Tokyo;The University of Tokyo,Adversarial Training;Privacy Protection;Random Subspace,57;57;57,45;45;45,-1;-1,NAN,NAN,n,4
1079,ICLR,2018,Evolutionary Expectation Maximization for Generative Models with Binary Latents,Enrico Guiraud;Jakob Drefs;Joerg Luecke,enrico.guiraud@cern.ch;jakob.heinrich.drefs@uni-oldenburg.de;joerg.luecke@uni-oldenburg.de,4;4;4,4;4;4,Reject,0,6,0.0,yes,10/27/17,CERN;University of Oldenburg;University of Oldenburg,unsupervised;learning;evolutionary;sparse;coding;noisyOR;BSC;EM;expectation-maximization;variational EM;optimization,-1;377;377,-1;-1;-1,-1;-1,europe,de,n,1;5
1080,ICLR,2018,Learnability of Learned Neural Networks,Rahul Anand Sharma;Navin Goyal;Monojit Choudhury;Praneeth Netrapalli,t-rahsha@microsoft.com;navingo@microsoft.com;monojitc@microsoft.com;praneeth@microsoft.com,7;6;4,4;4;4,Reject,0,6,0.0,yes,10/27/17,Microsoft;Microsoft;Microsoft;Microsoft,Learnability;Generalizability;Understanding Deep Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1081,ICLR,2018,Compact Neural Networks based on the Multiscale Entanglement Renormalization Ansatz,Andrew Hallam;Edward Grant;Vid Stojevic;Simone Severini;Andrew G. Green,andrew.hallam.10@ucl.ac.uk;edward.grant.16@ucl.ac.uk;vstojevic@gtn.ai;s.severini@ucl.ac.uk;andrew.green@ucl.ac.uk,5;5;4,3;4;4,Reject,0,3,0.0,yes,10/27/17,University College London;University College London;;University College London;University College London,Neural Networks;Tensor Networks;Tensor Trains,49;49;-1;49;49,-1;-1;-1;-1;-1,-1;-1,europe,uk,n,
1082,ICLR,2018,Online Hyper-Parameter Optimization,Damien Vincent;Sylvain Gelly;Nicolas Le Roux;Olivier Bousquet,damienv@google.com;sylvain.gelly@gmail.com;nicolas@le-roux.name;obousquet@gmail.com,4;5;4,3;3;3,Reject,0,1,0.0,yes,10/27/17,Google;Google;;Google,hyper-parameters;optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1083,ICLR,2018,Learning to Teach,Yang Fan;Fei Tian;Tao Qin;Xiang-Yang Li;Tie-Yan Liu,fyabc@mail.ustc.edu.cn;fetia@microsoft.com;taoqin@microsoft.com;tyliu@microsoft.com,8;9;5,4;3;4,Accept (Poster),0,10,0.0,yes,10/27/17,University of Science and Technology of China;Microsoft;Microsoft;Microsoft,,-1;-1;-1;-1,132;-1;-1;-1,-1;-1,NAN,NAN,n,8
1084,ICLR,2018,Word2net: Deep Representations of Language,Maja Rudolph;Francisco Ruiz;David Blei,marirudolph@gmail.com;f.ruiz@columbia.edu;david.blei@columbia.edu,5;4;4,5;4;4,Reject,0,3,0.0,yes,10/27/17,Bosch;Columbia University;Columbia University,neural language models;word embeddings;neural networks,-1;21;21,367;14;14,-1;-1,usa,usa,n,3
1085,ICLR,2018,The loss surface and expressivity of deep convolutional neural networks,Quynh Nguyen;Matthias Hein,quynh@cs.uni-saarland.de;hein@cs.uni-saarland.de,4;7;5;6,4;2;2;3,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Saarland University;Saarland University,convolutional neural networks;loss surface;expressivity;critical point;global minima;linear separability,82;82,-1;-1,-1;-1,europe,de,y,
1086,ICLR,2018,Combination of Supervised and Reinforcement Learning For Vision-Based Autonomous Control,Dmitry Kangin;Nicolas Pugeault,d.kangin@exeter.ac.uk;n.pugeault@exeter.ac.uk,4;5;3,5;3;4,Reject,0,4,0.0,yes,10/27/17,University of Exeter;University of Exeter,Reinforcement learning;deep learning;autonomous control,377;377,130;130,-1;-1,europe,gr,n,
1087,ICLR,2018,Gating out sensory noise in a spike-based Long Short-Term Memory network,Davide Zambrano;Isabella Pozzi;Roeland Nusselder;Sander Bohte,d.zambrano@cwi.nl;isabella.pozzi@cwi.nl;roeland.nusselder@gmail.com;s.m.bohte@cwi.nl,5;5;4,4;3;4,Reject,0,0,0.0,yes,10/27/17,Centrum voor Wiskunde en Informatica;Centrum voor Wiskunde en Informatica;;Centrum voor Wiskunde en Informatica,spiking neural networks;LSTM;recurrent neural networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1088,ICLR,2018,Learning to Infer Graphics Programs from Hand-Drawn Images,Kevin Ellis;Daniel Ritchie;Armando Solar-Lezama;Joshua B. Tenenbaum,ellisk@mit.edu;daniel_richie@brown.edu;asolar@csail.mit.edu;jbt@mit.edu,4;6;4,4;4;2,Reject,0,4,0.0,yes,10/27/17,Massachusetts Institute of Technology;Brown University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,program induction;HCI;deep learning,8;95;8;8,5;50;5;5,-1;-1,usa,usa,n,10
1089,ICLR,2018,Federated Learning: Strategies for Improving Communication Efficiency,Jakub Koneƒçn√Ω;H. Brendan McMahan;Felix X. Yu;Ananda Theertha Suresh;Dave Bacon;Peter Richt√°rik,konkey@google.com;mcmahan@google.com;felixyu@google.com;theertha@google.com;dabacon@google.com;peter.richtarik@kaust.edu.sa,5;7;5,3;5;5,Reject,0,4,0.0,yes,10/27/17,Google;Google;Google;Google;Google;KAUST,,-1;-1;-1;-1;-1;95,-1;-1;-1;-1;-1;-1,-1;-1,europe,gr,n,
1090,ICLR,2018,Convolutional Sequence Modeling Revisited,Shaojie Bai;J. Zico Kolter;Vladlen Koltun,shaojieb@cs.cmu.edu;zkolter@cs.cmu.edu;vkoltun@gmail.com,8;5;4,4;4;3,Invite to Workshop Track,1,9,4.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Intel,Temporal Convolutional Network;Sequence Modeling;Deep Learning,1;1;-1,24;24;-1,-1;-1,NAN,NAN,n,
1091,ICLR,2018,Searching for Activation Functions,Prajit Ramachandran;Barret Zoph;Quoc V. Le,prajitram@gmail.com;barretzoph@google.com;qvl@google.com,4;5;7,4;5;5,Invite to Workshop Track,5,8,0.0,yes,10/27/17,"University of Illinois, Urbana Champaign;Google;Google",meta learning;activation functions,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1092,ICLR,2018,On Convergence and Stability of GANs,Naveen Kodali;James Hays;Jacob Abernethy;Zsolt Kira,nkodali3@gatech.edu;hays@gatech.edu;prof@gatech.edu;zkira@gatech.edu,5;4;3,2;5;3,Reject,17,6,0.0,yes,10/27/17,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,GAN;Generative Adversarial Networks;Mode Collapse;Stability;Game Theory;Regret Minimization;Convergence;Gradient Penalty,13;13;13;13,33;33;33;33,-1;-1,usa,usa,y,5
1093,ICLR,2018,Training Autoencoders by Alternating Minimization,Sneha Kudugunta;Adepu Shankar;Surya Chavali;Vineeth Balasubramanian;Purushottam Kar,cs14btech11020@iith.ac.in;cs14resch11001@iith.ac.in;cs13b1028@iith.ac.in;vineethnb@iith.ac.in;purushot@cse.iitk.ac.in,6;4;7,4;4;5,Reject,0,3,0.0,yes,10/27/17,Indian Institute of Technology Hyderabad;Indian Institute of Technology Hyderabad;Indian Institute of Technology Hyderabad;Indian Institute of Technology Hyderabad;IIT Kanpur,Deep Learning;Autoencoders;Alternating Optimization,-1;-1;-1;-1;125,-1;-1;-1;-1;-1,-1;-1,asia,in,y,9
1094,ICLR,2018,Learning temporal evolution of probability distribution with Recurrent Neural Network,Kyongmin Yeo;Igor Melnyk;Nam Nguyen;Eun Kyung Lee,kyeo@us.ibm.com;igor.melnyk@ibm.com;nnguyen@us.ibm.com;eunkyung.lee@us.ibm.com,6;5;6,2;4;4,Reject,0,3,0.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines;International Business Machines,predictive distribution estimation;probabilistic RNN;uncertainty in time series prediction,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1095,ICLR,2018,LEARNING TO ORGANIZE KNOWLEDGE WITH N-GRAM MACHINES,Fan Yang;Jiazhong Nie;William W. Cohen;Ni Lao,fanyang1@cs.cmu.edu;niejiazhong@google.com;wcohen@cs.cmu.edu;nlao@google.com,4;5;4,4;4;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,Carnegie Mellon University;Google;Carnegie Mellon University;Google,neuro-symbolic reasoning;information extraction;learn to search,1;-1;1;-1,24;-1;24;-1,-1;-1,NAN,NAN,n,3
1096,ICLR,2018,Stabilizing GAN Training with Multiple Random Projections,Behnam Neyshabur;Srinadh Bhojanapalli;Ayan Chakrabarti,bneyshabur@ttic.edu;srinadh@ttic.edu;ayan@wustl.edu,5;3;8,4;5;4,Reject,0,4,0.0,yes,10/27/17,"Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Washington University, St. Louis",generative adversarial networks;stable training;low-dimensional projections;deep learning,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,y,5;4
1097,ICLR,2018,Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,Chelsea Finn;Sergey Levine,cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,6;6;7,3;1;1,Accept (Poster),0,6,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley,meta-learning;learning to learn;universal function approximation,-1;-1,18;18,-1;-1,usa,usa,y,6
1098,ICLR,2018,TCAV: Relative concept importance testing with Linear Concept Activation Vectors,Been Kim;Justin Gilmer;Martin Wattenberg;Fernanda Vi√©gas,beenkim@google.com;viegas@google.com;wattenberg@google.com;gilmer@google.com,4;4;5;3,4;3;2;5,Reject,0,6,0.0,yes,10/27/17,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,7
1099,ICLR,2018,Shifting Mean Activation Towards Zero with Bipolar Activation Functions,Lars Hiller Eidnes;Arild N√∏kland,larseidnes@gmail.com;arild.nokland@gmail.com,4;5;5,4;5;3,Invite to Workshop Track,0,4,2.0,yes,10/27/17,Itema;Norges teknisk-naturvitenskapelige universitet,,-1;-1,-1;-1,-1;-1,NAN,NAN,y,3
1100,ICLR,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Changyou Chen;Chunyuan Li;Liqun Chen;Wenlin Wang;Yunchen Pu;Lawrence Carin,cchangyou@gmail.com;chunyuan.li@duke.edu;lc267@duke.edu;wenlin.wang@duke.edu;yunchen.pu@duke.edu;lcarin@duke.edu,3;6;6,3;4;4,Reject,0,3,0.0,yes,10/27/17,"State University of New York, Buffalo;Duke University;Duke University;Duke University;Duke University;Duke University",continuous-time flows;efficient inference;density estimation;deep generative models,-1;39;39;39;39;39,-1;17;17;17;17;17,-1;-1,europe,se,y,5;4
1101,ICLR,2018,Large-scale Cloze Test Dataset Designed by Teachers,Qizhe Xie;Guokun Lai;Zihang Dai;Eduard Hovy,qizhex@gmail.com;guokun@cs.cmu.edu;zander.dai@gmail.com;hovy@cs.cmu.edu,4;7;4,4;4;4,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Google;Carnegie Mellon University,dataset;human-designed;language understanding,-1;1;-1;1,-1;24;-1;24,-1;-1,usa,usa,n,8
1102,ICLR,2018,Deep Learning is Robust to Massive Label Noise,David Rolnick;Andreas Veit;Serge Belongie;Nir Shavit,drolnick@mit.edu;av443@cornell.edu;sjb344@cornell.edu;shanir@csail.mit.edu,5;4;5,4;5;5,Reject,2,4,0.0,yes,10/27/17,Massachusetts Institute of Technology;Cornell University;Cornell University;Massachusetts Institute of Technology,label noise;weakly supervised learning;robustness of neural networks;deep learning;large datasets,8;5;5;8,5;19;19;5,-1;-1,usa,usa,n,
1103,ICLR,2018,Unsupervised Hierarchical Video Prediction,Nevan Wichers;Dumitru Erhan;Honglak Lee,wichersn@google.com;dumitru@google.com;honglak@google.com,4;4;4,4;4;4,Reject,0,2,0.0,yes,10/27/17,Google;Google;Google,video prediction;visual analogy network;unsupervised;hierarchical,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1104,ICLR,2018,One-shot and few-shot learning of word embeddings,Andrew Kyle Lampinen;James Lloyd McClelland,lampinen@stanford.edu;mcclelland@stanford.edu,4;3;4,4;4;4,Reject,3,3,0.0,yes,10/27/17,Stanford University;Stanford University,One-shot learning;embeddings;word embeddings;natural language processing;NLP,5;5,3;3,-1;-1,usa,usa,n,6;3
1105,ICLR,2018,Unbiasing Truncated Backpropagation Through Time,Corentin Tallec;Yann Ollivier,corentin.tallec@polytechnique.edu;yann@yann-ollivier.org,6;5;5,3;4;4,Reject,0,0,0.0,yes,10/27/17,Ecole polytechnique;Facebook,RNN,-1;-1,115;-1,-1;-1,NAN,NAN,y,3;1;10
1106,ICLR,2018,Joint autoencoders: a flexible meta-learning framework,Baruch Epstein;Ron Meir;Tomer Michaeli,baruch.epstein@gmail.com;rmeir@ee.technion.ac.il;tomer.m@ee.technion.ac.il,4;5;5,4;3;4,Reject,0,4,0.0,yes,10/27/17,"Technion, Technion;Technion, Technion;Technion, Technion",transfer learning;domain adaptation;unsupervised learning;autoencoders;multi-task learning,21;21;21,-1;-1;-1,-1;-1,NAN,NAN,n,6
1107,ICLR,2018,On the Use of Word Embeddings Alone to Represent Natural Language Sequences,Dinghan Shen;Guoyin Wang;Wenlin Wang;Martin Renqiang Min;Qinliang Su;Yizhe Zhang;Ricardo Henao;Lawrence Carin,dinghan.shen@duke.edu;guoyin.wang@duke.edu;wenlin.wang@duke.edu;renqiang@nec-labs.com;qinliang.su@duke.edu;yizhe.zhang@duke.edu;ricardo.henao@duke.edu;lcarin@duke.edu,7;5;6,4;4;5,Reject,0,14,0.0,yes,10/27/17,Duke University;Duke University;Duke University;NEC-Labs;Duke University;Duke University;Duke University;Duke University,Natural Language Processing;Deep Learning,39;39;39;-1;39;39;39;39,17;17;17;-1;17;17;17;17,-1;-1,europe,se,n,3;1
1108,ICLR,2018,Byte-Level Recursive Convolutional Auto-Encoder for Text,Xiang Zhang;Yann LeCun,xiang@cs.nyu.edu;yann@cs.nyu.edu,7;5;5,4;3;5,Reject,0,0,1.0,yes,10/27/17,New York University;New York University,,21;21,27;27,-1;-1,usa,usa,n,
1109,ICLR,2018,Phase Conductor on Multi-layered Attentions for Machine Comprehension,Rui Liu;Wei Wei;Weiguang Mao;Maria Chikina,ult.rui.liu@gmail.com;weiwei@cs.cmu.edu;mwg10.thu@gmail.com;mchikina@gmail.com,8;5;5,3;5;4,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;University of Pittsburgh;University of Pittsburgh,Attention Model;Machine Comprehension;Question Answering,-1;1;67;-1,-1;24;100;-1,-1;-1,asia,in,n,8;3
1110,ICLR,2018,Gaussian Prototypical Networks for Few-Shot Learning on Omniglot,Stanislav Fort,sfort1@stanford.edu,4;3;3,4;4;4,Reject,0,0,0.0,yes,10/27/17,Stanford University,one-shot learning;few-shot learning;Omniglot,5,3,-1,usa,usa,n,6
1111,ICLR,2018,Anomaly Detection with Generative Adversarial Networks,Lucas Deecke;Robert Vandermeulen;Lukas Ruff;Stephan Mandt;Marius Kloft,ldeecke@gmail.com;vandermeulen@cs.uni-kl.de;contact@lukasruff.com;stephan.mandt@disneyresearch.com;kloft@cs.uni-kl.de,4;6;4,5;4;4,Reject,0,3,0.0,yes,10/27/17,"University of Edinburgh;TU Kaiserslautern;Aignostics GmbH;Disney Research, Disney;TU Kaiserslautern",Anomaly Detection;Generative Adversarial Networks;Deep Learning;Inverse Problems,-1;162;-1;-1;162,-1;-1;-1;-1;-1,-1;-1,europe,de,n,5;4
1112,ICLR,2018,Learning Gaussian Policies from Smoothed Action Value Functions,Ofir Nachum;Mohammad Norouzi;George Tucker;Dale Schuurmans,ofirnachum@google.com;mnorouzi@google.com;gjt@google.com;schuurmans@google.com,6;6;5,4;4;3,Reject,0,3,0.0,yes,10/27/17,Google;Google;Google;Google,Reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1113,ICLR,2018,Spectral Graph Wavelets for Structural Role Similarity in Networks,Claire Donnat;Marinka Zitnik;David Hallac;Jure Leskovec,cdonnat@stanford.edu;marinka@cs.stanford.edu;hallac@stanford.edu;jure@cs.stanford.edu,5;5;3,5;4;4,Reject,0,3,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University;Stanford University,Graphs;Structural Similarities;Spectral Graph Wavelets;Graph Signal Processing;Unsupervised Learning,5;5;5;5,3;3;3;3,-1;-1,usa,usa,y,1;10
1114,ICLR,2018,Adversarial Spheres,Justin Gilmer;Luke Metz;Fartash Faghri;Sam Schoenholz;Maithra Raghu;Martin Wattenberg;Ian Goodfellow,gilmer@google.com;lmetz@google.com;fartash.faghri@google.com;schsam@google.com;maithra@google.com;goodfellow@google.com,4;5;3,4;3;3,Invite to Workshop Track,0,2,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,Adversarial Examples;Deep Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,2;1;4
1115,ICLR,2018,Modifying memories in a Recurrent Neural Network Unit,Vlad Velici;Adam Pr√ºgel-Bennett,vsv1g12@soton.ac.uk;apb@soton.ac.uk,4;4;3,3;3;4,Reject,1,1,0.0,yes,10/27/17,University of Southampton;University of Southampton,LSTM;RNN;rotation matrix;long-term memory;natural language processing,224;224,126;126,-1;-1,europe,uk,n,
1116,ICLR,2018,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,Tuomas Haarnoja;Aurick Zhou;Pieter Abbeel;Sergey Levine,haarnoja@berkeley.edu;azhou42@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,3;7;5,4;4;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,deep reinforcement learning;maximum entropy learning;stochastic actor-critic,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,y,
1117,ICLR,2018,Challenges in Disentangling Independent Factors of Variation,Attila  Szabo;Qiyang  Hu;Tiziano  Portenier;Matthias  Zwicker;Paolo  Favaro,szabo@inf.unibe.ch;hu@inf.unibe.ch;portenier@inf.unibe.ch;zwicker@inf.unibe.ch;paolo.favaro@inf.unibe.ch,6;5;5,4;3;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,University of Bern;University of Bern;University of Bern;University of Bern;University of Bern,disentangling;factors;attribute;transfer;autoencoder;GAN,224;224;224;224;224,105;105;105;105;105,-1;-1,europe,uk,n,1;5;4
1118,ICLR,2018,Ground-Truth Adversarial Examples,Nicholas Carlini;Guy Katz;Clark Barrett;David L. Dill,nicholas@carlini.com;katz911@gmail.com;barrett@cs.stanford.edu;dill@cs.stanford.edu,5;4;6,4;4;3,Reject,0,0,0.0,yes,10/27/17,Google;Hebrew University of Jerusalem;Stanford University;Stanford University,adversarial examples;neural networks;formal verification;ground truths,-1;67;5;5,-1;205;3;3,-1;-1,usa,usa,n,4
1119,ICLR,2018,Learning Parsimonious Deep Feed-forward Networks,Zhourong Chen;Xiaopeng Li;Nevin L. Zhang,zchenbb@cse.ust.hk;xlibo@cse.ust.hk;lzhang@cse.ust.hk,5;4;5,5;2;2,Reject,0,5,0.0,yes,10/27/17,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Parsimonious Deep Feed-forward Networks;structure learning;classification;overfitting;fewer parameters;high interpretability,-1;-1;-1,44;44;44,-1;-1,NAN,NAN,n,
1120,ICLR,2018,Learning Deep Generative Models of Graphs,Yujia Li;Oriol Vinyals;Chris Dyer;Razvan Pascanu;Peter Battaglia,yujiali@google.com;vinyals@google.com;cdyer@google.com;razp@google.com;peterbattaglia@google.com,5;6;6,3;3;4,Invite to Workshop Track,2,7,0.0,yes,10/27/17,Google;Google;Google;Google;Google,Generative Model of Graphs,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,10;5
1121,ICLR,2018,An information-theoretic analysis of deep latent-variable models,Alex Alemi;Ben Poole;Ian Fischer;Josh Dillon;Rif A. Saurus;Kevin Murphy,alemi@google.com;poole@cs.stanford.edu;iansf@google.com;jvdillon@google.com;rif@google.com;kpmurphy@google.com,5;7;5,4;5;5,Reject,1,5,0.0,yes,10/27/17,Google;Stanford University;Google;Google;Google;Google,information theory;generative models;latent variable models;variational autoencoders,-1;5;-1;-1;-1;-1,-1;3;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;5
1122,ICLR,2018,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,Ofir Nachum;Mohammad Norouzi;Kelvin Xu;Dale Schuurmans,ofirnachum@google.com;mnorouzi@google.com;iamkelvinxu@gmail.com;schuurmans@google.com,6;5;5,4;4;1,Accept (Poster),0,5,0.0,yes,10/27/17,Google;Google;University of California Berkeley;Google,Reinforcement learning,-1;-1;-1;-1,-1;-1;18;-1,-1;-1,NAN,NAN,n,
1123,ICLR,2018,Modular Continual Learning in a Unified Visual Environment,Kevin T. Feigelis;Blue Sheffer;Daniel L. K. Yamins,feigelis@stanford.edu;bsheffer@stanford.edu;yamins@stanford.edu,6;8;8,2;3;2,Accept (Poster),0,5,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,Continual Learning;Neural Modules;Interface Learning;Task Switching;Reinforcement Learning;Visual Decision Making,5;5;5,3;3;3,-1;-1,usa,usa,n,
1124,ICLR,2018,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Yang Song;Taesup Kim;Sebastian Nowozin;Stefano Ermon;Nate Kushman,yangsong@cs.stanford.edu;taesup.kim@umontreal.ca;sebastian.nowozin@microsoft.com;ermon@cs.stanford.edu;nkushman@microsoft.com,7;7;7,4;4;4,Accept (Poster),0,3,0.0,yes,10/27/17,Stanford University;University of Montreal;Microsoft;Stanford University;Microsoft,Adversarial Examples;Generative Models;Purification;Hypothesis Testing,5;125;-1;5;-1,3;108;-1;3;-1,-1;-1,NAN,NAN,n,4
1125,ICLR,2018,BinaryFlex: On-the-Fly Kernel Generation in Binary Convolutional Networks,Vincent W.-S. Tseng;Sourav Bhattachary;Javier Fern√°ndez Marqu√©s;Milad Alizadeh;Catherine Tong;Nicholas Donald Lane,wt262@cornell.edu;sourav.bhattacharya@nokia-bell-labs.com;javier.fernandezmarques@cs.ox.ac.uk;milad.alizadeh@cs.ox.ac.uk;eu.tong@cs.ox.ac.uk;nicholas.lane@cs.ox.uk,5;5;3,3;3;4,Reject,0,4,0.0,yes,10/27/17,Cornell University;Bell Labs;University of Oxford;University of Oxford;University of Oxford;University of Oxford,,5;-1;39;39;39;-1,19;-1;1;1;1;-1,-1;-1,asia,in,n,2
1126,ICLR,2018,Neural Networks for irregularly observed continuous-time Stochastic Processes,Francois W. Belletti;Alexander Ku;Joseph E. Gonzalez,francois.belletti@berkeley.edu;alexku@berkeley.edu;jegonzal@berkeley.edu,5;5;2,5;4;3,Reject,0,4,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep Learning;Stochastic Processes;Time Series Analysis,-1;-1;-1,18;18;18,-1;-1,usa,usa,y,
1127,ICLR,2018,Learning to diagnose from scratch by exploiting dependencies among labels,Li Yao;Eric Poblenz;Dmitry Dagunts;Ben Covington;Devon Bernard;Kevin Lyman,li@enlitic.com;eric@enlitic.com;dmitry@enlitic.com;ben@enlitic.com;devon@entlic.com;kevin@enlitic.com,6;6;6,3;4;3,Reject,0,3,0.0,yes,10/27/17,Enlitic;Enlitic;Enlitic;Enlitic;Entlic;Enlitic,medical diagnosis;medical imaging;multi-label classification,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1128,ICLR,2018,Towards Provable Control for Unknown Linear Dynamical Systems,Sanjeev Arora;Elad Hazan;Holden Lee;Karan Singh;Cyril Zhang;Yi Zhang,arora@cs.princeton.edu;ehazan@cs.princeton.edu;holdenl@princeton.edu;karans@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,4;7;5,3;3;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Princeton University;Princeton University;Princeton University;Princeton University;Princeton University;Princeton University,optimal control;reinforcement learning,30;30;30;30;30;30,7;7;7;7;7;7,-1;-1,usa,usa,y,
1129,ICLR,2018,Depth separation and weight-width trade-offs for sigmoidal neural networks,Amit Deshpande;Navin Goyal;Sushrut Karmalkar,amitdesh@microsoft.com;navingo@microsoft.com;sushrutk@cs.utexas.edu,6;5;3,4;4;5,Reject,0,4,0.0,yes,10/27/17,"Microsoft;Microsoft;University of Texas, Austin",depth separation;neural networks;weights-width trade-off,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,y,
1130,ICLR,2018,Time Limits in Reinforcement Learning,Fabio Pardo;Arash Tavakoli;Vitaly Levdik;Petar Kormushev,f.pardo@imperial.ac.uk;a.tavakoli@imperial.ac.uk;v.levdik@imperial.ac.uk;p.kormushev@imperial.ac.uk,5;4;4,4;5;4,Reject,0,7,0.0,yes,10/27/17,Imperial College London;Imperial College London;Imperial College London;Imperial College London,reinforcement learning;Markov decision processes;deep learning,49;49;49;49,8;8;8;8,-1;-1,europe,uk,n,10
1131,ICLR,2018,Learning Independent Features with Adversarial Nets for Non-linear ICA,Philemon Brakel;Yoshua Bengio,pbpop3@gmail.com;yoshua.bengio@umontreal.ca,5;3;6,5;5;3,Reject,0,4,0.0,yes,10/27/17,Google;University of Montreal,adversarial networks;ica;unsupervised;independence,-1;125,-1;108,-1;-1,canada,ca,n,4
1132,ICLR,2018,Discovering the mechanics of hidden neurons,Simon Carbonnelle;Christophe De Vleeschouwer,simon.carbonnelle@uclouvain.be;christophe.devleeschouwer@uclouvain.be,7;4;5,4;4;4,Reject,1,7,0.0,yes,10/27/17,UCL;UCL,deep learning;experimental analysis;hidden neurons,224;224,16;16,-1;-1,europe,gr,n,
1133,ICLR,2018,DNN Model Compression Under Accuracy Constraints,Soroosh Khoram;Jing Li,khoram@wisc.edu;jli@ece.wisc.edu,4;3;3,3;3;5,Reject,0,0,0.0,yes,10/27/17,University of Southern California;University of Southern California,DNN Compression;Weigh-sharing;Model Compression,27;27,66;66,-1;-1,usa,usa,n,
1134,ICLR,2018,Using Deep Reinforcement Learning to Generate Rationales for Molecules,Benson Chen;Connor Coley;Regina Barzilay;Tommi Jaakkola,bensonc@mit.edu;ccoley@mit.edu;regina@csail.mit.edu;tommi@csail.mit.edu,5;5;5,4;4;4,Reject,0,3,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Reinforcement Learning;Chemistry;Interpretable Models,8;8;8;8,5;5;5;5,-1;-1,usa,usa,n,10
1135,ICLR,2018,Fast Node Embeddings: Learning Ego-Centric Representations,Tiago Pimentel;Adriano Veloso;Nivio Ziviani,tpimentel@dcc.ufmg.br;adrianov@dcc.ufmg.br;nivio@dcc.ufmg.br,5;6;4,4;4;5,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Universidade Federal de Minas Gerais;Universidade Federal de Minas Gerais;Universidade Federal de Minas Gerais,Graph;Node Embeddings;Distributed Representations;Learning Representations,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;10
1136,ICLR,2018,HybridNet: A Hybrid Neural Architecture to Speed-up Autoregressive  Models,Yanqi Zhou;Wei Ping;Sercan Arik;Kainan Peng;Greg Diamos,zhouyanqi@baidu.com;pingwei01@baidu.com;sercanarik@baidu.com;pengkainan@baidu.com;gregdiamos@baidu.com,6;4;4,5;5;5,Reject,0,3,0.0,yes,10/27/17,Baidu;Baidu;Baidu;Baidu;Baidu,neural architecture;inference time reduction;hybrid model,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1137,ICLR,2018,Sparse Regularized Deep Neural Networks For Efficient Embedded Learning,Jia Bi,jb4e14@soton.ac.uk,4;4;2,4;5;3,Reject,0,3,0.0,yes,10/27/17,University of Southampton,Sparse representation;Compression Deep Learning Models;L1 regularisation;Optimisation.,224,126,-1,europe,uk,n,9
1138,ICLR,2018,GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets,Jinsung Yoon;James Jordon;Mihaela van der Schaar,jsyoon0823@gmail.com;james.jordon@hertford.ox.ac.uk;mihaela.vanderschaar@oxford-man.ox.ac.uk,6;6;6,4;3;3,Accept (Poster),0,3,0.0,yes,10/27/17,Google;University of Oxford;University of Oxford,Individualized Treatment Effects;Counterfactual Estimation;Generative Adversarial Nets,-1;39;39,-1;1;1,-1;-1,europe,uk,n,5;4
1139,ICLR,2018,Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification,Kshiteesh Hegde;Malik Magdon-Ismail;Ram Ramanathan;Bishal Thapa,hegdek2@rpi.edu;magdon@rpi.edu;ram@gotenna.com;bishal.thapa@raytheon.com,3;6;6,3;3;3,Reject,0,6,0.0,yes,10/27/17,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute;Lyric Labs;Raytheon,deep learning;transfer learning;adjacency matrices;image feature representation;Caffe;graph classification,224;224;-1;-1,304;304;-1;-1,-1;-1,NAN,NAN,n,6;10
1140,ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Irina Higgins;Nicolas Sonnerat;Loic Matthey;Arka Pal;Christopher P Burgess;Matko Bo≈°njak;Murray Shanahan;Matthew Botvinick;Demis Hassabis;Alexander Lerchner,irinah@google.com;sonnerat@google.com;lmatthey@google.com;arkap@google.com;cpburgess@google.com;matko@google.com;mshanahan@google.com;botvinick@google.com;demishassabis@google.com;lerchner@google.com,5;6;7,4;4;4,Accept (Poster),0,6,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,grounded visual concepts;compositional representation;concept hierarchy;disentangling;beta-VAE;variational autoencoder;deep learning;generative model,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
1141,ICLR,2018,Variance-based Gradient Compression for Efficient Distributed Deep Learning,Yusuke Tsuzuku;Hiroto Imachi;Takuya Akiba,tsuzuku@ms.k.u-tokyo.ac.jp;imachi@preferred.jp;akiba@preferred.jp,6;4;7,4;4;4,Invite to Workshop Track,0,7,1.0,yes,10/27/17,"The University of Tokyo;Preferred Networks, Inc.;Preferred Networks, Inc.",distributed deep learning;gradient compression;collective communication;data parallel distributed sgd;image classification,57;-1;-1,45;-1;-1,-1;-1,NAN,NAN,n,1
1142,ICLR,2018,Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks,Yau-Shian Wang;Hung-Yi Lee,king6101@gmail.com;tlkagkb93901106@gmail.com,5;4;6,4;4;4,Reject,0,5,0.0,yes,10/27/17,National Taiwan University;National Taiwan University,unsupervised learning;text summarization;adversarial training,39;-1,52;-1,-1;-1,asia,in,n,
1143,ICLR,2018,Subspace Network: Deep Multi-Task Censored Regression for Modeling Neurodegenerative Diseases,Mengying Sun;Inci M. Baytas;Zhangyang Wang;Jiayu Zhou,sunmeng2@msu.edu;baytasin@msu.edu;atlaswang@tamu.edu;jiayuz@msu.edu,4;5;5,5;3;4,Reject,0,7,0.0,yes,10/27/17,Michigan State University;Michigan State University;Texas A&M;Michigan State University,subspace;censor;multi-task;deep network,125;125;49;125,84;84;160;84,-1;-1,usa,usa,y,5
1144,ICLR,2018,UCB EXPLORATION VIA Q-ENSEMBLES,Richard Y. Chen;Szymon Sidor;Pieter Abbeel;John Schulman,richardchen@openai.com;szymon@openai.com;pabbeel@cs.berkeley.edu;joschu@openai.com,6;7;5,5;4;3,Reject,0,12,0.0,yes,10/27/17,OpenAI;OpenAI;University of California Berkeley;OpenAI,Reinforcement learning;Q-learning;ensemble method;upper confidence bound,-1;-1;-1;-1,-1;-1;18;-1,-1;-1,NAN,NAN,n,
1145,ICLR,2018,Convergence rate of sign stochastic gradient descent for non-convex functions,Jeremy Bernstein;Kamyar Azizzadenesheli;Yu-Xiang Wang;Anima Anandkumar,bernstein@caltech.edu;kazizzad@uci.edu;yuxiangw@cs.cmu.edu;animakumar@gmail.com,4;4;5,4;4;5,Reject,0,15,2.0,yes,10/27/17,"California Institute of Technology;University of California, Irvine;Carnegie Mellon University;California Institute of Technology",sign;stochastic;gradient;non-convex;optimization;gradient;quantization;convergence;rate,125;-1;1;125,3;99;24;3,-1;-1,usa,usa,y,1;9
1146,ICLR,2018,Empirical Analysis of the Hessian of Over-Parametrized Neural Networks,Levent Sagun;Utku Evci;V. Ugur Guney;Yann Dauphin;Leon Bottou,leventsagun@gmail.com;ue225@nyu.edu;vug@fb.com;yann@dauphin.io;leonb@fb.com,5;4;5,2;4;4,Invite to Workshop Track,0,7,0.0,yes,10/27/17,Facebook;New York University;Facebook;Google;Facebook,Deep Learning;Over-parametrization;Hessian;Eigenvalues;Flat minima;Large batch Small batch,-1;21;-1;-1;-1,-1;27;-1;-1;-1,-1;-1,NAN,NAN,n,9
1147,ICLR,2018,CNNs as Inverse Problem Solvers and Double Network Superresolution,Cem TARHAN;G√∂zde BOZDAƒûI AKAR,cemtarhan@aselsan.com.tr;bozdagi@metu.edu.tr,6;3;4,2;5;4,Reject,0,3,0.0,yes,10/27/17,Aselsan.tr;METU,superresolution;convolutional neural network;sparse representation;inverse problem,-1;224,-1;-1,-1;-1,asia,bd,y,
1148,ICLR,2018,IVE-GAN: Invariant Encoding Generative Adversarial Networks,Robin Winter;Djork-Arn√® Clevert,robin.winter@bayer.com;djork-arne.clevert@bayer.com,5;4;5,4;5;4,Reject,2,0,0.0,yes,10/27/17,Bayer Ag;Bayer Ag,Deep learning;Unsupervised Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,5;4
1149,ICLR,2018,Composable Planning with Attributes,Amy Zhang;Adam Lerer;Sainbayar Sukhbaatar;Rob Fergus;Arthur Szlam,amyzhang@fb.com;alerer@fb.com;sainbar@cs.nyu.edu;fergus@cs.nyu.edu;aszlam@fb.com,5;4;7,4;5;3,Reject,0,5,0.0,yes,10/27/17,Facebook;Facebook;New York University;New York University;Facebook,Planning;Compositionality;Attributes;Reinforcement learning,-1;-1;21;21;-1,-1;-1;27;27;-1,-1;-1,NAN,NAN,n,10
1150,ICLR,2018,How do deep convolutional neural networks learn from raw audio waveforms?,Yuan Gong;Christian Poellabauer,ygong1@nd.edu;cpoellab@nd.edu,3;3;2,4;5;5,Reject,0,7,0.0,yes,10/27/17,University of Notre Dame;University of Notre Dame,Convolutional neural networks;Audio processing;Speech processing,125;125,150;150,-1;-1,usa,usa,n,
1151,ICLR,2018,Relevance of Unsupervised Metrics in Task-Oriented Dialogue for Evaluating Natural Language Generation,Shikhar Sharma;Layla El Asri;Hannes Schulz;Jeremie Zumer,shikhar.sharma@microsoft.com;layla.elasri@microsoft.com;hannes.schulz@microsoft.com;jeremie_zumer@hotmail.com,4;5;5,4;4;3,Reject,0,3,0.0,yes,10/27/17,Microsoft;Microsoft;Microsoft;University of Montreal,task-oriented dialog;goal-oriented dialog;nlg evaluation;natural language generation;automated metrics for nlg,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,3
1152,ICLR,2018,Evaluation of generative networks through their data augmentation capacity,Timoth√©e Lesort;Florian Bordes;Jean-Francois Goudou;David Filliat,t.lesort@gmail.com;florian.bordes@umontreal.ca;jean-francois.goudou@thalesgroup.com;david.filliat@ensta-paristech.fr,3;3;5,5;5;3,Reject,0,3,0.0,yes,10/27/17,University of Montreal;University of Montreal;Thalesgroup;ENSTA ParisTech,Generative models;Evaluation of generative models;Data Augmentation,125;125;-1;-1,108;108;-1;-1,-1;-1,NAN,NAN,n,5;4
1153,ICLR,2018,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,Jie Chen;Tengfei Ma;Cao Xiao,chenjie@us.ibm.com;tengfei.ma1@ibm.com;cxiao@us.ibm.com,6;7;7;8,4;2;4;4,Accept (Poster),2,20,1.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines,Graph convolutional networks;importance sampling,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,10
1154,ICLR,2018,Interpretable and Pedagogical Examples,Smitha Milli;Pieter Abbeel;Igor Mordatch,smilli@berkeley.edu;pabbeel@cs.berkeley.edu;igor.mordatch@gmail.com,8;8;4,3;4;3,Reject,0,3,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of Washington,machine teaching;interpretability;communication;cognitive science,-1;-1;8,18;18;25,-1;-1,usa,usa,n,
1155,ICLR,2018,On the Generalization Effects of DenseNet Model Structures ,Yin Liu;Vincent Chen,liuyin14@mails.tsinghua.edu.cn;389091983@qq.com,2;3;3,5;4;4,Reject,0,0,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;QQ.com",Skip connection;generalization;gegularization;deep network;representation.,5;-1,30;-1,-1;-1,NAN,NAN,n,1
1156,ICLR,2018,INTERPRETATION OF NEURAL NETWORK IS FRAGILE,Amirata Ghorbani;Abubakar Abid;James Zou,amiratag@stanford.edu;a12d@stanford.edu;jamesz@stanford.edu,6;4;5,2;4;5,Reject,9,8,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,Adversarial Attack;Interpretability;Saliency Map;Influence Function;Robustness;Machine Learning;Deep Learning;Neural Network,5;5;5,3;3;3,-1;-1,usa,usa,n,4
1157,ICLR,2018,Faster Discovery of Neural Architectures by Searching for Paths in a Large Model,Hieu Pham;Melody Y. Guan;Barret Zoph;Quoc V. Le;Jeff Dean,hyhieu@cmu.edu;mguan@stanford.edu;barretzoph@google.com;qvl@google.com;jeff@google.com,6;5;5,2;3;2,Invite to Workshop Track,4,14,0.0,yes,10/27/17,Carnegie Mellon University;Stanford University;Google;Google;Google,neural architecture search,1;5;-1;-1;-1,24;3;-1;-1;-1,-1;-1,NAN,NAN,n,
1158,ICLR,2018,Deep Lipschitz networks and Dudley GANs,Ehsan Abbasnejad;Javen Shi;Anton van den Hengel,ehsan.abbasnejad@adelaide.edu.au;javen.shi@adelaide.edu.au;anton.vandenhengel@adelaide.edu.au,8;5;5,4;3;1,Reject,0,3,0.0,yes,10/27/17,The University of Adelaide;The University of Adelaide;The University of Adelaide,GAN;Lipschitz neural network,95;95;95,134;134;134,-1;-1,NAN,NAN,y,1;5;4
1159,ICLR,2018,Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning,Wenbin Li;Jeannette Bohg;Mario Fritz,wenbinli@mpi-inf.mpg.de;bohg@stanford.edu;mfritz@mpi-inf.mpg.de,5;4;5,4;4;3,Reject,0,0,0.0,yes,10/27/17,Max-Planck Institute;Stanford University;Max-Planck Institute,,-1;5;-1,-1;3;-1,-1;-1,NAN,NAN,n,1
1160,ICLR,2018,XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings,Amelie Royer;Konstantinos Bousmalis;Stephan Gouws;Fred Bertsch;Inbar Mosseri;Forrester Cole;Kevin Murphy,aroyer@ist.ac.at;konstantinos@google.com;sgouws@google.com;fredbertsch@google.com;inbarm@google.com;fcole@google.com;kpmurphy@google.com,3;4;4,5;4;3,Reject,2,9,0.0,yes,10/27/17,Institute of Science and Technology Austria;Google;Google;Google;Google;Google;Google,unsupervised;gan;domain adaptation;style transfer;semantic;image translation;dataset,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
1161,ICLR,2018,Meta-Learning Transferable Active Learning Policies by Deep Reinforcement Learning,Kunkun Pang;Mingzhi Dong;Timothy Hospedales,k.pang@ed.ac.uk;mingzhi.dong.13@ucl.ac.uk;t.hospedales@ed.ac.uk,6;7;6,3;4;4,Reject,0,6,0.0,yes,10/27/17,University of Edinburgh;University College London;University of Edinburgh,Active Learning;Deep Reinforcement Learning,30;49;30,27;-1;27,-1;-1,europe,uk,n,6
1162,ICLR,2018,Feature Map Variational Auto-Encoders,Lars Maal√∏e;Ole Winther,larsma@dtu.dk;olwi@dtu.dk,5;3;6,4;3;4,Reject,14,5,0.0,yes,10/27/17,Technical University of Denmark;Technical University of Denmark,deep learning;representation learning;variational auto-encoders;variational inference;generative models,-1;-1,153;153,-1;-1,NAN,NAN,n,5
1163,ICLR,2018,Structured Exploration via Hierarchical Variational Policy Networks,Stephan Zheng;Yisong Yue,stephan@caltech.edu;yyue@caltech.edu,4;7;5,5;3;3,Reject,0,8,0.0,yes,10/27/17,California Institute of Technology;California Institute of Technology,Deep Reinforcement Learning;Structured Variational Inference;Multi-agent Coordination;Multi-agent Learning,125;125,3;3,-1;-1,usa,usa,n,
1164,ICLR,2018,Bayesian Time Series Forecasting with Change Point and Anomaly Detection,Anderson Y. Zhang;Miao Lu;Deguang Kong;Jimmy Yang,ye.zhang@yale.edu;mlu@oath.com;dkong@oath.com;jianyang@oath.com,5;6;4,5;3;5,Reject,0,3,0.0,yes,10/27/17,Yale University;Oath;Oath;Oath,Time Series Forecasting;Change Point Detection;Anomaly Detection;State Space Model;Bayesian,82;-1;-1;-1,12;-1;-1;-1,-1;-1,usa,usa,y,11
1165,ICLR,2018,An empirical study on evaluation metrics of generative adversarial networks,Gao Huang;Yang Yuan;Qiantong Xu;Chuan Guo;Yu Sun;Felix Wu;Kilian Weinberger,gh349@cornell.edu;yy528@cornell.edu;qx57@cornell.edu;cg563@cornell.edu;yusun@berkeley.edu;fw245@cornell.edu;kqw4@cornell.edu,8;7;5;5,3;4;5;3,Reject,2,11,0.0,yes,10/27/17,Cornell University;Cornell University;Cornell University;Cornell University;University of California Berkeley;Cornell University;Cornell University,generative adversarial networks;evaluation metric,5;5;5;5;-1;5;5,19;19;19;19;18;19;19,-1;-1,usa,usa,n,5;4
1166,ICLR,2018,Explaining the Mistakes of Neural Networks with Latent Sympathetic Examples,Riaan Zoetmulder;Efstratios Gavves;Peter O'Connor,riaan.zoetmulder@student.uva.nl;egavves@uva.nl;peter.ed.oconnor@gmail.com,4;4;6,5;3;4,Reject,0,4,0.0,yes,10/27/17,University of Amsterdam;University of Amsterdam;University of Amsterdam,Deep learning;Adversarial Examples;Difference Target Propagation;Generative Modelling;Classifiers;Explaining;Sympathetic Examples,125;125;-1,59;59;-1,-1;-1,asia,in,n,5;4
1167,ICLR,2018,FAST READING COMPREHENSION WITH CONVNETS,Felix Wu;Ni Lao;John Blitzer;Guandao Yang;Kilian Weinberger,fw245@cornell.edu;nlao@google.com;blitzer@google.com;gy46@cornell.edu;kqw4@cornell.edu,4;7;5,4;3;4,Reject,0,0,0.0,yes,10/27/17,Cornell University;Google;Google;Cornell University;Cornell University,reading comprehension;question answering;CNN;ConvNet;Inference,5;-1;-1;5;5,19;-1;-1;19;19,-1;-1,usa,usa,n,
1168,ICLR,2018,Block-Sparse Recurrent Neural Networks,Sharan Narang;Eric Undersander;Gregory Diamos,sharan@baidu.com;undersandereric@baidu.com;gdiamos@baidu.com,5;7;5,3;4;4,Reject,0,8,0.0,yes,10/27/17,Baidu;Baidu;Baidu,Pruning;block sparsity;structured sparsity;Recurrent Neural Networks;Speech Recognition,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
1169,ICLR,2018,Bias-Variance Decomposition for Boltzmann Machines,Mahito Sugiyama;Koji Tsuda;Hiroyuki Nakahara,mahito@nii.ac.jp;tsuda@k.u-tokyo.ac.jp;hiro@brain.riken.jp,5;7;5,2;5;5,Reject,0,3,0.0,yes,10/27/17,National Institute of Informatics;The University of Tokyo;RIKEN,Boltzmann machine;bias-variance decomposition;information geometry,-1;57;-1,-1;45;-1,-1;-1,NAN,NAN,y,1
1170,ICLR,2018,Unseen Class Discovery in Open-world Classification,Lei Shu;Hu Xu;Bing Liu,lshu3@uic.edu;hxu48@uic.edu;liub@uic.edu,5;5;4,4;5;4,Reject,0,0,0.0,yes,10/27/17,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
1171,ICLR,2018,DLVM: A modern compiler infrastructure for deep learning systems,Richard Wei;Lane Schwartz;Vikram Adve,xwei12@illinois.edu;lanes@illinois.edu;vadve@illinois.edu,5;7;5,4;4;3,Invite to Workshop Track,0,4,0.0,yes,10/27/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",deep learning;automatic differentiation;algorithmic differentiation;domain specific languages;neural networks;programming languages;DSLs,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,10
1172,ICLR,2018,Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design,Daniel Neil;Marwin Segler;Laura Guasch;Mohamed Ahmed;Dean Plumbley;Matthew Sellwood;Nathan Brown,daniel.neil@benevolent.ai;marwin.segler@benevolent.ai;laura.guasch@benevolent.ai;mohamed.ahmed@benevolent.ai;dean.plumbley@benevolent.ai;matthew.sellwood@benevolent.ai;nathan.brown@benevolent.ai,4;7;6,2;4;3,Invite to Workshop Track,0,6,1.0,yes,10/27/17,BenevolentAI;BenevolentAI;BenevolentAI;BenevolentAI;BenevolentAI;BenevolentAI;BenevolentAI,reinforcement learning;molecule design;de novo design;ppo;sample-efficient reinforcement learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1173,ICLR,2018,Transfer Learning to Learn with Multitask Neural Model Search,Catherine Wong;Andrea Gesmundo,catwong@cs.stanford.edu;agesmundo@google.com,5;7;4,2;3;4,Reject,0,7,0.0,yes,10/27/17,Stanford University;Google,Learning to Learn;Meta learning;Reinforcement learning;Transfer learning,5;-1,3;-1,-1;-1,NAN,NAN,n,6
1174,ICLR,2018,Multiple Source Domain Adaptation with Adversarial Learning,Han Zhao;Shanghang Zhang;Guanhang Wu;Jo\~{a}o  P. Costeira;Jos\'{e} M. F.  Moura;Geoffrey J. Gordon,han.zhao@cs.cmu.edu;shanghaz@andrew.cmu.edu;guanhanw@andrew.cmu.edu;jpc@isr.ist.utl.pt;moura@andrew.cmu.edu;ggordon@cs.cmu.edu,6;6;6;6,3;5;5;4,Invite to Workshop Track,0,9,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;T√©cnico Lisboa;Carnegie Mellon University;Carnegie Mellon University,adversarial learning;domain adaptation,1;1;1;-1;1;1,24;24;24;-1;24;24,-1;-1,usa,usa,n,1;4
1175,ICLR,2018,Deep Generative Dual Memory Network for Continual Learning,Nitin Kamra;Umang Gupta;Yan Liu,nkamra@usc.edu;umanggup@usc.edu;yanliu.cs@usc.edu,5;6;7,4;4;2,Reject,0,7,0.0,yes,10/27/17,University of Southern California;University of Southern California;University of Southern California,Continual Learning;Catastrophic Forgetting;Sequential Multitask Learning;Deep Generative Models;Dual Memory Networks;Deep Learning,27;27;27,66;66;66,-1;-1,usa,usa,n,5
1176,ICLR,2018,Learning to Infer,Joseph Marino;Yisong Yue;Stephan Mandt,jmarino@caltech.edu;yyue@caltech.edu;stephan.mandt@disneyresearch.com,5;6;5,4;5;4,Invite to Workshop Track,0,9,0.0,yes,10/27/17,"California Institute of Technology;California Institute of Technology;Disney Research, Disney",Bayesian Deep Learning;Amortized Inference;Variational Auto-Encoders;Learning to Learn,125;125;-1,3;3;-1,-1;-1,NAN,NAN,n,11;1;5
1177,ICLR,2018,Latent Space Oddity: on the Curvature of Deep Generative Models,Georgios Arvanitidis;Lars Kai Hansen;S√∏ren Hauberg,gear@dtu.dk;lkai@dtu.dk;sohau@dtu.dk,3;7;7,4;4;3,Accept (Poster),0,5,0.0,yes,10/27/17,Technical University of Denmark;Technical University of Denmark;Technical University of Denmark,Generative models;Riemannian Geometry;Latent Space,-1;-1;-1,153;153;153,-1;-1,NAN,NAN,n,5
1178,ICLR,2018,The Context-Aware Learner,Conor Durkan;Amos Storkey;Harrison Edwards,conor.durkan@ed.ac.uk;a.storkey@ed.ac.uk;h.l.edwards@sms.ed.ac.uk,6;4;4,5;3;4,Reject,0,0,0.0,yes,10/27/17,University of Edinburgh;University of Edinburgh;University of Edinburgh,,30;30;30,27;27;27,-1;-1,europe,uk,n,6;1
1179,ICLR,2018,When and where do feed-forward neural networks learn localist representations?,Ella M. Gale;Nicolas Martin;Jeffrey Bowers,eg16993@bristol.ac.uk;nm13850@bristol.ac.uk;j.bowers@bristol.ac.uk,3;3;5,3;5;4,Reject,0,5,0.0,yes,10/27/17,University of Bristol;University of Bristol;University of Bristol,localist;pdp;neural network;representation;psychology;cognition,125;125;125,76;76;76,-1;-1,europe,uk,n,1
1180,ICLR,2018,Generating Differentially Private Datasets Using GANs,Aleksei Triastcyn;Boi Faltings,aleksei.triastcyn@epfl.ch;boi.faltings@epfl.ch,6;5;4,4;4;4,Reject,2,4,0.0,yes,10/27/17,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,generative adversarial networks;differential privacy;synthetic data,-1;-1,-1;-1,-1;-1,NAN,NAN,y,5;4
1181,ICLR,2018,Auxiliary Guided Autoregressive Variational Autoencoders,Thomas Lucas;Jakob Verbeek,thomas.lucas@inria.fr;jakob.verbeek@inria.fr,5;7;5,4;4;4,Reject,0,12,0.0,yes,10/27/17,INRIA;INRIA,,-1;-1,-1;-1,-1;-1,europe,gr,n,5
1182,ICLR,2018,Orthogonal Recurrent Neural Networks with Scaled Cayley Transform,Kyle Helfrich;Devin Willmott;Qiang Ye,kyle.helfrich@uky.edu;devin.willmott@uky.edu;qiang.ye@uky.edu,7;6;5,3;3;4,Reject,0,5,0.0,yes,10/27/17,University of Kentucky;University of Kentucky;University of Kentucky,recurrent neural networks;vanishing gradients;exploding gradients;orthogonal;unitary;long term dependencies;uRNN,162;162;162,346;346;346,-1;-1,usa,usa,y,
1183,ICLR,2018,Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?,Maithra Raghu;Alex Irpan;Jacob Andreas;Robert Kleinberg;Quoc Le;Jon Kleinberg,maithrar@gmail.com;alexirpan@google.com;j.d.andreas@gmail.com;rdk@cs.cornell.edu;qvl@google.com;kleinber@cs.cornell.edu,5;6;6,3;3;3,Invite to Workshop Track,0,13,0.0,yes,10/27/17,Cornell University;Google;Massachusetts Institute of Technology;Cornell University;Google;Cornell University,deep learning;deep reinforcement learning;combinatorial games;optimality,5;-1;8;5;-1;5,19;-1;5;19;-1;19,-1;-1,usa,usa,y,1
1184,ICLR,2018,DNN Representations as Codewords: Manipulating Statistical Properties via Penalty Regularization,Daeyoung Choi;Changho Shin;Hyunghun Cho;Wonjong Rhee,choid@snu.ac.kr;ch.shin@snu.ac.kr;webofthink@snu.ac.kr;wrhee@snu.ac.kr,5;5;5,5;3;4,Reject,0,3,0.0,yes,10/27/17,Seoul National University;Seoul National University;Seoul National University;Seoul National University,DNN representation;penalty regularization;channel coding,39;39;39;39,74;74;74;74,-1;-1,asia,kr,n,
1185,ICLR,2018,A Tensor Analysis on Dense Connectivity via Convolutional Arithmetic Circuits,Emilio Rafael Balda;Arash Behboodi;Rudolf Mathar,emilio.balda@ti.rwth-aachen.de;arash.behboodi@ti.rwth-aachen.de;mathar@ti.rwth-aachen.de,4;4;5,3;3;3,Reject,0,3,0.0,yes,10/27/17,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University,DenseNets;Tensor Analysis;Convolutional Arithmetic Circuits,125;125;125,79;79;79,-1;-1,NAN,NAN,y,1
1186,ICLR,2018,Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach,Pierre Courtiol;Eric W. Tramel;Marc Sanselme;Gilles Wainrib,pierre.courtiol@owkin.com;eric.tramel@owkin.com;marc.sanselme@owkin.com;gilles.wainrib@owkin.com,5;6;5,4;3;3,Reject,0,8,0.0,yes,10/27/17,OWKIN;;;Ecole Normale Superieure,Weakly Supervised Learning;Medical Imaging;Histopathology;Deep Feature Extraction,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,2
1187,ICLR,2018,Realtime query completion via deep language models,Po-Wei Wang;J. Zico Kolter;Vijai Mohan;Inderjit S. Dhillon,poweiw@cs.cmu.edu;zkolter@cs.cmu.edu;vijaim@amazon.com;isd@a9.com,4;6;5,5;3;3,Reject,3,2,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Amazon;A9,query completion;realtime;error correction;recurrent network;beam search,1;1;-1;-1,24;24;-1;-1,-1;-1,europe,gr,n,3
1188,ICLR,2018,LEARNING SEMANTIC WORD RESPRESENTATIONS VIA TENSOR FACTORIZATION,Eric Bailey;Charles Meyer;Shuchin Aeron,popcorncolonel@gmail.com;cmey63@gmail.com;shuchin@ece.tufts.edu,5;5;5,3;5;5,Reject,0,6,0.0,yes,10/27/17,Tufts University;;Tufts University,Word Embeddings;Tensor Factorization;Natural Language Processing,-1;-1;162,-1;-1;169,-1;-1,usa,usa,n,3
1189,ICLR,2018,Finding ReMO (Related Memory Object): A Simple neural architecture for Text based Reasoning,Jihyung Moon;Hyochang Yang;Sungzoon Cho,jhmoon@dm.snu.ac.kr;hyochang@dm.snu.ac.kr;zoon@snu.ac.kr,4;4;4,4;4;4,Reject,0,4,0.0,yes,10/27/17,Seoul National University;Seoul National University;Seoul National University,Natural Language Processing;Deep Learning;Reasoning,39;39;39,74;74;74,-1;-1,asia,kr,n,
1190,ICLR,2018,Representing dynamically: An active process for describing sequential data,Juan Sebastian Olier;Emilia Barakova;Matthias Rauterberg;Carlo Regazzoni,j.s.olier.jauregui@tue.nl;e.i.barakova@tue.nl;g.w.m.rauterberg@tue.nl;carlo.regazzoni@unige.it,6;3;4;4,3;3;4;4,Reject,0,0,0.0,yes,10/27/17,Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology;Universit√† degli Studi di Genova,Generative Models;Latent representations;Predictive coding;Recurrent networks;Sequential data,-1;-1;-1;-1,141;141;141;-1,-1;-1,NAN,NAN,n,11;5
1191,ICLR,2018,Modeling Latent Attention Within Neural Networks,Christopher Grimm;Dilip Arumugam;Siddharth Karamcheti;David Abel;Lawson L.S. Wong;Michael L. Littman,crgrimm@umich.edu;dilip_arumugam@brown.edu;siddharth_karamcheti@brown.edu;david_abel@brown.edu;lsw@brown.edu;mlittman@cs.brown.edu,4;5;7,4;4;4,Reject,0,3,0.0,yes,10/27/17,University of Michigan;Brown University;Brown University;Brown University;Brown University;Brown University,deep learning;neural network;attention;attention mechanism;interpretability;visualization,10;95;95;95;95;95,21;50;50;50;50;50,-1;-1,usa,usa,n,8;2;3
1192,ICLR,2018,Deep Active Learning for Named Entity Recognition,Yanyao Shen;Hyokun Yun;Zachary C. Lipton;Yakov Kronrod;Animashree Anandkumar,shenyanyao@utexas.edu;yunhyoku@amazon.com;zlipton@cmu.edu;kronrod@amazon.com;animakumar@gmail.com,6;6;7,3;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,"University of Texas, Austin;Amazon;Carnegie Mellon University;Amazon;California Institute of Technology",active learning;deep learning;named entity recognition,-1;-1;1;-1;125,-1;-1;24;-1;3,-1;-1,usa,usa,n,3
1193,ICLR,2018,On the limitations of first order approximation in GAN dynamics,Jerry Li;Aleksander Madry;John Peebles;Ludwig Schmidt,jerryzli@mit.edu;madry@mit.edu;jpeebles@mit.edu;ludwigs@mit.edu,4;5;7,4;3;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,GANs;first order dynamics;convergence;mode collapse,8;8;8;8,5;5;5;5,-1;-1,usa,usa,y,1;5;4
1194,ICLR,2018,Learning Covariate-Specific Embeddings with Tensor Decompositions,Kevin Tian;Teng Zhang;James Zou,kjtian@stanford.edu;tengz@stanford.edu;jamesz@stanford.edu,5;5;5,3;5;4,Reject,0,0,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,Word embedding;tensor decomposition,5;5;5,3;3;3,-1;-1,usa,usa,n,3;7
1195,ICLR,2018,"LSD-Net: Look, Step and Detect for Joint Navigation and Multi-View Recognition with Deep Reinforcement Learning",N dinesh reddy,dnarapur@andrew.cmu.edu,4;6;3,4;4;4,Reject,0,0,0.0,yes,10/27/17,Carnegie Mellon University,,1,24,-1,usa,usa,n,
1196,ICLR,2018,Cross-View Training for Semi-Supervised Learning,Kevin Clark;Thang Luong;Quoc V. Le,kevclark@cs.stanford.edu;qvl@google.com;thangluong@google.com,2;5;7,4;4;4,Invite to Workshop Track,0,6,0.0,yes,10/27/17,Stanford University;Google;Google,semi-supervised learning;image recognition;sequence tagging;dependency parsing,5;-1;-1,3;-1;-1,-1;-1,NAN,NAN,n,3;4
1197,ICLR,2018,Learning Weighted Representations for Generalization Across Designs,Fredrik D. Johansson;Nathan Kallus;Uri Shalit;David Sontag,fredrikj@mit.edu;kallus@cornell.edu;urish22@gmail.com;dsontag@csail.mit.edu,5;8;7,3;3;4,Reject,0,4,0.0,yes,10/27/17,"Massachusetts Institute of Technology;Cornell University;Technion, Technion;Massachusetts Institute of Technology",Distributional shift;causal effects;domain adaptation,8;5;21;8,5;19;-1;5,-1;-1,usa,usa,y,1
1198,ICLR,2018,Exploring Asymmetric Encoder-Decoder Structure for Context-based Sentence Representation Learning,Shuai Tang;Hailin Jin;Chen Fang;Zhaowen Wang;Virginia R. de Sa,shuaitang93@ucsd.edu;hljin@adobe.com;cfang@adobe.com;zhawang@adobe.com;desa@ucsd.edu,7;6;3,4;4;5,Reject,4,5,0.0,yes,10/27/17,"University of California, San Diego;Adobe Systems;Adobe Systems;Adobe Systems;University of California, San Diego",asymmetric structure;RNN-CNN;fast;unsupervised;representation;sentence,-1;-1;-1;-1;-1,31;-1;-1;-1;31,-1;-1,usa,usa,n,
1199,ICLR,2018,Data Augmentation Generative Adversarial Networks,Anthreas Antoniou;Amos Storkey;Harrison Edwards,a.antoniou@sms.ed.ac.uk;a.storkey@ed.ac.uk;h.l.edwards@sms.ed.ac.uk,4;9;6,4;5;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,University of Edinburgh;University of Edinburgh;University of Edinburgh,,30;30;30,27;27;27,-1;-1,europe,uk,n,6;5;4
1200,ICLR,2018,Long-term Forecasting using Tensor-Train RNNs,Rose Yu;Stephan Zheng;Anima Anandkumar;Yisong Yue,rose@caltech.edu;stephan@caltech.edu;anima@caltech.edu;yyue@caltech.edu,4;5;6,4;3;4,Reject,0,0,0.0,yes,10/27/17,California Institute of Technology;California Institute of Technology;California Institute of Technology;California Institute of Technology,RNNs;time series forecasting;nonlinear dynamics;tensor-train,125;125;125;125,3;3;3;3,-1;-1,usa,usa,n,
1201,ICLR,2018,Autostacker: an Automatic Evolutionary Hierarchical  Machine Learning System,Boyuan Chen;Warren Mo;Ishanu Chattopadhyay;Hod Lipson,boyuan.chen@columbia.edu;warrenmo@uchicago.edu;ishanu@uchicago.edu;hod.lipson@columbia.edu,4;3;4,5;4;5,Reject,0,0,0.0,yes,10/27/17,Columbia University;University of Chicago;University of Chicago;Columbia University,Machine Learning;AutoML,21;57;57;21,14;9;9;14,-1;-1,usa,usa,n,
1202,ICLR,2018,Inducing Grammars with and for Neural Machine Translation,Ke Tran;Yonatan Bisk,ketranmanh@gmail.com;ybisk@yonatanbisk.com,3;6;5,5;5;4,Reject,0,7,0.0,yes,10/27/17,Amazon;SK Telecom,structured attention;neural machine translation;grammar induction,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
1203,ICLR,2018,Reinforcement and Imitation Learning for Diverse Visuomotor Skills,Yuke Zhu;Ziyu Wang;Josh Merel;Andrei Rusu;Tom Erez;Serkan Cabi;Saran Tunyasuvunakool;J√°nos Kram√°r;Raia Hadsell;Nando de Freitas;Nicolas Heess,yukez@cs.stanford.edu;ziyu@google.com;jsmerel@google.com;andreirusu@google.com;etom@google.com;cabi@google.com;stunya@google.com;janosk@google.com;raia@google.com;nandodefreitas@google.com;heess@google.com,4;4;6,4;4;5,Reject,0,6,0.0,yes,10/27/17,Stanford University;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;imitation learning;robotics;visuomotor skills,5;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,3;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
1204,ICLR,2018,Regret Minimization for Partially Observable Deep Reinforcement Learning,Peter H. Jin;Sergey Levine;Kurt Keutzer,phj@eecs.berkeley.edu;svlevine@eecs.berkeley.edu;keutzer@berkeley.edu,4;7;5,4;4;5,Invite to Workshop Track,0,5,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley,deep reinforcement learning,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,
1205,ICLR,2018,Dense Recurrent Neural Network with Attention Gate,Yong-Ho Yoo;Kook Han;Sanghyun Cho;Kyoung-Chul Koh;Jong-Hwan Kim,yhyoo@rit.kaist.ac.kr;khan@rit.kaist.ac.kr;scho@rit.kaist.ac.kr;kckoh@rit.kaist.ac.kr;johkim@rit.kaist.ac.kr,2;4;4,4;4;4,Reject,0,2,0.0,yes,10/27/17,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,recurrent neural network;language modeling;dense connection,-1;-1;-1;-1;-1,95;95;95;95;95,-1;-1,NAN,NAN,n,8;3
1206,ICLR,2018,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization,Jiong Zhang;Qi Lei;Inderjit S. Dhillon,zhangjiong724@utexas.edu;leiqi@ices.utexas.edu;inderjit@cs.utexas.edu,7;5;5,4;4;3,Reject,0,3,0.0,yes,10/27/17,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Recurrent Neural Network;Vanishing Gradient;Exploding Gradient;Linear Algebra;Householder Reflections,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,y,1
1207,ICLR,2018,Semantic Interpolation in Implicit Models,Yannic Kilcher;Aurelien Lucchi;Thomas Hofmann,yannic.kilcher@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch;thomas.hofmann@inf.ethz.ch,6;5;7,3;4;4,Accept (Poster),0,5,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep Generative Models;GANs,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1208,ICLR,2018,A Painless Attention Mechanism for Convolutional Neural Networks,Pau Rodr√≠guez;Guillem Cucurull;Jordi Gonz√†lez;Josep M. Gonfaus;Xavier Roca,pau.rodriguez@cvc.uab.es;gcucurull@cvc.uab.cat;poal@cvc.uab.cat;xavir@cvc.uab.es,5;5;6,4;4;4,Reject,0,10,1.0,yes,10/27/17,"Computer Vision Center, Universitat Aut√≤noma de Barcelona;Universitat Autonoma de Barcelona;Universitat Autonoma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona",computer vision;deep learning;convolutional neural networks;attention,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;7
1209,ICLR,2018,Bayesian Hypernetworks,David Krueger;Chin-Wei Huang;Riashat Islam;Ryan Turner;Alexandre Lacoste;Aaron Courville,david.scott.krueger@gmail.com;chin-wei.huang@umontreal.ca;riashat.islam@mail.mcgill.ca;turnerry@iro.umontreal.ca;allac@elementai.com;aaron.courville@gmail.com,6;6;6,4;4;4,Reject,1,12,0.0,yes,10/27/17,University of Montreal;University of Montreal;McGill University;University of Montreal;Element AI;University of Montreal,variational inference;bayesian inference;deep networks,-1;125;95;125;-1;125,-1;108;42;108;-1;108,-1;-1,canada,ca,n,11;1;4
1210,ICLR,2018,Distributional Adversarial Networks,Chengtao Li;David Alvarez-Melis;Keyulu Xu;Stefanie Jegelka;Suvrit Sra,ctli@mit.edu;dalvmel@mit.edu;keyulu@mit.edu;stefje@csail.mit.edu;suvrit@mit.edu,6;6;6,3;4;3,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial learning;generative model;domain adaptation;two-sample test,8;8;8;8;8,5;5;5;5;5,-1;-1,usa,usa,n,5;4
1211,ICLR,2018,Structured Deep Factorization Machine: Towards General-Purpose Architectures,Jos√© P. Gonz√°lez-Brenes;Ralph Edezhath,jgonzalez@chegg.com;redezhath@chegg.com,3;4;4,5;5;3,Reject,0,1,0.0,yes,10/27/17,Chegg;Chegg,factorization;general-purpose methods,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
1212,ICLR,2018,Learning to search with MCTSnets,Arthur Guez;Theophane Weber;Ioannis Antonoglou;Karen Simonyan;Oriol Vinyals;Daan Wierstra;Remi Munos;David Silver,aguez@google.com;theophane@google.com;ioannisa@google.com;simonyan@google.com;vinyals@google.com;wierstra@google.com;munos@google.com;davidsilver@google.com,7;4;5,3;4;4,Reject,0,3,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google;Google;Google,Monte-Carlo Tree Search;search;planning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1213,ICLR,2018,Open Loop Hyperparameter Optimization and Determinantal Point Processes,Jesse Dodge;Kevin Jamieson;Noah A. Smith,jessed@cs.cmu.edu;jamieson@cs.washington.edu;nasmith@cs.washington.edu,4;4;4,5;5;5,Reject,0,3,0.0,yes,9/27/18,Carnegie Mellon University;University of Washington;University of Washington,hyperparameter optimization;random search;determinantal point processes;low discrepancy sequences,1;8;8,24;25;25,-1;-1,usa,usa,n,
1214,ICLR,2018,Understanding and Exploiting the Low-Rank Structure of Deep Networks,Craig Bakker;Michael J. Henry;Nathan O. Hodas,craig.bakker@pnnl.gov;michael.j.henry@pnnl.gov;nathan.hodas@pnnl.gov,4;5;2,4;4;4,Reject,0,0,0.0,yes,10/27/17,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,Deep Learning;Derivative Calculations;Optimization Algorithms,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1215,ICLR,2018,Adversarially Regularized Autoencoders,Junbo (Jake) Zhao;Yoon Kim;Kelly Zhang;Alexander M. Rush;Yann LeCun,jakezhao@cs.nyu.edu;yoonkim@seas.harvard.edu;kz918@nyu.edu;srush@seas.harvard.edu;yann@cs.nyu.edu,5;6;3;9,4;3;4;3,Invite to Workshop Track,0,7,0.0,yes,10/27/17,New York University;Harvard University;New York University;Harvard University;New York University,representation learning;natural language generation;discrete structure modeling;adversarial training;unaligned text style-transfer,21;49;21;49;21,27;6;27;6;27,-1;-1,usa,usa,n,5;4
1216,ICLR,2018,Expressive power of recurrent neural networks,Valentin Khrulkov;Alexander Novikov;Ivan Oseledets,khrulkov.v@gmail.com;sasha.v.novikov@gmail.com;i.oseledets@skoltech.ru,6;6;6,4;5;3,Accept (Poster),0,4,0.0,yes,10/27/17,Yandex;Google;Skolkovo Institute of Science and Technology,Recurrent Neural Networks;Tensor Train;tensor decompositions;expressive power,-1;-1;-1,-1;-1;-1,-1;-1,europe,russia,y,1
1217,ICLR,2018,The (Un)reliability of saliency methods,Pieter-Jan Kindermans;Sara Hooker;Julius Adebayo;Kristof T. Sch√ºtt;Maximilian Alber;Sven D√§hne;Dumitru Erhan;Been Kim,pikinder@google.com;shooker@google.com;juliusad@google.com;kristof.schuett@tu-berlin.de;maximilian.aber@tu-berlin.de;sven.daehne@tu-berlin.de;dumitru@google.com;beenkim@google.com,5;4;4,3;4;4,Reject,0,4,0.0,yes,10/27/17,Google;Google;Google;TU Berlin;TU Berlin;TU Berlin;Google;Google,Deep learning interpretability;understanding,-1;-1;-1;125;125;125;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1218,ICLR,2018,Three factors influencing minima in SGD,Stanis≈Çaw Jastrzƒôbski;Zac Kenton;Devansh Arpit;Nicolas Ballas;Asja Fischer;Amos Storkey;Yoshua Bengio,staszek.jastrzebski@gmail.com;zakenton@gmail.com;devansh.arpit@umontreal.ca;ballas.n@gmail.com;asja.fischer@gmail.com;a.storkey@ed.ac.uk;yoshua.umontreal@gmail.com,6;3;5,4;4;4,Reject,0,8,0.0,yes,10/27/17,Jagiellonian University;Google;University of Montreal;Facebook;Institute for Cognitive Neuroscience/ Inst. for Neuroinformatics;University of Edinburgh;University of Montreal,SGD;Deep Learning;Generalization,-1;-1;125;-1;-1;30;125,695;-1;108;-1;-1;27;108,-1;-1,canada,ca,y,1
1219,ICLR,2018,A Deep Learning Approach for Survival Clustering without End-of-life Signals,S Chandra Mouli;Bruno Ribeiro;Jennifer Neville,chandr@purdue.edu;ribeiro@cs.purdue.edu;neville@cs.purdue.edu,6;4;6,1;4;5,Reject,0,3,0.0,yes,10/27/17,Purdue University;Purdue University;Purdue University,Survival Analysis;Kuiper statistics;model-free,27;27;27,60;60;60,-1;-1,usa,usa,y,
1220,ICLR,2018,Predicting Multiple Actions for Stochastic Continuous Control,Sanjeev Kumar;Christian Rupprecht;Federico Tombari;Gregory D. Hager,sanjeev.kumar@in.tum.de;christian.rupprecht@in.tum.de;tombari@in.tum.de;hager@cs.tum.edu,3;7;4,4;3;4,Reject,0,5,0.0,yes,10/27/17,Technical University Munich;Technical University Munich;Technical University Munich;Technical University of Munich,Reinforcement Learning;DDPG;Multiple Action Prediction,-1;-1;-1;-1,-1;-1;-1;41,-1;-1,NAN,NAN,n,
1221,ICLR,2018,Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection,Ludovic Trottier;Philippe Gigu√®re;Brahim Chaib-draa,ludovic.trottier.1@ulaval.ca;philippe.giguere@ift.ulaval.ca;brahim.chaib-draa@ift.ulaval.ca,5;6;6,5;4;4,Reject,0,6,0.0,yes,10/27/17,Laval university;Laval university;Laval university,multi-task learning;soft parameter sharing;facial landmark detection,-1;-1;-1,265;265;265,-1;-1,NAN,NAN,n,1
1222,ICLR,2018,State Space LSTM Models with Particle MCMC Inference,Xun Zheng;Manzil Zaheer;Amr Ahmed;Yuan Wang;Eric P. Xing;Alex Smola,xunzheng90@gmail.com;manzil@cmu.edu;amra@google.com;yuanwang@google.com;epxing@cs.cmu.edu;alex@smola.org,3;5;7,5;5;5,Reject,0,6,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Google;Google;Carnegie Mellon University;Carnegie-Mellon University,recurrent neural networks;state space models;sequential Monte Carlo,-1;1;-1;-1;1;1,-1;24;-1;-1;24;24,-1;-1,usa,usa,n,
1223,ICLR,2018,NOVEL AND EFFECTIVE PARALLEL MIX-GENERATOR GENERATIVE ADVERSARIAL NETWORKS,Xia Xiao;Sanguthevar Rajasekaran,xia.xiao@uconn.edu;sanguthevar.rajasekaran@uconn.edu,3;6;5,5;4;4,Reject,1,1,0.0,yes,10/27/17,University of Connecticut;University of Connecticut,neural networks;generative adversarial networks;parallel,224;224,324;324,-1;-1,usa,usa,n,5;4
1224,ICLR,2018,Topology Adaptive Graph Convolutional  Networks,Jian Du;Shanghang Zhang;Guanhang Wu;Jos√© M. F. Moura;Soummya Kar,jiand@andrew.cmu.edu;shanghaz@andrew.cmu.edu;guanhanw@andrew.cmu.edu;moura@andrew.cmu.edu;soummyak@andrew.cmu.edu,6;4;5,3;4;4,Reject,0,10,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,graph convolutional neural networks;graph-structured data;semi-classification,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,n,10
1225,ICLR,2018,From Information Bottleneck To Activation Norm Penalty,Allen Nie;Mihir Mongia;James Zou,anie@stanford.edu;mihir.mongia@mssm.edu;jamesz@stanford.edu,7;4;4,3;3;4,Reject,0,2,0.0,yes,10/27/17,Stanford University;Icahn School of Medicine at Mount Sinai;Stanford University,Deep Learning;Natural Language Processing,5;-1;5,3;-1;3,-1;-1,usa,usa,n,3;1
1226,ICLR,2018,TESLA: Task-wise Early Stopping and Loss Aggregation for Dynamic Neural Network Inference,Chun-Min Chang;Chia-Ching Lin;Hung-Yi Ou Yang;Chin-Laung Lei;Kuan-Ta Chen,cmchang@iis.sinica.edu.tw;d05921018@ntu.edu.tw;frank840925@gmail.com;cllei@ntu.edu.tw;swc@iis.sinica.edu.tw,4;5;4,4;2;2,Reject,0,3,0.0,yes,10/27/17,Academia Sinica;Nanyang Technological University;;Nanyang Technological University;Academia Sinica,,-1;39;-1;39;-1,-1;52;-1;52;-1,-1;-1,NAN,NAN,n,
1227,ICLR,2018,Stochastic Hyperparameter Optimization through Hypernetworks,Jonathan Lorraine;David Duvenaud,lorraine@cs.toronto.edu;duvenaud@cs.toronto.edu,6;6;6,4;3;1,Reject,0,4,0.0,yes,10/27/17,University of Toronto;University of Toronto,hypernetworks;hyperparameter optimization;metalearning;neural networks;Bayesian optimization;game theory;optimization,21;21,22;22,-1;-1,canada,ca,n,
1228,ICLR,2018,Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies,Robert DiPietro;Christian Rupprecht;Nassir Navab;Gregory D. Hager,rdipietro@gmail.com;christian.rupprecht@in.tum.de;nassir.navab@tum.de;hager@cs.jhu.edu,3;7;6,4;5;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,NVIDIA;Technical University Munich;Technical University Munich;Johns Hopkins University,recurrent neural networks;long-term dependencies;long short-term memory;LSTM,-1;-1;-1;57,-1;-1;-1;13,-1;-1,usa,usa,n,3
1229,ICLR,2018,Deep Temporal Clustering: Fully unsupervised learning of time-domain features,Naveen Sai Madiraju;Seid M. Sadat;Dimitry Fisher;Homa Karimabadi,naveen@avlab.ai;behnam@avlab.ai;dimitry@avlab.ai;homa@avlab.ai,3;5;4,5;4;4,Reject,0,0,0.0,yes,10/27/17,Arizona State University;;;Analytic Ventures,Unsupervised deep learning;Temporal clustering;Event Visualization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,
1230,ICLR,2018,Hierarchical Adversarially Learned Inference,Mohamed Ishmael Belghazi;Sai Rajeswar;Olivier Mastropietro;Negar Rostamzadeh;Jovana Mitrovic;Aaron Courville,ishmael.belghazi@gmail.com;rajsai24@gmail.com;oli.mastro@gmail.com;negar.rostamzadeh@gmail.com;jovana.mitrovic@spc.ox.ac.uk;aaron.courville@gmail.com,5;5;7,5;5;3,Reject,0,13,0.0,yes,10/27/17,University of Montreal;;;Google;University of Oxford;University of Montreal,generative;hierarchical;unsupervised;semisupervised;latent;ALI;GAN,125;-1;-1;-1;39;125,108;-1;-1;-1;1;108,-1;-1,canada,ca,y,5;4
1231,ICLR,2018,Intriguing Properties of Adversarial Examples,Ekin Dogus Cubuk;Barret Zoph;Samuel Stern Schoenholz;Quoc V. Le,cubuk@google.com;barretzoph@google.com;schsam@google.com;qvl@google.com,5;8;3,2;3;4,Invite to Workshop Track,2,5,0.0,yes,10/27/17,Google;Google;Google;Google,adversarial examples;universality;neural architecture search,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
1232,ICLR,2018,TRL: Discriminative Hints for Scalable Reverse Curriculum Learning,Chen Wang;Xiangyu Chen;Zelin Ye;Jialu Wang;Ziruo Cai;Shixiang Gu;Cewu Lu,jere.wang@sjtu.edu.cn;cxy_1997@sjtu.edu.cn;h_e_r_o@sjtu.edu.cn;faldict@sjtu.edu.cn;sjtu_caiziruo@sjtu.edu.cn;sg717@cam.ac.uk;lucewu@sjtu.edu.cn,4;4;5,4;4;4,Reject,0,4,0.0,yes,10/27/17,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of Cambridge;Shanghai Jiao Tong University,deep learning;deep reinforcement learning;robotics;perception,39;39;39;39;39;82;39,188;188;188;188;188;2;188,-1;-1,asia,cn,n,
1233,ICLR,2018,Continuous-fidelity Bayesian Optimization with Knowledge Gradient,Jian Wu;Peter I. Frazier,jw926@cornell.edu;pf98@cornell.edu,5;4;6,4;5;5,Reject,0,4,0.0,yes,10/27/17,Cornell University;Cornell University,Continuous fidelity;Bayesian optimization;fast;knowledge gradient;hyperparameter optimization,5;5,19;19,-1;-1,usa,usa,n,11
1234,ICLR,2018,Neural Program Search: Solving Data Processing Tasks from Description and Examples,Illia Polosukhin;Alexander Skidanov,illia@near.ai;alex@near.ai,4;5;7,4;4;4,Invite to Workshop Track,0,2,0.0,yes,10/27/17,NEAR;NEAR,Deep learning;Structured Prediction;Natural Language Processing;Neural Program Synthesis,-1;-1,-1;-1,-1;-1,europe,no,n,8;3
1235,ICLR,2018,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,Zhao Chen;Vijay Badrinarayanan;Chen-Yu Lee;Andrew Rabinovich,zchen@magicleap.com;vbadrinarayanan@magicleap.com;clee@magicleap.com;arabinovich@magicleap.com,6;4;4,2;4;4,Reject,0,9,0.0,yes,10/27/17,Magic Leap;Magic Leap;Magic Leap;Magic Leap,Multitask learning;computer vision;multitask loss function,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1236,ICLR,2018,Lung Tumor Location and Identification with AlexNet and a Custom CNN,Allison M Rossetto;Wenjin Zhou,allison_rossetto@student.uml.edu;wenjin_zhou@uml.edu,2;3;3,5;4;4,Reject,0,4,0.0,yes,10/27/17,"University of Massachusetts, Lowell;University of Massachusetts, Lowell",,224;224,191;191,-1;-1,usa,usa,n,
1237,ICLR,2018,Image Transformer,Ashish Vaswani;Niki Parmar;Jakob Uszkoreit;Noam Shazeer;Lukasz Kaiser,avaswani@google.com;nikip@google.com;uszkoreit@google.com;noam@google.com;lukaszkaiser@google.com,6;3;5,4;3;4,Reject,0,3,0.0,yes,10/27/17,Google;Google;Google;Google;Google,image generation;super-resolution;self-attention;transformer,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;5
1238,ICLR,2018,Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks,Junkyung Kim;Matthew Ricci;Thomas Serre,junkyung_kim@brown.edu;matthew_ricci_1@brown.edu;thomas_serre@brown.edu,6;6;6,3;3;4,Invite to Workshop Track,0,6,0.0,yes,10/27/17,Brown University;Brown University;Brown University,Visual Relations;Visual Reasoning;SVRT;Attention;Working Memory;Convolutional Neural Network;Deep Learning;Relational Network,95;95;95,50;50;50,-1;-1,usa,usa,n,8
1239,ICLR,2018,No Spurious Local Minima in a Two Hidden Unit ReLU Network,Chenwei Wu;Jiajun Luo;Jason D. Lee,wucw14@mails.tsinghua.edu.cn;jiajunlu@usc.edu;jasonlee@marshall.usc.edu,4;6;6,4;3;2,Invite to Workshop Track,0,3,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;University of Southern California;University of Southern California",Non-convex optimization;Deep Learning,5;27;27,30;66;66,-1;-1,usa,usa,y,
1240,ICLR,2018,Semi-Supervised Learning via New Deep Network Inversion,Balestriero R.;Roger V.;Glotin H.;Baraniuk R.,randallbalestriero@gmail.com;roger.dyni@gmail.com;herve.glotin@univ-tln.fr;richb@rice.edu,5;4;7,4;5;2,Reject,0,5,0.0,yes,10/27/17,Rice University;;CNRS university Toulon;Rice University,inversion scheme;deep neural networks;semi-supervised learning;MNIST;SVHN;CIFAR10,95;-1;-1;95,86;-1;-1;86,-1;-1,australasia,au,n,
1241,ICLR,2018,Stable Distribution Alignment Using the Dual of the Adversarial Distance,Ben Usman;Kate Saenko;Brian Kulis,usmn@bu.edu;saenko@bu.edu;bkulis@bu.edu,5;6;6,4;4;3,Invite to Workshop Track,0,7,0.0,yes,10/27/17,Boston University;Boston University;Boston University,domain adaptation;adversarial networks;statistical distance;duality,82;82;82,70;70;70,-1;-1,europe,it,n,5;4
1242,ICLR,2018,Discovery of Predictive Representations With a Network of General Value Functions,Matthew Schlegel;Andrew Patterson;Adam White;Martha White,mkschleg@ualberta.ca;andnpatt@indiana.edu;amw8@ualberta.ca;whitem@ualberta.ca,4;4;5,1;4;4,Reject,0,6,0.0,yes,10/27/17,University of Alberta;Indiana University;University of Alberta;University of Alberta,Reinforcement Learning;General Value Functions;Predictive Representations,95;67;95;95,119;117;119;119,-1;-1,canada,ca,n,
1243,ICLR,2018,Generation and Consolidation of Recollections for Efficient Deep Lifelong Learning,Matt Riemer;Michele Franceschini;and Tim Klinger,mdriemer@us.ibm.com;franceschini@us.ibm.com;tklinger@us.ibm.com,5;5;5,2;3;3,Reject,0,4,0.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
1244,ICLR,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Judy Hoffman;Eric Tzeng;Taesung Park;Jun-Yan Zhu;Phillip Isola;Kate Saenko;Alyosha Efros;Trevor Darrell,jhoffman@eecs.berkeley.edu;etzeng@eecs.berkeley.edu;taesung_park@berkeley.edu;junyanz@berkeley.edu;isola@eecs.berkeley.edu;saenko@bu.edu;efros@eecs.berkeley.edu;trevor@eecs.berkeley.edu,5;5;9,5;5;5,Reject,2,5,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Boston University;University of California Berkeley;University of California Berkeley,domain adaptation;unsupervised learning;classification;semantic segmentation,-1;-1;-1;-1;-1;82;-1;-1,18;18;18;18;18;70;18;18,-1;-1,usa,usa,n,2;5;4
1245,ICLR,2018,The Manifold Assumption and Defenses Against Adversarial Perturbations,Xi Wu;Uyeong Jang;Lingjiao Chen;Somesh Jha,xiwu@cs.wisc.edu;wjang@cs.wisc.edu;lchen@cs.wisc.edu;jha@cs.wisc.edu,3;4;5,3;3;3,Reject,0,4,0.0,yes,10/27/17,University of Southern California;University of Southern California;University of Southern California;University of Southern California,the manifold assumption;adversarial perturbation;neural networks,27;27;27;27,66;66;66;66,-1;-1,usa,usa,y,1;4
1246,ICLR,2018,Graph2Seq: Scalable Learning Dynamics for Graphs,Shaileshh Bojja Venkatakrishnan;Mohammad Alizadeh;Pramod Viswanath,bjjvnkt@csail.mit.edu;alizadeh@csail.mit.edu;pramodv@illinois.edu,4;4;4,4;4;3,Reject,0,6,0.0,yes,9/27/18,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Illinois, Urbana Champaign",,8;8;-1,5;5;-1,-1;-1,usa,usa,y,1;10
1247,ICLR,2018,Reinforcement Learning from Imperfect Demonstrations,Yang Gao;Huazhe(Harry) Xu;Ji Lin;Fisher Yu;Sergey Levine;Trevor Darrell,yg@eecs.berkeley.edu;huazhe_xu@eecs.berkeley.edu;lin-j14@mails.tsinghua.edu.cn;fy@eecs.berkeley.edu;svlevine@eecs.berkeley.edu;trevor@eecs.berkeley.edu,5;6;5,3;5;4,Invite to Workshop Track,1,4,0.0,yes,10/27/17,"University of California Berkeley;University of California Berkeley;Tsinghua University, Tsinghua University;University of California Berkeley;University of California Berkeley;University of California Berkeley",learning from demonstration;reinforcement learning;maximum entropy learning,-1;-1;5;-1;-1;-1,18;18;30;18;18;18,-1;-1,usa,usa,n,
1248,ICLR,2018,FigureQA: An Annotated Figure Dataset for Visual Reasoning,Samira Ebrahimi Kahou;Adam Atkinson;Vincent Michalski;√Åkos K√°d√°r;Adam Trischler;Yoshua Bengio,samira.ebrahimi@microsoft.com;adatkins@microsoft.com;vincent.michalski@umontreal.ca;kadar.akos@gmail.com;adam.trischler@microsoft.com;yoshua.bengio@umontreal.ca,6;6;6,4;3;4,Invite to Workshop Track,0,10,0.0,yes,10/27/17,Microsoft;Microsoft;University of Montreal;;Microsoft;University of Montreal,dataset;computer vision;deep learning;visual reasoning;relational reasoning,-1;-1;125;-1;-1;125,-1;-1;108;-1;-1;108,-1;-1,canada,ca,n,10
1249,ICLR,2018,Seq2SQL: Generating Structured Queries From Natural Language Using Reinforcement Learning ,Victor Zhong;Caiming Xiong;Richard Socher,victor@victorzhong.com;cxiong@salesforce.com;richard@socher.org,5;4;5,5;4;4,Reject,7,4,0.0,yes,10/27/17,University of Washington;SalesForce.com;SalesForce.com,deep learning;reinforcement learning;dataset;natural language processing;natural language interface;sql,8;-1;-1,25;-1;-1,-1;-1,NAN,NAN,n,3
1250,ICLR,2018,Learning to select examples for program synthesis,Yewen Pu;Zachery Miranda;Armando Solar-Lezama;Leslie Pack Kaelbling,yewenpu@mit.edu;zmiranda@mit.edu;asolar@csail.mit.edu;lpk@csail.mit.edu,4;5;5,4;4;3,Reject,0,3,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,program synthesis;program induction;example selection,8;8;8;8,5;5;5;5,-1;-1,usa,usa,n,
1251,ICLR,2018,Neuron as an Agent,Shohei Ohsawa;Kei Akuzawa;Tatsuya Matsushima;Gustavo Bezerra;Yusuke Iwasawa;Hiroshi Kajino;Seiya Takenaka;Yutaka Matsuo,ohsawa@weblab.t.u-tokyo.ac.jp;akuzawa-kei@weblab.t.u-tokyo.ac.jp;matsushima@weblab.t.u-tokyo.ac.jp;gustavo@weblab.t.u-tokyo.ac.jp;iwasawa@weblab.t.u-tokyo.ac.jp;kjn@jp.ibm.com;s.takenaka@aediworks.com;matsuo@weblab.t.u-tokyo.ac.jp,6;7;3,4;3;5,Invite to Workshop Track,6,5,1.0,yes,10/27/17,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo;International Business Machines;Aediworks;The University of Tokyo,Multi-agent Reinforcement Learning;Communication;Reward Distribution;Trusted Third Party;Auction Theory,57;57;57;57;57;-1;-1;57,45;45;45;45;45;-1;-1;45,-1;-1,NAN,NAN,n,1
1252,ICLR,2018,Toward predictive machine learning for active vision,Emmanuel Dauc√©,emmanuel.dauce@centrale-marseille.fr,5;3;3,2;4;5,Reject,0,5,0.0,yes,10/27/17,Centrale Marseille,active inference;predictive coding;motor control,-1,-1,-1,NAN,NAN,n,2
1253,ICLR,2018,Value Propagation Networks,Nantas Nardelli;Gabriel Synnaeve;Zeming Lin;Pushmeet Kohli;Nicolas Usunier,nantas@robots.ox.ac.uk;gab@fb.com;zlin@fb.com;pushmeet@google.com;usunier@fb.com,5;7;5,4;3;2,Invite to Workshop Track,0,3,0.0,yes,9/27/18,University of Oxford;Facebook;Facebook;Google;Facebook,Learning to plan;Reinforcement Learning;Value Iteration;Navigation;Convnets,39;-1;-1;-1;-1,1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1254,ICLR,2018,Correcting Nuisance Variation using Wasserstein Distance,Gil Tabak;Minjie Fan;Samuel J. Yang;Stephan Hoyer;Geoff Davis,tabak.gil@gmail.com;mjfan@google.com;samuely@google.com;shoyer@google.com;geoffd@google.com,5;4;7,3;5;3,Reject,0,6,0.0,yes,10/27/17,Stanford University;Google;Google;Google;Google,Nuisance variation;transform learning;image embeddings,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
1255,ICLR,2018,Parametric Adversarial Divergences are Good Task Losses for Generative Modeling,Gabriel Huang;Hugo Berard;Ahmed Touati;Gauthier Gidel;Pascal Vincent;Simon Lacoste-Julien,gbxhuang@gmail.com;berard.hugo@gmail.com;ahmed.touati@umontreal.ca;gauthier.gidel@inria.fr;pascal.vincent@umontreal.ca;slacoste@iro.umontreal.ca,6;4;4,3;4;3,Invite to Workshop Track,0,12,1.0,yes,10/27/17,university of montreal;Facebook;University of Montreal;INRIA;University of Montreal;University of Montreal,parametric;adversarial;divergence;generative;modeling;gan;neural;network;task;loss;structured;prediction,-1;-1;125;-1;125;125,-1;-1;108;-1;108;108,-1;-1,canada,ca,n,1;5;4
1256,ICLR,2018,Adaptive Memory Networks,Daniel Li;Asim Kadav,li.daniel@berkeley.edu;asim@nec-labs.com,5;7;4,4;5;3,Invite to Workshop Track,2,7,0.0,yes,10/27/17,University of California Berkeley;NEC-Labs,Memory Networks;Dynamic Networks;Faster Inference;Reasoning;QA,-1;-1,18;-1,-1;-1,NAN,NAN,n,
1257,ICLR,2018,Discrete Autoencoders for Sequence Models,Lukasz Kaiser;Samy Bengio,lukaszkaiser@google.com;bengio@google.com,5;4;6,5;4;1,Reject,0,4,0.0,yes,10/27/17,Google;Google,autoencoders;sequence models;discrete representations,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
1258,ICLR,2018,‚ÄúStyle‚Äù Transfer for Musical Audio Using Multiple Time-Frequency Representations,Shaun Barry;Youngmoo Kim,smb484@drexel.edu;ykim@drexel.edu,6;4;7,4;4;3,Reject,0,2,0.0,yes,10/27/17,Drexel University;Drexel University,Musical audio;neural style transfer;Time-Frequency;Spectrogram,224;224,392;392,-1;-1,europe,il,n,
1259,ICLR,2018,Model-based imitation learning from state trajectories,Subhajit Chaudhury;Daiki Kimura;Tadanobu Inoue;Ryuki Tachibana,subhajit@jp.ibm.com;daiki@jp.ibm.com;inouet@jp.ibm.com;ryuki@jp.ibm.com,7;4;3,3;4;5,Reject,1,3,0.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines;International Business Machines,Model based reinforcement learning;Imitation learning;dynamics model,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1260,ICLR,2018,Neural Task Graph Execution,Sungryull Sohn;Junhyuk Oh;Honglak Lee,srsohn@umich.edu;junhyuk@umich.edu;honglak@eecs.umich.edu,6;6;4,4;3;4,Reject,0,4,0.0,yes,10/27/17,University of Michigan;University of Michigan;University of Michigan,deep reinforcement learning;task execution;instruction execution,10;10;10,21;21;21,-1;-1,usa,usa,n,10
1261,ICLR,2018,Efficient Exploration through Bayesian   Deep Q-Networks,Kamyar Azizzadenesheli;Emma Brunskill;Animashree Anandkumar,kazizzad@uci.edu;ebrun@cs.stanford.edu;animakumar@gmail.com,6;5;5,4;4;4,Reject,2,14,0.0,yes,10/27/17,"University of California, Irvine;Stanford University;California Institute of Technology",Deep RL;Thompson Sampling;Posterior update,-1;5;125,99;3;3,-1;-1,usa,usa,n,11
1262,ICLR,2018,UNSUPERVISED SENTENCE EMBEDDING USING DOCUMENT STRUCTURE-BASED CONTEXT,Taesung Lee;Youngja Park,taesung.lee@ibm.com;young_park@us.ibm.com,7;5;5,4;4;4,Reject,0,7,0.0,yes,10/27/17,International Business Machines;International Business Machines,distributed representation;sentence embedding;structure;technical documents;sentence embedding;out-of-vocabulary,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1263,ICLR,2018,Time-Dependent Representation for Neural Event Sequence Prediction,Yang Li;Nan Du;Samy Bengio,liyang@google.com;dunan@google.com;bengio@google.com,4;4;5,4;5;3,Invite to Workshop Track,0,4,0.0,yes,10/27/17,Google;Google;Google,Neural sequence prediction;Embedding;LSTM;Regularization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
1264,ICLR,2018,Directing Generative Networks with Weighted Maximum Mean Discrepancy,Maurice Diesendruck;Guy W. Cole;Sinead Williamson,momod@utexas.edu;guywcole@utexas.edu;sinead.williamson@mccombs.utexas.edu,4;4;4,4;4;5,Reject,0,3,0.0,yes,10/27/17,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",generative networks;two sample tests;bias correction;maximum mean discrepancy,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,7;5
1265,ICLR,2018,Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks,Vitalii Zhelezniak;Dan Busbridge;April Shen;Samuel L. Smith;Nils Y. Hammerla,vitali.zhelezniak@babylonhealth.com;dan.busbridge@babylonhealth.com;april.shen@babylonhealth.com;slsmith@google.com;nils.hammerla@babylonhealth.com,6;5;4,4;5;4,Invite to Workshop Track,0,6,0.0,yes,10/27/17,babylon health;babylon health;babylon health;Google;babylon health,distributed representations;sentence embedding;representation learning;unsupervised learning;encoder-decoder;RNN,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
1266,ICLR,2018,Learning Parametric Closed-Loop Policies for Markov Potential Games,Sergio Valcarcel Macua;Javier Zazo;Santiago Zazo,sergio@prowler.io;javier.zazo.ruiz@upm.es;santiago@gaps.ssr.upm.es,7;6;6,2;3;1,Accept (Poster),0,4,0.0,yes,10/27/17,Prowler.io;Universidad Polit√©cnica de Madrid;Universidad Polit√©cnica de Madrid,Stochastic games;potential games;closed loop;reinforcement learning;multiagent systems,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
1267,ICLR,2018,Soft Value Iteration Networks for Planetary Rover Path Planning,Max Pflueger;Ali Agha;Gaurav S. Sukhatme,mpflueger@gmail.com;aliahga@jpl.nasa.gov;gaurav@usc.edu,3;3;4,5;3;4,Reject,0,3,0.0,yes,10/27/17,University of Southern California;Jet Propulsion Laboratory;University of Southern California,value iteration networks;robotics;space robotics;imitation learning;convolutional neural networks;path planning,27;-1;27,66;-1;66,-1;-1,usa,usa,n,
1268,ICLR,2018,A Classification-Based Perspective on GAN Distributions,Shibani Santurkar;Ludwig Schmidt;Aleksander Madry,shibani@mit.edu;ludwigs@mit.edu;madry@mit.edu,5;6;3,5;4;4,Reject,0,3,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Generative adversarial networks;classification;benchmark;mode collapse;diversity,8;8;8,5;5;5,-1;-1,usa,usa,n,5;4
1269,ICLR,2018,Inference Suboptimality in Variational Autoencoders,Chris Cremer;Xuechen Li;David Duvenaud,ccremer@cs.toronto.edu;lxuechen@cs.toronto.edu;duvenaud@cs.toronto.edu,6;6;6,5;5;4,Invite to Workshop Track,0,4,0.0,yes,10/27/17,University of Toronto;University of Toronto;University of Toronto,Approximate Inference;Amortization;Posterior Approximations;Variational Autoencoder,21;21;21,22;22;22,-1;-1,canada,ca,n,1;5
1270,ICLR,2018,Achieving Strong Regularization for Deep Neural Networks,Dae Hoon Park;Chiu Man Ho;Yi Chang,pdhvip@gmail.com;chiuman100@gmail.com;yi.chang@huawei.com,6;4;5,2;5;5,Reject,0,5,0.0,yes,10/27/17,Huawei Technologies Ltd.;Innopeak Technology;Huawei Technologies Ltd.,deep learning;regularization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1
1271,ICLR,2018,A Spectral Approach to Generalization and Optimization in Neural Networks,Farzan Farnia;Jesse Zhang;David Tse,farnia@stanford.edu;jessez@stanford.edu;dntse@stanford.edu,6;6;4,3;3;4,Reject,1,11,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,Generalization;Neural Networks;Fourier Analysis,5;5;5,3;3;3,-1;-1,usa,usa,y,1
1272,ICLR,2018,Small Coresets to Represent Large Training Data for Support Vector Machines,Cenk Baykal;Murad Tukan;Dan Feldman;Daniela Rus,baykal@mit.edu;muradtuk@gmail.com;dannyf.post@gmail.com;rus@csail.mit.edu,5;7;5,3;3;4,Reject,0,8,0.0,yes,10/27/17,Massachusetts Institute of Technology;;University of Haifa;Massachusetts Institute of Technology,coresets;data compression,8;-1;162;8,5;-1;608;5,-1;-1,usa,usa,y,
1273,ICLR,2018,Investigating Human Priors for Playing Video Games,Rachit Dubey;Pulkit Agrawal;Deepak Pathak;Thomas L. Griffiths;Alexei A. Efros,rach0012@berkeley.edu;pulkitag@berkeley.edu;pathak@berkeley.edu;tom_griffiths@berkeley.edu;efros@eecs.berkeley.edu,4;5;7,3;4;4,Invite to Workshop Track,0,6,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Prior knowledge;Reinforcement learning;Cognitive Science,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,
1274,ICLR,2018,Learning Deep Models: Critical Points and Local Openness,Maher Nouiehed;Meisam Razaviyayn,nouiehed@usc.edu;razaviya@usc.edu,6;5;6,4;4;4,Invite to Workshop Track,0,3,0.0,yes,10/27/17,University of Southern California;University of Southern California,Training Deep Models;Non-convex Optimization;Local and Global Equivalence;Local Openness,27;27,66;66,-1;-1,usa,usa,y,
1275,ICLR,2018,Contextual Explanation Networks,Maruan Al-Shedivat;Avinava Dubey;Eric P. Xing,alshedivat@cs.cmu.edu;akdubey@cs.cmu.edu;epxing@cs.cmu.edu,6;6;6,5;2;3,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,interpretability;regularization;deep learning;graphical models;model diagnostics;survival analysis,1;1;1,24;24;24,-1;-1,usa,usa,y,1;10
1276,ICLR,2018,LSH Softmax: Sub-Linear Learning and Inference of the Softmax Layer in Deep Architectures,Daniel Levy;Danlu Chan;Stefano Ermon,danilevy@cs.stanford.edu;taineleau@gmail.com;ermon@cs.stanford.edu,5;5;5,4;3;4,Reject,7,3,0.0,yes,10/27/17,Stanford University;;Stanford University,LSH;softmax;deep;learning;sub;linear;efficient;GPU,5;-1;5,3;-1;3,-1;-1,usa,usa,y,3
1277,ICLR,2018,Recurrent Relational Networks for complex relational reasoning,Rasmus Berg Palm;Ulrich Paquet;Ole Winther,rasmusbergpalm@gmail.com;upaq@google.com;olwi@dtu.dk,3;5;5,5;3;3,Reject,0,4,0.0,yes,10/27/17,IT University of Copenhagen;Google;Technical University of Denmark,relational reasoning;graph neural networks,162;-1;-1,109;-1;153,-1;-1,NAN,NAN,n,
1278,ICLR,2018,Influence-Directed Explanations for Deep Convolutional Networks,Anupam Datta;Matt Fredrikson;Klas Leino;Linyi Li;Shayak Sen,danupam@cmu.edu;mfredrik@cs.cmu.edu;kleino@cs.cmu.edu;ly-li14@mails.tsinghua.edu.cn;shayaks@cs.cmu.edu,5;4;4,3;5;3,Reject,0,0,0.0,yes,10/27/17,"Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Tsinghua University, Tsinghua University;Carnegie Mellon University",Deep neural networks;convolutional networks;influence measures;explanations,1;1;1;5;1,24;24;24;30;24,-1;-1,usa,usa,n,
1279,ICLR,2018,Recurrent Neural Networks with Top-k Gains for Session-based Recommendations,Bal√°zs Hidasi;Alexandros Karatzoglou,hidasib@gmail.com;alexk@tid.es,8;4;6,4;5;5,Reject,0,3,0.0,yes,10/27/17,Gravity R&D;Google,gru4rec;session-based recommendations;recommender systems;recurrent neural network,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1280,ICLR,2018, Explicit Induction Bias for Transfer Learning with Convolutional Networks,Xuhong LI;Yves GRANDVALET;Franck DAVOINE,xuhong.li@utc.fr;yves.grandvalet@utc.fr;franck.davoine@utc.fr,6;7;6,5;4;4,Reject,0,4,1.0,yes,10/27/17,"Heudiasyc, University of Technology of Compi√®gne, Universit√© de technologie de Compi√®gne;Heudiasyc, University of Technology of Compi√®gne, Universit√© de technologie de Compi√®gne;Heudiasyc, University of Technology of Compi√®gne, Universit√© de technologie de Compi√®gne",transfer Learning;convolutional networks;fine-tuning;regularization;induction bias,-1;-1;-1,635;635;635,-1;-1,NAN,NAN,n,6
1281,ICLR,2018,Simple Nearest Neighbor Policy Method for Continuous Control Tasks,Elman Mansimov;Kyunghyun Cho,mansimov@cs.nyu.edu;kyunghyun.cho@nyu.edu,4;4;3,5;4;5,Reject,0,6,0.0,yes,10/27/17,New York University;New York University,nearest neighbor;reinforcement learning;policy;continuous control,21;21,27;27,-1;-1,usa,usa,n,
1282,ICLR,2018,Deep Mean Field Theory: Layerwise Variance and Width Variation as Methods to Control Gradient Explosion,Greg Yang;Sam S. Schoenholz,gregyang@microsoft.com;schsam@google.com,7;5;5,3;1;3,Invite to Workshop Track,0,6,0.0,yes,10/27/17,Microsoft;Google,mean field;dynamics;residual network;variance variation;width variation;initialization,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
1283,ICLR,2018,Optimizing the Latent Space of Generative Networks,Piotr Bojanowski;Armand Joulin;David Lopez-Paz;Arthur Szlam,bojanowski@fb.com;ajoulin@fb.com;dlp@fb.com;aszlam@fb.com,4;6;6,4;4;3,Reject,0,3,0.0,yes,10/27/17,Facebook;Facebook;Facebook;Facebook,generative models;latent variable models;image generation;generative adversarial networks;convolutional neural networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
1284,ICLR,2018,Accelerating Neural Architecture Search using Performance Prediction,Bowen Baker*;Otkrist Gupta*;Ramesh Raskar;Nikhil Naik,bowen@mit.edu;otkrist@mit.edu;raskar@mit.edu;naik@mit.edu,6;6;4,4;5;3,Invite to Workshop Track,0,5,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,,8;8;8;8,5;5;5;5,-1;-1,usa,usa,n,11;3
1285,ICLR,2018,Data-efficient Deep Reinforcement Learning for Dexterous Manipulation,Ivo Popov;Nicolas Heess;Timothy P. Lillicrap;Roland Hafner;Gabriel Barth-Maron;Matej Vecerik;Thomas Lampe;Tom Erez;Yuval Tassa;Martin Riedmiller,ivaylo.popov@hotmail.com;heess@google.com;countzero@google.com;rhafner@google.com;gabrielbm@google.com;matejvecerik@google.com;thomaslampe@google.com;etom@google.com;tassa@google.com;riedmiller@google.com,4;2;3,4;5;4,Reject,1,0,0.0,yes,10/27/17,Ocado;Google;Google;Google;Google;Google;Google;Google;Google;Google,Reinforcement learning;robotics;dexterous manipulation;off-policy learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1286,ICLR,2018,Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning,Clemens Rosenbaum;Tim Klinger;Matthew Riemer,crosenbaum@umass.edu;tklinger@us.ibm.com;mdriemer@us.ibm.com,7;6;8,3;3;4,Accept (Poster),0,9,0.0,yes,10/27/17,"University of Massachusetts, Amherst;International Business Machines;International Business Machines",multi-task;transfer;routing;marl;multi-agent;reinforcement;self-organizing,21;-1;-1,191;-1;-1,-1;-1,NAN,NAN,n,
1287,ICLR,2018,Gradients explode - Deep Networks are shallow - ResNet explained,George Philipp;Dawn Song;Jaime G. Carbonell,george.philipp@email.de;dawnsong@gmail.com;jgc@cs.cmu.edu,3;5;8,2;4;1,Invite to Workshop Track,5,6,2.0,yes,10/27/17,Carnegie Mellon University;University of California Berkeley;Carnegie Mellon University,deep learning;MLP;ResNet;residual network;exploding gradient problem;vanishing gradient problem;effective depth;batch normalization;covariate shift,1;-1;1,24;18;24,-1;-1,usa,usa,y,1
1288,ICLR,2018,GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders,Martin Simonovsky;Nikos Komodakis,simonovm@imagine.enpc.fr;nikos.komodakis@enpc.fr,5;7;7,3;2;4,Reject,0,13,0.0,yes,10/27/17,ENPC;ENPC,graph;generative model;autoencoder,-1;-1,-1;-1,-1;-1,europe,ch,n,10;5
1289,ICLR,2018,UPS: optimizing Undirected Positive Sparse graph for neural graph filtering,Mikhail Yurochkin;Dung Thai;Hung Hai Bui;XuanLong Nguyen,moonfolk@umich.edu;dthai@iesl.cs.umass.edu;bui.h.hung@gmail.com;xuanlong@umich.edu,6;3;4,3;3;3,Reject,0,4,0.0,yes,10/27/17,"University of Michigan;University of Massachusetts, Amherst;Google;University of Michigan",,10;21;-1;10,21;191;-1;21,-1;-1,usa,usa,n,10
1290,ICLR,2018,Learning Document Embeddings With CNNs,Shunan Zhao;Chundi Lui;Maksims Volkovs,shunan@layer6.ai;chundi@layer6.ai;maksims.volkovs@gmail.com,6;4;2,4;3;5,Reject,3,6,0.0,yes,10/27/17,Layer 6 AI;Layer 6 AI;Layer 6 AI,unsupervised embedding;convolutional neural network,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
1291,ICLR,2018,Predict Responsibly: Increasing Fairness by Learning to Defer,David Madras;Toniann Pitassi;Richard Zemel,david.madras@mail.utoronto.ca;zemel@cs.toronto.edu;toni@cs.toronto.edu,5;4;6,3;5;3,Invite to Workshop Track,0,5,0.0,yes,10/27/17,Toronto University;University of Toronto;University of Toronto,Fairness;IDK;Calibration;Automated decision-making;Transparency;Accountability,-1;21;21,-1;22;22,-1;-1,canada,ca,n,7
1292,ICLR,2018,Reward Estimation via State Prediction,Daiki Kimura;Subhajit Chaudhury;Ryuki Tachibana;Sakyasingha Dasgupta,daiki@jp.ibm.com;subhajit@jp.ibm.com;ryuki@jp.ibm.com;sakya@leapmind.io,4;5;3,4;3;4,Reject,0,3,0.0,yes,10/27/17,"International Business Machines;International Business Machines;International Business Machines;LeapMind, Inc.",reinforcement learning;inverse reinforcement learning;imitation learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
1293,ICLR,2018,Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks,Nan Rosemary Ke;Anirudh Goyal;Olexa Bilaniuk;Jonathan Binas;Laurent Charlin;Chris Pal;Yoshua Bengio,rosemary.nan.ke@gmail.com;anirudhgoyal9119@gmail.com;obilaniu@gmail.com;jbinas@gmail.com;lcharlin@gmail.com;chris.j.pal@gmail.com;yoshua.umontreal@gmail.com,5;5;8,3;4;4,Reject,0,7,0.0,yes,10/27/17,University of Montreal;;;University of Montreal;HEC Montreal;Polytechnique Montreal;University of Montreal,recurrent neural networks;long-term dependencies;back-propagation through time;truncated back-propagation;biological inspiration;self-attention,-1;-1;-1;125;-1;377;125,-1;-1;-1;108;-1;-1;108,-1;-1,canada,ca,n,8
1294,ICLR,2018,GraphGAN: Generating Graphs via Random Walks,Aleksandar Bojchevski;Oleksandr Shchur;Daniel Z√ºgner;Stephan G√ºnnemann,a.bojchevski@in.tum.de;shchur@in.tum.de;daniel.zuegner@gmail.com;guennemann@in.tum.de,6;7;4,4;4;5,Reject,4,12,0.0,yes,10/27/17,Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich,GAN;graphs;random walks;implicit generative models,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,10;1;5
1295,ICLR,2018,LEAP: Learning Embeddings for Adaptive Pace,Vithursan Thangarasa;Graham W. Taylor,vthangar@uoguelph.ca;gwtaylor@uoguelph.ca,6;3;4,3;4;4,Reject,0,2,0.0,yes,10/27/17,University of Guelph;University of Guelph,deep metric learning;self-paced learning;representation learning;cnn,224;224,-1;-1,-1;-1,canada,ca,n,
1296,ICLR,2018,Prototype Matching Networks for Large-Scale Multi-label  Genomic Sequence Classification,Jack Lanchantin;Arshdeep Sekhon;Ritambhara Singh;Yanjun Qi,jjl5sw@virginia.edu;as5cu@virginia.edu;rs3zz@virginia.edu;yq2h@virginia.edu,5;5;5,4;5;3,Reject,0,15,0.0,yes,10/27/17,University of Virginia;University of Virginia;University of Virginia;University of Virginia,bioinformatics;multi-label classification;matching networks;prototypes;memory networks;attention,57;57;57;57,113;113;113;113,-1;-1,usa,usa,n,6
1297,ICLR,2018,Forced Apart: Discovering Disentangled Representations Without Exhaustive Labels,Alexey Romanov;Anna Rumshisky,jgc128@outlook.com;arum@cs.uml.edu,5;5;4,5;4;4,Reject,0,4,0.0,yes,10/27/17,"University of Massachusetts, Lowell;University of Massachusetts, Lowell",learning representation;clustering;loss,-1;224,-1;191,-1;-1,usa,usa,n,
1298,ICLR,2018,Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering,Elliot Meyerson;Risto Miikkulainen,ekm@cs.utexas.edu;risto@cs.utexas.edu,7;6;7,4;3;4,Accept (Poster),0,5,0.0,yes,10/27/17,"University of Texas, Austin;University of Texas, Austin",multitask learning;deep learning;modularity,-1;-1,-1;-1,-1;-1,usa,usa,n,
1299,ICLR,2018,Attention-based Graph Neural Network for Semi-supervised Learning,Kiran K. Thekumparampil;Sewoong Oh;Chong Wang;Li-Jia Li,kirankoshy@gmail.com;sewoong79@gmail.com;chongw@google.com;lijiali@cs.stanford.edu,6;6;7,3;2;4,Reject,4,5,0.0,yes,10/27/17,"University of Illinois, Urbana Champaign;University of Washington;Google;Stanford University",Graph Neural Network;Attention;Semi-supervised Learning,-1;8;-1;5,-1;25;-1;3,-1;-1,usa,usa,n,8;10
1300,ICLR,2018,Attacking Binarized Neural Networks,Angus Galloway;Graham W. Taylor;Medhat Moussa,gallowaa@uoguelph.ca;gwtaylor@uoguelph.ca;mmoussa@uoguelph.ca,7;7;6,3;4;5,Accept (Poster),1,3,0.0,yes,10/27/17,University of Guelph;University of Guelph;University of Guelph,adversarial examples;adversarial attacks;binary;binarized neural networks,224;224;224,-1;-1;-1,-1;-1,canada,ca,n,4
1301,ICLR,2018,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,Jingyi Xu;Zilu Zhang;Tal Friedman;Yitao Liang;Guy Van den Broeck,jixu@g.ucla.edu;zhangzilu@pku.edu.cn;tal@cs.ucla.edu;yliang@cs.ucla.edu;guyvdb@cs.ucla.edu,7;5;4,3;3;4,Reject,0,3,0.0,yes,10/27/17,"University of California, Los Angeles;Peking University;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",deep learning;symbolic knowledge;semi-supervised learning;constraints,-1;14;-1;-1;-1,15;27;15;15;15,-1;-1,usa,usa,y,
1302,ICLR,2018,Representing Entropy : A short proof of the equivalence between soft Q-learning and policy gradients,Pierre H. Richemond;Brendan Maginnis,phr17@imperial.ac.uk;b.maginnis@imperial.ac.uk,5;2;5,5;5;4,Reject,0,3,0.0,yes,10/27/17,Imperial College London;Imperial College London,soft Q-learning;policy gradients;entropy;Legendre transformation;duality;convex analysis;Donsker-Varadhan,49;49,8;8,-1;-1,europe,uk,n,1
1303,ICLR,2018,Generative Discovery of Relational Medical Entity Pairs,Chenwei Zhang;Yaliang Li;Nan Du;Wei Fan;Philip S. Yu,czhang99@uic.edu;yaliangli@baidu.com;nandu@baidu.com;davidwfan@tencent.com;psyu@uic.edu,4;4;2,3;4;5,Reject,0,3,1.0,yes,10/27/17,"University of Illinois, Chicago;Baidu;Baidu;Tencent AI Lab;University of Illinois, Chicago",Knowledge Discovery;Generative Modeling;Medical;Entity Pair,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,n,5
1304,ICLR,2018,Understanding GANs: the LQG Setting,Soheil Feizi;Changho Suh;Fei Xia;David Tse,sfeizi@stanford.edu;chsuh@kaist.ac.kr;feixia@stanford.edu;dntse@stanford.edu,4;4;5,4;5;4,Reject,8,2,0.0,yes,10/27/17,Stanford University;Korea Advanced Institute of Science and Technology;Stanford University;Stanford University,Generative Adversarial Networks;Wasserstein;Generalization;PCA,5;-1;5;5,3;95;3;3,-1;-1,usa,usa,y,5;4
1305,ICLR,2018,Synthesizing Robust Adversarial Examples,Anish Athalye;Logan Engstrom;Andrew Ilyas;Kevin Kwok,aathalye@mit.edu;engstrom@mit.edu;ailyas@mit.edu;kevink16@gmail.com,5;6;8,4;4;3,Reject,9,8,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;LabSix,adversarial examples,8;8;8;-1,5;5;5;-1,-1;-1,asia,in,n,4
1306,ICLR,2018,Extending the Framework of Equilibrium Propagation to General Dynamics,Benjamin Scellier;Anirudh Goyal;Jonathan Binas;Thomas Mesnard;Yoshua Bengio,benjamin.scellier@polytechnique.edu;anirudhgoyal9119@gmail.com;jbinas@gmail.com;thomas.mesnard@gmail.com;yoshua.umontreal@gmail.com,4;3;6,4;4;2,Invite to Workshop Track,0,3,0.0,yes,10/27/17,Ecole polytechnique;;University of Montreal;University of Montreal;University of Montreal,Deep Learning;Backpropagation;Fixed Point Recurrent Neural Network;Biologically Plausible Learning;Feedback Alignment;Dynamical System;Gradient-Free Optimization,-1;-1;125;125;125,115;-1;108;108;108,-1;-1,canada,ca,y,1
1307,ICLR,2018,Lifelong Word Embedding via Meta-Learning,Hu Xu;Bing Liu;Lei Shu;Philip S. Yu,hxu48@uic.edu;liub@uic.edu;lshu3@uic.edu;psyu@uic.edu,4;5;3,4;4;4,Reject,0,0,0.0,yes,10/27/17,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",Lifelong learning;meta learning;word embedding,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,n,6;3
1308,ICLR,2018,A comparison of second-order methods for deep convolutional neural networks,Patrick H. Chen;Cho-jui Hsieh,phpchen@ucdavis.edu;chohsieh@ucdavis.edu,5;6;3,5;3;4,Reject,0,3,0.0,yes,10/27/17,"University of California, Davis;University of California, Davis",,-1;-1,54;54,-1;-1,usa,usa,n,
1309,ICLR,2018,Automatic Parameter Tying in Neural Networks,Yibo Yang;Nicholas Ruozzi;Vibhav Gogate,yibo.yang@utdallas.edu;nicholas.ruozzi@utdallas.edu;vgogate@hlt.utdallas.edu,6;6;6,5;4;4,Reject,0,4,0.0,yes,10/27/17,"University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas",neural network;quantization;compression,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
1310,ICLR,2018,Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks,Joseph Futoma;Anthony Lin;Mark Sendak;Armando Bedoya;Meredith Clement;Cara O'Brien;Katherine Heller,jfutoma14@gmail.com;anthony.lin@duke.edu;mark.sendak@duke.edu;armando.bedoya@duke.edu;meredith.edwards@duke.edu;cara.obrien@duke.edu;kheller@gmail.com,6;3;4,3;4;4,Reject,0,8,0.0,yes,10/27/17,Duke University;Duke University;Duke University;Duke University;Duke University;Duke University;Duke University,Healthcare;Gaussian Process;Deep Reinforcement Learning,-1;39;39;39;39;39;39,-1;17;17;17;17;17;17,-1;-1,europe,se,n,
1311,ICLR,2018,Latent forward model for Real-time Strategy game planning with incomplete information,Yuandong Tian;Qucheng Gong,yuandong@fb.com;qucheng@fb.com,5;4;4,4;5;3,Reject,0,1,0.0,yes,10/27/17,Facebook;Facebook,Real time strategy;latent space;forward model;monte carlo tree search;reinforcement learning;planning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1312,ICLR,2018,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,Hao Zhang;Bo Chen;Dandan Guo;Mingyuan Zhou,zhanghao_xidian@163.com;bchen@mail.xidian.edu.cn;gdd_xidian@126.com;mzhou@utexas.edu,6;6;5,4;2;4,Accept (Poster),0,3,1.0,yes,10/27/17,"163;Xidian University;126;University of Texas, Austin",,-1;-1;-1;-1,-1;917;-1;-1,-1;-1,usa,usa,n,1;5
1313,ICLR,2018,Faster Distributed Synchronous SGD with Weak Synchronization,Cong Xie;Oluwasanmi O. Koyejo;Indranil Gupta,cx2@illinois.edu;sanmi@illinois.edu;indy@illinois.edu,4;3;4,5;4;5,Reject,0,0,0.0,yes,10/27/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",distributed;deep learning;straggler,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
1314,ICLR,2018,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,Emmanuel de Bezenac;Arthur Pajot;Patrick Gallinari,emmanuel.de_bezenac@lip6.fr;arthur.pajot@lip6.fr;patrick.gallinari@lip6.fr,7;7;6,3;3;2,Accept (Poster),6,4,2.0,yes,10/27/17,LIP6;LIP6;LIP6,deep learning;physical processes;forecasting;spatio-temporal,377;377;377,-1;-1;-1,-1;-1,asia,ir,n,
1315,ICLR,2018,DeepArchitect: Automatically Designing and Training Deep Architectures,Renato Negrinho;Geoff Gordon,negrinho@cs.cmu.edu;ggordon@cs.cmu.edu,4;5;4,5;3;5,Reject,0,6,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University,architecture search;deep learning;hyperparameter tuning,1;1,24;24,-1;-1,usa,usa,n,10
1316,ICLR,2018,Improving generalization by regularizing in $L^2$ function space,Ari S Benjamin;Konrad Kording,aarrii@seas.upenn.edu,6;5;4,3;4;3,Reject,0,1,0.0,yes,10/27/17,University of Pennsylvania,natural gradient;generalization;optimization;function space;Hilbert,15,10,-1;-1,usa,usa,n,1
1317,ICLR,2018,"Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping",Keyi Yu;Yang Liu;Alexander G. Schwing;Jian Peng,yu-ky14@mails.tsinghua.edu.cn;liu301@illinois.edu;aschwing@illinois.edu;jianpeng@illinois.edu,5;5;7,4;3;4,Invite to Workshop Track,3,6,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Topic Classification;Sentiment Analysis;Natural Language Processing,5;-1;-1;-1,30;-1;-1;-1,-1;-1,usa,usa,n,3
1318,ICLR,2018,Gaussian Process Neurons,Sebastian Urban;Patrick van der Smagt,surban@tum.de;smagt@brml.org,5;4;7,4;5;2,Reject,0,1,0.0,yes,10/27/17,"Technical University Munich;Machine Learning Research Lab, Volkswagen Group",gaussian process neuron activation function stochastic transfer function learning variational bayes probabilistic,-1;-1,-1;-1,-1;-1,NAN,NAN,n,11
1319,ICLR,2018,Neural Tree Transducers for Tree to Tree Learning,Jo√£o Sedoc;Dean Foster;Lyle Ungar,joao@cis.upenn.edu;dean@foster.net;ungar@cis.upenn.edu,3;7;2,4;4;5,Reject,0,0,0.0,yes,10/27/17,University of Pennsylvania;;University of Pennsylvania,deep learning;tree transduction,15;-1;15,10;-1;10,-1;-1,usa,usa,pdf miss,
1320,ICLR,2018,Network of Graph Convolutional Networks Trained on Random Walks,Sami Abu-El-Haija;Amol Kapoor;Bryan Perozzi;Joonseok Lee,haija@google.com;ajk2227@columbia.edu;bperozzi@acm.org;joonseok@google.com,5;5;6,2;4;5,Reject,2,7,0.0,yes,10/27/17,Google;Columbia University;Google;Google,Graph Convolution;Deep Learning;Network of Networks,-1;21;-1;-1,-1;14;-1;-1,-1;-1,NAN,NAN,n,1;10;4
1321,ICLR,2018,LSH-SAMPLING BREAKS THE COMPUTATIONAL CHICKEN-AND-EGG LOOP IN ADAPTIVE STOCHASTIC GRADIENT ESTIMATION,Beidi Chen;Yingchen Xu;Anshumali Shrivastava,beidi.chen@rice.edu;yingchen.xu@rice.edu;anshumali@rice.edu,8;4;4,4;5;5,Invite to Workshop Track,0,10,0.0,yes,10/27/17,Rice University;Rice University;Rice University,Stochastic Gradient Descent;Optimization;Sampling;Estimation,95;95;95,86;86;86,-1;-1,australasia,au,n,
1322,ICLR,2018,Deep Boosting of Diverse Experts,Wei Zhang;Qiuyu Chen;Jun Yu;Jianping Fan,weizh@fudan.edu.cn;qchen12@uncc.edu;yujun@hdu.edu.cn;jfan@uncc.edu,2;6;5,5;3;4,Reject,0,2,0.0,yes,10/27/17,"Fudan University;University of North Carolina, Charlotte;Shandong University;University of North Carolina, Charlotte",boosting learning;deep learning;neural network,67;67;125;67,116;-1;569;-1,-1;-1,NAN,NAN,n,
1323,ICLR,2018,Bounding and Counting Linear Regions of Deep Neural Networks,Thiago Serra;Christian Tjandraatmadja;Srikumar Ramalingam,tserra@gmail.com;ctjandra@andrew.cmu.edu;srikumar.ramalingam@gmail.com,6;4;6,5;5;3,Reject,0,6,0.0,yes,10/27/17,Bucknell University;Carnegie Mellon University;Google,rectifier networks;maxout networks;piecewise linear functions;linear regions;mixed-integer programming,-1;1;-1,-1;24;-1,-1;-1,NAN,NAN,y,
1324,ICLR,2018,Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning,Charles Schaff;David Yunis;Ayan Chakrabarti;Matthew R. Walter,cbschaff@ttic.edu;dyunis@uchicago.edu;ayan@wustl.edu;mwalter@ttic.edu,9;4;5,5;4;3,Invite to Workshop Track,0,3,0.0,yes,10/27/17,"Toyota Technological Institute at Chicago;University of Chicago;Washington University, St. Louis;Toyota Technological Institute at Chicago",robot locomotion;reinforcement learning;policy gradients;physical design;deep learning,-1;57;-1;-1,-1;9;-1;-1,-1;-1,NAN,NAN,n,
1325,ICLR,2018,Tandem Blocks in Deep Convolutional Neural Networks,Chris Hettinger;Tanner Christensen;Jeff Humpherys;Tyler J Jarvis,chrishettinger@gmail.com;tkchristensen@byu.edu;jeffh@math.byu.edu;jarvis@math.byu.edu,5;7;4,4;4;4,Reject,0,12,0.0,yes,10/27/17,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,resnet;residual;shortcut;convolutional;linear;skip;highway,125;125;125;125,182;182;182;182,-1;-1,asia,hk,n,
1326,ICLR,2018,On the difference between building and extracting patterns: a causal analysis of deep generative models.,Michel Besserve;Dominik Janzing;Bernhard Schoelkopf,michel.besserve@tuebingen.mpg.de;dominik.janzing@tuebingen.mpg.de;bs@tuebingen.mpg.de,2;7;7,4;3;2,Reject,0,0,0.0,yes,10/27/17,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,GAN;VAE;causality,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
1327,ICLR,2018,Generalization of Learning using Reservoir Computing,Sanjukta Krishnagopal;Yiannis Aloimonos;Michelle Girvan,sanjukta@umd.edu;yiannis@cs.umd.edu;girvan@umd.edu,4;4;4,3;5;4,Reject,0,4,0.0,yes,10/27/17,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",Generalization;Reservoir Computing;dynamical system;Siamese Neural Network;image classification;similarity;dimensionality reduction,12;12;12,69;69;69,-1;-1,usa,usa,n,1
1328,ICLR,2018,Adversarial Examples for Natural Language Classification Problems,Volodymyr Kuleshov;Shantanu Thakoor;Tingfung Lau;Stefano Ermon,vol.kuleshov@gmail.com;shanu.thakoor@gmail.com;ldf921@126.com;ermon@cs.stanford.edu,4;6;4,5;3;4,Reject,1,13,0.0,yes,10/27/17,Stanford University;Google;126;Stanford University,,-1;-1;-1;5,-1;-1;-1;3,-1;-1,usa,usa,n,3;4
1329,ICLR,2018,"Model Specialization for Inference Via End-to-End Distillation, Pruning, and Cascades",Daniel Kang;Karey Shi;Thao Ngyuen;Stephanie Mallard;Peter Bailis;Matei Zaharia,ddkang@stanford.edu;kareyshi@stanford.edu;thao2605@stanford.edu;pbailis@cs.stanford.edu;matei@cs.stanford.edu,6;4;3,3;4;4,Reject,0,0,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,,5;5;5;5;5,3;3;3;3;3,-1;-1,usa,usa,n,
1330,ICLR,2018,Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning,Yichi Zhang;Zhijian Ou,zhangyic17@mails.tsinghua.edu.cn;ozj@tsinghua.edu.cn,4;6;6,4;3;5,Reject,1,5,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",ensemble learning;SG-MCMC;group sparse prior;network pruning,5;5,30;30,-1;-1,NAN,NAN,n,3
1331,ICLR,2018,A dynamic game approach to training robust deep policies,Olalekan Ogunmolu,opo140030@utdallas.edu,5;3;5,4;3;2,Reject,0,1,0.0,yes,10/27/17,"University of Texas, Dallas",game-theory;reinforcement-learning;guided-policy-search;dynamic-programming,-1,-1,-1,usa,usa,n,1;4
1332,ICLR,2018,MACHINE VS MACHINE: MINIMAX-OPTIMAL DEFENSE AGAINST ADVERSARIAL EXAMPLES,Jihun Hamm,hammj@cse.ohio-state.edu,5;6;5,3;3;4,Reject,1,7,0.0,yes,10/27/17,Ohio State University,,57,70,-1,usa,usa,n,4
1333,ICLR,2018,EXPLORING NEURAL ARCHITECTURE SEARCH FOR LANGUAGE TASKS,Minh-Thang Luong;David Dohan;Adams Wei Yu;Quoc V. Le;Barret Zoph;Vijay Vasudevan,luong.m.thang@gmail.com;ddohan@google.com;adamsyuwei@gmail.com;qvl@google.com;barretzoph@google.com;vrv@google.com,3;4;3,4;4;4,Reject,1,1,0.0,yes,10/27/17,Google;Google;Google;Google;Google;Google,Neural architecture search;language tasks;neural machine translation;reading comprehension;SQuAD,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
1334,ICLR,2018,Multimodal Sentiment Analysis To Explore the Structure of Emotions,Anthony Hu;Seth Flaxman,anthony.hu@stats.ox.ac.uk;s.flaxman@imperial.ac.uk,6;4;5,5;5;5,Reject,0,4,0.0,yes,10/27/17,University of Oxford;Imperial College London,,39;49,1;8,-1;-1,europe,uk,n,3
1335,ICLR,2018,Building Generalizable Agents with a Realistic and Rich 3D Environment,Yi Wu;Yuxin Wu;Georgia Gkioxari;Yuandong Tian,jxwuyi@gmail.com;ppwwyyxxc@gmail.com;georgia.gkioxari@gmail.com;yuandong.tian@gmail.com,4;5;8,5;4;4,Invite to Workshop Track,4,6,0.0,yes,10/27/17,"Tsinghua University, Tsinghua University;Facebook;Facebook;Facebook",reinforcement learning;generalization;navigation;3D scenes,5;-1;-1;-1,30;-1;-1;-1,-1;-1,NAN,NAN,n,1
1336,ICLR,2018,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,Dejiao Zhang;Haozhu Wang;Mario Figueiredo;Laura Balzano,dejiao@umich.edu;hzwang@umich.edu;mario.figueiredo@lx.it.pt;girasole@umich.edu,6;8;7,3;5;4,Accept (Poster),0,8,0.0,yes,10/27/17,"University of Michigan;University of Michigan;Instituto de Telecomunica√ß√µes, Portugal;University of Michigan",Compressing neural network;simultaneously parameter tying and sparsification;group ordered l1 regularization,10;10;-1;10,21;21;-1;21,-1;-1,usa,usa,n,1
1337,ICLR,2018,Self-Supervised Learning of Object Motion Through Adversarial Video Prediction,Alex X. Lee;Frederik Ebert;Richard Zhang;Chelsea Finn;Pieter Abbeel;Sergey Levine,rich.zhang@eecs.berkeley.edu;febert@berkeley.edu;cbfinn@eecs.berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,7;3;3;3,5;4;5;5,Reject,2,0,0.0,yes,10/27/17,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,adversarial;video prediction;flow,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,
1338,ICLR,2018,ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions,Soham Parikh;Ananya Sai;Preksha Nema;Mitesh M Khapra,sohamp@cse.iitm.ac.in;ananyasb@cse.iitm.ac.in;preksha@cse.iitm.ac.in;miteshk@cse.iitm.ac.in,5;5;4,3;3;4,Reject,0,0,0.0,yes,10/27/17,Indian Institute of Technology Madras;Indian Institute of Technology Madras;Indian Institute of Technology Madras;Indian Institute of Technology Madras,Reading Comprehension;Answering Multiple Choice Questions,-1;-1;-1;-1,625;625;625;625,-1;-1,NAN,NAN,n,
1339,ICLR,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Gabriel Synnaeve;Zeming Lin;Jonas Gehring;Vasil Khalidov;Nicolas Carion;Nicolas Usunier,gab@fb.com;zlin@fb.com;jgehring@fb.com;vkhalidov@fb.com;alcinos@fb.com;usunier@fb.com,5;4;5,4;1;3,Reject,0,2,0.0,yes,10/27/17,Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,forward modeling;partially observable;deep learning;strategy game;real-time strategy,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1340,ICLR,2018,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,Stephanie Hyland;Crist√≥bal Esteban;Gunnar R√§tsch,stephanie.hyland@inf.ethz.ch;cr_est@ethz.ch;raetsch@inf.ethz.ch,4;6;5,4;4;4,Reject,0,3,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,GAN;medical;records;time;series;generation;privacy,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
1341,ICLR,2018,Regularization Neural Networks via Constrained Virtual  Movement Field,Zhendong Zhang;Cheolkon Jung,zhd.zhang.ai@gmail.com;zhengzk@xidian.edu.cn,5;5;6,4;4;4,Invite to Workshop Track,0,5,0.0,yes,10/27/17,Xidian University;Xidian University,,-1;-1,-1;917,m;m,asia,cn,n,4
1342,ICLR,2018,Learning to Write by Learning the Objective,Ari Holtzman;Jan Buys;Maxwell Forbes;Antoine Bosselut;Yejin Choi,ahai@cs.washington.edu;jbuys@cs.washington.edu;mbforbes@cs.washington.edu;antoineb@cs.washington.edu;yejin@cs.washington.edu,6;5;4,5;4;5,Invite to Workshop Track,0,4,0.0,yes,10/27/17,University of Washington;University of Washington;University of Washington;University of Washington;University of Washington,natural language generation,8;8;8;8;8,25;25;25;25;25,-1;-1,usa,usa,n,3;5
1343,ICLR,2018,Key Protected Classification for GAN Attack Resilient Collaborative Learning,Mert B√ºlent Sarƒ±yƒ±ldƒ±z;Ramazan G√∂kberk Cinbi≈ü;Erman Ayday,mbsariyildiz@gmail.com;gokberkcinbis@gmail.com;erman@cs.bilkent.edu.tr,4;5;3,4;2;4,Reject,0,12,0.0,yes,10/27/17,Naver Labs Europe;METU;Bilkent University,privacy preserving deep learning;collaborative learning;adversarial attack,-1;224;377,-1;-1;426,-1;-1,europe,tr,n,5;4
1344,ICLR,2018,Bit-Regularized Optimization of Neural Nets,Mohamed Amer;Aswin Raghavan;Graham W. Taylor;Sek Chai,mohamed.amer@sri.com;aswin.raghavan@sri.com;gwtaylor@uoguelph.ca;sek.chai@sri.com,4;3;4,5;4;4,Reject,2,6,0.0,yes,10/27/17,SRI International;SRI International;University of Guelph;SRI International,,-1;-1;224;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1345,ICLR,2018,ShakeDrop regularization,Yoshihiro Yamada;Masakazu Iwamura;Koichi Kise,yamada@m.cs.osakafu-u.ac.jp;masa@cs.osakafu-u.ac.jp;kise@cs.osakafu-u.ac.jp,5;4;4,2;4;3,Reject,3,10,0.0,yes,10/27/17,Meiji University;Meiji University;Meiji University,,-1;-1;-1,978;978;978,-1;-1,asia,jp,n,
1346,ICLR,2018,AUTOMATA GUIDED HIERARCHICAL REINFORCEMENT LEARNING FOR ZERO-SHOT SKILL COMPOSITION,Xiao Li;Yao Ma;Calin Belta,xli87@bu.edu;yaoma@bu.edu;cbelta@bu.edu,5;3;4,4;4;3,Reject,0,3,0.0,yes,10/27/17,Boston University;Boston University;Boston University,Hierarchical reinforcement learning;temporal logic;skill composition,82;82;82,70;70;70,-1;-1,europe,it,n,
1347,ICLR,2018,Quadrature-based features for kernel approximation,Marina Munkhoeva;Yermek Kapushev;Evgeny Burnaev;Ivan Oseledets,marina.munkhoeva@skolkovotech.ru;kapushev@gmail.com;e.burnaev@skoltech.ru;i.oseledets@skoltech.ru,4;7;6,3;5;4,Reject,0,3,0.0,yes,10/27/17,Skolkovo Institute of Science and Technology;;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology,kernel methods;low-rank approximation;quadrature rules;random features,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,europe,russia,n,
1348,ICLR,2018,Parametrizing filters of a CNN with a GAN,Yannic Kilcher;Gary Becigneul;Thomas Hofmann,yannic.kilcher@inf.ethz.ch;gary.becigneul@inf.ethz.ch;thomas.hofmann@inf.ethz.ch,2;4;4,4;4;5,Reject,0,1,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,invariance;cnn;gan;infogan;transformation,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
1349,ICLR,2018,Jiffy: A Convolutional Approach to Learning Time Series Similarity,Divya Shanmugam;Davis Blalock;John Guttag,divyas@mit.edu;dblalock@mit.edu;jguttag@mit.edu,6;4;8,4;4;3,Reject,0,10,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Time Series;Time Series Classification,8;8;8,5;5;5,-1;-1,usa,usa,n,
1350,ICLR,2018,Transfer Learning on Manifolds via Learned Transport Operators,Marissa Connor;Christopher Rozell,marissa.connor@gatech.edu;crozell@gatech.edu,5;4;4,4;4;4,Reject,0,0,0.0,yes,10/27/17,Georgia Institute of Technology;Georgia Institute of Technology,manifold learning;transfer learning,13;13,33;33,-1;-1,usa,usa,n,6;5
1351,ICLR,2018,Visualizing the Loss Landscape of Neural Nets,Hao Li;Zheng Xu;Gavin Taylor;Tom Goldstein,haoli@cs.umd.edu;xuzh@cs.umd.edu;taylor@usna.edu;tomg@cs.umd.edu,5;4;5,4;3;3,Invite to Workshop Track,0,5,0.0,yes,10/27/17,"University of Maryland, College Park;University of Maryland, College Park;University of Arizona;University of Maryland, College Park",visualization;loss surface;flatness;sharpness,12;12;224;12,69;69;161;69,-1;-1,usa,usa,n,1
1352,ICLR,2018,Demystifying overcomplete nonlinear auto-encoders: fast SGD convergence towards sparse representation from random initialization,Cheng Tang;Claire Monteleoni,tangch@gwu.edu;cmontel@gwu.edu,2;3;2,4;3;4,Reject,0,4,0.0,yes,10/27/17,George Washington University;George Washington University,stochastic gradient descent;autoencoders;nonconvex optimization;representation learning;theory,224;224,226;226,-1;-1,usa,usa,y,9
1353,ICLR,2018,On Characterizing the Capacity of Neural Networks Using Algebraic Topology,William H. Guss;Ruslan Salakhutdinov,wguss@cs.cmu.edu;rsalakhu@cs.cmu.edu,3;4;4,5;5;5,Reject,0,4,0.0,yes,10/27/17,Carnegie Mellon University;Carnegie Mellon University,deep learning theory;architecture selection;algebraic topology,1;1,24;24,-1;-1,usa,usa,y,1
1354,ICLR,2018,Gated ConvNets for Letter-Based ASR,Vitaliy Liptchinsky;Gabriel Synnaeve;Ronan Collobert,vitaliy888@fb.com;gab@fb.com;locronan@fb.com,3;6;4,5;5;4,Reject,1,4,0.0,yes,10/27/17,Facebook;Facebook;Facebook,automatic speech recognition;letter-based acoustic model;gated convnets,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3
1355,ICLR,2018,Variance Regularizing Adversarial Learning,Karan Grewal;R Devon Hjelm;Yoshua Bengio,karanraj.grewal@mail.utoronto.ca;erroneus@gmail.com;yoshua.umontreal@gmail.com,5;4;6,4;4;3,Reject,0,0,0.0,yes,10/27/17,Toronto University;Microsoft;University of Montreal,Generative Adversarial Network;Integral Probability Metric;Meta-Adversarial Learning,-1;-1;125,-1;-1;108,-1;-1,canada,ca,n,5;4
1356,ICLR,2018,The Information-Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Modeling,Shengjia Zhao;Jiaming Song;Stefano Ermon,sjzhao@stanford.edu;tsong@cs.stanford.edu;ermon@cs.stanford.edu,4;5;6,4;4;4,Reject,0,5,0.0,yes,10/27/17,Stanford University;Stanford University;Stanford University,Generative Models;Variational Autoencoder;Generative Adversarial Network,5;5;5,3;3;3,-1;-1,usa,usa,y,1;5;4
1357,ICLR,2018,Learning Priors for Adversarial Autoencoders,Hui-Po Wang;Wei-Jan Ko;Wen-Hsiao Peng,a88575847@gmail.com;ts771164@gmail.com;wpeng@cs.nctu.edu.tw,6;5;6,3;3;4,Reject,1,5,0.0,yes,10/27/17,National Chiao Tung University;;National Chiao Tung University,deep learning;computer vision;generative adversarial networks,162;-1;162,452;-1;452,-1;-1,asia,tw,n,5;4
1358,ICLR,2018,Faster Reinforcement Learning with Expert State Sequences,Xiaoxiao Guo;Shiyu Chang;Mo Yu;Miao Liu;Gerald Tesauro,xiaoxiao.guo@ibm.com;shiyu.chang@ibm.com;yum@us.ibm.com,6;5;6,3;5;4,Reject,2,4,0.0,yes,10/27/17,International Business Machines;International Business Machines;International Business Machines,Reinforcement Learning;Imitation Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1359,ICLR,2018,Training Neural Machines with Partial Traces,Matthew Mirman;Dimitar Dimitrov;Pavle Djordjevich;Timon Gehr;Martin Vechev,matthew.mirman@inf.ethz.ch;dpavle@student.ethz.ch;dimitar.dimitrov@inf.ethz.ch;timon.gehr@inf.ethz.ch;martin.vechev@inf.ethz.ch,4;5;4,5;4;3,Reject,0,5,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Neural Abstract Machines;Neural Turing Machines;Neural Random Access Machines;Program Synthesis;Program Induction,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1360,ICLR,2018,STRUCTURED ALIGNMENT NETWORKS,Yang Liu;Matt Gardner,yang.liu2@ed.ac.uk;mattg@allenai.org,6;5;5,4;4;4,Reject,0,1,0.0,yes,10/27/17,University of Edinburgh;Allen Institute for Artificial Intelligence,structured attention;sentence matching,30;-1,27;-1,-1;-1,NAN,NAN,n,8;3
1361,ICLR,2018,Revisiting The Master-Slave Architecture In Multi-Agent Deep Reinforcement Learning,Xiangyu Kong;Fangchen Liu;Bo Xin;Yizhou Wang,kxyzc1992@gmail.com;liufangchen@pku.edu.cn;boxin@microsoft.com;yizhou.wang@pku.edu.cn,5;5;4,5;4;3,Reject,0,6,0.0,yes,10/27/17,Peking University;Peking University;Microsoft;Peking University,Deep Reinforcement Learning;Multi-Agent Reinforcement Learning;StarCraft Micromanagement Tasks,-1;14;-1;14,-1;27;-1;27,-1;-1,asia,cn,n,
1362,ICLR,2018,GATED FAST WEIGHTS FOR ASSOCIATIVE RETRIEVAL,Imanol Schlag;J√ºrgen Schmidhuber,imanol@idsia.ch;juergen@idsia.ch,3;5;4,5;4;4,Reject,0,0,0.0,yes,10/27/17,IDSIA;IDSIA,fast weights;RNN;associative retrieval;time-varying variables,-1;-1,-1;-1,-1;-1,asia,in,n,
1363,ICLR,2018,Connectivity Learning in Multi-Branch Networks,Karim Ahmed;Lorenzo Torresani,karim.mmm@gmail.com;lt@dartmouth.edu,5;5;5,5;4;4,Reject,0,3,0.0,yes,10/27/17,Cornell University;Dartmouth College,connectivity learning;multi-branch networks;image categorization,-1;162,-1;89,-1;-1,usa,usa,n,
1364,ICLR,2018,AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks,Alexander L. Gaunt;Matthew A. Johnson;Alan Lawrence;Maik Riechert;Daniel Tarlow;Ryota Tomioka;Dimitrios Vytiniotis;Sam Webster,algaunt@microsoft.com;matjoh@microsoft.com;allawr@microsoft.com;a-mariec@microsoft.com;dannytarlow@gmail.com;ryoto@microsoft.com;dimitris@microsoft.com;sweb@microsoft.com,6;6;4,5;4;5,Reject,0,6,0.0,yes,10/27/17,Microsoft;Microsoft;Microsoft;Microsoft;Google;Microsoft;Microsoft;Microsoft,asynchronous;neural network;deep learning;graph;tree;rnn,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1365,ICLR,2018,POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION,Prannay Khosla;Preethi Jyothi;Vinay P. Namboodiri;Mukundhan Srinivasan,prannayk@iitk.ac.in;pjyothi@cse.iitb.ac.in;vinaypn@cse.iitk.ac.in;msrinivasan@nvidia.com,5;3;4,4;4;4,Reject,0,6,0.0,yes,10/27/17,IIT Kanpur;Indian Institute of Technology Bombay;IIT Kanpur;NVIDIA,speech;generation;accent;gan;adversarial;reinforcement;memory;lstm;policy;gradients;human,125;-1;125;-1,-1;367;-1;-1,-1;-1,NAN,NAN,n,5;4
1366,ICLR,2018,Autonomous Vehicle Fleet Coordination With Deep Reinforcement Learning,Cane Punma,cane.cane@live.com,3;3;4,5;3;4,Reject,0,0,0.0,yes,10/27/17,0,Deep Reinforcement Learning;mult-agent systems,,,-1,NAN,NAN,n,6
1367,ICLR,2018,BLOCK-NORMALIZED GRADIENT METHOD: AN EMPIRICAL STUDY FOR TRAINING DEEP NEURAL NETWORK,Adams Wei Yu;Lei Huang;Qihang Lin;Ruslan Salakhutdinov;Jaime Carbonell,weiyu@cs.cmu.edu;huanglei@nlsde.buaa.edu.cn;qihang-lin@uiowa.edu;rsalakhu@cs.cmu.edu;jgc@cs.cmu.edu,4;9;2,5;5;5,Reject,0,5,0.0,yes,10/27/17,Carnegie Mellon University;Beihang University;University of Iowa;Carnegie Mellon University;Carnegie Mellon University,,1;95;162;1;1,24;658;223;24;24,-1;-1,usa,usa,y,1
1368,ICLR,2018,Learning Representations for Faster Similarity Search,Ludwig Schmidt;Kunal Talwar,ludwigs@mit.edu;kunal@google.com,4;4;4,5;5;4,Reject,0,0,0.0,yes,10/27/17,Massachusetts Institute of Technology;Google,,8;-1,5;-1,-1;-1,NAN,NAN,y,
1369,ICLR,2018,Optimal transport maps for distribution preserving operations on latent spaces of Generative Models,Eirikur Agustsson;Alexander Sage;Radu Timofte;Luc Van Gool,aeirikur@vision.ee.ethz.ch;sagea@student.ethz.ch;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,4;6;6,3;3;4,Reject,0,4,0.0,yes,10/27/17,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Generative Models;GANs;latent space operations;optimal transport,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,5;4
1370,ICLR,2018,Neural Compositional Denotational Semantics for Question Answering,Nitish Gupta;Mike Lewis,nitishg@cis.upenn.edu;mikelewis@facebook.com,4;5;7,4;4;4,Reject,0,5,0.0,yes,10/27/17,University of Pennsylvania;Facebook,question answering;knowledge graph;compositional model;semantics,15;-1,10;-1,-1;-1,asia,in,n,10
1371,ICLR,2018,Variational Bi-LSTMs,Samira Shabanian;Devansh Arpit;Adam Trischler;Yoshua Bengio,s.shabanian@gmail.com;devansharpit@gmail.com;adam.trischler@microsoft.com;yoshua.umontreal@gmail.com,4;7;6,4;3;4,Reject,6,5,0.0,yes,10/27/17,Microsoft;SalesForce.com;Microsoft;University of Montreal,,-1;-1;-1;125,-1;-1;-1;108,-1;-1,canada,ca,n,
1372,ICLR,2018,TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING,Ahmed A Aly;Joanne Bechta Dugan,aaa2cn@virginia.edu;jbd@virginia.edu,3;2;2,4;3;4,Reject,0,0,0.0,yes,10/27/17,University of Virginia;University of Virginia,Deep Learning;Robotics;Artificial Intelligence;Computer Vision,57;57,113;113,-1;-1,usa,usa,n,2;5;4
1373,ICLR,2018,Towards a Testable Notion of Generalization for Generative Adversarial Networks,Robert Cornish;Hongseok Yang;Frank Wood,rcornish@robots.ox.ac.uk;hongseok.yang@cs.ox.ac.uk;fwood@robots.ox.ac.uk,5;6;4,3;3;4,Reject,6,3,0.0,yes,10/27/17,University of Oxford;University of Oxford;University of Oxford,generative adversarial networks;Wasserstein;GAN;generalization;theory,39;39;39,1;1;1,-1;-1,europe,uk,n,5;4
1374,ICLR,2018,3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY,Yeu-Chern Harn;Vladimir Jojic,ycharn@cs.unc.edu;vjojic@gmail.com,5;4;4,5;4;5,Reject,0,0,0.0,yes,10/27/17,"University of North Carolina, Chapel Hill;Calico Labs",,67;-1,-1;-1,-1;-1,NAN,NAN,n,5
1375,ICLR,2018,Alpha-divergence bridges maximum likelihood and reinforcement learning in neural sequence generation,Sotetsu Koyamada;Yuta Kikuchi;Atsunori Kanemura;Shin-ichi Maeda;Shin Ishii,sotetsu.koyamada@gmail.com,4;4;4,5;1;3,Reject,0,0,0.0,yes,10/27/17,0,neural network;reinforcement learning;natural language processing;machine translation;alpha-divergence,,,-1;-1,NAN,NAN,y,3
1376,ICLR,2018,Don't encrypt the data; just approximate the model \ Towards Secure Transaction and Fair Pricing of Training Data,Xinlei Xu,xxu@hmc.edu,2;4;3,4;5;5,Reject,0,0,0.0,yes,10/27/17,Harvey Mudd College,Applications;Security in Machine Learning;Fairness and Security;Model Compression,-1,-1,-1,NAN,NAN,n,4
1377,ICLR,2018,An inference-based policy gradient method for learning options,Matthew J. A. Smith;Herke van Hoof;Joelle Pineau,matthew.smith5@mail.mcgill.ca;herke.vanhoof@mail.mcgill.ca;jpineau@cs.mcgill.ca,3;3;4,4;5;4,Reject,0,5,0.0,yes,10/27/17,McGill University;McGill University;McGill University,reinforcement learning;hierarchy;options;inference,95;95;95,42;42;42,-1;-1,canada,ca,n,
1378,ICLR,2018,Sequential Coordination of Deep Models for Learning Visual Arithmetic,Eric Crawford;Guillaume Rabusseau;Joelle Pineau,eric.crawford@mail.mcgill.ca;guillaume.rabusseau@mail.mcgill.ca;jpineau@cs.mcgill.ca,4;3;2,4;4;4,Reject,0,4,0.0,yes,10/27/17,McGill University;McGill University;McGill University,reinforcement learning;pretrained;deep learning;perception;algorithmic,95;95;95,42;42;42,-1;-1,canada,ca,n,
1379,ICLR,2018,What is image captioning made of?,Pranava Madhyastha;Josiah Wang;Lucia Specia,p.madhyastha@sheffield.ac.uk;j.k.wang@sheffield.ac.uk;l.specia@sheffield.ac.uk,4;4;4,5;4;5,Reject,0,10,0.0,yes,10/27/17,University of Sheffield;University of Sheffield;University of Sheffield,image captioning;representation learning;interpretability;rnn;multimodal;vision to language,162;162;162,104;104;104,-1;-1,europe,uk,n,
1380,ICLR,2018,Fraternal Dropout,Konrad Zolna;Devansh Arpit;Dendi Suhubdy;Yoshua Bengio,konrad.zolna@gmail.com;devansh.arpit@umontreal.ca;dasuhubd@ncsu.edu;bengioy@iro.umontreal.ca,5;5;6,4;3;3,Accept (Poster),0,7,0.0,yes,10/27/17,Jagiellonian University;University of Montreal;SUN YAT-SEN UNIVERSITY;University of Montreal,fraternal dropout;activity regularization;recurrent neural networks;RNN;LSTM;faster convergence,-1;125;-1;125,695;108;352;108,-1;-1,canada,ca,n,3
1381,ICLR,2018,TD Learning with Constrained Gradients,Ishan Durugkar;Peter Stone,ishand@cs.utexas.edu;pstone@cs.utexas.edu,2;3;4,4;4;4,Reject,1,4,0.0,yes,10/27/17,"University of Texas, Austin;University of Texas, Austin",Reinforcement Learning;TD Learning;DQN,-1;-1,-1;-1,-1;-1,usa,usa,n,
1382,ICLR,2018,WSNet: Learning Compact and Efficient Networks with Weight Sampling,Xiaojie Jin;Yingzhen Yang;Ning Xu;Jianchao Yang;Jiashi Feng;Shuicheng Yan,xiaojie.jin@u.nus.edu;superyyzg@gmail.com;ning.xu@snap.com;jiachao.yang@snap.com;elefjia@nus.edu.sg;yanshuicheng@360.com,6;6;5,4;3;5,Invite to Workshop Track,0,0,0.0,yes,10/27/17,National University of Singapore;;Snap Inc.;Snap Inc.;National University of Singapore;360,Deep learning;model compression,15;-1;-1;-1;15;-1,22;-1;-1;-1;22;-1,-1;-1,asia,in,n,
1383,ICLR,2018,Generative Entity Networks: Disentangling Entitites and Attributes in Visual Scenes using Partial Natural Language Descriptions,Charlie Nash;Sebastian Nowozin;Nate Kushman,charlie.nash@ed.ac.uk;sebastian.nowozin@microsoft.com;nate@kushman.org,4;5;5,4;4;5,Reject,0,3,0.0,yes,10/27/17,University of Edinburgh;Microsoft;Google,VAE;Generative Model;Vision;Natural Language,30;-1;-1,27;-1;-1,-1;-1,NAN,NAN,n,8;3;5
1384,ICLR,2018,Prediction Under Uncertainty with Error Encoding Networks,Mikael Henaff;Junbo Zhao;Yann Lecun,mbh305@nyu.edu;j.zhao@nyu.edu;yann@cs.nyu.edu,4;5;5,4;3;2,Reject,7,3,0.0,yes,10/27/17,New York University;New York University;New York University,,21;21;21,27;27;27,-1;-1,usa,usa,n,4
1385,ICLR,2018,Noise-Based Regularizers for Recurrent Neural Networks,Adji B. Dieng;Jaan Altosaar;Rajesh Ranganath;David M. Blei,abd2141@columbia.edu;altosaar@princeton.edu;rajeshr@cs.princeton.edu;david.blei@columbia.edu,2;5;3,5;4;3,Reject,2,2,0.0,yes,10/27/17,Columbia University;Princeton University;Princeton University;Columbia University,,21;30;30;21,14;7;7;14,-1;-1,usa,usa,n,3
1386,ICLR,2018,Learning To Generate Reviews and Discovering Sentiment,Alec Radford;Rafal Jozefowicz;Ilya Sutskever,alec@openai.com;rafal@openai.com;ilya@openai.com,4;2;4,3;5;5,Reject,1,0,0.0,yes,10/27/17,OpenAI;OpenAI;OpenAI,unsupervised learning;representation learning;deep learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;5
1387,ICLR,2018,Deep learning mutation prediction enables early stage lung cancer detection in liquid biopsy,Steven T. Kothen-Hill;Asaf Zviran;Rafael C. Schulman;Sunil Deochand;Federico Gaiti;Dillon Maloney;Kevin Y. Huang;Will Liao;Nicolas Robine;Nathaniel D. Omans;Dan A. Landau,sth2022@med.cornell.edu;azviran@nygenome.org;rschulman@nygenome.org;sdd325@nyu.edu;fgaiti@nygenome.org;dmaloney@nygenome.org;khuang@nygenome.org;wliao@nygenome.org;nrobine@nygenome.org;nao2013@med.cornell.edu;dal3005@med.cornell.edu,8;4;5,4;3;4,Invite to Workshop Track,0,7,0.0,yes,10/27/17,Cornell University;New York Genome Center;New York Genome Center;New York University;New York Genome Center;New York Genome Center;New York Genome Center;New York Genome Center;New York Genome Center;Cornell University;Cornell University,somatic mutation;variant calling;cancer;liquid biopsy;early detection;convolution;deep learning;machine learning;lung cancer;error suppression;mutect,5;-1;-1;21;-1;-1;-1;-1;-1;5;5,19;-1;-1;27;-1;-1;-1;-1;-1;19;19,-1;-1,usa,usa,n,
1388,ICLR,2018,Covariant Compositional Networks For Learning Graphs,Risi Kondor;Truong Son Hy;Horace Pan;Brandon M. Anderson;Shubhendu Trivedi,risi@cs.uchicago.edu;hytruongson@uchicago.edu;hopan@cs.uchicago.edu;brandona@uchicago.edu;shubhendu@ttic.edu,5;5;6,3;2;3,Invite to Workshop Track,0,12,0.0,yes,10/27/17,University of Chicago;University of Chicago;University of Chicago;University of Chicago;Toyota Technological Institute at Chicago,graph neural networks;message passing;label propagation;high order representation,57;57;57;57;-1,9;9;9;9;-1,-1;-1,NAN,NAN,y,10
1389,ICLR,2018,A novel method to determine the number of latent dimensions with SVD,Asana Neishabouri;Michel Desmarais,asana.neishabouri@polymtl.ca;michel.desmarais@polymtl.ca,1;2;3,4;5;4,Reject,1,0,0.0,yes,10/27/17,Polytechnique Montreal;Polytechnique Montreal,SVD;Latent Dimensions;Dimension Reductions;Machine Learning,377;377,-1;-1,-1;-1,canada,ca,n,
1390,ICLR,2018,Automatic Goal Generation for Reinforcement Learning Agents,David Held;Xinyang Geng;Carlos Florensa;Pieter Abbeel,dheld@andrew.cmu.edu;young.geng@berkeley.edu;florensa@berkeley.edu;pabbeel@berkeley.edu,8;4;6,4;4;4,Reject,0,19,0.0,yes,10/27/17,Carnegie Mellon University;University of California Berkeley;University of California Berkeley;University of California Berkeley,Reinforcement Learning;Multi-task Learning;Curriculum Learning,1;-1;-1;-1,24;18;18;18,-1;-1,usa,usa,n,5;4
1391,ICLR,2018,A Goal-oriented Neural Conversation Model by Self-Play,Wei Wei;Quoc V. Le;Andrew M. Dai;Li-Jia Li,wewei@google.com;adai@google.com;qvl@google.com;lijiali@google.com,6;4;3,3;3;4,Reject,0,0,0.0,yes,10/27/17,Google;Google;Google;Google,conversation model;seq2seq;self-play;reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
1392,ICLR,2018,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,Mattias Teye;Hossein Azizpour;Kevin Smith,teye@kth.se;azizpour@kth.se;ksmith@kth.se,5;5;6,3;4;4,Reject,0,5,1.0,yes,10/27/17,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",uncertainty estimation;deep learning;Bayesian learning;batch normalization,162;162;162,173;173;173,-1;-1,NAN,NAN,n,11
1393,ICLR,2018,Learning Efficient Tensor Representations with Ring Structure Networks,Qibin Zhao;Masashi Sugiyama;Longhao Yuan;Andrzej Cichocki,qibin.zhao@riken.jp;sugi@k.u-tokyo.ac.jp;longhao.yuan@riken.jp;a.cichocki@riken.jp,5;5;6,4;4;3,Invite to Workshop Track,0,5,0.0,yes,10/27/17,RIKEN;The University of Tokyo;RIKEN;RIKEN,Tensor Decomposition;Tensor Networks;Stochastic Gradient Descent,-1;57;-1;-1,-1;45;-1;-1,-1;-1,NAN,NAN,y,
1394,ICLR,2018,Video Action Segmentation with Hybrid Temporal Networks,Li Ding;Chenliang Xu,liding@rochester.edu;chenliang.xu@rochester.edu,3;4;3,5;4;5,Reject,0,0,0.0,yes,10/27/17,University of Rochester;University of Rochester,action segmentation;video labeling;temporal networks,95;95,153;153,-1;-1,europe,uk,n,8;2
1395,ICLR,2018,The Variational Homoencoder: Learning to Infer High-Capacity Generative Models from Few Examples,Luke Hewitt;Andrea Gane;Tommi Jaakkola;Joshua B. Tenenbaum,lbh@mit.edu;agane@mit.edu;tommi@csail.mit.edu;jbt@mit.edu,7;5;6,4;5;3,Reject,0,5,0.0,yes,10/27/17,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,generative models;one-shot learning;metalearning;pixelcnn;hierarchical bayesian;omniglot,8;8;8;8,5;5;5;5,-1;-1,usa,usa,n,11;5
1396,ICLR,2018,Hyperedge2vec: Distributed Representations for Hyperedges,Ankit Sharma;Shafiq Joty;Himanshu Kharkwal;Jaideep Srivastava,sharm170@umn.edu;srjoty@ntu.edu.sg;himanshukharkwal765@gmail.com;srivasta@umn.edu,5;5;5,3;3;4,Reject,0,5,0.0,yes,10/27/17,"University of Minnesota, Minneapolis;Nanyang Technological University;;University of Minnesota, Minneapolis",hypergraph;representation learning;tensors,67;39;-1;67,56;52;-1;56,-1;-1,NAN,NAN,n,10
1397,ICLR,2018,Combining Model-based and Model-free RL via Multi-step Control Variates,Tong Che;Yuchen Lu;George Tucker;Surya Bhupatiraju;Shane Gu;Sergey Levine;Yoshua Bengio,gerryche@berkeley.edu;luyuchen.paul@gmail.com;gjt@google.com;sbhupatiraju@google.com;shanegu@google.com;svlevine@eecs.berkeley.edu;bengioy@iro.umontreal.ca,5;5;4,4;4;3,Reject,0,2,0.0,yes,10/27/17,University of California Berkeley;University of Montreal;Google;Google;Google;University of California Berkeley;University of Montreal,,-1;125;-1;-1;-1;-1;125,18;108;-1;-1;-1;18;108,-1;-1,canada,ca,n,
1398,ICLR,2018,Tree2Tree Learning with Memory Unit,Ning Miao;Hengliang Wang;Ran Le;Chongyang Tao;Mingyue Shang;Rui Yan;Dongyan Zhao,miaoning@pku.edu.cn;wanghl@pku.edu.cn;leran@buaa.edu.cn;chongyangtao@pku.edu.cn;shangmy@pku.edu.cn;ruiyan@pku.edu.cn;zhaody@pku.edu.cn,2;5;4,4;4;4,Reject,0,1,0.0,yes,10/27/17,Peking University;Peking University;Beihang University;Peking University;Peking University;Peking University;Peking University,,14;14;95;14;14;14;14,27;27;658;27;27;27;27,-1;-1,asia,cn,n,3
1399,ICLR,2018,Revisiting Knowledge Base Embedding as Tensor Decomposition,Jiezhong Qiu;Hao Ma;Yuxiao Dong;Kuansan Wang;Jie Tang,xptree@gmail.com;haoma@microsoft.com;yuxdong@microsoft.com;kuansanw@microsoft.com;jietang@tsinghua.edu.cn,3;5;3,4;4;4,Reject,5,0,0.0,yes,10/27/17,"Tsinghua University;Microsoft;Microsoft;Microsoft;Tsinghua University, Tsinghua University",Knowledge base embedding,-1;-1;-1;-1;5,-1;-1;-1;-1;30,-1;-1,NAN,NAN,n,
1400,ICLR,2018,Assessing the scalability of biologically-motivated deep learning algorithms and architectures,Anonymous,ICLR.cc/2018/Conference/Paper607/Authors,8;5;6,5;3;4,Withdrawn,1,0,,yes,1/13/18,0,target propagation;biologically-plausible learning;benchmark;neuroscience;,,,-1,NAN,NAN,n,1
1401,ICLR,2018,Neural Variational Sparse Topic Model,Anonymous,ICLR.cc/2018/Conference/Paper79/Authors,5;3;3,4;4;4,Withdrawn,0,0,,yes,1/21/18,0,Variational Autoencoder;Sparse Topical Coding;Neural Variational Inference;,,,-1,NAN,NAN,n,3;5
1402,ICLR,2018,Melody Generation for Pop Music via Word Representation of Musical Properties,Andrew Shin;Leopold Crestel;Hiroharu Kato;Kuniaki Saito;Katsunori Ohnishi;Masataka Yamaguchi;Masahiro Nakawaki;Yoshitaka Ushiku;Tatsuya Harada,andrew@mi.t.u-tokyo.ac.jp;crestel@ircam.fr;kato@mi.t.u-tokyo.ac.jp;k-saito@mi.t.u-tokyo.ac.jp;ohnishi@mi.t.u-tokyo.ac.jp;yamaguchi@mi.t.u-tokyo.ac.jp;nakawaki.ici@gmail.com;ushiku@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,4;4;5,5;4;4,Withdrawn,0,0,,yes,1/29/18,The University of Tokyo;Institut de Recherche et Coordination Acoustique/Musique;The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo;;The University of Tokyo;The University of Tokyo,music;lstm;gan;generation;rnn;hmm;,57;-1;57;57;57;57;-1;57;57,45;-1;45;45;45;45;-1;45;45,-1;-1,NAN,NAN,n,
1403,ICLR,2018,Spatial Variational Auto-Encoding via Matrix-Variate Normal Distributions,Zhengyang Wang;Hao Yuan;Shuiwang Ji,zwang6@eecs.wsu.edu;hao.yuan@wsu.edu;sji@eecs.wsu.edu,5;4;3,2;4;5,Withdrawn,0,0,,yes,12/3/17,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Variational auto-encoder;unsupervised learning;image generation;spatial information;matrix-variate normal distribution;,-1;-1;-1,352;352;352,-1;-1,NAN,NAN,n,5
1404,ICLR,2018,Dense Transformer Networks,Jun Li;Yongjun Chen;Lei Cai;Ian Davidson;Shuiwang Ji,jun.li3@wsu.edu;yongjun.chen@wsu.edu;lei.cai@wsu.edu;davidson@cs.ucdavis.edu;sji@eecs.wsu.edu,3;4;4,5;4;4,Withdrawn,0,0,,yes,12/2/17,"SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;University of California, Davis;SUN YAT-SEN UNIVERSITY",,-1;-1;-1;-1;-1,352;352;352;54;352,-1;-1,NAN,NAN,n,8;2
1405,ICLR,2018,Self-Organization adds application robustness to deep learners,Pitoyo Hartono;Thomas Trappenberg,hartono@ieee.org;tt@cs.dal.edu,4;2;2,4;5;5,Withdrawn,0,0,,yes,12/25/17,Chukyo University;Dalhousie University,supervised learning;unsupervised learning;self-organization;internal representation;topological structure;,-1;-1,904;-1,-1;-1,asia,in,n,
1406,ICLR,2018,Information Theoretic Co-Training,David McAllester,mcallester@ttic.edu,4;5;4,4;3;4,Withdrawn,0,0,,yes,1/5/18,Toyota Technological Institute at Chicago,co-training;phonetics;unsupervised learning;mutual information;,-1,-1,-1,NAN,NAN,n,
1407,ICLR,2018,Towards Quantum Inspired Convolution Networks,Davi Geiger;Zvi Kedem,dg1@nyu.edu;kedem@nyu.edu,3;4;5,5;3;3,Withdrawn,3,0,,yes,12/2/17,New York University;New York University,quantum technique;convolution networks;shape detection;,21;21,27;27,-1;-1,usa,usa,n,11;1
1408,ICLR,2018,A cluster-to-cluster framework for neural machine translation,Anonymous,ICLR.cc/2018/Conference/Paper150/Authors,6;3;5,3;4;2,Withdrawn,0,0,,yes,12/13/17,0,Natural Language Processing;Machine Translation;Deep Learning;Data Augmentation;,,,-1,NAN,NAN,n,3
1409,ICLR,2018,Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic Interpretation of Deep Learning,Anonymous,ICLR.cc/2018/Conference/Paper167/Authors,3;7;4,3;2;4,Withdrawn,0,0,,yes,1/4/18,0,deep learning;CNN;fuzzy logic;generalized hamming distance;,,,-1,NAN,NAN,y,1
1410,ICLR,2018,Interactive Boosting of Neural Networks for Small-sample Image Classification,Xiaoxu Li;Dongliang Chang;Zheng-Hua Tan;Zhanyu Ma;Jun Guo;Jie Cao,xiaoxulilut@gmail.com;dlchanglut@hotmai.com;zt@es.aau.dk;mazhanyu@bupt.edu.cn;guojun@bupt.edu.cn;caoj@lut.cn,5;5;4,4;5;4,Withdrawn,1,4,,yes,1/2/18,Lanzhou University of Technology;Hotmai;Aarhus University;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Lanzhou University of Technology,ensemble learning;neural network;small-sample;overfitting;variance;,-1;-1;82;-1;-1;-1,-1;-1;109;-1;-1;-1,-1;-1,asia,in,n,1
1411,ICLR,2018,Tensor-Based Preposition Representation,Hongyu Gong;Suma Bhat;Pramod Viswanath,hgong6@illinois.edu;pramodv@illinois.edu;spbhat2@illinois.edu,6;4;5,4;4;4,Withdrawn,0,0,,yes,12/12/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",word representation;unsupervised learning;computational linguistics;,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
1412,ICLR,2018,Tactical Decision Making for Lane Changing with Deep Reinforcement Learning,Mustafa Mukadam;Akansel Cosgun;Alireza Nakhaei;Kikuo Fujimura,mmukadam3@gatech.edu;acosgun@hra.com;anakhaei@hra.com;kfujimura@hra.com,3;3;3,4;5;5,Withdrawn,0,0,,yes,12/13/17,Georgia Institute of Technology;Hra;Hra;Hra,autonomous lane changing;decision making;deep reinforcement learning;q-learning;,13;-1;-1;-1,33;683;683;683,-1;-1,asia,in,n,
1413,ICLR,2018, A Matrix Approximation View of NCE that Justifies Self-Normalization,Jacob Goldberger;Oren Melamud,jacob.goldberger@biu.ac.il;oren@melamuds.com,6;2;3,3;4;5,Withdrawn,0,0,,yes,12/14/17,Bar Ilan University;Melamuds,language modeling;NCE;self-normalization;,82;-1,456;-1,-1;-1,NAN,NAN,y,3;8;1
1414,ICLR,2018,Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text,Anonymous,ICLR.cc/2018/Conference/Paper265/Authors,4;3;4,5;4;5,Withdrawn,0,0,,yes,1/22/18,0,Text;Empirical Investigation;Model Capacity;Generalization Ability;Neural Networks;Deep Learning;,,,-1,NAN,NAN,n,3;1
1415,ICLR,2018,Detecting Anomalies in Communication Packet Streams based on  Generative Adversarial Networks,Anonymous,ICLR.cc/2018/Conference/Paper280/Authors,6;4;5,4;5;3,Withdrawn,0,3,,yes,1/3/18,0,Anomaly Detection;Fault diagnosis;Generative Adversarial Networks;Network Operation;TCP/IP;,,,-1,NAN,NAN,n,6;10;4
1416,ICLR,2018,Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection,Haw-Shiuan Chang;ZiYun Wang;Luke Vilnis;Andrew McCallum,hschang@cs.umass.edu;wang-zy14@mails.tsinghua.edu.cn;luke@cs.umass.edu;mccallum@cs.umass.edu,4;5;5,5;5;5,Withdrawn,0,3,,yes,12/15/17,"University of Massachusetts, Amherst;Tsinghua University, Tsinghua University;University of Massachusetts, Amherst;University of Massachusetts, Amherst",unsupervised word embedding;unsupervised hypernym detection;distributional inclusion hypothesis;non-negative matrix factorization;word sense disambiguation;hypernym scoring functions;,21;5;21;21,191;30;191;191,-1;-1,usa,usa,n,3;1
1417,ICLR,2018,Embedding Multimodal Relational Data,Pouya Pezeshkpour;Liyan Chen;Sameer Singh,pezeshkp@uci.edu;liyanc@uci.edu;sameer@uci.edu,6;4;5,4;4;5,Withdrawn,0,0,,yes,12/13/17,"University of California, Irvine;University of California, Irvine;University of California, Irvine",multimodal;knowledge base;relational modeling;embedding;link prediction;neural network encoders;,-1;-1;-1,99;99;99,-1;-1,usa,usa,n,
1418,ICLR,2018,pix2code: Generating Code from a Graphical User Interface Screenshot,Anonymous,ICLR.cc/2018/Conference/Paper334/Authors,2;5;5,5;4;4,Withdrawn,0,0,,yes,12/14/17,0,computer vision;scene understanding;text processing;,,,-1,NAN,NAN,n,10
1419,ICLR,2018,Improved Learning in Convolutional Neural Networks with Shifted Exponential Linear Units (ShELUs),Anonymous,ICLR.cc/2018/Conference/Paper459/Authors,1;4;3,5;5;5,Withdrawn,0,5,,yes,1/17/18,0,,,,-1,NAN,NAN,n,
1420,ICLR,2018,Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning,Mo Yu;Xiaoxiao Guo;Jinfeng Yi;Shiyu Chang;Saloni Potdar;Gerald Tesauro;Haoyu Wang;Bowen Zhou,yum@us.ibm.com;xiaoxiao.guo@ibm.com;jinfengyi.ustc@gmail.com,5;4;5,4;4;4,Withdrawn,0,0,,yes,12/14/17,International Business Machines;International Business Machines;JD AI Research,task clustering;matrix completion;multi-task learning;few-shot learning;,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,6;1
1421,ICLR,2018,Per-Weight Class-Based Learning Rates via Analytical Continuation,Michael Rotman;Lior Wolf,migo007@gmail.com;wolf@fb.com,3;3;3,4;2;4,Withdrawn,0,0,,yes,12/2/17,Tel Aviv University;Facebook,adaptive learning rates;analytical continuation;fully connected networks;,30;-1,217;-1,-1;-1,NAN,NAN,n,
1422,ICLR,2018,VSE++: Improving Visual-Semantic Embeddings with Hard Negatives,Fartash Faghri;David J. Fleet;Jamie Ryan Kiros;Sanja Fidler,faghri@cs.toronto.edu;fleet@cs.toronto.edu;rkiros@cs.toronto.edu;fidler@cs.toronto.edu,4,4,Withdrawn,0,0,,yes,11/16/17,University of Toronto;University of Toronto;University of Toronto;University of Toronto,Joint embeddings;Hard Negatives;Visual-semantic embeddings;Cross-modal retrieval;Ranking;,21;21;21;21,22;22;22;22,-1;-1,canada,ca,n,
1423,ICLR,2018,Dynamically Learning the Learning Rates:  Online Hyperparameter Optimization,Tuhin Sarkar;Anima Anandkumar;Leo Dirac,tsarkar@mit.edu;animakumar@gmail.com;leodirac@amazon.com,4;5;4,4;4;4,Withdrawn,0,0,,yes,1/3/18,Massachusetts Institute of Technology;California Institute of Technology;Amazon,hyperparameters;optimization;SGD;Adam;Bayesian;,8;125;-1,5;3;-1,-1;-1,NAN,NAN,n,11
1424,ICLR,2018,MULTI-MODAL GEOLOCATION ESTIMATION USING DEEP NEURAL NETWORKS,Jesse Johns;Jeremiah Rounds;Michael Henry,jesse.johns@pnnl.gov;jeremiah.rounds@pnnl.gov;michael.j.henry@pnnl.gov,4;4;3,4;4;4,Withdrawn,0,0,,yes,1/3/18,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,deep neural networks;geolocation;inception;long-short term memory networks;social media applications;,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1425,ICLR,2018,Accelerating Convolutional Neural Networks using Iterative Two-Pass Decomposition,Wei-Shiang Lin;Hao-Ning Wu;Chih-Tsun Huang,weishianglin1993@gmail.com;wuhoward2002@gmail.com;cthuang@cs.nthu.edu.tw,4;3;5,4;5;4,Withdrawn,0,0,,yes,1/5/18,National Tsing Hua University;;National Tsing Hua University,Convolutional Neural Networks;CNN;CP Decomposition;Low Rank Approximation;,-1;-1;224,-1;-1;323,-1;-1,asia,tw,n,
1426,ICLR,2018,Adaptive Weight Sparsity for Training Deep Neural Networks,Michael James;Jack Lindsey;Ilya Sharapov,michael@cerebras.net;jacklindsey@stanford.edu;ilya@cerebras.net,5;3;4,3;4;2,Withdrawn,0,1,,yes,1/20/18,"Cerebras Systems, Inc;Stanford University;Cerebras Systems, Inc",deep learning;sparsity;adaptive methods;,-1;5;-1,-1;3;-1,-1;-1,NAN,NAN,n,
1427,ICLR,2018,Deep Net Triage: Assessing The Criticality of Network Layers by Structural Compression,Theodore S. Nowak;Jason J. Corso,tsnowak@umich.edu;jjcorso@umich.edu,5;4;5,4;4;3,Withdrawn,0,0,,yes,1/6/18,University of Michigan;University of Michigan,Deep Compression;Deep Learning;Parent-Teacher Networks;,10;10,21;21,-1;-1,usa,usa,n,
1428,ICLR,2018,Deep Active Learning over the Long Tail,Anonymous,ICLR.cc/2018/Conference/Paper718/Authors,5;4;4,3;4;4,Withdrawn,0,1,,yes,1/5/18,0,Active Learning;Deep Learning;Coreset;Deep Representation;Compression;,,,-1,NAN,NAN,n,
1429,ICLR,2018,THE LOCAL DIMENSION OF DEEP MANIFOLD,Mengxiao Zhang;Wangquan Wu;Yanren Zhang;Kun He;Tao Yu;Huan Long;John E. Hopcroft,zmx@hust.edu.cn;u201514497@hust.edu.cn;hhxjzyr@hust.edu.cn;brooklet60@hust.edu.cn;ydtydr@sjtu.edu.cn;longhuan@cs.sjtu.edu.cn;jeh@cs.cornell.edu,3;3;5,4;3;4,Withdrawn,0,0,,yes,1/3/18,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Cornell University,activation manifold;dimension;deep neural network;singular value decomposition;,-1;-1;-1;-1;39;39;5,44;44;44;44;188;188;19,-1;-1,usa,usa,n,
1430,ICLR,2018,Learning to Imagine Manipulation Goals for Robot Task Planning,Chris Paxton;Kapil Katyal;Christian Rupprecht;Raman Arora;Gregory D Hager,cpaxton@jhu.edu;kkatyal2@jhu.edu;christian.rupprecht@in.tum.de;arora@cs.jhu.edu;hager@cs.jhu.edu,3;3;3,4;3;3,Withdrawn,1,0,,yes,12/22/17,Johns Hopkins University;Johns Hopkins University;Technical University Munich;Johns Hopkins University;Johns Hopkins University,deep learning;planning;prediction;generative models;,57;57;-1;57;57,13;13;-1;13;13,-1;-1,usa,usa,n,
1431,ICLR,2018,Human-like Clustering with Deep Convolutional Neural Networks,Ali Borji;Aysegul Dundar,aliborji@gmail.com;adundar@purdue.edu,4;3,5;5,Withdrawn,1,1,,yes,12/4/17,HCL America;Purdue University,Cluttering;deep learning;human learning;,-1;27,-1;60,-1;-1,usa,usa,n,2
1432,ICLR,2018,Attribute-aware Collaborative Filtering: Survey and Classification,Wen-Hao Chen;Chin-Chi Hsu;Mi-Yen Yeh;Shou-De Lin,b02902023@ntu.edu.tw;chinchi@iis.sinica.edu.tw;miyen@iis.sinica.edu.tw;sdlin@csie.ntu.edu.tw,5;5;4,4;5;5,Withdrawn,0,0,,yes,12/11/17,Nanyang Technological University;Academia Sinica;Academia Sinica;Nanyang Technological University,,39;-1;-1;39,52;-1;-1;52,-1;-1,asia,sg,n,
1433,ICLR,2018,Continuous Propagation: Layer-Parallel Training,Michael James;Devansh Arpit;Herman Sahota;Ilya Sharapov,michae@cerebras.net;devansharpit@gmail.com;herman@cerebras.net;ilya@cerebras.net,5;4;3,4;3;4,Withdrawn,1,3,,yes,1/19/18,"Cerebras Systems, Inc;SalesForce.com;Cerebras Systems, Inc;Cerebras Systems, Inc",Deep Learning;Model parallelism;Learning theory;,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,9
1434,ICLR,2018,Learning Topics using Semantic Locality,Ziyi Zhao;Krittaphat Pugdeethosapol;Sheng Lin;Zhe Li;Yanzhi Wang;Qinru Qiu,zzhao37@syr.edu;kpugdeet@syr.edu;shlin@syr.edu;zli89@syr.edu;ywang393@syr.edu;qiqiu@syr.edu,3;4;3,4;4;5,Withdrawn,0,0,,yes,1/24/18,Syracuse University;Syracuse University;Syracuse University;Syracuse University;Syracuse University;Syracuse University,,224;224;224;224;224;224,275;275;275;275;275;275,-1;-1,usa,usa,n,
1435,ICLR,2018,Anticipatory Asynchronous Advantage Actor-Critic (A4C): The power of Anticipation in Deep Reinforcement Learning,Xun Luan;Tharun Medini;Anshumali Shrivastava,xun.luan@rice.edu;trm3@rice.edu;anshumali@rice.edu,4;2;3,4;5;5,Withdrawn,0,2,,yes,1/13/18,Rice University;Rice University;Rice University,deep reinforcement learning;A3C;deep learning;Atari games;,95;95;95,86;86;86,-1;-1,australasia,au,n,
1436,ICLR,2018,Sparse Deep Scattering Crois√© Network,Romain Cosentino;Randall Balestriero;Richard Baraniuk;Ankit Patel,rom.cosentino@gmail.com;randallbalestriero@gmail.com;ankitpatel715@gmail.com;baraniuk@gmail.com,6,4,Withdrawn,0,0,,yes,11/25/17,Rice University;Rice University;;College de France,Deep Scattering Network;Continuous Wavelet Thresholding;Sparse Activations;Time-frequency represenation;Multi-Family;Wavelets;Convolutional Network;Bird Detection;,95;95;-1;-1,86;86;-1;-1,-1;-1,asia,in,n,
1437,ICLR,2018,Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing,Syed Shakib Sarwar;Aayush Ankit;Kaushik Roy,sarwar@purdue.edu;aankit@purdue.edu;kaushik@purdue.edu,4;2;4,4;5;5,Withdrawn,0,0,,yes,12/7/17,Purdue University;Purdue University;Purdue University,Deep learning;Incremental learning;energy-efficient learning;supervised learning;,27;27;27,60;60;60,-1;-1,usa,usa,n,6
1438,ICLR,2018,Bayesian Embeddings for Long-Tailed Datasets,Victor Fragoso;Deva Ramanan,victor.fragoso@mail.wvu.edu;deva@andrew.cmu.edu,5;5;5,4;4;4,Withdrawn,1,3,,yes,1/17/18,West Virginia University;Carnegie Mellon University,Long-tail datasets;Imbalanced datasets;,224;1,-1;24,-1;-1,usa,usa,n,11
1439,ICLR,2018,Deep Hyperspherical Defense against Adversarial Perturbations,Weiyang Liu;Zhen Liu;Zhehui Chen;Bo Dai;Tuo Zhao;Le Song,wyliu@gatech.edu;liuzhen1994@gatech.edu;zchen451@gatech.edu;bohr.dai@gmail.com;tourzhao@gatech.edu;lsong@cc.gatech.edu,4;5;5,5;4;3,Withdrawn,0,0,,yes,12/4/17,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Google;Georgia Institute of Technology;Georgia Institute of Technology,,13;13;13;-1;13;13,33;33;33;-1;33;33,-1;-1,usa,usa,y,4
1440,ICLR,2018,FastNorm: Improving Numerical Stability of Deep Network Training with Efficient Normalization,Sadhika Malladi;Ilya Sharapov,sadhika@mit.edu;ilya@cerebras.net,4;4;3,3;4;3,Withdrawn,0,2,,yes,1/20/18,"Massachusetts Institute of Technology;Cerebras Systems, Inc",Neural networks;Training;Convergence;,8;-1,5;-1,-1;-1,NAN,NAN,n,
1441,ICLR,2018,Cluster-based Warm-Start Nets,Anonymous,ICLR.cc/2018/Conference/Paper998/Authors,6;3;3,5;4;4,Withdrawn,0,4,,yes,1/5/18,0,hierarchical labels;weak labels;pairwise constraints;clustering;classification;,,,-1,NAN,NAN,n,
1442,ICLR,2018,Do Convolutional Neural Networks act  as Compositional Nearest Neighbors?,Anonymous,ICLR.cc/2018/Conference/Paper1109/Authors,4;3;3,5;5;3,Withdrawn,1,13,,yes,1/17/18,0,interpreting convolutional neural networks;nearest neighbors;generative adversarial networks;,,,-1,NAN,NAN,n,2;5
1443,ICLR,2018,DETECTING ADVERSARIAL PERTURBATIONS WITH SALIENCY,Chiliang Zhang;Zuochang Ye;Bo Zhang;Deli Zhao,zhangcl16@mails.tsinghua.edu.cn;zuochang@tsinhua.edu.cn;zhangbo@xiaomi.com;zhaodeli@gmail.com,3;4;4;4,5;4;4;4,Withdrawn,0,1,,yes,12/12/17,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Xiaomi;Alibaba Group",Adversarial Examples;Detection;Saliency;Model Interpretation;,5;5;-1;-1,30;30;-1;-1,-1;-1,NAN,NAN,n,1;4
1444,ICLR,2018,Withdraw,Liyuan Liu;Jingbo Shang;Xiaotao Gu;Xiang Ren;Jian Peng;Jiawei Han,ll2@illinois.edu;shang7@illinois.edu;xiaotao2@illinois.du;xiangren@usc.edu;jianpeng@illinois.edu;hanj@illinois.edu,5;4;3,3;5;5,Withdrawn,0,0,,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;;University of Southern California;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1;-1;27;-1;-1,-1;-1;-1;66;-1;-1,-1;-1,usa,usa,n,
1445,ICLR,2018,Complex- and Real-Valued Neural Network Architectures,Nils Moenning;Suresh Manandhar,nm819@york.ac.uk;suresh.manandhar@york.ac.uk,2;4;3,5;4;4,Withdrawn,0,3,,yes,1/3/18,University of York;University of York,complex numbers;complex-valued;neural;network;multi-layer;perceptron;architecture;,224;224,137;137,-1;-1,europe,ch,n,
1446,ICLR,2018,Learning with Mental Imagery,Anonymous,ICLR.cc/2018/Conference/Paper839/Authors,4;3;3,4;4;4,Withdrawn,0,0,,yes,1/5/18,0,Deep Learning;Adversarial Networks;Object Instance Recognition;Cognitive AI;,,,-1,NAN,NAN,n,5;4
1447,ICLR,2018,Withdrawn,withdrawn.,withdrawn,5;7;5,5;4;4,Withdrawn,0,0,,yes,1/2/18,0,,,,-1,NAN,NAN,pdf miss,
1448,ICLR,2018,HyperNetworks with statistical filtering for defending adversarial examples,Anonymous,ICLR.cc/2018/Conference/Paper293/Authors,5;4;5,3;3;4,Withdrawn,0,0,,yes,12/18/17,0,,,,-1,NAN,NAN,n,4
1449,ICLR,2018,withdrawn,withdrawn,withdrawn,4;5;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,0,,,,-1,NAN,NAN,pdf miss,
1450,ICLR,2019,RANDOM MASK: Towards Robust Convolutional Neural Networks,Tiange Luo;Tianle Cai;Mengxiao Zhang;Siyu Chen;Liwei Wang,luotg@pku.edu.cn;caitianle1998@pku.edu.cn;zhan147@usc.edu;siyuchen@pku.edu.cn;wanglw@cis.pku.edu.cn,4;6;7,3;3;3,Reject,10,18,1.0,yes,9/27/18,Peking University;Peking University;University of Southern California;Peking University;Peking University,adversarial examples;robust machine learning;cnn structure;metric;deep feature representations,14;14;27;14;14,27;27;66;27;27,-1;-1,asia,cn,n,4
1451,ICLR,2019,"Unsupervised Discovery of Parts, Structure, and Dynamics",Zhenjia Xu*;Zhijian Liu*;Chen Sun;Kevin Murphy;William T. Freeman;Joshua B. Tenenbaum;Jiajun Wu,xuzhenjia1997@gmail.com;zhijian@mit.edu;chensun@google.com;kpmurphy@google.com;billf@mit.edu;jbt@mit.edu;jiajunwu@mit.edu,6;6;7;5,3;3;4;3,Accept (Poster),0,14,0.0,yes,9/27/18,Columbia University;Massachusetts Institute of Technology;Google;Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Self-Supervised Learning;Visual Prediction;Hierarchical Models,-1;6;-1;-1;6;6;6,-1;5;-1;-1;5;5;5,-1;-1,usa,usa,n,
1452,ICLR,2019,BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning,Maxime Chevalier-Boisvert;Dzmitry Bahdanau;Salem Lahlou;Lucas Willems;Chitwan Saharia;Thien Huu Nguyen;Yoshua Bengio,maximechevalierb@gmail.com;dimabgv@gmail.com;salemlahlou9@gmail.com;lcswillems@gmail.com;chitwaniit@gmail.com;thien@cs.uoregon.edu;yoshua.bengio@umontreal.ca,7;6;6,5;4;4,Accept (Poster),0,10,0.0,yes,9/27/18,University of Montreal;Element AI;;;Google;University of Oregon;University of Montreal,language;learning;efficiency;imitation learning;reinforcement learning,116;-1;-1;-1;-1;207;116,108;-1;-1;-1;-1;267;108,-1;-1,canada,ca,n,
1453,ICLR,2019,Environment Probing Interaction Policies,Wenxuan Zhou;Lerrel Pinto;Abhinav Gupta,wenxuanz@andrew.cmu.edu;lerrelp@andrew.cmu.edu;abhinavg@cs.cmu.edu,6;6;6,3;2;4,Accept (Poster),0,5,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Reinforcement Learning,1;1;1,24;24;24,-1;-1,usa,usa,n,1
1454,ICLR,2019,Classifier-agnostic saliency map extraction,Konrad Zolna;Krzysztof J. Geras;Kyunghyun Cho,konrad.zolna@gmail.com;k.j.geras@nyu.edu;kyunghyun.cho@nyu.edu,4;5;4,3;4;4,Reject,0,5,1.0,yes,9/27/18,Jagiellonian University;New York University;New York University,saliency maps;explainable AI;convolutional neural networks;generative adversarial training;classification,-1;24;24,695;27;27,-1;-1,usa,usa,n,
1455,ICLR,2019,Reinforced Imitation Learning from Observations,Konrad Zolna;Negar Rostamzadeh;Yoshua Bengio;Sungjin Ahn;Pedro O. Pinheiro,konrad.zolna@gmail.com;negar.rostamzadeh@gmail.com;yoshua.umontreal@gmail.com;sjn.ahn@gmail.com;pedro@opinheiro.com,5;6;4,5;2;4,Reject,0,6,0.0,yes,9/27/18,Jagiellonian University;Google;University of Montreal;Rutgers University;Deep Genomics,imitation learning;state-only observations;self-exploration,-1;-1;116;31;-1,695;-1;108;-1;-1,-1;-1,NAN,NAN,n,
1456,ICLR,2019,Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds,Peng Cao*;Yilun Xu*;Yuqing Kong;Yizhou  Wang,caopeng2016@pku.edu.cn;xuyilun@pku.edu.cn;yuqing.kong@pku.edu.cn;yizhou.wang@pku.edu.cn,6;7;6,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,Peking University;Peking University;Peking University;Peking University,crowdsourcing;information theory,14;14;14;14,27;27;27;27,-1;-1,asia,cn,y,
1457,ICLR,2019,Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets,Penghang Yin;Jiancheng Lyu;Shuai Zhang;Stanley Osher;Yingyong Qi;Jack Xin,yph@ucla.edu;jianchel@uci.edu;shuazhan@qti.qualcomm.com;sjo@math.ucla.edu;yingyong@qti.qualcomm.com;jxin@math.uci.edu,6;7;7,3;4;4,Accept (Poster),1,10,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Irvine;Qualcomm Inc, QualComm;University of California, Los Angeles;Qualcomm Inc, QualComm;University of California, Irvine",straight-through estimator;quantized activation;binary neuron,-1;-1;-1;-1;-1;-1,15;99;-1;15;-1;99,-1;-1,usa,usa,y,1
1458,ICLR,2019,Learning Multi-Level Hierarchies with Hindsight,Andrew Levy;George Konidaris;Robert Platt;Kate Saenko,andrew_levy2@brown.edu;gdk@cs.brown.edu;saenko@bu.edu;rplatt@ccs.neu.edu,6;7;5,4;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,Brown University;Brown University;Boston University;Northeastern University,Hierarchical Reinforcement Learning;Reinforcement Learning;Deep Reinforcement Learning,86;86;77;15,50;50;70;839,-1;-1,usa,usa,n,
1459,ICLR,2019,NOODL: Provable Online Dictionary Learning and Sparse Coding,Sirisha Rambhatla;Xingguo Li;Jarvis Haupt,rambh002@umn.edu;lixx1661@umn.edu;jdhaupt@umn.edu,7;6;7,2;2;2,Accept (Poster),0,3,0.0,yes,9/27/18,"University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis",dictionary learning;provable dictionary learning;online dictionary learning;sparse coding;support recovery;iterative hard thresholding;matrix factorization;neural architectures;neural networks;noodl,67;67;67,56;56;56,-1;-1,NAN,NAN,y,
1460,ICLR,2019,Learning to Infer and Execute 3D Shape Programs,Yonglong Tian;Andrew Luo;Xingyuan Sun;Kevin Ellis;William T. Freeman;Joshua B. Tenenbaum;Jiajun Wu,yonglong@mit.edu;aluo@mit.edu;xs5@princeton.edu;ellisk@mit.edu;billf@mit.edu;jbt@mit.edu;jiajunwu@mit.edu,6;7;7,4;5;4,Accept (Poster),3,13,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Princeton University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Program Synthesis;3D Shape Modeling;Self-supervised Learning,6;6;31;6;6;6;6,5;5;7;5;5;5;5,-1;-1,usa,usa,n,
1461,ICLR,2019,Meta-learning with differentiable closed-form solvers,Luca Bertinetto;Joao F. Henriques;Philip Torr;Andrea Vedaldi,luca@robots.ox.ac.uk;joao@robots.ox.ac.uk;philip.torr@eng.ox.ac.uk;vedaldi@robots.ox.ac.uk,5;2;7,3;5;4,Accept (Poster),0,21,3.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford;University of Oxford,few-shot learning;one-shot learning;meta-learning;deep learning;ridge regression;classification,44;44;44;44,1;1;1;1,-1;-1,europe,uk,n,6
1462,ICLR,2019,Adaptive Gradient Methods with Dynamic Bound of Learning Rate,Liangchen Luo;Yuanhao Xiong;Yan Liu;Xu Sun,luolc@pku.edu.cn;xiongyh@zju.edu.cn;yanliu.cs@usc.edu;xusun@pku.edu.cn,7;4;6,4;5;4,Accept (Poster),9,6,1.0,yes,9/27/18,Peking University;Zhejiang University;University of Southern California;Peking University,Optimization;SGD;Adam;Generalization,14;36;27;14,27;177;66;27,-1;-1,asia,cn,y,1
1463,ICLR,2019,AD-VAT: An Asymmetric Dueling mechanism for learning Visual Active Tracking,Fangwei Zhong;Peng Sun;Wenhan Luo;Tingyun Yan;Yizhou Wang,zfw@pku.edu.cn;pengsun000@gmail.com;whluo.china@gmail.com;yanty18@pku.edu.cn;yizhou.wang@pku.edu.cn,5;4;6,4;3;4,Accept (Poster),0,5,0.0,yes,9/27/18,Peking University;Tecent Inc.;;Peking University;Peking University,Active tracking;reinforcement learning;adversarial learning;multi agent,14;-1;-1;14;14,27;-1;-1;27;27,-1;-1,asia,cn,n,1;4
1464,ICLR,2019,Variational Autoencoder with Arbitrary Conditioning,Oleg Ivanov;Michael Figurnov;Dmitry Vetrov,tigvarts@gmail.com;michael@figurnov.ru;vetrovd@yandex.ru,6;7;6,3;3;3,Accept (Poster),0,8,2.0,yes,9/27/18,Samsung;Google;Higher School of Economics,unsupervised learning;generative models;conditional variational autoencoder;variational autoencoder;missing features multiple imputation;inpainting,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
1465,ICLR,2019,Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile,Panayotis Mertikopoulos;Bruno Lecouat;Houssam Zenati;Chuan-Sheng Foo;Vijay Chandrasekhar;Georgios Piliouras,panayotis.mertikopoulos@imag.fr;bruno_lecouat@i2r.a-star.edu.sg;houssam_zenati@i2r.a-star.edu.sg;foocs@i2r.a-star.edu.sg;vijay@i2r.a-star.edu.sg;georgios@sutd.edu.sg,7;6;5,3;5;5,Accept (Poster),0,5,2.0,yes,9/27/18,"French National Center for Scientific Research;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Singapore University of Technology and Design",Mirror descent;extra-gradient;generative adversarial networks;saddle-point problems,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,5;4
1466,ICLR,2019,A2BCD: Asynchronous Acceleration with Optimal Complexity,Robert Hannah;Fei Feng;Wotao Yin,roberthannah89@gmail.com;fei.feng@math.ucla.edu;wotaoyin@math.ucla.edu,7;7;9,4;5;5,Accept (Poster),0,6,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",asynchronous;optimization;parallel;accelerated;complexity,-1;-1;-1,-1;15;15,-1;-1,usa,usa,y,1
1467,ICLR,2019,Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters,Marton Havasi;Robert Peharz;Jos√© Miguel Hern√°ndez-Lobato,mh740@cam.ac.uk;rp587@cam.ac.uk;jmh233@cam.ac.uk,7;6;7,4;2;3,Accept (Poster),2,6,0.0,yes,9/27/18,University of Cambridge;University of Cambridge;University of Cambridge,compression;neural networks;bits-back argument;Bayesian;Shannon;information theory,77;77;77,2;2;2,-1;-1,europe,uk,y,1
1468,ICLR,2019,Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic,Mikael Henaff;Alfredo Canziani;Yann LeCun,mbh305@nyu.edu;canziani@nyu.edu;yann@cs.nyu.edu,6;7;6,4;5;5,Accept (Poster),0,6,0.0,yes,9/27/18,New York University;New York University;New York University,model-based reinforcement learning;stochastic video prediction;autonomous driving,24;24;24,27;27;27,-1;-1,usa,usa,n,
1469,ICLR,2019,Feature-Wise Bias Amplification,Klas Leino;Emily Black;Matt Fredrikson;Shayak Sen;Anupam Datta,kleino@cs.cmu.edu;emilybla@cs.cmu.edu;mfredrik@cs.cmu.edu;shayaks@cs.cmu.edu;danupam@cmu.edu,6;6;7,5;4;4,Accept (Poster),0,13,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,bias;bias amplification;classification,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,y,
1470,ICLR,2019,RelGAN: Relational Generative Adversarial Networks for Text Generation,Weili Nie;Nina Narodytska;Ankit Patel,wn8@rice.edu;nnarodytska@vmware.com;abp4@rice.edu,6;8;6,4;4;4,Accept (Poster),0,0,6.0,yes,9/27/18,Rice University;VMware Research;Rice University,RelGAN;text generation;relational memory;Gumbel-Softmax relaxation;multiple embedded representations,94;-1;94,86;-1;86,-1;-1,australasia,au,n,5;4
1471,ICLR,2019,Neural Speed Reading with Structural-Jump-LSTM,Christian Hansen;Casper Hansen;Stephen Alstrup;Jakob Grue Simonsen;Christina Lioma,chrh@di.ku.dk;c.hansen@di.ku.dk;s.alstrup@di.ku.dk;simonsen@di.ku.dk;c.lioma@di.ku.dk,7;7;5,5;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen,natural language processing;speed reading;recurrent neural network;classification,86;86;86;86;86,109;109;109;109;109,-1;-1,europe,dk,n,3
1472,ICLR,2019,Time-Agnostic Prediction: Predicting Predictable Video Frames,Dinesh Jayaraman;Frederik Ebert;Alexei Efros;Sergey Levine,dineshjayaraman@berkeley.edu;febert@berkeley.edu;efros@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,8;7;7,4;3;5,Accept (Poster),0,7,1.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,visual prediction;subgoal generation;bottleneck states;time-agnostic,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,
1473,ICLR,2019,Generative Question Answering: Learning to Answer the Whole Question,Mike Lewis;Angela Fan,mikelewis@fb.com;angelafan@fb.com,7;8;6,4;4;4,Accept (Poster),1,6,0.0,yes,9/27/18,Facebook;Facebook,Question answering;question generation;reasoning;squad;clevr,-1;-1,-1;-1,-1;-1,NAN,NAN,n,5;4
1474,ICLR,2019,Episodic Curiosity through Reachability,Nikolay Savinov;Anton Raichuk;Damien Vincent;Raphael Marinier;Marc Pollefeys;Timothy Lillicrap;Sylvain Gelly,nikolay.savinov@inf.ethz.ch;raveman@google.com;damienv@google.com;raphaelm@google.com;marc.pollefeys@inf.ethz.ch;countzero@google.com;sylvaingelly@google.com,8;7;8;6,4;4;3;4,Accept (Poster),2,17,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Google;Google;Google;Swiss Federal Institute of Technology;Google;Google,deep learning;reinforcement learning;curiosity;exploration;episodic memory,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1475,ICLR,2019,Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks,Yikang Shen;Shawn Tan;Alessandro Sordoni;Aaron Courville,yikang.shn@gmail.com;shawn@wtf.sg;alsordon@microsoft.com;aaron.courville@gmail.com,7;9;8,3;4;4,Accept (Oral),0,6,0.0,yes,9/27/18,University of Montreal;;Microsoft;University of Montreal,Deep Learning;Natural Language Processing;Recurrent Neural Networks;Language Modeling,116;-1;-1;116,108;-1;-1;108,-1;-1,canada,ca,n,3
1476,ICLR,2019,Automatically Composing Representation Transformations as a Means for Generalization,Michael Chang;Abhishek Gupta;Sergey Levine;Thomas L. Griffiths,mbchang@berkeley.edu;abhigupta@berkeley.edu;svlevine@eecs.berkeley.edu;tom_griffiths@berkeley.edu,7;9;7,2;4;3,Accept (Poster),1,8,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,compositionality;deep learning;metareasoning,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,1;10
1477,ICLR,2019,Bayesian Policy Optimization for Model Uncertainty,Gilwoo Lee;Brian Hou;Aditya Mandalika;Jeongseok Lee;Sanjiban Choudhury;Siddhartha S. Srinivasa,gilwoo@cs.uw.edu;bhou@cs.uw.edu;adityavk@cs.uw.edu;jslee02@cs.uw.edu;sanjibac@cs.uw.edu;siddh@cs.uw.edu,5;7;6;7,4;4;3;3,Accept (Poster),0,9,1.0,yes,9/27/18,"University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle",Bayes-Adaptive Markov Decision Process;Model Uncertainty;Bayes Policy Optimization,10;10;10;10;10;10,25;25;25;25;25;25,-1;-1,NAN,NAN,n,11
1478,ICLR,2019,Diversity-Sensitive Conditional Generative Adversarial Networks,Dingdong Yang;Seunghoon Hong;Yunseok Jang;Tianchen Zhao;Honglak Lee,didoyang@umich.edu;hongseu@umich.edu;yunseokj@umich.edu;ericolon@umich.edu;honglak@eecs.umich.edu,6;7;7,5;3;5,Accept (Poster),1,5,0.0,yes,9/27/18,University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan,Conditional Generative Adversarial Network;mode-collapse;multi-modal generation;image-to-image translation;image in-painting;video prediction,9;9;9;9;9,21;21;21;21;21,-1;-1,usa,usa,n,5;4
1479,ICLR,2019,Poincare Glove: Hyperbolic Word Embeddings,Alexandru Tifrea*;Gary Becigneul*;Octavian-Eugen Ganea*,tifreaa@student.ethz.ch;gary.becigneul@inf.ethz.ch;octavian.ganea@inf.ethz.ch,6;7;6,4;3;4,Accept (Poster),0,5,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,word embeddings;hyperbolic spaces;poincare ball;hypernymy;analogy;similarity;gaussian embeddings,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;1;10
1480,ICLR,2019,Stochastic Optimization of Sorting Networks via Continuous Relaxations,Aditya Grover;Eric Wang;Aaron Zweig;Stefano Ermon,adityag@cs.stanford.edu;ejwang@cs.stanford.edu;azweig@cs.stanford.edu;ermon@cs.stanford.edu,7;8;6,3;4;3,Accept (Poster),0,5,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University,continuous relaxations;sorting;permutation;stochastic computation graphs;Plackett-Luce,4;4;4;4,3;3;3;3,-1;-1,usa,usa,y,10
1481,ICLR,2019,Hyperbolic Attention Networks,Caglar Gulcehre;Misha Denil;Mateusz Malinowski;Ali Razavi;Razvan Pascanu;Karl Moritz Hermann;Peter Battaglia;Victor Bapst;David Raposo;Adam Santoro;Nando de Freitas,ca9lar@gmail.com;mdenil@google.com;mateuszm@google.com;alirazavi@google.com;razp@google.com;kmh@google.com;vbapst@google.com;drapso@google.com;adamsantoro@google.com;nandodefreitas@google.com,6;7;7,5;5;4,Accept (Poster),2,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Hyperbolic Geometry;Attention Methods;Reasoning on Graphs;Relation Learning;Scale Free Graphs;Transformers;Power Law,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;8;1;10
1482,ICLR,2019,Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network,Xuanqing Liu;Yao Li;Chongruo Wu;Cho-Jui Hsieh,xqliu@cs.ucla.edu;yaoli@ucdavis.edu;crwu@ucdavis.edu;chohsieh@cs.ucla.edu,7;6;7,3;4;3,Accept (Poster),0,13,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Davis;University of California, Davis;University of California, Los Angeles",,-1;-1;-1;-1,15;54;54;15,-1;-1,usa,usa,n,11;4
1483,ICLR,2019,How Important is a Neuron,Kedar Dhamdhere;Mukund Sundararajan;Qiqi Yan,kedar@google.com;mukunds@google.com;qiqiyan@google.com,7;7;7,4;2;5,Accept (Poster),2,7,0.0,yes,9/27/18,Google;Google;Google,attribution;saliency;influence,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
1484,ICLR,2019,Small nonlinearities in activation functions create bad local minima in neural networks,Chulhee Yun;Suvrit Sra;Ali Jadbabaie,chulheey@mit.edu;suvrit@mit.edu;jadbabai@mit.edu,7;7;8,3;3;4,Accept (Poster),0,5,1.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,spurious local minima;loss surface;optimization landscape;neural network,6;6;6,5;5;5,-1;-1,usa,usa,y,1
1485,ICLR,2019,Efficiently testing local optimality and escaping saddles for ReLU networks,Chulhee Yun;Suvrit Sra;Ali Jadbabaie,chulheey@mit.edu;suvrit@mit.edu;jadbabai@mit.edu,3;6;6;8,4;2;3;3,Accept (Poster),0,10,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,local optimality;second-order stationary point;escaping saddle points;nondifferentiability;ReLU;empirical risk,6;6;6,5;5;5,-1;-1,usa,usa,y,1;9
1486,ICLR,2019,Local SGD Converges Fast and Communicates Little,Sebastian U. Stich,sebastian.stich@epfl.ch,8;5;8,5;5;4,Accept (Poster),0,7,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne,optimization;communication;theory;stochastic gradient descent;SGD;mini-batch;local SGD;parallel restart SGD;distributed training,-1,-1,-1,NAN,NAN,y,1;9
1487,ICLR,2019,Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference,Matthew Riemer;Ignacio Cases;Robert Ajemian;Miao Liu;Irina Rish;Yuhai Tu;and Gerald Tesauro,mdriemer@us.ibm.com;cases@stanford.edu;ajemian@mit.edu;miao.liu1@ibm.com;rish@us.ibm.com;yuhai@us.ibm.com;gtesauro@us.ibm.com,6;8;7,5;4;5,Accept (Poster),2,6,0.0,yes,9/27/18,International Business Machines;Stanford University;Massachusetts Institute of Technology;International Business Machines;International Business Machines;International Business Machines;International Business Machines,,-1;4;6;-1;-1;-1;-1,-1;3;5;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
1488,ICLR,2019,Excessive Invariance Causes Adversarial Vulnerability,Joern-Henrik Jacobsen;Jens Behrmann;Richard Zemel;Matthias Bethge,j.jacobsen@vectorinstitute.ai;jensb@uni-bremen.de;zemel@cs.toronto.edu;matthias.bethge@uni-tuebingen.de,6;6;7,4;2;4,Accept (Poster),0,8,6.0,yes,9/27/18,Vector Institute;Universit√§t Bremen;University of Toronto;University of Tuebingen,Generalization;Adversarial Examples;Invariance;Information Theory;Invertible Networks,-1;-1;18;136,-1;-1;22;94,-1;-1,europe,de,y,4
1489,ICLR,2019,Decoupled Weight Decay Regularization,Ilya Loshchilov;Frank Hutter,ilya.loshchilov@gmail.com;fh@cs.uni-freiburg.de,6;7;5,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,University of Freiburg;University of Freiburg,optimization;regularization;weight decay;Adam,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1
1490,ICLR,2019,Learning Robust Representations by Projecting Superficial Statistics Out,Haohan Wang;Zexue He;Zachary C. Lipton;Eric P. Xing,haohanw@cs.cmu.edu;zexueh@mail.bnu.edu.cn;zlipton@cmu.edu;epxing@cs.cmu.edu,7;7;9,4;4;3,Accept (Oral),0,4,0.0,yes,9/27/18,Carnegie Mellon University;Australian National University;Carnegie Mellon University;Carnegie Mellon University,domain generalization;robustness,1;116;1;1,24;48;24;24,-1;-1,usa,usa,n,1
1491,ICLR,2019,Spectral Inference Networks: Unifying Deep and Spectral Learning,David Pfau;Stig Petersen;Ashish Agarwal;David G. T. Barrett;Kimberly L. Stachenfeld,pfau@google.com;svp@google.com;agarwal@google.com;barrettdavid@google.com;stachenfeld@google.com,5;7;5,3;3;3,Accept (Poster),0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google,spectral learning;unsupervised learning;manifold learning;dimensionality reduction,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,10;5
1492,ICLR,2019,A rotation-equivariant convolutional neural network model of primary visual cortex,Alexander S. Ecker;Fabian H. Sinz;Emmanouil Froudarakis;Paul G. Fahey;Santiago A. Cadena;Edgar Y. Walker;Erick Cobos;Jacob Reimer;Andreas S. Tolias;Matthias Bethge,alexander.ecker@uni-tuebingen.de;sinz@bcm.edu;froudara@bcm.edu;paul.fahey@bcm.edu;sa.cadena721@gmail.com;eywalker@bcm.edu;emcobost@gmail.com;reimer@bcm.edu;astolias@bcm.edu;matthias.bethge@bethgelab.org,5;7;8,4;4;3,Accept (Poster),0,21,1.0,yes,9/27/18,"University of Tuebingen;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;;Baylor College of Medicine;Max-Planck Institute;Baylor College of Medicine;Baylor College of Medicine;Centre for Integrative Neuroscience, AG Bethge",rotation equivariance;equivariance;primary visual cortex;V1;neuroscience;system identification,136;-1;-1;-1;-1;-1;-1;-1;-1;-1,94;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1493,ICLR,2019,Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity,Thomas Miconi;Aditya Rawal;Jeff Clune;Kenneth O. Stanley,tmiconi@uber.com;aditya.rawal@uber.com;jeffclune@uber.com;kstanley@uber.com,5;4;9,4;4;4,Accept (Poster),0,9,0.0,yes,9/27/18,Uber;Uber;Uber;Uber,meta-learning;reinforcement learning;plasticity;neuromodulation;Hebbian learning;recurrent neural networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,southamerica,br,n,3
1494,ICLR,2019,Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset,Curtis Hawthorne;Andriy Stasyuk;Adam Roberts;Ian Simon;Cheng-Zhi Anna Huang;Sander Dieleman;Erich Elsen;Jesse Engel;Douglas Eck,fjord@google.com;astas@google.com;adarob@google.com;iansimon@google.com;annahuang@google.com;sedielem@google.com;eriche@google.com;jesseengel@google.com;deck@google.com,8;8;8,5;2;4,Accept (Oral),0,4,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google,music;piano transcription;transformer;wavnet;audio synthesis;dataset;midi,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1495,ICLR,2019,Invariant and Equivariant Graph Networks,Haggai Maron;Heli Ben-Hamu;Nadav Shamir;Yaron Lipman,haggai.maron@weizmann.ac.il;heli.benhamu@weizmann.ac.il;nadav13@gmail.com;yaron.lipman@weizmann.ac.il,8;4;9,5;5;4,Accept (Poster),0,8,0.0,yes,9/27/18,Weizmann Institute;Weizmann Institute;;Weizmann Institute,graph learning;equivariance;deep learning,116;116;-1;116,-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;10
1496,ICLR,2019,Solving the Rubik's Cube with Approximate Policy Iteration,Stephen McAleer;Forest Agostinelli;Alexander Shmakov;Pierre Baldi,smcaleer@uci.edu;fagostin@uci.edu;ashmakov@uci.edu;pfbaldi@ics.uci.edu,7;7;7,4;4;3,Accept (Poster),0,3,1.0,yes,9/27/18,"University of California, Irvine;University of California, Irvine;University of California, Irvine;University of California, Irvine",reinforcement learning;Rubik's Cube;approximate policy iteration;deep learning;deep reinforcement learning,-1;-1;-1;-1,99;99;99;99,-1;-1,usa,usa,n,
1497,ICLR,2019,Execution-Guided Neural Program Synthesis,Xinyun Chen;Chang Liu;Dawn Song,xinyun.chen@berkeley.edu;liuchang@eecs.berkeley.edu;dawnsong.travel@gmail.com,7;7;7,4;2;5,Accept (Poster),0,12,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,
1498,ICLR,2019,Transferring Knowledge across Learning Processes,Sebastian Flennerhag;Pablo G. Moreno;Neil D. Lawrence;Andreas Damianou,sflennerhag@turing.ac.uk;morepabl@amazon.com;lawrennd@amazon.com;damianou@amazon.com,8;8;6,3;4;4,Accept (Oral),0,13,0.0,yes,9/27/18,Alan Turing Institute;Amazon;Amazon;Amazon,meta-learning;transfer learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;2
1499,ICLR,2019,Theoretical Analysis of Auto Rate-Tuning by Batch Normalization,Sanjeev Arora;Zhiyuan Li;Kaifeng Lyu,arora@cs.princeton.edu;zhiyuanli@cs.princeton.edu;vfleaking@gmail.com,7;7;7,4;2;2,Accept (Poster),0,7,0.0,yes,9/27/18,Princeton University;Princeton University;Princeton University,batch normalization;scale invariance;learning rate;stationary point,31;31;31,7;7;7,-1;-1,usa,usa,y,1;9
1500,ICLR,2019,Neural Logic Machines,Honghua Dong;Jiayuan Mao;Tian Lin;Chong Wang;Lihong Li;Denny Zhou,dhh19951@gmail.com;maojiayuan@gmail.com;tianlin@google.com;chongw@google.com;lihongli.cs@gmail.com;dennyzhou@gmail.com,6;7;5,3;2;5,Accept (Poster),0,0,9.0,yes,9/27/18,University of Toronto;Massachusetts Institute of Technology;Google;Google;Amazon;Google,Neuro-Symbolic Computation;Logic Induction,18;6;-1;-1;-1;-1,22;5;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;10
1501,ICLR,2019,"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision",Jiayuan Mao;Chuang Gan;Pushmeet Kohli;Joshua B. Tenenbaum;Jiajun Wu,maojiayuan@gmail.com;ganchuang1990@gmail.com;pushmeet@google.com;jbt@mit.edu;jiajunwu@mit.edu,6;7;9,4;4;5,Accept (Oral),0,9,1.0,yes,9/27/18,Massachusetts Institute of Technology;;Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neuro-Symbolic Representations;Concept Learning;Visual Reasoning,6;-1;-1;6;6,5;-1;-1;5;5,-1;-1,usa,usa,n,1
1502,ICLR,2019,Disjoint Mapping Network for Cross-modal Matching of Voices and Faces,Yandong Wen;Mahmoud Al Ismail;Weiyang Liu;Bhiksha Raj;Rita Singh,yandongw@andrew.cmu.edu;mahmoudi@andrew.cmu.edu;wyliu@gatech.edu;bhiksha@cs.cmu.edu;rsingh@cs.cmu.edu,7;6;7,4;3;4,Accept (Poster),0,3,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Georgia Institute of Technology;Carnegie Mellon University;Carnegie Mellon University,cross-modal matching;voices;faces,1;1;13;1;1,24;24;33;24;24,-1;-1,usa,usa,n,
1503,ICLR,2019,Learning Neural PDE Solvers with Convergence Guarantees,Jun-Ting Hsieh;Shengjia Zhao;Stephan Eismann;Lucia Mirabella;Stefano Ermon,junting@stanford.edu;sjzhao@stanford.edu;seismann@stanford.edu;lucia.mirabella@siemens.com;ermon@cs.stanford.edu,7;8;6,4;4;3,Accept (Poster),2,3,2.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Siemens Corporate Research;Stanford University,Partial differential equation;deep learning,4;4;4;-1;4,3;3;3;-1;3,-1;-1,usa,usa,y,
1504,ICLR,2019,Dimensionality Reduction for Representing the Knowledge of Probabilistic Models,Marc T Law;Jake Snell;Amir-massoud Farahmand;Raquel Urtasun;Richard S Zemel,law@cs.toronto.edu;jsnell@cs.toronto.edu;farahmand@vectorinstitute.ai;urtasun@cs.toronto.edu;zemel@cs.toronto.edu,7;6;9,4;1;3,Accept (Poster),0,4,0.0,yes,9/27/18,University of Toronto;University of Toronto;Vector Institute;University of Toronto;University of Toronto,metric learning;distance learning;dimensionality reduction;bound guarantees,18;18;-1;18;18,22;22;-1;22;22,-1;-1,canada,ca,y,6;1
1505,ICLR,2019,Improving the Generalization of Adversarial Training with Domain Adaptation,Chuanbiao Song;Kun He;Liwei Wang;John E. Hopcroft,cbsong@hust.edu.cn;brooklet60@hust.edu.cn;wanglw@pku.edu.cn;jeh@cs.cornell.edu,6;6;6,2;3;4,Accept (Poster),0,7,0.0,yes,9/27/18,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Peking University;Cornell University,adversarial training;domain adaptation;adversarial example;deep learning,-1;-1;14;6,44;44;27;19,-1;-1,usa,usa,n,1;4
1506,ICLR,2019,Towards Understanding Regularization in Batch Normalization,Ping Luo;Xinjiang Wang;Wenqi Shao;Zhanglin Peng,pluo@ie.cuhk.edu.hk;wangxinjiang@sensetime.com;shaowenqi@sensetime.com;zhanglinpeng@sensetime.com,5;6;6,3;5;2,Accept (Poster),0,4,0.0,yes,9/27/18,The Chinese University of Hong Kong;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited,batch normalization;regularization;deep learning,285;-1;-1;-1,40;-1;-1;-1,-1;-1,NAN,NAN,y,1
1507,ICLR,2019,Differentiable Learning-to-Normalize via Switchable Normalization,Ping Luo;Jiamin Ren;Zhanglin Peng;Ruimao Zhang;Jingyu Li,pluo@ie.cuhk.edu.hk;renjiamin@sensetime.com;pengzhanglin@sensetime.com;zhangruimao@sensetime.com;lijingyu@sensetime.com,7;7;7,5;3;4,Accept (Poster),0,2,1.0,yes,9/27/18,The Chinese University of Hong Kong;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited,normalization;deep learning;CNN;computer vision,285;-1;-1;-1;-1,40;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1508,ICLR,2019,Neural Graph Evolution: Towards Efficient Automatic Robot Design,Tingwu Wang;Yuhao Zhou;Sanja Fidler;Jimmy Ba,tingwuwang@cs.toronto.edu;henryzhou@cs.toronto.edu;fidler@cs.toronto.edu;jba@cs.toronto.edu,5;8;6,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto;University of Toronto,Reinforcement learning;graph neural networks;robotics;deep learning;transfer learning,18;18;18;18,22;22;22;22,-1;-1,canada,ca,n,10
1509,ICLR,2019,Systematic Generalization: What Is Required and Can It Be Learned?,Dzmitry Bahdanau*;Shikhar Murty*;Michael Noukhovitch;Thien Huu Nguyen;Harm de Vries;Aaron Courville,dimabgv@gmail.com;shikhar.murty@gmail.com;michael.noukhovitch@umontreal.ca;thien@cs.uoregon.edu;mail@harmdevries.com;aaron.courville@gmail.com,6;6;4,3;5;4,Accept (Poster),0,9,0.0,yes,9/27/18,Element AI;Stanford University;University of Montreal;University of Oregon;Harmdevries;University of Montreal,systematic generalization;language understanding;visual questions answering;neural module networks,-1;4;116;207;-1;116,-1;3;108;267;-1;108,-1;-1,canada,ca,n,1
1510,ICLR,2019,Preferences Implicit in the State of the World,Rohin Shah;Dmitrii Krasheninnikov;Jordan Alexander;Pieter Abbeel;Anca Dragan,rohinmshah@berkeley.edu;dmitrii.krasheninnikov@student.uva.nl;jfalex@stanford.edu;pabbeel@cs.berkeley.edu;anca@berkeley.edu,6;6;7;7,3;4;3;4,Accept (Poster),0,7,0.0,yes,9/27/18,University of California Berkeley;University of Amsterdam;Stanford University;University of California Berkeley;University of California Berkeley,Preference learning;Inverse reinforcement learning;Inverse optimal stochastic control;Maximum entropy reinforcement learning;Apprenticeship learning,-1;136;4;-1;-1,18;59;3;18;18,-1;-1,usa,usa,n,1
1511,ICLR,2019,"Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids",Yunzhu Li;Jiajun Wu;Russ Tedrake;Joshua B. Tenenbaum;Antonio Torralba,liyunzhu@mit.edu;jiajunwu@mit.edu;russt@mit.edu;jbt@mit.edu;torralba@mit.edu,6;8;7,4;3;3,Accept (Poster),0,10,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Dynamics modeling;Control;Particle-Based Representation,6;6;6;6;6,5;5;5;5;5,-1;-1,usa,usa,n,10
1512,ICLR,2019,On the Relation Between the Sharpest Directions of DNN Loss and the SGD Step Length,Stanis≈Çaw Jastrzƒôbski;Zachary Kenton;Nicolas Ballas;Asja Fischer;Yoshua Bengio;Amos Storkey,staszek.jastrzebski@gmail.com;zakenton@gmail.com;ballasn@fb.com;asja.fischer@gmail.com;yoshua.umontreal@gmail.com;a.storkey@ed.ac.uk,7;6;6,3;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Jagiellonian University;Google;Facebook;Institute for Cognitive Neuroscience/ Inst. for Neuroinformatics;University of Montreal;University of Edinburgh,optimization;generalization;theory of deep learning;SGD;hessian,-1;-1;-1;-1;116;36,695;-1;-1;-1;108;27,-1;-1,europe,uk,n,1
1513,ICLR,2019,A Variational Inequality Perspective on Generative Adversarial Networks,Gauthier Gidel;Hugo Berard;Ga√´tan Vignoud;Pascal Vincent;Simon Lacoste-Julien,gauthier.gidel@umontreal.ca;hugo.berard@gmail.com;gaetan.vignoud@gmail.com;vincentp@iro.umontreal.ca;slacoste@iro.umontreal.ca,8;8;7,3;3;4,Accept (Poster),0,5,1.0,yes,9/27/18,University of Montreal;;INRIA;University of Montreal;University of Montreal,optimization;variational inequality;games;saddle point;extrapolation;averaging;extragradient;generative modeling;generative adversarial network,116;-1;-1;116;116,108;-1;-1;108;108,-1;-1,canada,ca,y,5;4
1514,ICLR,2019,Learning-Based Frequency Estimation Algorithms,Chen-Yu Hsu;Piotr Indyk;Dina Katabi;Ali Vakilian,cyhsu@mit.edu;indyk@mit.edu;dina@csail.mit.edu;vakilian@mit.edu,6;7;6,1;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,streaming algorithms;heavy-hitters;Count-Min;Count-Sketch,6;6;6;6,5;5;5;5,-1;-1,usa,usa,y,1
1515,ICLR,2019,Learning to Design RNA,Frederic Runge;Danny Stoll;Stefan Falkner;Frank Hutter,runget@cs.uni-freiburg.de;d.stoll@tutanota.com;sfalkner@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,8;6;6,4;4;1,Accept (Poster),0,16,0.0,yes,9/27/18,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,matter engineering;bioinformatics;rna design;reinforcement learning;meta learning;neural architecture search;hyperparameter optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
1516,ICLR,2019,L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data,Jianbo Chen;Le Song;Martin J. Wainwright;Michael I. Jordan,jianbochen@berkeley.edu;lsong@cc.gatech.edu;wainwrig@berkeley.edu;jordan@cs.berkeley.edu,6;7;7,4;3;2,Accept (Poster),2,5,0.0,yes,9/27/18,University of California Berkeley;Georgia Institute of Technology;University of California Berkeley;University of California Berkeley,Model Interpretation;Feature Selection,-1;13;-1;-1,18;33;18;18,-1;-1,usa,usa,y,1;10
1517,ICLR,2019,Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization,Navid Azizan;Babak Hassibi,azizan@caltech.edu;hassibi@caltech.edu,5;7;5,3;4;3,Accept (Poster),0,5,0.0,yes,9/27/18,California Institute of Technology;California Institute of Technology,optimization;stochastic gradient descent;mirror descent;implicit regularization;deep learning theory,136;136,3;3,-1;-1,usa,usa,y,
1518,ICLR,2019,Boosting Robustness Certification of Neural Networks,Gagandeep Singh;Timon Gehr;Markus P√ºschel;Martin Vechev,gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;pueschel@inf.ethz.ch;martin.vechev@inf.ethz.ch,4;5;6,3;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Robustness certification;Adversarial Attacks;Abstract Interpretation;MILP Solvers;Verification of Neural Networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;4
1519,ICLR,2019,Two-Timescale Networks for Nonlinear Value Function Approximation,Wesley Chung;Somjit Nath;Ajin Joseph;Martha White,wchung@ualberta.ca;somjit@ualberta.ca;ajoseph@ualberta.ca;whitem@ualberta.ca,6;7;6;6,4;4;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,University of Alberta;University of Alberta;University of Alberta;University of Alberta,Reinforcement learning;policy evaluation;nonlinear function approximation,94;94;94;94,119;119;119;119,-1;-1,canada,ca,y,1
1520,ICLR,2019,Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning,Michael Lutter;Christian Ritter;Jan Peters,michael@robot-learning.de;ritter@stud.tu-darmstadt.de;peters@ias.tu-darmstadt.de,7;4;7,4;5;3,Accept (Poster),0,9,0.0,yes,9/27/18,TU Darmstadt;TU Darmstadt;TU Darmstadt,Deep Model Learning;Robot Control,-1;59;59,-1;-1;-1,-1;-1,europe,de,n,1
1521,ICLR,2019,Improving MMD-GAN Training with Repulsive Loss Function,Wei Wang;Yuan Sun;Saman Halgamuge,weiw8@student.unimelb.edu.au;yuan.sun@rmit.edu.au;saman@unimelb.edu.au,7;7;6,5;5;2,Accept (Poster),2,5,0.0,yes,9/27/18,The University of Melbourne;Massachusetts Institute of Technology;The University of Melbourne,generative adversarial nets;loss function;maximum mean discrepancy;image generation;unsupervised learning,77;6;77,32;5;32,-1;-1,NAN,NAN,y,5;4
1522,ICLR,2019,Deep Anomaly Detection with Outlier Exposure,Dan Hendrycks;Mantas Mazeika;Thomas Dietterich,hendrycks@berkeley.edu;mantas@ttic.edu;tgd@oregonstate.edu,6;6;8,4;5;4,Accept (Poster),3,9,1.0,yes,9/27/18,University of California Berkeley;Toyota Technological Institute at Chicago;Oregon State University,confidence;uncertainty;anomaly;robustness,-1;-1;77,18;-1;318,-1;-1,usa,usa,n,3;5
1523,ICLR,2019,Temporal Difference Variational Auto-Encoder,Karol Gregor;George Papamakarios;Frederic Besse;Lars Buesing;Theophane Weber,karol.gregor@gmail.com;g.papamakarios@ed.ac.uk;fbesse@google.com;lbuesing@google.com;theophane@google.com,8;9;7,4;4;5,Accept (Oral),0,3,1.0,yes,9/27/18,Google;University of Edinburgh;Google;Google;Google,generative models;variational auto-encoders;state space models;temporal difference learning,-1;36;-1;-1;-1,-1;27;-1;-1;-1,-1;-1,NAN,NAN,n,5
1524,ICLR,2019,Meta-Learning with Latent Embedding Optimization,Andrei A. Rusu;Dushyant Rao;Jakub Sygnowski;Oriol Vinyals;Razvan Pascanu;Simon Osindero;Raia Hadsell,andreirusu@google.com;dushyantr@google.com;sygi@google.com;vinyals@google.com;razp@google.com;osindero@google.com;raia@google.com,6;5;8,5;3;5,Accept (Poster),2,11,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google,meta-learning;few-shot;miniImageNet;tieredImageNet;hypernetworks;generative;latent embedding;optimization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;5
1525,ICLR,2019,Active Learning with Partial Feedback,Peiyun Hu;Zachary C. Lipton;Anima Anandkumar;Deva Ramanan,peiyunh@cs.cmu.edu;zlipton@cmu.edu;anima@caltech.edu;deva@cs.cmu.edu,7;6;7,4;3;4,Accept (Poster),0,4,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;California Institute of Technology;Carnegie Mellon University,Active Learning;Learning from Partial Feedback,1;1;136;1,24;24;3;24,-1;-1,usa,usa,n,
1526,ICLR,2019,A Universal Music Translation Network,Noam Mor;Lior Wolf;Adam Polyak;Yaniv Taigman,noam.mor@gmail.com;wolf@fb.com;adampolyak@fb.com;yaniv@fb.com,7;6;8,4;4;4,Accept (Poster),2,6,1.0,yes,9/27/18,Tel Aviv University;Facebook;Facebook;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1527,ICLR,2019,Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach,Minhao Cheng;Thong Le;Pin-Yu Chen;Huan Zhang;JinFeng Yi;Cho-Jui Hsieh,mhcheng@ucla.edu;thmle@ucdavis.edu;pin-yu.chen@ibm.com;huan@huan-zhang.com;yijinfeng@jd.com;chohsieh@cs.ucla.edu,7;6;7,3;5;4,Accept (Poster),0,3,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Davis;International Business Machines;Carnegie Mellon University;JD AI Research;University of California, Los Angeles",Adversarial example;Hard-label;Black-box attack;Query-efficient,-1;-1;-1;1;-1;-1,15;54;-1;24;-1;15,-1;-1,usa,usa,y,1;9;4
1528,ICLR,2019,Multi-step Retriever-Reader Interaction for Scalable Open-domain Question Answering,Rajarshi Das;Shehzaad Dhuliawala;Manzil Zaheer;Andrew McCallum,rajarshi@cs.umass.edu;sdhuliawala@cs.umass.edu;manzil@cmu.edu;mccallum@cs.umass.edu,7;6;6,4;5;4,Accept (Poster),0,11,6.0,yes,9/27/18,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;Carnegie Mellon University;University of Massachusetts, Amherst",Open domain Question Answering;Reinforcement Learning;Query reformulation,27;27;1;27,191;191;24;191,-1;-1,usa,usa,n,
1529,ICLR,2019,Analysing Mathematical Reasoning Abilities of Neural Models,David Saxton;Edward Grefenstette;Felix Hill;Pushmeet Kohli,saxton@google.com;etg@google.com;felixhill@google.com;pushmeet@google.com,7;6;6,3;3;4,Accept (Poster),0,0,4.0,yes,9/27/18,Google;Google;Google;Google,mathematics;dataset;algebraic;reasoning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1530,ICLR,2019,Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers,Yonatan Geifman;Guy Uziel;Ran El-Yaniv,yonatan.g@cs.technion.ac.il;uzielguy@gmail.com;rani@cs.technion.ac.il,7;7;7,3;4;2,Accept (Poster),0,9,2.0,yes,9/27/18,"Technion, Technion;;Technion, Technion",Uncertainty estimation;Deep learning,27;-1;27,-1;-1;-1,-1;-1,NAN,NAN,n,11
1531,ICLR,2019,The Deep Weight Prior,Andrei Atanov;Arsenii Ashukha;Kirill Struminsky;Dmitriy Vetrov;Max Welling,andrewatanov@yandex.ru;ars.ashuha@gmail.com;k.struminsky@gmail.com;vetrovd@yandex.ru;m.welling@uva.nl,6;8;7,4;4;3,Accept (Poster),0,8,0.0,yes,9/27/18,Yandex;Samsung;;Higher School of Economics;University of Amsterdam,deep learning;variational inference;prior distributions,-1;-1;-1;-1;136,-1;-1;-1;-1;59,-1;-1,europe,nl,n,11;5
1532,ICLR,2019,Complement Objective Training,Hao-Yun Chen;Pei-Hsin Wang;Chun-Hao Liu;Shih-Chieh Chang;Jia-Yu Pan;Yu-Ting Chen;Wei Wei;Da-Cheng Juan,haoyunchen@gapp.nthu.edu.tw;peihsin@gapp.nthu.edu.tw;newgod1992@gapp.nthu.edu.tw;scchang@cs.nthu.edu.tw;jypan@google.com;yutingchen@google.com;wewei@google.com;dacheng@google.com,8;5;7,4;4;4,Accept (Poster),0,19,0.0,yes,9/27/18,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Google;Google;Google;Google,optimization;entropy;image recognition;natural language understanding;adversarial attacks;deep learning,207;207;207;207;-1;-1;-1;-1,323;323;323;323;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;3;4
1533,ICLR,2019,Eidetic 3D LSTM: A Model for Video Prediction and Beyond,Yunbo Wang;Lu Jiang;Ming-Hsuan Yang;Li-Jia Li;Mingsheng Long;Li Fei-Fei,yunbowang1989@gmail.com;lujiang@google.com;mhyang@ucmerced.edu;lijiali@google.com;mingsheng@tsinghua.edu.cn;feifeili@cs.stanford.edu,7;7;7,5;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,"Shanghai Jiao Tong University;Google;University of California at Merced;Google;Tsinghua University, Tsinghua University;Stanford University",,36;-1;-1;-1;4;4,188;-1;-1;-1;30;3,-1;-1,usa,usa,n,8
1534,ICLR,2019,Diagnosing and Enhancing VAE Models,Bin Dai;David Wipf,v-bindai@microsoft.com;davidwipf@gmail.com,6;7;9,3;4;4,Accept (Poster),0,18,4.0,yes,9/27/18,Microsoft;Amazon,variational autoencoder;generative models,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1;5
1535,ICLR,2019,Posterior Attention Models for Sequence to Sequence Learning,Shiv Shankar;Sunita Sarawagi,sshankar@umass.edu;sunita@iitb.ac.in,9;8;7,4;5;4,Accept (Poster),0,11,0.0,yes,9/27/18,"University of Massachusetts, Amherst;Indian Institute of Technology Bombay",posterior inference;attention;seq2seq learning;translation,27;-1,191;367,-1;-1,NAN,NAN,n,8
1536,ICLR,2019,Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension,Rajarshi Das;Tsendsuren Munkhdalai;Xingdi Yuan;Adam Trischler;Andrew McCallum,rajarshi@cs.umass.edu;tsmunkhd@microsoft.com;eric.yuan@microsoft.com;adam.trischler@microsoft.com;mccallum@cs.umass.edu,7;6;7,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,"University of Massachusetts, Amherst;Microsoft;Microsoft;Microsoft;University of Massachusetts, Amherst",recurrent graph networks;dynamic knowledge base construction;entity state tracking;machine reading comprehension,27;-1;-1;-1;27,191;-1;-1;-1;191,-1;-1,usa,usa,n,10
1537,ICLR,2019,An analytic theory of generalization dynamics and transfer learning in deep linear networks,Andrew K. Lampinen;Surya Ganguli,lampinen@stanford.edu;sganguli@stanford.edu,8;7;6,4;4;3,Accept (Poster),5,3,0.0,yes,9/27/18,Stanford University;Stanford University,Generalization;Theory;Transfer;Multi-task;Linear,4;4,3;3,-1;-1,usa,usa,n,6;8;1
1538,ICLR,2019,Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution,Min Liu;Fupin Yao;Chiho Choi;Ayan Sinha;Karthik Ramani,liu66@purdue.edu;yao153@purdue.edu;chihochoi@purdue.edu;asinha@magicleap.com;ramani@purdue.edu,6;8;7,3;5;5,Accept (Poster),0,10,0.0,yes,9/27/18,Purdue University;Purdue University;Purdue University;Magic Leap;Purdue University,Spherical Convolution;Geometric deep learning;3D shape analysis,24;24;24;-1;24,60;60;60;-1;60,-1;-1,usa,usa,n,
1539,ICLR,2019,Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency,Liqian Ma;Xu Jia;Stamatios Georgoulis;Tinne Tuytelaars;Luc Van Gool,liqian.ma@esat.kuleuven.be;xu.jia@esat.kuleuven.be;georgous@ee.ethz.ch;tinne.tuytelaars@esat.kuleuven.be;luc.vangool@esat.kuleuven.be,6;5;8,4;5;4,Accept (Poster),0,5,0.0,yes,9/27/18,KU Leuven;KU Leuven;Swiss Federal Institute of Technology;KU Leuven;KU Leuven,image-to-image translation;image generation;domain adaptation,136;136;-1;136;136,47;47;-1;47;47,-1;-1,europe,be,n,8
1540,ICLR,2019,Fixup Initialization: Residual Learning Without Normalization,Hongyi Zhang;Yann N. Dauphin;Tengyu Ma,hongyiz@mit.edu;yann@dauphin.io;tengyuma@stanford.edu,5;7;7,4;3;3,Accept (Poster),0,19,3.0,yes,9/27/18,Massachusetts Institute of Technology;Google;Stanford University,deep learning;residual networks;initialization;batch normalization;layer normalization,6;-1;4,5;-1;3,-1;-1,usa,usa,y,3;1
1541,ICLR,2019,Capsule Graph Neural Network,Zhang Xinyi;Lihui Chen,xinyi001@e.ntu.edu.sg;elhchen@ntu.edu.sg,6;6;6,4;4;4,Accept (Poster),0,3,3.0,yes,9/27/18,Nanyang Technological University;Nanyang Technological University,CapsNet;Graph embedding;GNN,44;44,52;52,-1;-1,asia,sg,n,8;10
1542,ICLR,2019,Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions,Matthew Mackay;Paul Vicol;Jonathan Lorraine;David Duvenaud;Roger Grosse,mmackay@cs.toronto.edu;pvicol@cs.toronto.edu;lorraine@cs.toronto.edu;duvenaud@cs.toronto.edu;rgrosse@cs.toronto.edu,6;7;6,3;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto;University of Toronto;University of Toronto,hyperparameter optimization;game theory;optimization,18;18;18;18;18,22;22;22;22;22,-1;-1,canada,ca,y,
1543,ICLR,2019,Learning to Make Analogies by Contrasting Abstract Relational Structure,Felix Hill;Adam Santoro;David Barrett;Ari Morcos;Timothy Lillicrap,felixhill@google.com;adamsantoro@google.com;barrettdavid@google.com;arimorcos@google.com;countzero@google.com,6;7;7,3;3;5,Accept (Poster),1,0,11.0,yes,9/27/18,Google;Google;Google;Google;Google,cognitive science;analogy;psychology;cognitive theory;cognition;abstraction;generalization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
1544,ICLR,2019,DPSNet: End-to-end Deep Plane Sweep Stereo,Sunghoon Im;Hae-Gon Jeon;Stephen Lin;In So Kweon,dlarl8927@kaist.ac.kr;haegonj@andrew.cmu.edu;stevelin@microsoft.com;iskweon77@kaist.ac.kr,6;7;6,5;4;4,Accept (Poster),2,7,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Carnegie Mellon University;Microsoft;Korea Advanced Institute of Science and Technology,Deep Learning;Stereo;Depth;Geometry,-1;1;-1;-1,95;24;-1;95,-1;-1,NAN,NAN,n,
1545,ICLR,2019,M^3RL: Mind-aware Multi-agent Management Reinforcement Learning,Tianmin Shu;Yuandong Tian,tianmin.shu@ucla.edu;yuandong@fb.com,6;7;6,3;4;1,Accept (Poster),0,6,1.0,yes,9/27/18,"University of California, Los Angeles;Facebook",Multi-agent Reinforcement Learning;Deep Reinforcement Learning,-1;-1,15;-1,-1;-1,NAN,NAN,n,1
1546,ICLR,2019,Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization,Takayuki Osa;Voot Tangkaratt;Masashi Sugiyama,osa@mfg.t.u-tokyo.ac.jp;voot.tangkaratt@riken.jp;sugi@k.u-tokyo.ac.jp,6;7;5,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,The University of Tokyo;RIKEN;The University of Tokyo,Hierarchical reinforcement learning;Representation learning;Continuous control,59;-1;59,45;-1;45,-1;-1,NAN,NAN,n,
1547,ICLR,2019,ACCELERATING NONCONVEX LEARNING VIA REPLICA EXCHANGE LANGEVIN DIFFUSION,Yi Chen;Jinglin Chen;Jing Dong;Jian Peng;Zhaoran Wang,yichen2016@u.northwestern.edu;jinglinc@illinois.edu;jd2736@columbia.edu;jianpeng@illinois.edu;zhaoranwang@gmail.com,4;7;6,4;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,"Northwestern University;University of Illinois, Urbana Champaign;Columbia University;University of Illinois, Urbana Champaign;Northwestern University",,50;-1;21;-1;50,20;-1;14;-1;20,-1;-1,usa,usa,y,1;9
1548,ICLR,2019,Improving Sequence-to-Sequence Learning via Optimal Transport,Liqun Chen;Yizhe Zhang;Ruiyi Zhang;Chenyang Tao;Zhe Gan;Haichao Zhang;Bai Li;Dinghan Shen;Changyou Chen;Lawrence Carin,liqun.chen@duke.edu;yizhe.zhang@microsoft.com;rz68@duke.edu;chenyang.tao@duke.edu;zhe.gan@microsoft.com;hczhang1@gmail.com;bai.li@duke.edu;dinghan.shen@duke.edu;cchangyou@gmail.com;lcarin@duke.edu,6;7;5,3;4;4,Accept (Poster),0,5,2.0,yes,9/27/18,"Duke University;Microsoft;Duke University;Duke University;Microsoft;Horizon Robotics;Duke University;Duke University;State University of New York, Buffalo;Duke University",NLP;optimal transport;sequence to sequence;natural language processing,47;-1;47;47;-1;-1;47;47;-1;47,17;-1;17;17;-1;-1;17;17;-1;17,-1;-1,europe,se,n,3
1549,ICLR,2019,Overcoming Catastrophic Forgetting for Continual Learning via Model Adaptation,Wenpeng Hu;Zhou Lin;Bing Liu;Chongyang Tao;Zhengwei Tao;Jinwen Ma;Dongyan Zhao;Rui Yan,wenpeng.hu@pku.edu.cn;scene@pku.edu.cn;liub@uic.edu;chongyangtao@pku.edu.cn;tttzw@pku.edu.cn;jwma@math.pku.edu.cn;zhaody@pku.edu.cn;ruiyan@pku.edu.cn,5;6;7,4;2;4,Accept (Poster),0,13,0.0,yes,9/27/18,"Peking University;Peking University;University of Illinois, Chicago;Peking University;Peking University;Peking University;Peking University;Peking University",overcoming forgetting;model adaptation;continual learning,14;14;-1;14;14;14;14;14,27;27;-1;27;27;27;27;27,-1;-1,asia,cn,n,
1550,ICLR,2019,Adaptive Posterior Learning: few-shot learning with a surprise-based memory module,Tiago Ramalho;Marta Garnelo,tiago.mpramalho@gmail.com;garnelo@google.com,7;6;7,4;4;3,Accept (Poster),0,6,1.0,yes,9/27/18,Google;Google,metalearning;memory;few-shot;relational;self-attention;classification;sequential;reasoning;working memory;episodic memory,-1;-1,-1;-1,-1;-1,NAN,NAN,n,6
1551,ICLR,2019,A Mean Field Theory of Batch Normalization,Greg Yang;Jeffrey Pennington;Vinay Rao;Jascha Sohl-Dickstein;Samuel S. Schoenholz,gregyang@microsoft.com;jpennin@google.com;vinaysrao@google.com;jaschasd@google.com;schsam@google.com,7;6;7,3;1;3,Accept (Poster),2,6,0.0,yes,9/27/18,Microsoft;Google;Google;Google;Google,theory;batch normalization;mean field theory;trainability,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1552,ICLR,2019,Rethinking the Value of Network Pruning,Zhuang Liu;Mingjie Sun;Tinghui Zhou;Gao Huang;Trevor Darrell,zhuangl@berkeley.edu;sunmj15@gmail.com;tinghuiz@eecs.berkeley.edu;gaohuang.thu@gmail.com;trevor@eecs.berkeley.edu,6;7;6,5;5;4,Accept (Poster),20,40,1.0,yes,9/27/18,"University of California Berkeley;;University of California Berkeley;Tsinghua University, Tsinghua University;University of California Berkeley",network pruning;network compression;architecture search;train from scratch,-1;-1;-1;4;-1,18;-1;18;30;18,-1;-1,usa,usa,n,
1553,ICLR,2019,Benchmarking Neural Network Robustness to Common Corruptions and Perturbations,Dan Hendrycks;Thomas Dietterich,hendrycks@berkeley.edu;tgd@oregonstate.edu,7;9;9,3;5;4,Accept (Poster),0,16,2.0,yes,9/27/18,University of California Berkeley;Oregon State University,robustness;benchmark;convnets;perturbations,-1;77,18;318,-1;-1,usa,usa,n,1;4
1554,ICLR,2019,Universal Transformers,Mostafa Dehghani;Stephan Gouws;Oriol Vinyals;Jakob Uszkoreit;Lukasz Kaiser,dehghani@uva.nl;sgouws@google.com;vinyals@google.com;usz@google.com;lukaszkaiser@google.com,8;6;6,4;4;2,Accept (Poster),0,13,0.0,yes,9/27/18,University of Amsterdam;Google;Google;Google;Google,sequence-to-sequence;rnn;transformer;machine translation;language understanding;learning to execute,136;-1;-1;-1;-1,59;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;8;1
1555,ICLR,2019,Characterizing Audio Adversarial Examples Using Temporal Dependency,Zhuolin Yang;Bo Li;Pin-Yu Chen;Dawn Song,lucas110550@sjtu.edu.cn;lxbosky@gmail.com;pin-yu.chen@ibm.com;dawnsong@gmail.com,7;6;6,3;3;3,Accept (Poster),4,4,0.0,yes,9/27/18,Shanghai Jiao Tong University;University of California Berkeley;International Business Machines;University of California Berkeley,audio adversarial example;mitigation;detection;machine learning,36;-1;-1;-1,188;18;-1;18,-1;-1,usa,usa,n,4
1556,ICLR,2019,Contingency-Aware Exploration in Reinforcement Learning,Jongwook Choi;Yijie Guo;Marcin Moczulski;Junhyuk Oh;Neal Wu;Mohammad Norouzi;Honglak Lee,jwook@umich.edu;guoyijie@umich.edu;marcin.lukasz.moczulski@gmail.com;junhyuk@umich.edu;neal@nealwu.com;mnorouzi@google.com;honglak@eecs.umich.edu,7;6;7,4;3;2,Accept (Poster),0,10,0.0,yes,9/27/18,University of Michigan;University of Michigan;University of Oxford;University of Michigan;Google;Google;University of Michigan,Reinforcement Learning;Exploration;Contingency-Awareness,9;9;44;9;-1;-1;9,21;21;1;21;-1;-1;21,-1;-1,usa,usa,n,
1557,ICLR,2019,Visual Semantic Navigation using Scene Priors,Wei Yang;Xiaolong Wang;Ali Farhadi;Abhinav Gupta;Roozbeh Mottaghi,wyang@ee.cuhk.edu.hk;xiaolonw@cs.cmu.edu;ali@cs.washington.edu;abhinavg@cs.cmu.edu;roozbehm@allenai.org,7;7;7,3;1;4,Accept (Poster),0,7,0.0,yes,9/27/18,The Chinese University of Hong Kong;Carnegie Mellon University;University of Washington;Carnegie Mellon University;Allen Institute for Artificial Intelligence,Visual Navigation;Scene Prior;Knowledge Graph;Graph Convolution Networks;Deep Reinforcement Learning,285;1;10;1;-1,40;24;25;24;-1,-1;-1,NAN,NAN,n,1;10
1558,ICLR,2019,On Computation and Generalization of Generative Adversarial Networks under Spectrum Control,Haoming Jiang;Zhehui Chen;Minshuo Chen;Feng Liu;Dingding Wang;Tuo Zhao,jianghm@gatech.edu;zhchen@gatech.edu;mchen393@gatech.edu;fliu2016@fau.edu;wangd@fau.edu;tourzhao@gatech.edu,8;6;7,4;2;4,Accept (Poster),0,4,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Florida Atlantic University;Florida Atlantic University;Georgia Institute of Technology,,13;13;13;419;419;13,33;33;33;712;712;33,-1;-1,usa,usa,y,1;5;4
1559,ICLR,2019,The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure,Frederic Koehler;Andrej Risteski,fkoehler@mit.edu;risteski@mit.edu,7;7;7,3;3;3,Accept (Poster),0,1,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,theory;representational power;universal approximators;polynomial kernels;latent sparsity;beyond worst case;separation result,6;6,5;5,-1;-1,usa,usa,y,1;4
1560,ICLR,2019,"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks",Jonathan Frankle;Michael Carbin,jfrankle@mit.edu;mcarbin@csail.mit.edu,5;9;9,4;4;4,Accept (Oral),0,14,3.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neural networks;sparsity;pruning;compression;performance;architecture search,6;6,5;5,-1;-1,usa,usa,n,
1561,ICLR,2019,Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer,David Berthelot*;Colin Raffel*;Aurko Roy;Ian Goodfellow,dberth@google.com;craffel@gmail.com;aurkor@google.com;goodfellow@google.com,7;8;9,4;3;4,Accept (Poster),0,18,0.0,yes,9/27/18,Google;;Google;Google,autoencoders;interpolation;unsupervised learning;representation learning;adversarial learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1562,ICLR,2019,Learning Implicitly Recurrent CNNs Through Parameter Sharing,Pedro Savarese;Michael Maire,savarese@ttic.edu;mmaire@uchicago.edu,8;7;6,4;3;4,Accept (Poster),0,7,0.0,yes,9/27/18,Toyota Technological Institute at Chicago;University of Chicago,deep learning;architecture search;computer vision,-1;50,-1;9,-1;-1,usa,usa,n,
1563,ICLR,2019,G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space,Qi Meng;Shuxin Zheng;Huishuai Zhang;Wei Chen;Qiwei Ye;Zhi-Ming Ma;Nenghai Yu;Tie-Yan Liu,meq@microsoft.com;zhengsx@mail.ustc.edu.cn;huzhang@microsoft.com;wche@microsoft.com;qiwye@microsoft.com;mazm@amt.ac.cn;ynh@ustc.edu.cn;tyliu@microsoft.com,7;7;7,4;2;3,Accept (Poster),0,7,1.0,yes,9/27/18,Microsoft;University of Science and Technology of China;Microsoft;Microsoft;Microsoft;Chinese Academy of Sciences;University of Science and Technology of China;Microsoft,optimization;neural network;irreducible positively scale-invariant space;deep learning,-1;-1;-1;-1;-1;31;-1;-1,-1;132;-1;-1;-1;-1;132;-1,-1;-1,NAN,NAN,y,1
1564,ICLR,2019,SGD Converges to Global Minimum in Deep Learning via Star-convex Path,Yi Zhou;Junjie Yang;Huishuai Zhang;Yingbin Liang;Vahid Tarokh,yi.zhou610@duke.edu;baymax@mail.ustc.edu.cn;huishuai.zhang@microsoft.com;liang.889@osu.edu;vahid.tarokh@duke.edu,8;6;5,4;4;5,Accept (Poster),0,5,0.0,yes,9/27/18,Duke University;University of Science and Technology of China;Microsoft;Ohio State University;Duke University,SGD;deep learning;global minimum;convergence,47;-1;-1;59;47,17;132;-1;70;17,-1;-1,europe,se,y,9
1565,ICLR,2019,Discovery of Natural Language Concepts in Individual Units of CNNs,Seil Na;Yo Joong Choe;Dong-Hyun Lee;Gunhee Kim,seil.na@vision.snu.ac.kr;yj.c@kakaocorp.com;benjamin.lee@kakaobrain.com;gunhee@snu.ac.kr,6;6;6,4;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,Seoul National University;Kakao;Kakao Brain;Seoul National University,interpretability of deep neural networks;natural language representation,36;-1;-1;36,74;-1;-1;74,-1;-1,asia,kr,n,3
1566,ICLR,2019,LanczosNet: Multi-Scale Deep Graph Convolutional Networks,Renjie Liao;Zhizhen Zhao;Raquel Urtasun;Richard Zemel,rjliao@cs.toronto.edu;zhizhenz@illinois.edu;urtasun@uber.com;zemel@cs.toronto.edu,7;7;8,3;5;4,Accept (Poster),0,4,0.0,yes,9/27/18,"University of Toronto;University of Illinois, Urbana Champaign;Uber;University of Toronto",Lanczos Network;Graph Neural Networks;Deep Graph Convolutional Networks;Deep Learning on Graph Structured Data;QM8 Quantum Chemistry Benchmark,18;-1;-1;18,22;-1;-1;22,-1;-1,canada,ca,y,10
1567,ICLR,2019,Learning to Learn with Conditional Class Dependencies,Xiang Jiang;Mohammad Havaei;Farshid Varno;Gabriel Chartrand;Nicolas Chapados;Stan Matwin,xiang.jiang@dal.ca;mohammad@imagia.com;f.varno@dal.ca;gabriel@imagia.com;nic@imagia.com;stan@cs.dal.ca,6;8;4,3;3;5,Accept (Poster),0,4,0.0,yes,9/27/18,Dalhousie University;Imagia;Dalhousie University;Imagia;Imagia;Dalhousie University,meta-learning;learning to learn;few-shot learning,285;-1;285;-1;-1;285,289;-1;289;-1;-1;289,-1;-1,canada,ca,n,6
1568,ICLR,2019,Optimal Transport Maps For Distribution Preserving Operations on Latent Spaces of Generative Models,Eirikur Agustsson;Alexander Sage;Radu Timofte;Luc Van Gool,aeirikur@vision.ee.ethz.ch;alexander.sage@gmail.com;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,5;7;5,3;5;3,Accept (Poster),0,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology;;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,generative models;optimal transport;distribution preserving operations,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,5;4
1569,ICLR,2019,MARGINALIZED AVERAGE ATTENTIONAL NETWORK FOR WEAKLY-SUPERVISED LEARNING,Yuan Yuan;Yueming Lyu;Xi Shen;Ivor W. Tsang;Dit-Yan Yeung,yuanyuan910115@gmail.com;lv_yueming@outlook.com;shenxiluc@gmail.com;ivor.tsang@uts.edu.au;dyyeung@cse.ust.hk,5;6;3,3;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Massachusetts Institute of Technology;University of Technology Sydney;;University of Technology Sydney;The Hong Kong University of Science and Technology,feature aggregation;weakly supervised learning;temporal action localization,-1;67;-1;67;-1,-1;216;-1;216;44,-1;-1,NAN,NAN,y,8;1
1570,ICLR,2019,Predict then Propagate: Graph Neural Networks meet Personalized PageRank,Johannes Klicpera;Aleksandar Bojchevski;Stephan G√ºnnemann,klicpera@in.tum.de;a.bojchevski@in.tum.de;guennemann@in.tum.de,5;5;7,4;4;4,Accept (Poster),0,10,5.0,yes,9/27/18,Technical University Munich;Technical University Munich;Technical University Munich,Graph;GCN;GNN;Neural network;Graph neural network;Message passing neural network;Semi-supervised classification;Semi-supervised learning;PageRank;Personalized PageRank,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,10
1571,ICLR,2019,Variance Reduction for Reinforcement Learning in Input-Driven Environments,Hongzi Mao;Shaileshh Bojja Venkatakrishnan;Malte Schwarzkopf;Mohammad Alizadeh,hongzi@csail.mit.edu;bjjvnkt@csail.mit.edu;malte@csail.mit.edu;alizadeh@csail.mit.edu,6;7;9,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,reinforcement learning;policy gradient;input-driven environments;variance reduction;baseline,6;6;6;6,5;5;5;5,-1;-1,usa,usa,y,6
1572,ICLR,2019,Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees,Yuping Luo;Huazhe Xu;Yuanzhi Li;Yuandong Tian;Trevor Darrell;Tengyu Ma,yupingl@cs.princeton.edu;huazhe_xu@eecs.berkeley.edu;yuanzhili92@gmail.com;yuandong@fb.com;trevor@eecs.berkeley.edu;tengyuma@stanford.edu,7;6;6,4;4;2,Accept (Poster),0,8,0.0,yes,9/27/18,Princeton University;University of California Berkeley;;Facebook;University of California Berkeley;Stanford University,model-based reinforcement learning;sample efficiency;deep reinforcement learning,31;-1;-1;-1;-1;4,7;18;-1;-1;18;3,-1;-1,usa,usa,y,1
1573,ICLR,2019,Efficient Training on Very Large Corpora via Gramian Estimation,Walid Krichene;Nicolas Mayoraz;Steffen Rendle;Li Zhang;Xinyang Yi;Lichan Hong;Ed Chi;John Anderson,walidk@google.com;nmayoraz@google.com;srendle@google.com;liqzhang@google.com;xinyang@google.com;lichan@google.com;edchi@google.com;janders@google.com,8;7;7,4;4;2,Accept (Poster),8,4,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,similarity learning;pairwise learning;matrix factorization;Gramian estimation;variance reduction;neural embedding models;recommender systems,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
1574,ICLR,2019,Representing Formal Languages: A Comparison Between Finite Automata and Recurrent Neural Networks ,Joshua J. Michalenko;Ameesh Shah;Abhinav Verma;Richard G. Baraniuk;Swarat Chaudhuri;Ankit B. Patel,jjm7@rice.edu;ameesh@rice.edu;averma@rice.edu;richb@rice.edu;swarat@rice.edu;abp4@rice.edu,7;5;5,3;3;3,Accept (Poster),1,10,0.0,yes,9/27/18,Rice University;Rice University;Rice University;Rice University;Rice University;Rice University,Language recognition;Recurrent Neural Networks;Representation Learning;deterministic finite automaton;automaton,94;94;94;94;94;94,86;86;86;86;86;86,-1;-1,australasia,au,n,
1575,ICLR,2019,From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following,Justin Fu;Anoop Korattikara;Sergey Levine;Sergio Guadarrama,justinjfu@eecs.berkeley.edu;kbanoop@google.com;svlevine@eecs.berkeley.edu;sguada@google.com,9;5;5,5;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,University of California Berkeley;Google;University of California Berkeley;Google,inverse reinforcement learning;language grounding;instruction following;language-based learning,-1;-1;-1;-1,18;-1;18;-1,-1;-1,NAN,NAN,n,3
1576,ICLR,2019,Learning from Positive and Unlabeled Data with a Selection Bias,Masahiro Kato;Takeshi Teshima;Junya Honda,mkato@ms.k.u-tokyo.ac.jp;teshima@ms.k.u-tokyo.ac.jp;honda@edu.k.u-tokyo.ac.jp,7;6;5,2;4;4,Accept (Poster),0,3,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo;The University of Tokyo,PU learning;deep learning;machine learning;anomaly detection;sampling bias,59;59;59,45;45;45,-1;-1,NAN,NAN,y,
1577,ICLR,2019,Dynamic Channel Pruning: Feature Boosting and Suppression,Xitong Gao;Yiren Zhao;≈Åukasz Dudziak;Robert Mullins;Cheng-zhong Xu,xt.gao@siat.ac.cn;yaz21@cam.ac.uk;lukaszd.mail@gmail.com;robert.mullins@cl.cam.ac.uk;czxu@um.edu.mo,6;7;6;7,4;5;3;4,Accept (Poster),0,10,2.0,yes,9/27/18,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;University of Cambridge;Samsung;University of Cambridge;University of Macau",dynamic network;faster CNNs;channel pruning,31;77;-1;77;-1,-1;2;-1;2;399,-1;-1,europe,de,n,
1578,ICLR,2019,Maximal Divergence Sequential Autoencoder for Binary Software Vulnerability Detection,Tue Le;Tuan Nguyen;Trung Le;Dinh Phung;Paul Montague;Olivier De Vel;Lizhen Qu,tue.le.ict@jvn.edu.vn;nguyenvutuan1995@gmail.com;trunglm@monash.edu;dinh.phung@monash.edu;paul.montague@dst.defence.gov.au;olivier.devel@dst.defence.gov.au;lizhen.qu@data61.csiro.au,6;7;6;6,4;2;3;2,Accept (Poster),0,8,0.0,yes,9/27/18,Trusting Social;;Monash University;Monash University;Defence Science and Technology Group;Defence Science and Technology Group;CSIRO,Vulnerabilities Detection;Sequential Auto-Encoder;Separable Representation,-1;-1;94;94;-1;-1;-1,-1;-1;80;80;-1;-1;-1,-1;-1,asia,in,n,5
1579,ICLR,2019,Large Scale GAN Training for High Fidelity Natural Image Synthesis,Andrew Brock;Jeff Donahue;Karen Simonyan,ajb5@hw.ac.uk;jeffdonahue@google.com;simonyan@google.com,9;7;8,4;3;4,Accept (Oral),10,11,1.0,yes,9/27/18,Heriot-Watt University;Google;Google,GANs;Generative Models;Large Scale Training;Deep Learning,207;-1;-1,363;-1;-1,-1;-1,NAN,NAN,n,5;4
1580,ICLR,2019,Learning Exploration Policies for Navigation,Tao Chen;Saurabh Gupta;Abhinav Gupta,taoc1@andrew.cmu.edu;sgupta@eecs.berkeley.edu;abhinavg@cs.cmu.edu,7;3;7,4;5;5,Accept (Poster),0,18,0.0,yes,9/27/18,Carnegie Mellon University;University of California Berkeley;Carnegie Mellon University,Exploration;navigation;reinforcement learning,1;-1;1,24;18;24,-1;-1,usa,usa,n,8
1581,ICLR,2019,Variational Autoencoders with Jointly Optimized Latent Dependency Structure,Jiawei He;Yu Gong;Joseph Marino;Greg Mori;Andreas Lehrmann,jha203@sfu.ca;yu_gong@sfu.ca;jmarino@caltech.edu;mori@cs.sfu.ca;andreas.lehrmann@gmail.com,7;8;6,4;5;3,Accept (Poster),0,9,0.0,yes,9/27/18,Simon Fraser University;Simon Fraser University;California Institute of Technology;Simon Fraser University;Borealis AI,deep generative models;structure learning,50;50;136;50;-1,253;253;3;253;-1,-1;-1,asia,in,n,11;10;5
1582,ICLR,2019,Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution,Thomas Elsken;Jan Hendrik Metzen;Frank Hutter,thomas.elsken@de.bosch.com;janhendrik.metzen@de.bosch.com;fh@cs.uni-freiburg.de,6;6;6,3;3;4,Accept (Poster),0,4,0.0,yes,9/27/18,Bosch;Bosch;Universit√§t Freiburg,Neural Architecture Search;AutoML;AutoDL;Deep Learning;Evolutionary Algorithms;Multi-Objective Optimization,-1;-1;-1,367;367;-1,-1;-1,NAN,NAN,n,
1583,ICLR,2019,Amortized Bayesian Meta-Learning,Sachin Ravi;Alex Beatson,sachinr@princeton.edu;abeatson@cs.princeton.edu,6;6;5,3;4;3,Accept (Poster),0,5,0.0,yes,9/27/18,Princeton University;Princeton University,variational inference;meta-learning;few-shot learning;uncertainty quantification,31;31,7;7,-1;-1,usa,usa,n,6;4
1584,ICLR,2019,How to train your MAML,Antreas Antoniou;Harrison Edwards;Amos Storkey,a.antoniou@sms.ed.ac.uk;h.l.edwards@sms.ac.uk;a.storkey@sms.ed.ac.uk,5;6;7,3;5;4,Accept (Poster),4,5,0.0,yes,9/27/18,University of Edinburgh;;University of Edinburgh,meta-learning;deep-learning;few-shot learning;supervised learning;neural-networks;stochastic optimization,36;-1;36,27;-1;27,-1;-1,europe,uk,n,6;1
1585,ICLR,2019,Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration,Xiaoshuai Zhang;Yiping Lu;Jiaying Liu;Bin Dong,jet@pku.edu.cn;luyiping9712@pku.edu.cn;liujiaying@pku.edu.cn;dongbin@math.pku.edu.cn,6;6;7,3;5;4,Accept (Poster),0,9,1.0,yes,9/27/18,Peking University;Peking University;Peking University;Peking University,image restoration;differential equation,14;14;14;14,27;27;27;27,-1;-1,asia,cn,n,
1586,ICLR,2019,Learning To Simulate,Nataniel Ruiz;Samuel Schulter;Manmohan Chandraker,nruiz9@bu.edu;samuel@nec-labs.com;manu@nec-labs.com,6;7;6,4;4;5,Accept (Poster),0,5,0.0,yes,9/27/18,Boston University;NEC-Labs;NEC-Labs,Simulation in machine learning;reinforcement learning;policy gradients;image rendering,77;-1;-1,70;-1;-1,-1;-1,NAN,NAN,n,2
1587,ICLR,2019,What do you learn from context? Probing for sentence structure in contextualized word representations,Ian Tenney;Patrick Xia;Berlin Chen;Alex Wang;Adam Poliak;R Thomas McCoy;Najoung Kim;Benjamin Van Durme;Samuel R. Bowman;Dipanjan Das;Ellie Pavlick,iftenney@google.com;paxia@cs.jhu.edu;bchen6@swarthmore.edu;alexwang@nyu.edu;azpoliak@cs.jhu.edu;tom.mccoy@jhu.edu;n.kim@jhu.edu;vandurme@cs.jhu.edu;bowman@nyu.edu;dipanjand@google.com;ellie_pavlick@brown.edu,7;7;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Google;Johns Hopkins University;Swarthmore College;New York University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;New York University;Google;Brown University,natural language processing;word embeddings;transfer learning;interpretability,-1;67;-1;24;67;67;67;67;24;-1;86,-1;13;-1;27;13;13;13;13;27;-1;50,-1;-1,usa,usa,n,3
1588,ICLR,2019,"Towards Robust, Locally Linear Deep Networks",Guang-He Lee;David Alvarez-Melis;Tommi S. Jaakkola,guanghe@csail.mit.edu;davidam@csail.mit.edu;tommi@csail.mit.edu,8;8;7,3;4;4,Accept (Poster),0,9,1.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,robust derivatives;transparency;interpretability,6;6;6,5;5;5,-1;-1,usa,usa,y,
1589,ICLR,2019,Gradient descent aligns the layers of deep linear networks,Ziwei Ji;Matus Telgarsky,ziweiji2@illinois.edu;mjt@illinois.edu,9;6;7,4;5;4,Accept (Poster),0,6,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",implicit regularization;alignment of layers;deep linear networks;gradient descent;separable data,-1;-1,-1;-1,-1;-1,usa,usa,y,
1590,ICLR,2019,Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes,Roman Novak;Lechao Xiao;Yasaman Bahri;Jaehoon Lee;Greg Yang;Jiri Hron;Daniel A. Abolafia;Jeffrey Pennington;Jascha Sohl-dickstein,romann@google.com;xlc@google.com;yasamanb@google.com;jaehlee@google.com;gregyang@microsoft.com;jh2084@cam.ac.uk;danabo@google.com;jpennin@google.com;jaschasd@google.com,7;7;7;6,3;2;5;4,Accept (Poster),0,18,1.0,yes,9/27/18,Google;Google;Google;Google;Microsoft;University of Cambridge;Google;Google;Google,Deep Convolutional Neural Networks;Gaussian Processes;Bayesian,-1;-1;-1;-1;-1;77;-1;-1;-1,-1;-1;-1;-1;-1;2;-1;-1;-1,-1;-1,NAN,NAN,y,11
1591,ICLR,2019,MisGAN: Learning from Incomplete Data with Generative Adversarial Networks,Steven Cheng-Xian Li;Bo Jiang;Benjamin Marlin,cxl@cs.umass.edu;bjiang@sjtu.edu.cn;marlin@cs.umass.edu,7;6;7,4;5;4,Accept (Poster),0,3,0.0,yes,9/27/18,"University of Massachusetts, Amherst;Shanghai Jiao Tong University;University of Massachusetts, Amherst",generative models;missing data,27;36;27,191;188;191,-1;-1,usa,usa,y,5;4
1592,ICLR,2019,Information Theoretic lower bounds on negative log likelihood,Luis A. Lastras-Monta√±o,lastrasl@us.ibm.com,6;7;6,3;3;4,Accept (Poster),0,8,0.0,yes,9/27/18,International Business Machines,latent variable modeling;rate-distortion theory;log likelihood bounds,-1,-1,-1,NAN,NAN,y,1
1593,ICLR,2019,A Data-Driven and Distributed Approach to Sparse Signal Representation and Recovery,Ali Mousavi;Gautam Dasarathy;Richard G. Baraniuk,ali.mousavi1988@gmail.com;gautamd@asu.edu;richb@rice.edu,7;8;6,3;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,Apple;SUN YAT-SEN UNIVERSITY;Rice University,Sparsity;Compressive Sensing;Convolutional Network,-1;-1;94,-1;352;86,-1;-1,australasia,au,n,
1594,ICLR,2019,Efficient Augmentation via Data Subsampling,Michael Kuchnik;Virginia Smith,mkuchnik@andrew.cmu.edu;smithv@cmu.edu,6;7;6,4;4;3,Accept (Poster),0,3,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University,data augmentation;invariance;subsampling;influence,1;1,24;24,-1;-1,usa,usa,n,
1595,ICLR,2019,Explaining Image Classifiers by Counterfactual Generation,Chun-Hao Chang;Elliot Creager;Anna Goldenberg;David Duvenaud,kingsley@cs.toronto.edu;creager@cs.toronto.edu;anna.goldenberg@utoronto.ca;duvenaud@cs.toronto.edu,5;7;5,4;3;5,Accept (Poster),0,6,2.0,yes,9/27/18,University of Toronto;University of Toronto;Toronto University;University of Toronto,Explainability;Interpretability;Generative Models;Saliency Map;Machine Learning;Deep Learning,18;18;-1;18,22;22;-1;22,-1;-1,canada,ca,n,5
1596,ICLR,2019,A Max-Affine Spline Perspective of Recurrent Neural Networks,Zichao Wang;Randall Balestriero;Richard Baraniuk,richb@rice.edu;zw16@rice.edu;randallbalestriero@gmail.com,6;6;6,3;3;3,Accept (Poster),0,3,0.0,yes,9/27/18,Rice University;Rice University;Rice University,RNN;max-affine spline operators,94;94;94,86;86;86,-1;-1,australasia,au,y,1
1597,ICLR,2019,Learning Actionable Representations with Goal Conditioned Policies,Dibya Ghosh;Abhishek Gupta;Sergey Levine,dibya.ghosh@berkeley.edu;abhigupta@berkeley.edu;svlevine@eecs.berkeley.edu,6;6;5,4;4;4,Accept (Poster),0,13,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,Representation Learning;Reinforcement Learning,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,5
1598,ICLR,2019,Supervised Community Detection with Line Graph Neural Networks,Zhengdao Chen;Lisha Li;Joan Bruna,zc1216@nyu.edu;lapis.lazuli.8@gmail.com;bruna@cims.nyu.edu,6;9;8,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,New York University;;New York University,community detection;graph neural networks;belief propagation;energy landscape;non-backtracking matrix,24;-1;24,27;-1;27,-1;-1,usa,usa,y,10;5
1599,ICLR,2019,Unsupervised Learning via Meta-Learning,Kyle Hsu;Sergey Levine;Chelsea Finn,kyle.hsu@mail.utoronto.ca;svlevine@eecs.berkeley.edu;cbfinn@eecs.berkeley.edu,7;6;6;8,4;3;3;4,Accept (Poster),0,8,0.0,yes,9/27/18,Toronto University;University of California Berkeley;University of California Berkeley,unsupervised learning;meta-learning,-1;-1;-1,-1;18;18,-1;-1,usa,usa,n,6
1600,ICLR,2019,Music Transformer: Generating Music with Long-Term Structure,Cheng-Zhi Anna Huang;Ashish Vaswani;Jakob Uszkoreit;Ian Simon;Curtis Hawthorne;Noam Shazeer;Andrew M. Dai;Matthew D. Hoffman;Monica Dinculescu;Douglas Eck,chengzhiannahuang@gmail.com;avaswani@google.com;uszkoreit@google.com;iansimon@google.com;fjord@google.com;noam@google.com;adai@google.com;mhoffman@google.com;noms@google.com;deck@google.com,7;6;4;5,3;4;4;3,Accept (Poster),0,12,0.0,yes,9/27/18,Mila;Google;Google;Google;Google;Google;Google;Google;Google;Google,music generation,136;-1;-1;-1;-1;-1;-1;-1;-1;-1,314;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
1601,ICLR,2019,"Deep, Skinny Neural Networks are not Universal Approximators",Jesse Johnson,jejo.math@gmail.com,6;8;7,4;4;4,Accept (Poster),2,2,1.0,yes,9/27/18,0,neural network;universality;expressability,,,-1,NAN,NAN,y,
1602,ICLR,2019,Multilingual Neural Machine Translation with Knowledge Distillation,Xu Tan;Yi Ren;Di He;Tao Qin;Zhou Zhao;Tie-Yan Liu,xuta@microsoft.com;rayeren613@gmail.com;dihe@microsoft.com;taoqin@microsoft.com;zhaozhou@zju.edu.cn;tyliu@microsoft.com,7;7;7,4;3;4,Accept (Poster),0,16,6.0,yes,9/27/18,Microsoft;;Microsoft;Microsoft;Zhejiang University;Microsoft,NMT;Multilingual NMT;Knowledge Distillation,-1;-1;-1;-1;36;-1,-1;-1;-1;-1;177;-1,-1;-1,NAN,NAN,n,8;3
1603,ICLR,2019,textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE TOPIC MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR,Pankaj Gupta;Yatin Chaudhary;Florian Buettner;Hinrich Schuetze,pankaj_gupta96@yahoo.com;yatinchaudhary91@gmail.com;fbuettner.phys@gmail.com;hinrich@hotmail.com,8;7;6,4;4;4,Accept (Poster),6,18,1.0,yes,9/27/18,DRIMCo GmbH;;;University of Munich,neural topic model;natural language processing;text representation;language modeling;information retrieval;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,3;1;5
1604,ICLR,2019,Learning Embeddings into Entropic Wasserstein Spaces,Charlie Frogner;Farzaneh Mirzazadeh;Justin Solomon,frogner@mit.edu;farzaneh@ibm.com;jsolomon@mit.edu,7;7;3,3;4;4,Accept (Poster),0,12,3.0,yes,9/27/18,Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology,Embedding;Wasserstein;Sinkhorn;Optimal Transport,6;-1;6,5;-1;5,-1;-1,usa,usa,n,
1605,ICLR,2019,Deep Layers as Stochastic Solvers,Adel Bibi;Bernard Ghanem;Vladlen Koltun;Rene Ranftl,adel.bibi@kaust.edu.sa;bernard.ghanem@kaust.edu.sa;vkoltun@gmail.com;ranftlr@gmail.com,7;7;8,5;4;1,Accept (Poster),2,8,0.0,yes,9/27/18,KAUST;KAUST;Intel;Intel,deep networks;optimization,94;94;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,y,9
1606,ICLR,2019,Learning to Describe Scenes with Programs,Yunchao Liu;Zheng Wu;Daniel Ritchie;William T. Freeman;Joshua B. Tenenbaum;Jiajun Wu,georgeycliu@gmail.com;14wuzheng@sjtu.edu.cn;daniel_ritchie@brown.edu;billf@mit.edu;jbt@mit.edu;jiajunwu@mit.edu,6;4;6,3;3;4,Accept (Poster),0,13,1.0,yes,9/27/18,Tsinghua University;Shanghai Jiao Tong University;Brown University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Structured scene representations;program synthesis,-1;36;86;6;6;6,-1;188;50;5;5;5,-1;-1,usa,usa,n,
1607,ICLR,2019,BA-Net: Dense Bundle Adjustment Networks,Chengzhou Tang;Ping Tan,cta73@sfu.ca;pingtan@sfu.ca,8;7;9,4;4;4,Accept (Oral),0,6,0.0,yes,9/27/18,Simon Fraser University;Simon Fraser University,Structure-from-Motion;Bundle Adjustment;Dense Depth Estimation,50;50,253;253,-1;-1,canada,ca,n,1
1608,ICLR,2019,Stochastic Prediction of Multi-Agent Interactions from Partial Observations,Chen Sun;Per Karlsson;Jiajun Wu;Joshua B Tenenbaum;Kevin Murphy,chensun@google.com;perk@google.com;jiajunwu@mit.edu;jbt@mit.edu;kpmurphy@google.com,6;6;6,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Google;Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Google,Dynamics modeling;partial observations;multi-agent interactions;predictive models,-1;-1;6;6;-1,-1;-1;5;5;-1,-1;-1,NAN,NAN,n,10
1609,ICLR,2019,"Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control",Kendall Lowrey;Aravind Rajeswaran;Sham Kakade;Emanuel Todorov;Igor Mordatch,kendall.lowrey@gmail.com;rajeswaran.aravind@gmail.com;sham@cs.washington.edu;etodorov@gmail.com;mordatch@openai.com,5;6;4,5;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,"University of Washington, Seattle;Facebook;University of Washington;Roboti LLC;OpenAI",deep reinforcement learning;exploration;model-based,10;-1;10;-1;-1,25;-1;25;-1;-1,-1;-1,NAN,NAN,y,
1610,ICLR,2019,Composing Complex Skills by Learning Transition Policies,Youngwoon Lee*;Shao-Hua Sun*;Sriram Somasundaram;Edward S. Hu;Joseph J. Lim,lee504@usc.edu;shaohuas@usc.edu;sriramso@usc.edu;hues@usc.edu;limjj@usc.edu,7;9;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,University of Southern California;University of Southern California;University of Southern California;University of Southern California;University of Southern California,reinforcement learning;hierarchical reinforcement learning;continuous control;modular framework,27;27;27;27;27,66;66;66;66;66,-1;-1,usa,usa,n,
1611,ICLR,2019,The role of over-parametrization in generalization of neural networks,Behnam Neyshabur;Zhiyuan Li;Srinadh Bhojanapalli;Yann LeCun;Nathan Srebro,bneyshabur@gmail.com;zhiyuanli@cs.princeton.edu;srinadh@ttic.edu;yann@cs.nyu.edu;nati@ttic.edu,7;7;7,3;5;3,Accept (Poster),0,5,0.0,yes,9/27/18,Google;Princeton University;Toyota Technological Institute at Chicago;New York University;Toyota Technological Institute at Chicago,Generalization;Over-Parametrization;Neural Networks;Deep Learning,-1;31;-1;24;-1,-1;7;-1;27;-1,-1;-1,NAN,NAN,y,1
1612,ICLR,2019,Learning Procedural Abstractions and Evaluating Discrete Latent Temporal Structure,Karan Goel;Emma Brunskill,kgoel93@gmail.com;ebrun@cs.stanford.edu,5;6;7,2;3;3,Accept (Poster),0,6,1.0,yes,9/27/18,Stanford University;Stanford University,learning procedural abstractions;latent variable modeling;evaluation criteria,4;4,3;3,-1;-1,usa,usa,n,11
1613,ICLR,2019,Learning Mixed-Curvature Representations in Product Spaces,Albert Gu;Frederic Sala;Beliz Gunel;Christopher R√©,albertgu@stanford.edu;fredsala@stanford.edu;bgunel@stanford.edu;chrismre@cs.stanford.edu,7;7;7,5;2;3,Accept (Poster),0,8,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University,embeddings;non-Euclidean geometry;manifolds;geometry of data,4;4;4;4,3;3;3;3,-1;-1,usa,usa,y,3;10
1614,ICLR,2019,Synthetic Datasets for Neural Program Synthesis,Richard Shin;Neel Kant;Kavi Gupta;Chris Bender;Brandon Trabucco;Rishabh Singh;Dawn Song,ricshin@berkeley.edu;kantneel@berkeley.edu;kavi@berkeley.edu;chrisbender@berkeley.edu;btrabucco@berkeley.edu;rising@google.com;dawnsong@cs.berkeley.edu,6;6;7,4;2;3,Accept (Poster),0,6,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Google;University of California Berkeley,,-1;-1;-1;-1;-1;-1;-1,18;18;18;18;18;-1;18,-1;-1,usa,usa,n,1
1615,ICLR,2019,Energy-Constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking,Haichuan Yang;Yuhao Zhu;Ji Liu,h.yang@rochester.edu;yzhu@rochester.edu;ji.liu.uwisc@gmail.com,7;7;7,4;4;3,Accept (Poster),0,9,0.0,yes,9/27/18,University of Rochester;University of Rochester;Kwai Inc.,model compression;inference energy saving;deep neural network pruning,94;94;-1,153;153;-1,-1;-1,asia,in,y,1
1616,ICLR,2019,The Unusual Effectiveness of Averaging in GAN Training,Yasin Yaz{\i}c{\i};Chuan-Sheng Foo;Stefan Winkler;Kim-Hui Yap;Georgios Piliouras;Vijay Chandrasekhar,yasin001@e.ntu.edu.sg;foocs@i2r.a-star.edu.sg;stefan.winkler@adsc-create.edu.sg;ekhyap@ntu.edu.sg;georgios@sutd.edu.sg;vijay@i2r.a-star.edu.sg,6;5;6,4;2;4,Accept (Poster),3,6,0.0,yes,9/27/18,"Nanyang Technological University;Institute for Infocomm Research, A*STAR;ADSC;Nanyang Technological University;Singapore University of Technology and Design;Institute for Infocomm Research, A*STAR",Generative Adversarial Networks (GANs);Moving Average;Exponential Moving Average;Convergence;Limit Cycles,44;-1;-1;44;-1;-1,52;-1;-1;52;-1;-1,-1;-1,NAN,NAN,y,5
1617,ICLR,2019,Selfless Sequential Learning,Rahaf Aljundi;Marcus Rohrbach;Tinne Tuytelaars,rahaf.aljundi@gmail.com;mrf@fb.com;tinne.tuytelaars@esat.kuleuven.be,6;6;7,5;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,Toyota Motor Europe;Facebook;KU Leuven,Lifelong learning;Continual Learning;Sequential learning;Regularization,-1;-1;136,-1;-1;47,-1;-1,europe,be,n,
1618,ICLR,2019,Learning Protein Structure with a Differentiable Simulator,John Ingraham;Adam Riesselman;Chris Sander;Debora Marks,john.ingraham@gmail.com;adam.riesselman@gmail.com;cccsander@gmail.com;deboramarks@gmail.com,6;7;6;7,3;5;5;3,Accept (Oral),4,7,0.0,yes,9/27/18,Massachusetts Institute of Technology;insitro;Harvard University;Harvard University,generative models;simulators;molecular modeling;proteins;structured prediction,6;-1;50;-1,5;-1;6;-1,-1;-1,asia,in,n,
1619,ICLR,2019,DOM-Q-NET:  Grounded RL on Structured Language,Sheng Jia;Jamie Ryan Kiros;Jimmy Ba,sheng.jia@mail.utoronto.ca;kirosjamie@gmail.com;jba@cs.utoronto.ca,7;6;7,3;3;1,Accept (Poster),0,10,0.0,yes,9/27/18,Toronto University;Google;Toronto University,Reinforcement Learning;Web Navigation;Graph Neural Networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,10
1620,ICLR,2019,Predicting the Generalization Gap in Deep Networks with Margin Distributions,Yiding Jiang;Dilip Krishnan;Hossein Mobahi;Samy Bengio,ydjiang@google.com;dilipkay@google.com;hmobahi@google.com;bengio@google.com,6;5;9,4;4;4,Accept (Poster),2,5,0.0,yes,9/27/18,Google;Google;Google;Google,Deep learning;large margin;generalization bounds;generalization gap.,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1621,ICLR,2019,Neural TTS Stylization with Adversarial and Collaborative Games,Shuang Ma;Daniel Mcduff;Yale Song,shuangma@buffalo.edu;damcduff@microsoft.com;yalesong@csail.mit.edu,6;6;7;6,5;5;5;3,Accept (Poster),0,14,1.0,yes,9/27/18,"State University of New York, Buffalo;Microsoft;Massachusetts Institute of Technology",Text-To-Speech synthesis;GANs,-1;-1;6,-1;-1;5,-1;-1,usa,usa,n,8;5;4
1622,ICLR,2019,Learning a Meta-Solver for Syntax-Guided Program Synthesis,Xujie Si;Yuan Yang;Hanjun Dai;Mayur Naik;Le Song,xsi@cis.upenn.edu;yyang754@gatech.edu;hanjundai@gatech.edu;mhnaik@cis.upenn.edu;lsong@cc.gatech.edu,7;7;7,5;4;2,Accept (Poster),0,14,0.0,yes,9/27/18,University of Pennsylvania;Georgia Institute of Technology;Georgia Institute of Technology;University of Pennsylvania;Georgia Institute of Technology,Syntax-guided Synthesis;Context Free Grammar;Logical Specification;Representation Learning;Meta Learning;Reinforcement Learning,21;13;13;21;13,10;33;33;10;33,-1;-1,usa,usa,n,6;10
1623,ICLR,2019,DyRep: Learning Representations over Dynamic Graphs,Rakshit Trivedi;Mehrdad Farajtabar;Prasenjeet Biswal;Hongyuan Zha,rstrivedi@gatech.edu;farajtabar@google.com;bprasenjeet1108@gmail.com;zha@cc.gatech.edu,6;7;8,4;5;4,Accept (Poster),4,9,4.0,yes,9/27/18,Georgia Institute of Technology;Google;;Georgia Institute of Technology,Dynamic Graphs;Representation Learning;Dynamic Processes;Temporal Point Process;Attention;Latent Representation,13;-1;-1;13,33;-1;-1;33,-1;-1,usa,usa,n,8;10
1624,ICLR,2019,Modeling the Long Term Future in Model-Based Reinforcement Learning,Nan Rosemary Ke;Amanpreet Singh;Ahmed Touati;Anirudh Goyal;Yoshua Bengio;Devi Parikh;Dhruv Batra,rosemary.nan.ke@gmail.com;asg@fb.com;ahmed.touati@umontreal.ca;anirudhgoyal9119@gmail.com;yoshua.umontreal@gmail.com;parikh@gatech.edu;dbatra@gatech.edu,7;6;6,4;4;4,Accept (Poster),0,23,0.0,yes,9/27/18,University of Montreal;Facebook;University of Montreal;;University of Montreal;Georgia Institute of Technology;Georgia Institute of Technology,model-based reinforcement learning;variation inference,-1;-1;116;-1;116;13;13,-1;-1;108;-1;108;33;33,-1;-1,usa,usa,n,
1625,ICLR,2019,ProbGAN: Towards Probabilistic GAN with Theoretical Guarantees,Hao He;Hao Wang;Guang-He Lee;Yonglong Tian,haohe@mit.edu;hwang87@mit.edu;guanghe@mit.edu;yonglong@mit.edu,5;6;9,4;3;4,Accept (Poster),0,9,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Generative Adversarial Networks;Bayesian Deep Learning;Mode Collapse;Inception Score;Generator;Discriminator;CIFAR-10;STL-10;ImageNet,6;6;6;6,5;5;5;5,-1;-1,usa,usa,y,11;5;4
1626,ICLR,2019,Defensive Quantization: When Efficiency Meets Robustness,Ji Lin;Chuang Gan;Song Han,jilin@mit.edu;ganchuang1990@gmail.com;songhan@mit.edu,7;6;7,4;3;2,Accept (Poster),13,4,0.0,yes,9/27/18,Massachusetts Institute of Technology;;Massachusetts Institute of Technology,defensive quantization;model quantization;adversarial attack;efficiency;robustness,6;-1;6,5;-1;5,-1;-1,usa,usa,n,4
1627,ICLR,2019,Identifying and Controlling Important Neurons in Neural Machine Translation,Anthony Bau;Yonatan Belinkov;Hassan Sajjad;Nadir Durrani;Fahim Dalvi;James Glass,abau@mit.edu;belinkov@mit.edu;hsajjad@hbku.edu.qa;ndurrani@qf.org.qa;faimaduddin@qf.org.qa;glass@mit.edu,7;10;6,3;3;4,Accept (Poster),0,5,1.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Peking University;IDKT-RDI QF;IDKT-RDI QF;Massachusetts Institute of Technology,neural machine translation;individual neurons;unsupervised;analysis;correlation;translation control;distributivity;localization,6;6;14;-1;-1;6,5;5;27;-1;-1;5,-1;-1,usa,usa,n,3
1628,ICLR,2019,Knowledge Flow: Improve Upon Your Teachers,Iou-Jen Liu;Jian Peng;Alexander Schwing,iliu3@illinois.edu;jianpeng@illinois.edu;aschwing@illinois.edu,6;8;7,3;5;4,Accept (Poster),0,7,1.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Transfer Learning;Reinforcement Learning,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
1629,ICLR,2019,FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS,Shengyang Sun;Guodong Zhang;Jiaxin Shi;Roger Grosse,ssy@cs.toronto.edu;gdzhang.cs@gmail.com;shijx15@mails.tsinghua.edu.cn;rgrosse@cs.toronto.edu,7;6;6,4;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,"University of Toronto;University of Toronto;Tsinghua University, Tsinghua University;University of Toronto",functional variational inference;Bayesian neural networks;stochastic processes,18;18;4;18,22;22;30;22,-1;-1,canada,ca,y,11;1
1630,ICLR,2019,K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning,Pramod Kaushik Mudrakarta;Mark Sandler;Andrey Zhmoginov;Andrew Howard,pramodkm@uchicago.edu;mark.sandler@gmail.com;azhmogin@google.com;howarda@google.com,6;7;8,3;5;4,Accept (Poster),0,5,0.0,yes,9/27/18,University of Chicago;Google;Google;Google,deep learning;mobile;transfer learning;multi-task learning;computer vision;small models;imagenet;inception;batch normalization,50;-1;-1;-1,9;-1;-1;-1,-1;-1,NAN,NAN,n,6
1631,ICLR,2019,Neural Program Repair by Jointly Learning to Localize and Repair,Marko Vasic;Aditya Kanade;Petros Maniatis;David Bieber;Rishabh Singh,vasic@utexas.edu;akanade@google.com;maniatis@google.com;dbieber@google.com;rising@google.com,7;6;5,4;5;5,Accept (Poster),0,11,0.0,yes,9/27/18,"University of Texas, Austin;Google;Google;Google;Google",neural program repair;neural program embeddings;pointer networks,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1632,ICLR,2019,On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data,Nan Lu;Gang Niu;Aditya Krishna Menon;Masashi Sugiyama,lu@ms.k.u-tokyo.ac.jp;gang.niu@riken.jp;adityakmenon@google.com;sugi@k.u-tokyo.ac.jp,7;8;8;7,4;3;3;4,Accept (Poster),0,15,0.0,yes,9/27/18,The University of Tokyo;RIKEN;Google;The University of Tokyo,learning from only unlabeled data;empirical risk minimization;unbiased risk estimator,59;-1;-1;59,45;-1;-1;45,-1;-1,NAN,NAN,y,1
1633,ICLR,2019,Regularized Learning for  Domain Adaptation under Label Shifts,Kamyar Azizzadenesheli;Anqi Liu;Fanny Yang;Animashree Anandkumar,kazizzad@uci.edu;anqiliu@caltech.edu;fan.yang@stat.math.ethz.ch;anima@caltech.edu,7;6;6,3;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,"University of California, Irvine;California Institute of Technology;Swiss Federal Institute of Technology;California Institute of Technology",Deep Learning;Domain Adaptation;Label Shift;Importance Weights;Generalization,-1;136;-1;136,99;3;-1;3,-1;-1,usa,usa,y,1
1634,ICLR,2019,Toward Understanding the Impact of Staleness in Distributed Machine Learning,Wei Dai;Yi Zhou;Nanqing Dong;Hao Zhang;Eric Xing,daviddai@apple.com;zhou.1172@osu.edu;nanqing.dong@petuum.com;hao.zhang@petuum.com;eric.xing@petuum.com,7;4;9,5;5;4,Accept (Poster),0,5,0.0,yes,9/27/18,Apple;Ohio State University;Petuum Inc.;Petuum Inc.;Petuum Inc.,,-1;59;-1;-1;-1,-1;70;-1;-1;-1,-1;-1,NAN,NAN,y,9
1635,ICLR,2019,Generalizable Adversarial Training via Spectral Normalization,Farzan Farnia;Jesse Zhang;David Tse,farnia@stanford.edu;jessez@stanford.edu;dntse@stanford.edu,6;6;5,4;5;3,Accept (Poster),2,6,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University,Adversarial attacks;adversarial training;spectral normalization;generalization guarantee,4;4;4,3;3;3,-1;-1,usa,usa,y,1;4
1636,ICLR,2019,Don't let your Discriminator  be fooled,Brady Zhou;Philipp Kr√§henb√ºhl,brady.zhou@utexas.edu;philkr@cs.utexas.edu,6;7;7,4;3;3,Accept (Poster),0,4,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",GAN;generative models;computer vision,-1;-1,-1;-1,-1;-1,usa,usa,y,5;4
1637,ICLR,2019,Diversity and Depth in Per-Example Routing Models,Prajit Ramachandran;Quoc V. Le,prajitram@gmail.com;qvl@google.com,7;6;6,5;4;5,Accept (Poster),0,5,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;Google",conditional computation;routing models;depth,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1638,ICLR,2019,Latent Convolutional Models,ShahRukh Athar;Evgeny Burnaev;Victor Lempitsky,sathar@cs.stonybrook.edu;e.burnaev@skoltech.ru;lempitsky@skoltech.ru,7;6;7,4;3;2,Accept (Poster),0,4,0.0,yes,9/27/18,"State University of New York, Stony Brook;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology",latent models;convolutional networks;unsupervised learning;deep learning;modeling natural images;image restoration,-1;-1;-1,-1;-1;-1,-1;-1,europe,russia,n,5;4
1639,ICLR,2019,Learning Grid Cells as Vector Representation of Self-Position Coupled with Matrix Representation of Self-Motion,Ruiqi Gao;Jianwen Xie;Song-Chun Zhu;Ying Nian Wu,ruiqigao@ucla.edu;jianwen@ucla.edu;sczhu@stat.ucla.edu;ywu@stat.ucla.edu,7;7;8,5;4;4,Accept (Poster),0,10,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",,-1;-1;-1;-1,15;15;15;15,-1;-1,usa,usa,n,
1640,ICLR,2019,Meta-Learning Update Rules for Unsupervised Representation Learning,Luke Metz;Niru Maheswaranathan;Brian Cheung;Jascha Sohl-Dickstein,lmetz@google.com;nirum@google.com;bcheung@berkeley.edu;jaschasd@google.com,8;8;8,3;4;3,Accept (Oral),0,3,1.0,yes,9/27/18,Google;Google;University of California Berkeley;Google,Meta-learning;unsupervised learning;representation learning,-1;-1;-1;-1,-1;-1;18;-1,-1;-1,NAN,NAN,n,6;5
1641,ICLR,2019,Discriminator Rejection Sampling,Samaneh Azadi;Catherine Olsson;Trevor Darrell;Ian Goodfellow;Augustus Odena,sazadi@berkeley.edu;catherio@google.com;trevor@eecs.berkeley.edu;goodfellow@google.com;augustusodena@google.com,7;6;6,4;3;4,Accept (Poster),0,9,1.0,yes,9/27/18,University of California Berkeley;Google;University of California Berkeley;Google;Google,GANs;rejection sampling,-1;-1;-1;-1;-1,18;-1;18;-1;-1,-1;-1,NAN,NAN,n,5
1642,ICLR,2019,TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer,Sicong Huang;Qiyang Li;Cem Anil;Xuchan Bao;Sageev Oore;Roger B. Grosse,huang@cs.toronto.edu;colinli@cs.toronto.edu;anilcem@cs.toronto.edu;jennybao@cs.toronto.edu;sageev@dal.ca;rgrosse@cs.toronto.edu,4;7;8,5;4;4,Accept (Poster),3,7,5.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto;University of Toronto;Dalhousie University;University of Toronto,Generative models;Timbre Transfer;Wavenet;CycleGAN,18;18;18;18;285;18,22;22;22;22;289;22,-1;-1,canada,ca,n,
1643,ICLR,2019,Smoothing the Geometry of Probabilistic Box Embeddings,Xiang Li;Luke Vilnis;Dongxu Zhang;Michael Boratko;Andrew McCallum,xiangl@cs.umass.edu;luke@cs.umass.edu;dongxuzhang@cs.umass.edu;mboratko@math.umass.edu;mccallum@cs.umass.edu,7;8;8,3;3;4,Accept (Oral),0,6,0.0,yes,9/27/18,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",embeddings;order embeddings;knowledge graph embedding;relational learning,27;27;27;27;27,191;191;191;191;191,-1;-1,usa,usa,n,10
1644,ICLR,2019,Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces,Senthil Purushwalkam;Abhinav Gupta;Danny Kaufman;Bryan Russell,spurushw@andrew.cmu.edu;abhinavg@cs.cmu.edu;dkaufman@adobe.com;brussell@adobe.com,8;6;7,4;3;4,Accept (Poster),0,8,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Adobe Systems;Adobe Systems,intuitive physics;visual prediction;surface normal;restitution;bounces,1;1;-1;-1,24;24;-1;-1,-1;-1,NAN,NAN,n,
1645,ICLR,2019,Critical Learning Periods in Deep Networks,Alessandro Achille;Matteo Rovere;Stefano Soatto,achille@cs.ucla.edu;matrovere@gmail.com;soatto@cs.ucla.edu,9;8;6,4;4;5,Accept (Poster),0,6,0.0,yes,9/27/18,"University of California, Los Angeles;;University of California, Los Angeles",Critical Period;Deep Learning;Information Theory;Artificial Neuroscience;Information Plasticity,-1;-1;-1,15;-1;15,-1;-1,usa,usa,n,
1646,ICLR,2019,GANSynth: Adversarial Neural Audio Synthesis,Jesse Engel;Kumar Krishna Agrawal;Shuo Chen;Ishaan Gulrajani;Chris Donahue;Adam Roberts,jesseengel@google.com;kumarkagrawal@gmail.com;chenshuo@google.com;igul222@gmail.com;christopherdonahue@gmail.com;adarob@google.com,6;7;8,3;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Google;University of California Berkeley;Google;Stanford University;Stanford University;Google,GAN;Audio;WaveNet;NSynth;Music,-1;-1;-1;4;4;-1,-1;18;-1;3;3;-1,-1;-1,NAN,NAN,n,5;4
1647,ICLR,2019,A Closer Look at Few-shot Classification,Wei-Yu Chen;Yen-Cheng Liu;Zsolt Kira;Yu-Chiang Frank Wang;Jia-Bin Huang,weiyuc@andrew.cmu.edu;ycliu@gatech.edu;zkira@gatech.edu;ycwang@ntu.edu.tw;jbhuang@vt.edu,6;6;6,2;5;4,Accept (Poster),0,7,12.0,yes,9/27/18,Carnegie Mellon University;Georgia Institute of Technology;Georgia Institute of Technology;Nanyang Technological University;Virginia Tech,few shot classification;meta-learning,1;13;13;44;77,24;33;33;52;-1,-1;-1,usa,usa,n,6;1
1648,ICLR,2019,Robustness May Be at Odds with Accuracy,Dimitris Tsipras;Shibani Santurkar;Logan Engstrom;Alexander Turner;Aleksander Madry,tsipras@mit.edu;shibani@mit.edu;engstrom@mit.edu;turneram@mit.edu;madry@mit.edu,8;7;8,3;4;2,Accept (Poster),0,5,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial examples;robust machine learning;robust optimization;deep feature representations,6;6;6;6;6,5;5;5;5;5,-1;-1,usa,usa,y,1;4
1649,ICLR,2019,Visceral Machines: Risk-Aversion in  Reinforcement Learning with Intrinsic Physiological Rewards,Daniel McDuff;Ashish Kapoor,damcduff@microsoft.com;akapoor@microsoft.com,6;6;7,4;4;5,Accept (Poster),0,4,0.0,yes,9/27/18,Microsoft;Microsoft,Reinforcement Learning;Simulation;Affective Computing,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1650,ICLR,2019,Diffusion Scattering Transforms on Graphs,Fernando Gama;Alejandro Ribeiro;Joan Bruna,fgama@seas.upenn.edu;aribeiro@seas.upenn.edu;bruna@cims.nyu.edu,7;6;9,3;4;5,Accept (Poster),0,7,0.0,yes,9/27/18,University of Pennsylvania;University of Pennsylvania;New York University,graph neural networks;deep learning;stability;scattering transforms;convolutional neural networks,21;21;24,10;10;27,-1;-1,usa,usa,y,2;10
1651,ICLR,2019,Learning Self-Imitating Diverse Policies,Tanmay Gangwani;Qiang Liu;Jian Peng,gangwan2@uiuc.edu;lqiang@cs.utexas.edu;jianpeng@illinois.edu,6;8;8,2;3;4,Accept (Poster),0,11,2.0,yes,9/27/18,"University of Illinois, Urbana-Champaign;University of Texas, Austin;University of Illinois, Urbana Champaign",Reinforcement-learning;Imitation-learning;Ensemble-training,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
1652,ICLR,2019,Adaptive Input Representations for Neural Language Modeling,Alexei Baevski;Michael Auli,alexei.b@gmail.com;michael.auli@gmail.com,7;8;8,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Facebook;Facebook,Neural language modeling,-1;-1,-1;-1,-1;-1,NAN,NAN,n,8;3
1653,ICLR,2019,Top-Down Neural Model For Formulae,Karel Chvalovsk√Ω,karel@chvalovsky.cz,6;6;6,2;3;4,Accept (Poster),0,5,0.0,yes,9/27/18,Czech Technical University in Prague,logic;formula;recursive neural networks;recurrent neural networks,169,740,-1,NAN,NAN,n,
1654,ICLR,2019,Deep learning generalizes because the parameter-function map is biased towards simple functions,Guillermo Valle-Perez;Chico Q. Camargo;Ard A. Louis,guillermo.valle@dtc.ox.ac.uk;chico.camargo@gmail.com;ard.louis@physics.ox.ac.uk,7;5;4,4;3;4,Accept (Poster),0,8,0.0,yes,9/27/18,University of Oxford;;University of Oxford,generalization;deep learning theory;PAC-Bayes;Gaussian processes;parameter-function map;simplicity bias,44;-1;44,1;-1;1,-1;-1,europe,uk,y,1
1655,ICLR,2019,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,Alex Wang;Amanpreet Singh;Julian Michael;Felix Hill;Omer Levy;Samuel R. Bowman,alexwang@nyu.edu;amanpreet@nyu.edu;julianjm@cs.washington.edu;felixhill@google.com;omerlevy@cs.washington.edu;bowman@nyu.edu,8;7;5,4;1;2,Accept (Poster),2,3,0.0,yes,9/27/18,New York University;New York University;University of Washington;Google;University of Washington;New York University,natural language understanding;multi-task learning;evaluation,24;24;10;-1;10;24,27;27;25;-1;25;27,-1;-1,usa,usa,n,3;1
1656,ICLR,2019,Learning to Navigate the Web,Izzeddin Gur;Ulrich Rueckert;Aleksandra Faust;Dilek Hakkani-Tur,izzeddingur@gmail.com;rueckert@google.com;sandrafaust@google.com;dilek@ieee.org,8;7;7,3;3;3,Accept (Poster),0,4,0.0,yes,9/27/18,Google;Google;Google;Google,navigating web pages;reinforcement learning;q learning;curriculum learning;meta training,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,6;3
1657,ICLR,2019,Learnable Embedding Space for Efficient Neural Architecture Compression,Shengcao Cao;Xiaofang Wang;Kris M. Kitani,caoshengcao@pku.edu.cn;xiaofan2@cs.cmu.edu;kkitani@cs.cmu.edu,6;7;5,3;4;3,Accept (Poster),1,15,11.0,yes,9/27/18,Peking University;Carnegie Mellon University;Carnegie Mellon University,Network Compression;Neural Architecture Search;Bayesian Optimization;Architecture Embedding,14;1;1,27;24;24,-1;-1,usa,usa,n,11
1658,ICLR,2019,Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions,Zaiyi Chen;Zhuoning Yuan;Jinfeng Yi;Bowen Zhou;Enhong Chen;Tianbao Yang,czy6516@hotmail.com;zhuoning-yuan@uiowa.edu;jinfengyi.ustc@gmail.com;bwen@jd.com;cheneh@ustc.edu.cn;tianbao-yang@uiowa.edu,6;8;6,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,University of Science and Technology of China;University of Iowa;JD AI Research;JD AI Research;University of Science and Technology of China;University of Iowa,optimization;sgd;adagrad,-1;169;-1;-1;-1;169,-1;223;-1;-1;132;223,-1;-1,europe,de,y,1;9
1659,ICLR,2019,Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning,Ilya Kostrikov;Kumar Krishna Agrawal;Debidatta Dwibedi;Sergey Levine;Jonathan Tompson,kostrikov@cs.nyu.edu;kumarkagrawal@gmail.com;debidatta@google.com;slevine@google.com;tompson@google.com,6;8;7,4;2;3,Accept (Poster),6,15,3.0,yes,9/27/18,New York University;University of California Berkeley;Google;Google;Google,deep learning;reinforcement learning;imitation learning;adversarial learning,24;-1;-1;-1;-1,27;18;-1;-1;-1,-1;-1,NAN,NAN,n,4
1660,ICLR,2019,Learning concise representations for regression by evolving networks of trees,William La Cava;Tilak Raj Singh;James Taggart;Srinivas Suri;Jason H. Moore,lacava@upenn.edu;tilakraj@seas.upenn.edu;surisr@seas.upenn.edu;jhmoore@upenn.edu,6;7;8,3;1;4,Accept (Poster),0,5,0.0,yes,9/27/18,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,regression;stochastic optimization;evolutionary compution;feature engineering,21;21;21;21,10;10;10;10,-1;-1,usa,usa,n,1
1661,ICLR,2019,Interpolation-Prediction Networks for Irregularly Sampled Time Series,Satya Narayan Shukla;Benjamin Marlin,snshukla@cs.umass.edu;marlin@cs.umass.edu,6;6;6,4;4;4,Accept (Poster),0,10,0.0,yes,9/27/18,"University of Massachusetts, Amherst;University of Massachusetts, Amherst",irregular sampling;multivariate time series;supervised learning;interpolation;missing data,27;27,191;191,-1;-1,usa,usa,n,
1662,ICLR,2019,GAN Dissection: Visualizing and Understanding Generative Adversarial Networks,David Bau;Jun-Yan Zhu;Hendrik Strobelt;Bolei Zhou;Joshua B. Tenenbaum;William T. Freeman;Antonio Torralba,davidbau@csail.mit.edu;junyanz@csail.mit.edu;hendrik.strobelt@ibm.com;bzhou@csail.mit.edu;jbt@csail.mit.edu;billf@csail.mit.edu;torralba@csail.mit.edu,7;7;8,3;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,GANs;representation;interpretability;causality,6;6;-1;6;6;6;6,5;5;-1;5;5;5;5,-1;-1,usa,usa,n,2;5;4
1663,ICLR,2019,Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience,Vaishnavh Nagarajan;Zico Kolter,vaishnavh@cs.cmu.edu;zkolter@cs.cmu.edu,5;7;8;7,4;3;5;2,Accept (Poster),0,30,1.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University,generalization;PAC-Bayes;SGD;learning theory;implicit regularization,1;1,24;24,-1;-1,usa,usa,y,11;1
1664,ICLR,2019,Deep reinforcement learning with relational inductive biases,Vinicius Zambaldi;David Raposo;Adam Santoro;Victor Bapst;Yujia Li;Igor Babuschkin;Karl Tuyls;David Reichert;Timothy Lillicrap;Edward Lockhart;Murray Shanahan;Victoria Langston;Razvan Pascanu;Matthew Botvinick;Oriol Vinyals;Peter Battaglia,vzambaldi@google.com;draposo@google.com;adamsantoro@google.com;vbapst@google.com;yujiali@google.com;ibab@google.com;karltuyls@google.com;reichert@google.com;countzero@google.com;locked@google.com;mshanahan@google.com;vlangston@google.com;razp@google.com;botvinick@google.com;vinyals@google.com;peterbattaglia@google.com,6;7;7,4;3;4,Accept (Poster),0,7,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,relational reasoning;reinforcement learning;graph neural networks;starcraft;generalization;inductive bias,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1665,ICLR,2019,Tree-Structured Recurrent Switching Linear Dynamical Systems for Multi-Scale Modeling,Josue Nassar;Scott Linderman;Monica Bugallo;Il Memming Park,josue.nassar@stonybrook.edu;scott.linderman@columbia.edu;monica.bugallo@stonybrook.edu;memming.park@stonybrook.edu,7;7;6,2;2;4,Accept (Poster),0,7,0.0,yes,9/27/18,"State University of New York, Stony Brook;Columbia University;State University of New York, Stony Brook;State University of New York, Stony Brook",machine learning;bayesian statistics;dynamical systems,-1;21;-1;-1,-1;14;-1;-1,-1;-1,NAN,NAN,y,11
1666,ICLR,2019,Biologically-Plausible Learning Algorithms Can Scale to Large Datasets,Will Xiao;Honglin Chen;Qianli Liao;Tomaso Poggio,xiaow@fas.harvard.edu;chenhonglin@g.ucla.edu;lql@mit.edu;tp@csail.mit.edu,9;9;4,5;4;4,Accept (Poster),0,14,0.0,yes,9/27/18,"Harvard University;University of California, Los Angeles;Massachusetts Institute of Technology;Massachusetts Institute of Technology",biologically plausible learning algorithm;ImageNet;sign-symmetry;feedback alignment,50;-1;6;6,6;15;5;5,-1;-1,usa,usa,n,
1667,ICLR,2019,Generative predecessor models for sample-efficient imitation learning,Yannick Schroecker;Mel Vecerik;Jon Scholz,yannickschroecker@gatech.edu;vec@google.com;jscholz@google.com,7;5;6,4;5;3,Accept (Poster),0,12,0.0,yes,9/27/18,Georgia Institute of Technology;Google;Google,Imitation Learning;Generative Models;Deep Learning,13;-1;-1,33;-1;-1,-1;-1,NAN,NAN,n,5
1668,ICLR,2019,Kernel RNN Learning (KeRNL),Christopher Roth;Ingmar Kanitscheider;Ila Fiete,christopher_roth@utexas.edu;ingmar@openai.com;fiete@mit.edu,7;5;6,4;1;4,Accept (Poster),0,3,0.0,yes,9/27/18,"University of Texas, Austin;OpenAI;Massachusetts Institute of Technology",RNNs;Biologically plausible learning rules;Algorithm;Neural Networks;Supervised Learning,-1;-1;6,-1;-1;5,-1;-1,usa,usa,n,
1669,ICLR,2019,Integer Networks for Data Compression with Latent-Variable Models,Johannes Ball√©;Nick Johnston;David Minnen,jballe@google.com;nickj@google.com;dminnen@google.com,7;8;6,3;3;3,Accept (Poster),0,9,1.0,yes,9/27/18,Google;Google;Google,data compression;variational models;network quantization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1670,ICLR,2019,Sample Efficient Imitation Learning for Continuous Control,Fumihiro Sasaki;Tetsuya Yohira;Atsuo Kawaguchi,fumihiro.fs.sasaki@jp.ricoh.com,7;5;5;5,5;4;5;5,Accept (Poster),0,2,0.0,yes,9/27/18,"Ricoh software limited, Beijing",Imitation Learning;Continuous Control;Reinforcement Learning;Inverse Reinforcement Learning;Conditional Generative Adversarial Network,-1,-1,-1;-1,NAN,NAN,n,5;4
1671,ICLR,2019,Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs,Ryan L. Murphy;Balasubramaniam Srinivasan;Vinayak Rao;Bruno Ribeiro,murph213@purdue.edu;bsriniv@purdue.edu;varao@purdue.edu;ribeiro@cs.purdue.edu,5;7;8,4;4;4,Accept (Poster),0,8,1.0,yes,9/27/18,Purdue University;Purdue University;Purdue University;Purdue University,representation learning;permutation invariance;set functions;feature pooling,24;24;24;24,60;60;60;60,-1;-1,usa,usa,y,
1672,ICLR,2019,Modeling Uncertainty with Hedged Instance Embeddings,Seong Joon Oh;Kevin P. Murphy;Jiyan Pan;Joseph Roth;Florian Schroff;Andrew C. Gallagher,coallaoh@linecorp.com;agallagher@google.com;kpmurphy@google.com;fschroff@google.com;jiyanpan@google.com;josephroth@google.com,7;7;7,5;3;3,Accept (Poster),0,7,0.0,yes,9/27/18,LINE;Google;Google;Google;Google;Google,uncertainty;instance embedding;metric learning;probabilistic embedding,-1;-1;-1;-1;-1;-1,382;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1673,ICLR,2019,Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks,Reinhard Heckel;Paul Hand,rh43@rice.edu;p.hand@northeastern.edu,7;8;8,3;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Rice University;Northeastern University,natural image model;image prior;under-determined neural networks;untrained network;non-convolutional network;denoising;inverse problem,94;15,86;839,-1;-1,usa,usa,y,
1674,ICLR,2019,Probabilistic Planning with Sequential Monte Carlo methods,Alexandre Piche;Valentin Thomas;Cyril Ibrahim;Yoshua Bengio;Chris Pal,alexandrelpiche@gmail.com;vltn.thomas@gmail.com;cyril.ibrahim@elementai.com;yoshua.umontreal@gmail.com;christopher.pal@polymtl.ca,5;6;8,4;4;4,Accept (Poster),0,14,5.0,yes,9/27/18,University of Montreal;;Element AI;University of Montreal;Polytechnique Montreal,control as inference;probabilistic planning;sequential monte carlo;model based reinforcement learning,116;-1;-1;116;285,108;-1;-1;108;-1,-1;-1,canada,ca,n,11
1675,ICLR,2019,Random mesh projectors for inverse problems,Konik Kothari*;Sidharth Gupta*;Maarten v. de Hoop;Ivan Dokmanic,kkothar3@illinois.edu;gupta67@illinois.edu;mdehoop@rice.edu;dokmanic@illinois.edu,6;7;4,4;4;3,Accept (Poster),0,19,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Rice University;University of Illinois, Urbana Champaign",imaging;inverse problems;subspace projections;random Delaunay triangulations;CNN;geophysics;regularization,-1;-1;94;-1,-1;-1;86;-1,-1;-1,usa,usa,n,
1676,ICLR,2019,A Direct Approach to Robust Deep Learning Using Adversarial Networks,Huaxia Wang;Chun-Nam Yu,hwang38@stevens.edu;cnyu@cs.cornell.edu,5;7;6,4;3;3,Accept (Poster),3,6,0.0,yes,9/27/18,Stevens Institute of Technology;Cornell University,deep learning;adversarial learning;generative adversarial networks,169;6,512;19,-1;-1,usa,usa,n,5;4
1677,ICLR,2019,"Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning",Anusha Nagabandi;Ignasi Clavera;Simin Liu;Ronald S. Fearing;Pieter Abbeel;Sergey Levine;Chelsea Finn,nagaban2@berkeley.edu;iclavera@berkeley.edu;simin.liu@berkeley.edu;ronf@berkeley.edu;pabbeel@berkeley.edu;svlevine@eecs.berkeley.edu;cbfinn@eecs.berkeley.edu,7;7;2,3;5;5,Accept (Poster),2,10,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,meta-learning;reinforcement learning;meta reinforcement learning;online adaptation,-1;-1;-1;-1;-1;-1;-1,18;18;18;18;18;18;18,-1;-1,usa,usa,n,6;2
1678,ICLR,2019,Robust Conditional Generative Adversarial Networks,Grigorios G. Chrysos;Jean Kossaifi;Stefanos Zafeiriou,greggchrysos@gmail.com;jean.kossaifi@gmail.com;s.zafeiriou@imperial.ac.uk,6;6;6,4;4;4,Accept (Poster),0,10,1.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;NVIDIA;Imperial College London,conditional GAN;unsupervised pathway;autoencoder;robustness,-1;-1;47,-1;-1;8,-1;-1,europe,uk,n,2;1;5;4
1679,ICLR,2019,signSGD with Majority Vote is Communication Efficient and Fault Tolerant,Jeremy Bernstein;Jiawei Zhao;Kamyar Azizzadenesheli;Anima Anandkumar,bernstein@caltech.edu;jiaweizhao.zjw@qq.com;kazizzad@uci.edu;anima@caltech.edu,6;6;7,5;5;4,Accept (Poster),1,9,1.0,yes,9/27/18,"California Institute of Technology;California Institute of Technology;University of California, Irvine;California Institute of Technology",large-scale learning;distributed systems;communication efficiency;convergence rate analysis;robust optimisation,136;136;-1;136,3;3;99;3,-1;-1,usa,usa,y,1;4
1680,ICLR,2019,The Singular Values of Convolutional Layers,Hanie Sedghi;Vineet Gupta;Philip M. Long,hsedghi@google.com;vineet@google.com;plong@google.com,8;4;7,4;5;3,Accept (Poster),0,24,2.0,yes,9/27/18,Google;Google;Google,singular values;operator norm;convolutional layers;regularization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
1681,ICLR,2019,Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL,Anusha Nagabandi;Chelsea Finn;Sergey Levine,nagaban2@berkeley.edu;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,7;7;7,3;3;3,Accept (Poster),0,3,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,meta-learning;model-based;reinforcement learning;online learning;adaptation,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,6
1682,ICLR,2019,InfoBot: Transfer and Exploration via the Information Bottleneck,Anirudh Goyal;Riashat Islam;DJ Strouse;Zafarali Ahmed;Hugo Larochelle;Matthew Botvinick;Yoshua Bengio;Sergey Levine,anirudhgoyal9119@gmail.com;riashat.islam@mail.mcgill.ca;danieljstrouse@gmail.com;zafarali.ahmed@mail.mcgill.ca;hugolarochelle@google.com;botvinick@google.com;svlevine@eecs.berkeley.edu;yoshua.bengio@mila.quebec,7;7;3,3;3;3,Accept (Poster),0,28,1.0,yes,9/27/18,University of Montreal;McGill University;Google;McGill University;Google;Google;University of California Berkeley;Mila,Information bottleneck;policy transfer;policy generalization;exploration,-1;94;-1;94;-1;-1;-1;136,-1;42;-1;42;-1;-1;18;314,-1;-1,NAN,NAN,n,
1683,ICLR,2019,Optimal Control Via Neural Networks: A Convex Approach,Yize Chen;Yuanyuan Shi;Baosen Zhang,yizechen@uw.edu;yyshi@uw.edu;zhangbao@uw.edu,6;8;7,3;4;4,Accept (Poster),1,10,1.0,yes,9/27/18,"University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle",optimal control;input convex neural network;convex optimization,10;10;10,25;25;25,-1;-1,NAN,NAN,y,
1684,ICLR,2019,Preventing Posterior Collapse with delta-VAEs,Ali Razavi;Aaron van den Oord;Ben Poole;Oriol Vinyals,alirazavi@google.com;avdnoord@google.com;pooleb@google.com;vinyals@google.com,6;7;6,3;4;3,Accept (Poster),2,4,1.0,yes,9/27/18,Google;Google;Google;Google,Posterior Collapse;VAE;Autoregressive Models,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
1685,ICLR,2019,Combinatorial Attacks on Binarized Neural Networks,Elias B Khalil;Amrita Gupta;Bistra Dilkina,lyes@gatech.edu;agupta375@gatech.edu;dilkina@usc.edu,5;6;7,4;4;4,Accept (Poster),0,10,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;University of Southern California,binarized neural networks;combinatorial optimization;integer programming,13;13;27,33;33;66,-1;-1,usa,usa,n,4
1686,ICLR,2019,How Powerful are Graph Neural Networks?,Keyulu Xu*;Weihua Hu*;Jure Leskovec;Stefanie Jegelka,keyulu@mit.edu;weihuahu@stanford.edu;jure@cs.stanford.edu;stefje@mit.edu,7;7;8,5;5;5,Accept (Oral),22,30,4.0,yes,9/27/18,Massachusetts Institute of Technology;Stanford University;Stanford University;Massachusetts Institute of Technology,graph neural networks;theory;deep learning;representational power;graph isomorphism;deep multisets,6;4;4;6,5;3;3;5,-1;-1,usa,usa,y,10
1687,ICLR,2019,On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization,Xiangyi Chen;Sijia Liu;Ruoyu Sun;Mingyi Hong,chen5719@umn.edu;sijia.liu@ibm.com;ruoyus@illinois.edu;mhong@umn.edu,7;7;6,3;2;3,Accept (Poster),0,8,1.0,yes,9/27/18,"University of Minnesota, Minneapolis;International Business Machines;University of Illinois, Urbana Champaign;University of Minnesota, Minneapolis",nonconvex optimization;Adam;convergence analysis,67;-1;-1;67,56;-1;-1;56,-1;-1,NAN,NAN,y,9
1688,ICLR,2019,Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks,Amanpreet Singh;Tushar Jain;Sainbayar Sukhbaatar,amanpreet@nyu.edu;tushar@nyu.edu;sainbar@cs.nyu.edu,7;6;6,3;3;3,Accept (Poster),0,12,0.0,yes,9/27/18,New York University;New York University;New York University,multiagent;communication;competitive;cooperative;continuous;emergent;reinforcement learning,24;24;24,27;27;27,-1;-1,usa,usa,n,9
1689,ICLR,2019,signSGD via Zeroth-Order Oracle,Sijia Liu;Pin-Yu Chen;Xiangyi Chen;Mingyi Hong,sijia.liu@ibm.com;pin-yu.chen@ibm.com;chen5719@umn.edu;mhong@umn.edu,7;8;6,5;3;2,Accept (Poster),0,11,0.0,yes,9/27/18,"International Business Machines;International Business Machines;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis",nonconvex optimization;zeroth-order algorithm;black-box adversarial attack,-1;-1;67;67,-1;-1;56;56,-1;-1,NAN,NAN,y,9;4
1690,ICLR,2019,Information asymmetry in KL-regularized RL,Alexandre Galashov;Siddhant M. Jayakumar;Leonard Hasenclever;Dhruva Tirumala;Jonathan Schwarz;Guillaume Desjardins;Wojciech M. Czarnecki;Yee Whye Teh;Razvan Pascanu;Nicolas Heess,agalashov@google.com;sidmj@google.com;leonardh@google.com;dhruvat@google.com;schwarzjn@google.com;gdesjardins@google.com;lejlot@google.com;ywteh@google.com;razp@google.com;heess@google.com,7;5;7,3;5;4,Accept (Poster),0,4,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Deep Reinforcement Learning;Continuous Control;RL as Inference,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1691,ICLR,2019,Cost-Sensitive Robustness against Adversarial Examples,Xiao Zhang;David Evans,xz7bc@virginia.edu;evans@virginia.edu,5;8;5,4;3;3,Accept (Poster),0,12,0.0,yes,9/27/18,University of Virginia;University of Virginia,Certified robustness;Adversarial examples;Cost-sensitive learning,59;59,113;113,-1;-1,usa,usa,n,4
1692,ICLR,2019,Learning deep representations by mutual information estimation and maximization,R Devon Hjelm;Alex Fedorov;Samuel Lavoie-Marchildon;Karan Grewal;Phil Bachman;Adam Trischler;Yoshua Bengio,devon.hjelm@microsoft.com;eidos92@gmail.com;samuel.lavoie-marchildon@umontreal.ca;karang@cs.toronto.edu;phil.bachman@gmail.com;adam.trischler@microsoft.com;yoshua.umontreal@gmail.com,7;9;7,5;3;4,Accept (Oral),2,7,0.0,yes,9/27/18,Microsoft;Georgia Institute of Technology;University of Montreal;University of Toronto;Microsoft;Microsoft;University of Montreal,representation learning;unsupervised learning;deep learning,-1;13;116;18;-1;-1;116,-1;33;108;22;-1;-1;108,-1;-1,canada,ca,n,4
1693,ICLR,2019,A Generative Model For Electron Paths,John Bradshaw;Matt J. Kusner;Brooks Paige;Marwin H. S. Segler;Jos√© Miguel Hern√°ndez-Lobato,jab255@cam.ac.uk;mkusner@turing.ac.uk;bpaige@turing.ac.uk;marwin.segler@benevolent.ai;jmh233@cam.ac.uk,8;4;8,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,University of Cambridge;Alan Turing Institute;Alan Turing Institute;BenevolentAI;University of Cambridge,Molecules;Reaction Prediction;Graph Neural Networks;Deep Generative Models,77;-1;-1;-1;77,2;-1;-1;-1;2,-1;-1,europe,uk,n,5
1694,ICLR,2019,Whitening and Coloring Batch Transform for GANs,Aliaksandr Siarohin;Enver Sangineto;Nicu Sebe,aliaksandr.siarohin@unitn.it;enver.sangineto@unitn.it;niculae.sebe@unitn.it,7;7;7,4;2;4,Accept (Poster),0,13,0.0,yes,9/27/18,University of Trento;University of Trento;University of Trento,Generative Adversarial Networks;conditional GANs;Batch Normalization,136;136;136,258;258;258,-1;-1,europe,gr,n,5;4
1695,ICLR,2019,Learning protein sequence embeddings using information from structure,Tristan Bepler;Bonnie Berger,tbepler@mit.edu;bab@mit.edu,8;7;7,4;3;4,Accept (Poster),0,8,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,sequence embedding;sequence alignment;RNN;LSTM;protein structure;amino acid sequence;contextual embeddings;transmembrane prediction,6;6,5;5,-1;-1,usa,usa,n,
1696,ICLR,2019,DARTS: Differentiable Architecture Search,Hanxiao Liu;Karen Simonyan;Yiming Yang,hanxiaol@cs.cmu.edu;simonyan@google.com;yiming@cs.cmu.edu,6;7;8,2;5;3,Accept (Poster),24,10,6.0,yes,9/27/18,Carnegie Mellon University;Google;Carnegie Mellon University,deep learning;autoML;neural architecture search;image classification;language modeling,1;-1;1,24;-1;24,-1;-1,usa,usa,n,3
1697,ICLR,2019,Representation Degeneration Problem in Training Natural Language Generation Models,Jun Gao;Di He;Xu Tan;Tao Qin;Liwei Wang;Tieyan Liu,jungao@cs.toronto.edu;dihe@microsoft.com;xu.tan@microsoft.com;taoqin@microsoft.com;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,7;7;7,4;3;3,Accept (Poster),0,5,0.0,yes,9/27/18,University of Toronto;Microsoft;Microsoft;Microsoft;Peking University;Microsoft,Natural Language Processing;Representation Learning,18;-1;-1;-1;14;-1,22;-1;-1;-1;27;-1,-1;-1,NAN,NAN,n,3
1698,ICLR,2019,Structured Adversarial Attack:  Towards General Implementation and Better Interpretability,Kaidi Xu;Sijia Liu;Pu Zhao;Pin-Yu Chen;Huan Zhang;Quanfu Fan;Deniz Erdogmus;Yanzhi Wang;Xue Lin,xu.kaid@husky.neu.edu;sijia.liu@ibm.com;zhao.pu@husky.neu.edu;pin-yu.chen@ibm.com;ecezhang@ucdavis.edu;qfan@us.ibm.com;erdogmus@ece.neu.edu;yanz.wang@northeastern.edu;xue.lin@northeastern.edu,6;7;7,2;2;3,Accept (Poster),0,8,0.0,yes,9/27/18,"Northeastern University;International Business Machines;Northeastern University;International Business Machines;University of California, Davis;International Business Machines;Northeastern University;Northeastern University;Northeastern University",,15;-1;15;-1;-1;-1;15;15;15,839;-1;839;-1;54;-1;839;839;839,-1;-1,usa,usa,y,4
1699,ICLR,2019,Learning sparse relational transition models,Victoria Xia;Zi Wang;Kelsey Allen;Tom Silver;Leslie Pack Kaelbling,victoria.f.xia281@gmail.com;ziw@mit.edu;krallen@mit.edu;tslvr@mit.edu;lpk@csail.mit.edu,6;7;8,4;2;3,Accept (Poster),0,0,1.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deictic reference;relational model;rule-based transition model,-1;6;6;6;6,-1;5;5;5;5,-1;-1,usa,usa,n,
1700,ICLR,2019,ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware,Han Cai;Ligeng Zhu;Song Han,hancai@mit.edu;ligeng@mit.edu;songhan@mit.edu,7;6;6,2;4;2,Accept (Poster),1,20,7.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neural Architecture Search;Efficient Neural Networks,6;6;6,5;5;5,-1;-1,usa,usa,n,
1701,ICLR,2019,No Training Required: Exploring Random Encoders for Sentence Classification,John Wieting;Douwe Kiela,jwieting@cs.cmu.edu;dkiela@fb.com,7;7;8,4;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,Carnegie Mellon University;Facebook,sentence embeddings,1;-1,24;-1,-1;-1,NAN,NAN,n,3
1702,ICLR,2019,Equi-normalization of Neural Networks,Pierre Stock;Benjamin Graham;R√©mi Gribonval;Herv√© J√©gou,pstock@fb.com;benjamingraham@fb.com;remi.gribonval@inria.fr;rvj@fb.com,7;7;5,4;3;3,Accept (Poster),2,6,1.0,yes,9/27/18,Facebook;Facebook;INRIA;Facebook,convolutional neural networks;Normalization;Sinkhorn;Regularization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,
1703,ICLR,2019,Deep Frank-Wolfe For Neural Network Optimization,Leonard Berrada;Andrew Zisserman;M. Pawan Kumar,lberrada@robots.ox.ac.uk;az@robots.ox.ac.uk;pawan@robots.ox.ac.uk,7;7;8,4;5;4,Accept (Poster),0,8,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,optimization;conditional gradient;Frank-Wolfe;SVM,44;44;44,1;1;1,-1;-1,europe,uk,y,1;9
1704,ICLR,2019,Learning what and where to attend,Drew Linsley;Dan Shiebler;Sven Eberhardt;Thomas Serre,drewlinsley@gmail.com;danshiebler@gmail.com;sven2sven2sven2@gmail.com;thomas_serre@brown.edu,6;6;8,4;3;3,Accept (Poster),0,9,0.0,yes,9/27/18,Brown University;University of Oxford;;Brown University,Attention models;human feature importance;object recognition;cognitive science,-1;44;-1;86,-1;1;-1;50,-1;-1,usa,usa,n,8;1
1705,ICLR,2019,Minimum Divergence vs. Maximum Margin: an Empirical Comparison on Seq2Seq Models,Huan Zhang;Hai Zhao,zhanghuan0468@gmail.com;zhaohai@cs.sjtu.edu.cn,7;7;5,4;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University,sequence to sequence;training criteria,-1;36,-1;188,-1;-1,asia,cn,n,3
1706,ICLR,2019,Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality,Taiji Suzuki,taiji@mist.i.u-tokyo.ac.jp,8;6;6,2;2;2,Accept (Poster),0,7,0.0,yes,9/27/18,The University of Tokyo,deep learning theory;approximation analysis;generalization error analysis;Besov space;minimax optimality,59,45,-1,NAN,NAN,y,3;9
1707,ICLR,2019,Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs,Sachin Kumar;Yulia Tsvetkov,sachink@cs.cmu.edu;ytsvetko@cs.cmu.edu,6;6;7,5;4;4,Accept (Poster),6,5,5.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University,Language Generation;Regression;Word Embeddings;Machine Translation,1;1,24;24,-1;-1,usa,usa,n,3
1708,ICLR,2019,Feed-forward Propagation in Probabilistic Neural Networks with Categorical and Max Layers,Alexander Shekhovtsov;Boris Flach,shekhovtsov@gmail.com;bflach@inf.tu-dresden.de,6;6;6,3;5;4,Accept (Poster),0,7,0.0,yes,9/27/18,Czech Technical University in Prague;TU Dresden,probabilistic neural network;uncertainty;dropout;bayesian;softmax;argmax;logsumexp,169;169,740;155,-1;-1,europe,de,y,
1709,ICLR,2019,Generative Code Modeling with Graphs,Marc Brockschmidt;Miltiadis Allamanis;Alexander L. Gaunt;Oleksandr Polozov,mabrocks@microsoft.com;miallama@microsoft.com;algaunt@microsoft.com;polozov@microsoft.com,7;7;7,5;4;4,Accept (Poster),0,14,0.0,yes,9/27/18,Microsoft;Microsoft;Microsoft;Microsoft,Generative Model;Source Code;Graph Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,10;5
1710,ICLR,2019,Do Deep Generative Models Know What They Don't Know? ,Eric Nalisnick;Akihiro Matsukawa;Yee Whye Teh;Dilan Gorur;Balaji Lakshminarayanan,e.nalisnick@eng.cam.ac.uk;amatsukawa@google.com;ywteh@google.com;dilang@google.com;balajiln@google.com,7;6;7,4;4;3,Accept (Poster),2,18,1.0,yes,9/27/18,University of Cambridge;Google;Google;Google;Google,deep generative models;out-of-distribution inputs;flow-based models;uncertainty;density,77;-1;-1;-1;-1,2;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
1711,ICLR,2019,Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation,Soochan Lee;Junsoo Ha;Gunhee Kim,soochan.lee@vision.snu.ac.kr;kuc2477@gmail.com;gunhee@snu.ac.kr,4;8;7,5;4;3,Accept (Poster),0,5,3.0,yes,9/27/18,Seoul National University;;Seoul National University,conditional GANs;conditional image generation;multimodal generation;reconstruction loss;maximum likelihood estimation;moment matching,36;-1;36,74;-1;74,-1;-1,asia,kr,n,1;5
1712,ICLR,2019,Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks,Jose Oramas;Kaili Wang;Tinne Tuytelaars,jose.oramas@esat.kuleuven.be;kaili.wang@esat.kuleuven.be;tinne.tuytelaars@esat.kuleuven.be,8;5;4,4;3;5,Accept (Poster),0,6,0.0,yes,9/27/18,KU Leuven;KU Leuven;KU Leuven,model explanation;model interpretation;explainable ai;evaluation,136;136;136,47;47;47,-1;-1,europe,be,n,
1713,ICLR,2019,Learning Finite State Representations of Recurrent Policy Networks,Anurag Koul;Alan Fern;Sam Greydanus,koula@oregonstate.edu;alan.fern@oregonstate.edu;sgrey@google.com,7;7;6,3;5;3,Accept (Poster),0,9,0.0,yes,9/27/18,Oregon State University;Oregon State University;Google,recurrent neural networks;finite state machine;quantization;interpretability;autoencoder;moore machine;reinforcement learning;imitation learning;representation;Atari;Tomita,77;77;-1,318;318;-1,-1;-1,NAN,NAN,n,
1714,ICLR,2019,Human-level Protein Localization with Convolutional Neural Networks,Elisabeth Rumetshofer;Markus Hofmarcher;Clemens R√∂hrl;Sepp Hochreiter;G√ºnter Klambauer,rumetshofer@ml.jku.at;hofmarcher@ml.jku.at;clemens.roehrl@meduniwien.ac.at;hochreit@ml.jku.at;klambauer@ml.jku.at,4;5;8,4;3;4,Accept (Poster),0,4,0.0,yes,9/27/18,Johannes Kepler University Linz;Johannes Kepler University Linz;Medical University of Vienna;Johannes Kepler University Linz;Johannes Kepler University Linz,Convolutional Neural Networks;High-resolution images;Multiple-Instance Learning;Microscopy Imaging;Protein Localization,-1;-1;169;-1;-1,-1;-1;257;-1;-1,-1;-1,NAN,NAN,n,
1715,ICLR,2019,Value Propagation Networks,Nantas Nardelli;Gabriel Synnaeve;Zeming Lin;Pushmeet Kohli;Philip H. S. Torr;Nicolas Usunier,nantas@robots.ox.ac.uk;gab@fb.com;zlin@fb.com;pushmeet@google.com;philip.torr@eng.ox.ac.uk;usunier@fb.com,6;7;7,3;3;3,Accept (Poster),0,3,0.0,yes,9/27/18,University of Oxford;Facebook;Facebook;Google;University of Oxford;Facebook,Reinforcement Learning;Value Iteration;Navigation;Convolutional Neural Networks;Learning to plan,44;-1;-1;-1;44;-1,1;-1;-1;-1;1;-1,-1;-1,NAN,NAN,n,
1716,ICLR,2019,Adversarial Attacks on Graph Neural Networks via Meta Learning,Daniel Z√ºgner;Stephan G√ºnnemann,zuegnerd@in.tum.de;guennemann@in.tum.de,7;7;6,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Technical University Munich;Technical University Munich,graph mining;adversarial attacks;meta learning;graph neural networks;node classification,-1;-1,-1;-1,-1;-1,NAN,NAN,n,10;4
1717,ICLR,2019,Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering,Xiaopeng Li;Zhourong Chen;Leonard K. M. Poon;Nevin L. Zhang,xlibo@cse.ust.hk;zchenbb@cse.ust.hk;kmpoon@eduhk.hk;lzhang@cse.ust.hk,7;7;8,3;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Education University of Hong Kong;The Hong Kong University of Science and Technology,latent tree model;variational autoencoder;deep learning;latent variable model;bayesian network;structure learning;stepwise em;message passing;graphical model;multidimensional clustering;unsupervised learning,-1;-1;94;-1,44;44;40;44,-1;-1,NAN,NAN,n,5
1718,ICLR,2019,Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy,Yuan Xie;Boyi Liu;Qiang Liu;Zhaoran Wang;Yuan Zhou;Jian Peng,xieyuan@umail.iu.edu;boyiliu2018@u.northwestern.edu;lqiang@cs.utexas.edu;zhaoranwang@gmail.com;yzhoucs@iu.edu;jianpeng@illinois.edu,6;8;6,4;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,"Indiana University, Bloomington;Northwestern University;University of Texas, Austin;Northwestern University;Indiana University, Bloomington;University of Illinois, Urbana Champaign",Causal inference;Policy Optimization;Non-asymptotic analysis,67;50;-1;50;67;-1,117;20;-1;20;117;-1,-1;-1,usa,usa,y,1
1719,ICLR,2019,SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY,Namhoon Lee;Thalaiyasingam Ajanthan;Philip Torr,namhoon@robots.ox.ac.uk;ajanthan@robots.ox.ac.uk;phst@robots.ox.ac.uk,8;7;9,5;4;4,Accept (Poster),8,15,4.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,neural network pruning;connection sensitivity,44;44;44,1;1;1,-1;-1,europe,uk,n,
1720,ICLR,2019,Generating Multi-Agent Trajectories using Programmatic Weak Supervision,Eric Zhan;Stephan Zheng;Yisong Yue;Long Sha;Patrick Lucey,ezhan@caltech.edu;stzheng@caltech.edu;yyue@caltech.edu;lsha@stats.com;plucey@stats.com,7;6;6,3;3;3,Accept (Poster),0,4,0.0,yes,9/27/18,California Institute of Technology;California Institute of Technology;California Institute of Technology;STATS;STATS,deep learning;generative models;imitation learning;hierarchical methods;data programming;weak supervision;spatiotemporal,136;136;136;-1;-1,3;3;3;-1;-1,-1;-1,asia,sg,n,5
1721,ICLR,2019,Learning to Represent Edits,Pengcheng Yin;Graham Neubig;Miltiadis Allamanis;Marc Brockschmidt;Alexander L. Gaunt,pcyin@cs.cmu.edu;gneubig@cs.cmu.edu;miallama@microsoft.com;mabrocks@microsoft.com;algaunt@microsoft.com,6;7;6,3;3;4,Accept (Poster),0,13,2.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Microsoft;Microsoft;Microsoft,Representation Learning;Source Code;Natural Language;edit,1;1;-1;-1;-1,24;24;-1;-1;-1,-1;-1,NAN,NAN,n,3
1722,ICLR,2019,Transfer Learning for Sequences via Learning to Collocate,Wanyun Cui;Guangyu Zheng;Zhiqiang Shen;Sihang Jiang;Wei Wang,cui.wanyun@sufe.edu.cn;simonzgy@outlook.com;shen54@illinois.edu;tedjiangfdu@gmail.com;weiwang1@fudan.edu.cn,5;6;6,4;4;3,Accept (Poster),0,7,5.0,yes,9/27/18,"University of Science and Technology of China;;University of Illinois, Urbana Champaign;;Fudan University",transfer learning;recurrent neural network;attention;natural language processing,-1;-1;-1;-1;67,132;-1;-1;-1;116,-1;-1,asia,cn,n,6;3
1723,ICLR,2019,Multi-Agent Dual Learning,Yiren Wang;Yingce Xia;Tianyu He;Fei Tian;Tao Qin;ChengXiang Zhai;Tie-Yan Liu,yiren@illinois.edu;yingce.xia@gmail.com;hetianyu@mail.ustc.edu.cn;fetia@microsoft.com;taoqin@microsoft.com;czhai@illinois.edu;tie-yan.liu@microsoft.com,6;6;6,2;3;4,Accept (Poster),4,8,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;Microsoft;University of Science and Technology of China;Microsoft;Microsoft;University of Illinois, Urbana Champaign;Microsoft",Dual Learning;Machine Learning;Neural Machine Translation,-1;-1;-1;-1;-1;-1;-1,-1;-1;132;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;2;3
1724,ICLR,2019,On the Sensitivity of Adversarial Robustness to Input Data Distributions,Gavin Weiguang Ding;Kry Yik Chau Lui;Xiaomeng Jin;Luyu Wang;Ruitong Huang,gavin.ding@borealisai.com;yikchau.y.lui@borealisai.com;tracy.jin@mail.utoronto.ca;luyu.wang@borealisai.com;ruitong.huang@borealisai.com,7;5;7,3;4;2,Accept (Poster),0,3,0.0,yes,9/27/18,Borealis AI;Borealis AI;Toronto University;Borealis AI;Borealis AI,adversarial robustness;adversarial training;PGD training;adversarial perturbation;input data distribution,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,4
1725,ICLR,2019,GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING,Jacob Menick;Nal Kalchbrenner,jmenick@google.com;nalk@google.com,9;10;7,3;5;3,Accept (Oral),2,9,1.0,yes,9/27/18,Google;Google,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1726,ICLR,2019,Scalable Unbalanced Optimal Transport using Generative Adversarial Networks,Karren D. Yang;Caroline Uhler,karren@mit.edu;cuhler@mit.edu,7;6;6,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,unbalanced optimal transport;generative adversarial networks;population modeling,6;6,5;5,-1;-1,usa,usa,y,5;4
1727,ICLR,2019,ANYTIME MINIBATCH: EXPLOITING STRAGGLERS IN ONLINE DISTRIBUTED OPTIMIZATION,Nuwan Ferdinand;Haider Al-Lawati;Stark Draper;Matthew Nokleby,nuwan.ferdinand@utoronto.ca;haider.al.lawati@mail.utoronto.ca;stark.draper@utoronto.ca;matthew.nokleby@target.com,4;7;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Toronto University;Toronto University;Toronto University;Target,distributed optimization;gradient descent;minibatch;stragglers,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,
1728,ICLR,2019,Aggregated Momentum: Stability Through Passive Damping,James Lucas;Shengyang Sun;Richard Zemel;Roger  Grosse,jlucas@cs.toronto.edu;ssy@cs.toronto.edu;zemel@cs.toronto.edu;rgrosse@cs.toronto.edu,7;6;5,3;3;4,Accept (Poster),0,7,0.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto;University of Toronto,momentum;optimization;deep learning;neural networks,18;18;18;18,22;22;22;22,-1;-1,canada,ca,y,
1729,ICLR,2019,ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech,Wei Ping;Kainan Peng;Jitong Chen,weiping.thu@gmail.com;pengkainan@baidu.com;jitongc@gmail.com,6;9;7,3;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,NVIDIA;Baidu;ByteDance,text-to-speech;deep generative models;end-to-end training;text to waveform,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1730,ICLR,2019,Adaptive Estimators Show Information Compression in Deep Neural Networks,Ivan Chelombiev;Conor Houghton;Cian O'Donnell,ic14436@bristol.ac.uk;conor.houghton@bristol.ac.uk;cian.odonnell@bristol.ac.uk,7;6;7,4;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,University of Bristol;University of Bristol;University of Bristol,deep neural networks;mutual information;information bottleneck;noise;L2 regularization,94;94;94,76;76;76,-1;-1,europe,uk,n,1
1731,ICLR,2019,A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs,Jack Lindsey;Samuel A. Ocko;Surya Ganguli;Stephane Deny,lindsey6@stanford.edu;socko@stanford.edu;sganguli@stanford.edu;sdeny@stanford.edu,8;8;8,5;5;3,Accept (Oral),0,6,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University,visual system;convolutional neural networks;efficient coding;retina,4;4;4;4,3;3;3;3,-1;-1,usa,usa,n,1;5
1732,ICLR,2019,RNNs implicitly implement tensor-product representations,R. Thomas McCoy;Tal Linzen;Ewan Dunbar;Paul Smolensky,tom.mccoy@jhu.edu;tal.linzen@jhu.edu;ewan.dunbar@univ-paris-diderot.fr;smolensky@jhu.edu,7;6;6,4;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,Johns Hopkins University;Johns Hopkins University;Universit√© Paris Diderot;Johns Hopkins University,tensor-product representations;compositionality;neural network interpretability;recurrent neural networks,67;67;-1;67,13;13;-1;13,-1;-1,usa,usa,n,
1733,ICLR,2019,An Empirical study of Binary Neural Networks' Optimisation,Milad Alizadeh;Javier Fern√°ndez-Marqu√©s;Nicholas D. Lane;Yarin Gal,milad.alizadeh@cs.ox.ac.uk;javier.fernandezmarques@cs.ox.ac.uk;nicholas.lane@cs.ox.ac.uk;yarin.gal@cs.ox.ac.uk,8;4;6,4;4;3,Accept (Poster),2,3,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford;University of Oxford,binary neural networks;quantized neural networks;straight-through-estimator,44;44;44;44,1;1;1;1,-1;-1,europe,uk,n,
1734,ICLR,2019,A Statistical Approach to Assessing Neural Network Robustness,Stefan Webb;Tom Rainforth;Yee Whye Teh;M. Pawan Kumar,info@stefanwebb.me;twgr@robots.ox.ac.uk;y.w.teh@stats.ox.ac.uk;pawan@robots.ox.ac.uk,6;7;8,5;4;3,Accept (Poster),0,10,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford;University of Oxford,neural network verification;multi-level splitting;formal verification,-1;44;44;44,-1;1;1;1,-1;-1,europe,uk,n,
1735,ICLR,2019,Meta-Learning For Stochastic Gradient MCMC,Wenbo Gong;Yingzhen Li;Jos√© Miguel Hern√°ndez-Lobato,wg242@cam.ac.uk;yl494@cam.ac.uk;jmh233@cam.ac.uk,7;7;6,4;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,University of Cambridge;University of Cambridge;University of Cambridge,Meta Learning;MCMC,77;77;77,2;2;2,-1;-1,europe,uk,n,6;11
1736,ICLR,2019,Wizard of Wikipedia: Knowledge-Powered Conversational Agents,Emily Dinan;Stephen Roller;Kurt Shuster;Angela Fan;Michael Auli;Jason Weston,edinan@fb.com;roller@fb.com;kshuster@fb.com;angelafan@fb.com;michaelauli@fb.com;jase@fb.com,7;6;8,4;5;4,Accept (Poster),0,0,7.0,yes,9/27/18,Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,dialogue;knowledge;language;conversation,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1737,ICLR,2019,Information-Directed Exploration for Deep Reinforcement Learning,Nikolay Nikolov;Johannes Kirschner;Felix Berkenkamp;Andreas Krause,nikolay.nikolov14@imperial.ac.uk;jkirschner@inf.ethz.ch;befelix@inf.ethz.ch;krausea@ethz.ch,7;7;7,4;3;4,Accept (Poster),2,3,0.0,yes,9/27/18,Imperial College London;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,reinforcement learning;exploration;information directed sampling,47;-1;-1;-1,8;-1;-1;-1,-1;-1,NAN,NAN,n,1
1738,ICLR,2019,FlowQA: Grasping Flow in History for Conversational Machine Comprehension,Hsin-Yuan Huang;Eunsol Choi;Wen-tau Yih,hsinyuan@caltech.edu;eunsol@cs.washington.edu;scottyih@allenai.org,7;6;7,5;4;4,Accept (Poster),0,0,8.0,yes,9/27/18,California Institute of Technology;University of Washington;Allen Institute for Artificial Intelligence,Machine Comprehension;Conversational Agent;Natural Language Processing;Deep Learning,136;10;-1,3;25;-1,-1;-1,NAN,NAN,n,
1739,ICLR,2019,FFJORD: Free-Form Continuous Dynamics for Scalable Reversible Generative Models,Will Grathwohl;Ricky T. Q. Chen;Jesse Bettencourt;Ilya Sutskever;David Duvenaud,wgrathwohl@cs.toronto.edu;rtqichen@cs.toronto.edu;jessebett@cs.toronto.edu;ilyasu@openai.com;duvenaud@cs.toronto.edu,7;7;7,4;3;4,Accept (Oral),1,8,2.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto;OpenAI;University of Toronto,generative models;density estimation;approximate inference;ordinary differential equations,18;18;18;-1;18,22;22;22;-1;22,-1;-1,canada,ca,n,5
1740,ICLR,2019,Towards GAN Benchmarks Which Require Generalization,Ishaan Gulrajani;Colin Raffel;Luke Metz,igul222@gmail.com;craffel@gmail.com;lmetz@google.com,7;6;3,4;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,Stanford University;;Google,evaluation;generative adversarial networks;adversarial divergences,4;-1;-1,3;-1;-1,-1;-1,NAN,NAN,n,1;5
1741,ICLR,2019,Multi-Domain Adversarial Learning,Alice Schoenauer-Sebag;Louise Heinrich;Marc Schoenauer;Michele Sebag;Lani F. Wu;Steve J. Altschuler,alice.schoenauer@polytechnique.org;louise.heinrich@ucsf.edu;marc.schoenauer@inria.fr;sebag@lri.fr;lani.wu@ucsf.edu;steven.altschuler@ucsf.edu,5;8;6,4;5;5,Accept (Poster),0,3,0.0,yes,9/27/18,"University of California, San Francisco;University of California, San Francisco;INRIA;CNRS, Universit√© Paris-Saclay;University of California, San Francisco;University of California, San Francisco",multi-domain learning;domain adaptation;adversarial learning;H-divergence;deep representation learning;high-content microscopy,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;4
1742,ICLR,2019,Mode Normalization,Lucas Deecke;Iain Murray;Hakan Bilen,l.deecke@ed.ac.uk;i.murray@ed.ac.uk;hbilen@ed.ac.uk,6;5;6,4;4;4,Accept (Poster),6,5,0.0,yes,9/27/18,University of Edinburgh;University of Edinburgh;University of Edinburgh,Deep Learning;Expert Models;Normalization;Computer Vision,36;36;36,27;27;27,-1;-1,europe,uk,n,
1743,ICLR,2019,Universal Successor Features Approximators,Diana Borsa;Andre Barreto;John Quan;Daniel J. Mankowitz;Hado van Hasselt;Remi Munos;David Silver;Tom Schaul,borsa@google.com;andrebarreto@google.com;johnquan@google.com;dmankowitz@google.com;hado@google.com;munos@google.com;davidsilver@google.com;schaul@google.com,7;5;6,3;2;4,Accept (Poster),0,0,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;zero-shot transfer;successor features;universal value functions;general value functions,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
1744,ICLR,2019,Adversarial Imitation via Variational Inverse Reinforcement Learning,Ahmed H. Qureshi;Byron Boots;Michael C. Yip,a1quresh@eng.ucsd.edu;bboots@cc.gatech.edu;yip@ucsd.edu,6;6;6,4;3;4,Accept (Poster),0,11,0.0,yes,9/27/18,"University of California, San Diego;Georgia Institute of Technology;University of California, San Diego",Inverse Reinforcement Learning;Imitation learning;Variational lnference;Learning from demonstrations,-1;13;-1,31;33;31,-1;-1,usa,usa,n,6;5;4
1745,ICLR,2019,On Self Modulation for Generative Adversarial Networks,Ting Chen;Mario Lucic;Neil Houlsby;Sylvain Gelly,iamtingchen@gmail.com;lucic@google.com;neilhoulsby@google.com;sylvaingelly@google.com,5;7;7,5;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,Google;Google;Google;Google,unsupervised learning;generative adversarial networks;deep generative modelling,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
1746,ICLR,2019,Attentive Neural Processes,Hyunjik Kim;Andriy Mnih;Jonathan Schwarz;Marta Garnelo;Ali Eslami;Dan Rosenbaum;Oriol Vinyals;Yee Whye Teh,hyunjikk@google.com;amnih@google.com;schwarzjn@google.com;garnelo@google.com;aeslami@google.com;danro@google.com;vinyals@google.com;ywteh@google.com,6;6;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,Neural Processes;Conditional Neural Processes;Stochastic Processes;Regression;Attention,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
1747,ICLR,2019,Relaxed Quantization for Discretized Neural Networks,Christos Louizos;Matthias Reisser;Tijmen Blankevoort;Efstratios Gavves;Max Welling,c.louizos@uva.nl;m.reisser@uva.nl;tijmen@qti.qualcomm.com;egavves@uva.nl;m.welling@uva.nl,7;7;7,4;3;4,Accept (Poster),0,12,0.0,yes,9/27/18,"University of Amsterdam;University of Amsterdam;Qualcomm Inc, QualComm;University of Amsterdam;University of Amsterdam",Quantization;Compression;Neural Networks;Efficiency,136;136;-1;136;136,59;59;-1;59;59,-1;-1,europe,nl,n,
1748,ICLR,2019,Learning Factorized Multimodal Representations,Yao-Hung Hubert Tsai;Paul Pu Liang;Amir Zadeh;Louis-Philippe Morency;Ruslan Salakhutdinov,yaohungt@cs.cmu.edu;pliang@cs.cmu.edu;abagherz@cs.cmu.edu;morency@cs.cmu.edu;rsalakhu@cs.cmu.edu,7;7;6,3;2;3,Accept (Poster),0,5,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,multimodal learning;representation learning,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,y,5
1749,ICLR,2019,code2seq: Generating Sequences from Structured Representations of Code,Uri Alon;Shaked Brody;Omer Levy;Eran Yahav,urialon1@gmail.com;shakedbr@cs.technion.ac.il;omerlevy@gmail.com;yahave@cs.technion.ac.il,6;7;5,4;4;4,Accept (Poster),0,15,0.0,yes,9/27/18,"Technion;Technion, Technion;Tel Aviv University;Technion, Technion",source code;programs;code2seq,-1;27;31;27,-1;-1;217;-1,-1;-1,NAN,NAN,n,8;3
1750,ICLR,2019,Spreading vectors for similarity search,Alexandre Sablayrolles;Matthijs Douze;Cordelia Schmid;Herv√© J√©gou,asablayrolles@fb.com;matthijs@fb.com;cordelia.schmid@inria.fr;rvj@fb.com,6;6;7,4;3;4,Accept (Poster),0,8,0.0,yes,9/27/18,Facebook;Facebook;INRIA;Facebook,dimensionality reduction;similarity search;indexing;differential entropy,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1751,ICLR,2019,DeepOBS: A Deep Learning Optimizer Benchmark Suite,Frank Schneider;Lukas Balles;Philipp Hennig,frank.schneider@tuebingen.mpg.de;lukas.balles@tuebingen.mpg.de;philipp.hennig@uni-tuebingen.de,6;7;6,4;4;4,Accept (Poster),0,9,0.0,yes,9/27/18,Max-Planck Institute;Max-Planck Institute;University of Tuebingen,deep learning;optimization,-1;-1;136,-1;-1;94,-1;-1,europe,de,n,1
1752,ICLR,2019,Conditional Network Embeddings,Bo Kang;Jefrey Lijffijt;Tijl De Bie,bo.kang@ugent.be;jefrey.lijffijt@ugent.be;tijl.debie@ugent.be,6;4;5,3;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Ghent University;Ghent University;Ghent University,Network embedding;graph embedding;learning node representations;link prediction;multi-label classification of nodes,-1;-1;-1,107;107;107,-1;-1,NAN,NAN,n,11
1753,ICLR,2019,Neural Persistence: A Complexity Measure for Deep Neural Networks Using Algebraic Topology,Bastian Rieck;Matteo Togninalli;Christian Bock;Michael Moor;Max Horn;Thomas Gumbsch;Karsten Borgwardt,bastian.rieck@bsse.ethz.ch;matteo.togninalli@bsse.ethz.ch;christian.bock@bsse.ethz.ch;michael.moor@bsse.ethz.ch;max.horn@bsse.ethz.ch;thomas.gumbsch@bsse.ethz.ch;karsten.borgwardt@bsse.ethz.ch,7;6;4,4;5;4,Accept (Poster),2,6,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Algebraic topology;persistent homology;network complexity;neural network,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,10
1754,ICLR,2019,Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation,Sang-Woo Lee;Tong Gao;Sohee Yang;Jaejun Yoo;Jung-Woo Ha,sang.woo.lee@navercorp.com;tong.gao@navercorp.com;sh.yang@navercorp.com;jaejun.yoo@navercorp.com;jungwoo.ha@navercorp.com,6;7;6,4;5;2,Accept (Poster),0,13,1.0,yes,9/27/18,NAVER;NAVER;NAVER;NAVER;NAVER,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,europe,gr,n,
1755,ICLR,2019,Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks,Patrick Chen;Si Si;Sanjiv Kumar;Yang Li;Cho-Jui Hsieh,patrickchen@g.ucla.edu;sisidaisy@google.com;sanjivk@google.com;liyang@google.com;chohsieh@cs.ucla.edu,7;6;8,4;3;4,Accept (Poster),0,6,0.0,yes,9/27/18,"University of California, Los Angeles;Google;Google;Google;University of California, Los Angeles",fast inference;softmax computation;natural language processing,-1;-1;-1;-1;-1,15;-1;-1;-1;15,-1;-1,usa,usa,n,3
1756,ICLR,2019,Learning to Schedule Communication in Multi-agent Reinforcement Learning,Daewoo Kim;Sangwoo Moon;David Hostallero;Wan Ju Kang;Taeyoung Lee;Kyunghwan Son;Yung Yi,kdw2139@gmail.com;swmoon00@gmail.com;ddhostallero@kaist.ac.kr;soarhigh0714@gmail.com;tylee0325@gmail.com;khson@lanada.kaist.ac.kr;yiyung@kaist.edu,7;7;8,3;2;5,Accept (Poster),0,6,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,Multi agent reinforcement learning;deep reinforcement learning;Communication,-1;-1;-1;-1;-1;-1;17,95;95;95;-1;95;95;95,-1;-1,asia,in,n,
1757,ICLR,2019,"On Random Deep Weight-Tied Autoencoders: Exact Asymptotic Analysis, Phase Transitions, and Implications to Training",Ping Li;Phan-Minh Nguyen,pingli98@gmail.com;npminh@stanford.edu,8;9;8,4;4;4,Accept (Oral),0,7,0.0,yes,9/27/18,Baidu;Stanford University,Random Deep Autoencoders;Exact Asymptotic Analysis;Phase Transitions,-1;4,-1;3,-1;-1,usa,usa,y,
1758,ICLR,2019,DISTRIBUTIONAL CONCAVITY REGULARIZATION FOR GANS,Shoichiro Yamaguchi;Masanori Koyama,guguchi@preferred.jp;masomatics@preferred.jp,6;7;8;7,4;4;1;1,Accept (Poster),0,6,0.0,yes,9/27/18,"Preferred Networks, Inc.;Preferred Networks, Inc.",Generative Adversarial Networks;regularization;optimal transport;functional gradient;convex analysis,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1;5;4
1759,ICLR,2019,ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS,Chao GAO;jiyi LIU;Yuan YAO;Weizhi ZHU,chaogao@galton.uchicago.edu;jiyi.liu@yale.edu;yuany@ust.hk;wzhuai@connect.ust.hk,7;5;7,4;5;5,Accept (Poster),0,10,0.0,yes,9/27/18,University of Chicago;Yale University;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,robust statistics;neural networks;minimax rate;data depth;contamination model;Tukey median;GAN,50;67;-1;-1,9;12;44;44,-1;-1,NAN,NAN,y,5
1760,ICLR,2019,Pay Less Attention with Lightweight and Dynamic Convolutions,Felix Wu;Angela Fan;Alexei Baevski;Yann Dauphin;Michael Auli,fw245@cornell.edu;angelfan@fb.com;alexei.b@gmail.com;yann@dauphin.io;michael.auli@gmail.com,8;8;8,4;4;4,Accept (Oral),0,13,6.0,yes,9/27/18,Cornell University;Facebook;Facebook;Google;Facebook,Deep learning;sequence to sequence learning;convolutional neural networks;generative models,6;-1;-1;-1;-1,19;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3;5
1761,ICLR,2019,Analysis of Quantized Models,Lu Hou;Ruiliang Zhang;James T. Kwok,lhouab@cse.ust.hk;ruiliang.zhang@tusimple.ai;jamesk@cse.ust.hk,7;6;7,4;4;4,Accept (Poster),0,9,0.0,yes,9/27/18,The Hong Kong University of Science and Technology;TuSimple;The Hong Kong University of Science and Technology,weight quantization;gradient quantization;distributed learning,-1;-1;-1,44;-1;44,-1;-1,NAN,NAN,y,
1762,ICLR,2019,Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors,Andrew Ilyas;Logan Engstrom;Aleksander Madry,ailyas@mit.edu;engstrom@mit.edu;madry@mit.edu,7;7;8,5;3;2,Accept (Poster),1,12,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial examples;gradient estimation;black-box attacks;model-based optimization;bandit optimization,6;6;6,5;5;5,-1;-1,usa,usa,y,4
1763,ICLR,2019,Approximability of Discriminators Implies Diversity in GANs,Yu Bai;Tengyu Ma;Andrej Risteski,yub@stanford.edu;tengyuma@stanford.edu;risteski@mit.edu,8;7;7,2;3;3,Accept (Poster),2,4,0.0,yes,9/27/18,Stanford University;Stanford University;Massachusetts Institute of Technology,Theory;Generative adversarial networks;Mode collapse;Generalization,4;4;6,3;3;5,-1;-1,usa,usa,y,5;4
1764,ICLR,2019,Self-Monitoring Navigation Agent via Auxiliary Progress Estimation,Chih-Yao Ma;Jiasen Lu;Zuxuan Wu;Ghassan AlRegib;Zsolt Kira;Richard Socher;Caiming Xiong,cyma@gatech.edu;jiasenlu@gatech.edu;zxwu@cs.umd.edu;alregib@gatech.edu;zkira@gatech.edu;rsocher@salesforce.com;cxiong@salesforce.com,6;7;8,4;4;5,Accept (Poster),11,17,0.0,yes,9/27/18,"Georgia Institute of Technology;Georgia Institute of Technology;University of Maryland, College Park;Georgia Institute of Technology;Georgia Institute of Technology;SalesForce.com;SalesForce.com",visual grounding;textual grounding;instruction-following;navigation agent,13;13;12;13;13;-1;-1,33;33;69;33;33;-1;-1,-1;-1,NAN,NAN,n,
1765,ICLR,2019,Residual Non-local Attention Networks for Image Restoration,Yulun Zhang;Kunpeng Li;Kai Li;Bineng Zhong;Yun Fu,yulun100@gmail.com;kunpengli@ece.neu.edu;li.kai.gml@gmail.com;bnzhong@hqu.edu.cn;yunfu@ece.neu.edu,7;7;6,3;5;3,Accept (Poster),0,6,0.0,yes,9/27/18,Northeastern University;Northeastern University;;University of Science and Technology of China;Northeastern University,Non-local network;attention network;image restoration;residual learning,15;15;-1;-1;15,839;839;-1;132;839,-1;-1,usa,usa,n,8
1766,ICLR,2019,Emergent Coordination Through Competition,Siqi Liu;Guy Lever;Josh Merel;Saran Tunyasuvunakool;Nicolas Heess;Thore Graepel,liusiqi@google.com;guylever@google.com;jsmerel@google.com;stunya@google.com;heess@google.com;thore@google.com,6;7;7,3;3;3,Accept (Poster),0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google,Multi-agent learning;Reinforcement Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1767,ICLR,2019,Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder,Caio Corro;Ivan Titov,c.f.corro@uva.nl;i.a.titov@uva.nl,8;7;5,4;3;3,Accept (Poster),0,5,0.0,yes,9/27/18,University of Amsterdam;University of Amsterdam,differentiable dynamic programming;variational auto-encoder;dependency parsing;semi-supervised learning,136;136,59;59,-1;-1,europe,nl,n,3;5
1768,ICLR,2019,Meta-Learning Probabilistic Inference for Prediction,Jonathan Gordon;John Bronskill;Matthias Bauer;Sebastian Nowozin;Richard Turner,jg801@cam.ac.uk;jfb54@cam.ac.uk;bauer@tue.mpg.de;nowozin@google.com;ret26@cam.ac.uk,7;6;8,4;2;4,Accept (Poster),0,10,3.0,yes,9/27/18,University of Cambridge;University of Cambridge;Max-Planck Institute;Google;University of Cambridge,probabilistic models;approximate inference;few-shot learning;meta-learning,77;77;-1;-1;77,2;2;-1;-1;2,-1;-1,europe,uk,n,6
1769,ICLR,2019,Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds,Cenk Baykal;Lucas Liebenwein;Igor Gilitschenski;Dan Feldman;Daniela Rus,baykal@mit.edu;lucasl@mit.edu;igilitschenski@mit.edu;dannyf@gmail.com;rus@csail.mit.edu,6;7;6,4;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology,coresets;neural network compression;generalization bounds;matrix sparsification,6;6;6;-1;6,5;5;5;-1;5,-1;-1,usa,usa,y,1
1770,ICLR,2019,Beyond Greedy Ranking: Slate Optimization via List-CVAE,Ray Jiang;Sven Gowal;Yuqiu Qian;Timothy Mann;Danilo J. Rezende,rayjiang@google.com;sgowal@google.com;yqqian@cs.hku.hk;timothymann@google.com;danilor@google.com,6;6;7,3;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,Google;Google;The University of Hong Kong;Google;Google,CVAE;VAE;recommendation system;slate optimization;whole page optimization,-1;-1;94;-1;-1,-1;-1;40;-1;-1,-1;-1,NAN,NAN,n,5
1771,ICLR,2019,Generating Liquid Simulations with Deformation-aware Neural Networks,Lukas Prantl;Boris Bonev;Nils Thuerey,lukas.prantl@tum.de;boris.bonev@tum.de;nils.thuerey@tum.de,7;5;7,4;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Technical University Munich;Technical University Munich;Technical University Munich,deformation learning;spatial transformer networks;fluid simulation,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1772,ICLR,2019,Soft Q-Learning with Mutual-Information Regularization,Jordi Grau-Moya;Felix Leibfried;Peter Vrancx,jordi@prowler.io;felix@prowler.io;peter@prowler.io,7;6;6,4;3;4,Accept (Poster),4,12,0.0,yes,9/27/18,Prowler.io;Prowler.io;Prowler.io,reinforcement learning;regularization;entropy;mutual information,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
1773,ICLR,2019,Hindsight policy gradients,Paulo Rauber;Avinash Ummadisingu;Filipe Mutz;J√ºrgen Schmidhuber,paulo@idsia.ch;avinash.ummadisingu@usi.ch;filipe.mutz@ifes.edu.br;juergen@idsia.ch,7;7;7,4;4;4,Accept (Poster),2,7,0.0,yes,9/27/18,IDSIA;Universit√† della Svizzera Italiana;;IDSIA,reinforcement learning;policy gradients;multi-goal reinforcement learning,-1;169;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,y,
1774,ICLR,2019,Structured Neural Summarization,Patrick Fernandes;Miltiadis Allamanis;Marc Brockschmidt,t-pafern@microsoft.com;miallama@microsoft.com;mabrocks@microsoft.com,7;6;6,3;4;4,Accept (Poster),0,11,0.0,yes,9/27/18,Microsoft;Microsoft;Microsoft,Summarization;Graphs;Source Code,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;10
1775,ICLR,2019,ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA,Jialin Liu;Xiaohan Chen;Zhangyang Wang;Wotao Yin,liujl11@math.ucla.edu;chernxh@tamu.edu;atlaswang@tamu.edu;wotaoyin@math.ucla.edu,7;9;10,4;5;5,Accept (Poster),0,7,0.0,yes,9/27/18,"University of California, Los Angeles;Texas A&M;Texas A&M;University of California, Los Angeles",sparse recovery;neural networks,-1;50;50;-1,15;160;160;15,-1;-1,usa,usa,y,
1776,ICLR,2019,Subgradient Descent Learns Orthogonal Dictionaries,Yu Bai;Qijia Jiang;Ju Sun,yub@stanford.edu;qjiang2@stanford.edu;sunju@stanford.edu,6;7;7;7;7,1;2;3;4;3,Accept (Poster),0,8,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University,Dictionary learning;Sparse coding;Non-convex optimization;Theory,4;4;4,3;3;3,-1;-1,usa,usa,y,
1777,ICLR,2019,A new dog learns old tricks:  RL finds classic optimization algorithms,Weiwei Kong;Christopher Liaw;Aranyak Mehta;D. Sivakumar,wkong37@gatech.edu;cvliaw@cs.ubc.ca;aranyak@google.com;siva@google.com,6;6;7,3;3;5,Accept (Poster),0,11,0.0,yes,9/27/18,Georgia Institute of Technology;University of British Columbia;Google;Google,reinforcement learning;algorithms;adwords;knapsack;secretary,13;59;-1;-1,33;34;-1;-1,-1;-1,NAN,NAN,y,1;4
1778,ICLR,2019,Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures,Jonathan Uesato*;Ananya Kumar*;Csaba Szepesvari*;Tom Erez;Avraham Ruderman;Keith Anderson;Krishnamurthy (Dj) Dvijotham;Nicolas Heess;Pushmeet Kohli,juesato@gmail.com;ananya@cs.stanford.edu;szepi@google.com;etom@google.com;aruderman@google.com;keithanderson@google.com;dvij@google.com;heess@google.com;pushmeet@google.com,6;6;6,3;3;3,Accept (Poster),0,9,0.0,yes,9/27/18,Google;Stanford University;Google;Google;Google;Google;Google;Google;Google,agent evaluation;adversarial examples;robustness;safety;reinforcement learning,-1;4;-1;-1;-1;-1;-1;-1;-1,-1;3;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,4
1779,ICLR,2019,AntisymmetricRNN: A Dynamical System View on Recurrent Neural Networks,Bo Chang;Minmin Chen;Eldad Haber;Ed H. Chi,bchang@stat.ubc.ca;minminc@google.com;haber@math.ubc.ca;edchi@google.com,7;7;6,5;5;5,Accept (Poster),0,3,0.0,yes,9/27/18,University of British Columbia;Google;University of British Columbia;Google,,59;-1;59;-1,34;-1;34;-1,-1;-1,NAN,NAN,n,
1780,ICLR,2019,Recall Traces: Backtracking Models for Efficient Reinforcement Learning,Anirudh Goyal;Philemon Brakel;William Fedus;Soumye Singhal;Timothy Lillicrap;Sergey Levine;Hugo Larochelle;Yoshua Bengio,anirudhgoyal9119@gmail.com;philemon@google.com;liam.fedus@gmail.com;singhalsoumye@gmail.com;countzero@google.com;svlevine@eecs.berkeley.edu;hugolarochelle@google.com;yoshua.bengio@mila.quebec,7;7;6,2;3;3,Accept (Poster),0,10,0.0,yes,9/27/18,University of Montreal;Google;;;Google;University of California Berkeley;Google;Mila,Model free RL;Variational Inference,-1;-1;-1;-1;-1;-1;-1;136,-1;-1;-1;-1;-1;18;-1;314,-1;-1,NAN,NAN,n,
1781,ICLR,2019,Auxiliary Variational MCMC,Raza Habib;David Barber,raza.habib@cs.ucl.ac.uk;david.barber@ucl.ac.uk,7;7;7,5;4;4,Accept (Poster),0,11,0.0,yes,9/27/18,University College London;University College London,MCMC;Variational Inference,50;50,-1;-1,-1;-1,europe,uk,n,11
1782,ICLR,2019,Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability,Kai Y. Xiao;Vincent Tjeng;Nur Muhammad (Mahi) Shafiullah;Aleksander Madry,kaix@mit.edu;vtjeng@mit.edu;nshafiul@mit.edu;madry@mit.edu,5;8;7,3;2;3,Accept (Poster),0,14,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,verification;adversarial robustness;adversarial examples;stability;deep learning;regularization,6;6;6;6,5;5;5;5,-1;-1,usa,usa,n,4
1783,ICLR,2019,RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant Deep Networks,Xiuyuan Cheng;Qiang Qiu;Robert Calderbank;Guillermo Sapiro,xiuyuan.cheng@duke.edu;qiang.qiu@duke.edu;robert.calderbank@duke.edu;guillermo.sapiro@duke.edu,7;7;7,3;2;4,Accept (Poster),0,4,1.0,yes,9/27/18,Duke University;Duke University;Duke University;Duke University,,47;47;47;47,17;17;17;17,-1;-1,europe,se,y,
1784,ICLR,2019,Three Mechanisms of Weight Decay Regularization,Guodong Zhang;Chaoqi Wang;Bowen Xu;Roger Grosse,gdzhang.cs@gmail.com;cqwang@cs.toronto.edu;bowenxu@cs.toronto.com;rgrosse@cs.toronto.edu,6;7;7,4;5;4,Accept (Poster),0,9,0.0,yes,9/27/18,"University of Toronto;University of Toronto;Department of Computer Science, University of Toronto;University of Toronto",Generalization;Regularization;Optimization,18;18;18;18,22;22;22;22,-1;-1,canada,ca,y,1
1785,ICLR,2019,Imposing Category Trees Onto Word-Embeddings Using A Geometric Construction,Tiansi Dong;Chrisitan Bauckhage;Hailong Jin;Juanzi Li;Olaf Cremers;Daniel Speicher;Armin B. Cremers;Joerg Zimmermann,tian1shi2@gmail.com;christian.bauckhage@iais.fraunhofer.de;jinhl15@mails.tsinghua.edu.cn;lijuanzi2008@gmail.com;cremerso@iai.uni-bonn.de;dsp@bit.uni-bonn.de;abc@iai.uni-bonn.de;jz@bit.uni-bonn.de,3;4;4,4;5;4,Accept (Poster),0,2,32.0,yes,9/27/18,"University of Bonn;Fraunhofer IIS;Tsinghua University, Tsinghua University;;University of Bonn;University of Bonn;University of Bonn;University of Bonn",category tree;word-embeddings;geometry,-1;-1;4;-1;136;136;136;136,-1;-1;30;-1;100;100;100;100,-1;-1,europe,uk,n,3
1786,ICLR,2019,PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks,Jan Svoboda;Jonathan Masci;Federico Monti;Michael Bronstein;Leonidas Guibas,jan.svoboda@usi.ch;jonathan@nnaisense.com;federico.monti@usi.ch;michael.bronstein@usi.ch;guibas@cs.stanford.edu,6;7,5;4,Accept (Poster),2,8,0.0,yes,9/27/18,Universit√† della Svizzera Italiana;NNAISENSE;Universit√† della Svizzera Italiana;Universit√† della Svizzera Italiana;Stanford University,peernet;peernets;graph;geometric deep learning;adversarial;perturbation;defense;peer regularization,169;-1;169;169;4,-1;-1;-1;-1;3,-1;-1,usa,usa,n,10;4
1787,ICLR,2019,Measuring Compositionality in Representation Learning,Jacob Andreas,jda@cs.berkeley.edu,7;6;6,4;4;4,Accept (Poster),0,4,0.0,yes,9/27/18,University of California Berkeley,compositionality;representation learning;evaluation,-1,18,-1,usa,usa,y,8;1
1788,ICLR,2019,ProxQuant: Quantized Neural Networks via Proximal Operators,Yu Bai;Yu-Xiang Wang;Edo Liberty,yub@stanford.edu;yuxiangw@cs.ucsb.edu;libertye@amazon.com,7;5;8,4;4;4,Accept (Poster),2,9,0.0,yes,9/27/18,Stanford University;UC Santa Barbara;Amazon,Model quantization;Optimization;Regularization,4;-1;-1,3;-1;-1,-1;-1,NAN,NAN,y,9
1789,ICLR,2019,Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information,Mohit Sharma;Arjun Sharma;Nicholas Rhinehart;Kris M. Kitani,mohits1@andrew.cmu.edu;arjuns2@andrew.cmu.edu;nrhineha@cs.cmu.edu;kkitani@cs.cmu.edu,6;6;8,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Imitation Learning;Reinforcement Learning;Deep Learning,1;1;1;1,24;24;24;24,-1;-1,usa,usa,n,10;5;4
1790,ICLR,2019,Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies,Kenneth Marino;Abhinav Gupta;Rob Fergus;Arthur Szlam,kdmarino@cs.cmu.edu;abhinavg@cs.cmu.edu;fergus@cs.nyu.edu;aszlam@fb.com,7;6;7,5;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;New York University;Facebook,,1;1;24;-1,24;24;27;-1,-1;-1,NAN,NAN,n,
1791,ICLR,2019,ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness,Robert Geirhos;Patricia Rubisch;Claudio Michaelis;Matthias Bethge;Felix A. Wichmann;Wieland Brendel,robert@geirhos.de;patricia@rubisch.net;claudio.michaelis@bethgelab.org;matthias.bethge@uni-tuebingen.de;felix.wichmann@uni-tuebingen.de;wieland.brendel@bethgelab.org,8;7;8,4;4;4,Accept (Oral),2,9,3.0,yes,9/27/18,"University of Tuebingen;;Centre for Integrative Neuroscience, AG Bethge;University of Tuebingen;University of Tuebingen;Centre for Integrative Neuroscience, AG Bethge",deep learning;psychophysics;representation learning;object recognition;robustness;neural networks;data augmentation,-1;-1;-1;136;136;-1,-1;-1;-1;94;94;-1,-1;-1,NAN,NAN,n,2
1792,ICLR,2019,Verification of Non-Linear Specifications for Neural Networks,Chongli Qin;Krishnamurthy (Dj) Dvijotham;Brendan O'Donoghue;Rudy Bunel;Robert Stanforth;Sven Gowal;Jonathan Uesato;Grzegorz Swirszcz;Pushmeet Kohli,chongliqin@google.com;dvij@google.com;bodonoghue@google.com;rbunel@google.com;stanforth@google.com;sgowal@google.com;juesato@google.com;swirszcz@google.com;pushmeet@google.com,7;7;5,3;5;3,Accept (Poster),0,12,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google,Verification;Convex Optimization;Adversarial Robustness,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,4
1793,ICLR,2019,LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION,Mahsa Baktashmotlagh;Masoud Faraki;Tom Drummond;Mathieu Salzmann,m.baktashmotlagh@qut.edu.au;masoud.faraki@monash.edu;tom.drummond@monash.edu;mathieu.salzmann@epfl.ch,7;6;6,3;4;5,Accept (Poster),2,10,0.0,yes,9/27/18,South China University of Technology;Monash University;Monash University;Swiss Federal Institute of Technology Lausanne,Open Set Domain Adaptation,-1;94;94;-1,576;80;80;-1,-1;-1,NAN,NAN,n,
1794,ICLR,2019,Variance Networks: When Expectation Does Not Meet Your Expectations,Kirill Neklyudov;Dmitry Molchanov;Arsenii Ashukha;Dmitry Vetrov,k.necludov@gmail.com;dmolch111@gmail.com;ars.ashuha@gmail.com;vetrovd@yandex.ru,6;6;6,3;4;4,Accept (Poster),0,3,0.0,yes,9/27/18,University of Amsterdam;Samsung;Samsung;Higher School of Economics,deep learning;variational inference;variational dropout,136;-1;-1;-1,59;-1;-1;-1,-1;-1,NAN,NAN,y,11;4
1795,ICLR,2019,Function Space Particle Optimization for Bayesian Neural Networks,Ziyu Wang;Tongzheng Ren;Jun Zhu;Bo Zhang,wzy196@gmail.com;rtz19970824@gmail.com;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,7;7;7,3;4;3,Accept (Poster),0,10,2.0,yes,9/27/18,"Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Bayesian neural networks;uncertainty estimation;variational inference,4;-1;4;4,30;-1;30;30,-1;-1,NAN,NAN,y,8;11;4
1796,ICLR,2019,CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix Space Model,Florian Mai;Lukas Galke;Ansgar Scherp,florian.ren.mai@googlemail.com;lga@informatik.uni-kiel.de;mail@ansgarscherp.net,6;5;6,3;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,Idiap Research Institute;Kiel University;Ulm University,Text representation learning;Sentence embedding;Efficient training scheme;word2vec,-1;285;-1,-1;512;155,-1;-1,europe,tr,n,3
1797,ICLR,2019,Evaluating Robustness of Neural Networks with Mixed Integer Programming,Vincent Tjeng;Kai Y. Xiao;Russ Tedrake,vtjeng@mit.edu;kaix@mit.edu;russt@mit.edu,7;8;7,5;5;1,Accept (Poster),0,14,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,verification;adversarial robustness;adversarial examples;deep learning,6;6;6,5;5;5,-1;-1,usa,usa,y,4
1798,ICLR,2019,Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator,Makoto Yamada;Denny Wu;Yao-Hung Hubert Tsai;Hirofumi Ohta;Ruslan Salakhutdinov;Ichiro Takeuchi;Kenji Fukumizu,makoto.yamada@riken.jp;yiwu1@andrew.cmu.edu;yaohungt@cs.cmu.edu;hirofumi-ohta@g.ecc.u-tokyo.ac.jp;rsalakhu@cs.cmu.edu;takeuchi.ichiro@nitech.ac.jp;fukumizu@ism.ac.jp,6;5;8,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,"RIKEN;Carnegie Mellon University;Carnegie Mellon University;The University of Tokyo;Carnegie Mellon University;Nagoya Institute of Technology;The Institute of Statistical Mathematics, Japan",Maximum Mean Discrepancy;Selective Inference;Feature Selection;GAN,-1;1;1;59;1;-1;-1,-1;24;24;45;24;880;-1,-1;-1,NAN,NAN,y,5;4
1799,ICLR,2019,Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data Streams,Mohammad Kachuee;Orpaz Goldstein;Kimmo K√§rkk√§inen;Sajad Darabi;Majid Sarrafzadeh,mkachuee@cs.ucla.edu;orpgol@cs.ucla.edu;kimmo@cs.ucla.edu;sajad.darabi@cs.ucla.edu;majid@cs.ucla.edu,7;6;6,4;4;4,Accept (Poster),0,14,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Cost-Aware Learning;Feature Acquisition;Reinforcement Learning;Stream Learning;Deep Q-Learning,-1;-1;-1;-1;-1,15;15;15;15;15,-1;-1,usa,usa,n,
1800,ICLR,2019,Riemannian Adaptive Optimization Methods,Gary Becigneul;Octavian-Eugen Ganea,gary.becigneul@inf.ethz.ch;octavian.ganea@inf.ethz.ch,7;7;7,3;5;4,Accept (Poster),5,6,3.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Riemannian optimization;adaptive;hyperbolic;curvature;manifold;adam;amsgrad;adagrad;rsgd;convergence,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1
1801,ICLR,2019,StrokeNet: A Neural Painting Environment,Ningyuan Zheng;Yifan Jiang;Dingjiang Huang,zhengningyuan@qq.com;winhehe@163.com;djhuang@dase.ecnu.edu.cn,7;6;8,4;4;5,Accept (Poster),0,8,2.0,yes,9/27/18,East China Normal University;163;East China Normal University,image generation;differentiable model;reinforcement learning;deep learning;model based,-1;-1;-1,-1;-1;562,-1;-1,NAN,NAN,n,
1802,ICLR,2019,Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach,Wenda Zhou;Victor Veitch;Morgane Austern;Ryan P. Adams;Peter Orbanz,wz2335@columbia.edu;victorveitch@gmail.com;ma3293@columbia.edu;rpa@princeton.edu;porbanz@stat.columbia.edu,6;6;8,4;5;4,Accept (Poster),0,5,0.0,yes,9/27/18,Columbia University;University of Chicago;Columbia University;Princeton University;Columbia University,generalization;deep-learning;pac-bayes,21;50;21;31;21,14;9;14;7;14,-1;-1,usa,usa,y,1
1803,ICLR,2019,RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space,Zhiqing Sun;Zhi-Hong Deng;Jian-Yun Nie;Jian Tang,1500012783@pku.edu.cn;zhdeng@pku.edu.cn;nie@iro.umontreal.ca;jian.tang@hec.ca,7;7;7,4;3;4,Accept (Poster),1,21,13.0,yes,9/27/18,Peking University;Peking University;University of Montreal;HEC Montreal,knowledge graph embedding;knowledge graph completion;adversarial sampling,14;14;116;-1,27;27;108;-1,-1;-1,canada,ca,y,10;4
1804,ICLR,2019,STCN: Stochastic Temporal Convolutional Networks,Emre Aksan;Otmar Hilliges,eaksan@inf.ethz.ch;otmar.hilliges@inf.ethz.ch,6;6;6,4;3;5,Accept (Poster),0,8,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,latent variables;variational inference;temporal convolutional networks;sequence modeling;auto-regressive modeling,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1805,ICLR,2019,From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference,Randall Balestriero;Richard Baraniuk,randallbalestriero@gmail.com;richb@rice.edu,6;6;7,3;4;5,Accept (Poster),0,4,0.0,yes,9/27/18,Rice University;Rice University,Spline;Vector Quantization;Inference;Nonlinearities;Deep Network,94;94,86;86,-1;-1,australasia,au,y,2;1
1806,ICLR,2019,Competitive experience replay,Hao Liu;Alexander Trott;Richard Socher;Caiming Xiong,lhao499@gmail.com;atrott@salesforce.com;rsocher@salesforce.com;cxiong@salesforce.com,5;7;6;7,4;4;4;5,Accept (Poster),0,6,0.0,yes,9/27/18,University of California Berkeley;SalesForce.com;SalesForce.com;SalesForce.com,reinforcement learning;sparse reward;goal-based learning,-1;-1;-1;-1,18;-1;-1;-1,-1;-1,NAN,NAN,n,4
1807,ICLR,2019,Deterministic Variational Inference for Robust Bayesian Neural Networks,Anqi Wu;Sebastian Nowozin;Edward Meeds;Richard E. Turner;Jos√© Miguel Hern√°ndez-Lobato;Alexander L. Gaunt,anqiw@princeton.edu;sebastian.nowozin@microsoft.com;ted.meeds@microsoft.com;ret26@cam.ac.uk;jmh233@cam.ac.uk;algaunt@microsoft.com,7;7;7,3;3;5,Accept (Oral),0,3,1.0,yes,9/27/18,Princeton University;Microsoft;Microsoft;University of Cambridge;University of Cambridge;Microsoft,Bayesian neural network;variational inference;variational bayes;variance reduction;empirical bayes,31;-1;-1;77;77;-1,7;-1;-1;2;2;-1,-1;-1,NAN,NAN,n,11
1808,ICLR,2019,Marginal Policy Gradients: A Unified Family of Estimators for Bounded Action Spaces with Applications,Carson Eisenach;Haichuan Yang;Ji Liu;Han Liu,eisenach@princeton.edu;h.yang@rochester.edu;ji.liu.uwisc@gmail.com;hanliu.cmu@gmail.com,7;7;6,4;3;3,Accept (Poster),0,4,0.0,yes,9/27/18,Princeton University;University of Rochester;;Princeton University,reinforcement learning;policy gradient;MOBA games,31;94;-1;-1,7;153;-1;-1,-1;-1,asia,in,y,
1809,ICLR,2019,Harmonic Unpaired Image-to-image Translation,Rui Zhang;Tomas Pfister;Jia Li,zhangrui@ict.ac.cn;tpfister@google.com;lijiali@google.com,6;5;4,5;5;5,Accept (Poster),3,7,0.0,yes,9/27/18,"Institute of Computing Technology, Chinese Academy of Sciences;Google;Google",unpaired image-to-image translation;cyclegan;smoothness constraint,31;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,10
1810,ICLR,2019,Trellis Networks for Sequence Modeling,Shaojie Bai;J. Zico Kolter;Vladlen Koltun,shaojieb@cs.cmu.edu;zkolter@cs.cmu.edu;vkoltun@gmail.com,7;6;7,3;3;3,Accept (Poster),0,6,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Intel,sequence modeling;language modeling;recurrent networks;convolutional networks;trellis networks,1;1;-1,24;24;-1,-1;-1,NAN,NAN,y,3
1811,ICLR,2019,Adversarial Reprogramming of Neural Networks,Gamaleldin F. Elsayed;Ian Goodfellow;Jascha Sohl-Dickstein,gamaleldin.elsayed@gmail.com;goodfellow@google.com;jaschasd@google.com,8;6;4,4;5;3,Accept (Poster),2,6,2.0,yes,9/27/18,Google;Google;Google,Adversarial;Neural Networks;Machine Learning Security,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,2;4
1812,ICLR,2019,Variational Bayesian Phylogenetic Inference,Cheng Zhang;Frederick A. Matsen IV,zc.rabbit@gmail.com;matsen@fredhutch.org,6;5;7,3;3;1,Accept (Poster),0,6,0.0,yes,9/27/18,Peking University;Fred Hutchinson Cancer Research Center,Bayesian phylogenetic inference;Variational inference;Subsplit Bayesian networks,14;-1,27;-1,-1;-1,NAN,NAN,n,11;10
1813,ICLR,2019,Learning to Understand Goal Specifications by Modelling Reward,Dzmitry Bahdanau;Felix Hill;Jan Leike;Edward Hughes;Arian Hosseini;Pushmeet Kohli;Edward Grefenstette,dimabgv@gmail.com;felixhill@google.com;leike@google.com;edwardhughes@google.com;seyedarian.hosseini@umontreal.ca;pushmeet@google.com;etg@google.com,7;7;6,4;5;4,Accept (Poster),0,0,21.0,yes,9/27/18,Element AI;Google;Google;Google;University of Montreal;Google;Google,instruction following;reward modelling;language understanding,-1;-1;-1;-1;116;-1;-1,-1;-1;-1;-1;108;-1;-1,-1;-1,NAN,NAN,n,
1814,ICLR,2019,Overcoming the Disentanglement vs Reconstruction Trade-off via Jacobian Supervision,Jos√© Lezama,jlezama@fing.edu.uy,5;7;7,3;4;4,Accept (Poster),2,5,0.0,yes,9/27/18,Facultad de Ingenier√≠a,disentangling;autoencoders;jacobian;face manipulation,-1,-1,-1,NAN,NAN,n,4
1815,ICLR,2019,Relational Forward Models for Multi-Agent Learning,Andrea Tacchetti;H. Francis Song;Pedro A. M. Mediano;Vinicius Zambaldi;J√°nos Kram√°r;Neil C. Rabinowitz;Thore Graepel;Matthew Botvinick;Peter W. Battaglia,atacchet@google.com;songf@google.com;pmediano@imperial.ac.uk;vzambaldi@google.com;janosk@google.com;ncr@google.com;thore@google.com;botvinick@google.com;peterbattaglia@google.com,7;6;7;6,3;4;3;3,Accept (Poster),0,21,1.0,yes,9/27/18,Google;Google;Imperial College London;Google;Google;Google;Google;Google;Google,multi-agent reinforcement learning;relational reasoning;forward models,-1;-1;47;-1;-1;-1;-1;-1;-1,-1;-1;8;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1816,ICLR,2019,NADPEx: An on-policy temporally consistent exploration method for deep reinforcement learning,Sirui Xie;Junning Huang;Lanxin Lei;Chunxiao Liu;Zheng Ma;Wei Zhang;Liang Lin,xiesirui@sensetime.com;huangjunning@sensetime.com;leilanxin@sensetime.com;liuchunxiao@sensetime.com;mazheng@sensetime.com;wayne.zhang@sensetime.com;linliang@ieee.org,6;8;7,3;3;3,Accept (Poster),2,9,0.0,yes,9/27/18,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SUN YAT-SEN UNIVERSITY,Reinforcement learning;exploration,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,asia,in,n,
1817,ICLR,2019,"Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search",Lars Buesing;Theophane Weber;Yori Zwols;Nicolas Heess;Sebastien Racaniere;Arthur Guez;Jean-Baptiste Lespiau,lbuesing@google.com;theophane@google.com;yori@google.com;heess@google.com;sracaniere@google.com;aguez@google.com;jblespiau@google.com,7;7;7,2;3;3,Accept (Poster),0,5,1.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google,reinforcement learning;generative models;model-based reinforcement learning;causal inference,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
1818,ICLR,2019,Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition,Chun-Fu (Richard) Chen;Quanfu Fan;Neil Mallinar;Tom Sercu;Rogerio Feris,chenrich@us.ibm.com;qfan@us.ibm.com;neil.r.mallinar@ibm.com;tom.sercu1@ibm.com;rsferis@us.ibm.com,7;6;7,4;5;4,Accept (Poster),0,4,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,CNN;multi-scale;efficiency;object recognition;speech recognition,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
1819,ICLR,2019,There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average,Ben Athiwaratkun;Marc Finzi;Pavel Izmailov;Andrew Gordon Wilson,pa338@cornell.edu;maf388@cornell.edu;izmailovpavel@gmail.com;andrew@cornell.edu,6;8;6,4;4;1,Accept (Poster),2,6,5.0,yes,9/27/18,Cornell University;Cornell University;New York University;Cornell University,semi-supervised learning;computer vision;classification;consistency regularization;flatness;weight averaging;stochastic weight averaging,6;6;24;6,19;19;27;19,-1;-1,usa,usa,n,1
1820,ICLR,2019,Wasserstein Barycenter Model Ensembling,Pierre Dognin*;Igor Melnyk*;Youssef Mroueh*;Jarret Ross*;Cicero Dos Santos*;Tom Sercu*,pdognin@us.ibm.com;igor.melnyk@ibm.com;mroueh@us.ibm.com;rossja@us.ibm.com;cicerons@us.ibm.com;tom.sercu1@ibm.com,6;6;6,4;3;4,Accept (Poster),0,5,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,Wasserstein barycenter model ensembling,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,3
1821,ICLR,2019,Learning what you can do before doing anything,Oleh Rybkin;Karl Pertsch;Konstantinos G. Derpanis;Kostas Daniilidis;Andrew Jaegle,oleh@seas.upenn.edu;pertsch@usc.edu;kosta@ryerson.ca;kostas@seas.upenn.edu;ajaegle@upenn.edu,6;7;6,4;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,University of Pennsylvania;University of Southern California;Ryerson University;University of Pennsylvania;University of Pennsylvania,unsupervised learning;vision;motion;action space;video prediction;variational models,21;27;285;21;21,10;66;-1;10;10,-1;-1,usa,usa,n,
1822,ICLR,2019,Learning Localized Generative Models for 3D Point Clouds via Graph Convolution,Diego Valsesia;Giulia Fracastoro;Enrico Magli,diego.valsesia@polito.it;giulia.fracastoro@polito.it;enrico.magli@polito.it,6;9;7,4;3;3,Accept (Poster),0,7,0.0,yes,9/27/18,Politecnico di Torino;Politecnico di Torino;Politecnico di Torino,GAN;graph convolution;point clouds,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,2;10;1;5
1823,ICLR,2019,Policy Transfer with Strategy Optimization,Wenhao Yu;C. Karen Liu;Greg Turk,wyu68@gatech.edu;karenliu@cc.gatech.edu;turk@cc.gatech.edu,7;6;7,4;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,transfer learning;reinforcement learning;modeling error;strategy optimization,13;13;13,33;33;33,-1;-1,usa,usa,n,6
1824,ICLR,2019,Measuring and regularizing networks in function space,Ari Benjamin;David Rolnick;Konrad Kording,aarrii@seas.upenn.edu;drolnick@mit.edu;koerding@gmail.com,6;6;6,4;3;4,Accept (Poster),0,5,1.0,yes,9/27/18,University of Pennsylvania;Massachusetts Institute of Technology;University of Pennsylvania,function space;Hilbert space;empirical characterization;multitask learning;catastrophic forgetting;optimization;natural gradient,21;6;21,10;5;10,-1;-1,usa,usa,n,
1825,ICLR,2019,Learning Two-layer Neural Networks with Symmetric Inputs,Rong Ge;Rohith Kuditipudi;Zhize Li;Xiang Wang,rongge@cs.duke.edu;rohith.kuditipudi@duke.edu;zz-li14@mails.tsinghua.edu.cn;xwang@cs.duke.edu,7;6;7,4;4;5,Accept (Poster),0,3,0.0,yes,9/27/18,"Duke University;Duke University;Tsinghua University, Tsinghua University;Duke University",Neural Network;Optimization;Symmetric Inputs;Moment-of-moments,47;47;4;47,17;17;30;17,-1;-1,europe,se,y,9
1826,ICLR,2019,CEM-RL: Combining evolutionary and gradient-based methods for policy search,Pourchot;Sigaud,alois.pourchot@telecom-paristech.fr;olivier.sigaud@upmc.fr,6;7;7,3;5;4,Accept (Poster),0,7,0.0,yes,9/27/18,"T√©l√©com ParisTech;Computer Science Lab  - Pierre and Marie Curie University, Paris, France",evolution strategy;deep reinforcement learning,-1;-1,-1;123,-1;-1,NAN,NAN,n,
1827,ICLR,2019,Multiple-Attribute Text Rewriting,Guillaume Lample;Sandeep Subramanian;Eric Smith;Ludovic Denoyer;Marc'Aurelio Ranzato;Y-Lan Boureau,glample@fb.com;sandeep.subramanian.1@umontreal.ca;ems@fb.com;ludovic.denoyer@lip6.fr;ranzato@fb.com;ylan@fb.com,7;6;6,3;4;3,Accept (Poster),0,11,0.0,yes,9/27/18,Facebook;University of Montreal;Facebook;LIP6;Facebook;Facebook,controllable text generation;generative models;conditional generative models;style transfer,-1;116;-1;419;-1;-1,-1;108;-1;-1;-1;-1,-1;-1,NAN,NAN,n,7;4
1828,ICLR,2019,Improving Generalization and Stability of Generative Adversarial Networks,Hoang Thanh-Tung;Truyen Tran;Svetha Venkatesh,hoangtha@deakin.edu.au;truyen.tran@deakin.edu.au;svetha.venkatesh@deakin.edu.au,6;7;7,4;3;3,Accept (Poster),0,14,0.0,yes,9/27/18,Deakin University;Deakin University;Deakin University,GAN;generalization;gradient penalty;zero centered;convergence,-1;-1;-1,334;334;334,-1;-1,asia,cn,y,1;5;4
1829,ICLR,2019,Sliced Wasserstein Auto-Encoders,Soheil Kolouri;Phillip E. Pope;Charles E. Martin;Gustavo K. Rohde,skolouri@hrl.com;pepope@hrl.com;cemartin@hrl.com;gustavo@virginia.edu,6;4;6,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,"HRL Laboratories, LLC;HRL Laboratories, LLC;HRL Laboratories, LLC;University of Virginia",optimal transport;Wasserstein distances;auto-encoders;unsupervised learning,-1;-1;-1;59,-1;-1;-1;113,-1;-1,usa,usa,n,5;4
1830,ICLR,2019,The Laplacian in RL: Learning Representations with Efficient Approximations,Yifan Wu;George Tucker;Ofir Nachum,yw4@andrew.cmu.edu;gjt@google.com;ofirnachum@google.com,7;7;7,3;3;4,Accept (Poster),0,3,0.0,yes,9/27/18,Carnegie Mellon University;Google;Google,Laplacian;reinforcement learning;representation,1;-1;-1,24;-1;-1,-1;-1,NAN,NAN,n,10
1831,ICLR,2019,Sparse Dictionary Learning by Dynamical Neural Networks,Tsung-Han Lin;Ping Tak Peter Tang,tsung-han.lin@intel.com;peter.tang@intel.com,6;9;8,4;4;4,Accept (Poster),0,3,0.0,yes,9/27/18,Intel;Intel,dynamical neural networks;spiking neural networks;dynamical system;hardware friendly learning;feedback;contrastive learning;dictionary learning;sparse coding,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1
1832,ICLR,2019,Learning Programmatically Structured Representations with Perceptor Gradients,Svetlin Penkov;Subramanian Ramamoorthy,sv.penkov@gmail.com;s.ramamoorthy@ed.ac.uk,7;5;6,5;3;1,Accept (Poster),0,8,0.0,yes,9/27/18,University of Edinburgh;University of Edinburgh,representation learning;structured representations;symbols;programs,36;36,27;27,-1;-1,europe,uk,n,
1833,ICLR,2019,Adversarial Audio Synthesis,Chris Donahue;Julian McAuley;Miller Puckette,cdonahue@ucsd.edu;jmcauley@eng.ucsd.edu;msp@ucsd.edu,6;5;6,3;4;4,Accept (Poster),0,7,0.0,yes,9/27/18,"University of California, San Diego;University of California, San Diego;University of California, San Diego",audio;waveform;spectrogram;GAN;adversarial;WaveGAN;SpecGAN,-1;-1;-1,31;31;31,-1;-1,usa,usa,n,5;4
1834,ICLR,2019,PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees,James Jordon;Jinsung Yoon;Mihaela van der Schaar,james.jordon@wolfson.ox.ac.uk;jsyoon0823@gmail.com;mihaela.vanderschaar@eng.ox.ac.uk,6;7;7,4;4;3,Accept (Poster),0,11,2.0,yes,9/27/18,University of Oxford;Google;University of Oxford,Synthetic data generation;Differential privacy;Generative adversarial networks;Private Aggregation of Teacher ensembles,44;-1;44,1;-1;1,-1;-1,europe,uk,y,1;5;4
1835,ICLR,2019,Caveats for information bottleneck in deterministic scenarios,Artemy Kolchinsky;Brendan D. Tracey;Steven Van Kuyk,artemyk@gmail.com;tracey.brendan@gmail.com;steven.jvk@gmail.com,2;8;6,4;4;4,Accept (Poster),0,18,0.0,yes,9/27/18,Santa Fe Institute;;Victoria University of Wellington,information bottleneck;supervised learning;deep learning;information theory,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,y,
1836,ICLR,2019,Unsupervised Adversarial Image Reconstruction,Arthur Pajot;Emmanuel de Bezenac;Patrick Gallinari,arthur.pajot@lip6.fr;emmanuel.de-bezenac@lip6.fr;patrick.gallinari@lip6.fr,6;8;4,3;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,LIP6;LIP6;LIP6,Deep Learning;Adversarial;MAP;GAN;neural networks,419;419;419,-1;-1;-1,-1;-1,asia,ir,n,5;4
1837,ICLR,2019,LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING,Yanbin Liu;Juho Lee;Minseop Park;Saehoon Kim;Eunho Yang;Sung Ju Hwang;Yi Yang,csyanbin@gmail.com;juho.lee@stats.ox.ac.uk;mike_seop@aitrics.com;shkim@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr;yi.yang@uts.edu.au,5;6;7,3;3;4,Accept (Poster),7,12,0.0,yes,9/27/18,University of Technology Sydney;University of Oxford;AITRICS;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;University of Technology Sydney,few-shot learning;meta-learning;label propagation;manifold learning,67;44;-1;-1;-1;-1;67,216;1;-1;-1;95;95;216,-1;-1,australasia,au,n,6;10
1838,ICLR,2019,Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet,Wieland Brendel;Matthias Bethge,wieland.brendel@bethgelab.org;matthias.bethge@uni-tuebingen.de,6;7;7,4;4;4,Accept (Poster),2,19,2.0,yes,9/27/18,"Centre for Integrative Neuroscience, AG Bethge;University of Tuebingen",interpretability;representation learning;bag of features;deep learning;object recognition,-1;136,-1;94,-1;-1,europe,de,n,
1839,ICLR,2019,"Attention, Learn to Solve Routing Problems!",Wouter Kool;Herke van Hoof;Max Welling,w.w.m.kool@uva.nl;h.c.vanhoof@uva.nl;m.welling@uva.nl,7;6;7,5;5;5,Accept (Poster),0,5,0.0,yes,9/27/18,University of Amsterdam;University of Amsterdam;University of Amsterdam,learning;routing problems;heuristics;attention;reinforce;travelling salesman problem;vehicle routing problem;orienteering problem;prize collecting travelling salesman problem,136;136;136,59;59;59,-1;-1,europe,nl,n,8
1840,ICLR,2019,Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images,Sanjana Srivastava;Guy Ben-Yosef;Xavier Boix,sanjanas@mit.edu;gby@csail.mit.edu;xboix@mit.edu,7;7;6,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,,6;6;6,5;5;5,-1;-1,usa,usa,n,4
1841,ICLR,2019,Detecting Egregious Responses in Neural Sequence-to-sequence Models,Tianxing He;James Glass,tianxing@mit.edu;glass@mit.edu,7;7;8,4;3;2,Accept (Poster),0,8,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deep Learning;Natural Language Processing;Adversarial Attacks;Dialogue Response Generation,6;6,5;5,-1;-1,usa,usa,n,4
1842,ICLR,2019,Analyzing Inverse Problems with Invertible Neural Networks,Lynton Ardizzone;Jakob Kruse;Carsten Rother;Ullrich K√∂the,lynton.ardizzone@iwr.uni-heidelberg.de;jakob.kruse@iwr.uni-heidelberg.de;carsten.rother@iwr.uni-heidelberg.de;ullrich.koethe@iwr.uni-heidelberg.de,7;7;6,5;2;3,Accept (Poster),2,16,0.0,yes,9/27/18,Heidelberg University;Heidelberg University;Heidelberg University;Heidelberg University,Inverse problems;Neural Networks;Uncertainty;Invertible Neural Networks,207;207;207;207,45;45;45;45,-1;-1,europe,de,n,1
1843,ICLR,2019,Initialized Equilibrium Propagation for Backprop-Free Training,Peter O'Connor;Efstratios Gavves;Max Welling,peter.ed.oconnor@gmail.com;egavves@uva.nl;m.welling@uva.nl,7;5;8,5;4;5,Accept (Poster),0,10,1.0,yes,9/27/18,University of Amsterdam;University of Amsterdam;University of Amsterdam,credit assignment;energy-based models;biologically plausible learning,-1;136;136,-1;59;59,-1;-1,europe,nl,n,
1844,ICLR,2019,L2-Nonexpansive Neural Networks,Haifeng Qian;Mark N. Wegman,qianhaifeng@us.ibm.com;wegman@us.ibm.com,8;5;6,4;3;4,Accept (Poster),13,49,0.0,yes,9/27/18,International Business Machines;International Business Machines,adversarial defense;regularization;robustness;generalization,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1;4
1845,ICLR,2019,KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks,James Jordon;Jinsung Yoon;Mihaela van der Schaar,james.jordon@wolfson.ox.ac.uk;jsyoon0823@gmail.com;mihaela.vanderschaar@eng.ox.ac.uk,6;10;7,4;4;4,Accept (Oral),0,4,1.0,yes,9/27/18,University of Oxford;Google;University of Oxford,Knockoff model;Feature selection;False discovery rate control;Generative Adversarial networks,44;-1;44,1;-1;1,-1;-1,europe,uk,y,5;4
1846,ICLR,2019,INVASE: Instance-wise Variable Selection using Neural Networks,Jinsung Yoon;James Jordon;Mihaela van der Schaar,jsyoon0823@gmail.com;james.jordon@wolfson.ox.ac.uk;mihaela.vanderschaar@eng.ox.ac.uk,6;6;6,3;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,Google;University of Oxford;University of Oxford,Instance-wise feature selection;interpretability;actor-critic methodology,-1;44;44,-1;1;1,-1;-1,europe,uk,n,
1847,ICLR,2019,Gradient Descent Provably Optimizes Over-parameterized Neural Networks,Simon S. Du;Xiyu Zhai;Barnabas Poczos;Aarti Singh,ssdu@cs.cmu.edu;xiyuzhai@mit.edu;bapoczos@cs.cmu.edu;aartisingh@cmu.edu,8;8;3;7,4;4;5;4,Accept (Poster),18,18,1.0,yes,9/27/18,Carnegie Mellon University;Massachusetts Institute of Technology;Carnegie Mellon University;Carnegie Mellon University,theory;non-convex optimization;overparameterization;gradient descent,1;6;1;1,24;5;24;24,-1;-1,usa,usa,y,1;9
1848,ICLR,2019,Phase-Aware Speech Enhancement with Deep Complex U-Net,Hyeong-Seok Choi;Jang-Hyun Kim;Jaesung Huh;Adrian Kim;Jung-Woo Ha;Kyogu Lee,kekepa15@snu.ac.kr;blue378@snu.ac.kr;jaesung.huh@navercorp.com;adrian.kim@navercorp.com;jungwoo.ha@navercorp.com;kglee@snu.ac.kr,6;7;7,4;4;4,Accept (Poster),0,5,2.0,yes,9/27/18,Seoul National University;Seoul National University;NAVER;NAVER;NAVER;Seoul National University,speech enhancement;deep learning;complex neural networks;phase estimation,36;36;-1;-1;-1;36,74;74;-1;-1;-1;74,-1;-1,asia,kr,n,
1849,ICLR,2019,Context-adaptive Entropy Model for End-to-end Optimized Image Compression,Jooyoung Lee;Seunghyun Cho;Seung-Kwon Beack,leejy1003@etri.re.kr;shcho@etri.re.kr;skbeack@etri.re.kr,7;7;6,5;4;3,Accept (Poster),3,9,0.0,yes,9/27/18,Electronics and Telecommunicatios Research Institute;Electronics and Telecommunicatios Research Institute;Electronics and Telecommunicatios Research Institute,image compression;deep learning;entropy model,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
1850,ICLR,2019,Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer,Hsueh-Ti Derek Liu;Michael Tao;Chun-Liang Li;Derek Nowrouzezahrai;Alec Jacobson,hsuehtil@cs.toronto.edu;mtao@dgp.toronto.edu;chunlial@cs.cmu.edu;derek@cim.mcgill.ca;jacobson@cs.toronto.edu,7;7;6,4;4;3,Accept (Poster),0,8,0.0,yes,9/27/18,University of Toronto;University of Toronto;Carnegie Mellon University;McGill University;University of Toronto,adversarial examples;norm-balls;differentiable renderer,18;18;1;94;18,22;22;24;42;22,-1;-1,canada,ca,n,4
1851,ICLR,2019,Multilingual Neural Machine Translation With Soft Decoupled Encoding,Xinyi Wang;Hieu Pham;Philip Arthur;Graham Neubig,xinyiw1@cs.cmu.edu;hyhieu@cmu.edu;philip.arthur@monash.edu;gneubig@cs.cmu.edu,6;7;6,5;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Monash University;Carnegie Mellon University,,1;1;94;1,24;24;80;24,-1;-1,usa,usa,n,3
1852,ICLR,2019,Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching,Chih-Kuan Yeh;Jianshu Chen;Chengzhu Yu;Dong Yu,cjyeh@cs.cmu.edu;chenjianshu@gmail.com;czyu@tencent.com;dyu@tencent.com,7;7;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Carnegie Mellon University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab,Unsupervised speech recognition;unsupervised learning;phoneme classification,1;-1;-1;-1,24;-1;-1;-1,-1;-1,NAN,NAN,n,2;3
1853,ICLR,2019,Understanding Composition of Word Embeddings via Tensor Decomposition,Abraham Frandsen;Rong Ge,abef@cs.duke.edu;rongge@cs.duke.edu,7;6;6,2;4;3,Accept (Poster),0,4,0.0,yes,9/27/18,Duke University;Duke University,word embeddings;semantic composition;tensor decomposition,47;47,17;17,-1;-1,europe,se,y,3;1;5
1854,ICLR,2019,Neural Message Passing for Multi-Label Classification,Jack Lanchantin;Arshdeep Sekhon;Yanjun Qi,jjl5sw@virginia.edu;as5cu@virginia.edu;yq2h@virginia.edu,4;6;5,4;4;2,Reject,0,17,0.0,yes,9/27/18,University of Virginia;University of Virginia;University of Virginia,Multi-label Classification;Graph Neural Networks;Attention;Graph Attention,59;59;59,113;113;113,-1;-1,usa,usa,n,
1855,ICLR,2019,ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks,Mingzhang Yin;Mingyuan Zhou,mzyin@utexas.edu;mingyuan.zhou@mccombs.utexas.edu,8;6;7,4;4;3,Accept (Poster),0,10,1.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",Antithetic sampling;variable augmentation;deep discrete latent variable models;variance reduction;variational auto-encoder,-1;-1,-1;-1,-1;-1,usa,usa,y,
1856,ICLR,2019,An Empirical Study of Example Forgetting during Deep Neural Network Learning,Mariya Toneva*;Alessandro Sordoni*;Remi Tachet des Combes*;Adam Trischler;Yoshua Bengio;Geoffrey J. Gordon,mariya.k.toneva@gmail.com;alsordon@microsoft.com;retachet@microsoft.com;adtrisch@microsoft.com;yoshua.bengio@mila.quebec;geoff.gordon@microsoft.com,7;8;9,4;4;5,Accept (Poster),0,9,1.0,yes,9/27/18,Carnegie Mellon University;Microsoft;Microsoft;Microsoft;Mila;Microsoft,catastrophic forgetting;sample weighting;deep generalization,-1;-1;-1;-1;136;-1,-1;-1;-1;-1;314;-1,-1;-1,NAN,NAN,n,1
1857,ICLR,2019,Distribution-Interpolation Trade off in Generative Models,Damian Le≈õniak;Igor Sieradzki;Igor Podolak,damian.lesniak@doctoral.uj.edu.pl;igor.sieradzki@doctoral.uj.edu.pl;igor.podolak@uj.edu.pl,6;5;7,4;4;3,Accept (Poster),0,9,0.0,yes,9/27/18,Jagiellonian University;Jagiellonian University;Jagiellonian University,generative models;latent distribution;Cauchy distribution;interpolations,-1;-1;-1,695;695;695,-1;-1,NAN,NAN,n,1;5
1858,ICLR,2019,Practical lossless compression with latent variables using bits back coding,James Townsend;Thomas Bird;David Barber,james.townsend@cs.ucl.ac.uk;thomas.bird@cs.ucl.ac.uk;david.barber@ucl.ac.uk,6;6;8,4;3;5,Accept (Poster),0,7,1.0,yes,9/27/18,University College London;University College London;University College London,compression;variational auto-encoders;deep latent gaussian models;lossless compression;latent variables;approximate inference;variational inference,50;50;50,-1;-1;-1,-1;-1,europe,uk,n,5
1859,ICLR,2019,Double Viterbi: Weight Encoding for High Compression Ratio and Fast On-Chip Reconstruction for Deep Neural Network,Daehyun Ahn;Dongsoo Lee;Taesu Kim;Jae-Joon Kim,daehyun.ahn@postech.ac.kr;dslee3@gmail.com;taesukim@postech.ac.kr;jaejoon@postech.ac.kr,6;7;6,3;2;4,Accept (Poster),0,13,0.0,yes,9/27/18,POSTECH;Samsung;POSTECH;POSTECH,quantization;pruning;memory footprint;model compression;sparse matrix,136;-1;136;136,137;-1;137;137,-1;-1,asia,kr,n,
1860,ICLR,2019,Zero-training Sentence Embedding via Orthogonal Basis,Ziyi Yang;Chenguang Zhu;Weizhu Chen,ziyi.yang@stanford.edu;chezhu@microsoft.com;wzchen@microsoft.com,5;4;5,4;4;4,Reject,6,6,0.0,yes,9/27/18,Stanford University;Microsoft;Microsoft,Natural Language Processing;Sentence Embeddings,4;-1;-1,3;-1;-1,-1;-1,NAN,NAN,n,3;1
1861,ICLR,2019,Guiding Policies with Language via Meta-Learning,John D. Co-Reyes;Abhishek Gupta;Suvansh Sanjeev;Nick Altieri;Jacob Andreas;John DeNero;Pieter Abbeel;Sergey Levine,jcoreyes@eecs.berkeley.edu;abhigupta@berkeley.edu;suvansh@berkeley.edu;naltieri@berkeley.edu;j.d.andreas@gmail.com;denero@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,6;6;6,4;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Massachusetts Institute of Technology;University of California Berkeley;University of California Berkeley;University of California Berkeley,meta-learning;language grounding;interactive,-1;-1;-1;-1;6;-1;-1;-1,18;18;18;18;5;18;18;18,-1;-1,usa,usa,n,6;3
1862,ICLR,2019,Towards the first adversarially robust neural network model on MNIST,Lukas Schott;Jonas Rauber;Matthias Bethge;Wieland Brendel,lukas.schott@bethgelab.org;jonas.rauber@bethgelab.org;matthias.bethge@bethgelab.org;wieland.brendel@bethgelab.org,7;7;6,4;3;3,Accept (Poster),7,18,1.0,yes,9/27/18,"Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge",adversarial examples;MNIST;robustness;deep learning;security,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;4
1863,ICLR,2019,Neural network gradient-based learning of black-box function interfaces,Alon Jacovi;Guy Hadash;Einat Kermany;Boaz Carmeli;Ofer Lavi;George Kour;Jonathan Berant,alon.jacovi@il.ibm.com;guyh@il.ibm.com;einatke@il.ibm.com;boazc@il.ibm.com;oferl@il.ibm.com;gkour@ibm.com;joberant@cs.tau.ac.il,7;7;7,3;3;3,Accept (Poster),0,5,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Tel Aviv University,neural networks;black box functions;gradient descent,-1;-1;-1;-1;-1;-1;31,-1;-1;-1;-1;-1;-1;217,-1;-1,europe,il,n,
1864,ICLR,2019,Learning Multimodal Graph-to-Graph Translation for Molecule Optimization,Wengong Jin;Kevin Yang;Regina Barzilay;Tommi Jaakkola,wengong@csail.mit.edu;yangk@mit.edu;regina@csail.mit.edu;tommi@csail.mit.edu,7;7;6,5;4;4,Accept (Poster),0,9,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,graph-to-graph translation;graph generation;molecular optimization,6;6;6;6,5;5;5;5,-1;-1,usa,usa,n,10;4
1865,ICLR,2019,Lagging Inference Networks and Posterior Collapse in Variational Autoencoders,Junxian He;Daniel Spokoyny;Graham Neubig;Taylor Berg-Kirkpatrick,junxianh@cs.cmu.edu;dspokoyn@cs.cmu.edu;gneubig@cs.cmu.edu;tberg@cs.cmu.edu,8;7;8,4;4;4,Accept (Poster),3,12,2.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,variational autoencoders;posterior collapse;generative models,1;1;1;1,24;24;24;24,-1;-1,usa,usa,n,1;5
1866,ICLR,2019,Stable Opponent Shaping in Differentiable Games,Alistair Letcher;Jakob Foerster;David Balduzzi;Tim Rockt√§schel;Shimon Whiteson,ahp.letcher@gmail.com;jakobfoerster@gmail.com;dbalduzzi@google.com;tim.rocktaeschel@gmail.com;shimon.whiteson@cs.ox.ac.uk,8;6;6,4;2;1,Accept (Poster),0,7,0.0,yes,9/27/18,University of Oxford;;Google;Facebook AI Research;University of Oxford,multi-agent learning;multiple interacting losses;opponent shaping;exploitation;convergence,-1;-1;-1;-1;44,-1;-1;-1;-1;1,-1;-1,europe,uk,n,1;5
1867,ICLR,2019,DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NETWORKS,Xingjian Li;Haoyi Xiong;Hanchao Wang;Yuxuan Rao;Liping Liu;Jun Huan,1762778193@qq.com;xhyccc@gmail.com;wanghanchao01@baidu.com;yrao4@illinois.edu;liuliping@baidu.com;huanjun@baidu.com,6;7;6,4;3;4,Accept (Poster),0,9,0.0,yes,9/27/18,"Baidu;Baidu;Baidu;University of Illinois, Urbana Champaign;Baidu;Baidu",transfer learning;deep learning;regularization;attention;cnn,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;8
1868,ICLR,2019,CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild,Yang Zhang;Hassan Foroosh;Philip David;Boqing Gong,yangzhang4065@gmail.com;foroosh@cs.ucf.edu;philip.j.david4.civ@mail.mil;boqinggo@outlook.com,4;8;7,3;4;3,Accept (Poster),0,4,4.0,yes,9/27/18,University of Central Florida;University of Central Florida;Army Reserach laboratory;International Computer Science Institute,Adversarial Attack;Object Detection;Synthetic Simulation,-1;77;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
1869,ICLR,2019,Visual Reasoning by Progressive Module Networks,Seung Wook Kim;Makarand Tapaswi;Sanja Fidler,seung@cs.toronto.edu;makarand@cs.toronto.edu;fidler@cs.toronto.edu,6;6;7,4;4;5,Accept (Poster),0,12,0.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto,,18;18;18,22;22;22,-1;-1,canada,ca,n,8
1870,ICLR,2019,Recurrent Experience Replay in Distributed Reinforcement Learning,Steven Kapturowski;Georg Ostrovski;John Quan;Remi Munos;Will Dabney,skapturowski@google.com;ostrovski@google.com;johnquan@google.com;munos@google.com;wdabney@google.com,7;8;7,2;4;3,Accept (Poster),7,11,0.0,yes,9/27/18,Google;Google;Google;Google;Google,RNN;LSTM;experience replay;distributed training;reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1871,ICLR,2019,Dynamic Sparse Graph for Efficient Deep Learning,Liu Liu;Lei Deng;Xing Hu;Maohua Zhu;Guoqi Li;Yufei Ding;Yuan Xie,liu_liu@ucsb.edu;leideng@ucsb.edu;huxing@ece.ucsb.edu;maohuazhu@ucsb.edu;liguoqi@mail.tsinghua.edu.cn;yufeiding@cs.ucsb.edu;yuanxie@ucsb.edu,7;8;7,2;3;4,Accept (Poster),0,4,0.0,yes,9/27/18,"UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;Tsinghua University, Tsinghua University;UC Santa Barbara;UC Santa Barbara",Sparsity;compression;training;acceleration,-1;-1;-1;-1;4;-1;-1,-1;-1;-1;-1;30;-1;-1,-1;-1,NAN,NAN,n,10
1872,ICLR,2019,Learning Recurrent Binary/Ternary Weights,Arash Ardakani;Zhengyun Ji;Sean C. Smithson;Brett H. Meyer;Warren J. Gross,arash.ardakani@mail.mcgill.ca;zhengyun.ji@mail.mcgill.ca;sean.smithson@mail.mcgill.ca;brett.meyer@mcgill.ca;warren.gross@mcgill.ca,7;6;8,4;3;3,Accept (Poster),0,11,0.0,yes,9/27/18,McGill University;McGill University;McGill University;McGill University;McGill University,Quantized Recurrent Neural Network;Hardware Implementation;Deep Learning,94;94;94;94;94,42;42;42;42;42,-1;-1,canada,ca,n,3
1873,ICLR,2019,Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning,Ying Wen;Yaodong Yang;Rui Luo;Jun Wang;Wei Pan,ying.wen@cs.ucl.ac.uk;yaodong.yang@cs.ucl.ac.uk;rui.luo@cs.ucl.ac.uk;jun.wang@cs.ucl.ac.uk;wei.pan@tudelft.nl,7;8;7,4;3;4,Accept (Poster),0,10,0.0,yes,9/27/18,University College London;University College London;University College London;University College London;Delft University of Technology,Multi-agent Reinforcement Learning;Recursive Reasoning,50;50;50;50;-1,-1;-1;-1;-1;63,-1;-1,NAN,NAN,y,
1874,ICLR,2019,"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware",Florian Tramer;Dan Boneh,tramer@cs.stanford.edu;dabo@cs.stanford.edu,7;7;9,3;2;4,Accept (Oral),0,4,10.0,yes,9/27/18,Stanford University;Stanford University,Trusted hardware;integrity;privacy;secure inference;SGX,4;4,3;3,-1;-1,usa,usa,y,
1875,ICLR,2019,"A comprehensive, application-oriented study of catastrophic forgetting in DNNs",B. Pf√ºlb;A. Gepperth,benedikt.pfuelb@cs.hs-fulda.de;alexander.gepperth@cs.hs-fulda.de,6;7;5,5;3;4,Accept (Poster),0,1,0.0,yes,9/27/18,University of Applied Sciences Fulda;University of Applied Sciences Fulda,incremental learning;deep neural networks;catatrophic forgetting;sequential learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1876,ICLR,2019,Stable Recurrent Models,John Miller;Moritz Hardt,miller_john@berkeley.edu;hardt@berkeley.edu,6;7;6,4;2;4,Accept (Poster),0,10,2.0,yes,9/27/18,University of California Berkeley;University of California Berkeley,stability;gradient descent;non-convex optimization;recurrent neural networks,-1;-1,18;18,-1;-1,usa,usa,y,1
1877,ICLR,2019,Large Scale Graph Learning From Smooth Signals,Vassilis Kalofolias;Nathana√´l Perraudin,v.kalofolias@gmail.com;nathanael.perraudin@sdsc.ethz.ch,7;5;7,5;3;4,Accept (Poster),0,7,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Graph learning;Graph signal processing;Network inference,-1;-1,-1;-1,-1;-1,NAN,NAN,y,10
1878,ICLR,2019,Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep Networks,Charbel Sakr;Naigang Wang;Chia-Yu Chen;Jungwook Choi;Ankur Agrawal;Naresh Shanbhag;Kailash Gopalakrishnan,sakr2@illinois.edu;nwang@us.ibm.com;cchen@us.ibm.com;choij@us.ibm.com;ankuragr@us.ibm.com;shanbhag@illinois.edu;kailash@us.ibm.com,7;6;6,4;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Illinois, Urbana Champaign;International Business Machines",reduced precision floating-point;partial sum accumulation bit-width;deep learning;training,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1879,ICLR,2019,Learning to Remember More with Less Memorization,Hung Le;Truyen Tran;Svetha Venkatesh,lethai@deakin.edu.au;truyen.tran@deakin.edu.au;svetha.venkatesh@deakin.edu.au,7;7;8,3;4;4,Accept (Oral),0,5,3.0,yes,9/27/18,Deakin University;Deakin University;Deakin University,memory-augmented neural networks;writing optimization,-1;-1;-1,334;334;334,-1;-1,asia,cn,y,1
1880,ICLR,2019,Bayesian Prediction of Future Street Scenes using Synthetic Likelihoods,Apratim Bhattacharyya;Mario Fritz;Bernt Schiele,abhattac@mpi-inf.mpg.de;mfritz@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de,6;8;6,4;4;2,Accept (Poster),0,8,1.0,yes,9/27/18,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,bayesian inference;segmentation;anticipation;multi-modality,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11
1881,ICLR,2019,Label super-resolution networks,Kolya Malkin;Caleb Robinson;Le Hou;Rachel Soobitsky;Jacob Czawlytko;Dimitris Samaras;Joel Saltz;Lucas Joppa;Nebojsa Jojic,kolya_malkin@hotmail.com;dcrobins@gatech.edu;le.hou@stonybrook.edu;rsoobitsky@chesapeakeconservancy.org;jczawlytko@chesapeakeconservancy.org;samaras@cs.stonybrook.edu;joel.saltz@stonybrookmedicine.edu;lujoppa@microsoft.com;jojic@microsoft.com,7;6;9,4;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,"Mila;Georgia Institute of Technology;State University of New York, Stony Brook;;;State University of New York, Stony Brook;Renaissance School of Medicine at Stony Brook University;Microsoft;Microsoft",weakly supervised segmentation;land cover mapping;medical imaging,136;13;-1;-1;-1;-1;36;-1;-1,314;33;-1;-1;-1;-1;258;-1;-1,-1;-1,NAN,NAN,n,2
1882,ICLR,2019,Variational Smoothing in Recurrent Neural Network Language Models,Lingpeng Kong;Gabor Melis;Wang Ling;Lei Yu;Dani Yogatama,lingpenk@cs.cmu.edu;melisgl@google.com;lingwang@google.com;leiyu@google.com;dyogatama@google.com,7;6;2,4;4;5,Accept (Poster),0,3,0.0,yes,9/27/18,Carnegie Mellon University;Google;Google;Google;Google,,1;-1;-1;-1;-1,24;-1;-1;-1;-1,-1;-1,NAN,NAN,y,11;3
1883,ICLR,2019,Hierarchical interpretations for neural network predictions,Chandan Singh;W. James Murdoch;Bin Yu,chandan_singh@berkeley.edu;jmurdoch@berkeley.edu;binyu@berkeley.edu,6;6;7,4;4;3,Accept (Poster),0,10,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,interpretability;natural language processing;computer vision,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,4
1884,ICLR,2019,h-detach: Modifying the LSTM Gradient Towards Better Optimization,Bhargav Kanuparthi;Devansh Arpit;Giancarlo Kerg;Nan Rosemary Ke;Ioannis Mitliagkas;Yoshua Bengio,bhargavkanuparthi25@gmail.com;devansharpit@gmail.com;giancarlo.kerg@gmail.com;rosemary.nan.ke@gmail.com;ioannis@iro.umontreal.ca;yoshua.umontreal@gmail.com,7;5;6,5;4;3,Accept (Poster),0,4,5.0,yes,9/27/18,University of Montreal;SalesForce.com;;;University of Montreal;University of Montreal,LSTM;Optimization;Long term dependencies;Back-propagation through time,-1;-1;-1;-1;116;116,-1;-1;-1;-1;108;108,-1;-1,canada,ca,n,1;10
1885,ICLR,2019,Neural Probabilistic Motor Primitives for Humanoid Control,Josh Merel;Leonard Hasenclever;Alexandre Galashov;Arun Ahuja;Vu Pham;Greg Wayne;Yee Whye Teh;Nicolas Heess,jsmerel@google.com;leonardh@google.com;agalashov@google.com;arahuja@google.com;vuph@google.com;gregwayne@google.com;ywteh@google.com;heess@google.com,3;6;4,4;4;4,Accept (Poster),0,8,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,Motor Primitives;Distillation;Reinforcement Learning;Continuous Control;Humanoid Control;Motion Capture;One-Shot Imitation,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1886,ICLR,2019,Hierarchical Visuomotor Control of Humanoids,Josh Merel;Arun Ahuja;Vu Pham;Saran Tunyasuvunakool;Siqi Liu;Dhruva Tirumala;Nicolas Heess;Greg Wayne,jsmerel@google.com;arahuja@google.com;vuph@google.com;stunya@google.com;liusiqi@google.com;dhruvat@google.com;heess@google.com;gregwayne@google.com,5;8;6,3;3;4,Accept (Poster),2,9,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,hierarchical reinforcement learning;motor control;motion capture,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1887,ICLR,2019,Adversarial Domain Adaptation for Stable Brain-Machine Interfaces,Ali Farshchian;Juan A. Gallego;Joseph P. Cohen;Yoshua Bengio;Lee E. Miller;Sara A. Solla,a-farshchiansadegh@northwestern.edu;juan.gallego@northwestern.edu;joseph@josephpcohen.com;yoshua.bengio@umontreal.ca;lm@northwestern.edu;solla@northwestern.edu,9;5;7,4;3;5,Accept (Poster),2,8,0.0,yes,9/27/18,Northwestern University;Northwestern University;Stanford University;University of Montreal;Northwestern University;Northwestern University,Brain-Machine Interfaces;Domain Adaptation;Adversarial Networks,50;50;4;116;50;50,20;20;3;108;20;20,-1;-1,usa,usa,n,4
1888,ICLR,2019,Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer,Ori Press;Tomer Galanti;Sagie Benaim;Lior Wolf,theoripress@gmail.com;tomer22g@gmail.com;sagiebenaim@gmail.com;wolf@fb.com,6;6;6,2;3;1,Accept (Poster),0,6,0.0,yes,9/27/18,Tel Aviv University;;Tel Aviv University;Facebook,Image-to-image Translation;Disentanglement;Autoencoders;Faces,31;-1;31;-1,217;-1;217;-1,-1;-1,NAN,NAN,y,
1889,ICLR,2019,Global-to-local Memory Pointer Networks for Task-Oriented Dialogue,Chien-Sheng Wu;Richard Socher;Caiming Xiong,jason.wu@connect.ust.hk;rsocher@salesforce.com;cxiong@salesforce.com,8;8;5,2;2;3,Accept (Poster),0,0,10.0,yes,9/27/18,The Hong Kong University of Science and Technology;SalesForce.com;SalesForce.com,pointer networks;memory networks;task-oriented dialogue systems;natural language processing,-1;-1;-1,44;-1;-1,-1;-1,NAN,NAN,n,
1890,ICLR,2019,"Improving Differentiable Neural Computers Through Memory Masking, De-allocation, and Link Distribution Sharpness Control",Robert Csordas;Juergen Schmidhuber,robert@idsia.ch;juergen@idsia.ch,7;8;7,5;5;5,Accept (Poster),0,5,0.0,yes,9/27/18,IDSIA;IDSIA,rnn;dnc;memory augmented neural networks;mann,-1;-1,-1;-1,-1;-1,asia,in,n,
1891,ICLR,2019,Learning Representations of Sets through Optimized Permutations,Yan Zhang;Jonathon Hare;Adam Pr√ºgel-Bennett,yz5n12@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,3;6;6,2;4;4,Accept (Poster),0,25,0.0,yes,9/27/18,University of Southampton;University of Southampton;University of Southampton,sets;representation learning;permutation invariance,207;207;207,126;126;126,-1;-1,europe,uk,n,
1892,ICLR,2019,Kernel Change-point Detection with Auxiliary Deep Generative Models,Wei-Cheng Chang;Chun-Liang Li;Yiming Yang;Barnab√°s P√≥czos,wchang2@cs.cmu.edu;chunlial@cs.cmu.edu;yiming@cs.cmu.edu;bapoczos@cs.cmu.edu,7;8;8,4;3;4,Accept (Poster),0,5,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,deep kernel learning;generative models;kernel two-sample test;time series change-point detection,1;1;1;1,24;24;24;24,-1;-1,usa,usa,n,1;5
1893,ICLR,2019,Unsupervised Domain Adaptation for Distance Metric Learning,Kihyuk Sohn;Wenling Shang;Xiang Yu;Manmohan Chandraker,kihyuk.sohn@gmail.com;wendyshang1208@gmail.com;xiangyu@nec-labs.com;manu@nec-labs.com,8;5;8,5;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Google;;NEC-Labs;NEC-Labs,domain adaptation;distance metric learning;face recognition,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,2;1;7
1894,ICLR,2019,Feature Intertwiner for Object Detection,Hongyang Li;Bo Dai;Shaoshuai Shi;Wanli Ouyang;Xiaogang Wang,yangli@ee.cuhk.edu.hk;db014@ie.cuhk.edu.hk;shaoss@link.cuhk.edu.hk;wanli.ouyang@gmail.com;xgwang@ee.cuhk.edu.hk,7;5;9,3;4;4,Accept (Poster),0,3,0.0,yes,9/27/18,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;University of Sydney;The Chinese University of Hong Kong,feature learning;computer vision;deep learning,285;285;285;67;285,40;40;40;61;40,-1;-1,NAN,NAN,n,2
1895,ICLR,2019,On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks,Yukun Ding;Jinglan Liu;Jinjun Xiong;Yiyu Shi,yding5@nd.edu;jliu16@nd.edu;jinjun@us.ibm.com;yshi4@nd.edu,7;6;8,3;3;3,Accept (Poster),0,4,0.0,yes,9/27/18,University of Notre Dame;University of Notre Dame;International Business Machines;University of Notre Dame,Quantized Neural Networks;Universial Approximability;Complexity Bounds;Optimal Bit-width,116;116;-1;116,150;150;-1;150,-1;-1,usa,usa,y,1
1896,ICLR,2019,SNAS: stochastic neural architecture search,Sirui Xie;Hehui Zheng;Chunxiao Liu;Liang Lin,xiesirui@sensetime.com;zhenghehui@sensetime.com;liuchunxiao@sensetime.com;linliang@ieee.org,7;6;7,4;4;4,Accept (Poster),2,19,1.0,yes,9/27/18,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SUN YAT-SEN UNIVERSITY,Neural Architecture Search,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,8;1
1897,ICLR,2019,LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators,Jianan Li;Jimei Yang;Aaron Hertzmann;Jianming Zhang;Tingfa Xu,lijianan15@gmail.com;jimyang@adobe.com;hertzman@adobe.com;jianmzha@adobe.com;ciom_xtf1@bit.edu.cn,7;7;6,3;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,National University of Singapore;Adobe Systems;Adobe Systems;Adobe Systems;Beijing Institute of Technology,,18;-1;-1;-1;-1,22;-1;-1;-1;688,-1;-1,NAN,NAN,n,8;10;5;4
1898,ICLR,2019,"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors",Vitalii Zhelezniak;Aleksandar Savkov;April Shen;Francesco Moramarco;Jack Flann;Nils Y. Hammerla,vitali.zhelezniak@babylonhealth.com;sasho.savkov@babylonhealth.com;april.shen@babylonhealth.com;francesco.moramarco@babylonhealth.com;jack.flann@babylonhealth.com;nils.hammerla@babylonhealth.com,8;8;5,3;4;3,Accept (Poster),3,12,1.0,yes,9/27/18,babylon health;babylon health;babylon health;babylon health;babylon health;babylon health,word vectors;sentence representations;distributed representations;fuzzy sets;bag-of-words;unsupervised learning;word vector compositionality;max-pooling;Jaccard index,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
1899,ICLR,2019,ADef: an Iterative Algorithm to Construct Adversarial Deformations,Rima Alaifari;Giovanni S. Alberti;Tandri Gauksson,rima.alaifari@sam.math.ethz.ch;alberti@dima.unige.it;tandrig@sam.math.ethz.ch,6;7;7,3;4;3,Accept (Poster),0,8,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Universit√† degli Studi di Genova;Swiss Federal Institute of Technology,Adversarial examples;deformations;deep neural networks;computer vision,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
1900,ICLR,2019,On the Turing Completeness of Modern Neural Network Architectures,Jorge P√©rez;Javier Marinkoviƒá;Pablo Barcel√≥,jperez@dcc.uchile.cl;javier.marinkovic95@gmail.com;pbarcelo@dcc.uchile.cl,6;7;7,2;2;2,Accept (Poster),2,14,0.0,yes,9/27/18,Universidad de Chile;;Universidad de Chile,Transformer;NeuralGPU;Turing completeness,285;-1;285,-1;-1;-1,-1;-1,southamerica,cl,y,8
1901,ICLR,2019,Spherical CNNs on Unstructured Grids,Chiyu Max Jiang;Jingwei Huang;Karthik Kashinath;Prabhat;Philip Marcus;Matthias Niessner,chiyu.jiang@berkeley.edu;jingweih@stanford.edu;kkashinath@lbl.gov;prabhat@lbl.gov;pmarcus@me.berkeley.edu;niessner@tum.de,7;6;7,3;3;5,Accept (Poster),2,3,0.0,yes,9/27/18,University of California Berkeley;Stanford University;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;University of California Berkeley;Technical University Munich,Spherical CNN;unstructured grid;panoramic;semantic segmentation;parameter efficiency,-1;4;-1;-1;-1;-1,18;3;-1;-1;18;-1,-1;-1,NAN,NAN,n,2
1902,ICLR,2019,Convolutional Neural Networks on Non-uniform Geometrical Signals Using Euclidean Spectral Transformation,Chiyu Max Jiang;Dequan Wang;Jingwei Huang;Philip Marcus;Matthias Niessner,chiyu.jiang@berkeley.edu;dqw@berkeley.edu;jingweih@stanford.edu;pmarcus@me.berkeley.edu;niessner@tum.de,5;7;4,3;4;3,Accept (Poster),0,3,1.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley;Technical University Munich,Non-uniform Fourier Transform;3D Learning;CNN;surface reconstruction,-1;-1;4;-1;-1,18;18;3;18;-1,-1;-1,NAN,NAN,n,10
1903,ICLR,2019,Graph Wavelet Neural Network,Bingbing Xu;Huawei Shen;Qi Cao;Yunqi Qiu;Xueqi Cheng,xubingbing@ict.ac.cn;shenhuawei@ict.ac.cn;caoqi@ict.ac.cn;qiuyunqi@ict.ac.cn;cxq@ict.ac.cn,7;7;4,5;4;4,Accept (Poster),8,17,4.0,yes,9/27/18,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",graph convolution;graph wavelet transform;graph Fourier transform;semi-supervised learning,31;31;31;31;31,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,10
1904,ICLR,2019,"A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation",Akhilesh Gotmare;Nitish Shirish Keskar;Caiming Xiong;Richard Socher,akhilesh.gotmare@epfl.ch;nkeskar@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,4;7;6,4;5;4,Accept (Poster),0,5,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;SalesForce.com;SalesForce.com;SalesForce.com,deep learning heuristics;learning rate restarts;learning rate warmup;knowledge distillation;mode connectivity;SVCCA,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,9
1905,ICLR,2019,Revealing interpretable object representations from human behavior,Charles Y. Zheng;Francisco Pereira;Chris I. Baker;Martin N. Hebart,charles.zheng@nih.gov;francisco.pereira@nih.gov;bakerchris@mail.nih.gov;martin.hebart@nih.gov,5;7;7,4;4;4,Accept (Poster),0,6,0.0,yes,9/27/18,National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health,category representation;sparse coding;representation learning;interpretable representations,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1906,ICLR,2019,Near-Optimal Representation Learning for Hierarchical Reinforcement Learning,Ofir Nachum;Shixiang Gu;Honglak Lee;Sergey Levine,ofirnachum@google.com;shanegu@google.com;honglak@google.com;svlevine@eecs.berkeley.edu,8;7;9,3;5;5,Accept (Poster),1,11,0.0,yes,9/27/18,Google;Google;Google;University of California Berkeley,representation hierarchy reinforcement learning,-1;-1;-1;-1,-1;-1;-1;18,-1;-1,usa,usa,y,1
1907,ICLR,2019,Quaternion Recurrent Neural Networks,Titouan Parcollet;Mirco Ravanelli;Mohamed Morchid;Georges Linar√®s;Chiheb Trabelsi;Renato De Mori;Yoshua Bengio,titouan.parcollet@alumni.univ-avignon.fr;mirco.ravanelli@gmail.com;mohamed.morchid@univ-avignon.fr;georges.linares@univ-avignon.fr;chiheb.trabelsi@polymtl.ca;rdemori@cs.mcgill.ca;yoshua.bengio@mila.quebec,7;7;8,5;5;4,Accept (Poster),0,8,0.0,yes,9/27/18,Avignon University;University of Montreal;Avignon University;Avignon University;Polytechnique Montreal;McGill University;Mila,Quaternion recurrent neural networks;quaternion numbers;recurrent neural networks;speech recognition,-1;116;-1;-1;285;94;136,-1;108;-1;-1;-1;42;314,-1;-1,NAN,NAN,n,
1908,ICLR,2019,Efficient Lifelong Learning with A-GEM,Arslan Chaudhry;Marc‚ÄôAurelio Ranzato;Marcus Rohrbach;Mohamed Elhoseiny,arslan.chaudhry@eng.ox.ac.uk;ranzato@fb.com;mrf@fb.com;elhoseiny@fb.com,7;7;6,4;4;4,Accept (Poster),0,0,7.0,yes,9/27/18,University of Oxford;Facebook;Facebook;Facebook,Lifelong Learning;Continual Learning;Catastrophic Forgetting;Few-shot Transfer,44;-1;-1;-1,1;-1;-1;-1,-1;-1,NAN,NAN,n,
1909,ICLR,2019,Quasi-hyperbolic momentum and Adam for deep learning,Jerry Ma;Denis Yarats,maj@fb.com;denisy@fb.com,6;7;8,4;4;3,Accept (Poster),0,18,1.0,yes,9/27/18,Facebook;Facebook,sgd;momentum;nesterov;adam;qhm;qhadam;optimization,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
1910,ICLR,2019,AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods,Zhiming Zhou*;Qingru Zhang*;Guansong Lu;Hongwei Wang;Weinan Zhang;Yong Yu,heyohai@apex.sjtu.edu.cn;neverquit@sjtu.edu.cn;gslu@apex.sjtu.edu.cn;wanghongwei55@gmail.com;wnzhang@sjtu.edu.cn;yyu@apex.sjtu.edu.cn,6;6;9,4;4;4,Accept (Poster),3,5,5.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Stanford University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,optimizer;Adam;convergence;decorrelation,36;36;36;4;36;36,188;188;188;3;188;188,-1;-1,asia,cn,y,1
1911,ICLR,2019,Diversity is All You Need: Learning Skills without a Reward Function,Benjamin Eysenbach;Abhishek Gupta;Julian Ibarz;Sergey Levine,beysenba@cs.cmu.edu;abhigupta@berkeley.edu;julianibarz@google.com;svlevine@eecs.berkeley.edu,8;7;7,4;3;4,Accept (Poster),0,3,0.0,yes,9/27/18,Carnegie Mellon University;University of California Berkeley;Google;University of California Berkeley,reinforcement learning;unsupervised learning;skill discovery,1;-1;-1;-1,24;18;-1;18,-1;-1,usa,usa,n,
1912,ICLR,2019,MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders,Xuezhe Ma;Chunting Zhou;Eduard Hovy,xuezhem@cs.cmu.edu;ctzhou@cs.cmu.edu;ehovy@cs.cmu.edu,7;6;6,5;4;4,Accept (Poster),2,7,1.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,VAE;regularization;auto-regressive,1;1;1,24;24;24,-1;-1,usa,usa,y,5
1913,ICLR,2019,Learning a SAT Solver from Single-Bit Supervision,"Daniel Selsam;Matthew Lamm;Benedikt B\{u}nz;Percy Liang;Leonardo de Moura;David L. Dill""",dselsam@cs.stanford.edu;mlamm@cs.stanford.edu;buenz@cs.stanford.edu;pliang@cs.stanford.edu;leonardo@microsoft.com;dill@cs.stanford.edu,7;7;7,3;4;3,Accept (Poster),1,14,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University;Microsoft;Stanford University,sat;search;graph neural network;theorem proving;proof,4;4;4;4;-1;4,3;3;3;3;-1;3,-1;-1,usa,usa,n,10
1914,ICLR,2019, Reasoning About Physical Interactions with Object-Oriented Prediction and Planning,Michael Janner;Sergey Levine;William T. Freeman;Joshua B. Tenenbaum;Chelsea Finn;Jiajun Wu,janner@berkeley.edu;svlevine@eecs.berkeley.edu;billf@mit.edu;jbt@mit.edu;cbfinn@eecs.berkeley.edu;jiajunwu@mit.edu,7;9;5,4;4;5,Accept (Poster),4,5,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley;Massachusetts Institute of Technology,structured scene representation;predictive models;intuitive physics;self-supervised learning,-1;-1;6;6;-1;6,18;18;5;5;18;5,-1;-1,usa,usa,n,
1915,ICLR,2019, The relativistic discriminator: a key element missing from standard GAN,Alexia Jolicoeur-Martineau,alexia.jolicoeur-martineau@mail.mcgill.ca,6;6;7,2;4;3,Accept (Poster),0,5,3.0,yes,9/27/18,McGill University,AI;deep learning;generative models;GAN,94,42,-1,canada,ca,n,5;4
1916,ICLR,2019,SOM-VAE: Interpretable Discrete Representation Learning on Time Series,Vincent Fortuin;Matthias H√ºser;Francesco Locatello;Heiko Strathmann;Gunnar R√§tsch,fortuin@inf.ethz.ch;mhueser@inf.ethz.ch;locatelf@inf.ethz.ch;heiko.strathmann@gmail.com;raetsch@inf.ethz.ch,6;9;6,2;4;4,Accept (Poster),0,1,2.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Google;Swiss Federal Institute of Technology,deep learning;self-organizing map;variational autoencoder;representation learning;time series;machine learning;interpretability,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
1917,ICLR,2019,The Limitations of Adversarial Training and the Blind-Spot Attack,Huan Zhang*;Hongge Chen*;Zhao Song;Duane Boning;Inderjit S. Dhillon;Cho-Jui Hsieh,huan@huan-zhang.com;chenhg@mit.edu;zhaos@utexas.edu;boning@mtl.mit.edu;inderjit@cs.utexas.edu;chohsieh@cs.ucla.edu,6;7;7,4;3;2,Accept (Poster),0,10,0.0,yes,9/27/18,"Carnegie Mellon University;Massachusetts Institute of Technology;University of Texas, Austin;Massachusetts Institute of Technology;University of Texas, Austin;University of California, Los Angeles",Adversarial Examples;Adversarial Training;Blind-Spot Attack,1;6;-1;6;-1;-1,24;5;-1;5;-1;15,-1;-1,usa,usa,n,4
1918,ICLR,2019,Generating Multiple Objects at Spatially Distinct Locations,Tobias Hinz;Stefan Heinrich;Stefan Wermter,hinz@informatik.uni-hamburg.de;heinrich@informatik.uni-hamburg.de;wermter@informatik.uni-hamburg.de,6;7;8,4;4;4,Accept (Poster),0,8,1.0,yes,9/27/18,University of Hamburg;University of Hamburg;University of Hamburg,controllable image generation;text-to-image synthesis;generative model;generative adversarial network;gan,207;207;207,207;207;207,-1;-1,europe,de,n,3;5;4
1919,ICLR,2019,Multi-class classification without multi-class labels,Yen-Chang Hsu;Zhaoyang Lv;Joel Schlosser;Phillip Odom;Zsolt Kira,yenchang.hsu@gatech.edu;zhaoyang.lv@gatech.edu;joel.schlosser@gtri.gatech.edu;phillip.odom@gtri.gatech.edu;zkira@gatech.edu,6;7;5,3;4;4,Accept (Poster),0,5,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,classification;unsupervised learning;semi-supervised learning;problem reduction;weak supervision;cross-task;learning;deep learning;neural network,13;13;13;13;13,33;33;33;33;33,-1;-1,usa,usa,n,10
1920,ICLR,2019,Optimal Completion Distillation for Sequence Learning,Sara Sabour;William Chan;Mohammad Norouzi,sasabour@google.com;williamchan@google.com;mnorouzi@google.com,7;7;6,4;4;3,Accept (Poster),1,8,1.0,yes,9/27/18,Google;Google;Google,Sequence Learning;Edit Distance;Speech Recognition;Deep Reinforcement Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
1921,ICLR,2019,Graph HyperNetworks for Neural Architecture Search,Chris Zhang;Mengye Ren;Raquel Urtasun,cjzhang@edu.uwaterloo.ca;mren@cs.toronto.edu;urtasun@cs.toronto.edu,7;6;7,4;4;4,Accept (Poster),5,7,0.0,yes,9/27/18,University of Waterloo;University of Toronto;University of Toronto,neural;architecture;search;graph;network;hypernetwork;meta;learning;anytime;prediction,31;18;18,207;22;22,-1;-1,canada,ca,n,10
1922,ICLR,2019,GO Gradient for Expectation-Based Objectives,Yulai Cong;Miaoyun Zhao;Ke Bai;Lawrence Carin,yulaicong@gmail.com;miaoyun9zhao@gmail.com;ke.bai@duke.edu;lcarin@duke.edu,7;7;6,4;4;4,Accept (Poster),2,5,3.0,yes,9/27/18,Duke University;Duke University;Duke University;Duke University,generalized reparameterization gradient;variance reduction;non-reparameterizable;discrete random variable;GO gradient;general and one-sample gradient;expectation-based objective;variable nabla;statistical back-propagation;hierarchical;graphical model,47;47;47;47,17;17;17;17,-1;-1,europe,se,y,
1923,ICLR,2019,InstaGAN: Instance-aware Image-to-Image Translation,Sangwoo Mo;Minsu Cho;Jinwoo Shin,swmo@kaist.ac.kr;mscho@postech.ac.kr;jinwoos@kaist.ac.kr,7;8;7,4;5;5,Accept (Poster),4,6,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;POSTECH;Korea Advanced Institute of Science and Technology,Image-to-Image Translation;Generative Adversarial Networks,-1;136;-1,95;137;95,-1;-1,NAN,NAN,n,8;2;5;4
1924,ICLR,2019,DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,Xiaodong Gu;Kyunghyun Cho;Jung-Woo Ha;Sunghun Kim,guxiaodong1987@126.com;kyunghyun.cho@nyu.edu;jungwoo.ha@navercorp.com;hunkim@cse.ust.hk,7;7;5,4;3;3,Accept (Poster),0,3,3.0,yes,9/27/18,126;New York University;NAVER;The Hong Kong University of Science and Technology,dialogue;GAN;VAE;WAE;chatbot,-1;24;-1;-1,-1;27;-1;44,-1;-1,NAN,NAN,n,5
1925,ICLR,2019,Supervised Policy Update for Deep Reinforcement Learning,Quan Vuong;Yiming Zhang;Keith W. Ross,quan.hovuong@gmail.com;yiming.zhang@nyu.edu;keithwross@nyu.edu,6;9;6,4;2;3,Accept (Poster),7,21,0.0,yes,9/27/18,"University of California, San Diego;New York University;New York University",Deep Reinforcement Learning,-1;24;24,-1;27;27,-1;-1,usa,usa,n,
1926,ICLR,2019,Unsupervised Learning of the Set of Local Maxima,Lior Wolf;Sagie Benaim;Tomer Galanti,wolf@fb.com;sagiebenaim@gmail.com;tomer22g@gmail.com,8;8;8,3;4;3,Accept (Poster),0,10,0.0,yes,9/27/18,Facebook;Tel Aviv University;Tel Aviv University,Unsupervised Learning;One-class Classification;Multi-player Optimization,-1;31;-1,-1;217;-1,-1;-1,asia,in,n,1
1927,ICLR,2019,Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm,Charbel Sakr;Naresh Shanbhag,sakr2@illinois.edu;shanbhag@illinois.edu,7;3;8,3;2;4,Accept (Poster),0,9,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",deep learning;reduced precision;fixed-point;quantization;back-propagation algorithm,-1;-1,-1;-1,-1;-1,usa,usa,y,
1928,ICLR,2019,Generalized Tensor Models for Recurrent Neural Networks,Valentin Khrulkov;Oleksii Hrinchuk;Ivan Oseledets,khrulkov.v@gmail.com;oleksii.hrinchuk@skoltech.ru;i.oseledets@skoltech.ru,6;7;7,4;3;4,Accept (Poster),0,5,0.0,yes,9/27/18,Yandex;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology,expressive power;recurrent neural networks;Tensor-Train decomposition,-1;-1;-1,-1;-1;-1,-1;-1,europe,russia,y,1
1929,ICLR,2019,Towards Metamerism via Foveated Style Transfer,Arturo Deza;Aditya Jonnalagadda;Miguel P. Eckstein,deza@dyns.ucsb.edu;aditya_jonnalagadda@ece.ucsb.edu;eckstein@psych.ucsb.edu,7;8;7,4;4;5,Accept (Poster),0,7,0.0,yes,9/27/18,UC Santa Barbara;UC Santa Barbara;UC Santa Barbara,Metamerism;foveation;perception;style transfer;psychophysics,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
1930,ICLR,2019,Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach,Saeed Amizadeh;Sergiy Matusevych;Markus Weimer,saeed.amizadeh@gmail.com;sergiym@microsoft.com;markus.weimer@microsoft.com,6;8;7,5;4;3,Accept (Poster),0,7,0.0,yes,9/27/18,Microsoft;Microsoft;Microsoft,Neuro-Symbolic Methods;Circuit Satisfiability;Neural SAT Solver;Graph Neural Networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,1
1931,ICLR,2019,Deep Convolutional Networks as shallow Gaussian Processes,Adri√† Garriga-Alonso;Carl Edward Rasmussen;Laurence Aitchison,ag919@cam.ac.uk;cer54@cam.ac.uk;laurence.aitchison@gmail.com,5;8;5,5;3;4,Accept (Poster),0,3,0.0,yes,9/27/18,University of Cambridge;University of Cambridge;University of Bristol,Gaussian process;CNN;ResNet;Bayesian,77;77;94,2;2;76,-1;-1,europe,uk,y,
1932,ICLR,2019,"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow",Xue Bin Peng;Angjoo Kanazawa;Sam Toyer;Pieter Abbeel;Sergey Levine,jasonpeng142@hotmail.com;kanazawa@eecs.berkeley.edu;sdt@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,6;10;8,3;4;3,Accept (Poster),0,6,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;generative adversarial networks;imitation learning;inverse reinforcement learning;information bottleneck,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,y,5;4
1933,ICLR,2019,Hierarchical Generative Modeling for Controllable Speech Synthesis,Wei-Ning Hsu;Yu Zhang;Ron J. Weiss;Heiga Zen;Yonghui Wu;Yuxuan Wang;Yuan Cao;Ye Jia;Zhifeng Chen;Jonathan Shen;Patrick Nguyen;Ruoming Pang,wnhsu@mit.edu;ngyuzh@google.com;ronw@google.com;heigazen@google.com;yonghui@google.com;logpie@gmail.com;yuancao@google.com;jiaye@google.com;zhifengc@google.com;jonathanasdf@google.com;drpng@google.com;rpang@google.com,8;6;5,4;5;4,Accept (Poster),0,25,0.0,yes,9/27/18,Massachusetts Institute of Technology;Google;Google;Google;Google;ByteDance;Google;Google;Google;Google;Google;Google,speech synthesis;representation learning;deep generative model;sequence-to-sequence model,6;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,5;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
1934,ICLR,2019,Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives,George Tucker;Dieterich Lawson;Shixiang Gu;Chris J. Maddison,gjt@google.com;jdl404@nyu.edu;shanegu@google.com;cmaddis@google.com,7;7;6,3;5;4,Accept (Poster),0,4,2.0,yes,9/27/18,Google;New York University;Google;Google,variational autoencoder;reparameterization trick;IWAE;VAE;RWS;JVI,-1;24;-1;-1,-1;27;-1;-1,-1;-1,NAN,NAN,n,1
1935,ICLR,2019,Reward Constrained Policy Optimization,Chen Tessler;Daniel J. Mankowitz;Shie Mannor,chen.tessler@gmail.com;daniel.mankowitz@gmail.com;shiemannor@gmail.com,6;6;7,2;4;2,Accept (Poster),0,5,0.0,yes,9/27/18,"Technion, Technion;Google;Technion, Technion",reinforcement learning;markov decision process;constrained markov decision process;deep learning,27;-1;27,-1;-1;-1,-1;-1,NAN,NAN,y,1
1936,ICLR,2019,Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering,Victor Zhong;Caiming Xiong;Nitish Shirish Keskar;Richard Socher,victor@victorzhong.com;cxiong@salesforce.com;nkeskar@salesforce.com;richard@socher.org,7;7;4,4;5;3,Accept (Poster),0,10,0.0,yes,9/27/18,University of Washington;SalesForce.com;SalesForce.com;SalesForce.com,question answering;reading comprehension;nlp;natural language processing;attention;representation learning,10;-1;-1;-1,25;-1;-1;-1,-1;-1,NAN,NAN,n,8
1937,ICLR,2019,Preconditioner on Matrix Lie Group for SGD,Xi-Lin Li,lixilinx@gmail.com,5;8;7,5;5;3,Accept (Poster),0,5,1.0,yes,9/27/18,0,preconditioner;stochastic gradient descent;Newton method;Fisher information;natural gradient;Lie group,,,-1,NAN,NAN,n,
1938,ICLR,2019,LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos,Elke Kirschbaum;Manuel Hau√ümann;Steffen Wolf;Hannah Sonntag;Justus Schneider;Shehabeldin Elzoheiry;Oliver Kann;Daniel Durstewitz;Fred A Hamprecht,elke.kirschbaum@iwr.uni-heidelberg.de;manuel.haussmann@iwr.uni-heidelberg.de;steffen.wolf@iwr.uni-heidelberg.de;hannah.sonntag@mpimf-heidelberg.mpg.de;justus.schneider@physiologie.uni-heidelberg.de;shehab.elzoheiry@physiologie.uni-heidelberg.de;oliver.kann@physiologie.uni-heidelberg.de;daniel.durstewitz@zi-mannheim.de;fred.hamprecht@iwr.uni-heidelberg.de,5;8;8,4;4;5,Accept (Poster),0,7,0.0,yes,9/27/18,Heidelberg University;Heidelberg University;Heidelberg University;Max-Planck Institute;Heidelberg University;Heidelberg University;Heidelberg University;Central Institute of Mental Health;Heidelberg University,VAE;unsupervised learning;neuronal assemblies;calcium imaging analysis,207;207;207;-1;207;207;207;-1;207,45;45;45;-1;45;45;45;-1;45,-1;-1,europe,de,n,5
1939,ICLR,2019,On the loss landscape of a class of deep neural networks with no bad local valleys,Quynh Nguyen;Mahesh Chandra Mukkamala;Matthias Hein,quynh@cs.uni-saarland.de;mmahesh.chandra873@gmail.com;matthias.hein@uni-tuebingen.de,7;6;8,4;5;4,Accept (Poster),0,10,0.0,yes,9/27/18,Saarland University;Saarland University;University of Tuebingen,loss landscape;local minima;deep neural networks,86;86;136,-1;-1;94,-1;-1,europe,de,y,
1940,ICLR,2019,DHER: Hindsight Experience Replay for Dynamic Goals,Meng Fang;Cheng Zhou;Bei Shi;Boqing Gong;Jia Xu;Tong Zhang,moefang@gmail.com;chengzhmike@gmail.com;shibei00@gmail.com;boqinggo@outlook.com;jiaxu@cs.wisc.edu;tongzhang@tongzhang-ml.org,6;6;7,3;4;4,Accept (Poster),0,17,2.0,yes,9/27/18,Eindhoven University of Technology;;;International Computer Science Institute;University of Southern California;Google,Sparse rewards;Dynamic goals;Experience replay,-1;-1;-1;-1;27;-1,141;-1;-1;-1;66;-1,-1;-1,NAN,NAN,n,
1941,ICLR,2019,SPIGAN: Privileged Adversarial Learning from Simulation,Kuan-Hui Lee;German Ros;Jie Li;Adrien Gaidon,kuan.lee@tri.global;germanros1987@gmail.com;jie.li@tri.global;adrien.gaidon@tri.global,7;6;7,5;5;4,Accept (Poster),0,5,0.0,yes,9/27/18,Toyota Research Institute;Intel;Toyota Research Institute;Toyota Research Institute,domain adaptation;GAN;semantic segmentation;simulation;privileged information,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;5;4
1942,ICLR,2019,Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation,Ehsan Hosseini-Asl;Yingbo Zhou;Caiming Xiong;Richard Socher,ehosseiniasl@salesforce.com;yingbo.zhou@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,6;5;8,4;4;2,Accept (Poster),0,13,0.0,yes,9/27/18,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,Domain adaptation;generative adversarial network;cyclic adversarial learning;speech,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
1943,ICLR,2019,GamePad: A Learning Environment for Theorem Proving,Daniel Huang;Prafulla Dhariwal;Dawn Song;Ilya Sutskever,dehuang@berkeley.edu;prafulla@openai.com;dawnsong@cs.berkeley.edu;ilyasu@openai.com,4;7;7,4;3;2,Accept (Poster),0,5,1.0,yes,9/27/18,University of California Berkeley;OpenAI;University of California Berkeley;OpenAI,Theorem proving;ITP;systems;neural embeddings,-1;-1;-1;-1,18;-1;18;-1,-1;-1,NAN,NAN,n,1
1944,ICLR,2019,Deep Graph Infomax,Petar Veliƒçkoviƒá;William Fedus;William L. Hamilton;Pietro Li√≤;Yoshua Bengio;R Devon Hjelm,petar.velickovic@cst.cam.ac.uk;liam.fedus@gmail.com;wleif@stanford.edu;pietro.lio@cst.cam.ac.uk;yoshua.umontreal@gmail.com;devon.hjelm@microsoft.com,7;9;5,3;4;4,Accept (Poster),2,13,0.0,yes,9/27/18,University of Cambridge;;Stanford University;University of Cambridge;University of Montreal;Microsoft,Unsupervised Learning;Graph Neural Networks;Graph Convolutions;Mutual Information;Infomax;Deep Learning,77;-1;4;77;116;-1,2;-1;3;2;108;-1,-1;-1,NAN,NAN,y,10
1945,ICLR,2019,Fluctuation-dissipation relations for stochastic gradient descent,Sho Yaida,shoyaida@fb.com,8;5;6,5;4;3,Accept (Poster),0,3,1.0,yes,9/27/18,Facebook,stochastic gradient descent;adaptive method;loss surface;Hessian,-1,-1,m,NAN,NAN,n,1
1946,ICLR,2019,A Kernel Random Matrix-Based Approach for Sparse PCA,Mohamed El Amine Seddik;Mohamed Tamaazousti;Romain Couillet,melaseddik@gmail.com;mohamed.tamaazousti@cea.fr;romain.couillet@gmail.com,6;5;7,4;5;2,Accept (Poster),0,4,0.0,yes,9/27/18,Ecole polytechnique;CEA;Paris-Saclay University,Random Matrix Theory;Concentration of Measure;Sparse PCA;Covariance Thresholding,-1;207;-1,115;811;-1,-1;-1,asia,in,y,
1947,ICLR,2019,Sample Efficient Adaptive Text-to-Speech,Yutian Chen;Yannis Assael;Brendan Shillingford;David Budden;Scott Reed;Heiga Zen;Quan Wang;Luis C. Cobo;Andrew Trask;Ben Laurie;Caglar Gulcehre;A√§ron van den Oord;Oriol Vinyals;Nando de Freitas,yutianc@google.com;yannisassael@google.com;shillingford@google.com;budden@google.com;reedscot@google.com;heigazen@google.com;quanw@google.com;luisca@google.com;atrask@google.com;benl@google.com;caglarg@google.com;avdnoord@google.com;vinyals@google.com;nandodefreitas@google.com,7;7;6,4;4;5,Accept (Poster),0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,few shot;meta learning;text to speech;wavenet,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
1948,ICLR,2019,ProMP: Proximal Meta-Policy Search,Jonas Rothfuss;Dennis Lee;Ignasi Clavera;Tamim Asfour;Pieter Abbeel,jonas.rothfuss@gmail.com;dennisl88@berkeley.edu;iclavera@berkeley.edu;asfour@kit.edu;pabbeel@cs.berkeley.edu,6;7;9,3;3;3,Accept (Poster),11,10,2.0,yes,9/27/18,Swiss Federal Institute of Technology;University of California Berkeley;University of California Berkeley;Karlsruhe Institute of Technology;University of California Berkeley,Meta-Reinforcement Learning;Meta-Learning;Reinforcement-Learning,-1;-1;-1;169;-1,-1;18;18;133;18,-1;-1,usa,usa,n,6
1949,ICLR,2019,A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks,Sanjeev Arora;Nadav Cohen;Noah Golowich;Wei Hu,arora@cs.princeton.edu;cohennadav@ias.edu;ngolowich@college.harvard.edu;huwei@cs.princeton.edu,7;7;7,4;4;5,Accept (Poster),0,10,0.0,yes,9/27/18,"Princeton University;Institue for Advanced Study, Princeton;Harvard University;Princeton University",Deep Learning;Learning Theory;Non-Convex Optimization,31;-1;50;31,7;-1;6;7,-1;-1,usa,usa,y,
1950,ICLR,2019,Slimmable Neural Networks,Jiahui Yu;Linjie Yang;Ning Xu;Jianchao Yang;Thomas Huang,jyu79@illinois.edu;linjie.yang@snap.com;ning.xu@snap.com;jianchao.yang@bytedance.com;huang@ifp.uiuc.edu,8;9;7,4;5;4,Accept (Poster),1,15,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;Snap Inc.;Snap Inc.;ByteDance;University of Illinois, Urbana-Champaign",Slimmable neural networks;mobile deep learning;accuracy-efficiency trade-offs,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,n,2
1951,ICLR,2019,Discrete flow posteriors for variational inference in discrete dynamical systems,Laurence Aitchison;Vincent Adam;Srinivas C. Turaga,laurence.aitchison@gmail.com;vincent.adam@prowler.io;turagas@janelia.hhmi.org,4;4;7,3;4;4,Reject,0,0,0.0,yes,9/27/18,University of Bristol;Prowler.io;HHMI Janelia Research Campus,normalising flow;variational inference;discrete latent variable,94;-1;-1,76;-1;-1,-1;-1,NAN,NAN,n,5
1952,ICLR,2019,Variational Sparse Coding,Francesco Tonolini;Bjorn Sand Jensen;Roderick Murray-Smith,2402432t@student.gla.ac.uk;bjorn.jensen@glasgow.ac.uk;roderick.murray-smith@glasgow.ac.uk,4;5;5,4;5;4,Reject,3,6,2.0,yes,9/27/18,University of Glasgow;University of Glasgow;University of Glasgow,Variational Auto-Encoders;Sparse Coding;Variational Inference,207;207;207,80;80;80,-1;-1,europe,uk,n,1;5
1953,ICLR,2019,Detecting Memorization in ReLU Networks,Edo Collins;Siavash Arjomand Bigdeli;Sabine S√ºsstrunk,edo.collins@epfl.ch;siavash.bigdeli@epfl.ch;sabine.susstrunk@epfl.ch,6;5;9,4;4;5,Reject,0,11,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Memorization;Generalization;ReLU;Non-negative matrix factorization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1
1954,ICLR,2019,Reinforcement Learning with Perturbed Rewards,Jingkang Wang;Yang Liu;Bo Li,wangjksjtu_01@sjtu.edu.cn;yangliu@ucsc.edu;lxbosky@gmail.com,6;6;6,4;3;3,Reject,0,9,0.0,yes,9/27/18,Shanghai Jiao Tong University;University of Southern California;University of California Berkeley,robust reinforcement learning;noisy reward;sample complexity,36;27;-1,188;66;18,-1;-1,usa,usa,y,1
1955,ICLR,2019,Local Critic Training of Deep Neural Networks,Hojung Lee;Jong-Seok Lee,hjlee92@yonsei.ac.kr;jong-seok.lee@yonsei.ac.kr,6;7;6,3;5;4,Reject,0,7,0.0,yes,9/27/18,Yonsei University;Yonsei University,inter-layer locking;local critic network;backpropagation;convolutional neural network;structural optimization;progress inference;ensemble inference,169;169,231;231,-1;-1,asia,cn,n,
1956,ICLR,2019,Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor,Te-Lin Wu;Jaedong Hwang;Jingyun Yang;Shaofan Lai;Carl Vondrick;Joseph J. Lim,telinwu@usc.edu;jd730@snu.ac.kr;jingyuny@usc.edu;shaofanl@usc.edu;vondrick@cs.columbia.edu;limjj@usc.edu,4;4;4,4;4;3,Reject,0,0,0.0,yes,9/27/18,University of Southern California;Seoul National University;University of Southern California;University of Southern California;Columbia University;University of Southern California,Imitation Learning;Noisy Demonstration Set;Meta-Learning,27;36;27;27;21;27,66;74;66;66;14;66,-1;-1,usa,usa,n,6
1957,ICLR,2019,Detecting Topological Defects in 2D Active Nematics Using Convolutional Neural Networks,Ruoshi Liu;Michael M. Norton;Seth Fraden;Pengyu Hong,ruoshiliu@brandeis.edu;mmnorton@brandeis.edu;fraden@brandeis.edu;hongpeng@brandeis.edu,4;4;2,4;4;5,Reject,0,0,0.0,yes,9/27/18,Brandeis University;Brandeis University;Brandeis University;Brandeis University,,207;207;207;207,223;223;223;223,-1;-1,usa,usa,n,
1958,ICLR,2019,Rating Continuous Actions in Spatial Multi-Agent Problems,Uwe Dick;Maryam Tavakol;Ulf Brefeld,uwe.dick@leuphana.de;tavakol@leuphana.de;brefeld@leuphana.de,5;4;4,4;3;4,Reject,0,0,0.0,yes,9/27/18,Inst. of Information Systems / Machine Learning;Inst. of Information Systems / Machine Learning;Inst. of Information Systems / Machine Learning,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,4
1959,ICLR,2019,SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration,Xiangyu Kong;Jing Li;Bo Xin;Yizhou Wang,kong@pku.edu.cn;lijingg@pku.edu.cn;jimxinbo@gmail.com;yizhou.wang@pku.edu.cn,4;5;5,3;4;3,Reject,0,1,0.0,yes,9/27/18,Peking University;Peking University;;Peking University,reinforcement learning;multi-agent learning;multi-agent communication;deep learning,14;14;-1;14,27;27;-1;27,-1;-1,asia,cn,n,
1960,ICLR,2019,Generating Realistic Stock Market Order Streams,Junyi Li;Xintong Wang;Yaoyang Lin;Arunesh Sinha;Michael P. Wellman,junyili@umich.edu;xintongw@umich.edu;yaoyang@umich.edu;arunesh@umich.edu;wellman@umich.edu,5;5;4,4;4;5,Reject,0,4,0.0,yes,9/27/18,University of Michigan;University of Michigan;University of Michigan;University of Michigan;University of Michigan,application in finance;stock markets;generative models,9;9;9;9;9,21;21;21;21;21,-1;-1,usa,usa,n,5;4
1961,ICLR,2019,Causal Reasoning from Meta-reinforcement learning,Ishita Dasgupta;Jane Wang;Silvia Chiappa;Jovana Mitrovic;Pedro Ortega;David Raposo;Edward Hughes;Peter Battaglia;Matthew Botvinick;Zeb Kurth-Nelson,ishitadasgupta@g.harvard.edu;wangjane@google.com;csilvia@google.com;mitrovic@google.com;pedroortega@google.com;draposo@google.com;edwardhughes@google.com;peterbattaglia@google.com;botvinick@google.com;zebk@google.com,5;4;4;7,4;3;4;4,Reject,0,10,0.0,yes,9/27/18,Harvard University;Google;Google;Google;Google;Google;Google;Google;Google;Google,meta-learning;causal reasoning;deep reinforcement learning;artificial intelligence,50;-1;-1;-1;-1;-1;-1;-1;-1;-1,6;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
1962,ICLR,2019,MahiNet: A Neural Network for Many-Class Few-Shot Learning with Class Hierarchy,Lu Liu;Tianyi Zhou;Guodong Long;Jing Jiang;Chengqi Zhang,lu.liu.cs.uts@gmail.com;tianyizh@uw.edu;guodong.long@uts.edu.au;jing.jiang@uts.edu.au;chengqi.zhang@uts.edu.au,5;6;5,3;3;3,Reject,0,7,0.0,yes,9/27/18,"University of Technology Sydney;University of Washington, Seattle;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney",deep learning;many-class few-shot;class hierarchy;meta learning,67;10;67;67;67,216;25;216;216;216,-1;-1,australasia,au,n,6;8
1963,ICLR,2019,CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication,Nikita Kitaev;Jin-Hwa Kim;Xinlei Chen;Marcus Rohrbach;Yuandong Tian;Dhruv Batra;Devi Parikh,kitaev@cs.berkeley.edu;jnhwkim@gmail.com;xinleic@fb.com;maroffm@gmail.com;yuandong@fb.com;dbatra@gatech.edu;parikh@gatech.edu,4;6;7,4;4;4,Reject,0,3,0.0,yes,9/27/18,University of California Berkeley;SK Telecom;Facebook;Facebook;Facebook;Georgia Institute of Technology;Georgia Institute of Technology,CoDraw;collaborative drawing;grounded language,-1;-1;-1;-1;-1;13;13,18;-1;-1;-1;-1;33;33,-1;-1,usa,usa,n,3
1964,ICLR,2019,I Know the Feeling: Learning to Converse with Empathy,Hannah Rashkin;Eric Michael Smith;Margaret Li;Y-Lan Boureau,hrashkin@cs.washington.edu;ems@fb.com;hadasah@gmail.com;ylan@fb.com,4;7;5,4;4;3,Reject,0,11,0.0,yes,9/27/18,University of Washington;Facebook;Facebook;Facebook,dialogue generation;nlp applications;grounded text  generation;contextual representation learning,10;-1;-1;-1,25;-1;-1;-1,-1;-1,NAN,NAN,n,
1965,ICLR,2019,Neural MMO: A massively multiplayer game environment for intelligent agents,Joseph Suarez;Yilun Du;Phillip Isola;Igor Mordatch,joseph15@stanford.edu;yilundu@gmail.com;phillipi@mit.edu;mordatch@openai.com,6;5;7,4;2;5,Reject,0,5,0.0,yes,9/27/18,Stanford University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;OpenAI,MMO;Multiagent;Game;Reinforcement Learning;Platform;Framework;Niche Formation;Exploration,4;6;6;-1,3;5;5;-1,-1;-1,NAN,NAN,n,
1966,ICLR,2019,Temporal Gaussian Mixture Layer for Videos,AJ Piergiovanni;Michael S. Ryoo,ajpiergi@indiana.edu;mryoo@indiana.edu,6;6;7,5;3;5,Reject,0,6,1.0,yes,9/27/18,Indiana University;Indiana University,,67;67,117;117,-1;-1,usa,usa,n,
1967,ICLR,2019,LEARNING GENERATIVE MODELS FOR DEMIXING OF STRUCTURED SIGNALS FROM THEIR SUPERPOSITION USING GANS,Mohammadreza Soltani;Swayambhoo Jain;Abhinav V. Sambasivan,msoltani@iastate.edu;swayambhoo.jain@technicolor.com;samba014@umn.edu,7;4;5,4;5;4,Reject,0,3,0.0,yes,9/27/18,"Iowa State University;Technicolor;University of Minnesota, Minneapolis",Generative Models;GANs;Denosing;Demixing;Structured Recovery,207;-1;67,341;-1;56,-1;-1,NAN,NAN,n,5;4
1968,ICLR,2019,Invariant-equivariant representation learning for multi-class data,Ilya Feige,ilya@asidatascience.com,7;5;4,2;5;3,Reject,0,5,0.0,yes,9/27/18,Asidatascience,representation learning;semantic representations;local vs global information;latent variable modelling;generative modelling;semi-supervised learning;variational autoencoders.,-1,-1,-1,NAN,NAN,n,5
1969,ICLR,2019,Graph Matching Networks for Learning the Similarity of Graph Structured Objects,Yujia Li;Chenjie Gu;Thomas Dullien;Oriol Vinyals;Pushmeet Kohli,yujiali@google.com;gcj@google.com;thomasdullien@google.com;vinyals@google.com;pushmeet@google.com,6;5;6,4;4;4,Reject,0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google,Similarity learning;structured objects;graph matching networks,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;10
1970,ICLR,2019,Probabilistic Semantic Embedding,Yue Jiao;Jonathon Hare;Adam Pr√ºgel-Bennett,yj5y15@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,7;4;4,3;4;4,Reject,0,7,0.0,yes,9/27/18,University of Southampton;University of Southampton;University of Southampton,,207;207;207,126;126;126,-1;-1,europe,uk,n,
1971,ICLR,2019,SENSE: SEMANTICALLY ENHANCED NODE SEQUENCE EMBEDDING,Swati Rallapalli;Liang Ma;Mudhakar Srivatsa;Ananthram Swami;Heesung Kwon;Graham Bent;Christopher Simpkin,srallapalli@us.ibm.com;maliang@us.ibm.com;msrivats@us.ibm.com;ananthram.swami.civ@mail.mil;heesung.kwon.civ@mail.mil;gbent@uk.ibm.com;simpkin.chris@gmail.com,4;4;5,4;5;3,Reject,0,3,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;Army Reserach laboratory;Army Reserach laboratory;International Business Machines;Cardiff University,Semantic;Graph;Sequence;Embeddings,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,asia,in,y,1;10
1972,ICLR,2019,Pix2Scene: Learning Implicit 3D Representations from Images,Sai Rajeswar;Fahim Mannan;Florian Golemo;David Vazquez;Derek Nowrouzezahrai;Aaron Courville,rajsai24@gmail.com;fmannan@gmail.com;florian.golemo@inria.fr;dvazquez@cvc.uab.es;dereknow@gmail.com;aaron.courville@gmail.com,6;5;6,1;4;4,Reject,0,15,2.0,yes,9/27/18,"University of Montreal;;INRIA;Computer Vision Center, Universitat Aut√≤noma de Barcelona;;University of Montreal",Representation learning;generative model;adversarial learning;implicit 3D generation;scene generation,-1;-1;-1;-1;-1;116,-1;-1;-1;-1;-1;108,-1;-1,canada,ca,n,2;5;4
1973,ICLR,2019,COCO-GAN: Conditional Coordinate Generative Adversarial Network,Chieh Hubert Lin;Chia-Che Chang;Yu-Sheng Chen;Da-Cheng Juan;Wei Wei;Hwann-Tzong Chen,hubert052702@gmail.com;chang810249@gmail.com;nothinglo@cmlab.csie.ntu.edu.tw;dacheng@google.com;wewei@google.com;htchen@cs.nthu.edu.tw,6;4;6,4;5;4,Reject,0,27,0.0,yes,9/27/18,University of California at Merced;;Nanyang Technological University;Google;Google;National Tsing Hua University,,-1;-1;44;-1;-1;207,-1;-1;52;-1;-1;323,-1;-1,asia,tw,n,5;4
1974,ICLR,2019,Implicit Autoencoders,Alireza Makhzani,a.makhzani@gmail.com,3;6;6,3;4;3,Reject,0,7,1.0,yes,9/27/18,0,Unsupervised Learning;Generative Models;Variational Inference;Generative Adversarial Networks.,,,-1,NAN,NAN,n,5;4
1975,ICLR,2019,Identifying Bias in AI using Simulation,Daniel McDuff;Roger Cheng;Ashish Kapoor,damcduff@microsoft.com;rocheng@microsoft.com;akapoor@microsoft.com,7;5;6,5;4;2,Reject,0,9,0.0,yes,9/27/18,Microsoft;Microsoft;Microsoft,Bias;Simulation;Optimization;Face Detection,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11;7
1976,ICLR,2019,Backplay: 'Man muss immer umkehren',Cinjon Resnick;Roberta Raileanu;Sanyam Kapoor;Alexander Peysakhovich;Kyunghyun Cho;Joan Bruna,cinjon.resnick@gmail.com;raileanu.roberta@gmail.com;sanyam@nyu.edu;alexpeys@fb.com;kyunghyun.cho@nyu.edu;bruna@cims.nyu.edu,5;5;5,4;4;3,Reject,0,8,0.0,yes,9/27/18,New York University;;New York University;Facebook;New York University;New York University,Exploration;Games;Pommerman;Bomberman;AI;Reinforcement Learning;Machine Learning,24;-1;24;-1;24;24,27;-1;27;-1;27;27,-1;-1,usa,usa,n,
1977,ICLR,2019,Intrinsic Social Motivation via Causal Influence in Multi-Agent RL,Natasha Jaques;Angeliki Lazaridou;Edward Hughes;Caglar Gulcehre;Pedro A. Ortega;DJ Strouse;Joel Z. Leibo;Nando de Freitas,jaquesn@mit.edu;angeliki@google.com;edwardhughes@google.com;caglarg@google.com;pedroortega@google.com;danieljstrouse@gmail.com;jzl@google.com;nandodefreitas@google.com,5;4;6,3;5;3,Reject,0,9,1.0,yes,9/27/18,Massachusetts Institute of Technology;Google;Google;Google;Google;Google;Google;Google,multi-agent reinforcement learning;causal inference;game theory;social dilemma;intrinsic motivation;counterfactual reasoning;empowerment;communication,6;-1;-1;-1;-1;-1;-1;-1,5;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1978,ICLR,2019,Dynamic Planning Networks,Norman L. Tasfi;Miriam Capretz,ntasfi@gmail.com;mcapretz@uwo.ca,6;4;6,5;5;2,Reject,1,0,8.0,yes,9/27/18,University of Western Ontario;University of Western Ontario,reinforcement learning;planning;deep learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
1979,ICLR,2019,Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation,Rodrigo Nogueira;Jannis Bulian;Massimiliano Ciaramita,rodrigonogueira@nyu.edu;jbulian@google.com;massi@google.com,4;7;5,3;4;4,Reject,2,0,4.0,yes,9/27/18,New York University;Google;Google,Reinforcement Learning;Multi-agent;Information Retrieval;Question-Answering;Query Reformulation;Query Expansion,24;-1;-1,27;-1;-1,-1;-1,NAN,NAN,n,1
1980,ICLR,2019,Recovering the Lowest Layer of Deep Networks with High Threshold Activations,Surbhi Goel;Rina Panigrahy,surbhi@cs.utexas.edu;rinap@google.com,4;5;4,4;3;4,Reject,0,3,0.0,yes,9/27/18,"University of Texas, Austin;Google",Deep Learning;Parameter Recovery;Non-convex optimization;high threshold activation,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1
1981,ICLR,2019,Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps,Simon S. Du;Surbhi Goel,ssdu@cs.cmu.edu;surbhi@cs.utexas.edu,6;5;6,3;1;4,Reject,0,3,0.0,yes,9/27/18,"Carnegie Mellon University;University of Texas, Austin",deep learning;parameter recovery;convolutional neural networks;non-convex optimization,1;-1,24;-1,-1;-1,usa,usa,y,2
1982,ICLR,2019,Using Ontologies To Improve Performance In Massively Multi-label Prediction,Ethan Steinberg;Peter J. Liu,ethan.steinberg@gmail.com;peterjliu@google.com,6;5;4,3;3;4,Reject,0,4,0.0,yes,9/27/18,Stanford University;Google,multi-label;Bayesian network;ontology,4;-1,3;-1,-1;-1,NAN,NAN,n,11
1983,ICLR,2019,Overfitting Detection of Deep Neural Networks without a Hold Out Set,Konrad Groh,konrad.groh@de.bosch.com,4;5;3,4;3;4,Reject,0,1,0.0,yes,9/27/18,Bosch,deep learning;overfitting;generalization;memorization,-1,367,-1,NAN,NAN,y,
1984,ICLR,2019,TarMAC: Targeted Multi-Agent Communication,Abhishek Das;Theophile Gervet;Joshua Romoff;Dhruv Batra;Devi Parikh;Mike Rabbat;Joelle Pineau,abhshkdz@gatech.edu;tgervet@andrew.cmu.edu;joshua.romoff@mail.mcgill.ca;dbatra@gatech.edu;parikh@gatech.edu;mikerabbat@fb.com;jpineau@cs.mcgill.ca,6;6;6,5;4;5,Reject,0,11,0.0,yes,9/27/18,Georgia Institute of Technology;Carnegie Mellon University;McGill University;Georgia Institute of Technology;Georgia Institute of Technology;Facebook;McGill University,,13;1;94;13;13;-1;94,33;24;42;33;33;-1;42,-1;-1,canada,ca,n,
1985,ICLR,2019,DATNet: Dual Adversarial Transfer for Low-resource Named Entity Recognition,Joey Tianyi Zhou;Hao Zhang;Di Jin;Hongyuan Zhu;Rick Siow Mong Goh;Kenneth Kwok,joey.tianyi.zhou@gmail.com;isaac.changhau@gmail.com;jindi15@mit.edu;hongyuanzhu.cn@gmail.com;gohsm@ihpc.a-star.edu.sg;kenkwok@ihpc.a-star.edu.sg,6;6;6,4;5;4,Reject,0,3,0.0,yes,9/27/18,"A*STAR;A*STAR;Massachusetts Institute of Technology;Institute for Infocomm Research;Institute of High Performance Computing, Singapore, A*STAR;Institute of High Performance Computing, Singapore, A*STAR",Low-resource;Named Entity Recognition,-1;-1;6;-1;-1;-1,-1;-1;5;-1;-1;-1,-1;-1,NAN,NAN,n,1;4
1986,ICLR,2019,MILE: A Multi-Level Framework for Scalable Graph Embedding,Jiongqian Liang;Saket Gurukar;Srinivasan Parthasarathy,liang.albert@outlook.com;gurukar.1@osu.edu;srini@cse.ohio-state.edu,7;4;6,3;4;5,Reject,0,5,0.0,yes,9/27/18,Ohio State University;Ohio State University;Ohio State University,Network Embedding;Graph Convolutional Networks;Deep Learning,-1;59;59,-1;70;70,-1;-1,usa,usa,n,10
1987,ICLR,2019,Adversarial Attacks on Node Embeddings,Aleksandar Bojchevski;Stephan G√ºnnemann,a.bojchevski@in.tum.de;guennemann@in.tum.de,6;5;6,4;5;3,Reject,0,3,0.0,yes,9/27/18,Technical University Munich;Technical University Munich,node embeddings;adversarial attacks,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1;10;4
1988,ICLR,2019,DADAM: A consensus-based distributed adaptive gradient method for online optimization,Parvin Nazari;Davoud Ataee Tarzanagh;George Michailidis,p_nazari@aut.ac.ir;tarzanagh@ufl.edu;gmichail@ufl.edu,8;4;6,3;4;4,Reject,0,10,3.0,yes,9/27/18,Amirkabir University of Technology;University of Florida;University of Florida,,-1;136;136,613;143;143,-1;-1,usa,usa,y,1;9
1989,ICLR,2019,Training Hard-Threshold Networks with Combinatorial Search in a Discrete Target Propagation Setting,Lukas Nabergall;Justin Toth;Leah Cousins,lnaberga@uwaterloo.ca;wjtoth@uwaterloo.ca;lm2cousi@uwaterloo.ca,3;4;5,5;4;5,Reject,0,4,0.0,yes,9/27/18,University of Waterloo;University of Waterloo;University of Waterloo,hard-threshold network;combinatorial optimization;search;target propagation,31;31;31,207;207;207,-1;-1,canada,ca,n,
1990,ICLR,2019,Projective Subspace Networks For Few-Shot Learning,Christian Simon;Piotr Koniusz;Mehrtash Harandi,christian.simon@anu.edu.au;piotr.koniusz@data61.csiro.au;mehrtash.harandi@monash.edu,6;6;6,3;4;4,Reject,0,9,0.0,yes,9/27/18,Australian National University;CSIRO;Monash University,few-shot;one-shot;semi-supervised;meta-learning,116;-1;94,48;-1;80,-1;-1,australasia,au,n,6;1
1991,ICLR,2019,Alignment Based Mathching Networks for One-Shot Classification and Open-Set Recognition,Paresh Malalur;Tommi Jaakkola,pareshmg@csail.mit.edu;tommi@csail.mit.edu,7;6;7;4,3;2;4;4,Reject,0,3,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,,6;6,5;5,-1;-1,usa,usa,n,8
1992,ICLR,2019,Cramer-Wold AutoEncoder,Jacek Tabor;Szymon Knop;Przemys≈Çaw Spurek;Igor Podolak;Marcin Mazur;Stanis≈Çaw Jastrzƒôbski,jacek.tabor@uj.edu.pl;szymon.knop@doctoral.uj.edu.pl;przemyslaw.spurek@uj.edu.pl;igor.podolak@uj.edu.pl;marcin.mazur@uj.edu.pl;staszek.jastrzebski@gmail.com,6;7;5,4;4;4,Reject,0,9,0.0,yes,9/27/18,Jagiellonian University;Jagiellonian University;Jagiellonian University;Jagiellonian University;Jagiellonian University;Jagiellonian University,autoencoder;generative models;deep neural networks,-1;-1;-1;-1;-1;-1,695;695;695;695;695;695,-1;-1,NAN,NAN,y,5
1993,ICLR,2019,Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher Distributions in Deep Learning,Cheolhyoung Lee;Kyunghyun Cho;Wanmo Kang,bloodwass@kaist.ac.kr;kyunghyun.cho@nyu.edu;wanmo.kang@kaist.edu,6;5;4,3;3;3,Reject,0,7,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;New York University;KAIST,directional statistics;deep learning;SNR;gradient stochasticity;SGD;stochastic gradient;von Mises-Fisher;angle,-1;24;17,95;27;95,-1;-1,asia,in,y,
1994,ICLR,2019,Unsupervised Control Through Non-Parametric Discriminative Rewards,David Warde-Farley;Tom Van de Wiele;Tejas Kulkarni;Catalin Ionescu;Steven Hansen;Volodymyr Mnih,d.warde.farley@gmail.com;tomvandewiele@google.com;tejasdkulkarni@gmail.com;cdi@google.com;stevenhansen@google.com;vmnih@google.com,7;8;5,3;5;5,Accept (Poster),3,15,4.0,yes,9/27/18,Google;Google;Common Sense Machines;Google;Google;Google,deep reinforcement learning;goals;UVFA;mutual information,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
1995,ICLR,2019,Clean-Label Backdoor Attacks,Alexander Turner;Dimitris Tsipras;Aleksander Madry,turneram@mit.edu;tsipras@mit.edu;madry@mit.edu,6;7;4,2;2;4,Reject,0,11,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,data poisoning;backdoor attacks;clean labels;adversarial examples;generative adversarial networks,6;6;6,5;5;5,-1;-1,usa,usa,n,5;4
1996,ICLR,2019,Universal Successor Features for Transfer Reinforcement Learning,Chen Ma;Dylan R. Ashley;Junfeng Wen;Yoshua Bengio,chenchloem@gmail.com;dashley@ualberta.ca;junfengwen@gmail.com;yoshua.umontreal@gmail.com,6;4;7,5;5;5,Reject,0,15,3.0,yes,9/27/18,University of Alberta;University of Alberta;Layer 6 AI;University of Montreal,Reinforcement Learning;Successor Features;Successor Representations;Transfer Learning;Representation Learning,-1;94;-1;116,-1;119;-1;108,-1;-1,canada,ca,n,1
1997,ICLR,2019,Improved Language Modeling by Decoding the Past,Siddhartha Brahma,sidbrahma@gmail.com,3;6;7,5;3;5,Reject,8,6,0.0,yes,9/27/18,International Business Machines,language modeling;regularization;LSTM,-1,-1,-1,NAN,NAN,n,3
1998,ICLR,2019,ON BREIMAN‚ÄôS DILEMMA IN NEURAL NETWORKS: SUCCESS AND FAILURE OF NORMALIZED MARGINS,Yifei HUANG;Yuan YAO;Weizhi ZHU,yhuangcc@ust.hk;yuany@ust.hk;wzhuai@connect.ust.hk,4;5;5,4;4;3,Reject,0,3,0.0,yes,9/27/18,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Bregman's Dilemma;Generalization Error;Margin;Spectral normalization,-1;-1;-1,44;44;44,-1;-1,NAN,NAN,y,1
1999,ICLR,2019,Decoupling Gating from Linearity,Yonathan Fiat;Eran Malach;Shai Shalev-Shwartz,jonathan.fiat@gmail.com;eran.malach@mail.huji.ac.il;shais@cs.huji.ac.il,3;2;3,4;5;5,Reject,0,0,0.0,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Artificial Neural Networks;Neural Networks;ReLU;GaLU;Deep Learning,77;77;77,205;205;205,-1;-1,europe,il,n,1
2000,ICLR,2019,Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy,Gaurav Gupta;Mohamed Ridha Znaidi;Paul Bogdan,ggaurav@usc.edu;znaidi@usc.edu;pbogdan@usc.edu,5;4;5,3;2;4,Reject,0,6,0.0,yes,9/27/18,University of Southern California;University of Southern California;University of Southern California,compact representation;perception;dynamical systems;information bottleneck,27;27;27,66;66;66,-1;-1,usa,usa,y,1
2001,ICLR,2019,Efficient Dictionary Learning with Gradient Descent,Dar Gilboa;Sam Buchanan;John Wright,dg2893@columbia.edu;sdb2157@columbia.edu;jw2966@columbia.edu,5;4;5,4;3;2,Reject,0,0,0.0,yes,9/27/18,Columbia University;Columbia University;Columbia University,dictionary learning;nonconvex optimization,21;21;21,14;14;14,-1;-1,usa,usa,y,9
2002,ICLR,2019,Learning Backpropagation-Free Deep Architectures with Kernels,Shiyu Duan;Shujian Yu;Yunmei Chen;Jose Principe,michaelshiyu3@gmail.com;yusjlcy9011@ufl.edu,6;6;5,4;4;3,Reject,0,25,2.0,yes,9/27/18,University of Florida;University of Florida,supervised learning;backpropagation-free deep architecture;kernel method,136;136,143;143,-1;-1,usa,usa,y,1
2003,ICLR,2019,Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs,Yogesh Balaji;Hamed Hasani;Rama Chellappa;Soheil Feizi,yogesh@cs.umd.edu;hassani@seas.upenn.edu;rama@umiacs.umd.edu;sfeizi@cs.umd.edu,6;5;5,5;3;4,Reject,0,4,0.0,yes,9/27/18,"University of Maryland, College Park;University of Pennsylvania;University of Maryland, College Park;University of Maryland, College Park",GAN;VAE;likelihood estimation;statistical inference,12;21;12;12,69;10;69;69,-1;-1,usa,usa,y,1;5;4
2004,ICLR,2019,Incremental training of multi-generative adversarial networks,Qi Tan;Pingzhong Tang;Ke Xu;Weiran Shen;Song Zuo,thunderingtan@gmail.com;kenshinping@gmail.com;xuke@tsinghua.edu.cn;emersonswr@gmail.com;songzuo.z@gmail.com,5;6;6,3;4;3,Reject,0,3,0.0,yes,9/27/18,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Illinois, Urbana-Champaign;Google",GAN;Incremental training;Information projection;Mixture distribution,-1;4;4;-1;-1,-1;30;30;-1;-1,-1;-1,NAN,NAN,y,5;4
2005,ICLR,2019,Transformer-XL: Language Modeling with Longer-Term Dependency,Zihang Dai*;Zhilin Yang*;Yiming Yang;William W. Cohen;Jaime Carbonell;Quoc V. Le;Ruslan Salakhutdinov,zander.dai@gmail.com;zhiliny@cs.cmu.edu;yiming@cs.cmu.edu;wcohen@google.com;jgc@cs.cmu.edu;qvl@google.com;rsalakhu@cs.cmu.edu,6;6;4,4;4;4,Reject,0,9,6.0,yes,9/27/18,Google;Carnegie Mellon University;Carnegie Mellon University;Google;Carnegie Mellon University;Google;Carnegie Mellon University,Language Modeling;Self-Attention,-1;1;1;-1;1;-1;1,-1;24;24;-1;24;-1;24,-1;-1,usa,usa,n,8;3
2006,ICLR,2019,Formal Limitations on the Measurement of Mutual Information,David McAllester;Karl Stratos,mcallester@ttic.edu;stratos@ttic.edu,6;8;4,3;5;4,Reject,0,12,0.0,yes,9/27/18,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,mutual information;predictive coding;unsupervised learning;predictive learning;generalization bounds;MINE;DIM;contrastive predictive coding,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1
2007,ICLR,2019,Area Attention,Yang Li;Lukasz Kaiser;Samy Bengio;Si Si,liyang@google.com;lukaszkaiser@google.com;bengio@google.com;sisidaisy@google.com,6;5;5,4;5;4,Reject,12,10,0.0,yes,9/27/18,Google;Google;Google;Google,Deep Learning;attentional mechanisms;neural machine translation;image captioning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
2008,ICLR,2019,The Conditional Entropy Bottleneck,Ian Fischer,iansf@google.com,6;6;2,3;3;4,Reject,0,20,0.0,yes,9/27/18,Google,representation learning;information theory;uncertainty;out-of-distribution detection;adversarial example robustness;generalization;objective function,-1,-1,-1,NAN,NAN,n,1;4
2009,ICLR,2019,State-Denoised Recurrent Neural Networks,Michael C. Mozer;Denis Kazakov;Robert V. Lindsey,mozer@colorado.edu;denis.kazakov@colorado.edu;rob@imagen.ai,6;5;5,4;3;4,Reject,0,3,0.0,yes,9/27/18,"University of Colorado, Boulder;University of Colorado, Boulder;Imagen Technologies Inc",recurrent nets;attractor nets;denoising;sequence processing,59;59;-1,100;100;-1,-1;-1,NAN,NAN,n,1
2010,ICLR,2019,NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES,Xavier Suau;Luca Zappella;Nicholas Apostoloff,xsuaucuadros@apple.com;lzappella@apple.com;napostoloff@apple.com,6;5;5,3;4;5,Reject,0,7,1.0,yes,9/27/18,Apple;Apple;Apple,Artificial Intelligence;Deep learning;Machine learning;Compression,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,1
2011,ICLR,2019,LIT: Block-wise Intermediate Representation Training for Model Compression,Animesh Koratana*;Daniel Kang*;Peter Bailis;Matei Zaharia,koratana@stanford.edu;ddkang@stanford.edu;pbailis@cs.stanford.edu;matei@cs.stanford.edu,5;6;6,4;4;3,Reject,0,7,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University,,4;4;4;4,3;3;3;3,-1;-1,usa,usa,n,5
2012,ICLR,2019,NLProlog: Reasoning with Weak Unification for Natural Language Question Answering,Leon Weber;Pasquale Minervini;Ulf Leser;Tim Rockt√§schel,leonweber@posteo.de;p.minervini@gmail.com;leser@informatik.hu-berlin.de;tim.rocktaeschel@gmail.com,5;7;7,3;3;4,Reject,0,5,0.0,yes,9/27/18,Humboldt Universit√§t Berlin;University College London;Humboldt Universit√§t Berlin;Facebook AI Research,symbolic reasoning;neural networks;natural language processing;question answering;sentence embeddings;evolution strategies,-1;50;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2013,ICLR,2019,Revisiting Reweighted Wake-Sleep,Tuan Anh Le;Adam R. Kosiorek;N. Siddharth;Yee Whye Teh;Frank Wood,tuananh@robots.ox.ac.uk;adamk@robots.ox.ac.uk;nsid@robots.ox.ac.uk;y.w.teh@stats.ox.ac.uk;fwood@cs.ubc.ca,6;6;5,4;3;3,Reject,0,10,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of British Columbia,variational inference;approximate inference;generative models;gradient estimators,44;44;44;44;59,1;1;1;1;34,-1;-1,canada,ca,n,5
2014,ICLR,2019,Looking for ELMo's friends: Sentence-Level Pretraining Beyond Language Modeling,Samuel R. Bowman;Ellie Pavlick;Edouard Grave;Benjamin Van Durme;Alex Wang;Jan Hula;Patrick Xia;Raghavendra Pappagari;R. Thomas McCoy;Roma Patel;Najoung Kim;Ian Tenney;Yinghui Huang;Katherin Yu;Shuning Jin;Berlin Chen,bowman@nyu.edu;ellie_pavlick@brown.edu;egrave@fb.com;vandurme@cs.jhu.edu;alexwang@nyu.edu;jan.hula21@gmail.com;paxia@jhu.edu;raghu1991.p@gmail.com;tom.mccoy@jhu.edu;romapatel@brown.edu;n.kim@jhu.edu;iftenney@google.com;huangyi@us.ibm.com;yukatherin@fb.com;jinxx596@d.umn.edu;bchen6@swarthmore.edu,5;7;8,3;4;4,Reject,0,3,2.0,yes,9/27/18,"New York University;Brown University;Facebook;Johns Hopkins University;New York University;;Johns Hopkins University;;Johns Hopkins University;Brown University;Johns Hopkins University;Google;International Business Machines;Facebook;University of Minnesota, Minneapolis;Swarthmore College",natural language processing;transfer learning;multitask learning,24;86;-1;67;24;-1;67;-1;67;86;67;-1;-1;-1;67;-1,27;50;-1;13;27;-1;13;-1;13;50;13;-1;-1;-1;56;-1,-1;-1,NAN,NAN,n,3
2015,ICLR,2019,Estimating Information Flow in DNNs,Ziv Goldfeld;Ewout van den Berg;Kristjan Greenewald;Brian Kingsbury;Igor Melnyk;Nam Nguyen;Yury Polyanskiy,zivg@mit.edu;evandenberg@us.ibm.com;kristjan.h.greenewald@ibm.com;bedk@us.ibm.com;igor.melnyk@ibm.com;nnguyen@us.ibm.com;yp@mit.edu,7;7;4,4;4;5,Reject,0,9,0.0,yes,9/27/18,Massachusetts Institute of Technology;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Massachusetts Institute of Technology,information theory;representation learning;deep learning;differential entropy estimation,6;-1;-1;-1;-1;-1;6,5;-1;-1;-1;-1;-1;5,-1;-1,usa,usa,y,1
2016,ICLR,2019,Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks,Kenta Oono;Taiji Suzuki,k.oono.delta@gmail.com;taiji@mist.i.u-tokyo.ac.jp,4;6;4,4;3;3,Reject,0,6,0.0,yes,9/27/18,"Preferred Networks, Inc.;The University of Tokyo",CNN;ResNet;learning theory;approximation theory;non-parametric estimation;block-sparse,-1;59,-1;45,-1;-1,NAN,NAN,y,1
2017,ICLR,2019,Learning to Reinforcement Learn by Imitation,Rosen Kralev;Russell Mendonca;Alvin Zhang;Tianhe Yu;Abhishek Gupta;Pieter Abbeel;Sergey Levine;Chelsea Finn,rdkralev@gmail.com;russellm@berkeley.edu;alvinz@berkeley.edu;tianheyu927@gmail.com;abhigupta@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu;cbfinn@eecs.berkeley.edu,4;3;2;5,3;2;5;2,Reject,0,0,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,meta-learning;reinforcement learning;imitation learning,-1;-1;-1;4;-1;-1;-1;-1,-1;18;18;3;18;18;18;18,-1;-1,usa,usa,n,6
2018,ICLR,2019,Non-Synergistic Variational Autoencoders,Gonzalo Barrientos;Sten Sootla,gonzalo.ayquipa.16@ucl.ac.uk;sten.sootla.17@ucl.ac.uk,3;4;3,4;3;5,Reject,0,0,0.0,yes,9/27/18,University College London;University College London,vae;unsupervised learning,50;50,-1;-1,-1;-1,europe,uk,n,1;5
2019,ICLR,2019,On the Trajectory of Stochastic Gradient Descent in the Information Plane,Emilio Rafael Balda;Arash Behboodi;Rudolf Mathar,emilio.balda@ti.rwth-aachen.de;arash.behboodi@ti.rwth-aachen.de;mathar@ti.rwth-aachen.de,4;6;2,3;4;4,Reject,0,5,0.0,yes,9/27/18,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University,Stochastic gradient descent;Deep neural networks;Entropy;Information theory;Markov chains;Hidden Markov process.,136;136;136,79;79;79,-1;-1,NAN,NAN,y,
2020,ICLR,2019,Adversarial Vulnerability of Neural Networks Increases with Input Dimension,Carl-Johann Simon-Gabriel;Yann Ollivier;L√©on Bottou;Bernhard Sch√∂lkopf;David Lopez-Paz,cjsimon@tuebingen.mpg.de;yol@fb.com;leon@bottou.org;bs@tuebingen.mpg.de;dlp@fb.com,6;4;9;5,4;5;4;5,Reject,0,20,2.0,yes,9/27/18,Max-Planck Institute;Facebook;Facebook;Max-Planck Institute;Facebook,adversarial vulnerability;neural networks;gradients;FGSM;adversarial data-augmentation;gradient regularization;robust optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;4
2021,ICLR,2019,CoT: Cooperative Training for Generative Modeling of Discrete Data,Sidi Lu;Lantao Yu;Siyuan Feng;Yaoming Zhu;Weinan Zhang;Yong Yu,steve_lu@apex.sjtu.edu.cn;yulantao@apex.sjtu.edu.cn;siyuanfeng@apex.sjtu.edu;ymzhu@apex.sjtu.edu.cn;wnzhang@apex.sjtu.edu.cn;yyu@apex.sjtu.edu.cn,6;7;7,4;2;2,Reject,9,21,0.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Generative Models;Sequence Modeling;Text Generation,36;36;36;36;36;36,188;188;188;188;188;188,-1;-1,asia,cn,y,1;5
2022,ICLR,2019,Direct Optimization through $\arg \max$  for  Discrete Variational Auto-Encoder,Guy Lorberbom;Tamir Hazan,guy_lorber@campus.technion.ac.il;tamir.hazan@technion.ac.il,7;5;7,4;4;4,Reject,0,5,1.0,yes,9/27/18,"Technion, Technion;Technion, Technion",discrete variational auto encoders;generative models;perturbation models,27;27,-1;-1,-1;-1,NAN,NAN,y,
2023,ICLR,2019,Sinkhorn AutoEncoders,Giorgio Patrini;Marcello Carioni;Patrick Forr√©;Samarth Bhargav;Max Welling;Rianne van den Berg;Tim Genewein;Frank Nielsen,patrinig@hotmail.com;marcello.carioni@uni-graz.at;patrickforre@gmail.com;samarth.bhargav@student.uva.nl;welling.max@gmail.com;riannevdberg@gmail.com;tim.genewein@de.bosch.com;nielsen@lix.polytechnique.fr,7;5;6;7,3;4;3;3,Reject,0,7,0.0,yes,9/27/18,"University of Amsterdam;Karl-Franzens University Graz;University of Amsterdam;University of Amsterdam;University of California, Irvine;Google;Bosch;Ecole Polytechnique, France",generative models;autoencoders;optimal transport;sinkhorn algorithm,-1;-1;136;136;-1;-1;-1;-1,-1;-1;59;59;99;-1;367;-1,-1;-1,NAN,NAN,y,1;5
2024,ICLR,2019,Structured Prediction using cGANs with Fusion Discriminator,Faisal Mahmood;Wenhao Xu;Nicholas J. Durr;Jeremiah W. Johnson;Alan Yuille,faisalm@jhu.edu;wxu47@jhu.edu;ndurr@jhu.edu;jeremiah.johnson@unh.edu;alan.l.yuille@gmail.com,5;3;3,3;4;4,Reject,0,3,0.0,yes,9/27/18,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;University of New Hampshire;Johns Hopkins University,Generative Adversarial Networks;GANs;conditional GANs;Discriminator;Fusion,67;67;67;207;67,13;13;13;-1;13,-1;-1,usa,usa,n,2;5;4
2025,ICLR,2019,Evaluating GANs via Duality,Paulina Grnarova;Kfir Y Levy;Aurelien Lucchi;Nathanael Perraudin;Thomas Hofmann;Andreas Krause,paulina.grnarova@inf.ethz.ch;yehuda.levy@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch;nathanael.perraudin@sdsc.ethz.ch;thomas.hofmann@inf.ethz.ch;krausea@ethz.ch,4;5;3,3;3;4,Reject,0,12,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Generative Adversarial Networks;GANs;game theory,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1;5;4
2026,ICLR,2019,Hyper-Regularization: An Adaptive Choice for the Learning Rate in Gradient Descent,Guangzeng Xie;Hao Jin;Dachao Lin;Zhihua Zhang,smsxgz@pku.edu.cn;jin.hao@pku.edu.cn;lindachao@pku.edu.cn;zhzhang@math.pku.edu.cn,4;4;4,5;4;4,Reject,0,5,0.0,yes,9/27/18,Peking University;Peking University;Peking University;Peking University,Adaptive learning rate;novel framework,14;14;14;14,27;27;27;27,-1;-1,asia,cn,y,9
2027,ICLR,2019,Wasserstein proximal of GANs,Alex Tong Lin;Wuchen Li;Stanley Osher;Guido Montufar,atlin@math.ucla.edu;wcli@math.ucla.edu;sjo@math.ucla.edu;montufar@math.ucla.edu,3;6;4,5;3;3,Reject,0,5,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Optimal transport;Wasserstein gradient;Generative adversarial network;Unsupervised learning,-1;-1;-1;-1,15;15;15;15,-1;-1,usa,usa,y,1;5
2028,ICLR,2019,On the Convergence and Robustness of Batch Normalization,Yongqiang Cai;Qianxiao Li;Zuowei Shen,matcyon@nus.edu.sg;liqix@ihpc.a-star.edu.sg;matzuows@nus.edu.sg,4;6;4,5;3;3,Reject,0,9,0.0,yes,9/27/18,"National University of Singapore;Institute of High Performance Computing, Singapore, A*STAR;National University of Singapore",Batch normalization;Convergence analysis;Gradient descent;Ordinary least squares;Deep neural network,18;-1;18,22;-1;22,-1;-1,asia,sg,y,4
2029,ICLR,2019,Aligning Artificial Neural Networks to the Brain yields Shallow Recurrent Architectures,Jonas Kubilius;Martin Schrimpf;Ha Hong;Najib J. Majaj;Rishi Rajalingham;Elias B. Issa;Kohitij Kar;Pouya Bashivan;Jonathan Prescott-Roy;Kailyn Schmidt;Aran Nayebi;Daniel Bear;Daniel L. K. Yamins;James J. DiCarlo,qbilius@mit.edu;msch@mit.edu;dicarlo@mit.edu,7;7;5,4;4;4,Reject,0,11,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Computational Neuroscience;Brain-Inspired;Neural Networks;Simplified Models;Recurrent Neural Networks;Computer Vision,6;6;6,5;5;5,-1;-1,usa,usa,n,
2030,ICLR,2019,Finding Mixed Nash Equilibria of Generative Adversarial Networks,Ya-Ping Hsieh;Chen Liu;Volkan Cevher,ya-ping.hsieh@epfl.ch;chen.liu@epfl.ch;volkan.cevher@epfl.ch,6;4;5,4;4;5,Reject,0,10,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,GANs;mixed Nash equilibrium;mirror descent;sampling,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,1;5;4;9
2031,ICLR,2019,Local Stability and Performance of Simple Gradient Penalty $\mu$-Wasserstein GAN,Cheolhyeong Kim;Seungtae Park;Hyung Ju Hwang,tyty4@postech.ac.kr;swash21@postech.ac.kr;hjhwang@postech.ac.kr,6;5;4,4;4;3,Reject,0,6,0.0,yes,9/27/18,POSTECH;POSTECH;POSTECH,WGAN;gradient penalty;stability;measure valued differentiation,136;136;136,137;137;137,-1;-1,asia,kr,y,1;5
2032,ICLR,2019,Learning Discriminators as Energy Networks in Adversarial Learning,Pingbo Pan;Yan Yan;Tianbao Yang;Yi Yang,pingbo.pan@student.uts.edu.au;yan.yan-3@student.uts.edu.au;tianbao-yang@uiowa.edu;yi.yang@uts.edu.au,5;5;5,4;5;4,Reject,5,5,0.0,yes,9/27/18,University of Technology Sydney;University of Technology Sydney;University of Iowa;University of Technology Sydney,adversarial learning;structured prediction;energy networks,67;67;169;67,216;216;223;216,-1;-1,australasia,au,n,2;4
2033,ICLR,2019,Optimistic Acceleration for Optimization,Jun-Kun Wang;Xiaoyun Li;Ping Li,jimwang@gatech.edu;xl374@scarletmail.rutgers.edu;pingli98@gmail.com,5;6;5;4,4;2;4;4,Reject,0,7,0.0,yes,9/27/18,Georgia Institute of Technology;Rutgers University;Baidu,optimization;Adam;AMSGrad,13;31;-1,33;-1;-1,m;m,asia,in,y,
2034,ICLR,2019,Rethinking learning rate schedules for stochastic optimization,Rong Ge;Sham M. Kakade;Rahul Kidambi;Praneeth Netrapalli,rongge@cs.duke.edu;sham@cs.washington.edu;rkidambi@uw.edu;praneeth@microsoft.com,6;4;6,4;4;4,Reject,0,7,0.0,yes,9/27/18,"Duke University;University of Washington;University of Washington, Seattle;Microsoft",SGD;learning rate;step size schedules;stochastic approximation;stochastic optimization;deep learning;non-convex optimization;stochastic gradient descent,47;10;10;-1,17;25;25;-1,-1;-1,NAN,NAN,y,1;9
2035,ICLR,2019,On the Ineffectiveness of Variance Reduced Optimization for Deep Learning,Aaron Defazio,aaron.defazio@gmail.com,5;6;5,5;3;4,Reject,0,9,0.0,yes,9/27/18,Facebook,machine learning;optimization;variance reduction,-1,-1,-1,NAN,NAN,n,9
2036,ICLR,2019,EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE,Chao Ma;Sebastian Tschiatschek;Konstantina Palla;Jose Miguel Hernandez Lobato;Sebastian Nowozin;Cheng Zhang,cm905@cam.ac.uk;sebastian.tschiatschek@microsoft.com;konstantina.palla@microsoft.com;jmh233@cam.ac.uk;sebastian.nowozin@microsoft.com;cheng.zhang@microsoft.com,6;5;6,2;4;4,Reject,0,5,0.0,yes,9/27/18,University of Cambridge;Microsoft;Microsoft;University of Cambridge;Microsoft;Microsoft,active variable selection;missing data;amortized inference,77;-1;-1;77;-1;-1,2;-1;-1;2;-1;-1,-1;-1,NAN,NAN,n,11;1;5
2037,ICLR,2019,"Search-Guided, Lightly-supervised Training of  Structured Prediction Energy Networks",Amirmohammad Rooshenas;Dongxu Zhang;Gopal Sharma;Andrew McCallum,pedram@cs.umass.edu;dongxuzhang@cs.umass.edu;gopalsharma@cs.umass.edu;mccallum@cs.umass.edu,5;7;4,4;4;4,Reject,0,3,0.0,yes,9/27/18,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",structured prediction energy networks;indirect supervision;search-guided training;reward functions,27;27;27;27,191;191;191;191,-1;-1,usa,usa,n,
2038,ICLR,2019,Distinguishability of Adversarial Examples,Yi Qin;Ryan Hunt;Chuan Yue,yiqin@mines.edu;ryhunt@mines.edu;chuanyue@mines.edu,4;4;4,4;5;4,Reject,1,2,0.0,yes,9/27/18,Colorado School of Mines;Colorado School of Mines;Colorado School of Mines,Adversarial Examples;Machine Learning;Neural Networks;Distinguishability;Defense,207;207;207,268;268;268,-1;-1,usa,usa,n,2;4
2039,ICLR,2019,On the Geometry of Adversarial Examples,Marc Khoury;Dylan Hadfield-Menell,khoury@eecs.berkeley.edu;dhm@berkeley.edu,5;3;6,3;4;4,Reject,0,13,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley,adversarial examples;high-dimensional geometry,-1;-1,18;18,-1;-1,usa,usa,y,1;4
2040,ICLR,2019,Partially Mutual Exclusive Softmax for Positive and Unlabeled data,Ugo Tanielian;Flavian vasile;Mike Gartrell,u.tanielian@criteo.com;f.vasile@criteo.com;m.gartrell@criteo.com,5;4;5,4;4;4,Reject,0,2,0.0,yes,9/27/18,Criteo;Criteo;Criteo,Negative Sampling;Sampled Softmax;Word embeddings;Adversarial Networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;4
2041,ICLR,2019,Learning Global Additive Explanations for Neural Nets Using Model Distillation,Sarah Tan;Rich Caruana;Giles Hooker;Paul Koch;Albert Gordo,ht395@cornell.edu;rcaruana@microsoft.com;gjh27@cornell.edu;paulkoch@microsoft.com;albert.gordo.s@gmail.com,6;4;6,5;5;4,Reject,0,7,0.0,yes,9/27/18,Cornell University;Microsoft;Cornell University;Microsoft;Facebook,global interpretability;additive explanations;model distillation;neural nets;tabular data,6;-1;6;-1;-1,19;-1;19;-1;-1,-1;-1,NAN,NAN,n,10
2042,ICLR,2019,Predicted Variables in Programming,Victor Carbune;Thierry Coppey;Alexander Daryin;Thomas Deselaers;Nikhil Sarda;Jay Yagnik,victor.carbune@gmail.com;thierryc@google.com;shurick@google.com;deselaers@google.com;nikhilsarda@google.com;jyagnik@google.com,5;5;7,3;3;3,Reject,0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google,predicted variables;machine learning;programming;computing systems;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2043,ICLR,2019,Learning Abstract Models for Long-Horizon Exploration,Evan Zheran Liu;Ramtin Keramati;Sudarshan Seshadri;Kelvin Guu;Panupong Pasupat;Emma Brunskill;Percy Liang,evanliu@cs.stanford.edu;keramati@stanford.edu;ssesha@stanford.edu;kguu@stanford.edu;ppasupat@cs.stanford.edu;ebrun@cs.stanford.edu;pliang@cs.stanford.edu,6;5;4,2;4;4,Reject,0,10,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Reinforcement Learning;Hierarchical Reinforcement Learning;Model-based Reinforcement Learning;Exploration,4;4;4;4;4;4;4,3;3;3;3;3;3;3,-1;-1,usa,usa,y,
2044,ICLR,2019,Domain Adaptation for Structured Output via Disentangled Patch Representations,Yi-Hsuan Tsai;Kihyuk Sohn;Samuel Schulter;Manmohan Chandraker,wasidennis@gmail.com;kihyuk.sohn@gmail.com;samuel@nec-labs.com;manu@nec-labs.com,5;7;5,5;5;4,Reject,2,7,1.0,yes,9/27/18,NEC-Labs;Google;NEC-Labs;NEC-Labs,Domain Adaptation;Feature Representation Learning;Semantic Segmentation,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;4
2045,ICLR,2019,Meta-Learning Neural Bloom Filters,Jack W Rae;Sergey Bartunov;Timothy P Lillicrap,jwrae@google.com;bartunov@google.com;countzero@google.com,7;6;3,3;4;1,Reject,0,10,0.0,yes,9/27/18,Google;Google;Google,meta-learning;memory;one-shot learning;bloom filter;set membership;familiarity;compression,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,6
2046,ICLR,2019,The Universal Approximation Power of Finite-Width Deep ReLU Networks,Dmytro Perekrestenko;Philipp Grohs;Dennis Elbr√§chter;Helmut B√∂lcskei,pdmytro@nari.ee.ethz.ch;philipp.grohs@univie.ac.at;dennis.elbraechter@univie.ac.at;boelcskei@nari.ee.ethz.ch,5;5;6,3;4;3,Reject,0,5,0.0,yes,9/27/18,Swiss Federal Institute of Technology;University of Vienna;University of Vienna;Swiss Federal Institute of Technology,rate-distortion optimality;ReLU;deep learning;approximation theory;Weierstrass function,-1;169;169;-1,-1;164;164;-1,-1;-1,NAN,NAN,y,1
2047,ICLR,2019,Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation,Shani Gamrian;Yoav Goldberg,gamrianshani@gmail.com;yoav.goldberg@gmail.com,4;7;7,4;3;3,Reject,0,5,0.0,yes,9/27/18,Bar Ilan University;Bar-Ilan University,Transfer Learning;Reinforcement Learning;Generative Adversarial Networks;Video Games,-1;94,-1;456,-1;-1,europe,il,n,6;5;4
2048,ICLR,2019,Guiding Physical Intuition with Neural Stethoscopes,Fabian Fuchs;Oliver Groth;Adam Kosiorek;Alex Bewley;Markus Wulfmeier;Andrea Vedaldi;Ingmar Posner,fabian@robots.ox.ac.uk;ogroth@robots.ox.ac.uk;adamk@robots.ox.ac.uk;alex.bewley@gmail.com;m.wulfmeier@gmail.com;vedaldi@robots.ox.ac.uk;ingmar@robots.ox.ac.uk,6;4;7,4;3;3,Reject,0,3,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford;;DeepMind;University of Oxford;University of Oxford,Deep Learning;Intuitive Physics;Stability Prediction;Adversarial Training;Auxiliary Training;Multi-Task Learning,44;44;44;-1;-1;44;44,1;1;1;-1;-1;1;1,-1;-1,europe,uk,n,4
2049,ICLR,2019,An Adversarial Learning Framework for a Persona-based Multi-turn Dialogue Model,Oluwatobi O. Olabiyi;Anish Khazane;Alan Salimov;Erik T.Mueller,oluwatobi.olabiyi@capitalone.com;anish.khazan@capitalone.com;alan.salimov@capitalone.com;erik.mueller@capitalone.com,5;4;6,4;4;3,Reject,0,6,0.0,yes,9/27/18,Capital One Bank;Capital One Bank;Capital One Bank;Capital One Bank,conversation model;dialogue system;adversarial net;persona,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1;4
2050,ICLR,2019,Adaptive Sample-space & Adaptive Probability coding: a neural-network based approach for compression,Ken Nakanishi;Shin-ichi Maeda;Takeru Miyato;Masanori Koyama,ikyhn1.ken.n@gmail.com;ichi@preferred.jp;miyato@preferred.jp;masomatics@preferred.jp,5;7;5,4;3;4,Reject,0,5,0.0,yes,9/27/18,"The University of Tokyo;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Data compression;Image compression;Deep Learning;Convolutional neural networks,59;-1;-1;-1,45;-1;-1;-1,-1;-1,NAN,NAN,n,
2051,ICLR,2019,Seq2Slate: Re-ranking and Slate Optimization with RNNs,Irwan Bello;Sayali Kulkarni;Sagar Jain;Craig Boutilier;Ed Chi;Elad Eban;Xiyang Luo;Alan Mackey;Ofer Meshi,ibello@google.com;sayali@google.com;sagarj@google.com;cboutilier@google.com;edchi@google.com;elade@google.com;xyluo@google.com;mackeya@google.com;meshi@google.com,7;6;6,5;4;4,Reject,0,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google,Recurrent neural networks;learning to rank;pointer networks,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2052,ICLR,2019,An Efficient and Margin-Approaching Zero-Confidence Adversarial Attack,Yang Zhang;Shiyu Chang;Mo Yu;Kaizhi Qian,yang.zhang2@ibm.com;shiyu.chang@ibm.com;yum@us.ibm.com;kqian3@illinois.edu,6;5;5,5;3;4,Reject,8,15,0.0,yes,9/27/18,"International Business Machines;International Business Machines;International Business Machines;University of Illinois, Urbana Champaign",adversarial attack;zero-confidence attack,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,n,4
2053,ICLR,2019,Neural Causal Discovery with Learnable Input Noise,Tailin Wu;Thomas Breuel;Jan Kautz,tailin@mit.edu;tbreuel@nvidia.com;jkautz@nvidia.com,4;4;8,5;4;4,Reject,0,3,0.0,yes,9/27/18,Massachusetts Institute of Technology;NVIDIA;NVIDIA,neural causal learning;learnable noise,6;-1;-1,5;-1;-1,-1;-1,NAN,NAN,y,
2054,ICLR,2019,Dense Morphological Network: An Universal Function Approximator,Ranjan Mondal;Sanchayan Santra;Bhabatosh Chanda,ranjan.rev@gmail.com;sanchayan_r@isical.ac.in;chanda@isical.ac.in,5;5;5,3;4;5,Reject,2,9,0.0,yes,9/27/18,"Indian Statistical Institute, Kolkata;Indian Statistical Institute, Kolkata;Indian Statistical Institute, Kolkata",Mathematical Morphology;Neural Network;Activation Function;Universal Aproximatimation.,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,
2055,ICLR,2019,Filter Training and Maximum Response: Classification via Discerning,Lei Gu,gul2@uci.edu,2;3;6,1;4;3,Reject,0,0,0.0,yes,9/27/18,"University of California, Irvine",filter training;maximum response;multiple check;ensemble learning,-1,99,-1,usa,usa,n,
2056,ICLR,2019,BEHAVIOR MODULE IN NEURAL NETWORKS,Andrey Sakryukin;Yongkang Wong;Mohan S. Kankanhalli,asakryukin@u.nus.edu;yongkang.wong@nus.edu.sg;mohan@comp.nus.edu.sg,3;3;4,4;5;5,Reject,0,0,0.0,yes,9/27/18,National University of Singapore;National University of Singapore;National University of Singapore,Modular Networks;Reinforcement Learning;Task Separation;Representation Learning;Transfer Learning;Adversarial Transfer,18;18;18,22;22;22,-1;-1,asia,sg,n,
2057,ICLR,2019,Surprising Negative Results for Generative  Adversarial Tree Search ,Kamyar Azizzadenesheli;Brandon Yang;Weitang Liu;Emma Brunskill;Zachary Lipton;Animashree Anandkumar,kazizzad@uci.edu;bcyang@stanford.edu;wetliu@ucdavis.edu;ebrun@cs.stanford.edu;zlipton@cmu.edu;anima@caltech.edu,5;5;6,3;4;2,Reject,0,4,0.0,yes,9/27/18,"University of California, Irvine;Stanford University;University of California, Davis;Stanford University;Carnegie Mellon University;California Institute of Technology",Deep Reinforcement Learning;Generative Adversarial Nets,-1;4;-1;4;1;136,99;3;54;3;24;3,-1;-1,usa,usa,y,5;4
2058,ICLR,2019,Evaluation Methodology for Attacks Against Confidence Thresholding Models,Ian Goodfellow;Yao Qin;David Berthelot,goodfellow@google.com;yaoqin@google.com;dberth@google.com,2;3;4,4;3;4,Reject,0,1,0.0,yes,9/27/18,Google;Google;Google,adversarial examples,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
2059,ICLR,2019,Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference,Ruying Bao;Sihang Liang;Qingcan Wang,rbao@princeton.edu;sihangl@princeton.edu;qingcanw@princeton.edu,4;3;3,5;4;4,Reject,0,4,0.0,yes,9/27/18,Princeton University;Princeton University;Princeton University,,31;31;31,7;7;7,-1;-1,usa,usa,n,5;4
2060,ICLR,2019,ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES,Xiaoyun Wang;Joe Eaton;Cho-Jui Hsieh;Felix Wu,xiywang@ucdavis.edu;featon@nvidia.com;chohsieh@ucdavis.edu;sfwu@ucdavis.edu,4;3;3,3;4;2,Reject,0,0,0.0,yes,9/27/18,"University of California, Davis;NVIDIA;University of California, Davis;University of California, Davis",Graph Convolutional Network;adversarial attack;node classification,-1;-1;-1;-1,54;-1;54;54,-1;-1,usa,usa,n,10;4
2061,ICLR,2019,Stochastic Quantized Activation: To prevent Overfitting in Fast Adversarial Training,Wonjun Yoon;Jisuk Park;Daeshik Kim,wonjun.yoon@kaist.ac.kr;ssuk30@kaist.ac.kr;daeshik@kaist.ac.kr,4;5;4,3;5;4,Reject,0,0,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,adversarial examples;deep learning,-1;-1;-1,95;95;95,-1;-1,NAN,NAN,n,4
2062,ICLR,2019,BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks,Huili Chen;Bita Darvish Rouhani;Farinaz Koushanfar,huc044@ucsd.edu;bita@ucsd.edu;farinaz@ucsd.edu,5;4;4,3;4;4,Reject,0,0,0.0,yes,9/27/18,"University of California, San Diego;University of California, San Diego;University of California, San Diego",Digital Watermarking;IP Protection;Deep Neural Networks,-1;-1;-1,31;31;31,-1;-1,usa,usa,n,4
2063,ICLR,2019,Purchase as Reward : Session-based  Recommendation by Imagination Reconstruction,Qibing Li;Xiaolin Zheng,qblee@zju.edu.cn;xlzheng@zju.edu.cn,5;6;5,3;2;5,Reject,0,3,0.0,yes,9/27/18,Zhejiang University;Zhejiang University,recommender systems;reinforcement learning;predictive learning;self-supervised RL;model-based planning,36;36,177;177,-1;-1,asia,cn,n,
2064,ICLR,2019,Optimal Attacks against Multiple Classifiers,Juan C. Perdomo;Yaron Singer,jcperdomo@berkeley.edu;yaron@seas.harvard.edu,5;6;4;6,4;3;4;4,Reject,0,5,0.0,yes,9/27/18,University of California Berkeley;Harvard University,online learning;nonconvex optimization;robust optimization,-1;50,18;6,-1;-1,usa,usa,y,4
2065,ICLR,2019,Label Propagation Networks,Kojin Oshiba;Nir Rosenfeld;Amir Globerson,kojinoshiba@college.harvard.edu;nirr@g.harvard.edu;amir.globerson@gmail.com,5;5;6,4;2;4,Reject,5,4,0.0,yes,9/27/18,Harvard University;Harvard University;Tel Aviv University,semi supervised learning;graph networks;deep learning architectures,50;50;31,6;6;217,-1;-1,europe,il,n,10
2066,ICLR,2019,Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring,Du Su;Ali Yekkehkhany;Yi Lu;Wenmiao Lu,dusu3@illinois.edu;yekkehk2@illinois.edu;yilu4@illinois.edu;wenmiao.lu@gmail.com,3;5;4,3;3;4,Reject,2,5,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Nanyang Technological University",personalized learning;e-learning;text embedding;Skip-gram;imbalanced data set;data level classification methods,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,
2067,ICLR,2019,Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae,Piero Molino;Yang Wang;Jiawei Zhang,piero@uber.com;gnavvy@uber.com;rivulet.zhang@gmail.com,3;3;4,4;3;3,Reject,0,6,0.0,yes,9/27/18,Uber;Uber;Purdue University,visualization;embeddings;representations;t-sne;natural;language;processing;machine;learning;algebra,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,n,3
2068,ICLR,2019,Cross-Entropy Loss Leads To Poor Margins,Kamil Nar;Orhan Ocal;S. Shankar Sastry;Kannan Ramchandran,nar@berkeley.edu;ocal@eecs.berkeley.edu;sastry@eecs.berkeley.edu;kannanr@eecs.berkeley.edu,3;4;5;8;5,4;5;4;3;4,Reject,1,8,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Cross-entropy loss;Binary classification;Low-rank features;Adversarial examples;Differential training,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,y,4
2069,ICLR,2019,A Case for Object Compositionality in Deep Generative Models of Images,Sjoerd van Steenkiste;Karol Kurach;Sylvain Gelly,sjoerd@idsia.ch;kkurach@gmail.com;sylvain.gelly@gmail.com,5;4;6,5;5;4,Reject,0,6,0.0,yes,9/27/18,IDSIA;Google;Google,Objects;Compositionality;Generative Models;GAN;Unsupervised Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
2070,ICLR,2019,Object-Oriented Model Learning through Multi-Level Abstraction,Guangxiang Zhu;Jianhao Wang;ZhiZhou Ren;Chongjie Zhang,guangxiangzhu@outlook.com;jh-wang15@mails.tsinghua.edu.cn;rzz16@mails.tsinghua.edu.cn;chongjie@tsinghua.edu.cn,4;4;6,4;3;3,Reject,0,9,0.0,yes,9/27/18,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",action-conditioned dynamics learning;deep learning;generalization;interpretability;sample efficiency,-1;4;4;4,-1;30;30;30,-1;-1,NAN,NAN,n,1
2071,ICLR,2019,IB-GAN: Disentangled Representation Learning with Information Bottleneck GAN,Insu Jeon;Wonkwang Lee;Gunhee Kim,isjeon@vision.snu.ac.kr;wonkwang.lee.94@gmail.com;gunhee@snu.ac.kr,7;7;4,3;4;4,Reject,0,7,1.0,yes,9/27/18,Seoul National University;;Seoul National University,Unsupervised disentangled representation learning;GAN;Information Bottleneck;Variational Inference,36;-1;36,74;-1;74,-1;-1,asia,kr,n,1;5
2072,ICLR,2019,ACE: Artificial Checkerboard Enhancer to Induce and Evade Adversarial Attacks,Jisung Hwang;Younghoon Kim;Sanghyuk Chun;Jaejun Yoo;Ji-Hoon Kim;Dongyoon Han;Jung-Woo Ha,jeshwang92@uchicago.edu;snu13dlx@snu.ac.kr;sanghyuk.c@navercorp.com;jaejun.yoo@navercorp.com;genesis.kim@navercorp.com;dongyoon.han@navercorp.com;jungwoo.ha@navercorp.com,4;4;6,2;3;1,Reject,0,6,0.0,yes,9/27/18,University of Chicago;Seoul National University;NAVER;NAVER;NAVER;NAVER;NAVER,Adversarial Examples;Neural Network Security;Deep Neural Network;Checkerboard Artifact,50;36;-1;-1;-1;-1;-1,9;74;-1;-1;-1;-1;-1,-1;-1,europe,gr,n,2;4
2073,ICLR,2019,Second-Order Adversarial Attack and Certifiable Robustness,Bai Li;Changyou Chen;Wenlin Wang;Lawrence Carin,bai.li@duke.edu;cchangyou@gmail.com;wenlin.wang@duke.edu;lcarin@duke.edu,4;5;3,5;3;5,Reject,0,6,0.0,yes,9/27/18,"Duke University;State University of New York, Buffalo;Duke University;Duke University",,47;-1;47;47,17;-1;17;17,-1;-1,europe,se,y,1;4
2074,ICLR,2019,Learning Heuristics for Automated Reasoning through Reinforcement Learning,Gil Lederman;Markus N. Rabe;Edward A. Lee;Sanjit A. Seshia,gilled@berkeley.edu;markus.norman.rabe@gmail.com;eal@berkeley.edu;sseshia@eecs.berkeley.edu,5;6;7,3;4;4,Reject,0,6,0.0,yes,9/27/18,University of California Berkeley;Google;University of California Berkeley;University of California Berkeley,reinforcement learning;deep learning;logics;formal methods;automated reasoning;backtracking search;satisfiability;quantified Boolean formulas,-1;-1;-1;-1,18;-1;18;18,-1;-1,usa,usa,n,
2075,ICLR,2019,Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles,Edward Grefenstette;Robert Stanforth;Brendan O'Donoghue;Jonathan Uesato;Grzegorz Swirszcz;Pushmeet Kohli,etg@google.com;stanforth@google.com;bodonoghue@google.com;juesato@google.com;swirszcz@google.com;pushmeet@google.com,5;6;4,4;3;3,Reject,0,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google,adversarial examples;adversarial robustness;visualisation;ensembles,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
2076,ICLR,2019,Explaining Adversarial Examples with Knowledge Representation,Xingyu Zhou;Tengyu Ma;Huahong Zhang,xingyu.zhou@vanderbilt.edu;tengyu.ma@vanderbilt.edu;huahong.zhang@vanderbilt.edu,3;3;2,4;2;5,Reject,0,0,0.0,yes,9/27/18,Vanderbilt University;Vanderbilt University;Vanderbilt University,adversarial example;knowledge representation;distribution imitation,285;285;285,105;105;105,-1;-1,usa,usa,n,8;4
2077,ICLR,2019,Cutting Down Training Memory by Re-fowarding,Jianwei Feng;Dong Huang,jfeng1@andrew.cmu.edu;donghuang@cmu.edu,6;4;4;6,3;3;2;3,Reject,0,6,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University,deep learning;training memory;computation-memory trade off;optimal solution,1;1,24;24,-1;-1,usa,usa,y,1;10
2078,ICLR,2019,Neural Networks with Structural Resistance to Adversarial Attacks,Luca de Alfaro,luca@ucsc.edu,7;5;5,4;3;3,Reject,2,1,0.0,yes,9/27/18,University of Southern California,machine learning;adversarial attacks,27,66,-1,usa,usa,n,4
2079,ICLR,2019,Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation,Mahdieh Abbasi;Arezoo Rajabi;Azadeh Sadat Mozafari;Rakesh B. Bobba;Christian Gagn√©,mahdieh.abbasi.1@ulaval.ca;rajabia@oregonstate.edu;azadeh-sadat.mozafari.1@ulaval.ca;rakesh.bobba@oregonstate.edu;christian.gagne@gel.ulaval.ca,4;4;3,4;5;3,Reject,8,6,0.0,yes,9/27/18,Laval university;Oregon State University;Laval university;Oregon State University;Laval university,Convolutional Neural Networks;Adversarial Instances;Out-distribution Samples;Rejection Option;Over-generalization,-1;77;-1;77;-1,265;318;265;318;265,-1;-1,NAN,NAN,n,2;1;4
2080,ICLR,2019,Robust Determinantal Generative Classifier for Noisy Labels and Adversarial Attacks,Kimin Lee;Sukmin Yun;Kibok Lee;Honglak Lee;Bo Li;Jinwoo Shin,kiminlee@kaist.ac.kr;sm3199@kaist.ac.kr;kibok@umich.edu;honglak@eecs.umich.edu;lxbosky@gmail.com;jinwoos@kaist.ac.kr,7;3;4,5;4;4,Reject,0,8,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;University of Michigan;University of Michigan;University of California Berkeley;Korea Advanced Institute of Science and Technology,Noisy Labels;Adversarial Attacks;Generative Models,-1;-1;9;9;-1;-1,95;95;21;21;18;95,-1;-1,NAN,NAN,y,5;4
2081,ICLR,2019,Single Shot Neural Architecture Search Via Direct Sparse Optimization,Xinbang Zhang;Zehao Huang;Naiyan Wang,xinbang.zhang@nlpr.ia.ac.cn;zehaohuang18@gmail.com;winsty@gmail.com,7;6;6,3;4;3,Reject,0,18,1.0,yes,9/27/18,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;;The Hong Kong University of Science and Technology",Neural Architecture Search;Sparse Optimization,31;-1;-1,-1;-1;-1,-1;-1,asia,in,n,
2082,ICLR,2019,How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification,Suhua Lei;Huan Zhang;Ke Wang;Zhendong Su,sulei@ucdavis.edu;huan@huan-zhang.com;kewang@visa.com;zhendong.su@inf.ethz.ch,5;4;5,4;4;3,Reject,0,5,0.0,yes,9/27/18,"University of California, Davis;Carnegie Mellon University;Visa Research;Swiss Federal Institute of Technology",Adversarial attacks;Robustness;CW;I-FGSM,-1;1;-1;-1,54;24;-1;-1,-1;-1,NAN,NAN,n,4
2083,ICLR,2019,EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEEP NEURAL NETWORKS,Ting-Jui Chang;Yukun He;Peng Li,tingjui.chang@tamu.edu;dominiche@tamu.edu;pli@tamu.edu,5;6;7,4;3;3,Reject,2,1,0.0,yes,9/27/18,Texas A&M;Texas A&M;Texas A&M,Adversarial Examples;Adversarial Training;FGSM;IFGSM;Robustness,50;50;50,160;160;160,-1;-1,NAN,NAN,n,4
2084,ICLR,2019,Adaptive Neural Trees,Ryutaro Tanno;Kai Arulkumaran;Daniel C. Alexander;Antonio Criminisi;Aditya Nori,ryutaro.tanno.15@ucl.ac.uk;kailash.arulkumaran13@imperial.ac.uk;d.alexander@ucl.ac.uk;antcrim@microsoft.com;adityan@microsoft.com,6;6;4,4;3;4,Reject,0,7,2.0,yes,9/27/18,University College London;Imperial College London;University College London;Microsoft;Microsoft,neural networks;decision trees;computer vision,50;47;50;-1;-1,-1;8;-1;-1;-1,-1;-1,NAN,NAN,n,
2085,ICLR,2019,Graph Convolutional Network with Sequential Attention For Goal-Oriented Dialogue Systems,Suman Banerjee;Mitesh M. Khapra,suman@cse.iitm.ac.in;miteshk@cse.iitm.ac.in,5;6;7,3;4;2,Reject,0,0,5.0,yes,9/27/18,Indian Institute of Technology Madras;Indian Institute of Technology Madras,Goal-oriented Dialogue Systems;Graph Convolutional Networks,-1;-1,625;625,-1;-1,NAN,NAN,n,8;3;10
2086,ICLR,2019,Probabilistic Neural-Symbolic Models for Interpretable Visual Question Answering,Ramakrishna Vedantam;Stefan Lee;Marcus Rohrbach;Dhruv Batra;Devi Parikh,vrama@gatech.edu;steflee@gatech.edu;maroffm@gmail.com;dbatra@gatech.edu;parikh@gatech.edu,6;8;7,3;5;3,Reject,0,17,1.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Facebook;Georgia Institute of Technology;Georgia Institute of Technology,Neural-symbolic models;visual question answering;reasoning;interpretability;graphical models;variational inference,13;13;-1;13;13,33;33;-1;33;33,-1;-1,usa,usa,n,
2087,ICLR,2019,Neural separation of observed and unobserved distributions,Tavi Halperin;Ariel Ephrat;Yedid Hoshen,tavihalperin@gmail.com;ariel.ephrat@gmail.com;yedidh@fb.com,5;6;6,4;2;4,Reject,0,4,1.0,yes,9/27/18,Hebrew University of Jerusalem;Google;Facebook,source separation;non-adversarial training;source unmixing;iterative neural training;generative modeling,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2088,ICLR,2019,BNN+: Improved Binary Network Training,Sajad Darabi;Mouloud Belbahri;Matthieu Courbariaux;Vahid Partovi Nia,sajad.darabi@cs.ucla.edu;belbahrim@dms.umontreal.ca;matthieu.courbariaux@gmail.com;vahid.partovinia@huawei.com,4;8;6,4;4;3,Reject,13,15,1.0,yes,9/27/18,"University of California, Los Angeles;University of Montreal;;Huawei Technologies Ltd.",Binary Network;Binary Training;Model Compression;Quantization,-1;116;-1;-1,15;108;-1;-1,-1;-1,NAN,NAN,n,
2089,ICLR,2019,Dynamic Early Terminating of Multiply Accumulate Operations for Saving Computation Cost in Convolutional Neural Networks,Yu-Yi Su;Yung-Chih Chen;Xiang-Xiu Wu;Shih-Chieh Chang,wwball34@gmail.com;ycchen.phi@gmail.com;jaubau999@gmail.com;scchang@cs.nthu.edu.tw,5;6;6,3;5;3,Reject,0,8,0.0,yes,9/27/18,National Tsing Hua University;National Tsing Hua University;;National Tsing Hua University,Convolutional neural network;Early terminating;Dynamic model optimization,-1;207;-1;207,-1;323;-1;323,-1;-1,asia,tw,n,8
2090,ICLR,2019,SEGEN: SAMPLE-ENSEMBLE GENETIC EVOLUTIONARY NETWORK MODEL,Jiawei Zhang;Limeng Cui;Fisher B. Gouza,jiawei@ifmlab.org;lmcui932@163.com;fisherbgouza@gmail.com,4;5;5,4;2;5,Reject,0,5,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;Pennsylvania State University;IFM Lab,Genetic Evolutionary Network;Deep Learning;Genetic Algorithm;Ensemble Learning;Representation Learning,-1;44;-1,352;-1;-1,-1;-1,asia,in,n,
2091,ICLR,2019,Local Binary Pattern Networks for Character Recognition,Jeng-Hau Lin;Yunfan Yang;Rajesh K. Gupta;Zhuowen Tu,jel252@ucsd.edu;yuy130@ucsd.edu;rgupta@ucsd.edu;ztu@ucsd.edu,5;6;5,5;4;4,Reject,0,3,0.0,yes,9/27/18,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",deep learning;local binary pattern;supervised learning;hardware-friendly,-1;-1;-1;-1,31;31;31;31,-1;-1,usa,usa,n,
2092,ICLR,2019,A  Model Cortical Network for Spatiotemporal Sequence Learning and Prediction,Jielin Qiu;Ge Huang;Tai Sing Lee,ternence1996@gmail.com;hgesummer@gmail.com;taislee@andrew.cmu.edu,7;7;3,3;3;3,Reject,0,13,0.0,yes,9/27/18,Shanghai Jiao Tong University;;Carnegie Mellon University,cortical models;spatiotemporal memory;video prediction;predictive coding,-1;-1;1,-1;-1;24,-1;-1,usa,usa,n,
2093,ICLR,2019,Graph Transformer ,Yuan Li;Xiaodan Liang;Zhiting Hu;Yinbo Chen;Eric P. Xing,liyuanchristy@gmail.com;xiaodan1@cs.cmu.edu;zhitingh@cs.cmu.edu;cyb15@mails.tsinghua.edu.cn;epxing@cs.cmu.edu,6;6;6,5;5;3,Reject,3,8,0.0,yes,9/27/18,"Duke University;Carnegie Mellon University;Carnegie Mellon University;Tsinghua University, Tsinghua University;Carnegie Mellon University",Graph neural networks;transformer;attention,47;1;1;4;1,17;24;24;30;24,-1;-1,usa,usa,n,6;8;10
2094,ICLR,2019,Automata Guided Skill Composition,Xiao Li;Yao Ma;Calin Belta,xli87@bu.edu;yaoma@bu.edu;cbelta@bu.edu,5;7;6;5,2;3;4;2,Reject,0,5,1.0,yes,9/27/18,Boston University;Boston University;Boston University,Skill composition;temporal logic;finite state automata,77;77;77,70;70;70,-1;-1,europe,it,y,
2095,ICLR,2019,Manifold Mixup: Learning Better Representations by Interpolating Hidden States,Vikas Verma;Alex Lamb;Christopher Beckham;Amir Najafi;Aaron Courville;Ioannis Mitliagkas;Yoshua Bengio,vikasverma.iitm@gmail.com;lambalex@iro.umontreal.ca;christopher.j.beckham@gmail.com;najafy@ce.sharif.edu;aaron.courville@gmail.com;imitliagkas@gmail.com;yoshua.umontreal@gmail.com,8;6;4,2;4;4,Reject,0,33,0.0,yes,9/27/18,Aalto University;University of Montreal;;Sharif University of Technology;University of Montreal;University of Montreal;University of Montreal,Regularizer;Supervised Learning;Semi-supervised Learning;Better representation learning;Deep Neural Networks.,116;116;-1;285;116;116;116,190;108;-1;603;108;108;108,-1;-1,canada,ca,y,1;4
2096,ICLR,2019,Convolutional Neural Networks combined with Runge-Kutta Methods,Mai Zhu;Bo Chang;Chong Fu,zhumai@stumail.neu.edu.cn;bchang@stat.ubc.ca;fuchong@mail.neu.edu.cn,4;5;6,3;4;3,Reject,0,3,0.0,yes,9/27/18,Northeastern University;University of British Columbia;Northeastern University,,15;59;15,839;34;839,-1;-1,usa,usa,n,
2097,ICLR,2019,Exploring and Enhancing the Transferability of Adversarial Examples,Lei Wu;Zhanxing Zhu;Cheng Tai,leiwu@pku.edu.cn;zhanxing.zhu@pku.edu.cn;chengtai@pku.edu.cn,4;6;6,2;3;3,Reject,0,5,0.0,yes,9/27/18,Peking University;Peking University;Peking University,Deep learning;Adversarial example;Transferability;Smoothed gradient,14;14;14,27;27;27,-1;-1,asia,cn,n,4
2098,ICLR,2019,Invariance and Inverse Stability under ReLU,Jens Behrmann;S√∂ren Dittmer;Pascal Fernsel;Peter Maass,jensb@uni-bremen.de;sdittmer@math.uni-bremen.de;pfernsel@math.uni-bremen.de;pmaass@uni-bremen.de,6;6;7,3;4;3,Reject,0,8,0.0,yes,9/27/18,Universit√§t Bremen;Universit√§t Bremen;Universit√§t Bremen;Universit√§t Bremen,deep neural networks;invertibility;invariance;robustness;ReLU networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,4
2099,ICLR,2019,Improving Sentence Representations with Multi-view Frameworks,Shuai Tang;Virginia R. de Sa,shuaitang93@ucsd.edu;desa@ucsd.edu,6;5;7,5;4;4,Reject,0,8,0.0,yes,9/27/18,"University of California, San Diego;University of California, San Diego",multi-view;learning;sentence;representation,-1;-1,31;31,-1;-1,usa,usa,n,5
2100,ICLR,2019,Principled Deep Neural Network Training through Linear Programming,Daniel Bienstock;Gonzalo Mu√±oz;Sebastian Pokutta,dano@columbia.edu;gonzalo.munoz@polymtl.ca;sebastian.pokutta@isye.gatech.edu,6;6;8,4;3;3,Reject,0,9,0.0,yes,9/27/18,Columbia University;Polytechnique Montreal;Georgia Institute of Technology,deep learning theory;neural network training;empirical risk minimization;non-convex optimization;treewidth,21;285;13,14;-1;33,-1;-1,usa,usa,y,8
2101,ICLR,2019,The Importance of Norm Regularization in Linear Graph Embedding: Theoretical Analysis and Empirical Demonstration,Yihan Gao;Chao Zhang;Jian Peng;Aditya Parameswaran,gaoyihan@gmail.com;czhang82@illinois.edu;jianpeng@illinois.edu;adityagp@illinois.edu,7;4;4,3;3;4,Reject,0,5,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Graph Embedding;Generalization Analysis;Matrix Factorization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,y,1;10
2102,ICLR,2019,Learning to Decompose Compound Questions with Reinforcement Learning,Haihong Yang;Han Wang;Shuang Guo;Wei Zhang;Huajun Chen,capriceyhh@zju.edu.cn;wanghanwh@zju.edu.cn;guoshuang@zju.edu.cn;lantau.zw@alibaba-inc.com;huajunsir@zju.edu.cn,6;5;5,5;3;4,Reject,0,4,0.0,yes,9/27/18,Zhejiang University;Zhejiang University;Zhejiang University;Alibaba Group;Zhejiang University,Compound Question Decomposition;Reinforcement Learning;Knowledge-Based Question Answering;Learning-to-decompose,36;36;36;-1;36,177;177;177;-1;177,-1;-1,asia,cn,n,10
2103,ICLR,2019,Dimension-Free Bounds for Low-Precision Training,Zheng Li;Christopher De Sa,lzlz19971997@gmail.com;cdesa@cs.cornell.edu,6;6;6,3;4;3,Reject,0,4,0.0,yes,9/27/18,Tsinghua University;Cornell University,low precision;stochastic gradient descent,-1;6,-1;19,-1;-1,usa,usa,y,1;9
2104,ICLR,2019,Hint-based Training for Non-Autoregressive Translation,Zhuohan Li;Di He;Fei Tian;Tao Qin;Liwei Wang;Tie-Yan Liu,lizhuohan@pku.edu.cn;dihe@microsoft.com;fetia@microsoft.com;taoqin@microsoft.com;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,6;6;4,4;3;4,Reject,0,8,0.0,yes,9/27/18,Peking University;Microsoft;Microsoft;Microsoft;Peking University;Microsoft,Natural Language Processing;Machine Translation;Non-Autoregressive Model,14;-1;-1;-1;14;-1,27;-1;-1;-1;27;-1,-1;-1,NAN,NAN,n,3
2105,ICLR,2019,Convergence Guarantees for RMSProp and ADAM in Non-Convex Optimization and an Empirical Comparison to Nesterov Acceleration,Soham De;Anirbit Mukherjee;Enayat Ullah,sohamde@cs.umd.edu;amukhe14@jhu.edu;enayat@jhu.edu,5;4;5,3;5;4,Reject,0,7,0.0,yes,9/27/18,"University of Maryland, College Park;Johns Hopkins University;Johns Hopkins University",adaptive gradient descent;deeplearning;ADAM;RMSProp;autoencoders,12;67;67,69;13;13,-1;-1,usa,usa,y,1
2106,ICLR,2019,Globally Soft Filter Pruning For Efficient Convolutional Neural Networks,Ke Xu;Xiaoyun Wang;Qun Jia;Jianjing An;Dong Wang,17112071@bjtu.edu.cn;16120304@bjtu.edu.cn;16120347@bjtu.edu.cn;16112065@bjtu.edu.cn;wangdong@bjtu.edu.cn,6;5;4,4;4;3,Reject,0,5,0.0,yes,9/27/18,Beijing Jiaotong University;Beijing Jiaotong University;Beijing Jiaotong University;Beijing Jiaotong University;Beijing Jiaotong University,Filter Pruning;Model Compression;Efficient Convolutional Neural Networks,-1;-1;-1;-1;-1,854;854;854;854;854,-1;-1,NAN,NAN,n,
2107,ICLR,2019,Quantization for Rapid Deployment of Deep Neural Networks,Jun Haeng Lee;Sangwon Ha;Saerom Choi;Won-Jo Lee;Seungwon Lee,junhaeng2.lee@samsung.com;sw815.ha@samsung.com;sincere.choi@samsung.com;w-j.lee@samsung.com;seungw.lee@samsung.com,5;5;5,3;4;4,Reject,0,5,0.0,yes,9/27/18,Samsung;Samsung;Samsung;Samsung;Samsung,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;1
2108,ICLR,2019,Discovering Low-Precision Networks Close to Full-Precision Networks for Efficient Embedded Inference,Jeffrey L. McKinstry;Steven K. Esser;Rathinakumar Appuswamy;Deepika Bablani;John V. Arthur;Izzet B. Yildiz;Dharmendra S. Modha,jlmckins@us.ibm.com;sesser@us.ibm.com;rappusw@us.ibm.com;deepika.bablani@ibm.com;arthurjo@us.ibm.com;izzet.burak.yildiz@gmail.com;dmodha@us.ibm.com,4;6;5,5;3;4,Reject,0,6,1.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;;International Business Machines,Deep Learning;Convolutional Neural Networks;Low-precision inference;Network quantization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2109,ICLR,2019,Can I trust you more? Model-Agnostic Hierarchical Explanations,Michael Tsang;Youbang Sun;Dongxu Ren;Beibei Xin;Yan Liu,tsangm@usc.edu;syb98@mail.ustc.edu.cn;rdx15@mails.tsinghua.edu.cn;bxin@usc.edu;yanliu.cs@usc.edu,5;6;6,4;4;4,Reject,0,9,0.0,yes,9/27/18,"University of Southern California;University of Science and Technology of China;Tsinghua University, Tsinghua University;University of Southern California;University of Southern California",interpretability;interactions;context-dependent;context-free,27;-1;4;27;27,66;132;30;66;66,-1;-1,usa,usa,n,
2110,ICLR,2019,Towards a better understanding of Vector Quantized Autoencoders,Aurko Roy;Ashish Vaswani;Niki Parmar;Arvind Neelakantan,aurkor@google.com;avaswani@google.com;nikip@google.com;aneelakantan@google.com,6;7;5;3,3;4;4;4,Reject,0,13,0.0,yes,9/27/18,Google;Google;Google;Google,machine translation;vector quantized autoencoders;non-autoregressive;NMT,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3;5
2111,ICLR,2019,Human-Guided Column Networks: Augmenting Deep Learning with Advice,Mayukh Das;Yang Yu;Devendra Singh Dhami;Gautam Kunapuli;Sriraam Natarajan,mayukh.das1@utdallas.edu;yangyu@hlt.utdallas.edu;devendra.dhami@utdallas.edu;gautam.kunapuli@utdallas.edu;sriraam.natarajan@utdallas.edu,6;4;5,3;4;5,Reject,0,3,0.0,yes,9/27/18,"University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas",Knowledge-guided learning;Human advice;Column Networks;Knowledge-based relational deep model;Collective classification,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,n,
2112,ICLR,2019,Weakly-supervised Knowledge Graph Alignment with Adversarial Learning,Meng Qu;Jian Tang;Yoshua Bengio,qumn123@gmail.com;tangjianpku@gmail.com;yoshua.bengio@mila.quebec,5;5;5,3;4;3,Reject,2,0,0.0,yes,9/25/19,University of Montreal;HEC Montreal;Mila,Knowledge Graph Alignment;Generative Adversarial Network;Weakly Supervised,116;-1;136,108;-1;314,m;m,NAN,NAN,n,1;10;4
2113,ICLR,2019,RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding,Danushka Bollegala;Huda Hakami;Yuichi Yoshida;Ken-ichi Kawarabayashi,danushka@liverpool.ac.uk;h.a.hakami@liverpool.ac.uk;yyoshida@nii.ac.jp;k_keniti@nii.ac.jp,6;5;4,4;5;4,Reject,10,5,0.0,yes,9/27/18,University of Liverpool;University of Liverpool;National Institute of Informatics;National Institute of Informatics,relation representations;natural language processing;theoretical analysis;knowledge graphs,116;116;-1;-1,177;177;-1;-1,-1;-1,NAN,NAN,y,3;10;1;5
2114,ICLR,2019,Riemannian TransE: Multi-relational Graph Embedding in Non-Euclidean Space,Atsushi Suzuki;Yosuke Enokida;Kenji Yamanishi,atsushi-suzuki@g.ecc.u-tokyo.ac.jp;xenolay@g.ecc.u-tokyo.ac.jp;yamanishi@mist.i.u-tokyo.ac.jp,5;5;5,2;5;3,Reject,4,3,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo;The University of Tokyo,Riemannian TransE;graph embedding;multi-relational graph;Riemannian manifold;TransE;hyperbolic space;sphere;knowledge base,59;59;59,45;45;45,-1;-1,NAN,NAN,n,10
2115,ICLR,2019,Why Do Neural Response Generation Models Prefer Universal Replies?,Bowen Wu;Nan Jiang;Zhifeng Gao;Zongsheng Wang;Suke Li;Wenge Rong;Baoxun Wang,jasonwbw@yahoo.com;nanjiang@buaa.edu.cn;gao_zhifeng@pku.edu.cn;jasonwang0512@gmail.com;lisuke@ss.pku.edu.cn;w.rong@buaa.edu.cn;baoxun.wang@gmail.com,3;7;1,4;3;5,Reject,2,10,1.0,yes,9/27/18,Tencent AI Lab;Beihang University;Peking University;;Peking University;Beihang University;Tencent AI Lab,Neural Response Generation;Universal Replies;Optimization Goal Analysis;Max-Marginal Ranking Regularization,-1;94;14;-1;14;94;-1,-1;658;27;-1;27;658;-1,-1;-1,NAN,NAN,y,5
2116,ICLR,2019,CGNF: Conditional Graph Neural Fields,Tengfei Ma;Cao Xiao;Junyuan Shang;Jimeng Sun,tengfei.ma1@ibm.com;cxiao@us.ibm.com;sjy1203@pku.edu.cn;jsun@cc.gatech.edu,4;5;5,5;4;5,Reject,0,4,0.0,yes,9/27/18,International Business Machines;International Business Machines;Peking University;Georgia Institute of Technology,graph neural networks;energy models;conditional random fields;label correlation,-1;-1;14;13,-1;-1;27;33,-1;-1,usa,usa,n,10
2117,ICLR,2019,Few-shot Classification on Graphs with Structural Regularized GCNs,Shengzhong Zhang;Ziang Zhou;Zengfeng Huang;Zhongyu Wei,17210980007@fudan.edu.cn;15300180085@fudan.edu.cn;huangzf@fudan.edu.cn;zywei@fudan.edu.cn,4;6;5,4;3;4,Reject,0,5,0.0,yes,9/27/18,Fudan University;Fudan University;Fudan University;Fudan University,Graph Convolutional Networks;Few-shot;Classification,67;67;67;67,116;116;116;116,-1;-1,asia,cn,y,6;1;10
2118,ICLR,2019,Optimization on Multiple Manifolds,Mingyang Yi;Huishuai Zhang;Wei Chen;Zhi-ming Ma;Tie-yan Liu,yimingyang17@mails.ucas.edu.cn;huishuai.zhang@microsoft.com;wche@microsoft.com;mazm@amt.ac.cn;tie-yan.liu@mircosoft.com,7;1;3,3;5;4,Reject,2,0,0.0,yes,9/27/18,University of Chinese Academy of Sciences;Microsoft;Microsoft;Chinese Academy of Sciences;Mircosoft,Optimization;Multiple constraints;Manifold,31;-1;-1;31;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
2119,ICLR,2019,On the Selection of Initialization and Activation Function for Deep Neural Networks,Soufiane Hayou;Arnaud Doucet;Judith Rousseau,soufiane.hayou@stats.ox.ac.uk;doucet@stats.ox.ac.uk;judith.rousseau@stats.ox.ac.uk,3;4;5,5;4;4,Reject,0,13,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,Deep Neural Networks;Initialization;Gaussian Processes,44;44;44,1;1;1,-1;-1,europe,uk,y,
2120,ICLR,2019,Online Learning for Supervised Dimension Reduction,Ning Zhang;Qiang Wu,ningzhang0123@gmail.com;qwu@mtsu.edu,2;5;6,5;4;5,Reject,0,0,0.0,yes,9/27/18, Middle Tennessee State University;SUN YAT-SEN UNIVERSITY,Online Learning;Supervised Dimension Reduction;Incremental Sliced Inverse Regression;Effective Dimension Reduction Space,-1;-1,-1;352,-1;-1,NAN,NAN,n,8
2121,ICLR,2019,Accelerated Sparse Recovery Under Structured Measurements,Ke Li;Jitendra Malik,ke.li@eecs.berkeley.edu;malik@eecs.berkeley.edu,4;5;5,5;3;4,Reject,0,0,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley,sparse recovery,-1;-1,18;18,-1;-1,usa,usa,n,
2122,ICLR,2019,The Cakewalk Method,Uri Patish;Shimon Ullman,uri.patish@gmail.com;shimon.ullman@gmail.com,5;4;4,3;4;4,Reject,0,6,0.0,yes,9/27/18,Weizmann Institute;Weizmann Institute,policy gradient;combinatorial optimization;blackbox optimization;stochastic optimization;reinforcement learning,116;-1,-1;-1,-1;-1,asia,in,n,10
2123,ICLR,2019,A fast quasi-Newton-type method for large-scale stochastic optimisation,Adrian Wills;Thomas B. Sch√∂n;Carl Jidling,adrian.wills@newcastle.edu.au;thomas.schon@it.uu.se;carl.jidling@it.uu.se,4;5;5,4;5;5,Reject,0,6,0.0,yes,9/27/18,"University of Newcastle, Australia;Uppsala University;Uppsala University",optimisation;large-scale;stochastic,285;169;169,291;86;86,-1;-1,europe,se,n,
2124,ICLR,2019,Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior,Reinhard Heckel;Wen Huang;Paul Hand;Vladislav Voroninski,rh43@rice.edu;wen.huang@xmu.edu.cn;p.hand@northeastern.edu;vlad@helm.ai,5;6;6,3;3;4,Reject,0,3,0.0,yes,9/27/18,Rice University;Xiamen University;Northeastern University;Helm.ai,non-convex optimization;denoising;generative neural network,94;-1;15;-1,86;490;839;-1,-1;-1,NAN,NAN,y,1;5
2125,ICLR,2019,Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes,Mahsa Ghasemi;Ufuk Topcu,mahsa.ghasemi@utexas.edu;utopcu@utexas.edu,6;4;7,4;4;2,Reject,0,3,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",partially observable Markov decision processes;active perception;submodular optimization;point-based value iteration;reinforcement learning,-1;-1,-1;-1,-1;-1,usa,usa,y,
2126,ICLR,2019,Towards Consistent Performance on Atari using Expert Demonstrations,Tobias Pohlen;Bilal Piot;Todd Hester;Mohammad Gheshlaghi Azar;Dan Horgan;David Budden;Gabriel Barth-Maron;Hado van Hasselt;John Quan;Mel Veƒçer√≠k;Matteo Hessel;R√©mi Munos;Olivier Pietquin,pohlen@google.com;piot@google.com;toddhester@google.com;mazar@google.com;horgan@google.com;budden@google.com;gabrielbm@google.com;hado@google.com;johnquan@google.com;vec@google.com;mtthss@google.com;munos@google.com;pietquin@google.com,6;5;7;7,4;4;1;4,Reject,0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Reinforcement Learning;Atari;RL;Demonstrations,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2127,ICLR,2019,Manifold Alignment via Feature Correspondence,Jay S. Stanley III;Guy Wolf;Smita Krishnaswamy,jay.stanley@yale.edu;guy.wolf@yale.edu;smita.krishnaswamy@yale.edu,5;5;4,4;4;3,Reject,0,0,0.0,yes,9/27/18,Yale University;Yale University;Yale University,graph signal processing;graph alignment;manifold alignment;spectral graph wavelet transform;diffusion geometry;harmonic analysis,67;67;67,12;12;12,-1;-1,europe,fi,y,10
2128,ICLR,2019,Consistent Jumpy Predictions for Videos and Scenes,Ananya Kumar;S. M. Ali Eslami;Danilo Rezende;Marta Garnelo;Fabio Viola;Edward Lockhart;Murray Shanahan,skywalker94@gmail.com;aeslami@google.com;danilor@google.com;garnelo@google.com;fviola@google.com;locked@google.com;mshanahan@google.com,7;4;5,2;4;4,Reject,0,7,0.0,yes,9/27/18,Stanford University;Google;Google;Google;Google;Google;Google,jumpy predictions;generative models;scene reconstruction;video prediction;variational auto-encoders;DRAW,4;-1;-1;-1;-1;-1;-1,3;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2129,ICLR,2019,LEARNING ADVERSARIAL EXAMPLES WITH RIEMANNIAN GEOMETRY,Shufei Zhang;Kaizhu Huang;Rui Zhang;Amir Hussain,shufei.zhang@xjtlu.edu.cn;kaizhu.huang@xjtlu.edu.cn;rui.zhang02@xjtlu.edu.cn;ahu@cs.stir.ac.uk,6;4;3,2;5;5,Reject,0,15,0.0,yes,9/27/18,Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University;University of Stirling,Adversarial training;Adversarial examples;Riemannian Geometry;Machine Learning;Deep Learning,-1;-1;-1;-1,-1;-1;-1;309,-1;-1,NAN,NAN,y,8;1;4
2130,ICLR,2019,"On Tighter Generalization Bounds for Deep Neural Networks: CNNs, ResNets, and Beyond",Xingguo Li;Junwei Lu;Zhaoran Wang;Jarvis Haupt;Tuo Zhao,xingguol@princeton.edu;junweilu@hsph.harvard.edu;zhaoranwang@gmail.com;jdhaupt@umn.edu;tourzhao@gatech.edu,7;7;5,4;4;3,Reject,0,22,0.0,yes,9/27/18,"Princeton University;Harvard University;Northwestern University;University of Minnesota, Minneapolis;Georgia Institute of Technology",deep learning;generalization error bound;convolutional neural networks,31;50;50;67;13,7;6;20;56;33,-1;-1,usa,usa,y,1
2131,ICLR,2019,DEEP GEOMETRICAL GRAPH CLASSIFICATION,Mostafa Rahmani;Ping Li,rahmani.sut@gmail.com;pingli98@gmail.com,6;4;3,5;4;4,Reject,0,6,0.0,yes,9/27/18,Amazon;Accel,Graph classification;Deep Learning;Graph pooling;Embedding,-1;-1,-1;-1,m;m,asia,in,n,10
2132,ICLR,2019,Hierarchically Clustered Representation Learning,Su-Jin Shin;Kyungwoo Song;Il-Chul Moon,sujin.shin@kaist.ac.kr;gtshs2@kaist.ac.kr;icmoon@kaist.ac.kr,5;5;6,4;4;3,Reject,0,4,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Representation learning;Hierarchical clustering;Nonparametric Bayesian modeling,-1;-1;-1,95;95;95,-1;-1,NAN,NAN,n,11;5
2133,ICLR,2019,A Deep Learning Approach for Dynamic Survival Analysis with Competing Risks,Changhee Lee;Mihaela van der Schaar,chl8856@gmail.com;mihaela@ee.ucla.edu,4;4;8,3;4;4,Reject,0,5,0.0,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles",dynamic survival analysis;survival analysis;longitudinal measurements;competing risks,-1;-1,-1;15,-1;-1,usa,usa,n,
2134,ICLR,2019,Locally Linear Unsupervised Feature Selection,Guillaume DOQUET;Mich√®le SEBAG,doquet@lri.fr;sebag@lri.fr,4;6;3,5;2;5,Reject,2,3,0.0,yes,9/27/18,"CNRS, Universit√© Paris-Saclay;CNRS, Universit√© Paris-Saclay",Unsupervised Learning;Feature Selection;Dimension Reduction,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2135,ICLR,2019,Scalable Neural Theorem Proving on Knowledge Bases and Natural Language,Pasquale Minervini;Matko Bosnjak;Tim Rockt√§schel;Edward Grefenstette;Sebastian Riedel,p.minervini@gmail.com;matko.bosnjak@gmail.com;tim.rocktaeschel@gmail.com;etg@google.com;etg@google.com,5;4;5,3;3;3,Reject,0,13,0.0,yes,9/27/18,University College London;DeepMind;Facebook AI Research;Google;Google,Machine Reading;Natural Language Processing;Neural Theorem Proving;Representation Learning;First Order Logic,50;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;1
2136,ICLR,2019,A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks,Jinghui Chen;Jinfeng Yi;Quanquan Gu,jc4zg@virginia.edu;yijinfeng@jd.com;qgu@cs.ucla.edu,5;7;5,4;4;4,Reject,2,12,0.0,yes,9/27/18,"University of Virginia;JD AI Research;University of California, Los Angeles",,59;-1;-1,113;-1;15,-1;-1,usa,usa,y,1;9;4
2137,ICLR,2019,ACTRCE: Augmenting Experience via Teacher‚Äôs Advice,Yuhuai Wu;Harris Chan;Jamie Kiros;Sanja Fidler;Jimmy Ba,ywu@cs.toronto.edu;hchan@cs.toronto.edu;kirosjamie@gmail.com;fidler@cs.toronto.edu;jba@cs.toronto.edu,5;5;7,4;4;5,Reject,0,14,0.0,yes,9/27/18,University of Toronto;University of Toronto;Google;University of Toronto;University of Toronto,language goals;task generalization;hindsight experience replays;language grounding,18;18;-1;18;18,22;22;-1;22;22,-1;-1,canada,ca,n,3
2138,ICLR,2019,Learning data-derived privacy preserving representations from information metrics,Martin Bertran;Natalia Martinez;Afroditi Papadaki;Qiang Qiu;Miguel Rodrigues;Guillermo Sapiro,martin.bertran@duke.edu;natalia.martinez@duke.edu;a.papadaki.17@ucl.ac.uk;qiuqiang@gmail.com;m.rodrigues@ucl.ac.uk;guillermo.sapiro@duke.edu,6;6;5,3;4;4,Reject,0,6,0.0,yes,9/27/18,Duke University;Duke University;University College London;;University College London;Duke University,Machine learning;privacy;adversarial training;information theory;data-driven privacy,47;47;50;-1;50;47,17;17;-1;-1;-1;17,-1;-1,europe,se,n,2;1;7
2139,ICLR,2019,Probabilistic Federated Neural Matching,Mikhail Yurochkin;Mayank Agarwal;Soumya Ghosh;Kristjan Greenewald;Nghia Hoang;Yasaman Khazaeni,mikhail.yurochkin@ibm.com;mayank.agarwal@ibm.com;ghoshso@us.ibm.com;kristjan.h.greenewald@ibm.com;nghiaht@ibm.com;yasaman.khazaeni@us.ibm.com,4;6;6,3;4;4,Reject,0,4,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,Bayesian nonparametrics;Indian Buffet Process;Federated Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,11
2140,ICLR,2019,Learning to Refer to 3D Objects with Natural Language,Panos Achlioptas;Judy E. Fan;Robert X.D. Hawkins;Noah D. Goodman;Leo Guibas,optas@cs.stanford.edu;jefan@stanford.edu;rxdh@stanford.edu;ngoodman@stanford.edu;guibas@cs.stanford.edu,6;4;6,4;4;3,Reject,0,0,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Referential Language;3D Objects;Part-Awareness;Neural Speakers;Neural Listeners,4;4;4;4;4,3;3;3;3;3,-1;-1,usa,usa,n,1
2141,ICLR,2019,Monge-Amp\`ere Flow for Generative Modeling,Linfeng Zhang;Weinan E;Lei Wang,linfengz@princeton.edu;weinan@math.princeton.edu;wanglei@iphy.ac.cn,6;6;7,4;3;3,Reject,0,10,2.0,yes,9/27/18,Princeton University;Princeton University;Chinese Academy of Sciences,generative modeling;Monge-Amp\`ere equation;dynamical system;optimal transport;density estimation;free energy calculation,31;31;31,7;7;-1,-1;-1,asia,cn,n,1;5
2142,ICLR,2019,Negotiating Team Formation Using Deep Reinforcement Learning,Yoram Bachrach;Richard Everett;Edward Hughes;Angeliki Lazaridou;Joel Leibo;Marc Lanctot;Mike Johanson;Wojtek Czarnecki;Thore Graepel,yorambac@google.com;reverett@google.com;edwardhughes@google.com;jzl@google.com;angeliki@google.com;lanctot@google.com;mjohanson@google.com;lejlot@google.com;thore@google.com,5;6;5,3;2;3,Reject,0,8,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google,Reinforcement Learning;Negotiation;Team Formation;Cooperative Game Theory;Shapley Value,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2143,ICLR,2019,Why do deep convolutional networks generalize so poorly to small image transformations?,Aharon Azulay;Yair Weiss,aharon.azulay@mail.huji.ac.il;yweiss@cs.huji.ac.il,7;7;5,5;4;4,Reject,0,8,1.0,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem,Convolutional neural networks;The sampling theorem;Sensitivity to small image transformations;Dataset bias;Shiftability,77;77,205;205,-1;-1,europe,il,n,1
2144,ICLR,2019,Psychophysical vs. learnt texture representations in novelty detection,Michael Grunwald;Matthias Hermann;Fabian Freiberg;Matthias O. Franz,m.grunwald@htwg-konstanz.de;matthias.hermann@htwg-konstanz.de;f.freiberg@htwg-konstanz.de;mfanz@htwg-konstanz.de,3;3;3;1,3;3;4;3,Reject,0,0,0.0,yes,9/27/18,University of Utah;;;Institut für Optische Sensorsysteme,novelty detection;learnt texture representation;one-class neural network;human-vision-inspired anomaly detection,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,
2145,ICLR,2019,A fully automated periodicity detection in time series,Tom Puech;Matthieu Boussard,tom.puech@craft.ai;matthieu.boussard@craft.ai,3;5;3,3;2;2,Reject,0,0,0.0,yes,9/27/18,Intelligence artificielle pour Orange;Alcatel-Lucent Bell Labs,Time series;feature engineering;period detection;machine learning,-1;-1,-1;-1,-1;-1,asia,in,n,
2146,ICLR,2019,Downsampling leads to Image Memorization in Convolutional Autoencoders,Adityanarayanan Radhakrishnan;Caroline Uhler;Mikhail Belkin,aradha@mit.edu;cuhler@mit.edu;mbelkin@cse.ohio-state.edu,3;5;5,3;2;2,Reject,0,4,0.0,yes,9/27/18,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California, San Diego",Memorization in Deep Learning;Convolutional Autoencoders,6;6;-1,5;5;31,-1;-1,usa,usa,n,
2147,ICLR,2019,CDeepEx: Contrastive Deep Explanations,Amir Feghahati;Christian R. Shelton;Michael J. Pazzani;Kevin Tang,sfegh001@ucr.edu;cshelton@cs.ucr.edu;pazzani@ucr.edu;ktang012@ucr.edu,5;5;6,4;4;5,Reject,0,13,0.0,yes,9/27/18,"University of California, Riverside;University of California, Riverside;University of California, Riverside;University of California, Riverside",Deep learning;Explanation;Network interpretation;Contrastive explanation,-1;-1;-1;-1,197;197;197;197,-1;-1,usa,usa,n,2
2148,ICLR,2019,Pooling Is Neither Necessary nor Sufficient for Appropriate Deformation Stability in CNNs,Avraham Ruderman;Neil C. Rabinowitz;Ari S. Morcos;Daniel Zoran,aruderman@google.com;ncr@google.com;arimorcos@gmail.com;danielzoran@google.com,5;5;4;5,5;2;4;2,Reject,0,4,0.0,yes,9/27/18,Google;Google;Facebook;Google,Convolutional Neural Networks;Deformation Stability;Pooling;Transformation Invariance,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2149,ICLR,2019,Meta-Learning to Guide Segmentation,Kate Rakelly*;Evan Shelhamer*;Trevor Darrell;Alexei A. Efros;Sergey Levine,rakelly@eecs.berkeley.edu;shelhamer@cs.berkeley.edu;trevor@eecs.berkeley.edu;efros@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,7;3;3,4;4;5,Reject,0,5,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,meta-learning;few-shot learning;visual segmentation,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,6;2;1
2150,ICLR,2019,A theoretical framework for deep and locally connected ReLU network,Yuandong Tian,yuandong@fb.com,5;3;7,3;4;4,Reject,2,5,0.0,yes,9/27/18,Facebook,theoretical analysis;deep network;optimization;disentangled representation,-1,-1,-1,NAN,NAN,y,10
2151,ICLR,2019,FAST OBJECT LOCALIZATION VIA SENSITIVITY ANALYSIS,Mohammad K. Ebrahimpour;David C. Noelle,mebrahimpour@ucmerced.edu;dnoelle@ucmerced.edu,4;3;6,3;4;5,Reject,0,1,0.0,yes,9/27/18,University of California at Merced;University of California at Merced,Internal Representations;Sensitivity Analysis;Object Detection,-1;-1,-1;-1,-1;-1,usa,usa,n,
2152,ICLR,2019,Generative Feature Matching Networks,Cicero Nogueira dos Santos;Inkit Padhi;Pierre Dognin;Youssef Mroueh,cicerons@us.ibm.com;inkit.padhi@ibm.com;pdognin@us.ibm.com;mroueh@us.ibm.com,6;6;6;6,3;4;3;3,Reject,0,23,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines,Generative Deep Neural Networks;Feature Matching;Maximum Mean Discrepancy;Generative Adversarial Networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2153,ICLR,2019,Generative Adversarial Models for Learning Private and Fair Representations,Chong Huang;Xiao Chen;Peter Kairouz;Lalitha Sankar;Ram Rajagopal,chuang83@asu.edu;markcx@stanford.edu;kairouzp@stanford.edu;lsankar@asu.edu;ramr@stanford.edu,4;4;7,3;3;3,Reject,0,8,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;Stanford University;Stanford University;SUN YAT-SEN UNIVERSITY;Stanford University,Data Privacy;Fairness;Adversarial Learning;Generative Adversarial Networks;Minimax Games;Information Theory,-1;4;4;-1;4,352;3;3;352;3,-1;-1,usa,usa,y,7;5;4
2154,ICLR,2019,Understanding & Generalizing AlphaGo Zero,Ravichandra Addanki;Mohammad Alizadeh;Shaileshh Bojja Venkatakrishnan;Devavrat Shah;Qiaomin Xie;Zhi Xu,addanki@mit.edu;alizadeh@csail.mit.edu;bjjvnkt@csail.mit.edu;devavrat@mit.edu;qxie@mit.edu;zhixu@mit.edu,5;5;7,3;5;4,Reject,0,3,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,reinforcement learning;AlphaGo Zero,6;6;6;6;6;6,5;5;5;5;5;5,-1;-1,usa,usa,y,1
2155,ICLR,2019,Link Prediction in Hypergraphs using Graph Convolutional Networks,Naganand Yadati;Vikram Nitin;Madhav Nimishakavi;Prateek Yadav;Anand Louis;Partha Talukdar,y.naganand@gmail.com;vikramnitin9@gmail.com;madhav@iisc.ac.in;prateekyadav@iisc.ac.in;anandl@iisc.ac.in;ppt@iisc.ac.in,6;5;4,2;4;5,Reject,0,9,0.0,yes,9/27/18,Indian Institute of Science;Columbia University;Indian Institute of Science;Indian Institute of Science;Indian Institute of Science;Indian Institute of Science,Graph convolution;hypergraph;hyperlink prediction,-1;21;-1;-1;-1;-1,-1;14;273;273;273;273,-1;-1,NAN,NAN,n,10
2156,ICLR,2019,RedSync : Reducing Synchronization Traffic for Distributed Deep Learning,Jiarui Fang;Cho-Jui Hsieh,fang_jiarui@163.com;rainfarmer@gmail.com,5;5;5,3;4;4,Reject,2,5,0.0,yes,9/27/18,"Tencent;University of California, Los Angeles",Data parallel;Deep Learning;Multiple GPU system;Communication Compression;Sparsification;Quantization,-1;-1,-1;-1,-1;-1,asia,in,n,8;3
2157,ICLR,2019,PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS,Yanwei Fu;Shun Zhang;Donghao Li;Xinwei Sun;Xiangyang Xue;Yuan Yao,yanweifu@fudan.edu.cn;15300180012@fudan.edu.cn;15307100013@fudan.edu.cn;sxwxiaoxiaohehe@pku.edu.cn;xyxue@fudan.edu.cn;yuany@ust.hk,5;5;4,4;4;5,Reject,0,0,0.0,yes,9/27/18,Fudan University;Fudan University;Fudan University;Peking University;Fudan University;The Hong Kong University of Science and Technology,Split LBI;sparse penalty;network pruning;feature selection,67;67;67;14;67;-1,116;116;116;27;116;44,-1;-1,NAN,NAN,n,
2158,ICLR,2019,Integral Pruning on Activations and Weights for Efficient Neural Networks,Qing Yang;Wei Wen;Zuoguan Wang;Yiran Chen;Hai Li,qing.yang21@duke.edu;wei.wen@duke.edu;zuoguan.wang@blacksesame.com;yiran.chen@duke.edu;hai.li@duke.edu,4;5;5,3;4;4,Reject,0,4,0.0,yes,9/27/18,Duke University;Duke University;Blacksesame;Duke University;Duke University,activation pruning;weight pruning;computation cost reduction;efficient DNNs,47;47;-1;47;47,17;17;-1;17;17,-1;-1,europe,se,n,
2159,ICLR,2019,Penetrating the Fog: the Path to Efficient CNN Models,Kun Wan;Boyuan Feng;Shu Yang;Yufei Ding,kun@cs.ucsb.edu;boyuan@cs.ucsb.edu;shuyang1995@ucsb.edu;yufeiding@cs.ucsb.edu,5;5;4,3;3;3,Reject,0,0,0.0,yes,9/27/18,UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara,Efficient CNN models;Computer Vision,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2160,ICLR,2019,ACIQ: Analytical Clipping for Integer Quantization of neural networks,Ron Banner;Yury Nahshan;Elad Hoffer;Daniel Soudry,ron.banner@intel.com;yury.nahshan@intel.com;daniel.soudry@gmail.com;elad.hoffer@gmail.com,4;4;5,5;4;4,Reject,3,5,0.0,yes,9/27/18,"Intel;Intel;Technion, Technion;Habana Labs (Intel)",quantization;reduced precision;training;inference;activation,-1;-1;27;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2161,ICLR,2019,PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION,Wei Gao;Yi Wei;Quanquan Li;Hongwei Qin;Wanli Ouyang;Junjie Yan,weigao1996@outlook.com;wei-y15@mails.tsinghua.edu.cn;liquanquan@sensetime.com;qinghongwei@sensetime.com;wanli.ouyang@sydney.edu.cn;yanjunjie@outlook.com,4;5;4,3;4;4,Reject,0,0,0.0,yes,9/27/18,"California Institute of Technology;Tsinghua University, Tsinghua University;SenseTime Group Limited;SenseTime Group Limited;University of Science and Technology of China;SenseTime Group Limited",model acceleration;mimic;knowledge distillation;channel pruning,-1;4;-1;-1;-1;-1,-1;30;-1;-1;132;-1,-1;-1,NAN,NAN,n,2;1
2162,ICLR,2019,Progressive Weight Pruning Of Deep Neural Networks Using ADMM,Shaokai Ye;Tianyun Zhang;Kaiqi Zhang;Jiayu Li;Kaidi Xu;Yunfei Yang;Fuxun Yu;Jian Tang;Makan Fardad;Sijia Liu;Xiang Chen;Xue Lin;Yanzhi Wang,sye106@syr.edu;tzhan120@syr.edu;kzhang17@syr.edu;jli221@syr.edu;xu.kaid@husky.neu.edu;yunfei.yang717@gmail.com;fyu@gmu.edu;jtang02@syr.edu;makan@syr.edu;sijia.liu@ibm.com;xchen26@gmu.edu;xue.lin@northeastern.edu;yanz.wang@northeastern.edu,5;5;4,4;3;4,Reject,0,3,0.0,yes,9/27/18,Syracuse University;Syracuse University;Syracuse University;Syracuse University;Northeastern University;;George Mason University;Syracuse University;Syracuse University;International Business Machines;George Mason University;Northeastern University;Northeastern University,deep learning;model compression;optimization;ADMM;weight pruning,207;207;207;207;15;-1;94;207;207;-1;94;15;15,275;275;275;275;839;-1;336;275;275;-1;336;839;839,-1;-1,usa,usa,n,9
2163,ICLR,2019,Understanding Opportunities for Efficiency in Single-image Super Resolution Networks,Royson Lee;Nic Lane;Marko Stankovic;Sourav Bhattacharya,rs@roysonlee.com;nicholas.d.lane@gmail.com;marko.stankovic996@gmail.com;bsourav@gmail.com,4;5;3,5;4;5,Reject,0,3,0.0,yes,9/27/18,"University of Cambridge;University of Oxford;;Indian Institute of Management, Calcutta",Super-Resolution;Resource-Efficiency,-1;44;-1;-1,-1;1;-1;-1,-1;-1,asia,in,n,
2164,ICLR,2019,Actor-Attention-Critic for Multi-Agent Reinforcement Learning,Shariq Iqbal;Fei Sha,shariqiqbal2810@gmail.com;feisha.work@gmail.com,7;6;4,3;3;4,Reject,2,3,0.0,yes,9/27/18,University of Southern California;University of Southern California,multi-agent;reinforcement learning;attention;actor-critic,27;-1,66;-1,-1;-1,asia,in,n,8;4
2165,ICLR,2019,On the Margin Theory of Feedforward Neural Networks,Colin Wei;Jason Lee;Qiang Liu;Tengyu Ma,colinwei@stanford.edu;jasonlee@marshall.usc.edu;lqiang@cs.texas.edu;tengyuma@cs.stanford.edu,6;7;5;5,4;3;4;4,Reject,2,16,0.0,yes,9/27/18,Stanford University;University of Southern California;;Stanford University,generalization theory;implicit regularization;generalization;over-parametrization;theory;deep learning theory;margin,4;27;-1;4,3;66;-1;3,-1;-1,usa,usa,y,1
2166,ICLR,2019,Are adversarial examples inevitable?,Ali Shafahi;W. Ronny Huang;Christoph Studer;Soheil Feizi;Tom Goldstein,ashafahi@gmail.com;w.ronny.huang@gmail.com;studer@cornell.edu;feizi.soheil@gmail.com;tomg@cs.umd.edu,6;7;8,4;4;4,Accept (Poster),3,12,2.0,yes,9/27/18,"Apple;Google;Cornell University;;University of Maryland, College Park",adversarial examples;neural networks;security,-1;-1;6;-1;12,-1;-1;19;-1;69,-1;-1,usa,usa,y,4
2167,ICLR,2019,Open Loop Hyperparameter Optimization and Determinantal Point Processes,Jesse Dodge;Kevin Jamieson;Noah Smith,jessed@cs.cmu.edu;jamieson@cs.washington.edu;nasmith@cs.washington.edu,5;5;6,3;5;4,Reject,0,3,0.0,yes,9/27/18,Carnegie Mellon University;University of Washington;University of Washington,hyperparameter optimization;black box optimization,1;10;10,24;25;25,-1;-1,usa,usa,n,
2168,ICLR,2019,Cross-Task Knowledge Transfer for Visually-Grounded Navigation,Devendra Singh Chaplot;Lisa Lee;Ruslan Salakhutdinov;Devi Parikh;Dhruv Batra,chaplot@cs.cmu.edu;lslee@cs.cmu.edu;rsalakhu@cs.cmu.edu;parikh@gatech.edu;dbatra@gatech.edu,7;5;5,4;3;5,Reject,0,5,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Georgia Institute of Technology;Georgia Institute of Technology,,1;1;1;13;13,24;24;24;33;33,-1;-1,usa,usa,n,6;8
2169,ICLR,2019,Expanding the Reach of Federated Learning by Reducing Client Resource Requirements,Sebastian Caldas;Jakub Koneƒçn√Ω;Brendan McMahan;Ameet Talwalkar,scaldas@cmu.edu;konkey@google.com;mcmahan@google.com;talwalkar@cmu.edu,4;5;5,5;3;4,Reject,0,6,0.0,yes,9/27/18,Carnegie Mellon University;Google;Google;Carnegie Mellon University,,1;-1;-1;1,24;-1;-1;24,-1;-1,usa,usa,y,
2170,ICLR,2019,Generative Adversarial Self-Imitation Learning,Junhyuk Oh;Yijie Guo;Satinder Singh;Honglak Lee,junhyuk@umich.edu;guoyijie@umich.edu;baveja@umich.edu;honglak@google.com,5;5;6,4;5;5,Reject,0,7,0.0,yes,9/27/18,University of Michigan;University of Michigan;University of Michigan;Google,,9;9;9;-1,21;21;21;-1,-1;-1,NAN,NAN,n,5;4
2171,ICLR,2019,Diverse Machine Translation with a Single Multinomial Latent Variable,Tianxiao Shen;Myle Ott;Michael Auli;Marc‚ÄôAurelio Ranzato,tianxiao@mit.edu;myleott@fb.com;michaelauli@fb.com;ranzato@fb.com,3;6;5;7,4;4;4;4,Reject,0,6,0.0,yes,9/27/18,Massachusetts Institute of Technology;Facebook;Facebook;Facebook,machine translation;latent variable models;diverse decoding,6;-1;-1;-1,5;-1;-1;-1,-1;-1,NAN,NAN,n,
2172,ICLR,2019,Learning and Planning with a Semantic Model,Yi Wu;Yuxin Wu;Aviv Tamar;Stuart Russell;Georgia Gkioxari;Yuandong Tian,jxwuyi@gmail.com;yuxinwu@fb.com;avivt@berkeley.edu;russell@cs.berkeley.edu;gkioxari@fb.com;yuandong@fb.com,5;4;7,4;4;3,Reject,0,6,0.0,yes,9/27/18,"Tsinghua University, Tsinghua University;Facebook;University of California Berkeley;University of California Berkeley;Facebook;Facebook",deep reinforcement learning;generalization;semantic structure;model-based,4;-1;-1;-1;-1;-1,30;-1;18;18;-1;-1,-1;-1,NAN,NAN,n,11;1
2173,ICLR,2019,Visual Imitation with a Minimal Adversary,Scott Reed;Yusuf Aytar;Ziyu Wang;Tom Paine;A√§ron van den Oord;Tobias Pfaff;Sergio Gomez;Alexander Novikov;David Budden;Oriol Vinyals,reedscot@google.com;yusufaytar@google.com;ziyu@google.com;tpaine@google.com;avdnoord@google.com;tpfaff@google.com;sergomez@google.com;anovikov@google.com;budden@google.com;vinyals@google.com,5;3;6,4;3;4,Reject,0,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,imitation;from pixels;adversarial,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2174,ICLR,2019,One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL,Tom Le Paine;Sergio Gomez;Ziyu Wang;Scott Reed;Yusuf Aytar;Tobias Pfaff;Matt Hoffman;Gabriel Barth-Maron;Serkan Cabi;David Budden;Nando de Freitas,tpaine@google.com;sergomez@google.com;ziyu@google.com;reedscot@google.com;yusufaytar@google.com;tpfaff@google.com;mwhoffman@google.com;gabrielbm@google.com;cabi@google.com;budden@google.com;nandodefreitas@google.com,4;4;5;5,4;4;3;3,Reject,0,10,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Imitation Learning;Deep Learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2175,ICLR,2019,Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search,Bichen Wu;Yanghan Wang;Peizhao Zhang;Yuandong Tian;Peter Vajda;Kurt Keutzer,bichen@berkeley.edu;yanghan@instagram.com;stzpz@fb.com;yuandong@fb.com;vajdap@fb.com,5;7;6;6,5;3;3;3,Reject,0,21,0.0,yes,9/27/18,University of California Berkeley;Instagram;Facebook;Facebook;Facebook,Neural Net Quantization;Neural Architecture Search,-1;-1;-1;-1;-1,18;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2176,ICLR,2019,Language Modeling with Graph Temporal Convolutional Networks,Hongyin Luo;Yichen Li;Jie Fu;James Glass,hyluo@mit.edu;yl3506@nyu.edu;jie.fu@polymtl.ca;glass@mit.edu,4;4;4,5;3;5,Reject,0,3,0.0,yes,9/27/18,Massachusetts Institute of Technology;New York University;Polytechnique Montreal;Massachusetts Institute of Technology,Graph Neural Network;Language Modeling;Convolution,6;24;285;6,5;27;-1;5,-1;-1,usa,usa,n,3;10
2177,ICLR,2019,Lipschitz regularized Deep Neural Networks generalize,Adam M. Oberman;Jeff Calder,adam.oberman@mcgill.ca;jcalder@umn.edu,4;6;7,3;2;4,Reject,0,12,1.0,yes,9/27/18,"McGill University;University of Minnesota, Minneapolis",Deep Neural Networks;Regularization;Generalization;Convergence;Lipschitz;Stability,94;67,42;56,-1;-1,NAN,NAN,y,1;9
2178,ICLR,2019,Count-Based Exploration with the Successor Representation,Marlos C. Machado;Marc G. Bellemare;Michael Bowling,machado@ualberta.ca;bellemare@google.com;mbowling@ualberta.ca,5;5;4,4;2;3,Reject,0,7,0.0,yes,9/27/18,University of Alberta;Google;University of Alberta,reinforcement learning;successor representation;exploration;atari,94;-1;94,119;-1;119,-1;-1,canada,ca,y,1;10
2179,ICLR,2019,Precision Highway for Ultra Low-precision Quantization,Eunhyeok Park;Dongyoung Kim;Sungjoo Yoo;Peter Vajda,canusglow@gmail.com;dongyoungkim42@gmail.com;sungjoo.yoo@gmail.com;vajdap@fb.com,6;7;5,5;4;3,Reject,0,9,0.0,yes,9/27/18,POSTECH;;;Facebook,neural network;quantization;optimization;low-precision;convolutional network;recurrent network,136;-1;-1;-1,137;-1;-1;-1,-1;-1,NAN,NAN,n,3
2180,ICLR,2019,Graph Neural Networks with Generated Parameters for Relation Extraction,Hao Zhu;Yankai Lin;Zhiyuan Liu;Jie Fu;Tat-seng Chua and Maosong Sun,prokilchu@gmail.com;linyk14@mails.tsinghua.edu.cn;liuzy@tsinghua.edu.cn;full.jeffrey@gmail.com;chuats@comp.nus.edu.sg;sms@tsinghua.edu.cn,4;6;6,4;3;4,Reject,0,4,0.0,yes,9/27/18,"Carnegie Mellon University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Montreal;National University of Singapore;Tsinghua University, Tsinghua University",Graph Neural Networks;Relational Reasoning,1;4;4;116;18;4,24;30;30;108;22;30,-1;-1,NAN,NAN,n,3;10
2181,ICLR,2019,Cohen Welling bases & SO(2)-Equivariant classifiers using Tensor nonlinearity.,Muthuvel Murugan;K Venkata Subrahmanyam,muthu@cmi.ac.in;kv@cmi.ac.in,6;3;7,2;2;4,Reject,0,9,0.0,yes,9/27/18,Chennai Mathematical Institute;Chennai Mathematical Institute,group representations;group equivariant networks;tensor product nonlinearity,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
2182,ICLR,2019,Out-of-Sample Extrapolation with Neuron Editing,Matthew Amodio;David van Dijk;Ruth Montgomery;Guy Wolf;Smita Krishnaswamy,matthew.amodio@yale.edu;davidvandijk@gmail.com;ruth.montgomery@yale.edu;guy.wolf@yale.edu;smita.krishnaswamy@yale.edu,5;5;6,3;3;4,Reject,0,4,0.0,yes,9/27/18,Yale University;;Yale University;Yale University;Yale University,generative adversarial networks;computational biology;generating;generation;extrapolation;out-of-sample;neural network inference,67;-1;67;67;67,12;-1;12;12;12,-1;-1,europe,fi,n,5;4
2183,ICLR,2019,Security Analysis of Deep Neural Networks Operating in the Presence of Cache Side-Channel Attacks,Sanghyun Hong;Michael Davinroy;Yigitcan Kaya;Stuart Nevans Locke;Ian Rackow;Kevin Kulda;Dana Dachman-Soled;Tudor Dumitra»ô,shhong@cs.umd.edu;mdavinr1@swarthmore.edu;yigitcan@cs.umd.edu;stnevans@mail.rit.edu;ian.rackow@gmail.com;kevin_kulda1@baylor.edu;danadach@ece.umd.edu;tdumitra@umiacs.umd.edu,4;6;4,4;4;2,Reject,0,6,0.0,yes,9/27/18,"University of Maryland, College Park;Swarthmore College;University of Maryland, College Park;Rochester Institute of Technology;;Baylor University;University of Maryland, College Park;University of Maryland, College Park",DNN Security Analysis;Fingerprinting Attacks;Cache Side-Channel,12;-1;12;136;-1;-1;12;12,69;-1;69;666;-1;642;69;69,-1;-1,usa,usa,n,6;4
2184,ICLR,2019,Analyzing Federated Learning through an Adversarial Lens,Arjun Nitin Bhagoji;Supriyo Chakraborty;Seraphin Calo;Prateek Mittal,abhagoji@princeton.edu;supriyo@us.ibm.com;scalo@us.ibm.com;pmittal@princeton.edu,5;4;6,4;5;4,Reject,0,4,0.0,yes,9/27/18,Princeton University;International Business Machines;International Business Machines;Princeton University,federated learning;model poisoning,31;-1;-1;31,7;-1;-1;7,-1;-1,usa,usa,n,4
2185,ICLR,2019,Knows When it Doesn‚Äôt Know: Deep Abstaining Classifiers,Sunil Thulasidasan;Tanmoy Bhattacharya;Jeffrey Bilmes;Gopinath Chennupati;Jamal Mohd-Yusof,sunil@lanl.gov;tanmoy@lanl.gov;bilmes@uw.edu;gchennupati@lanl.gov;jamal@lanl.gov,6;5;5,4;3;5,Reject,0,6,0.0,yes,9/27/18,"Los Alamos National Laboratory;Los Alamos National Laboratory;University of Washington, Seattle;Los Alamos National Laboratory;Los Alamos National Laboratory",deep learning;robust learning;abstention;representation learning;abstaining classifier;open-set detection,-1;-1;10;-1;-1,-1;-1;25;-1;-1,-1;-1,NAN,NAN,y,
2186,ICLR,2019,Simple Black-box Adversarial Attacks,Chuan Guo;Jacob R. Gardner;Yurong You;Andrew G. Wilson;Kilian Q. Weinberger,cg563@cornell.edu;jrg365@cornell.edu;yy785@cornell.edu;andrew@cornell.edu;kqw4@cornell.edu,4;6;6,5;3;3,Reject,0,6,0.0,yes,9/27/18,Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,,6;6;6;6;6,19;19;19;19;19,-1;-1,usa,usa,n,4
2187,ICLR,2019,Modulating transfer between tasks in gradient-based meta-learning,Erin Grant;Ghassen Jerfel;Katherine Heller;Thomas L. Griffiths,eringrant@berkeley.edu;gj47@duke.edu;kheller@stat.duke.edu;tomg@princeton.edu,5;4;4,2;3;4,Reject,0,21,0.0,yes,9/27/18,University of California Berkeley;Duke University;Duke University;Princeton University,meta-learning;clustering;learning-to-learn;mixture;hierarchical Bayes;hierarchical model;gradient-based meta-learning,-1;47;47;31,18;17;17;7,-1;-1,usa,usa,n,6;11;1
2188,ICLR,2019,Approximation capability of neural networks on sets of probability measures and tree-structured data,Tom√°≈° Pevn√Ω;Vojtƒõch Kova≈ô√≠k,pevnak@gmail.com;vojta.kovarik@gmail.com,6;5;4,3;5;5,Reject,0,4,0.0,yes,9/27/18,Czech Technical University in Prague;Czech Technical University in Prague,multi-instance learning;hierarchical models;universal approximation theorem,169;-1,740;-1,-1;-1,asia,in,y,1
2189,ICLR,2019,Uncertainty in Multitask Transfer Learning,Alexandre Lacoste;Boris Oreshkin;Wonchang Chung;Thomas Boquet;Negar Rostamzadeh;David Krueger,alex.lacoste.shmu@gmail.com;boris@elementai.com;wonchang@elementai.com;thomas@elementai.com;negar.rostamzadeh@gmail.com;david.scott.krueger@gmail.com,4;3;2,4;5;5,Reject,0,4,0.0,yes,9/27/18,Element AI;Element AI;Element AI;Element AI;Google;Université de Montréal,Multi Task;Transfer Learning;Hierarchical Bayes;Variational Bayes;Meta Learning;Few Shot learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,asia,in,n,6
2190,ICLR,2019,Compound Density Networks,Agustinus Kristiadi;Asja Fischer,kristiadi@protonmail.com;asja.fischer@gmail.com,4;5;5,4;4;4,Reject,0,10,0.0,yes,9/27/18,University of Tuebingen;Institute for Cognitive Neuroscience/ Inst. for Neuroinformatics,uncertainty in neural networks;ensemble;mixture model,136;-1,94;-1,-1;-1,NAN,NAN,n,11;4
2191,ICLR,2019,Adversarial Examples Are a Natural Consequence of Test Error in Noise,Nicolas Ford;Justin Gilmer;Ekin D. Cubuk,nicf@google.com;gilmer@google.com;cubuk@google.com,4;5;4,4;3;3,Reject,6,5,3.0,yes,9/27/18,Google;Google;Google,Adversarial examples;generalization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8;1;4
2192,ICLR,2019,Stochastic Adversarial Video Prediction,Alex X. Lee;Richard Zhang;Frederik Ebert;Pieter Abbeel;Chelsea Finn;Sergey Levine,alexlee_gk@cs.berkeley.edu;rich.zhang@eecs.berkeley.edu;febert@berkeley.edu;pabbeel@cs.berkeley.edu;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,6;6;5,3;4;5,Reject,0,9,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,video prediction;GANs;variational autoencoder,-1;-1;-1;-1;-1;-1,18;18;18;18;18;18,-1;-1,usa,usa,n,4
2193,ICLR,2019,On Generalization Bounds of a Family of Recurrent Neural Networks,Minshuo Chen;Xingguo Li;Tuo Zhao,mchen393@gatech.edu;lixx1661@umn.edu;tourzhao@gatech.edu,3;4;6,4;4;4,Reject,4,7,0.0,yes,9/27/18,"Georgia Institute of Technology;University of Minnesota, Minneapolis;Georgia Institute of Technology",Recurrent Neural Networks;MGU;LSTM;Generalization Bound;PAC-Learning,13;67;13,33;56;33,-1;-1,usa,usa,y,1
2194,ICLR,2019,N-Ary Quantization for CNN Model Compression and Inference Acceleration,G√ºnther Schindler;Wolfgang Roth;Franz Pernkopf;Holger Fr√∂ning,guenther.schindler@ziti.uni-heidelberg.de;roth@tugraz.at;pernkopf@tugraz.at;holger.froening@ziti.uni-heidelberg.de,4;4;7,4;4;5,Reject,1,5,0.0,yes,9/27/18,Heidelberg University;Graz University of Technology;Graz University of Technology;Heidelberg University,low-resource deep neural networks;quantized weights;weight-clustering;resource efficient neural networks,207;116;116;207,45;443;443;45,-1;-1,europe,de,n,
2195,ICLR,2019,AntMan: Sparse Low-Rank Compression To Accelerate RNN Inference,Samyam Rajbhandari;Harsh Shrivastava;Yuxiong He,samyamr@microsoft.com;hshrivastava3@gatech.edu;yuxhe@microsoft.com,6;5;5,5;2;4,Reject,0,7,0.0,yes,9/27/18,Microsoft;Georgia Institute of Technology;Microsoft,model compression;RNN;perforamnce optimization;langugage model;machine reading comprehension;knowledge distillation;teacher-student,-1;13;-1,-1;33;-1,-1;-1,NAN,NAN,n,
2196,ICLR,2019,Convolutional CRFs for Semantic Segmentation,Marvin Teichmann;Roberto Cipolla,mttt2@cam.ac.uk;cipolla@eng.cam.ac.uk,7;4;6,4;4;4,Reject,0,8,1.0,yes,9/27/18,University of Cambridge;University of Cambridge,conditional random fields;semantic segmentation;computer vision;structured learning,77;77,2;2,-1;-1,europe,uk,n,2
2197,ICLR,2019,Holographic and other Point Set Distances for Machine Learning,Lukas Balles;Thomas Fischbacher,lukas.balles@tuebingen.mpg.de;tfish@google.com,3;7;4,4;3;3,Reject,0,0,0.0,yes,9/27/18,Max-Planck Institute;Google,point set;set;permutation-invariant;loss function,-1;-1,-1;-1,-1;-1,NAN,NAN,y,2;1
2198,ICLR,2019,Pixel Redrawn For A Robust Adversarial Defense,Jiacang Ho;Dae-Ki Kang,ho_jiacang@hotmail.com;dkkang@dongseo.ac.kr,4;6;3,3;3;4,Reject,22,3,0.0,yes,9/27/18,Dongseo University;Kyung Hee,adversarial machine learning;deep learning;adversarial example,-1;419,-1;407,-1;-1,NAN,NAN,n,4
2199,ICLR,2019,HIGHLY EFFICIENT 8-BIT LOW PRECISION INFERENCE OF CONVOLUTIONAL NEURAL NETWORKS,Haihao Shen;Jiong Gong;Xiaoli Liu;Guoming Zhang;Ge Jin;and Eric Lin,haihao.shen@intel.com;jiong.gong@intel.com;xiaoli.liu@intel.com;guoming.zhang@intel.com;ge.jin@intel.com;eric.lin@intel.com,6;4;4,4;4;4,Reject,0,0,0.0,yes,9/27/18,Intel;Intel;Intel;Intel;Intel;Intel,8-bit low precision inference;convolutional neural networks;statistical accuracy;8-bit Winograd convolution,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
2200,ICLR,2019,Modulated Variational Auto-Encoders for Many-to-Many Musical Timbre Transfer,Adrien Bitton;Philippe Esling;Axel Chemla-Romeu-Santos,bitton@ircam.fr;philippe.esling@ircam.fr;axel.chemla-romeu-santos@ircam.fr,5;5;3,3;3;4,Reject,5,7,0.0,yes,9/27/18,Institut de Recherche et Coordination Acoustique/Musique;Institut de Recherche et Coordination Acoustique/Musique;Institut de Recherche et Coordination Acoustique/Musique,Musical Timbre;Instrument Translation;Domain Translation;Style Transfer;Sound Synthesis;Musical Information;Deep Learning;Variational Auto-Encoder;Generative Models;Network Conditioning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2201,ICLR,2019,Geometry aware convolutional filters for omnidirectional images representation,Renata Khasanova;Pascal Frossard,renata.khasanova@epfl.ch;pascal.frossard@epfl.ch,4;6;4,4;4;5,Reject,2,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,omnidirectional images;classification;deep learning;graph signal processing,-1;-1,-1;-1,-1;-1,NAN,NAN,n,2
2202,ICLR,2019,A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS,Chandan Kumar;Subrahmanyam Vaddi;Aishwarya Sarkar,chandan@iastate.edu;svaddi@iastate.edu;asarkar1@iastate.edu,3;3;2,3;2;2,Reject,0,0,0.0,yes,9/27/18,Iowa State University;Iowa State University;Iowa State University,Energy Efficiency;Autonomous Flying;Trail Detection,207;207;207,341;341;341,-1;-1,usa,usa,n,8
2203,ICLR,2019,Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks,S. Hamid Rezatofighi;Roman Kaskman;Farbod T. Motlagh;Qinfeng Shi;Daniel Cremers;Laura Leal-Taix√©;Ian Reid,hamid.rezatofighi@adelaide.edu.au;roman.kaskman@tum.de;farbod.motlagh@student.adelaide.edu.au;javen.shi@adelaide.edu.au;cremers@tum.de;leal.taixe@tum.de;ian.reid@adelaide.edu.au,7;3;3,3;3;4,Reject,0,7,0.0,yes,9/27/18,The University of Adelaide;Technical University Munich;The University of Adelaide;The University of Adelaide;Technical University Munich;Technical University Munich;The University of Adelaide,Set learning;Permutation invariant;Object detection;CAPTCHA test,94;-1;94;94;-1;-1;94,134;-1;134;134;-1;-1;134,-1;-1,NAN,NAN,n,2
2204,ICLR,2019,DEEP-TRIM: REVISITING L1 REGULARIZATION FOR CONNECTION PRUNING OF DEEP NETWORK,Chih-Kuan Yeh;Ian E.H. Yen;Hong-You Chen;Chun-Pei Yang;Shou-De Lin;Pradeep Ravikumar,cjyeh@cs.cmu.edu;eyan2@snapchat.com;applebasket70179@gmail.com;skylyyang@gmail.com;sdlin@csie.ntu.edu.tw;pradeep.ravikumar@gmail.com,4;6;4,4;3;3,Reject,0,3,0.0,yes,9/27/18,Carnegie Mellon University;Snap Inc.;Ohio State University;;Nanyang Technological University;Carnegie Mellon University,L1 regularization;deep neural network;deep compression,1;-1;59;-1;44;1,24;-1;70;-1;52;24,-1;-1,usa,usa,y,1;9
2205,ICLR,2019,INTERPRETABLE CONVOLUTIONAL FILTER PRUNING,Zhuwei Qin;Fuxun Yu;Chenchen Liu;Xiang Chen,zqin@gmu.edu;fyu2@gmu.edu;chliu@clarkson.edu;xchen26@gmu.edu,4;4;3,4;3;4,Reject,0,16,0.0,yes,9/27/18,George Mason University;George Mason University;Clarkson University;George Mason University,,94;94;-1;94,336;336;-1;336,-1;-1,usa,usa,n,
2206,ICLR,2019,Learning Internal Dense But External Sparse Structures of Deep Neural Network,Yiqun Duan,duanyiquncc@gmail.com,5;5;6,3;3;2,Reject,0,5,0.0,yes,9/27/18,0,Convolutional Neural Network;Hierarchical Neural Architecture;Structural Sparsity;Evolving Algorithm,,,-1,NAN,NAN,n,
2207,ICLR,2019,Understand the dynamics of GANs via Primal-Dual Optimization,Songtao Lu;Rahul Singh;Xiangyi Chen;Yongxin Chen;Mingyi Hong,lus@umn.edu;rasingh@gatech.edu;chen5719@umn.edu;yongchen@gatech.edu;mhong@umn.edu,4;5;6,4;3;3,Reject,3,4,0.0,yes,9/27/18,"University of Minnesota, Minneapolis;Georgia Institute of Technology;University of Minnesota, Minneapolis;Georgia Institute of Technology;University of Minnesota, Minneapolis",non-convex optimization;generative adversarial network;primal dual algorithm,67;13;67;13;67,56;33;56;33;56,-1;-1,NAN,NAN,y,5;4
2208,ICLR,2019,Do Language Models Have Common Sense?,Trieu H. Trinh;Quoc V. Le,thtrieu@google.com;qvl@google.com,5;4;4,4;4;4,Reject,6,1,0.0,yes,9/27/18,Google;Google,,-1;-1,-1;-1,-1;-1,NAN,NAN,n,3
2209,ICLR,2019,"Prototypical Examples in Deep Learning: Metrics, Characteristics, and Utility",Nicholas Carlini;Ulfar Erlingsson;Nicolas Papernot,nicholas@carlini.com;ulfar@google.com;papernot@google.com,5;3;5,4;3;4,Reject,0,14,0.0,yes,9/27/18,Google;Google;Google,prototypes;curriculum learning;interpretability;differential privacy;adversarial robustness,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
2210,ICLR,2019,Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks,Han Zhao;Yao-Hung Hubert Tsai;Ruslan Salakhutdinov;Geoff Gordon,han.zhao@cs.cmu.edu;yaohungt@cs.cmu.edu;rsalakhu@cs.cmu.edu;ggordon@cs.cmu.edu,6;3;7,4;5;4,Reject,0,7,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Empirical Bayes;Bayesian Deep Learning,1;1;1;1,24;24;24;24,-1;-1,usa,usa,y,
2211,ICLR,2019,Pearl: Prototype lEArning via Rule Lists,Tianfan Fu*;Tian Gao*;Cao Xiao*;Tengfei Ma*;Jimeng Sun,tfu42@gatech.edu;tgao@us.ibm.com;cxiao@us.ibm.com;tengfei.ma1@ibm.com;jsun@cc.gatech.edu,5;3;4,4;3;4,Reject,0,4,0.0,yes,9/27/18,Georgia Institute of Technology;International Business Machines;International Business Machines;International Business Machines;Georgia Institute of Technology,rule list learning;prototype learning;interpretability;healthcare,13;-1;-1;-1;13,33;-1;-1;-1;33,-1;-1,usa,usa,n,
2212,ICLR,2019,Optimal margin Distribution Network,Shen-Huan Lv;Lu Wang;Zhi-Hua Zhou,lvsh@lamda.nju.edu.cn;wangl@lamda.nju.edu.cn;zhouzh@lamda.nju.edu.cn,5;5;6,4;5;3,Reject,3,4,0.0,yes,9/27/18,Zhejiang University;Zhejiang University;Zhejiang University,Optimal margin distribution;Deep neural network;Generalization bound,36;36;36,177;177;177,-1;-1,asia,cn,y,11;1
2213,ICLR,2019,An Information-Theoretic Metric of Transferability for Task Transfer Learning,Yajie Bao;Yang Li;Shao-Lun Huang;Lin Zhang;Amir R. Zamir;Leonidas J. Guibas,byjem123@163.com;tori2011@gmail.com;shaolun.huang@sz.tsinghua.edu.cn;linzhang@tsinghua.edu.cn;zamir@cs.stanford.edu;guibas@cs.stanford.edu,5;6;6,3;3;4,Reject,0,5,0.0,yes,9/27/18,"163;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Stanford University;Stanford University",transfer learning;task transfer learning;H-score;transferability,-1;4;4;4;4;4,-1;30;30;30;3;3,-1;-1,usa,usa,y,6
2214,ICLR,2019,Selective Convolutional Units: Improving CNNs via Channel Selectivity,Jongheon Jeong;Jinwoo Shin,jongheonj@kaist.ac.kr;jinwoos@kaist.ac.kr,6;5;5,2;3;3,Reject,0,5,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,convolutional neural networks;channel-selectivity;channel re-wiring;bottleneck architectures;deep learning,-1;-1,95;95,-1;-1,NAN,NAN,y,
2215,ICLR,2019,Sufficient Conditions for Robustness to Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks,Yarin Gal;Lewis Smith,yarin@cs.ox.ac.uk;lsgs@robots.ox.ac.uk,5;5;4,4;3;4,Reject,0,16,1.0,yes,9/27/18,University of Oxford;University of Oxford,Bayesian deep learning;Bayesian neural networks;adversarial examples,44;44,1;1,-1;-1,europe,uk,n,11;1;4
2216,ICLR,2019,Empirical Bounds on Linear Regions of Deep Rectifier Networks,Thiago Serra;Srikumar Ramalingam,tserra@gmail.com;srikumar.ramalingam@gmail.com,6;7;6,4;4;4,Reject,0,5,0.0,yes,9/27/18,Bucknell University;Google,linear regions;approximate model counting;mixed-integer linear programming,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1
2217,ICLR,2019,Provable Defenses against Spatially Transformed Adversarial Inputs: Impossibility and Possibility Results,Xinyang Zhang;Yifan Huang;Chanh Nguyen;Shouling Ji;Ting Wang,xizc15@lehigh.edu;yih319@lehigh.edu;cpn217@lehigh.edu;sji@zju.edu.cn;inbox.ting@gmail.com,5;3;5,3;4;3,Reject,0,0,0.0,yes,9/27/18,Lehigh University;Lehigh University;Lehigh University;Zhejiang University;Lehigh University,,285;285;285;36;285,533;533;533;177;533,-1;-1,usa,usa,y,4
2218,ICLR,2019,On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models,Paul Michel;Graham Neubig;Xian Li;Juan Miguel Pino,pmichel1@cs.cmu.edu;gneubig@cs.cmu.edu;xianl@fb.com;juancarabina@fb.com,4;6;4;3,4;3;4;4,Reject,0,11,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Facebook;Facebook,Sequence-to-sequence;adversarial attacks;evaluation;meaning preservation;machine translation,1;1;-1;-1,24;24;-1;-1,-1;-1,NAN,NAN,n,3;4
2219,ICLR,2019,Collapse of deep and narrow neural nets,Lu Lu;Yanhui Su;George Em Karniadakis,lu_lu_1@brown.edu;suyh@fzu.edu.cn;george_karniadakis@brown.edu,7;6;4,5;4;4,Reject,0,7,0.0,yes,9/27/18,Brown University;University of Science and Technology of China;Brown University,neural networks;deep and narrow;ReLU;collapse,86;-1;86,50;132;50,-1;-1,usa,usa,y,
2220,ICLR,2019,Diminishing Batch Normalization,Yintai Ma;Diego Klabjan,yintaima2020@u.northwestern.edu;d-klabjan@northwestern.edu,4;3;4,4;3;5,Reject,0,5,0.0,yes,9/27/18,Northwestern University;Northwestern University,deep learning;learning theory;convergence analysis;batch normalization,50;50,20;20,-1;-1,usa,usa,y,1;9
2221,ICLR,2019,The Nonlinearity Coefficient - Predicting Generalization in Deep Neural Networks,George Philipp;Jaime G. Carbonell,george.philipp@email.de;jgc@cs.cmu.edu,4;5;7,3;4;4,Reject,1,11,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University,deep learning;neural networks;nonlinearity;activation functions;exploding gradients;vanishing gradients;neural architecture search,1;1,24;24,-1;-1,usa,usa,n,1
2222,ICLR,2019,Multi-way Encoding for Robustness to Adversarial Attacks,Donghyun Kim;Sarah Adel Bargal;Jianming Zhang;Stan Sclaroff,donhk@bu.edu;sbargal@bu.edu;jianmzha@adobe.com;sclaroff@bu.edu,4;6;6;6,4;3;2;2,Reject,3,14,1.0,yes,9/27/18,Boston University;Boston University;Adobe Systems;Boston University,Adversarial Defense;Robustness of Deep Convolutional Networks,77;77;-1;77,70;70;-1;70,-1;-1,europe,it,n,2;4
2223,ICLR,2019,Improved robustness to adversarial examples using Lipschitz regularization of the loss,Chris Finlay;Adam M. Oberman;Bilal Abbasi,christopher.finlay@mail.mcgill.ca;adam.oberman@mcgill.ca;bilal.abbasi@mail.mcgill.ca,4;6;6,3;1;3,Reject,1,10,0.0,yes,9/27/18,McGill University;McGill University;McGill University,Adversarial training;adversarial examples;deep neural networks;regularization;Lipschitz constant,94;94;94,42;42;42,-1;-1,canada,ca,y,4
2224,ICLR,2019,CONTROLLING COVARIATE SHIFT USING EQUILIBRIUM NORMALIZATION OF WEIGHTS,Aaron Defazio,aaron.defazio@gmail.com,4;6;7,4;1;4,Reject,0,2,0.0,yes,9/27/18,Facebook,normalization;optimization,-1,-1,-1,NAN,NAN,n,
2225,ICLR,2019,Implicit Maximum Likelihood Estimation,Ke Li;Jitendra Malik,ke.li@eecs.berkeley.edu;malik@eecs.berkeley.edu,3;4;5,4;4;4,Reject,2,2,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley,likelihood-free inference;implicit probabilistic models,-1;-1,18;18,-1;-1,usa,usa,y,
2226,ICLR,2019,Mental Fatigue Monitoring using Brain Dynamics Preferences,Yuangang Pan;Avinash K Singh;Ivor W. Tsang;Chin-teng Lin,yuangang.pan@student.uts.edu.au;avinashsingh@outlook.com;ivor.tsang@uts.edu.au;chin-teng.lin@uts.edu.au,7;4;2,3;3;5,Reject,0,6,0.0,yes,9/27/18,University of Technology Sydney;;University of Technology Sydney;University of Technology Sydney,mental fatigue;brain dynamics preference;brain dynamics ranking;channel reliability;channel Selection,67;-1;67;67,216;-1;216;216,-1;-1,australasia,au,n,1
2227,ICLR,2019,Gradient-based learning for F-measure and other performance metrics,Yu Gai;Zheng Zhang;Kyunghyun Cho,yg1246@nyu.edu;zz@nyu.edu;kyunghyun.cho@nyu.edu,3;5;5,4;3;5,Reject,0,6,0.0,yes,9/27/18,New York University;New York University;New York University,,24;24;24,27;27;27,-1;-1,usa,usa,y,
2228,ICLR,2019,MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA,Rudrasis Chakraborty;Jose Bouza;Jonathan Manton;Baba C. Vemuri,rudrasischa@gmail.com;josebouza@ufl.edu;jonathan.manton@ieee.org;baba.vemuri@gmail.com,5;4;4,3;4;4,Reject,0,12,0.0,yes,9/27/18,University of Florida;University of Florida;;University of Florida,,136;136;-1;136,143;143;-1;143,-1;-1,usa,usa,y,1
2229,ICLR,2019,REPRESENTATION COMPRESSION AND GENERALIZATION IN DEEP NEURAL NETWORKS,Ravid Shwartz-Ziv;Amichai Painsky;Naftali Tishby,ravid.ziv@mail.huji.ac.il;amichai.painsky@mail.huji.ac.il;tishby@cs.huji.ac.il,3;6;4,3;3;3,Reject,0,3,0.0,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Deep neural network;information theory;training dynamics,77;77;77,205;205;205,-1;-1,europe,il,y,1
2230,ICLR,2019,Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond,Jikai Hou;Kaixuan Huang;Zhihua Zhang,houjikai@pku.edu.cn;hackyhuang@pku.edu.cn;zhzhang@math.pku.edu.cn,3;4;5,3;4;4,Reject,9,5,0.0,yes,9/27/18,Peking University;Peking University;Peking University,distributionally robust optimization;deep learning;SGD;learning theory,14;14;14,27;27;27,-1;-1,asia,cn,y,1;9
2231,ICLR,2019,A Priori Estimates  of the Generalization Error for Two-layer Neural Networks,Lei Wu;Chao Ma;Weinan E,leiwu@pku.edu.cn;chaom@princeton.edu;weinan@math.princeton.edu,4;4;4;5,3;3;4;3,Reject,0,0,0.0,yes,9/27/18,Peking University;Princeton University;Princeton University,Over-parameterization;A priori estimates;Path norm;Neural networks;Generalization error;Approximation error,14;31;31,27;7;7,-1;-1,usa,usa,y,1
2232,ICLR,2019,Online Hyperparameter Adaptation via Amortized Proximal Optimization,Paul Vicol;Jeffery Z. HaoChen;Roger Grosse,pvicol@cs.toronto.edu;zhc15@mails.tsinghua.edu.cn;rgrosse@cs.toronto.edu,7;6;5,3;4;4,Reject,0,11,0.0,yes,9/27/18,"University of Toronto;Tsinghua University, Tsinghua University;University of Toronto",hyperparameters;optimization;learning rate adaptation,18;4;18,22;30;22,-1;-1,canada,ca,y,9
2233,ICLR,2019,Adversarial Exploration Strategy for Self-Supervised Imitation Learning,Zhang-Wei Hong;Tsu-Jui Fu;Tzu-Yun Shann;Yi-Hsiang Chang;Chun-Yi Lee,williamd4112@gapp.nthu.edu.tw;yesray0216@gmail.com;ariel@shann.net;shawn420@gapp.nthu.edu.tw;cylee@cs.nthu.edu.tw,7;5;5,3;3;3,Reject,0,12,0.0,yes,9/27/18,National Tsing Hua University;;University of British Columbia;National Tsing Hua University;National Tsing Hua University,adversarial exploration;self-supervised;imitation learning,207;-1;59;207;207,323;-1;34;323;323,-1;-1,asia,tw,n,4
2234,ICLR,2019,On Learning Heteroscedastic Noise Models within Differentiable Bayes Filters,Alina Kloss;Jeannette Bohg,alina.kloss@tuebingen.mpg.de;bohg@stanford.edu,6;6;4,4;5;4,Reject,0,6,0.0,yes,9/27/18,Max-Planck Institute;Stanford University,bayesian filtering;heteroscedastic noise;deep learning,-1;4,-1;3,-1;-1,usa,usa,n,11
2235,ICLR,2019,Manifold regularization with GANs for semi-supervised learning,Bruno Lecouat;Chuan-Sheng Foo;Houssam Zenati;Vijay Chandrasekhar,bruno_lecouat@i2r.a-star.edu.sg;foo_chuan_sheng@i2r.a-star.edu.sg;houssam.zenati@student.ecp.fr;vijay@i2r.a-star.edu.sg,7;5;5,4;4;4,Reject,0,4,0.0,yes,9/27/18,"Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Ecole Centrale Paris;Institute for Infocomm Research, A*STAR",semi-supervised learning;generative adversarial networks;manifold regularization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2236,ICLR,2019,SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels,Or Litany;Daniel Freedman,orlitany@gmail.com;danielfreedman@google.com,7;5;5,4;4;4,Reject,0,4,0.0,yes,9/27/18,NVIDIA;Google,transfer learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,6
2237,ICLR,2019,SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning,Marvin Zhang*;Sharad Vikram*;Laura Smith;Pieter Abbeel;Matthew Johnson;Sergey Levine,marvin@cs.berkeley.edu;svikram@cs.ucsd.edu;smithlaura@berkeley.edu;pabbeel@cs.berkeley.edu;mattjj@google.com;svlevine@cs.berkeley.edu,5;5;5,4;4;3,Reject,0,10,0.0,yes,9/27/18,"University of California Berkeley;University of California, San Diego;University of California Berkeley;University of California Berkeley;Google;University of California Berkeley",model-based reinforcement learning;structured representation learning;robotics,-1;-1;-1;-1;-1;-1,18;31;18;18;-1;18,-1;-1,usa,usa,n,
2238,ICLR,2019,Selective Self-Training for semi-supervised Learning,Jisoo Jeong;Seungeui Lee;Nojun Kwak,soo3553@snu.ac.kr;dehlix@snu.ac.kr;nojunk@snu.ac.kr,5;4;4,4;5;4,Reject,0,5,0.0,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University,deep learning;image recognition;semi-supervised learning,36;36;36,74;74;74,-1;-1,asia,kr,n,
2239,ICLR,2019,Dissecting an Adversarial framework for Information Retrieval,Ameet Deshpande;Mitesh M.Khapra,cs15b001@cse.iitm.ac.in;miteshk@cse.iitm.ac.in,6;5;4,4;3;4,Reject,0,3,0.0,yes,9/27/18,Indian Institute of Technology Madras;Indian Institute of Technology Madras,GAN;Deep Learning;Reinforcement Learning,-1;-1,625;625,-1;-1,NAN,NAN,n,5;4
2240,ICLR,2019,Learning Latent Semantic Representation from Pre-defined Generative Model,Jin-Young Kim;Sung-Bae Cho,seago0828@yonsei.ac.kr;sbcho@yonsei.ac.kr,5;3;4,2;5;3,Reject,0,0,0.0,yes,9/27/18,Yonsei University;Yonsei University,Latent space;Generative adversarial network;variational autoencoder;conditioned generation,169;169,231;231,-1;-1,asia,cn,y,1;5
2241,ICLR,2019,Adversarial Information Factorization,Antonia Creswell;Yumnah Mohamied;Biswa Sengupta;Anil Bharath,ac2211@ic.ac.uk;ym1008@ic.ac.uk;biswasengupta@gmail.com;aab01@ic.ac.uk,6;6;6,4;4;4,Reject,2,27,0.0,yes,9/27/18,Imperial College London;Imperial College London;;Imperial College London,disentangled representations;factored representations;generative adversarial networks;variational auto encoders;generative models,47;47;-1;47,8;8;-1;8,-1;-1,europe,uk,n,5
2242,ICLR,2019,TequilaGAN: How To Easily Identify GAN Samples,Rafael Valle;Wilson Cai;Anish P. Doshi,rafaelvalle@berkeley.edu;wcai@berkeley.edu;apdoshi@berkeley.edu,5;4;6,4;4;5,Reject,0,5,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,Generative Adversarial Networks;Deep Learning,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,5;4
2243,ICLR,2019,Guided Evolutionary Strategies: Escaping the curse of dimensionality in random search,Niru Maheswaranathan;Luke Metz;George Tucker;Dami Choi;Jascha Sohl-Dickstein,nirum@google.com;lmetz@google.com;gjt@google.com;damichoi@google.com;jaschasd@google.com,5;4;6,3;3;4,Reject,0,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google,evolutionary strategies;optimization;gradient estimators;biased gradients,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
2244,ICLR,2019,DL2: Training and Querying Neural Networks with Logic,Marc Fischer;Mislav Balunovic;Dana Drachsler-Cohen;Timon Gehr;Ce Zhang;Martin Vechev,marcfisc@student.ethz.ch;bmislav@student.ethz.ch;dana.drachsler@inf.ethz.ch;timon.gehr@inf.ethz.ch;ce.zhang@inf.ethz.ch;martin.vechev@inf.ethz.ch,6;7;5,2;4;4,Reject,0,8,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,neural networks;training with constraints;querying networks;semantic training,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2245,ICLR,2019,D√©j√† Vu: An Empirical Evaluation of the Memorization Properties of Convnets,Alexandre Sablayrolles;Matthijs Douze;Cordelia Schmid;Herv√© J√©gou,asablayrolles@fb.com;matthijs@fb.com;cordelia.schmid@inria.fr;rvj@fb.com,6;4;5,2;2;4,Reject,0,4,0.0,yes,9/27/18,Facebook;Facebook;INRIA;Facebook,membership inference;memorization;attack;privacy,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2246,ICLR,2019,iRDA Method for Sparse Convolutional Neural Networks,Xiaodong Jia;Liang Zhao;Lian Zhang;Juncai He;Jinchao Xu,jiaxiaodong1994@gmail.com;zhaoliang14@lsec.cc.ac.cn;lzhangay@ust.hk;juncaihe@pku.edu.cn;xu@math.psu.edu,3;3;3,5;4;5,Reject,0,0,0.0,yes,9/27/18,Peking University;Chinese Academy of Sciences;The Hong Kong University of Science and Technology;Peking University;Pennsylvania State University,sparse convolutional neural networks;regularized dual averaging,14;31;-1;14;44,27;-1;44;27;-1,-1;-1,usa,usa,y,
2247,ICLR,2019,Variation Network: Learning High-level Attributes for Controlled Input Manipulation,Ga√´tan Hadjeres,hadjeres.g@gmail.com,3;6;4,4;2;3,Reject,0,3,0.0,yes,9/27/18,Sony Corporation,Generative models;Input manipulation;Unsupervised feature learning;Variations,-1,-1,-1,NAN,NAN,n,5
2248,ICLR,2019,Consistency-based anomaly detection with adaptive multiple-hypotheses predictions,Duc Tam Nguyen;Zhongyu Lou;Michael Klar;Thomas Brox,nguyen@cs.uni-freiburg.de;zhongyu.lou@de.bosch.com;michael.klar2@de.bosch.com;brox@cs.uni-freiburg.de,4;5;5,4;3;4,Reject,0,6,0.0,yes,9/27/18,Universit√§t Freiburg;Bosch;Bosch;Universit√§t Freiburg,Anomaly detection;outlier detection;generative models;VAE;GAN,-1;-1;-1;-1,-1;367;367;-1,-1;-1,NAN,NAN,y,5;4
2249,ICLR,2019,"VARIATIONAL SGD: DROPOUT , GENERALIZATION AND CRITICAL POINT AT THE END OF CONVEXITY",Michael Tetelman,michael.tetelman@gmail.com,4;2;2,3;4;5,Reject,0,1,2.0,yes,9/27/18,VW GOA IECC,Bayesian inference;neural networks;generalization;critical point solution,-1,-1,-1,NAN,NAN,n,11
2250,ICLR,2019,Learning to remember: Dynamic Generative Memory for Continual Learning,Oleksiy Ostapenko;Mihai Puscas;Tassilo Klein;Moin Nabi,oleksiy.ostapenko@sap.com;mihai.puscas@sap.com;mihaimarian.puscas@unitn.it;tassilo.klein@sap.com;m.nabi@sap.com,4;3;8,5;5;5,Reject,0,7,0.0,yes,9/27/18,SAP;SAP;University of Trento;SAP;SAP,Continual Learning;Catastrophic Forgetting;Dynamic Network Expansion,285;285;136;285;285,300;300;258;300;300,-1;-1,asia,in,n,5;4
2251,ICLR,2019,Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks,Patrick Schwab;Lorenz Linhardt;Walter Karlen,patrick.schwab@hest.ethz.ch;llorenz@student.ethz.ch;walter.karlen@hest.ethz.ch,5;5;6,3;4;4,Reject,0,11,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2252,ICLR,2019,Pyramid Recurrent Neural Networks for Multi-Scale Change-Point Detection,Zahra Ebrahimzadeh;Min Zheng;Selcuk Karakas;Samantha Kleinberg,shina.ebiz@gmail.com;mzheng3@stevens.edu;fkarakas@stevens.edu;samantha.kleinberg@stevens.edu,7;4;6,4;5;3,Reject,0,3,0.0,yes,9/27/18,Foolad Institue of Technology;Stevens Institute of Technology;Stevens Institute of Technology;Stevens Institute of Technology,changepoint detection;multivariate time series data;multiscale RNN,-1;169;169;169,-1;512;512;512,-1;-1,usa,usa,n,
2253,ICLR,2019,BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating,Xin Luo;Hankz Hankui Zhuo,luox35@mail2.sysu.edu.cn;zhuohank@mail.sysu.edu.cn,2;4;4,4;3;4,Reject,0,0,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,network embedding;unsupervised learning;inductive learning,-1;-1,352;352,-1;-1,NAN,NAN,n,6;8;10
2254,ICLR,2019,Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness,Heinrich Jiang;Yifan Wu;Ofir Nachum,heinrichj@google.com;yw4@andrew.cmu.edu;ofirnachum@google.com,5;5;4,3;4;3,Reject,0,3,0.0,yes,9/27/18,Google;Carnegie Mellon University;Google,fairness,-1;1;-1,-1;24;-1,-1;-1,NAN,NAN,n,7
2255,ICLR,2019,Learning to Augment Influential Data,Donghoon Lee;Chang D. Yoo,iamdh@kaist.ac.kr;cd_yoo@kaist.ac.kr,6;6;5,4;4;4,Reject,0,3,1.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,data augmentation;influence function;generative adversarial network,-1;-1,95;95,-1;-1,NAN,NAN,n,1
2256,ICLR,2019,Generative Adversarial Network Training is a Continual Learning Problem,Kevin J Liang;Chunyuan Li;Guoyin Wang;Lawrence Carin,kevin.liang@duke.edu;chunyuan.li@duke.edu;guoyin.wang@duke.edu;lcarin@duke.edu,7;5;3,4;4;5,Reject,6,13,0.0,yes,9/27/18,Duke University;Duke University;Duke University;Duke University,Generative Adversarial Networks;Continual Learning;Deep Learning,47;47;47;47,17;17;17;17,-1;-1,europe,se,n,5;4
2257,ICLR,2019,Multi-objective training of Generative Adversarial Networks with multiple discriminators,Isabela Albuquerque;Jo√£o Monteiro;Thang Doan;Breandan Considine;Tiago Falk;Ioannis Mitliagkas,isabelamcalbuquerque@gmail.com;joaomonteirof@gmail.com;thang.doan@mail.mcgill.ca;breandan.considine@gmail.com;falk@emt.inrs.ca;ioannis@iro.umontreal.ca,6;6;5,4;3;3,Reject,1,13,0.0,yes,9/27/18,Institut National de la Recherche Scientifique;;McGill University;McGill University;Institut national de la recherche scientifique;University of Montreal,Generative Adversarial Networks;Multi-objective optimization;Generative models,-1;-1;94;94;-1;116,-1;-1;42;42;-1;108,-1;-1,canada,ca,n,5;4
2258,ICLR,2019,Few-Shot Intent Inference via Meta-Inverse Reinforcement Learning,Kelvin Xu;Ellis Ratner;Anca Dragan;Sergey Levine;Chelsea Finn,kelvinxu@eecs.berkeley.edu;eratner@berkeley.edu;anca@berkeley.edu;svlevine@eecs.berkeley.edu;cbfinn@eecs.berkeley.edu,3;4;4,5;3;4,Reject,0,8,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Inverse Reinforcement Learning;Meta-Learning;Deep Learning,-1;-1;-1;-1;-1,18;18;18;18;18,-1;-1,usa,usa,n,6
2259,ICLR,2019,Latent Domain Transfer: Crossing modalities with Bridging Autoencoders,Yingtao Tian;Jesse Engel,yittian@cs.stonybrook.edu;jesseengel@google.com,4;4;4,4;4;4,Reject,1,3,0.0,yes,9/27/18,"State University of New York, Stony Brook;Google",Generative Model;Latent Space;Domain Transfer,-1;-1,-1;-1,-1;-1,NAN,NAN,n,5;4
2260,ICLR,2019,TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING,Xinqi Chen;Ming Hou;Guoxu Zhou;Qibin Zhao,xinqicham@gmail.com;ming.hou@riken.jp;gx.zhou@gdut.edu.cn;qibin.zhao@riken.jp,5;6;4,4;4;4,Reject,0,7,0.0,yes,9/27/18,University of Wollongong;RIKEN;South China University of Technology;RIKEN,deep learning;deep multi-task learning;tensor factorization;tensor ring nets,-1;-1;-1;-1,-1;-1;576;-1,-1;-1,NAN,NAN,n,
2261,ICLR,2019,Overcoming Multi-model Forgetting,Yassine Benyahia*;Kaicheng Yu*;Kamil Bennani-Smires;Martin Jaggi;Anthony Davison;Mathieu Salzmann;Claudiu Musat,yassine.benyahia1@gmail.com;kaicheng.yu@epfl.ch;kamil.bennani-smires@swisscom.com;martin.jaggi@epfl.ch;anthony.davison@epfl.ch;mathieu.salzmann@epfl.ch;claudiu.musat@swisscom.com,6;5;6,2;5;4,Reject,2,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swisscom;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swisscom,multi-model forgetting;deep learning;machine learning;multi-model training;neural architecture search,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,2;3
2262,ICLR,2019,Learning to Separate Domains in Generalized Zero-Shot and Open Set Learning: a probabilistic perspective,Hanze Dong;Yanwei Fu;Leonid Sigal;SungJu Hwang;Yu-Gang Jiang;Xiangyang Xue,hzdong15@fudan.edu.cn;yanweifu@fudan.edu.cn;lsigal@cs.ubc.ca;sjhwang82@kaist.ac.kr;ygj@fudan.edu.cn;xyxue@fudan.edu.cn,5;5;6,4;3;3,Reject,1,10,0.0,yes,9/27/18,Fudan University;Fudan University;University of British Columbia;Korea Advanced Institute of Science and Technology;Fudan University;Fudan University,Generalized zero-shot learning;domain division;bootstrapping;Kolmogorov-Smirnov,67;67;59;-1;67;67,116;116;34;95;116;116,-1;-1,asia,cn,n,6
2263,ICLR,2019,Uncovering Surprising Behaviors in Reinforcement Learning via Worst-case Analysis,Avraham Ruderman;Richard Everett;Bristy Sikder;Hubert Soyer;Jonathan Uesato;Ananya Kumar;Charlie Beattie;Pushmeet Kohli,aruderman@google.com;reverett@google.com;bristy@google.com;soyer@google.com;juesato@google.com;skywalker94@gmail.com;cbeattie@google.com;pushmeet@google.com,7;5;6,4;3;2,Reject,0,5,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Stanford University;Google;Google,Reinforcement learning;Adversarial examples;Navigation;Evaluation;Analysis,-1;-1;-1;-1;-1;4;-1;-1,-1;-1;-1;-1;-1;3;-1;-1,-1;-1,NAN,NAN,n,1
2264,ICLR,2019,Efficient Codebook and Factorization for Second Order Representation Learning,Pierre jacob;David Picard;Aymeric Histace;Edouard Klein,pierre.jacob@ensea.fr;picard@ensea.fr;aymeric.histace@ensea.fr;edouard.klein@gendarmerie.interieur.gouv.fr,4;5;6,5;2;4,Reject,0,8,0.0,yes,9/27/18,ETIS;ETIS;ETIS;Beaver Labs,Second order pooling,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,
2265,ICLR,2019,Metric-Optimized Example Weights,Sen Zhao;Mahdi Milani Fard;Maya Gupta,senzhao@google.com;mmilanifard@google.com;mayagupta@google.com,4;4;7,4;4;3,Reject,0,0,0.0,yes,9/27/18,Google;Google;Google,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,7
2266,ICLR,2019,Unsupervised classification into unknown number of classes,Sungyeob Han;Daeyoung Kim;Jungwoo Lee,syhan@cml.snu.ac.kr;kimdy7@snu.ac.kr;junglee@snu.ac.kr,4;4;5,2;4;4,Reject,0,5,0.0,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University,unsupervised learning,36;36;36,74;74;74,-1;-1,asia,kr,n,10;1;5;4
2267,ICLR,2019,Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations,Alex Lamb;Jonathan Binas;Anirudh Goyal;Dmitriy Serdyuk;Sandeep Subramanian;Ioannis Mitliagkas;Yoshua Bengio,lambalex@iro.umontreal.ca;jonathan.binas@umontreal.ca;anirudhgoyal9119@gmail.com;serdyuk.dmitriy@gmail.com;sandeep.subramanian@gmail.com;ioannis@iro.umontreal.ca;yoshua.bengio@mila.quebec,4;5;9;6,5;3;4;3,Reject,0,27,0.0,yes,9/27/18,University of Montreal;University of Montreal;;Google;University of Montreal;University of Montreal;Mila,adversarial examples;adversarial training;autoencoders;hidden state,116;116;-1;-1;116;116;136,108;108;-1;-1;108;108;314,-1;-1,NAN,NAN,n,4
2268,ICLR,2019,Better Accuracy with Quantified Privacy: Representations Learned via Reconstructive Adversarial Network,Sicong Liu;Anshumali Shrivastava;Junzhao Du;Lin Zhong,scliu007@gmail.com;anshumali@rice.edu;dujz@xidian.edu.cn;lzhong@rice.edu,4;5;3,4;4;4,Reject,0,3,0.0,yes,9/27/18,Northwestern Polytechnical University;Rice University;Xidian University;Rice University,end-user privacy;utility;feature learning;adversarial training,-1;94;-1;94,-1;86;917;86,-1;-1,australasia,au,n,4
2269,ICLR,2019,Sample-efficient policy learning in multi-agent Reinforcement Learning via meta-learning,Jialian Li;Hang Su;Jun Zhu,lijialian7@163.com;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,4;4;4,3;4;4,Reject,0,0,0.0,yes,9/27/18,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Multi-agent;Reinforcement Learning;Meta-learning,4;4;4,30;30;30,-1;-1,NAN,NAN,n,6
2270,ICLR,2019,UaiNets: From Unsupervised to Active Deep Anomaly Detection,Tiago Pimentel;Marianne Monteiro;Juliano Viana;Adriano Veloso;Nivio Ziviani,tiago.pimentel@kunumi.com;marianne@kunumi.com;juliano@kunumi.com;adrianov@dcc.ufmg.br;nivio@dcc.ufmg.br,4;5;3,4;2;4,Reject,3,4,0.0,yes,9/27/18,Universidade Federal de Minas Gerais;Kunumi;Kunumi;Universidade Federal de Minas Gerais;Universidade Federal de Minas Gerais,Anomaly Detection;Active  Learning;Unsupervised Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2271,ICLR,2019,Differentially Private Federated Learning: A Client Level Perspective,Robin C. Geyer;Tassilo J. Klein;Moin Nabi,geyerr@ethz.ch;tassilo.klein@sap.com;moin.nabi@sap.com,4;4;4,3;4;4,Reject,0,6,0.0,yes,9/27/18,Swiss Federal Institute of Technology;SAP;SAP,Machine Learning;Federated Learning;Privacy;Security;Differential Privacy,-1;285;285,-1;300;300,-1;-1,asia,in,n,4
2272,ICLR,2019,LSH Microbatches for Stochastic Gradients:  Value in Rearrangement,Eliav Buchnik;Edith Cohen;Avinatan Hassidim;Yossi Matias,edith@cohenwang.com;eliavbuh@gmail.com,4;4;4;3,4;3;4;2,Reject,0,5,0.0,yes,9/27/18,Tel Aviv University;Tel Aviv University,Stochastic Gradient Descent;Metric Embeddings;Locality  Sensitive Hashing;Microbatches;Sample coordination,31;31,217;217,-1;-1,europe,il,n,
2273,ICLR,2019,Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning,catalin ionescu;tejas kulkarni;aaron van de oord;andriy mnih;vlad mnih,cdi@google.com;tkulkarni@google.com;avdnoord@google.com;amnih@google.com;vmnih@google.com,4;4;5,3;3;3,Reject,0,6,0.0,yes,9/27/18,Google;Google;Google;Google;Google,exploration;deep reinforcement learning;intrinsic motivation;unsupervised learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2274,ICLR,2019,Large-Scale Study of Curiosity-Driven Learning,Yuri Burda;Harri Edwards;Deepak Pathak;Amos Storkey;Trevor Darrell;Alexei A. Efros,yburda@openai.com;harri@openai.com;pathak@berkeley.edu;a.storkey@ed.ac.uk;trevor@eecs.berkeley.edu;efros@eecs.berkeley.edu,6;9;7,4;5;3,Accept (Poster),0,4,0.0,yes,9/27/18,OpenAI;OpenAI;University of California Berkeley;University of Edinburgh;University of California Berkeley;University of California Berkeley,exploration;curiosity;intrinsic reward;no extrinsic reward;unsupervised;no-reward;skills,-1;-1;-1;36;-1;-1,-1;-1;18;27;18;18,-1;-1,usa,usa,n,
2275,ICLR,2019,Generative Models from the perspective of Continual Learning,Timoth√©e Lesort;Hugo Caselles-Dupr√©;Michael Garcia-Ortiz;Jean-Fran√ßois Goudou;David Filliat,timothee.lesort@thalesgroup.com;caselles@ensta.fr;mgarciaortiz@softbankrobotics.com;jean-francois.goudou@thalesgroup.com;david.filliat@ensta.fr,4;4;5,4;4;3,Reject,0,4,0.0,yes,9/27/18,University of Montreal;ENSTA ParisTech;Softbank Robotics Europe;Thalesgroup;ENSTA ParisTech,Generative Models;Continual Learning,116;-1;-1;-1;-1,108;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
2276,ICLR,2019,Graph Classification with Geometric Scattering,Feng Gao;Guy Wolf;Matthew Hirn,gaofeng2@msu.edu;guy.wolf@yale.edu;mhirn@msu.edu,5;6;5,4;3;4,Reject,0,6,0.0,yes,9/27/18,Michigan State University;Yale University;Michigan State University,geometric deep learning;graph neural network;graph classification;scattering,116;67;116,84;12;84,-1;-1,usa,usa,y,10
2277,ICLR,2019,An investigation of model-free planning,Arthur Guez;Mehdi Mirza;Karol Gregor;Rishabh Kabra;S√©bastien Racani√®re;Th√©ophane Weber;David Raposo;Adam Santoro;Laurent Orseau;Tom Eccles;Greg Wayne;David Silver;Timothy Lillicrap,aguez@google.com;mmirza@google.com;karolg@google.com;rkabra@google.com;sracaniere@google.com;theophane@google.com;draposo@google.com;adamsantoro@google.com;lorseau@google.com;eccles@google.com;gregwayne@google.com;davidsilver@google.com;countzero@google.com,5;5;4,4;3;5,Reject,0,4,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2278,ICLR,2019,Learning What to Remember: Long-term Episodic Memory Networks for Learning from Streaming Data,Hyunwoo Jung;Moonsu Han;Minki Kang;Sungju Hwang,hyunwooj@kaist.ac.kr;mshan92@kaist.ac.kr;zzxc1133@kaist.ac.kr;sjhwang82@kaist.ac.kr,5;4;4,5;4;4,Reject,0,0,3.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Memory Network;Lifelong Learning,-1;-1;-1;-1,95;95;95;95,-1;-1,NAN,NAN,n,
2279,ICLR,2019,Multi-Task Learning for Semantic Parsing with Cross-Domain Sketch,Huan Wang;Yuxiang Hu;Li Dong;Feijun Jiang;Zaiqing Nie,odile.wh@alibaba-inc.com;yuxiang.hyx@alibaba-inc.com;li.dong@ed.ac.uk;feijun.jiangfj@alibaba-inc.com;zaiqing.nzq@alibaba-inc.com,3;4;5,4;4;4,Reject,0,0,4.0,yes,9/27/18,Alibaba Group;Alibaba Group;University of Edinburgh;Alibaba Group;Alibaba Group,semantic parsing;natural language understanding;machine learning,-1;-1;36;-1;-1,-1;-1;27;-1;-1,-1;-1,NAN,NAN,n,8;3
2280,ICLR,2019,GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS,Robert M. Taylor;Yusong Tan,rtaylor@mitre.org;ytan@mitre.org,4;4;3,3;4;5,Reject,0,0,0.0,yes,9/27/18,"Virginia Tech; National University of Defense Technology, China",Bayesian nonparametric;robust;deep neural network;classifier;unsupervised learning;geometric,77;-1,-1;-1,-1;-1,asia,in,n,11;4
2281,ICLR,2019,Overlapping Community Detection with Graph Neural Networks,Oleksandr Shchur;Stephan G√ºnnemann,shchur@in.tum.de;guennemann@in.tum.de,5;3;4,4;5;5,Reject,0,0,0.0,yes,9/27/18,Technical University Munich;Technical University Munich,community detection;deep learning for graphs,-1;-1,-1;-1,-1;-1,NAN,NAN,n,10
2282,ICLR,2019,A Guider Network for Multi-Dual Learning,Wenpeng Hu;Zhengwei Tao;Zhanxing Zhu;Bing Liu;Zhou Lin;Jinwen Ma;Dongyan Zhao;Rui Yan,wenpeng.hu@pku.edu.cn;tttzw@pku.edu.cn;zhanxing.zhu@pku.edu.cn;liub@uic.edu;jokerlin@pku.edu.cn;jwma@math.pku.edu.cn;zhaody@pku.edu.cn;ruiyan@pku.edu.cn,4;5;4,3;2;5,Reject,0,0,0.0,yes,9/27/18,"Peking University;Peking University;Peking University;University of Illinois, Chicago;Peking University;Peking University;Peking University;Peking University",,14;14;14;-1;14;14;14;14,27;27;27;-1;27;27;27;27,-1;-1,asia,cn,n,3
2283,ICLR,2019,Dual Learning: Theoretical Study and Algorithmic Extensions,Zhibing Zhao;Yingce Xia;Tao Qin;Tie-Yan Liu,zhaoz6@rpi.edu;yingce.xia@gmail.com;taoqin@microsoft.com;tyliu@microsoft.com,6;2;5,3;4;3,Reject,0,1,0.0,yes,9/27/18,Rensselaer Polytechnic Institute;Microsoft;Microsoft;Microsoft,machine translation;dual learning,207;-1;-1;-1,304;-1;-1;-1,-1;-1,NAN,NAN,y,3;1
2284,ICLR,2019,Real-time Neural-based Input Method,Jiali Yao;Raphael Shu;Xinjian Li;Katsutoshi Ohtsuki;Hideki Nakayama,jiayao@microsoft.com;shu@nlab.ci.i.u-tokyo.ac.jp;xinjianl@andrew.cmu.edu;katsutoshi.ohtsuki@microsoft.com;nakayama@ci.i.u-tokyo.ac.jp,3;3;3,3;4;3,Reject,0,3,0.0,yes,9/27/18,Microsoft;The University of Tokyo;Carnegie Mellon University;Microsoft;The University of Tokyo,input method;language model;neural network;softmax,-1;59;1;-1;59,-1;45;24;-1;45,-1;-1,NAN,NAN,n,3
2285,ICLR,2019,CHEMICAL NAMES STANDARDIZATION USING NEURAL SEQUENCE TO SEQUENCE MODEL,Junlang Zhan;Hai Zhao,longmr.zhan@sjtu.edu.cn;zhaohai@cs.sjtu.edu.cn,4;3;7,4;5;3,Reject,0,9,0.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Chemical Names Standardization;Byte Pair Encoding;Sequence to Sequence Model,36;36,188;188,-1;-1,asia,cn,n,
2286,ICLR,2019,TabNN: A Universal Neural Network Solution for Tabular Data,Guolin Ke;Jia Zhang;Zhenhui Xu;Jiang Bian;Tie-Yan Liu,guolin.ke@microsoft.com;jia.zhang@microsoft.com;zhenhui.xu@pku.edu.cn;jiang.bian@microsoft.com;tyliu@microsoft.com,5;4;5,4;5;2,Reject,0,6,0.0,yes,9/27/18,Microsoft;Microsoft;Peking University;Microsoft;Microsoft,neural network;machine learning;tabular data,-1;-1;14;-1;-1,-1;-1;27;-1;-1,-1;-1,NAN,NAN,n,10
2287,ICLR,2019,Learning Representations of Categorical Feature Combinations via Self-Attention,Chen Xu;Chengzhen Fu;Peng Jiang;Wenwu Ou,chaos.xc@alibaba-inc.com;fuchengzhen@pku.edu.cn;jiangpeng.jp@alibaba-inc.com;wenwu.ou@alibaba-inc.com,5;5;5,4;3;4,Reject,0,0,0.0,yes,9/27/18,Alibaba Group;Peking University;Alibaba Group;Alibaba Group,Learning Representations;Feature Combinations;Self-Attention,-1;14;-1;-1,-1;27;-1;-1,-1;-1,NAN,NAN,n,8
2288,ICLR,2019,Spatial-Winograd Pruning Enabling Sparse Winograd Convolution,Jiecao Yu;Jongsoo Park;Maxim Naumov,jiecaoyu@umich.edu;jongsoo@fb.com;mnaumov@fb.com,5;4;6,3;3;3,Reject,0,8,0.0,yes,9/27/18,University of Michigan;Facebook;Facebook,deep learning;convolutional neural network;pruning;Winograd convolution,9;-1;-1,21;-1;-1,-1;-1,NAN,NAN,n,
2289,ICLR,2019,Phrase-Based Attentions,Phi Xuan Nguyen;Shafiq Joty,xuanphi001@e.ntu.edu.sg;srjoty@ntu.edu.sg,5;5;5,4;5;5,Reject,0,13,0.0,yes,9/27/18,Nanyang Technological University;Nanyang Technological University,neural machine translation;natural language processing;attention;transformer;seq2seq;phrase-based;phrase;n-gram,44;44,52;52,-1;-1,asia,sg,n,8;3
2290,ICLR,2019,Adaptive Pruning of Neural Language Models for Mobile Devices,Raphael Tang;Jimmy Lin,r33tang@uwaterloo.ca;jimmylin@uwaterloo.ca,6;5;6,4;3;4,Reject,0,5,0.0,yes,9/27/18,University of Waterloo;University of Waterloo,Inference-time pruning;Neural Language Models,31;31,207;207,-1;-1,canada,ca,n,3
2291,ICLR,2019,Total Style Transfer with a Single Feed-Forward Network,Minseong Kim;Hyun-Chul Choi,tyui592@ynu.ac.kr;pogary@ynu.ac.kr,4;5;4,5;5;3,Reject,2,0,0.0,yes,9/27/18,Kyung Hee;Kyung Hee,Image Style Transfer;Deep Learning;Neural Network,419;419,407;407,-1;-1,NAN,NAN,n,8
2292,ICLR,2019,Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms,Taesik Na;Minah Lee;Burhan A. Mudassar;Priyabrata Saha;Jong Hwan Ko;Saibal Mukhopadhyay,taesik.na@gatech.edu;minah.lee@gatech.edu;burhan.mudassar@gatech.edu;priyabratasaha@gatech.edu;jonghwan.ko@gatech.edu;smukhopadhyay6@gatech.edu,3;4;4,4;5;4,Reject,0,3,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,noise robust;object detection,13;13;13;13;13;13,33;33;33;33;33;33,-1;-1,usa,usa,n,2;4
2293,ICLR,2019,Multi-Scale Stacked Hourglass Network for Human Pose Estimation,Chunsheng Guo;Wenlong Du;Na Ying,guo.chsh@gmail.com;dwl1993@hdu.edu.cn;yingna@hdu.edu.cn,3;4;3,5;4;5,Reject,3,0,0.0,yes,9/27/18,Shandong University;Shandong University;Shandong University,Human pose estimation;Hourglass network;Multi-scale analysis,-1;136;136,-1;569;569,-1;-1,asia,cn,n,2
2294,ICLR,2019,A quantifiable testing of global translational invariance in Convolutional and Capsule Networks,Weikai Qi,wikaiqi@gmail.com,3;4;3,5;4;5,Reject,0,0,0.0,yes,9/27/18,0,Translational invariance;CNN;Capsule Network,,,-1,NAN,NAN,n,
2295,ICLR,2019,Multiple Encoder-Decoders Net for Lane Detection,Yuetong Du;Xiaodong Gu;Junqin Liu;Liwen He,1239832590@qq.com;gu3xuan@qq.com;65581134@qq.com;helw@njupt.edu.cn,2;2;4,4;5;4,Reject,0,0,0.0,yes,9/27/18,Chinese University of Hong Kong;;;University of Science and Technology of China,,-1;-1;-1;-1,-1;-1;-1;132,-1;-1,NAN,NAN,n,2
2296,ICLR,2019,Unsupervised Video-to-Video Translation,Dina Bashkirova;Ben Usman;Kate Saenko,dbash@bu.edu;usmn@bu.edu;saenko@bu.edu,3;4;4,4;5;5,Reject,0,0,0.0,yes,9/27/18,Boston University;Boston University;Boston University,Generative Adversarial Networks;Computer Vision;Deep Learning,77;77;77,70;70;70,-1;-1,europe,it,n,2
2297,ICLR,2019,Generative model based on minimizing exact empirical Wasserstein distance,Akihiro Iohara;Takahito Ogawa;Toshiyuki Tanaka,iohara@sys.i.kyoto-u.ac.jp;takahito.ogawa@datagrid.co.jp;tt@i.kyoto-u.ac.jp,5;2;3,2;5;4,Reject,0,0,1.0,yes,9/27/18,Kyoto University;DataGrid Inc.;Kyoto University,Generative modeling;Generative Adversarial Networks (GANs);Wasserstein GAN;Optimal transport,136;-1;136,74;-1;74,-1;-1,europe,fi,y,5;4
2298,ICLR,2019,Deli-Fisher GAN: Stable and Efficient Image Generation With Structured Latent Generative Space,Boli Fang;Chuck Jia;Miao Jiang;Dhawal Chaturvedi,bfang@iu.edu;jiac@iu.edu;miajiang@iu.edu;dhchat@iu.edu,2;2;3,4;5;5,Reject,0,1,0.0,yes,9/27/18,"Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington",Generative Adversarial Networks;Structured Latent Space;Stable Training,67;67;67;67,117;117;117;117,-1;-1,NAN,NAN,n,5;4
2299,ICLR,2019,Stacking for Transfer Learning,Peng Yuankai,pyk3350266@163.com,3;4;2,5;5;5,Reject,0,0,0.0,yes,9/27/18,163,data diversiÔ¨Åcation;domain adaptation;transfer learning;stacked generalization,-1,-1,-1,asia,in,n,6;1
2300,ICLR,2019,Graph Spectral Regularization For Neural Network Interpretability,Alexander Tong;David van Dijk;Jay Stanley;Guy Wolf;Smita Krishnaswamy,alexander.tong@yale.edu;david.vandijk@yale.edu;jay.stanley@yale.edu;guy.wolf@yale.edu;smita.krishnaswamy@yale.edu,4;3;4,4;5;3,Reject,0,0,0.0,yes,9/27/18,Yale University;Yale University;Yale University;Yale University;Yale University,autoencoder;interpretable;graph signal processing;graph spectrum;graph filter;capsule,67;67;67;67;67,12;12;12;12;12,-1;-1,europe,fi,n,10
2301,ICLR,2019,RETHINKING SELF-DRIVING : MULTI -TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATION ABILITY,Zhihao LI;Toshiyuki MOTOYOSHI;Kazuma SASAKI;Tetsuya OGATA;Shigeki SUGANO,mr.zhihao.li@gmail.com;motoyoshi@idr.ias.sci.waseda.ac.jp;ssk.sasaki@suou.waseda.jp;ogata@waseda.jp;sugano@waseda.jp,4;4;3,4;5;4,Reject,2,0,0.0,yes,9/27/18,Facebook;Meiji University;Waseda University;Waseda University;Waseda University,Autonomous car;convolution network;image segmentation;depth estimation;generalization ability;explanation ability;multi-task learning,-1;-1;285;285;285,-1;978;642;642;642,-1;-1,asia,jp,n,2;1
2302,ICLR,2019,Normalization Gradients are Least-squares Residuals,Yi Liu,liu.yi.pei@gmail.com,4;4;3,5;4;4,Reject,0,3,0.0,yes,9/27/18,0,Deep Learning;Normalization;Least squares;Gradient regression,,,-1,NAN,NAN,y,
2303,ICLR,2019,Task-GAN for Improved GAN based Image Restoration,Jiahong Ouyang;Guanhua Wang;Enhao Gong;Kevin Chen;John Pauly and Greg Zaharchuk,jiahongo@stanford.edu;guanhua@stanford.edu;enhaog@stanford.edu;ktchen@stanford.edu;pauly@stanford.edu;gregz@stanford.edu,4;5;4,5;4;5,Reject,0,0,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Task-GAN: Improving Generative Adversarial Network for Image Restoration,4;4;4;4;4;4,3;3;3;3;3;3,-1;-1,usa,usa,n,2;5;4
2304,ICLR,2019,Morpho-MNIST: Quantitative Assessment and Diagnostics for Representation Learning,Daniel C. Castro;Jeremy Tan;Bernhard Kainz;Ender Konukoglu;Ben Glocker,d.coelho-de-castro15@imperial.ac.uk;j.tan17@imperial.ac.uk;b.kainz@imperial.ac.uk;kender@vision.ee.ethz.ch;b.glocker@imperial.ac.uk,3;5;4,4;3;3,Reject,0,5,0.0,yes,9/27/18,Imperial College London;Imperial College London;Imperial College London;Swiss Federal Institute of Technology;Imperial College London,quantitative evaluation;diagnostics;generative models;representation learning;morphometrics;image perturbations,47;47;47;-1;47,8;8;8;-1;8,-1;-1,europe,uk,n,5;4
2305,ICLR,2019,Small steps and giant leaps: Minimal Newton solvers for Deep Learning,Joao Henriques;Sebastien Ehrhardt;Samuel Albanie;Andrea Vedaldi,joao@robots.ox.ac.uk;hyenal@robots.ox.ac.uk;albanie@robots.ox.ac.uk;vedali@robots.ox.ac.uk,7;3;7,5;5;4,Reject,0,11,1.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford;University of Oxford,deep learning,44;44;44;44,1;1;1;1,-1;-1,europe,uk,n,
2306,ICLR,2019,Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction,Simon Odense;Artur d'Avila Garcez,simon.odense@city.ac.uk;a.garcez@city.ac.uk,4;4;4;5,2;5;4;3,Reject,0,4,0.0,yes,9/27/18,"City, University of London;City, University of London",Deep Networks;Explainability;Knowledge Extraction,285;285,373;373,-1;-1,europe,uk,n,
2307,ICLR,2019,When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?,Tengyu Xu;Yi Zhou;Kaiyi Ji;Yingbin Liang,xu.3260@osu.edu;zhou.1172@osu.edu;ji.367@osu.edu;liang.889@osu.edu,5;4;5,5;3;4,Reject,0,0,0.0,yes,9/27/18,Ohio State University;Ohio State University;Ohio State University;Ohio State University,gradient method;max-margin;ReLU model,59;59;59;59,70;70;70;70,-1;-1,usa,usa,y,
2308,ICLR,2019,A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING,Hichem Mezaoui;Isar Nejadgholi,hichem@imrsv.ai;isar@imrsv.ai,3;3;3,3;3;4,Reject,0,0,1.0,yes,9/27/18,"IMRSV Data Labs;National Research Council, Canada",sentence embedding;generative models,-1;-1,-1;-1,-1;-1,asia,in,n,
2309,ICLR,2019,The loss landscape of overparameterized neural networks,Y. Cooper,yaim@math.ias.edu,5;7;5,4;3;4,Reject,0,16,0.0,yes,9/27/18,"Institue for Advanced Study, Princeton",,-1,-1,-1,NAN,NAN,y,1
2310,ICLR,2019,Stop memorizing: A data-dependent regularization framework for intrinsic pattern learning,Wei Zhu;Qiang Qiu;Bao Wang;Jianfeng Lu;Guillermo Sapiro;Ingrid Daubechies,zhu@math.duke.edu;qiang.qiu@duke.edu;wangbao@math.ucla.edu;jianfeng@math.duke.edu;guillermo.sapiro@duke.edu;ingrid@math.duke.edu,7;4;4,4;3;4,Reject,0,4,0.0,yes,9/27/18,"Duke University;Duke University;University of California, Los Angeles;Duke University;Duke University;Duke University",deep neural networks;memorizing;data-dependent regularization,47;47;-1;47;47;47,17;17;15;17;17;17,-1;-1,europe,se,y,
2311,ICLR,2019,Neural Variational Inference For Embedding Knowledge Graphs,Alexander I. Cowen-Rivers;Pasquale Minervini,mc_rivers@icloud.com;p.minervini@ucl.ac.uk,5;5;4,3;5;3,Reject,0,7,0.0,yes,9/27/18,Icloud;University College London,Statistical Relational Learning;Knowledge Graphs;Knowledge Extraction;Latent Feature Models;Variational Inference.,-1;50,-1;-1,-1;-1,europe,uk,n,10;5
2312,ICLR,2019,Learning Implicit Generative Models by Teaching Explicit Ones,Chao Du;Kun Xu;Chongxuan Li;Jun Zhu;Bo Zhang,duchao0726@gmail.com;kunxu.thu@gmail.com;chongxuanli1991@gmail.com;dcszj@tsinghua.edu.cn;dcszb@tsinghua.edu.cn,6;7;5,4;3;4,Reject,0,6,0.0,yes,9/27/18,"Alibaba Group;;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",,-1;-1;-1;4;4,-1;-1;-1;30;30,-1;-1,NAN,NAN,n,5;4
2313,ICLR,2019,"The GAN Landscape: Losses, Architectures, Regularization, and Normalization",Karol Kurach;Mario Lucic;Xiaohua Zhai;Marcin Michalski;Sylvain Gelly,kkurach@gmail.com;lucic@google.com;xzhai@google.com;michalski@google.com;sylvain.gelly@gmail.com,4;4;7,3;2;4,Reject,0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google,GANs;empirical evaluation;large-scale;reproducibility,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2314,ICLR,2019,PAIRWISE AUGMENTED GANS WITH ADVERSARIAL RECONSTRUCTION LOSS,Aibek Alanov;Max Kochurov;Daniil Yashkov;Dmitry Vetrov,alanov.aibek@gmail.com;maxim.v.kochurov@gmail.com;daniil.yashkov@phystech.edu;vetrodim@gmail.com,6;4;5,4;3;4,Reject,0,5,0.0,yes,9/27/18,Higher School of Economics;;Moscow Institute of Physics and Technology;Higher School of Economics,Computer vision;Deep learning;Unsupervised Learning;Generative Adversarial Networks,-1;-1;-1;-1,-1;-1;254;-1,-1;-1,NAN,NAN,y,5;4
2315,ICLR,2019,Improving Sample-based Evaluation for Generative Adversarial Networks,Shaohui Liu*;Yi Wei*;Jiwen Lu;Jie Zhou,b1ueber2y@gmail.com;wei-y15@mails.tsinghua.edu.cn;lujiwen@tsinghua.edu.cn;jzhou@tsinghua.edu.cn,5;5;3,3;4;5,Reject,0,1,0.0,yes,9/27/18,"ETH Zürich;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",,-1;4;4;4,-1;30;30;30,-1;-1,NAN,NAN,n,5;4
2316,ICLR,2019,Tinkering with black boxes: counterfactuals uncover modularity in generative models,Michel Besserve;Remy Sun;Bernhard Schoelkopf,michel.besserve@tuebingen.mpg.de;remy.sun@ens-rennes.fr;bs@tuebingen.mpg.de,4;6;4,5;3;4,Reject,0,3,0.0,yes,9/27/18,Max-Planck Institute;Ecole Normale Superieure de Rennes;Max-Planck Institute,generatice models;causality;disentangled representations,-1;419;-1,-1;-1;-1,-1;-1,NAN,NAN,y,5;4
2317,ICLR,2019,Deep Generative Models for learning Coherent Latent Representations from Multi-Modal Data,Timo Korthals;Marc Hesse;J√ºrgen Leitner,korthals.timo@gmail.com;mhesse@cit-ec.uni-bielefeld.de;juxi.leitner@gmail.com,4;4;4,2;3;4,Reject,0,6,0.0,yes,9/27/18,"Bielefeld University, CITEC;Bielefeld University;South China University of Technology",Multi-Modal Deep Generative Models;Sensor Fusion;Data Generation;VAE,285;285;-1,288;288;576,-1;-1,NAN,NAN,n,5
2318,ICLR,2019,Mol-CycleGAN - a generative model for molecular optimization,≈Åukasz Maziarka;Agnieszka Pocha;Jan Kaczmarczyk;Micha≈Ç Warcho≈Ç,l.maziarka@gmail.com;lamiane.chan@gmail.com;jan.kaczmarczyk@ardigen.com;michal.warchol@ardigen.com,4;4;4,5;4;3,Reject,0,0,0.0,yes,9/27/18,Ardigen;;Ardigen;Ardigen,generative adversarial networks;drug design;deep learning;molecule optimization,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
2319,ICLR,2019,Effective and Efficient Batch Normalization Using Few Uncorrelated Data for Statistics' Estimation,Zhaodong Chen;Lei Deng;Guoqi Li;Jiawei Sun;Xing Hu;Ling Liang;YufeiDing;Yuan Xie,chenzd15@mails.tsinghua.edu.cn;leideng@ucsb.edu;liguoqi@mail.tsinghua.edu.cn;sunjw15@mails.tsinghua.edu.cn;xinghu@ucsb.edu;lingliang@ucsb.edu;yufeiding@cs.ucsb.edu;yuanxie@ucsb.edu,5;4;5,5;3;3,Reject,0,5,0.0,yes,9/27/18,"Tsinghua University, Tsinghua University;UC Santa Barbara;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara",batch normalization;acceleration;correlation;sampling,4;-1;4;4;-1;-1;-1;-1,30;-1;30;30;-1;-1;-1;-1,-1;-1,NAN,NAN,n,9
2320,ICLR,2019,Contextual Recurrent Convolutional Model for Robust Visual Learning,Siming Yan*;Bowen Xiao*;Yimeng Zhang;Tai Sing Lee,simingyan@pku.edu.cn;mike.xiao@pku.edu.cn;zym1010@gmail.com;taislee@andrew.cmu.edu,4;3;4,4;5;5,Reject,0,5,0.0,yes,9/27/18,Peking University;Peking University;Pinterest;Carnegie Mellon University,contextual modulation;recurrent convolutional network;robust visual learning,14;14;-1;1,27;27;-1;24,-1;-1,usa,usa,n,2
2321,ICLR,2019,A unified theory of adaptive stochastic gradient descent as Bayesian filtering,Laurence Aitchison,laurence.aitchison@gmail.com,5;5;7,3;4;4,Reject,0,29,0.0,yes,9/27/18,University of Bristol,SGD;Bayesian;RMSprop;Adam,94,76,-1,europe,uk,n,11
2322,ICLR,2019,MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION,Mingwei Wei;James Stokes;David J Schwab,m.wei@u.northwestern.edu;james@tunnel.tech;dschwab@gc.cuny.edu,7;6;5,3;3;3,Reject,0,6,0.0,yes,9/27/18,Northwestern University;;The City University of New York,neural networks;optimization;batch normalization;mean field theory;Fisher information,50;-1;-1,20;-1;-1,-1;-1,NAN,NAN,y,1
2323,ICLR,2019,Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout,Kun Wan;Boyuan Feng;Lingwei Xie;Yufei Ding,kun@cs.ucsb.edu;boyuan@cs.ucsb.edu;xielingwei@stu.xmu.edu.cn;yufeiding@cs.ucsb.edu,5;3;4,4;3;4,Reject,0,0,0.0,yes,9/27/18,UC Santa Barbara;UC Santa Barbara;Xiamen University;UC Santa Barbara,Specialized dropout;computer vision,-1;-1;-1;-1,-1;-1;490;-1,-1;-1,NAN,NAN,n,
2324,ICLR,2019,PCNN: Environment Adaptive Model Without Finetuning,Boyuan Feng;Kun Wan;Shu Yang;Yufei Ding,boyuan@cs.ucsb.edu;kun@cs.ucsb.edu;shuyang1995@ucsb.edu;yufeiding@cs.ucsb.edu,4;3;4,4;4;4,Reject,1,3,0.0,yes,9/27/18,UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara,Class skew;Runtime adaption,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;2
2325,ICLR,2019,ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE,Liangbo He;Hao Sun,heliangbo@tsinghua.edu.cn;sh759811581@tsinghua.edu.cn,3;4;2,5;4;4,Reject,0,0,0.0,yes,9/27/18,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",attention mechanism;various image size,4;4,30;30,-1;-1,NAN,NAN,n,8
2326,ICLR,2019,What a difference a pixel makes: An empirical examination of features used by CNNs for categorisation,Gaurav Malhotra;Jeffrey Bowers,gaurav.malhotra@bristol.ac.uk;j.bowers@bristol.ac.uk,4;4;7,4;4;5,Reject,1,12,0.0,yes,9/27/18,University of Bristol;University of Bristol,deep learning;shape bias;vision;feature selection,94;94,76;76,-1;-1,europe,uk,n,
2327,ICLR,2019,Trace-back along capsules and its application on semantic segmentation  		,Tao Sun;Zhewei Wang;C. D. Smith;Jundong Liu,zw340113@ohio.edu;ts202115@ohio.edu;cdsmith.uk@gmail.com;liuj1@ohio.edu,6;6;5,4;3;4,Reject,0,12,0.0,yes,9/27/18,Ohio University;Ohio University;;Ohio University,capsule;capsule network;semantic segmentation;FCN,285;285;-1;285,627;627;-1;627,-1;-1,asia,jp,n,2
2328,ICLR,2019,"Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs",Peter Sadowski;Pierre Baldi,peter.sadowski@hawaii.edu;pfbaldi@ics.uci.edu,3;3;4,4;5;4,Reject,1,1,0.0,yes,9/27/18,"University of Hawaii, Manoa;University of California, Irvine",regression;uncertainty;deep learning,-1;-1,-1;99,-1;-1,usa,usa,n,
2329,ICLR,2019,Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding,Ga Wu;Justin Domke;Scott Sanner,wuga@mie.utoronto.ca;domke@cs.umass.edu;ssanner@mie.utoronto.ca,4;4;4,4;4;5,Reject,0,2,0.0,yes,9/27/18,"Toronto University;University of Massachusetts, Amherst;Toronto University",,-1;27;-1,-1;191;-1,-1;-1,NAN,NAN,y,5
2330,ICLR,2019,Neural Rendering Model: Joint Generation and Prediction for Semi-Supervised Learning,Nhat Ho;Tan Nguyen;Ankit B. Patel;Anima Anandkumar;Michael I. Jordan;Richard G. Baraniuk,minhnhat@berkeley.edu;mn15@rice.edu;ankit.patel@bcm.edu;anima@caltech.edu;jordan@cs.berkeley.edu;richb@rice.edu,5;5;3,3;3;4,Reject,0,8,0.0,yes,9/27/18,University of California Berkeley;Rice University;Baylor College of Medicine;California Institute of Technology;University of California Berkeley;Rice University,neural nets;generative models;semi-supervised learning;cross-entropy,-1;94;-1;136;-1;94,18;86;-1;3;18;86,-1;-1,australasia,au,y,1;5
2331,ICLR,2019,Modular Deep Probabilistic Programming,Zhenwen Dai;Eric Meissner;Neil D. Lawrence,zhenwend@amazon.com;erimeiss@amazon.com;lawrennd@amazon.com,5;3;4,3;3;4,Reject,1,4,0.0,yes,9/27/18,Amazon;Amazon;Amazon,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11
2332,ICLR,2019,Asynchronous SGD without gradient delay for efficient distributed training,Roman Talyansky;Pavel Kisilev;Zach Melamed;Natan Peterfreund;Uri Verner,roma.talyansky@gmail.com;pavel.kisilev@huawei.com;zach.melamed@huawei.com;natan.peterfreund@gmail.com;uri.verner@gmail.com,5;4;4,4;4;5,Reject,0,0,0.0,yes,9/27/18,Amazon;Huawei Technologies Ltd.;Huawei Technologies Ltd.;;NVIDIA,SGD;distributed asynchronous training;deep learning;optimisation,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,asia,in,y,9
2333,ICLR,2019,EnGAN: Latent Space MCMC and Maximum Entropy Generators for Energy-based Models,Rithesh Kumar;Anirudh Goyal;Aaron Courville;Yoshua Bengio,ritheshkumar.95@gmail.com;anirudhgoyal9119@gmail.com;aaron.courville@gmail.com;yoshua.umontreal@gmail.com,6;5;5,4;5;4,Reject,4,13,0.0,yes,9/27/18,Descript;;University of Montreal;University of Montreal,Energy based model;Generative models;MCMC;GANs,-1;-1;116;116,-1;-1;108;108,-1;-1,canada,ca,n,5;4
2334,ICLR,2019,Variational recurrent models for representation learning,Qingming Tang;Mingda Chen;Weiran Wang;Karen Livescu,qmtang@ttic.edu;mchen@ttic.edu;weiranw@amazon.com;klivescu@ttic.edu,5;5;3,3;3;5,Reject,0,3,2.0,yes,9/27/18,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Amazon;Toyota Technological Institute at Chicago,Representation learning;variational model,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5
2335,ICLR,2019,HR-TD: A Regularized TD Method to Avoid Over-Generalization,Ishan Durugkar;Bo Liu;Peter Stone,ishand@cs.utexas.edu;liubo19831214@gmail.com;pstone@cs.utexas.edu,4;3;2,4;4;5,Reject,0,0,0.0,yes,9/27/18,"University of Texas, Austin;Auburn University;University of Texas, Austin",Reinforcement Learning;TD Learning;Deep Learning,-1;419;-1,-1;652;-1,-1;-1,usa,usa,n,1;10
2336,ICLR,2019,Discovering General-Purpose Active Learning Strategies,Ksenia Konyushkova;Raphael Sznitman;Pascal Fua,ksenia.konyushkova@epfl.ch;raphael.sznitman@artorg.unibe.ch;pascal.fua@epfl.ch,5;4;4;4,4;5;5;4,Reject,0,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;University of Bern;Swiss Federal Institute of Technology Lausanne,active learning;meta learning;reinforcement learning,-1;285;-1,-1;105;-1,-1;-1,NAN,NAN,n,
2337,ICLR,2019,Multi-Objective Value Iteration with Parameterized Threshold-Based Safety Constraints,Hussein Sibai;Sayan Mitra,sibai2@illinois.edu;mitras@illinois.edu,5;5;3,4;2;4,Reject,0,5,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",reinforcement learning;Markov decision processes;safety constraints;multi-objective optimization;geometric analysis,-1;-1,-1;-1,-1;-1,usa,usa,y,
2338,ICLR,2019,Optimizing for Generalization in Machine Learning with Cross-Validation Gradients,Barratt;Shane;Sharma;Rishi,sbarratt@stanford.edu;rsh@stanford.edu,5;2;4,5;4;4,Reject,1,0,0.0,yes,9/27/18,Stanford University;Stanford University,,4;4,3;3,-1;-1,usa,usa,n,1
2339,ICLR,2019,FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE,Masanori Yamada;Kim Heecheol;Kosuke Miyoshi;Hiroshi Yamakawa,yamada0224@gmail.com;h-kim@isi.imi.i.u-tokyo.ac.jp;miyoshi@narr.jp;hiroshi_yamakawa@dwango.co.jp,5;6;4,4;5;4,Reject,0,7,0.0,yes,9/27/18,NTT;The University of Tokyo;;International Aeronautical Federation,disentangled representation learning,207;59;-1;-1,-1;45;-1;-1,-1;-1,asia,in,n,5
2340,ICLR,2019,Learning Partially Observed PDE Dynamics with Neural Networks,Ibrahim Ayed;Emmanuel De B√©zenac;Arthur Pajot;Patrick Gallinari,ayedibrahim@gmail.com;emmanuel.de-bezenac@lip6.fr;arthur.pajot@lip6.fr;patrick.gallinari@lip6.fr,6;5;5,3;5;3,Reject,0,6,0.0,yes,9/27/18,LIP6;LIP6;LIP6;LIP6,deep learning;spatio-temporal dynamics;physical processes;differential equations;dynamical systems,419;419;419;419,-1;-1;-1;-1,-1;-1,asia,ir,n,
2341,ICLR,2019,Weak contraction mapping and optimization,Siwei Luo,siuluosiwei@gmail.com,3;1;4,2;5;5,Reject,0,4,0.0,yes,9/27/18,"University of Illinois, Chicago",Weak contraction mapping;fixed-point theorem;non-convex optimization,-1,-1,-1,usa,usa,n,9
2342,ICLR,2019,Riemannian Stochastic Gradient Descent for Tensor-Train Recurrent Neural Networks,Jun Qi;Chin-Hui Lee;Javier Tejedor,jqi41@gatech.edu;qij13@uw.edu;javiertejedornoguerales@gmail.com,4;4;3,4;4;3,Reject,0,0,0.0,yes,9/27/18,"Georgia Institute of Technology;University of Washington, Seattle;Universidad CEU San Pablo",Riemannian Stochastic Gradient Descent;Tensor-Train;Recurrent Neural Networks,13;10;-1,33;25;-1,-1;-1,asia,in,y,8;3
2343,ICLR,2019,Unseen Action Recognition with Unpaired Adversarial Multimodal Learning,AJ Piergiovanni;Michael S. Ryoo,ajpiergi@indiana.edu;mryoo@indiana.edu,7;5;4,4;4;5,Reject,0,3,0.0,yes,9/27/18,Indiana University;Indiana University,,67;67,117;117,-1;-1,usa,usa,n,6;4
2344,ICLR,2019,Unlabeled Disentangling of GANs with Guided Siamese Networks,G√∂khan Yildirim;Nikolay Jetchev;Urs Bergmann,gokhan.yildirim@zalando.de;nikolay.jetchev@zalando.de;urs.bergmann@zalando.de,5;6;6;5,4;4;3;4,Reject,0,11,1.0,yes,9/27/18,Zalando SE;Zalando SE;Zalando SE,GAN;disentange;siamese networks;semantic,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
2345,ICLR,2019,Local Image-to-Image Translation via Pixel-wise Highway Adaptive Instance Normalization,Wonwoong Cho;Seunghwan Choi;Junwoo Park;David Keetae Park;Tao Qin;Jaegul Choo,tyflehd21@korea.ac.kr;shadow2496@korea.ac.kr;skp.1003874@sk.com;heykeetae@gmail.com;taotsin@msn.com;jchoo@korea.ac.kr,5;6;5,4;4;5,Reject,0,6,2.0,yes,9/27/18,Korea University;Korea University;SK Telecom;;;Korea University,image to image translation;image translation;exemplar;mutlimodal,169;169;-1;-1;-1;169,244;244;-1;-1;-1;244,-1;-1,asia,kr,n,2
2346,ICLR,2019,Empirically Characterizing Overparameterization Impact on Convergence,Newsha Ardalani;Joel Hestness;Gregory Diamos,newsha@baidu.com;joel@baidu.com;gregdiamos@baidu.com,5;4;3,3;5;4,Reject,0,0,0.0,yes,9/27/18,Baidu;Baidu;Baidu,gradient descent;optimization;convergence time;halting time;characterization,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2347,ICLR,2019,A Biologically Inspired Visual Working Memory for Deep Networks,Ethan Harris;Mahesan Niranjan;Jonathon Hare,ewah1g13@ecs.soton.ac.uk;mn@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk,9;4;5,5;4;4,Reject,0,5,0.0,yes,9/27/18,University of Southampton;University of Southampton;University of Southampton,memory;visual attention;image classification;image reconstruction;latent representations,207;207;207,126;126;126,-1;-1,europe,uk,n,8
2348,ICLR,2019,Using GANs for Generation of Realistic City-Scale Ride Sharing/Hailing Data Sets,Abhinav Jauhri;Brad Stocks;Jian Hui Li;Koichi Yamada;John Paul Shen,ajauhri@cmu.edu;brad.stocks@sv.cmu.edu;jian.hui.li@intel.com;koichi.yamada@intel.com;jpshen@cmu.edu,4;5;5,4;4;4,Reject,0,4,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Intel;Intel;Carnegie Mellon University,ride-sharing;generative modeling;parallelization;application,1;1;-1;-1;1,24;24;-1;-1;24,-1;-1,usa,usa,n,5;4
2349,ICLR,2019,Pushing the bounds of dropout,G√°bor Melis;Charles Blundell;Tom√°≈° Koƒçisk√Ω;Karl Moritz Hermann;Chris Dyer;Phil Blunsom,melisgl@google.com;cblundell@google.com;tkocisky@google.com;kmh@google.com;cdyer@google.com;pblunsom@google.com,5;5;4,3;2;3,Reject,0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;1
2350,ICLR,2019,Traditional and Heavy Tailed Self Regularization in Neural Network Models,Charles H. Martin;Michael W. Mahoney,charles@calculationconsulting.com;mmahoney@stat.berkeley.edu,4;4;6,4;1;5,Reject,0,11,0.0,yes,9/27/18,Calculationconsulting;University of California Berkeley,statistical mechanics;self-regularization;random matrix;glassy behavior;heavy-tailed,-1;-1,-1;18,-1;-1,usa,usa,n,1
2351,ICLR,2019,ISA-VAE: Independent Subspace Analysis with Variational Autoencoders,Jan St√ºhmer;Richard Turner;Sebastian Nowozin,t-jastuh@microsoft.com;ret26@cam.ac.uk;senowozi@microsoft.com,4;7;4,3;4;5,Reject,0,3,0.0,yes,9/27/18,Microsoft;University of Cambridge;Microsoft,representation learning;disentanglement;interpretability;variational autoencoders,-1;77;-1,-1;2;-1,-1;-1,NAN,NAN,n,5
2352,ICLR,2019,Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross Entropy,Haoyu Fu;Yuejie Chi;Yingbin Liang,fu.436@osu.edu;yuejiechi@cmu.edu;liang.889@osu.edu,3;4;5,4;4;4,Reject,0,0,0.0,yes,9/27/18,Ohio State University;Carnegie Mellon University;Ohio State University,cross entropy;neural networks;parameter recovery,59;1;59,70;24;70,-1;-1,usa,usa,y,1;9
2353,ICLR,2019,Metropolis-Hastings view on variational inference and adversarial training,Kirill Neklyudov;Dmitry Vetrov,k.necludov@gmail.com;vetrodim@gmail.com,6;9;5,4;4;3,Reject,0,10,0.0,yes,9/27/18,University of Amsterdam;Higher School of Economics,MCMC;GANs;Variational Inference,136;-1,59;-1,-1;-1,NAN,NAN,y,11;1;5;4
2354,ICLR,2019,Open-Ended Content-Style Recombination Via Leakage Filtering,Karl Ridgeway;Michael C. Mozer,karl.ridgeway@colorado.edu;mozer@colorado.edu,5;7;5,4;4;3,Reject,0,3,0.0,yes,9/27/18,"University of Colorado, Boulder;University of Colorado, Boulder",,59;59,100;100,-1;-1,usa,usa,n,6;5
2355,ICLR,2019,VHEGAN: Variational Hetero-Encoder Randomized GAN for Zero-Shot Learning,Hao Zhang;Bo Chen;Long Tian;Zhengjue Wang;Mingyuan Zhou,zhanghao_xidian@163.com;bchen@mail.xidian.edu.cn;zhengjuewang@163.com;tianlong_xidian@163.com;mingyuan.zhou@mccombs.utexas.edu,5;5;5,4;5;5,Reject,1,4,0.0,yes,9/27/18,"163;Xidian University;163;163;University of Texas, Austin",Deep generative models;deep topic modeling;generative adversarial learning;variational encoder;zero-short learning,-1;-1;-1;-1;-1,-1;917;-1;-1;-1,m;m,usa,usa,n,6;5;4
2356,ICLR,2019,$A^*$ sampling with probability matching,Yichi Zhou;Jun Zhu,vofhqn@gmail.com;dcszj@mail.tsinghua.edu.cn,5;6;3,5;2;5,Reject,0,0,0.0,yes,9/27/18,"Microsoft;Tsinghua University, Tsinghua University",,-1;4,-1;30,-1;-1,NAN,NAN,y,1
2357,ICLR,2019,Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN,Fangzhou Luo;Xiaolin Wu,fluo1993@gmail.com;xwu510@gmail.com,4;4;6,5;5;4,Reject,0,4,0.0,yes,9/27/18,McMaster University;McMaster University,,419;-1,78;-1,-1;-1,asia,in,n,5;4
2358,ICLR,2019,Ada-Boundary: Accelerating the DNN Training via Adaptive Boundary Batch Selection,Hwanjun Song;Sundong Kim;Minseok Kim;Jae-Gil Lee,songhwanjun@kaist.ac.kr;sundong.kim@kaist.ac.kr;minseokkim@kaist.ac.kr;jaegil@kaist.ac.kr,5;5;5,4;3;4,Reject,0,8,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,acceleration;batch selection;convergence;decision boundary,-1;-1;-1;-1,95;95;95;95,-1;-1,NAN,NAN,n,
2359,ICLR,2019,A Resizable Mini-batch Gradient Descent based on a Multi-Armed Bandit,Seong Jin Cho;Sunghun Kang;Chang D. Yoo,ipcng00@kaist.ac.kr;sunghun.kang@kaist.ac.kr;cd_yoo@kaist.ac.kr,6;7;4,3;4;4,Reject,0,4,1.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Batch size;Optimization;Mini-batch gradient descent;Multi-armed bandit,-1;-1;-1,95;95;95,-1;-1,NAN,NAN,y,
2360,ICLR,2019,Neural Network Cost Landscapes as Quantum States,Abdulah Fawaz;Sebastien Piat;Paul Klein;Peter Mountney;Simone Severini,abdulah.fawaz.14@ucl.ac.uk;sebastien.piat@siemens-healthineers.com;klein.paul@siemens-healthineers.com;peter.mountney@siemens-healthineers.com;s.severini@ucl.ac.uk,5;3;4,5;4;4,Reject,0,4,0.0,yes,9/27/18,University College London;Siemens Healthineers;Siemens Healthineers;Siemens Healthineers;University College London,quantum;neural networks;meta-learning,50;-1;-1;-1;50,-1;-1;-1;-1;-1,-1;-1,europe,uk,n,
2361,ICLR,2019,Over-parameterization Improves Generalization in the XOR Detection Problem,Alon Brutzkus;Amir Globerson,brutzkus@gmail.com;amir.globerson@gmail.com,5;4;5,4;4;4,Reject,0,5,0.0,yes,9/27/18,Tel Aviv University;Tel Aviv University,deep learning;theory;non convex optimization;over-parameterization,31;31,217;217,-1;-1,europe,il,y,1
2362,ICLR,2019,On the effect of the activation function on the distribution of hidden nodes in a deep network,Philip M. Long and Hanie Sedghi,plong@google.com;hsedghi@google.com,4;4;5,3;3;3,Reject,0,3,0.0,yes,9/27/18,Google;Google,theory;length map;initialization,-1;-1,-1;-1,m;f,NAN,NAN,y,1
2363,ICLR,2019,INFORMATION MAXIMIZATION AUTO-ENCODING,Dejiao Zhang;Tianchen Zhao;Laura Balzano,dejiao@umich.edu;ericolon@umich.edu;girasole@umich.edu,5;6;4,5;4;4,Reject,0,17,0.0,yes,9/27/18,University of Michigan;University of Michigan;University of Michigan,Information maximization;unsupervised learning of hybrid of discrete and continuous representations,9;9;9,21;21;21,-1;-1,usa,usa,y,5
2364,ICLR,2019,Infinitely Deep Infinite-Width Networks,Jovana Mitrovic;Peter Wirnsberger;Charles Blundell;Dino Sejdinovic;Yee Whye Teh,jovana.mitrovic@spc.ox.ac.uk;pewi@google.com;cblundell@google.com;dino.sejdinovic@stats.ox.ac.uk;ywteh@google.com,6;5;6,4;4;2,Reject,0,6,0.0,yes,9/27/18,University of Oxford;Google;Google;University of Oxford;Google,Infinite-width networks;initialisation;kernel methods;reproducing kernel Hilbert spaces;Gaussian processes,44;-1;-1;44;-1,1;-1;-1;1;-1,-1;-1,NAN,NAN,y,
2365,ICLR,2019,Training Variational Auto Encoders with Discrete Latent Representations using Importance Sampling,Alexander Bartler;Felix Wiewel;Bin Yang;Lukas Mauch,alexander.bartler@iss.uni-stuttgart.de;felix.wiewel@iss.uni-stuttgart.de;bin.yang@iss.uni-stuttgart.de;lukas.mauch@iss.uni-stuttgart.de,3;1;3,5;5;5,Reject,0,0,0.0,yes,9/27/18,University of Stuttgart;University of Stuttgart;University of Stuttgart;University of Stuttgart,Variational Auto Encoder;Importance Sampling;Discrete latent representation,116;116;116;116,219;219;219;219,-1;-1,europe,de,n,1;5
2366,ICLR,2019,An Exhaustive Analysis of Lazy vs. Eager Learning Methods for Real-Estate Property Investment,Setareh Rafatirad;Maryam Heidari,srafatir@gmu.edu;mheidari@gmu.edu,3;4;2,5;4;4,Reject,0,0,0.0,yes,9/27/18,George Mason University;George Mason University,applied machine learning;housing analytics;eager learning;lazy learning;rent prediction,94;94,336;336,-1;-1,usa,usa,n,
2367,ICLR,2019,Graph2Seq: Graph to Sequence Learning with Attention-Based Neural Networks,Kun Xu;Lingfei Wu;Zhiguo Wang;Yansong Feng;Michael Witbrock;Vadim Sheinin,xukun@pku.edu.cn;lwu@email.wm.edu;zhigwang@us.ibm.com;fengyansong@pku.edu.cn;witbrock@us.ibm.com;vadims@us.ibm.com,4;6;6,5;4;4,Reject,0,17,0.0,yes,9/27/18,Peking University;College of William and Mary;International Business Machines;Peking University;International Business Machines;International Business Machines,Graph Encoder;Graph Decoder;Graph2Seq;Graph Attention,14;207;-1;14;-1;-1,27;-1;-1;27;-1;-1,-1;-1,NAN,NAN,n,8;3;10
2368,ICLR,2019,Scaling shared model governance via model splitting,Miljan Martic;Jan Leike;Andrew Trask;Matteo Hessel;Shane Legg;Pushmeet Kohli,miljanm@google.com;leike@google.com;atrask@google.com;mtthss@google.com;legg@google.com;pushmeet@google.com,5;4;9,4;3;4,Reject,0,10,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google,deep learning;reinforcement learning;multi-party computation,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2369,ICLR,2019,An Alarm System for Segmentation Algorithm Based on Shape Model,Fengze Liu;Yingda Xia;Dong Yang;Alan Yuille;Daguang Xu,liufz13@gmail.com;yxia25@jhu.edu;don.yang.mech@gmail.com;alan.l.yuille@gmail.com;cathy.xudg@gmail.com,3;6;7;5,5;4;3;4,Reject,0,4,0.0,yes,9/27/18,Johns Hopkins University;Johns Hopkins University;NVIDIA;Johns Hopkins University;NVIDIA,segmentation evaluation;shape feature;variational auto-encoder,67;67;-1;67;-1,13;13;-1;13;-1,-1;-1,asia,in,n,2;5
2370,ICLR,2019,Interpretable Continual Learning,Tameem Adel;Cuong V. Nguyen;Richard E. Turner;Zoubin Ghahramani;Adrian Weller,tah47@cam.ac.uk;nvcuong92@gmail.com;ret26@cam.ac.uk;zoubin@eng.cam.ac.uk;aw665@cam.ac.uk,4;5;6,4;3;3,Reject,0,2,1.0,yes,9/27/18,University of Cambridge;Amazon;University of Cambridge;University of Cambridge;University of Cambridge,Interpretability;Continual Learning,77;-1;77;77;77,2;-1;2;2;2,-1;-1,europe,uk,n,8
2371,ICLR,2019,On the Spectral Bias of Neural Networks,Nasim Rahaman;Aristide Baratin;Devansh Arpit;Felix Draxler;Min Lin;Fred Hamprecht;Yoshua Bengio;Aaron Courville,nasim.rahaman@iwr.uni-heidelberg.de;aristidebaratin@hotmail.com;devansharpit@gmail.com;felix.draxler@iwr.uni-heidelberg.de;mavenlin@gmail.com;yoshua.umontreal@gmail.com;aaron.courville@umontreal.ca,6;4;6;5,3;4;3;3,Reject,0,12,1.0,yes,9/27/18,Heidelberg University;University of Montreal;SalesForce.com;Heidelberg University;Sea Group;University of Montreal;University of Montreal,deep learning theory;fourier analysis,207;116;-1;207;-1;116;116,45;108;-1;45;-1;108;108,-1;-1,canada,ca,y,
2372,ICLR,2019,REVISTING NEGATIVE TRANSFER USING ADVERSARIAL LEARNING,Saneem Ahmed Chemmengath;Samarth Bharadwaj;Suranjana Samanta;Karthik Sankaranarayanan,saneem.cg@in.ibm.com;samarth.b@in.ibm.com;suransam@in.ibm.com;kartsank@in.ibm.com,4;2;6,4;4;4,Reject,0,1,0.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines,Negative Transfer;Adversarial Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
2373,ICLR,2019,PIE: Pseudo-Invertible Encoder,Jan Jetze Beitler;Ivan Sosnovik;Arnold Smeulders,j.j.beitler@uva.nl;i.sosnovik@uva.nl;a.w.m.smeulders@uva.nl,3;5;5,4;5;4,Reject,2,3,12.0,yes,9/27/18,University of Amsterdam;University of Amsterdam;University of Amsterdam,Invertible Mappings;Bijectives;Dimensionality reduction;Autoencoder,136;136;136,59;59;59,-1;-1,europe,nl,n,5
2374,ICLR,2019,Variational Domain Adaptation,Hirono Okamoto;Shohei Ohsawa;Itto Higuchi;Haruka Murakami;Mizuki Sango;Zhenghang Cui;Masahiro Suzuki;Hiroshi Kajino;Yutaka Matsuo,ohsawa@weblab.t.u-tokyo.ac.jp,4;4;5,3;5;3,Reject,0,6,1.0,yes,9/27/18,The University of Tokyo,domain adaptation;variational inference;multi-domain,59,45,-1;-1,NAN,NAN,n,11;5
2375,ICLR,2019,Siamese Capsule Networks,James O' Neill,james.o-neill@liverpool.ac.uk,5;6;3,4;4;4,Reject,0,2,0.0,yes,9/27/18,University of Liverpool,capsule networks;pairwise learning;few-shot learning;face verification,116,177,-1,europe,uk,n,6;2
2376,ICLR,2019,Unsupervised Multi-Target Domain Adaptation: An Information Theoretic Approach,Behnam Gholami;Pritish Sahu;Ognjen (Oggi) Rudovic;Konstantinos Bousmalis;Vladimir Pavlovic,bb510@cs.rutgers.edu;ps851@cs.rutgers.edu;orudovic@mit.edu;konstantinos@google.com;vladimir@cs.rutgers.edu,4;6;5,4;5;4,Reject,0,4,0.0,yes,9/27/18,Rutgers University;Rutgers University;Massachusetts Institute of Technology;Google;Rutgers University,,31;31;6;-1;31,-1;-1;5;-1;-1,-1;-1,usa,usa,n,
2377,ICLR,2019,Flow++: Improving Flow-Based Generative Models  with  Variational Dequantization and Architecture Design  ,Jonathan Ho;Xi Chen;Aravind Srinivas;Yan Duan;Pieter Abbeel,jonathanho@berkeley.edu;peter@covariant.ai;aravind_srinivas@berkeley.edu;dementrock@gmail.com;pabbeel@cs.berkeley.edu,6;6;5,4;3;5,Reject,0,4,0.0,yes,9/27/18,University of California Berkeley;covariant.ai;University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep Generative Models;Normalizing Flows;RealNVP;Density Estimation,-1;-1;-1;-1;-1,18;-1;18;18;18,-1;-1,usa,usa,n,5
2378,ICLR,2019,End-to-end learning of pharmacological assays from high-resolution microscopy images,Markus Hofmarcher;Elisabeth Rumetshofer;Sepp Hochreiter;G√ºnter Klambauer,hofmarcher@ml.jku.at;rumetshofer@ml.jku.at;hochreit@ml.jku.at;klambauer@ml.jku.at,3;6;5,3;5;4,Reject,0,4,0.0,yes,9/27/18,Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz,Convolutional Neural Networks;High-resolution images;Multiple-Instance Learning;Drug Discovery;Molecular Biology,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
2379,ICLR,2019,Meta-Learning with Domain Adaptation for Few-Shot Learning under Domain Shift,Doyen Sahoo;Hung Le;Chenghao Liu;Steven C. H. Hoi,doyens@smu.edu.sg;hungle.2018@phdis.smu.edu.sg;chliu@smu.edu.sg;chhoi@smu.edu.sg,5;6;6,3;3;3,Reject,2,5,0.0,yes,9/27/18,Singapore Management University;Singapore Management University;Singapore Management University;Singapore Management University,Meta-Learning;Few-Shot Learning;Domain Adaptation,77;77;77;77,-1;-1;-1;-1,-1;-1,asia,sg,n,6;4
2380,ICLR,2019,On-Policy Trust Region Policy Optimisation with Replay Buffers,Dmitry Kangin;Nicolas Pugeault,d.kangin@exeter.ac.uk;n.pugeault@exeter.ac.uk,7;6;5,5;3;4,Reject,0,4,0.0,yes,9/27/18,University of Exeter;University of Exeter,reinforcement learning;on-policy learning;trust region policy optimisation;replay buffer,419;419,130;130,-1;-1,europe,gr,y,
2381,ICLR,2019,Stochastic Gradient Descent Learns State Equations with Nonlinear Activations,Samet Oymak,sametoymak@gmail.com,7;7;5,3;3;5,Reject,0,3,0.0,yes,9/27/18,"University of California, Riverside",recurrent neural network;state equation;gradient descent;sample complexity,-1,197,-1,usa,usa,y,1
2382,ICLR,2019,Identifying Generalization Properties in Neural Networks,Huan Wang;Nitish Shirish Keskar;Caiming Xiong;Richard Socher,huan.wang@salesforce.com;nkeskar@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,5;6;6,4;4;4,Reject,0,5,0.0,yes,9/27/18,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,generalization;PAC-Bayes;Hessian;perturbation,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
2383,ICLR,2019,Stackelberg GAN: Towards Provable Minimax Equilibrium via Multi-Generator Architectures,Hongyang Zhang;Susu Xu;Jiantao Jiao;Pengtao Xie;Ruslan Salakhutdinov;Eric P. Xing,hongyanz@cs.cmu.edu;susux@andrew.cmu.edu;jiantao@eecs.berkeley.edu;pengtao.xie@petuum.com;rsalakhu@cs.cmu.edu;epxing@cs.cmu.edu,4;5;7,4;3;3,Reject,0,10,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;University of California Berkeley;Petuum Inc.;Carnegie Mellon University;Carnegie Mellon University,generative adversarial nets;minimax duality gap;equilibrium,1;1;-1;-1;1;1,24;24;18;-1;24;24,-1;-1,usa,usa,y,5
2384,ICLR,2019,Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions,Ali Ramezani-Kebrya;Ashish Khisti;and Ben Liang,aramezani@ece.utoronto.ca;akhisti@ece.utoronto.ca;liang@ece.utoronto.ca,4;6;4,5;4;4,Reject,0,16,1.0,yes,9/27/18,Toronto University;Toronto University;Toronto University,Generalization Error;Stochastic Gradient Descent;Uniform Stability,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,1
2385,ICLR,2019,A Variational Dirichlet Framework for Out-of-Distribution Detection,Wenhu Chen;Yilin Shen;William Wang;Hongxia Jin,wenhuchen@ucsb.edu;yilin.shen@samsung.com;william@cs.ucsb.edu;hongxia.jin@samsung.com,6;5;6,4;5;3,Reject,4,7,0.0,yes,9/27/18,UC Santa Barbara;Samsung;UC Santa Barbara;Samsung,out-of-distribution detection;variational inference;Dirichlet distribution;deep learning;uncertainty measure,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2386,ICLR,2019,Optimized Gated Deep Learning Architectures for Sensor Fusion,Myung Seok Shim;Peng Li,mrshim1101@tamu.edu;pli@tamu.edu,4;4;3,5;4;4,Reject,0,0,0.0,yes,9/27/18,Texas A&M;Texas A&M,deep learning;convolutional neural network;sensor fusion;activity recognition,50;50,160;160,-1;-1,NAN,NAN,n,
2387,ICLR,2019,RESIDUAL NETWORKS CLASSIFY INPUTS BASED ON THEIR NEURAL TRANSIENT DYNAMICS,Fereshteh Lagzi,lagzi@informatik.uni-freiburg.de,4;2;5,4;4;5,Reject,0,4,0.0,yes,9/27/18,Universit√§t Freiburg,Residual Networks;Dynamical Systems;Classification,-1,-1,-1,NAN,NAN,n,
2388,ICLR,2019,Better Generalization with On-the-fly Dataset Denoising,Jiaming Song;Tengyu Ma;Michael Auli;Yann Dauphin,jiaming.tsong@gmail.com;tengyuma@cs.stanford.edu;michael.auli@gmail.com;yann@dauphin.io,5;6;6,4;3;5,Reject,0,9,0.0,yes,9/27/18,Stanford University;Stanford University;Facebook;Google,dataset denoising;supervised learning;implicit regularization,4;4;-1;-1,3;3;-1;-1,-1;-1,NAN,NAN,n,1
2389,ICLR,2019,Generative Adversarial Networks for Extreme Learned Image Compression,Eirikur Agustsson;Michael Tschannen;Fabian Mentzer;Radu Timofte;Luc van Gool,aeirikur@vision.ee.ethz.ch;michaelt@nari.ee.ethz.ch;mentzerf@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,6;6;4,3;3;4,Reject,0,5,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Learned compression;generative adversarial networks;extreme compression,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2390,ICLR,2019,A Synaptic Neural Network and Synapse Learning,Chang Li,changli@neatware.com,2;3;2;2,4;3;3;3,Reject,0,17,0.0,yes,9/27/18,Neatware,synaptic neural network;surprisal;synapse;probability;excitation;inhibition;synapse learning;bose-einstein distribution;tensor;gradient;loss function;mnist;topologically conjugate,-1,-1,-1,NAN,NAN,y,1;10
2391,ICLR,2019,Reducing Overconfident Errors outside the Known Distribution,Zhizhong Li;Derek Hoiem,zli115@illinois.edu;dhoiem@illinois.edu,6;4;6,4;4;3,Reject,0,8,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Machine learning safety;confidence;overconfidence;unknown domain;novel distribution;generalization;distillation;ensemble;underrepresentation,-1;-1,-1;-1,-1;-1,usa,usa,n,7
2392,ICLR,2019,Adversarial Sampling for Active Learning,Christoph Mayer;Radu Timofte,chmayer@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch,6;5;5,2;4;5,Reject,0,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,active learning;adversarial training;GAN,-1;-1,-1;-1,-1;-1,NAN,NAN,n,4
2393,ICLR,2019,"Classification from Positive, Unlabeled and Biased Negative Data",Yu-Guan Hsieh;Gang Niu;Masashi Sugiyama,yu-guan.hsieh@ens.fr;gang.niu@riken.jp;sugi@k.u-tokyo.ac.jp,5;6;5,5;3;3,Reject,0,8,0.0,yes,9/27/18,Ecole Normale Superieure;RIKEN;The University of Tokyo,positive-unlabeled learning;dataset shift;empirical risk minimization,116;-1;59,-1;-1;45,-1;-1,NAN,NAN,y,1
2394,ICLR,2019,Learning Diverse Generations using Determinantal Point Processes,Mohamed Elfeki;Camille Couprie;Mohamed Elhoseiny,m.elfeki11@gmail.com;coupriec@fb.com;elhoseiny@fb.com,5;5;5,4;5;4,Reject,0,7,1.0,yes,9/27/18,University of Central Florida;Facebook;Facebook,Generative Adversarial Networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2395,ICLR,2019,Probabilistic Binary Neural Networks,Jorn W.T. Peters;Tim Genewein;Max Welling,jornpeters@gmail.com;tim.genewein@gmail.com;welling.max@gmail.com,6;5;3,4;2;3,Reject,0,6,0.0,yes,9/27/18,"University of Amsterdam;Google;University of California, Irvine",binary neural Network;efficient deep learning;stochastic training;discrete neural network;efficient inference,136;-1;-1,59;-1;99,-1;-1,usa,usa,n,
2396,ICLR,2019,Geomstats: a Python Package for Riemannian Geometry in Machine Learning,Nina Miolane;Johan Mathe;Claire Donnat;Mikael Jorda;Xavier Pennec,nmiolane@stanford.edu;johan@froglabs.ai;cdonnat@stanford.edu;mjorda@stanford.edu;xavier.pennec@inria.fr,4;4;3;8,4;5;5;2,Reject,1,1,0.0,yes,9/27/18,Stanford University;;Stanford University;Stanford University;INRIA,Riemannian geometry;Python package;machine learning;deep learning,4;-1;4;4;-1,3;-1;3;3;-1,-1;-1,europe,gr,n,
2397,ICLR,2019,Outlier Detection from Image Data,Lei Cao;Yizhou Yan;Samuel Madden;Elke Rundensteiner,lcao@csail.mit.edu;yyan2@wpi.edu;madden@csail.mit.edu;rundenst@cs.wpi.edu,4;5;5,4;3;4,Reject,1,11,0.0,yes,9/27/18,Massachusetts Institute of Technology;Worcester Polytechnic Institute;Massachusetts Institute of Technology;Worcester Polytechnic Institute,Image outlier;CNN;Deep Neural Forest,6;169;6;169,5;-1;5;-1,-1;-1,usa,usa,n,1
2398,ICLR,2019,Investigating CNNs' Learning Representation under label noise,Ryuichiro Hataya;Hideki Nakayama,hataya@nlab.ci.i.u-tokyo.ac.jp;nakayama@nlab.ci.i.u-tokyo.aco.jp,5;4;5,4;5;5,Reject,0,3,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo,learning with noisy labels;deep learning;convolutional neural networks,59;-1,45;-1,-1;-1,asia,in,n,
2399,ICLR,2019,Discriminative out-of-distribution detection for semantic segmentation,Petra Bevandiƒá;Sini≈°a ≈†egviƒá;Ivan Kre≈°o;Marin Or≈°iƒá,petra.bevandic@fer.hr;sinisa.segvic@fer.hr;ivan.kreso@fer.hr;marin.orsic@fer.hr,4;7;3,4;5;3,Reject,0,5,0.0,yes,9/27/18,"Faculty of Electrical Engineering and Computing, University of Zagreb;Faculty of Electrical Engineering and Computing, University of Zagreb;Faculty of Electrical Engineering and Computing, University of Zagreb;Faculty of Electrical Engineering and Computing, University of Zagreb",out-of-distribution detection;semantic segmentation,-1;-1;-1;-1,894;894;894;894,-1;-1,NAN,NAN,n,2;1
2400,ICLR,2019,DppNet: Approximating Determinantal Point Processes with Deep Networks,Zelda Mariet;Jasper Snoek;Yaniv Ovadia,zelda@csail.mit.edu;jsnoek@google.com;yovadia@google.com,3;5;5,5;4;3,Reject,0,5,0.0,yes,9/27/18,Massachusetts Institute of Technology;Google;Google,dpp;submodularity;determinant,6;-1;-1,5;-1;-1,-1;-1,NAN,NAN,n,8;5
2401,ICLR,2019,Difference-Seeking Generative Adversarial Network,Yi-Lin Sung;Sung-Hsien Hsieh;Soo-Chang Pei;Chun-Shien Lu,r06942076@ntu.edu.tw;parvaty316@hotmail.com;peisc@ntu.edu.tw;lcs@iis.sinica.edu.tw,5;4;3,4;3;4,Reject,0,4,0.0,yes,9/27/18,Nanyang Technological University;;Nanyang Technological University;Academia Sinica,Generative Adversarial Network;Semi-Supervised Learning;Adversarial Training,44;-1;44;-1,52;-1;52;-1,-1;-1,NAN,NAN,y,5;4
2402,ICLR,2019,Learning to Search Efficient DenseNet with Layer-wise Pruning,Xuanyang Zhang;Hao liu;Zhanxing Zhu;Zenglin Xu,xuanyang91.zhang@gmail.com;uestcliuhao@gmail.com;zhanxing.zhu@pku.edu.cn;zenglin@gmail.com,4;4;4,5;4;4,Reject,0,0,0.0,yes,9/27/18,University of Electronic Science and Technology of China;;Peking University;Harbin Institute of Technology,reinforcement learning;DenseNet;neural network compression,-1;-1;14;136,-1;-1;27;522,-1;-1,asia,cn,n,
2403,ICLR,2019,Unsupervised  one-to-many image translation,Samuel Lavoie-Marchildon;Sebastien Lachapelle;Miko≈Çaj Bi≈Ñkowski;Aaron Courville;Yoshua Bengio;R Devon Hjelm,samuel.lavoie-marchildon@umontreal.ca;sebastien.lachapelle@umontreal.ca;mikbinkowski@gmail.com;aaron.courville@gmail.com;yoshua.umontreal@gmail.com;devon.hjelm@microsoft.com,3;4;4,4;4;4,Reject,0,5,0.0,yes,9/27/18,University of Montreal;University of Montreal;;University of Montreal;University of Montreal;Microsoft,Image-to-image;Translation;Unsupervised;Generation;Adversarial;Learning,116;116;-1;116;116;-1,108;108;-1;108;108;-1,-1;-1,NAN,NAN,n,
2404,ICLR,2019,Calibration of neural network logit vectors to combat adversarial attacks,Oliver Goldstein,og14775@my.bristol.ac.uk,3;2;4,4;4;5,Reject,2,3,0.0,yes,9/27/18,University of Bristol,Adversarial attacks;calibration;probability;adversarial defence,94,76,-1,europe,uk,n,4
2405,ICLR,2019,The Expressive Power of Gated Recurrent Units as a Continuous Dynamical System,Ian D. Jordan;Piotr Aleksander Sokol;Il Memming Park,ian.jordan@stonybrook.edu;piotr.sokol@stonybrook.edu;memming.park@stonybrook.edu,6;5;5,4;4;4,Reject,0,6,0.0,yes,9/27/18,"State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook",Gated Recurrent Units;Recurrent Neural Network;Time Series Predictions;interpretable;Nonlinear Dynamics;Dynamical Systems,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,1
2406,ICLR,2019,A Self-Supervised Method for Mapping Human Instructions to Robot Policies,Hsin-Wei Yu;Po-Yu Wu;Chih-An Tsao;You-An Shen;Shih-Hsuan Lin;Zhang-Wei Hong;Yi-Hsiang Chang;Chun-Yi Lee,hsinweiyo@gmail.com;bwoyu85928@gmai.com;hl6540@gmail.com;jerrylin1121@gmail.com;williamd4112@gapp.nthu.edu.tw;shawn420@gapp.nthu.edu.tw;cylee@gapp.nthu.edu.tw,4;3;2,5;5;4,Reject,0,0,0.0,yes,9/27/18,National Taiwan University;Gmai;;;National Tsing Hua University;National Tsing Hua University;National Tsing Hua University,,-1;-1;-1;-1;207;207;207,-1;-1;-1;-1;323;323;323,-1;-1,asia,tw,n,
2407,ICLR,2019,Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics,Igor M. Quintanilha;Roberto de M. E. Filho;Jos√© Lezama;Mauricio Delbracio;Leonardo O. Nunes,igormq@poli.ufrj.br;robertomest@poli.ufrj.br;jlezama@fing.edu.uy;mdelbra@fing.edu.uy;lnunes@microsoft.com,7;5;5,4;4;4,Reject,3,16,1.0,yes,9/27/18,Federal University of Rio de Janeiro - UFRJ;Federal University of Rio de Janeiro - UFRJ;Facultad de Ingenier√≠a;Facultad de Ingenier√≠a;Microsoft,computer vision;out-of-distribution detection;image classification,419;419;-1;-1;-1,715;715;-1;-1;-1,-1;-1,NAN,NAN,n,
2408,ICLR,2019,Context Dependent Modulation of Activation Function,Long Sha;Jonathan Schwarcz;Pengyu Hong,longsha@brandeis.edu;johnschwarcz@brandeis.edu;hongpeng@brandeis.edu,4;4;4;4;6,5;3;4;5;4,Reject,0,5,0.0,yes,9/27/18,Brandeis University;Brandeis University;Brandeis University,Artificial Neural Network;Convolution Neural Network;Long Short-Term Memory;Activation Function;Neuromodulation,207;207;207,223;223;223,-1;-1,usa,usa,n,
2409,ICLR,2019,Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors,Danijar Hafner;Dustin Tran;Timothy Lillicrap;Alex Irpan;James Davidson,mail@danijar.com;trandustin@google.com;countzero@google.com;alexirpan@google.com;james@electric-thought.com,7;4;6,3;4;4,Reject,1,4,0.0,yes,9/27/18,"Department of Computer Science, University of Toronto;Google;Google;Google;Electric-thought",uncertainty estimates;out of distribution;bayesian neural network;neural network priors;regression;active learning,18;-1;-1;-1;-1,22;-1;-1;-1;-1,-1;-1,NAN,NAN,n,11
2410,ICLR,2019,DON‚ÄôT JUDGE A BOOK BY ITS COVER - ON THE DYNAMICS OF RECURRENT NEURAL NETWORKS,Doron Haviv;Alexander Rivkind;Omri Barak,doron.haviv12@gmail.com;sashkarivkind@gmail.com;omri.barak@gmail.com,6;5;7,3;4;4,Reject,0,6,0.0,yes,9/27/18,"Cornell University;;Technion, Technion",,-1;-1;27,-1;-1;-1,-1;-1,NAN,NAN,n,
2411,ICLR,2019,Volumetric Convolution: Automatic Representation Learning in Unit Ball,Sameera Ramasinghe;Salman Khan;Nick Barnes,sameera.ramasinghe@anu.edu.au;salman.khan@anu.edu.au;nick.barnes@data61.csiro.au,6;5;5,2;5;3,Reject,0,7,0.0,yes,9/27/18,Australian National University;Australian National University;CSIRO,convolution;unit sphere;3D object recognition,116;116;-1,48;48;-1,-1;-1,asia,in,n,
2412,ICLR,2019,Classification in the dark using tactile exploration,Mayur Mudigonda;Blake Tickell;Pulkit Agrawal,mudigonda@berkeley.edu;btickell@berkeley.edu;pulkitag@berkeley.edu,4;3;2,3;5;5,Reject,0,0,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,tactile sensing;multimodal representations;vision;object identification,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,
2413,ICLR,2019,"Deep Imitative Models for Flexible Inference, Planning, and Control",Nicholas Rhinehart;Rowan McAllister;Sergey Levine,nrhineha@cs.cmu.edu;rmcallister@berkeley.edu;svlevine@eecs.berkeley.edu,6;5;6,3;5;1,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;University of California Berkeley;University of California Berkeley,imitation learning;forecasting;computer vision,1;-1;-1,24;18;18,m;m,usa,usa,n,
2414,ICLR,2019,SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization,Haoyi Xiong;Wenqing Hu;Zhanxing Zhu;Xinjian Li;Yunchao Zhang;Jun Huan,xhyccc@gmail.com;huwenqing.pku@gmail.com;zhanxing.zhu@pku.edu.cn;lixingjian@baidu.com;yzgv7@mst.edu;huanjun@baidu.com,4;3;3,4;3;5,Reject,0,0,0.0,yes,9/27/18,Baidu;Missouri University of Science and Technology;Peking University;Baidu;Missouri University of Science and Technology;Baidu,derivative-free optimization,-1;-1;14;-1;-1;-1,-1;538;27;-1;538;-1,-1;-1,NAN,NAN,y,
2415,ICLR,2019,Universal discriminative quantum neural networks,Hongxiang Chen;Leonard Wossnig;Hartmut Neven;Simone Severini;Masoud Mohseni,we.taper@gmail.com;leonard.wossnig.17@ucl.ac.uk;neven@google.com;s.severini@ucl.ac.uk;mohseni@google.com,5;5;2,3;2;2,Reject,0,0,0.0,yes,9/27/18,University College London;University College London;Google;University College London;Google,quantum machine learning;quantum data classification,-1;50;-1;50;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2416,ICLR,2019,Bias Also Matters: Bias Attribution for Deep Neural Network Explanation,Shengjie Wang;Tianyi Zhou;Jeff Bilmes,wangsj@cs.washington.edu;tianyi.david.zhou@gmail.com;bilmes@uw.edu,5;5;5,5;5;4,Reject,0,0,0.0,yes,9/27/18,"University of Washington;University of Washington;University of Washington, Seattle",explainable AI;interpreting deep neural networks;bias;attribution method;piecewise linear activation function;backpropagation,10;10;10,25;25;25,-1;-1,NAN,NAN,y,
2417,ICLR,2019,Dirichlet Variational Autoencoder,Weonyoung Joo;Wonsung Lee;Sungrae Park;and Il-Chul Moon,weonyoungjoo@gmail.com;aporia@kaist.ac.kr;sungraepark@kaist.ac.kr;icmoon@kaist.ac.kr,6;5;7,4;5;3,Reject,0,10,0.0,yes,9/27/18,Samsung;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Variational autoencoder;Unsupervised learning;(Semi-)Supervised learning;Topic modeling,-1;-1;-1;-1,-1;95;95;95,-1;-1,NAN,NAN,n,5
2418,ICLR,2019,DANA: Scalable Out-of-the-box Distributed ASGD Without Retuning,Ido Hakimi;Saar Barkai;Moshe Gabel;Assaf Schuster,idohakimi@gmail.com;saarbarkai@gmail.com;mgabel@cs.toronto.edu;assaf@cs.technion.ac.il,5;7;5,3;4;4,Reject,0,8,0.0,yes,9/27/18,"Technion, Technion;;University of Toronto;Technion, Technion",distributed;asynchronous;gradient staleness;nesterov;optimization;out-of-the-box;stochastic gradient descent;sgd;imagenet;distributed training;neural networks;deep learning,27;-1;18;27,-1;-1;22;-1,-1;-1,NAN,NAN,n,
2419,ICLR,2019,Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation,Wei Deng;Xiao Zhang;Faming Liang;Guang Lin,deng106@purdue.edu;zhang923@purdue.edu;fmliang@purdue.edu;guanglin@purdue.edu,5;4;6,4;2;5,Reject,0,0,1.0,yes,9/27/18,Purdue University;Purdue University;Purdue University;Purdue University,generalized stochastic approximation;stochastic gradient Markov chain Monte Carlo;adaptive algorithm;EM algorithm;convolutional neural networks;Bayesian inference;sparse prior;spike and slab prior;local trap,24;24;24;24,60;60;60;60,-1;-1,usa,usa,y,11;4
2420,ICLR,2019,Physiological Signal Embeddings (PHASE) via Interpretable Stacked Models,Hugh Chen;Scott Lundberg;Gabe Erion;Su-In Lee,hughchen@cs.washington.edu;slund1@cs.washington.edu;erion@cs.washington.edu;suinlee@cs.washington.edu,6;5;4,5;4;4,Reject,0,10,0.0,yes,9/27/18,University of Washington;University of Washington;University of Washington;University of Washington,Representation learning;transfer learning;health;machine learning;physiological signals;interpretation;feature attributions;shapley values;univariate embeddings;LSTMs;XGB;neural networks;stacked models;model pipelines;interpretable stacked models,10;10;10;10,25;25;25;25,-1;-1,usa,usa,y,3;2;1
2421,ICLR,2019,ReNeg and Backseat Driver: Learning from demonstration with continuous human feedback,Zoe Papakipos;Jacob Beck;Michael Littman,zoe_papakipos@alumni.brown.edu;jacob_beck@alumni.brown.edu;mlittman@cs.brown.edu,3;4;2,4;4;5,Reject,0,12,0.0,yes,9/27/18,Brown University;Brown University;Brown University,learning from demonstration;imitation learning;behavioral cloning;reinforcement learning;off-policy;continuous control;autonomous vehicles;deep learning;machine learning;policy gradient,86;86;86,50;50;50,-1;-1,usa,usa,n,10
2422,ICLR,2019,Learning  agents with prioritization and parameter noise in continuous state and action space,Rajesh Devaraddi;G. Srinivasaraghavan,rajesh.dm@iiitb.ac.in;gsr@iiitb.ac.in,3;4;4,4;3;4,Reject,0,0,0.0,yes,9/27/18,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay,reinforcement learning;continuous action space;prioritization;parameter;noise;policy gradients,-1;-1,367;367,-1;-1,NAN,NAN,n,
2423,ICLR,2019,Gradient Descent Happens in a Tiny Subspace,Guy Gur-Ari;Daniel A. Roberts;Ethan Dyer,guyg@ias.edu;danr@fb.com;edyer@google.com,4;6;4,3;4;4,Reject,0,4,1.0,yes,9/27/18,"Institue for Advanced Study, Princeton;Facebook;Google",Gradient Descent;Hessian;Deep Learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2424,ICLR,2019,Nested Dithered Quantization for Communication Reduction in Distributed Training,Afshin Abdi;Faramarz Fekri,abdi@ece.gatech.edu;fekri@ece.gatech.edu,5;5;7,4;3;4,Reject,0,5,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology,machine learning;distributed training;dithered quantization;nested quantization;distributed compression,13;13,33;33,-1;-1,usa,usa,y,1
2425,ICLR,2019,Learned optimizers that outperform on wall-clock and validation loss,Luke Metz;Niru Maheswaranathan;Jeremy Nixon;Daniel Freeman;Jascha Sohl-dickstein,lmetz@google.com;nirum@google.com;jeremynixon@google.com;cdfreeman@google.com;jaschasd@google.com,5;4;5,3;5;4,Reject,0,10,1.0,yes,9/27/18,Google;Google;Google;Google;Google,Learned Optimizers;Meta-Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2426,ICLR,2019,A Walk with SGD: How SGD Explores Regions of Deep Network Loss?,Chen Xing;Devansh Arpit;Christos Tsirigotis;Yoshua Bengio,xingchen1113@gmail.com;devansharpit@gmail.com;tsirif@gmail.com;yoshua.umontreal@gmail.com,4;4;3,5;3;4,Reject,1,0,0.0,yes,9/27/18,SalesForce.com;SalesForce.com;University of Montreal;University of Montreal,,-1;-1;116;116,-1;-1;108;108,-1;-1,canada,ca,n,
2427,ICLR,2019,Combining adaptive algorithms and hypergradient method: a performance and robustness study,Akram Erraqabi;Nicolas Le Roux,akram.er-raqabi@umontreal.ca;nicolas@le-roux.name,3;3;4,4;2;4,Reject,0,4,0.0,yes,9/27/18,University of Montreal;Google,optimization;adaptive methods;learning rate decay,116;-1,108;-1,-1;-1,asia,in,n,
2428,ICLR,2019,The Expressive Power of Deep Neural Networks with Circulant Matrices,Alexandre Araujo;Benjamin Negrevergne;Yann Chevaleyre;Jamal Atif,alexandre.araujo@dauphine.eu;benjamin.negrevergne@dauphine.fr;yann.chevaleyre@lamsade.dauphine.fr;jamal.atif@lamsade.dauphine.fr,6;4;7,5;4;4,Reject,0,3,0.0,yes,9/27/18,Univerist√© Paris-Dauphine;Univerist√© Paris-Dauphine;Univerist√© Paris-Dauphine;Univerist√© Paris-Dauphine,deep learning;circulant matrices;universal approximation,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2429,ICLR,2019,The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects,Zhanxing Zhu;Jingfeng Wu;Bing Yu;Lei Wu;Jinwen Ma,zhanxing.zhu@pku.edu.cn;pkuwjf@pku.edu.cn;byu@pku.edu.cn;leiwu@pku.edu.cn;jwma@math.pku.edu.cn,5;4;6,4;5;3,Reject,0,0,0.0,yes,9/27/18,Peking University;Peking University;Peking University;Peking University;Peking University,Stochastic gradient descent;anisotropic noise;regularization,14;14;14;14;14,27;27;27;27;27,-1;-1,asia,cn,y,
2430,ICLR,2019,Stochastic Gradient Push for Distributed Deep Learning,Mahmoud Assran;Nicolas Loizou;Nicolas Ballas;Mike Rabbat,massran@fb.com;n.loizou@sms.ed.ac.uk;ballasn@fb.com;mikerabbat@fb.com,6;6;6,3;4;3,Reject,0,9,2.0,yes,9/27/18,Facebook;University of Edinburgh;Facebook;Facebook,optimization;distributed;large scale;deep learning,-1;36;-1;-1,-1;27;-1;-1,-1;-1,NAN,NAN,y,1;9
2431,ICLR,2019,Towards Language Agnostic Universal Representations,Armen Aghajanyan;Xia Song;Saurabh Tiwary,araghaja@microsoft.com;xiaso@microsoft.com;satiwary@microsoft.com,5;4;6,4;4;3,Reject,0,7,0.0,yes,9/27/18,Microsoft;Microsoft;Microsoft,universal representations;language agnostic representations;NLP;GAN,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,6
2432,ICLR,2019,Mapping the hyponymy relation of wordnet onto vector Spaces,Jean-Philippe Bernardy;Aleksandre Maskharashvili,jean-philippe.bernardy@gu.se;aleksandre.maskharashvili@gu.se,3;3;3,4;3;5,Reject,0,1,0.0,yes,9/27/18,University of Gothenburg;University of Gothenburg,fasttext;hyponymy;wordnet,-1;-1,197;197,-1;-1,NAN,NAN,n,
2433,ICLR,2019,Model Compression with Generative Adversarial Networks,Ruishan Liu;Nicolo Fusi;Lester Mackey,ruishan@stanford.edu;fusi@microsoft.com;lmackey@microsoft.com,6;5;5,4;4;4,Reject,0,7,0.0,yes,9/27/18,Stanford University;Microsoft;Microsoft,Model compression;distillation;generative adversarial network;GAN;deep neural network;random forest;ensemble;decision tree;convolutional neural network,4;-1;-1,3;-1;-1,-1;-1,NAN,NAN,n,10;5;4
2434,ICLR,2019,Efficient Convolutional Neural Network Training with Direct Feedback Alignment,Donghyeon Han;Hoi-jun Yoo,hdh4797@kaist.ac.kr;hjyoo@kaist.ac.kr,4;4;5,4;4;3,Reject,0,4,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Direct Feedback Alignment;Convolutional Neural Network;DNN Training,-1;-1,95;95,-1;-1,NAN,NAN,n,
2435,ICLR,2019, Large-Scale Visual Speech Recognition,Brendan Shillingford;Yannis Assael;Matthew W. Hoffman;Thomas Paine;C√≠an Hughes;Utsav Prabhu;Hank Liao;Hasim Sak;Kanishka Rao;Lorrayne Bennett;Marie Mulville;Ben Coppin;Ben Laurie;Andrew Senior;Nando de Freitas,shillingford@google.com;assael@google.com;mwhoffman@google.com;tpaine@google.com;cianh@google.com;utsavprabhu@google.com;hankliao@google.com;hasim@google.com;kanishkarao@google.com;lorrayne@google.com;mariecharlotte@google.com;coppin@google.com;benl@google.com;andrewsenior@google.com;nandodefreitas@google.com,9;4;3,4;4;5,Reject,0,17,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,visual speech recognition;speech recognition;lipreading,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2436,ICLR,2019,The effectiveness of layer-by-layer training using the information bottleneck principle,Adar Elad;Doron Haviv;Yochai Blau;Tomer Michaeli,adarelad@campus.technion.ac.il;doron.haviv12@gmail.com;yochai@campus.technion.ac.il;tomer.m@ee.technion.ac.il,5;5;2,5;4;4,Reject,0,5,0.0,yes,9/27/18,"Technion, Technion;;Technion, Technion;Technion, Technion",,27;-1;27;27,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2437,ICLR,2019,The Case for Full-Matrix Adaptive Regularization,Naman Agarwal;Brian Bullins;Xinyi Chen;Elad Hazan;Karan Singh;Cyril Zhang;Yi Zhang,namanagarwal@google.com;bbullins@cs.princeton.edu;xinyic@google.com;ehazan@cs.princeton.edu;karans@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,5;6;5,3;3;3,Reject,0,3,0.0,yes,9/27/18,Google;Princeton University;Google;Princeton University;Princeton University;Princeton University;Princeton University,adaptive regularization;non-convex optimization,-1;31;-1;31;31;31;31,-1;7;-1;7;7;7;7,-1;-1,usa,usa,y,1;9
2438,ICLR,2019,What Information Does a ResNet Compress?,Luke Nicholas Darlow;Amos Storkey,l.n.darlow@sms.ed.ac.uk;a.storkey@ed.ac.uk,4;4;6,4;3;5,Reject,0,11,0.0,yes,9/27/18,University of Edinburgh;University of Edinburgh,Deep Learning;Information Bottleneck;Residual Neural Networks;Information Theory,36;36,27;27,-1;-1,europe,uk,n,
2439,ICLR,2019,Information Regularized Neural Networks,Tianchen Zhao;Dejiao Zhang;Zeyu Sun;Honglak Lee,ericolon@umich.edu;dejiao@umich.edu;zeyusun@umich.edu;honglak@eecs.umich.edu,6;5;6,4;3;3,Reject,0,7,0.0,yes,9/27/18,University of Michigan;University of Michigan;University of Michigan;University of Michigan,supervised classification;information theory;deep learning;regularization,9;9;9;9,21;21;21;21,-1;-1,usa,usa,y,1
2440,ICLR,2019,NICE: noise injection and clamping estimation for neural network quantization,Chaim Baskin;Natan Liss;Yoav Chai;Evgenii Zheltonozhskii;Eli Schwartz;Raja Girayes;Avi Mendelson;Alexander M.Bronstein,chaimbaskin@cs.technion.ac.il;lissnatan@campus.technion.ac.il;yoavchai1@mail.tau.ac.il;evgeniizh@campus.technion.ac.il;eli.shw@gmail.com;raja@tauex.tau.ac.il;avi.mendelson@tce.technion.ac.il;bron@cs.technion.ac.il,4;5;4,4;3;3,Reject,1,0,0.0,yes,9/27/18,"Technion, Technion;Technion, Technion;Tel Aviv University;Technion, Technion;Tel Aviv University;Tel Aviv University;Technion, Technion;Technion, Technion",Efficient inference;Hardware-efficient model architectures;Quantization,27;27;31;27;31;31;27;27,-1;-1;217;-1;217;217;-1;-1,-1;-1,NAN,NAN,n,2;3
2441,ICLR,2019,Mean Replacement Pruning  ,Utku Evci;Nicolas Le Roux;Pablo Castro;Leon Bottou,evcu@google.com;nicolas@le-roux.name;psc@google.com;leon@bottou.org,5;5;4,3;3;4,Reject,0,9,0.0,yes,9/27/18,Google;;Google;Facebook,pruning;saliency;neural networks;optimization;redundancy;model compression,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2442,ICLR,2019,The Effectiveness of Pre-Trained Code Embeddings,Ben Trevett;Donald Reay;N. K. Taylor,bbt1@hw.ac.uk;n.k.taylor@hw.ac.uk;d.s.reay@hw.ac.uk,6;4;5,3;4;4,Reject,0,5,0.0,yes,9/27/18,Heriot-Watt University;Heriot-Watt University;Heriot-Watt University,machine learning;deep learning;summarization;embeddings;word embeddings;source code;programming languages;programming language processing,207;207;207,363;363;363,-1;-1,europe,uk,n,3
2443,ICLR,2019,Laplacian Networks: Bounding Indicator Function Smoothness for Neural Networks Robustness,Carlos Eduardo Rosar Kos Lassance;Vincent Gripon;Antonio Ortega,carlos.rosarkoslassance@imt-atlantique.fr;vincent.gripon@imt-atlantique.fr;antonio.ortega@ee.usc.edu,9;5;5,5;3;4,Reject,0,11,0.0,yes,9/27/18,IMT Atlantique;IMT Atlantique;University of Southern California,GSP;robustness;noise;deep learning;neural networks,-1;-1;27,-1;-1;66,-1;-1,usa,usa,n,10;4
2444,ICLR,2019,Jumpout: Improved Dropout for Deep Neural Networks with Rectified Linear Units,Shengjie Wang;Tianyi Zhou;Jeff Bilmes,tianyi.david.zhou@gmail.com,5;4;4,4;3;5,Reject,0,5,0.0,yes,9/27/18,University of Washington,Dropout;deep neural networks with ReLU;local linear model,10,25,-1;-1,usa,usa,n,1
2445,ICLR,2019,Causal importance of orientation selectivity for generalization in image recognition,Jumpei Ukita,i.love.ny517@gmail.com,5;4;7,4;4;2,Reject,0,5,1.0,yes,9/27/18,M3,deep learning;generalization;selectivity;neuroscience,419,-1,-1,asia,in,n,1
2446,ICLR,2019,Backprop with Approximate Activations for Memory-efficient Network Training,Ayan Chakrabarti;Benjamin Moseley,ayan@wustl.edu;moseleyb@andrew.cmu.edu,5;5;7,5;3;4,Reject,0,9,0.0,yes,9/27/18,"Washington University, St. Louis;Carnegie Mellon University",Back-propagation;Memory Efficient Training;Approximate Gradients;Deep Learning,-1;1,-1;24,-1;-1,usa,usa,n,
2447,ICLR,2019,Experience replay for continual learning,David Rolnick;Arun Ahuja;Jonathan Schwarz;Timothy P. Lillicrap;Greg Wayne,drolnick@mit.edu;arahuja@google.com;schwarzjn@google.com;countzero@google.com;gregwayne@google.com,5;5;5,5;4;5,Reject,0,4,0.0,yes,9/27/18,Massachusetts Institute of Technology;Google;Google;Google;Google,continual learning;catastrophic forgetting;lifelong learning;behavioral cloning;reinforcement learning;interference;stability-plasticity,6;-1;-1;-1;-1,5;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2448,ICLR,2019,Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference,Shun Liao;Ting Chen;Tian Lin;Chong Wang;Dengyong Zhou,sliao3@cs.toronto.edu;tingchen@cs.ucla.edu;tianlin@google.com;dennyzhou@google.com;chongw@google.com,6;4;7,3;3;3,Reject,0,4,0.0,yes,9/27/18,"University of Toronto;University of California, Los Angeles;Google;Google;Google",hierarchical softmax;model compression,18;-1;-1;-1;-1,22;15;-1;-1;-1,-1;-1,NAN,NAN,n,
2449,ICLR,2019,LARGE BATCH SIZE TRAINING OF NEURAL NETWORKS WITH ADVERSARIAL TRAINING AND SECOND-ORDER INFORMATION,Zhewei Yao;Amir Gholami;Kurt Keutzer;Michael Mahoney,zheweiy@berkeley.edu;amirgh@berkeley.edu;keutzer@berkeley.edu;mmahoney@stat.berkeley.edu,7;4;4,4;5;4,Reject,0,7,1.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,adversarial training;large batch size;neural network,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,y,1;4
2450,ICLR,2019,Double Neural Counterfactual Regret Minimization,Hui Li;Kailiang Hu;Zhibang Ge;Tao Jiang;Yuan Qi;Le Song,ken.lh@antfin.com;hkl163251@antfin.com;zhibang.zg@antfin.com;lvshan.jt@antfin.com;yuan.qi@antfin.com;lsong@cc.gatech.edu,5;6;4,4;2;5,Reject,5,8,0.0,yes,9/25/19,Antfin;Antfin;Antfin;Antfin;Antfin;Georgia Institute of Technology,Counterfactual Regret Minimization;Imperfect Information game,-1;-1;-1;-1;-1;13,-1;-1;-1;-1;-1;33,u;m,usa,usa,y,10
2451,ICLR,2019,Escaping Flat Areas via Function-Preserving Structural Network Modifications,Yannic Kilcher;Gary B√©cigneul;Thomas Hofmann,yannic.kilcher@inf.ethz.ch;garybecigneul06@gmail.com;thomas.hofmann@inf.ethz.ch,6;6;4,4;3;4,Reject,0,2,0.0,yes,9/27/18,Swiss Federal Institute of Technology;;Swiss Federal Institute of Technology,deep learning;cnn;structural modification;optimization;saddle point,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2452,ICLR,2019,DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation,Rim Assouel;Mohamed Ahmed;Marwin Segler;Amir Saffari;Yoshua Bengio,rim.assouel@hotmail.fr;mohamed.ahmed@benevolent.ai;marwin.segler@benevolent.ai;amir.saffari@benevolent.ai;yoshua.bengio@mila.quebec,4;3;5,4;5;3,Reject,4,4,0.0,yes,9/27/18,Université de Montréal;BenevolentAI;BenevolentAI;BenevolentAI;Mila,molecular graphs;conditional autoencoder;graph autoencoder,-1;-1;-1;-1;136,-1;-1;-1;-1;314,-1;-1,NAN,NAN,n,10;5
2453,ICLR,2019,Neural Random Projections for Language Modelling,Davide Nunes;Luis Antunes,nunesd@campus.ul.pt;xarax@ciencias.ulisboa.pt,3;4;3,4;3;4,Reject,0,7,0.0,yes,9/27/18,"Faculdade de Ci√™ncias, Universidade de Lisboa, Portugal;University of Lisbon",neural networks;language modelling;natural language processing;uncertainty;random projections,116;-1,-1;509,-1;-1,NAN,NAN,n,3
2454,ICLR,2019,NATTACK: A STRONG AND UNIVERSAL GAUSSIAN BLACK-BOX ADVERSARIAL ATTACK,Yandong Li;Lijun Li;Liqiang Wang;Tong Zhang;Boqing Gong,lyndon.leeseu@outlook.com;lilijun1990@buaa.edu.cn;lwang@cs.ucf.edu;bradymzhang@tencent.com;boqinggo@outlook.com,7;4;4,3;3;5,Reject,4,25,0.0,yes,9/27/18,Google;Beihang University;University of Central Florida;Tencent AI Lab;International Computer Science Institute,adversarial attack;black-box;evolutional strategy;policy gradient,-1;94;77;-1;-1,-1;658;-1;-1;-1,-1;-1,NAN,NAN,n,4
2455,ICLR,2019,Improved resistance of neural networks to adversarial images through generative pre-training,Joachim Wabnig,joachim.wabnig@nokia-bell-labs.com,4;4;6,4;3;4,Reject,0,6,0.0,yes,9/27/18,Bell Labs,adversarial images;Boltzmann machine;mean field approximation,-1,-1,-1,NAN,NAN,n,5;4
2456,ICLR,2019,Select Via Proxy: Efficient Data Selection For Training Deep Networks,Cody Coleman;Stephen Mussmann;Baharan Mirzasoleiman;Peter Bailis;Percy Liang;Jure Leskovec;Matei Zaharia,cody@cs.stanford.edu;mussmann@stanford.edu;baharanm@stanford.edu;pbailis@stanford.edu;pliang@cs.stanford.edu;jure@cs.stanford.edu;mzaharia@stanford.edu,4;4;5,4;2;4,Reject,2,5,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,data selection;deep learning;uncertainty sampling,4;4;4;4;4;4;4,3;3;3;3;3;3;3,-1;-1,usa,usa,n,3
2457,ICLR,2019,Generalized Capsule Networks with Trainable Routing Procedure,Zhenhua Chen;Chuhua Wang;Tiancong Zhao;David Crandall,chen478@iu.edu;cw234@iu.edu;tz11@iu.edu;djcran@iu.edu,4;5;3,5;3;5,Reject,0,6,0.0,yes,9/27/18,"Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington",Capsule networks;generalization;scalability;adversarial robustness,67;67;67;67,117;117;117;117,-1;-1,NAN,NAN,n,1;5;4
2458,ICLR,2019,Padam: Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks,Jinghui Chen;Quanquan Gu,jc4zg@virginia.edu;qgu@cs.ucla.edu,6;6;9,4;4;3,Reject,0,5,0.0,yes,9/27/18,"University of Virginia;University of California, Los Angeles",,59;-1,113;15,-1;-1,usa,usa,y,1;9
2459,ICLR,2019,Text Embeddings for Retrieval from a Large Knowledge Base,Tolgahan Cakaloglu;Christian Szegedy;Xiaowei Xu,txcakaloglu@ualr.edu;szegedy@google.com;xwxu@ualr.edu,3;5;3,4;4;5,Reject,0,0,0.0,yes,9/27/18,"University of Arkansas, Little Rock;Google;University of Arkansas, Little Rock",Text Embeddings;Document Ranking;Improving Retrieval;Question-Answering;Learning to Rank,285;-1;285,585;-1;585,-1;-1,NAN,NAN,n,3
2460,ICLR,2019,Combining Learned Representations for Combinatorial Optimization,Saavan Patel;Sayeef Salahuddin,saavan@berkeley.edu;sayeef@berkeley.edu,4;4;5,3;5;3,Reject,0,4,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley,Generative Models;Restricted Boltzmann Machines;Transfer Learning;Compositional Learning,-1;-1,18;18,-1;-1,usa,usa,n,
2461,ICLR,2019,Intriguing Properties of Learned Representations,Amartya Sanyal;Varun Kanade;Philip H. Torr,amartya.sanyal@cs.ox.ac.uk;varunk@cs.ox.ac.uk;philip.torr@eng.ox.ac.uk,3;6;5,4;2;2,Reject,0,5,0.0,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,deep learning;low rank representations;adversarial robustness,44;44;44,1;1;1,-1;-1,europe,uk,y,6;4
2462,ICLR,2019,Predictive Local Smoothness for Stochastic Gradient Methods,Jun Li;Hongfu Liu;Bineng Zhong;Yue Wu;Yun Fu,junl.mldl@gmail.com;hongfuliu@brandeis.edu;bnzhong@gmail.com;wuyuebupt@gmail.com;yunfu@ece.neu.edu,2;3;2;4,4;3;5;5,Reject,0,0,0.0,yes,9/27/18,Massachusetts Institute of Technology;Brandeis University;;;Northeastern University,stochastic gradient method;local smoothness;linear system;AMSGrad,6;207;-1;-1;15,5;223;-1;-1;839,-1;-1,usa,usa,y,1;9
2463,ICLR,2019,Accelerating first order optimization algorithms,Ange tato;Roger nkambou,nyamen_tato.ange_adrienne@courrier.uqam.ca;nkambou.roger@uqam.ca,3;4;4,3;3;5,Reject,0,0,0.0,yes,9/27/18,UQAM;UQAM,Optimization;Optimizer;Adam;Gradient Descent,-1;-1,-1;-1,-1;-1,asia,ir,y,
2464,ICLR,2019,An Analysis of Composite Neural Network Performance from Function Composition Perspective,Ming-Chuan Yang;Meng Chang Chen,mingchuan@iis.sinica.edu.tw;mcc@iis.sinica.edu.tw,3;3;3,2;3;4,Reject,0,3,0.0,yes,9/27/18,Academia Sinica;Academia Sinica,,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1;10
2465,ICLR,2019,Complexity of Training ReLU Neural Networks,Digvijay Boob;Santanu S. Dey;Guanghui Lan,digvijaybb40@gatech.edu;santanu.dey@isye.gatech.edu;george.lan@isye.gatech.edu,3;5;4,5;5;3,Reject,0,0,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,NP-hardness;ReLU activation;Two hidden layer networks,13;13;13,33;33;33,-1;-1,usa,usa,y,
2466,ICLR,2019,Backdrop: Stochastic Backpropagation,Siavash Golkar;Kyle Cranmer,siavash.golkar@gmail.com;kyle.cranmer@nyu.edu,5;5;3,3;3;3,Reject,0,0,0.0,yes,9/27/18,Flatiron Institute;New York University,stochastic optimization;multi-scale data analysis;non-decomposable loss;generalization;one-shot learning,-1;24,-1;27,-1;-1,usa,usa,n,1
2467,ICLR,2019,A preconditioned accelerated stochastic gradient descent algorithm,Alexandru Onose;Seyed Iman Mossavat;Henk-Jan H. Smilde,alexandru.onose@asml.com;iman.mossavat@asml.com;henk-jan.smilde@asml.com,4;4;5,3;5;3,Reject,0,0,0.0,yes,9/27/18,Asml;Asml;Asml,stochastic optimization;neural network;preconditioned accelerated stochastic gradient descent,-1;-1;-1,-1;-1;-1,-1;-1,europe,gr,y,1
2468,ICLR,2019,Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification,Xiang Jiang;Mohammad Havaei;Gabriel Chartrand;Hassan Chouaib;Thomas Vincent;Andrew Jesson;Nicolas Chapados;Stan Matwin,xiang.jiang@dal.ca;mohammad@imagia.com;gabriel@imagia.com;hassan.chouaib@imagia.com;thomas.vincent@imagia.com;andrew.jesson@imagia.com;nic@imagia.com;stan@cs.dal.ca,5;5;7,4;3;3,Reject,0,0,0.0,yes,9/27/18,Dalhousie University;Imagia;Imagia;Imagia;Imagia;Imagia;Imagia;Dalhousie University,meta-learning;learning to learn;few-shot learning,285;-1;-1;-1;-1;-1;-1;285,289;-1;-1;-1;-1;-1;-1;289,-1;-1,canada,ca,n,3;8;1;6
2469,ICLR,2019,Open Vocabulary Learning on Source Code with a Graph-Structured Cache,Milan Cvitkovic;Badal Singh;Anima Anandkumar,mcvitkov@caltech.edu;sbadal@amazon.com;anima@caltech.edu,4;4;6,4;4;5,Reject,0,13,0.0,yes,9/27/18,California Institute of Technology;Amazon;California Institute of Technology,deep learning;graph neural network;open vocabulary;natural language processing;source code;abstract syntax tree;code completion;variable naming,136;-1;136,3;-1;3,-1;-1,usa,usa,n,3;10
2470,ICLR,2019,The Natural Language Decathlon: Multitask Learning as Question Answering,Bryan McCann;Nitish Shirish Keskar;Caiming Xiong;Richard Socher,bmccann@salesforce.com;nkeskar@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,5;5;3,3;4;4,Reject,2,18,0.0,yes,9/27/18,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,multitask learning;natural language processing;question answering;machine translation;relation extraction;semantic parsing;commensense reasoning;summarization;entailment;sentiment;dialog,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;3
2471,ICLR,2019,NEURAL MALWARE CONTROL WITH DEEP REINFORCEMENT LEARNING,Yu Wang;Jack W. Stokes;Mady Marinescu,yu.wang@yale.edu;jstokes@microsoft.com;mady@microsoft.com,5;4;5,2;3;2,Reject,0,3,0.0,yes,9/27/18,Yale University;Microsoft;Microsoft,malware;execution;control;deep reinforcement learning,67;-1;-1,12;-1;-1,-1;-1,NAN,NAN,y,4
2472,ICLR,2019,Beyond Games: Bringing Exploration to Robots in Real-world,Deepak Pathak;Dhiraj Gandhi;Abhinav Gupta,pathak@berkeley.edu;dgandhi@andrew.cmu.edu;abhinavg@cs.cmu.edu,5;3;3,3;5;4,Reject,0,18,0.0,yes,9/27/18,University of California Berkeley;Carnegie Mellon University;Carnegie Mellon University,Exploration;curiosity;manipulation,-1;1;1,18;24;24,-1;-1,usa,usa,n,
2473,ICLR,2019,Overcoming catastrophic forgetting through weight consolidation and long-term memory,Shixian Wen;Laurent Itti,shixianwen1993@gmail.com;itti@usc.edu,4;4;4,4;4;5,Reject,2,0,0.0,yes,9/27/18,University of Southern California;University of Southern California,Catastrophic Forgetting;Life-Long Learning;adversarial examples,27;27,66;66,-1;-1,usa,usa,n,4
2474,ICLR,2019,Localized random projections challenge benchmarks for bio-plausible deep learning,Bernd Illing;Wulfram Gerstner;Johanni Brea,bernd.illing@epfl.ch;wulfram.gerstner@epfl.ch;johanni.brea@epfl.ch,5;3;3,3;4;5,Reject,0,4,0.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,deep learning;bio-plausibility;random projections;spiking networks;unsupervised learning;MNIST;spike timing dependent plasticity,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2475,ICLR,2019,Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards,Vikas Dhiman;Shurjo Banerjee;Jeffrey M Siskind;Jason J Corso,dhiman@umich.edu;shurjo@umich.edu;qobi@purdue.edu;jjcorso@umich.edu,4;1;3,3;4;4,Reject,2,6,1.0,yes,9/27/18,University of Michigan;University of Michigan;Purdue University;University of Michigan,Floyd-Warshall;Reinforcement learning;goal conditioned value functions;multi-goal,9;9;24;9,21;21;60;21,-1;-1,usa,usa,n,10
2476,ICLR,2019,Unsupervised Hyper-alignment for Multilingual Word Embeddings,Jean Alaux;Edouard Grave;Marco Cuturi;Armand Joulin,jean.alaux--lorain@ens.fr;egrave@fb.com;marco.cuturi.cameto@gmail.com;ajoulin@fb.com,5;6;7,3;4;3,Accept (Poster),0,1,0.0,yes,9/27/18,Ecole Normale Superieure;Facebook;Google;Facebook,,116;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2477,ICLR,2019,Synthnet: Learning synthesizers end-to-end,Florin Schimbinschi;Christian Walder;Sarah Erfani;James Bailey,florinsch@student.unimelb.edu.au;christian.walder@data61.csiro.au;sarah.erfani@unimelb.edu.au;baileyj@unimelb.edu.au,4;4;3,3;4;5,Reject,0,21,0.0,yes,9/27/18,The University of Melbourne;CSIRO;The University of Melbourne;The University of Melbourne,audio;synthesizers;music;convolutional neural networks;generative models;autoregressive models,77;-1;77;77,32;-1;32;32,-1;-1,NAN,NAN,n,5
2478,ICLR,2019,Relational Graph Attention Networks,Dan Busbridge;Dane Sherburn;Pietro Cavallo;Nils Y. Hammerla,dan.busbridge@gmail.com;danesherbs@gmail.com;p.cavallo85@gmail.com;nils.hammerla@babylonhealth.com,4;4;4,5;4;5,Reject,6,4,0.0,yes,9/27/18,babylon health;babylon health;;babylon health,RGCN;attention;graph convolutional networks;semi-supervised learning;graph classification;molecules,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;10
2479,ICLR,2019,IEA: Inner Ensemble Average within a convolutional neural network,Abduallah Mohamed;Xinrui Hua;Xianda Zhou;Christian Claudel,abduallah.mohamed@utexas.edu;xinruihua@utexas.edu;xianda@utexas.edu;christian.claudel@utexas.edu,4;2;4,3;4;5,Reject,0,6,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Ensemble Convolutional Neural Networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,n,
2480,ICLR,2019,ChainGAN: A sequential approach to GANs,Safwan Hossain;Kiarash Jamali;Yuchen Li;Frank Rudzicz,safwan.hossain@mail.utoronto.ca;kiarash.jamali@mail.utoronto.ca;ychnlgy.li@utoronto.ca;frank@spoclab.com,4;4;4,4;4;4,Reject,0,0,0.0,yes,9/27/18,Toronto University;Toronto University;Toronto University;University of Toronto,Machine Learning;Sequential Models;GANs,-1;-1;-1;18,-1;-1;-1;22,-1;-1,canada,ca,n,5;4
2481,ICLR,2019,Adaptive Convolutional Neural Networks,Julio Cesar Zamora;Jesus Adan Cruz Vargas;Omesh Tickoo,julio.c.zamora.esquivel@intel.com;jesus.a.cruz.vargas@intel.com;omesh.tickoo@intel.com,5;4;4,3;3;4,Reject,0,3,0.0,yes,9/27/18,Intel;Intel;Intel,Adaptive kernels;Dynamic kernels;Pattern recognition;low memory CNNs,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2482,ICLR,2019,Explicit Recall for Efficient Exploration,Honghua Dong;Jiayuan Mao;Xinyue Cui;Lihong Li,dhh19951@gmail.com;maojiayuan@gmail.com;rogar2233cxy@gmail.com;lihongli.cs@gmail.com,7;4;3,3;4;4,Reject,0,6,0.0,yes,9/27/18,University of Toronto;Massachusetts Institute of Technology;;Amazon,Exploration;goal-directed;deep reinforcement learning;explicit memory,18;6;-1;-1,22;5;-1;-1,-1;-1,NAN,NAN,n,
2483,ICLR,2019,A Multi-modal one-class generative adversarial network for anomaly detection in manufacturing,Shuhui Qu;Janghwan Lee;Wei Xiong;Wonhyouk Jang;Jie Wang,shuhuiq@stanford.edu;jake.ee@samsung.com;w.xiong@samsung.com;damian.jang@samsung.com;jiewang@stanford.edu,3;4;5,4;5;4,Reject,0,0,0.0,yes,9/27/18,Stanford University;Samsung;Samsung;Samsung;Stanford University,Anomaly detection;one-class model;GAN,4;-1;-1;-1;4,3;-1;-1;-1;3,-1;-1,usa,usa,n,5;4
2484,ICLR,2019,Learning to encode spatial relations from natural language,Tiago Ramalho;Tomas Kocisky‚Äé;Frederic Besse;S. M. Ali Eslami;Gabor Melis;Fabio Viola;Phil Blunsom;Karl Moritz Hermann,tiago.mpramalho@gmail.com;tkocisky@google.com;fbesse@google.com;aeslami@google.com;melisgl@google.com;fviola@google.com;pblunsom@google.com;kmh@google.com,6;5;5,5;4;4,Reject,0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,generative model;grounded language;scene understanding;natural language,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2485,ICLR,2019,D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation,Florent CHIARONI. Mohamed-Cherif RAHAL. Nicolas HUEBER. Fr√©d√©ric DUFAUX.,florent.chiaroni@vedecom.fr;mohamed.rahal@vedecom.fr;nicolas.hueber@isl.eu;frederic.dufaux@l2s.centralesupelec.fr,3;5;3,4;1;5,Reject,1,11,0.0,yes,9/27/18,ETS Montrea;;;CentraleSupelec,Representation learning. Generative Adversarial Network (GAN). Positive Unlabeled learning. Image classification,-1;-1;-1;-1,-1;-1;-1;452,-1,NAN,NAN,n,5;4
2486,ICLR,2019,Assessing Generalization in Deep Reinforcement Learning,Charles Packer*;Katelyn Gao*;Jernej Kos;Philipp Krahenbuhl;Vladlen Koltun;Dawn Song,cpacker@berkeley.edu;katelyn.gao@intel.com;jernej@kos.mx;philkr@cs.utexas.edu;vladlen.koltun@intel.com;dawnsong@berkeley.edu,5;3;5,2;5;3,Reject,0,5,0.0,yes,9/27/18,"University of California Berkeley;Intel;National University of Singapore;University of Texas, Austin;Intel;University of California Berkeley",reinforcement learning;generalization;benchmark,-1;-1;18;-1;-1;-1,18;-1;22;-1;-1;18,-1;-1,usa,usa,n,1
2487,ICLR,2019,Where and when to look? Spatial-temporal attention for action recognition in videos,Lili Meng;Bo Zhao;Bo Chang;Gao Huang;Frederick Tung;Leonid Sigal,lilimeng1103@gmail.com;bzhao03@cs.ubc.ca;bchang@stat.ubc.ca;gh349@cornell.edu;ftung@sfu.ca;lsigal@cs.ubc.ca,6;6;3,4;4;5,Reject,0,8,0.0,yes,9/27/18,University of British Columbia;University of British Columbia;University of British Columbia;Cornell University;Simon Fraser University;University of British Columbia,visual attention;video action recognition;network interpretability,59;59;59;6;50;59,34;34;34;19;253;34,-1;-1,canada,ca,y,8
2488,ICLR,2019,Integrated Steganography and Steganalysis with Generative Adversarial Networks,Chong Yu,dxxzdxxz@126.com,5;6;5,5;4;2,Reject,0,2,0.0,yes,9/27/18,NVIDIA,Steganography;Steganography;Security;Generative Adversarial Networks,-1,-1,-1,NAN,NAN,n,2;5;4
2489,ICLR,2019,Heated-Up Softmax Embedding,Xu Zhang;Felix Xinnan Yu;Svebor Karaman;Wei Zhang;Shih-Fu Chang,xu.zhang@columbia.edu;felixyu@google.com;svebor.karaman@gmail.com;wz2363@columbia.edu;sc250@columbia.edu,8;3;5,4;5;4,Reject,0,3,0.0,yes,9/27/18,Columbia University;Google;Columbia University;Columbia University;Columbia University,,21;-1;21;21;21,14;-1;14;14;14,-1;-1,usa,usa,n,1
2490,ICLR,2019,"S3TA: A Soft, Spatial, Sequential, Top-Down Attention Model",Alex Mott;Daniel Zoran;Mike Chrzanowski;Daan Wierstra;Danilo J. Rezende,alexmott@google.com;danielzoran@google.com;chrzanowskim@google.com;wierstra@google.com;danilor@google.com,5;5;5,4;4;4,Reject,0,4,0.0,yes,9/27/18,Google;Google;Google;Google;Google,Attention;RL;Top-Down;Interpretability,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
2491,ICLR,2019,ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT,Tin Lay Nwe;Shudong Xie;Balaji Nataraj;Yiqun Li;Joo-Hwee Lim,tlnma@i2r.a-star.edu.sg;xie_shudong@i2r.a-star.edu.sg;e0267605@u.nus.edu;yqli@i2r.a-star.edu.sg;joohwee@i2r.a-star.edu.sg,5;4;3,5;4;4,Reject,0,0,0.0,yes,9/27/18,"Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;National University of Singapore;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR",Incremental learning;deep learning;autoencoder;privacy;convolutional neural network,-1;-1;18;-1;-1,-1;-1;22;-1;-1,-1;-1,NAN,NAN,n,
2492,ICLR,2019,"Look Ma, No GANs! Image Transformation with ModifAE",Chad Atalla;Bartholomew Tam;Amanda Song;Gary Cottrell,chada@ucsd.edu;b4tam@ucsd.edu,3;4;5,4;4;3,Reject,0,0,0.0,yes,9/27/18,"University of California, San Diego;University of California, San Diego",Computer Vision;Deep Learning;Autoencoder;GAN;Image Modification;Social Traits;Social Psychology,-1;-1,31;31,-1;-1,usa,usa,n,5
2493,ICLR,2019,Object detection deep learning networks for Optical Character Recognition,Christopher Bourez;Aurelien Coquard,christopher.bourez@gmail.com;acq@ivalua.com,2;1;2;1,5;5;5;5,Reject,0,0,0.0,yes,9/27/18,Ivalua Inc;Ivalua Inc,OCR;object detection;RCNN;Yolo,-1;-1,-1;-1,-1;-1,NAN,NAN,n,2
2494,ICLR,2019,Learning to Drive by Observing the Best and Synthesizing the Worst,Mayank Bansal;Alex Krizhevsky;Abhijit Ogale,mayban@waymo.com;akrizhevsky@gmail.com;ogale@waymo.com,3;6;5,4;4;4,Reject,0,8,0.0,yes,9/27/18,Waymo;;Waymo,Imitation Learning;End-to-End Driving;Learning to drive;Autonomous Driving,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2495,ICLR,2019,An adaptive homeostatic algorithm for the unsupervised learning of visual features,Victor Boutin;Angelo Franciosini;Laurent Perrinet,victor.boutin@univ-amu.fr;angelo.franciosini@univ-amu.fr;laurent.perrinet@univ-amu.fr,5;4;9,5;4;4,Reject,0,5,0.0,yes,9/27/18,Aix Marseille Univ;Aix Marseille Univ;Aix Marseille Univ,Sparse Coding;Unsupervised Learning;Natural Scene Statistics;Biologically Plausible Deep Networks;Visual Perception;Computer Vision,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2496,ICLR,2019,Efficient Exploration through Bayesian Deep Q-Networks,Kamyar Azizzadenesheli;Animashree Anandkumar,kazizzad@uci.edu;anima@caltech.edu,4;6;2;4,2;2;5;4,Reject,2,16,3.0,yes,9/27/18,"University of California, Irvine;California Institute of Technology",Deep RL;Exploration Exploitation;DQN;Bayesian Regret;Thompson Sampling,-1;136,99;3,-1;-1,usa,usa,y,11;1
2497,ICLR,2019,Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks,Saeid Asgari Taghanaki;Shekoofeh Azizi;Ghassan Hamarneh,sasgarit@sfu.ca;shazizi@ece.ubc.ca;hamarneh@sfu.ca,4;4;3,4;3;4,Reject,0,0,0.0,yes,9/27/18,Simon Fraser University;University of British Columbia;Simon Fraser University,Radial basis feature transformation;convolutional neural networks;adversarial defense,50;59;50,253;34;253,-1;-1,canada,ca,n,2;4
2498,ICLR,2019,Machine Translation With Weakly Paired Bilingual Documents,Lijun Wu;Jinhua Zhu;Di He;Fei Gao;Xu Tan;Tao Qin;Tie-Yan Liu,wulijun3@mail2.sysu.edu.cn;teslazhu@mail.ustc.edu.cn;di_he@pku.edu.cn;feiga@microsoft.com;xuta@microsoft.com;taoqin@microsoft.com;tyliu@microsoft.com,7;6;5,5;3;5,Reject,1,14,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;University of Science and Technology of China;Peking University;Microsoft;Microsoft;Microsoft;Microsoft,Natural Language Processing;Machine Translation;Unsupervised Learning,-1;-1;14;-1;-1;-1;-1,352;132;27;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2499,ICLR,2019,DVOLVER: Efficient Pareto-Optimal Neural Network Architecture Search,Guillaume Michel;Mohammed Amine Alaoui;Alice Lebois;Amal Feriani;Mehdi Felhi,guillaume.michel@netatmo.com;mohammed-amine.alaoui@netatmo.com;alice.lebois@netatmo.com;amal.feriani@netatmo.com;mehdi.felhi@netatmo.com,4;5;4,4;3;4,Reject,0,3,0.0,yes,9/27/18,Netatmo;Netatmo;Netatmo;Georgia Institute of Technology;Netatmo,architecture search;Pareto optimality;multi-objective;optimization;cnn;deep learning,-1;-1;-1;13;-1,-1;-1;-1;33;-1,-1;-1,NAN,NAN,n,
2500,ICLR,2019,Complementary-label learning for arbitrary losses and models,Takashi Ishida;Gang Niu;Aditya Krishna Menon;Masashi Sugiyama,ishida@ms.k.u-tokyo.ac.jp;gang.niu@riken.jp;aditya.menon@anu.edu.au;sugi@k.u-tokyo.ac.jp,5;5;6,3;4;4,Reject,0,3,0.0,yes,9/27/18,The University of Tokyo;RIKEN;Australian National University;The University of Tokyo,complementary labels;weak supervision,59;-1;116;59,45;-1;48;45,-1;-1,NAN,NAN,y,
2501,ICLR,2019,Feature Transformers: A Unified Representation Learning Framework for Lifelong Learning,Hariharan Ravishankar;Rahul Venkataramani;Saihareesh Anamandra;Prasad Sudhakar,hariharan.ravishankar@ge.com;rahul.venkataramani@ge.com;saihareesh.anamandra@ge.com;prasad.sudhakar@ge.com,4;3;4,3;4;5,Reject,0,4,0.0,yes,9/27/18,General Electric;General Electric;General Electric;General Electric,continual learning;deep learning;lifelong learning;new task learning;representation learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8
2502,ICLR,2019,Functional Bayesian Neural Networks for Model Uncertainty Quantification,Nanyang Ye;Zhanxing Zhu,yn272@cam.ac.uk;zhanxing.zhu@pku.edu.cn,3;4;5,3;4;2,Reject,0,0,0.0,yes,9/27/18,University of Cambridge;Peking University,,77;14,2;27,-1;-1,asia,cn,n,11
2503,ICLR,2019,Learning shared manifold representation of images and attributes for generalized zero-shot learning,Masahiro Suzuki;Yusuke Iwasawa;Yutaka Matsuo,masa@weblab.t.u-tokyo.ac.jp;iwasawa@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,5;5;4,4;4;5,Reject,0,6,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo;The University of Tokyo,zero-shot learning;variational autoencoders,59;59;59,45;45;45,-1;-1,NAN,NAN,n,6;5
2504,ICLR,2019,Continual Learning via Explicit Structure Learning,Xilai Li;Yingbo Zhou;Tianfu Wu;Richard Socher;Caiming Xiong,xli47@ncsu.edu;yingbo.zhou@salesforce.com;tianfu_wu@ncsu.edu;rsocher@salesforce.com;cxiong@salesforce.com,4;4;4,4;4;5,Reject,0,8,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;SalesForce.com;SUN YAT-SEN UNIVERSITY;SalesForce.com;SalesForce.com,continuous learning;catastrophic forgetting;architecture learning,-1;-1;-1;-1;-1,352;-1;352;-1;-1,-1;-1,NAN,NAN,n,
2505,ICLR,2019,In Your Pace: Learning the Right Example at the Right Time,Guy Hacohen;Daphna Weinshall,guy.hacohen@mail.huji.ac.il;daphna@cs.huji.ac.il,5;4;4,4;4;4,Reject,3,1,0.0,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem,Curriculum Learning;Transfer Learning;Self-Paced Learning;Image Recognition,77;77,205;205,-1;-1,europe,il,n,6
2506,ICLR,2019,Polar Prototype Networks,Pascal Mettes;Elise van der Pol;Cees G. M. Snoek,p.s.m.mettes@uva.nl;e.e.vanderpol@uva.nl;cgmsnoek@uva.nl,5;3;4,3;4;5,Reject,0,4,0.0,yes,9/27/18,University of Amsterdam;University of Amsterdam;University of Amsterdam,prototype networks;polar prototypes;output structure,136;136;136,59;59;59,-1;-1,europe,nl,n,
2507,ICLR,2019,Meta-Learning for Contextual Bandit Exploration,Amr Sharaf;Hal Daum√© III,amr@cs.umd.edu;hal@umiacs.umd.edu,7;6;3,4;4;4,Reject,0,3,0.0,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park",meta-learning;bandits;exploration;imitation learning,12;12,69;69,m;m,usa,usa,y,6
2508,ICLR,2019,FEED: Feature-level Ensemble Effect for knowledge Distillation,SeongUk Park;Nojun Kwak,swpark0703@snu.ac.kr;nojunk@snu.ac.kr,5;4;4,3;3;4,Reject,0,5,0.0,yes,9/27/18,Seoul National University;Seoul National University,Knowledge Distillation;Ensemble Effect;Knowledge Transfer,36;36,74;74,-1;-1,asia,kr,n,
2509,ICLR,2019,Like What You Like: Knowledge Distill via Neuron Selectivity Transfer,Zehao Huang;Naiyan Wang,zehaohuang18@gmail.com;winsty@gmail.com,4;4;6,4;4;5,Reject,2,0,0.0,yes,9/27/18,TuSimple;TuSimple,Knowledge Distill,-1;-1,-1;-1,-1;-1,asia,in,n,8;2
2510,ICLR,2019,Activity Regularization for Continual Learning,Quang H. Pham;Steven C. H. Hoi,hqpham.2017@smu.edu.sg;chhoi@smu.edu.sg,4;4;4,5;5;4,Reject,0,0,0.0,yes,9/27/18,Singapore Management University;Singapore Management University,continual learning;regularization,77;77,-1;-1,-1;-1,asia,sg,n,
2511,ICLR,2019,Empirical Study of Easy and Hard Examples in CNN Training,Ikki Kishida;Hideki Nakayama,kishida@nlab.ci.i.u-tokyo.ac.jp;nakayama@nlab.ci.i.u-tokyo.ac.jp,3;4;3,4;5;4,Reject,0,0,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo,easy examples;hard example;CNN,59;59,45;45,-1;-1,NAN,NAN,n,1
2512,ICLR,2019,Improving machine classification using human uncertainty measurements,Ruairidh M. Battleday;Joshua C. Peterson;Thomas L. Griffiths,ruairidh.battleday@gmail.com;peterson.c.joshua@gmail.com;tomg@princeton.edu,6;3;3,4;5;2,Reject,3,0,0.0,yes,9/27/18,Princeton University;University of California Berkeley;Princeton University,image classification;human experiments;risk minimization,-1;-1;31,-1;18;7,-1;-1,usa,usa,n,1;4
2513,ICLR,2019,Policy Optimization via Stochastic Recursive Gradient Algorithm,Huizhuo Yuan;Chris Junchi Li;Yuhao Tang;Yuren Zhou,yuanhz@pku.edu.cn;junchi.li.duke@gmail.com;yuhaotang97@gmail.com;yuren.zhou@duke.edu,5;6;5,3;2;3,Reject,0,1,0.0,yes,9/27/18,Peking University;University of California Berkeley;University of Nottingham;Duke University,reinforcement learning;policy gradient;variance reduction;stochastic recursive gradient algorithm,14;-1;207;47,27;18;146;17,-1;-1,europe,se,n,1
2514,ICLR,2019,Discriminative Active Learning,Daniel Gissin;Shai Shalev-Shwartz,daniel.gissin@mail.huji.ac.il;shais@cs.huji.ac.il,6;8;4,4;4;4,Reject,0,15,0.0,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem,Active Learning;Neural Networks,77;77,205;205,-1;-1,europe,il,n,
2515,ICLR,2019,Robustness and Equivariance of Neural Networks,Amit Deshpande;Sandesh Kamath;K.V.Subrahmanyam,amitdesh@microsoft.com;ksandeshk@cmi.ac.in;kv@cmi.ac.in,3;4;5,5;4;3,Reject,0,3,0.0,yes,9/27/18,Microsoft;Chennai Mathematical Institute;Chennai Mathematical Institute,robust;adversarial;equivariance;rotations;GCNNs;CNNs;steerable;neural networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8;4
2516,ICLR,2019,Knowledge Distillation from Few Samples,Tianhong Li;Jianguo Li;Zhuang Liu;Changshui Zhang,tianhong@mit.edu;jianguo.li@intel.com;zhuangl@berkeley.edu;zcs@mail.tsinghua.edu.cn,4;6;6,4;4;3,Reject,2,12,0.0,yes,9/27/18,"Massachusetts Institute of Technology;Intel;University of California Berkeley;Tsinghua University, Tsinghua University",knowledge distillation;few-sample learning;network compression,6;-1;-1;4,5;-1;18;30,-1;-1,NAN,NAN,n,1
2517,ICLR,2019,An Automatic Operation Batching Strategy for the Backward Propagation of Neural Networks Having Dynamic Computation Graphs,Yuchen Qiao;Kenjiro Taura,qiao@eidos.ic.i.u-tokyo.ac.jp;tau@eidos.ic.i.u-tokyo.ac.jp,5;6;4,3;5;4,Reject,0,1,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo,Automatic Operation Batching;Dynamic Computation Graphs,59;59,45;45,-1;-1,NAN,NAN,n,10
2518,ICLR,2019,Graph Learning Network: A Structure Learning Algorithm,Darwin Danilo Saire Pilco;Ad√≠n Ram√≠rez Rivera,darwin.pilco@ic.unicamp.br;adin@ic.unicamp.br,4;3;4,5;4;4,Reject,0,4,0.0,yes,9/27/18,University of Campinas;University of Campinas,graph prediction;graph structure learning;graph neural network,-1;-1,441;441,-1;-1,NAN,NAN,n,10
2519,ICLR,2019,Remember and Forget for Experience Replay,Guido Novati;Petros Koumoutsakos,novatig@ethz.ch;petros@ethz.ch,7;6;6,3;3;3,Reject,0,6,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,reinforcement learning;experience replay;policy gradients,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2520,ICLR,2019,Probabilistic Model-Based Dynamic Architecture Search,Nozomu Yoshinari;Kento Uchida;Shota Saito;Shinichi Shirakawa;Youhei Akimoto,yoshinari-nozomu-ry@ynu.jp;uchida-kento-nc@ynu.jp;saito-shota-bt@ynu.jp;shirakawa-shinichi-bg@ynu.ac.jp;akimoto@cs.tsukuba.ac.jp,5;6;5,4;4;4,Reject,0,4,0.0,yes,9/27/18,Yokohama National University;Yokohama National University;Yokohama National University;Meiji University;The University of Tsukuba,architecture search;stochastic natural gradient;convolutional neural networks,-1;-1;-1;-1;94,827;827;827;978;468,-1;-1,NAN,NAN,n,2
2521,ICLR,2019,Talk The Walk: Navigating Grids in New York City through Grounded Dialogue,Harm de Vries;Kurt Shuster;Dhruv Batra;Devi Parikh;Jason Weston;Douwe Kiela,mail@harmdevries.com;kshuster@fb.com;dbatra@gatech.edu;parikh@gatech.edu;jase@fb.com;dkiela@fb.com,6;7;4,4;4;3,Reject,2,0,3.0,yes,9/27/18,Harmdevries;Facebook;Georgia Institute of Technology;Georgia Institute of Technology;Facebook;Facebook,Dialogue;Navigation;Grounded Language Learning,-1;-1;13;13;-1;-1,-1;-1;33;33;-1;-1,-1;-1,NAN,NAN,n,8;3
2522,ICLR,2019,Large-scale classification of structured objects using a CRF with deep class embedding,Eran Goldman;Jacob Goldberger,eg4000@gmail.com;jacob.goldberger@biu.ac.il,4;3;3,4;3;5,Reject,0,0,0.0,yes,9/27/18,Bar Ilan University;Bar Ilan University,large-scale structure prediction;likelihood approximation;deep class embedding,-1;94,-1;456,-1;-1,europe,il,n,
2523,ICLR,2019,Deep Ensemble Bayesian Active Learning : Adressing the Mode Collapse issue in Monte Carlo dropout via Ensembles,Remus Pop;Patric Fulop,remus.p.pop@gmail.com;patric.fulop@ed.ac.uk,4;4;5,4;4;4,Reject,0,9,0.0,yes,9/27/18,University of Edinburgh;University of Edinburgh,Active Learning;Deep Learning;Bayesian Neural Networks;Bayesian Deep Learning;Ensembles,-1;36,-1;27,-1;-1,europe,uk,n,11
2524,ICLR,2019,MixFeat: Mix Feature in Latent Space Learns Discriminative Space,Yoichi Yaguchi;Fumiyuki Shiratani;Hidekazu Iwaki,yoichi_yaguchi@ot.olympus.co.jp;f_shiratani@ot.olympus.co.jp;h_iwaki@ot.olympus.co.jp,6;4;4,4;3;4,Reject,0,10,0.0,yes,9/27/18,Olympus Corporation;Olympus Corporation;Olympus Corporation,regularization;generalization;image classification;latent space;feature learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2525,ICLR,2019,Question Generation using a Scratchpad Encoder,Ryan Y Benmalek;Madian Khabsa;Suma Desu;Claire Cardie;Michele Banko,ryanai3@cs.cornell.edu;me@madiankhabsa.com;desuma24@gmail.com;cardie@cs.cornell.edu;mbanko@apple.com,4;3;4,4;5;5,Reject,0,3,0.0,yes,9/27/18,Cornell University;Facebook;;Cornell University;Apple,Question Generation;Natural Language Generation;Scratchpad Encoder;Sequence to Sequence,6;-1;-1;6;-1,19;-1;-1;19;-1,-1;-1,NAN,NAN,n,3
2526,ICLR,2019,Interpreting Adversarial Robustness: A View from Decision Surface in Input Space,Fuxun Yu;Chenchen Liu;Yanzhi Wang;Xiang Chen,fyu2@gmu.edu;chliu@clarkson.edu;yanz.wang@northeastern.edu;xchen26@gmu.com,3;6;5,5;4;5,Reject,1,8,1.0,yes,9/27/18,George Mason University;Clarkson University;Northeastern University;Gmu,Adversarial examples;Robustness,94;-1;15;-1,336;-1;839;-1,-1;-1,asia,in,n,1;4
2527,ICLR,2019,Sequenced-Replacement Sampling for Deep Learning,Chiu Man Ho;Dae Hoon Park;Wei Yang;Yi Chang,chiuman100@gmail.com;pdhvip@gmail.com;wei.yang2@huawei.com;yichang@acm.org,3;5;4,4;5;4,Reject,0,0,0.0,yes,9/27/18,"Innopeak Technology;Huawei Technologies Ltd.;Huawei Technologies Ltd.; School of Artificial Intelligence, Jilin University",deep neural networks;stochastic gradient descent;sequenced-replacement sampling,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,asia,in,n,1
2528,ICLR,2019,Representation-Constrained Autoencoders and an Application to Wireless Positioning,Pengzhi Huang;Emre Gonultas;Said Medjkouh;Oscar Castaneda;Olav Tirkkonen;Tom Goldstein;Christoph Studer,ph448@cornell.edu;eg566@cornell.edu;sm2685@cornell.edu;oc66@cornell.edu;olav.tirkkonen@aalto.fi;tomg@cs.umd.edu;studer@cornell.edu,5;4;6,4;4;2,Reject,0,4,0.0,yes,9/27/18,"Cornell University;Cornell University;Cornell University;Cornell University;Aalto University;University of Maryland, College Park;Cornell University",Autoencoder;dimensionality reduction;wireless positioning;channel charting;localization,6;6;6;6;116;12;6,19;19;19;19;190;69;19,-1;-1,usa,usa,n,
2529,ICLR,2019,Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating,Benyuan Sun;Yizhou Wang,sunbenyuan@pku.edu.cn;yizhou.wang@pku.edu.cn,2;3;4,5;3;4,Reject,0,0,0.0,yes,9/27/18,Peking University;Peking University,Curriculum Learning;Internal Covariate Shift,14;14,27;27,-1;-1,asia,cn,n,
2530,ICLR,2019,On the Statistical and Information Theoretical Characteristics of DNN Representations,Daeyoung Choi;Wonjong Rhee;Kyungeun Lee;Changho Shin,choid@snu.ac.kr;wrhee@snu.ac.kr;ruddms0415@snu.ac.kr;chshin@encoredtech.com,5;4;3,3;4;3,Reject,0,8,0.0,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University;University of Southern California,learned representation;statistical characteristics;information theoretical characteristics;deep network,36;36;36;27,74;74;74;66,-1;-1,usa,usa,y,1
2531,ICLR,2019,Trajectory VAE for multi-modal imitation,Xiaoyu Lu;Jan Stuehmer;Katja Hofmann,xiaoyu.lu@stats.ox.ac.uk;t-jastuh@microsoft.com;katja.hofmann@microsoft.com,4;4;4,4;4;4,Reject,0,3,0.0,yes,9/27/18,University of Oxford;Microsoft;Microsoft,imitation learning;latent variable model;variational autoencoder;diverse behaviour,44;-1;-1,1;-1;-1,-1;-1,NAN,NAN,n,5
2532,ICLR,2019,SIMILE: Introducing Sequential Information towards More Effective Imitation Learning,Yutong Bai;Lingxi Xie,ytongbai@gmail.com;198808xc@gmail.com,6;4;4,3;5;4,Reject,0,3,0.0,yes,9/27/18,Johns Hopkins University;Huawei Technologies,Reinforcement Learning;Imitation Learning;Sequential Information,67;-1,13;-1,-1;-1,asia,in,n,
2533,ICLR,2019,A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS,Sylvain Lamprier,sylvain.lamprier@lip6.fr,7;4;4,4;4;4,Reject,0,4,0.0,yes,9/27/18,LIP6,Information Diffusion;Recurrent Neural Network;Black Box Inference,419,-1,-1,asia,ir,n,10
2534,ICLR,2019,Multi-task Learning with Gradient Communication,Pengfei Liu;Xuanjing Huang,pfliu14@fudan.edu.cn;xjhuang@fudan.edu.cn,5;4;7,4;4;3,Reject,0,3,0.0,yes,9/27/18,Fudan University;Fudan University,Pretend to share;Gradient Communication,67;67,116;116,-1;-1,asia,cn,n,
2535,ICLR,2019,Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning,Damien Sileo;Tim Van de Cruys;Camille Pradel;Philippe Muller,damien.sileo@synapse-fr.com;tim.van-de-cruys@irit.fr;camille.pradel@synapse-fr.com;philippe.muller@irit.fr,5;5;6,3;3;4,Reject,0,4,0.0,yes,9/27/18,"Synapse-fr;IRIT, CNRS;Synapse-fr;IRIT, CNRS",Statistical Relational Learning;Sentence Embedding;Composition functions;Natural Language Inference;InferSent;SentEval;ComplEx,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2536,ICLR,2019,A Variational Autoencoder for Probabilistic Non-Negative Matrix Factorisation,Steven Squires;Adam Prugel-Bennett;Mahesan Niranjan,ses2g14@ecs.soton.ac.uk;apb@ecs.soton.ac.uk;mn@ecs.soton.ac.uk,4;4;7,5;3;5,Reject,0,5,0.0,yes,9/27/18,University of Southampton;University of Southampton;University of Southampton,Non-negative matrix factorisation;Variational autoencoder;Probabilistic,207;207;207,126;126;126,-1;-1,europe,uk,n,5
2537,ICLR,2019,Inferring Reward Functions from Demonstrators with Unknown Biases,Rohin Shah;Noah Gundotra;Pieter Abbeel;Anca Dragan,rohinmshah@berkeley.edu;noah.gundotra@berkeley.edu;pabbeel@cs.berkeley.edu;anca@berkeley.edu,5;5;5,4;3;4,Reject,0,0,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Inverse reinforcement learning;differentiable planning,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,
2538,ICLR,2019,Low Latency Privacy Preserving Inference,Alon Brutzkus;Oren Elisha;Ran Gilad-Bachrach,brutzkus@gmail.com;oren.elisha@microsoft.com;rani.gb@gmail.com,5;6;5,3;2;4,Reject,5,4,0.0,yes,9/27/18,Tel Aviv University;Microsoft;Microsoft,privacy;classification;homomorphic encryption;neural networks,31;-1;-1,217;-1;-1,-1;-1,NAN,NAN,n,
2539,ICLR,2019,Ain't Nobody Got Time for Coding: Structure-Aware Program Synthesis from Natural Language,Jakub Bednarek;Karol Piaskowski;Krzysztof Krawiec,jakub.bednarek@put.poznan.pl;kar.piaskowski@gmail.com;krawiec@cs.put.poznan.pl,4;4;4,4;3;5,Reject,0,9,0.0,yes,9/27/18,Poznan University of Technology;Poznan University of Technology;Poznan University of Technology,Program synthesis;tree2tree autoencoders;soft attention;doubly-recurrent neural networks;LSTM;nlp2tree,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,8;3
2540,ICLR,2019,Likelihood-based Permutation Invariant Loss Function for Probability Distributions,Masataro Asai,masataro.asai@ibm.com,5;6;4,4;3;4,Reject,0,11,0.0,yes,9/27/18,International Business Machines,Set reconstruction;maximum likelihood;permutation invariance,-1,-1,-1,NAN,NAN,n,
2541,ICLR,2019,Learning to Progressively Plan,Xinyun Chen;Yuandong Tian,xinyun.chen@berkeley.edu;yuandong@fb.com,5;5;5,3;3;3,Reject,0,6,0.0,yes,9/27/18,University of California Berkeley;Facebook,,-1;-1,18;-1,-1;-1,NAN,NAN,n,
2542,ICLR,2019,"CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks",Yu Wang;Fengjuan Gao;Amin Alipour;Linzhang Wang;Xuandong Li;Zhendong Su,yuwang@seg.nju.edu.cn;fjgao@seg.nju.edu.cn;alipour@cs.uh.edu;lzwang@nju.edu.cn;lxd@nju.edu.cn;zhendong.su@inf.ethz.ch,5;6;5,4;2;4,Reject,1,20,0.0,yes,9/27/18,Zhejiang University;Zhejiang University;University of Houston;Zhejiang University;Zhejiang University;Swiss Federal Institute of Technology,Convolutional Neural Networks;Boolean satisfiability problem;Satisfiability modulo theories,36;36;207;36;36;-1,177;177;330;177;177;-1,-1;-1,NAN,NAN,n,
2543,ICLR,2019,Transferring SLU Models in Novel Domains,Yaohua Tang;Kaixiang Mo;Qian Xu;Chao Zhang;Qiang Yang,yaohuatang@webank.com;kxmo@connect.ust.hk;fleurxq@outlook.com;carlzzhang@webank.com;qyang@cse.ust.hk,6;5;4,4;3;3,Reject,0,0,5.0,yes,9/27/18,"WeBank Co., Ltd.;The Hong Kong University of Science and Technology;;WeBank Co., Ltd.;The Hong Kong University of Science and Technology",transfer learning;semantic representation;spoken language understanding,-1;-1;-1;-1;-1,-1;44;-1;-1;44,-1;-1,NAN,NAN,n,6;3
2544,ICLR,2019,Fake Sentence Detection as a Training Task for Sentence Encoding,Viresh Ranjan;Heeyoung Kwon;Niranjan Balasubramanian;Minh Hoai,vranjan@cs.stonybrook.edu;heekwon@cs.stonybrook.edu;niranjan@cs.stonybrook.edu;minhhoai@cs.stonybrook.edu,5;3;3,3;4;5,Reject,0,0,0.0,yes,9/27/18,"State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook",,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;5
2545,ICLR,2019,Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning,Fabio Pardo;Vitaly Levdik;Petar Kormushev,f.pardo@imperial.ac.uk;v.levdik@imperial.ac.uk;p.kormushev@imperial.ac.uk,4;5;4,3;4;5,Reject,0,7,1.0,yes,9/27/18,Imperial College London;Imperial College London;Imperial College London,reinforcement learning;goal-oriented;convolutions;off-policy,47;47;47,8;8;8,-1;-1,europe,uk,n,1
2546,ICLR,2019,Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video,Samvit Jain;Joseph Gonzalez,samvit@eecs.berkeley.edu;jegonzal@cs.berkeley.edu,5;3;5,4;5;4,Reject,0,4,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley,semantic segmentation;video;efficient inference;video segmentation;video compression,-1;-1,18;18,-1;-1,usa,usa,n,2
2547,ICLR,2019,3D-RelNet: Joint Object and Relational Network for 3D Prediction,Nilesh Kulkarni;Ishan Misra;Shubham Tulsiani;Abhinav Gupta,nileshk@cs.cmu.edu;ishan@cmu.edu;shubhtuls@fb.com;abhinavg@cs.cmu.edu,6;5;3,4;5;5,Reject,0,6,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Facebook;Carnegie Mellon University,3D Reconstruction;3D Scene Understanding;Relative Prediction,1;1;-1;1,24;24;-1;24,-1;-1,usa,usa,n,
2548,ICLR,2019,Image Score: how to select useful samples,Simiao Zuo;Jialin Wu,zsmx1996@utexas.edu;jialinwu@utexas.edu,4;4;3,3;4;3,Reject,0,0,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",,-1;-1,-1;-1,-1;-1,usa,usa,n,
2549,ICLR,2019,Learning Neuron Non-Linearities with Kernel-Based Deep Neural Networks,Giuseppe Marra;Dario Zanca;Alessandro Betti;Marco Gori,g.marra@unifi.it;dario.zanca@unifi.it;alessandro.betti@unifi.it;marco.gori@unisi.it,5;4;6,3;3;4,Reject,0,0,0.0,yes,9/27/18,Universit√† di Firenze;Universit√† di Firenze;Universit√† di Firenze;University of Siena,Activation functions;Kernel methods;Recurrent networks,-1;-1;-1;169,-1;-1;-1;501,-1;-1,europe,uk,n,1
2550,ICLR,2019,DelibGAN: Coarse-to-Fine Text Generation via Adversarial Network,Ke Wang;Xiaojun Wan,wangke17@pku.edu.cn;wanxiaojun@pku.edu.cn,4;3;4,4;4;4,Reject,0,0,0.0,yes,9/27/18,Peking University;Peking University,unsupervised text generation;coarse-to-fine generator;multiple instance discriminator;GAN;DelibGAN,14;14,27;27,-1;-1,asia,cn,n,4
2551,ICLR,2019,High Resolution and Fast Face Completion via Progressively Attentive GANs,Zeyuan Chen;Shaoliang Nie;Tianfu Wu;Christopher G. Healey,zchen23@ncsu.edu;snie@ncsu.edu;tianfu_wu@ncsu.edu;healey@ncsu.edu,5;5;5,5;2;5,Reject,0,4,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Face Completion;progressive GANs;Attribute Control;Frequency-oriented Attention,-1;-1;-1;-1,352;352;352;352,-1;-1,NAN,NAN,n,8;5;4
2552,ICLR,2019,Unsupervised Disentangling Structure and Appearance,Wayne Wu;Kaidi Cao;Cheng Li;Chen Qian;Chen Change Loy,wuwenyan@sensetime.com;kaidicao@cs.stanford.edu;chengli@sensetime.com;qianchen@sensetime.com;ccloy225@gmail.com,6;5;3,4;4;4,Reject,0,0,0.0,yes,9/27/18,SenseTime Group Limited;Stanford University;SenseTime Group Limited;SenseTime Group Limited;the Chinese University of Hong Kong,disentangled representations;VAE;generative models;unsupervised learning,-1;4;-1;-1;47,-1;3;-1;-1;40,-1;-1,NAN,NAN,n,5
2553,ICLR,2019,Language Model Pre-training for Hierarchical Document Representations,Ming-Wei Chang;Kristina Toutanova;Kenton Lee;Jacob Devlin,mingweichang@google.com;kristout@google.com;kentonl@google.com;jacobdevlin@google.com,6;6;6,4;4;4,Reject,0,6,0.0,yes,9/27/18,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2;3
2554,ICLR,2019,Human Action Recognition Based on Spatial-Temporal Attention,Wensong Chan;Zhiqiang Tian;Xuguang Lan,2489925838@qq.com;zhiqiangtian@xjtu.edu.cn;xglan@xjtu.edu.cn,4;3;3,4;5;4,Reject,0,0,0.0,yes,9/27/18,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,,-1;-1;-1,565;565;565,-1;-1,NAN,NAN,n,8
2555,ICLR,2019,Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers,Nathan Inkawhich;Matthew Inkawhich;Hai Li;Yiran Chen,nathan.inkawhich@duke.edu;matthew.inkawhich@duke.edu;hai.li@duke.edu;yiran.chen@duke.edu,4;3;5,5;4;4,Reject,0,4,0.0,yes,9/27/18,Duke University;Duke University;Duke University;Duke University,adversarial attacks;action recognition;video classification,47;47;47;47,17;17;17;17,-1;-1,europe,se,n,4
2556,ICLR,2019,Computing committor functions for the study of rare events using deep learning with importance sampling,Qianxiao Li;Bo Lin;Weiqing Ren,liqix@ihpc.a-star.edu.sg;linbo94@u.nus.edu;matrw@nus.edu.sg,6;6;5;7,4;4;4;4,Reject,0,6,0.0,yes,9/27/18,"Institute of High Performance Computing, Singapore, A*STAR;National University of Singapore;National University of Singapore",committor function;rare event;deep learning;importance sampling,-1;18;18,-1;22;22,-1;-1,asia,sg,n,
2557,ICLR,2019,(Unconstrained) Beam Search is Sensitive to Large Search Discrepancies,Eldan Cohen;J. Christopher Beck,ecohen@mie.utoronto.ca;jcb@mie.utoronto.ca,5;5;7,4;5;5,Reject,0,10,0.0,yes,9/27/18,Toronto University;Toronto University,beam search;sequence models;search;sequence to sequence,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2558,ICLR,2019,Multi-turn Dialogue Response Generation in an Adversarial Learning Framework,Oluwatobi O. Olabiyi;Alan Salimov;Anish Khazane;Erik T. Mueller,oluwatobi.olabiyi@capitalone.com;alan.salimov@capitalone.com;anish.khazan@capitalone.com;erik.mueller@capitalone.com,4;4;6;5,4;4;4;5,Reject,0,5,0.0,yes,9/27/18,Capital One Bank;Capital One Bank;Capital One Bank;Capital One Bank,dialogue models;adversarial networks;dialogue generation,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2559,ICLR,2019,Zero-Resource Multilingual Model Transfer: Learning What to Share,Xilun Chen;Ahmed Hassan Awadallah;Hany Hassan;Wei Wang;Claire Cardie,xlchen@cs.cornell.edu;hassanam@microsoft.com;hanyh@microsoft.com;wei.wang@microsoft.com;cardie@cs.cornell.edu,6;5;6,4;5;4,Reject,0,6,0.0,yes,9/27/18,Cornell University;Microsoft;Microsoft;Microsoft;Cornell University,cross-lingual transfer learning;multilingual transfer learning;zero-resource model transfer;adversarial training;mixture of experts;multilingual natural language understanding,6;-1;-1;-1;6,19;-1;-1;-1;19,-1;-1,usa,usa,n,6;3;4
2560,ICLR,2019,Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning,David Earl Hostallero;Daewoo Kim;Kyunghwan Son;Yung Yi,ddhostallero@kaist.ac.kr;kdw2139@gmail.com;khson@lanada.kaist.ac.kr;yiyung@kaist.edu,5;5;5,3;4;4,Reject,0,4,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,multi-agent reinforcement learning;deep reinforcement learning;multi-agent systems,-1;-1;-1;17,95;95;95;95,-1;-1,asia,in,n,
2561,ICLR,2019,VECTORIZATION METHODS IN RECOMMENDER SYSTEM,Qiang Sun;Bin Wang;Zizhou Gu;Yanwei Fu,sunqiang85@gmail.com;vborisw@gmail.com;2470569@qq.com;yanweifu@fudan.edu.cn,2;2;3,5;5;4,Reject,0,0,0.0,yes,9/27/18,Fudan University;;;Fudan University,,67;-1;-1;67,116;-1;-1;116,-1;-1,asia,cn,n,3
2562,ICLR,2019,The Forward-Backward Embedding of Directed Graphs,Thomas Bonald;Nathan De Lara,thomas.bonald@telecom-paristech.fr;nathan.delara@telecom-paristech.fr,5;3;4,5;5;4,Reject,2,4,0.0,yes,9/27/18,T√©l√©com ParisTech;T√©l√©com ParisTech,Graph embedding;SVD;random walk;co-clustering,-1;-1,-1;-1,-1;-1,NAN,NAN,y,1;10
2563,ICLR,2019,Provable Guarantees on Learning Hierarchical Generative Models with Deep CNNs,Eran Malach;Shai Shalev-Shwartz,eran.malach@mail.huji.ac.il;shais@cs.huji.ac.il,6;4;6,3;4;3,Reject,0,3,0.0,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem,deep learning;theory,77;77,205;205,-1;-1,europe,il,y,5;9
2564,ICLR,2019,Contextualized Role Interaction for Neural Machine Translation,Dirk Weissenborn;Douwe Kiela;Jason Weston;Kyunghyun Cho,dirk.weissenborn@gmail.com;dkiela@fb.com;jase@fb.com;kyunghyun.cho@nyu.edu,4;5;4,5;4;4,Reject,0,5,0.0,yes,9/27/18,German Research Center for AI;Facebook;Facebook;New York University,Neural Machine Translation;Natural Language Processing,-1;-1;-1;24,-1;-1;-1;27,-1;-1,usa,usa,n,3
2565,ICLR,2019,Dual Skew Divergence Loss for Neural Machine Translation,Yingting Wu;Hai Zhao;Rui Wang,wuyingting@sjtu.edu.cn;zhaohai@cs.sjtu.edu.cn;wangrui.nlp@gmail.com,3;6;5,4;4;4,Reject,0,0,0.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,,36;36;36,188;188;188,-1;-1,asia,cn,n,3;1
2566,ICLR,2019,On Accurate Evaluation of GANs for Language Generation,Stanislau Semeniuta;Aliaksei Severyn;Sylvain Gelly,stas@inb.uni-luebeck.de;severyn@google.com;sylvaingelly@google.com,6;5;3,4;4;4,Reject,0,4,0.0,yes,9/27/18,University of Luebeck;Google;Google,GANs;Evaluation;Generative Models,285;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;5;4
2567,ICLR,2019,Zero-shot Dual Machine Translation,Lierni Sestorain;Massimiliano Ciaramita;Christian Buck;Thomas Hofmann,lierni@google.com;massi@google.com;cbuck@google.com;thomas.hofmann@inf.ethz.ch,5;4;6,4;5;3,Reject,0,6,0.0,yes,9/27/18,Google;Google;Google;Swiss Federal Institute of Technology,unsupervised;machine translation;dual learning;zero-shot,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;8;3
2568,ICLR,2019,Towards the Latent Transcriptome,Assya Trofimov;Francis Dutil;Claude Perreault;Sebastien Lemieux;Yoshua Bengio;Joseph Paul Cohen,trofimov.assya@gmail.com;frdutil@gmail.com;claude.perreault@umontreal.ca;s.lemieux@umontreal.ca;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,4;2;5,4;5;4,Reject,0,4,1.0,yes,9/27/18,University of Montreal;;University of Montreal;University of Montreal;Mila;Stanford University,representation learning;RNA-Seq;gene expression;bioinformatics;computational biology;transcriptomics;deep learning;genomics,116;-1;116;116;136;4,108;-1;108;108;314;3,-1;-1,usa,usa,n,
2569,ICLR,2019,On the Relationship between Neural Machine Translation and Word Alignment,Xintong Li;Lemao Liu;Guanlin Li;Max Meng;Shuming Shi,znculee@gmail.com;redmondliu@tencent.com;epsilonlee.green@gmail.com;max.meng@ieee.org;shumingshi@tencent.com,4;5;6,4;4;4,Reject,0,9,0.0,yes,9/27/18,The Chinese University of Hong Kong;Tencent AI Lab;;;Tencent AI Lab,Neural Machine Translation;Word Alignment;Neural Network;Pointwise Mutual Information,285;-1;-1;-1;-1,40;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
2570,ICLR,2019,"FROM DEEP LEARNING TO DEEP DEDUCING: AUTOMATICALLY TRACKING DOWN NASH EQUILIBRIUM THROUGH AUTONOMOUS NEURAL AGENT, A POSSIBLE MISSING STEP TOWARD GENERAL A.I.",Brown Wang,brownwang0426@gmail.com,3;2;4,3;4;5,Reject,0,1,0.0,yes,9/27/18,Nanyang Technological University,Reinforcement Learning;Deep Feed-forward Neural Network;Recurrent Neural Network;Game Theory;Control Theory;Nash Equilibrium;Optimization,44,52,-1,asia,sg,n,
2571,ICLR,2019,Neural Predictive Belief Representations,Zhaohan Daniel Guo;Mohammad Gheshlaghi Azar;Bilal Piot;Bernardo Avila Pires;R√©mi Munos,z.daniel.guo@gmail.com;mazar@google.com;piot@google.com;bavilapires@google.com;munos@google.com,4;7;5,3;4;3,Reject,0,4,0.0,yes,9/27/18,DeepMind;Google;Google;Google;Google,belief states;representation learning;contrastive predictive coding;reinforcement learning;predictive state representations;deep reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2572,ICLR,2019,Accidental exploration through value predictors,Tomasz Kisielewski;Damian Le≈õniak;Maia Pasek,tymorl@gmail.com;damian.lesniak@doctoral.uj.edu.pl;maiapasek@gmail.com,3;5;4,4;4;4,Reject,0,6,0.0,yes,9/27/18,Jagiellonian University;Jagiellonian University;,reinforcement learning;value predictors;exploration,-1;-1;-1,695;695;-1,-1;-1,asia,in,n,
2573,ICLR,2019,Neural Model-Based Reinforcement Learning for Recommendation,Xinshi Chen;Shuang Li;Hui Li;Shaohua Jiang;Le Song,xinshi.chen@gatech.edu;sli370@gatech.edu;ken.lh@alibaba-inc.com;shaohua.jsh@alipay.com;lsong@cc.gatech.edu,5;6;5,4;3;5,Reject,0,5,0.0,yes,9/27/18,Georgia Institute of Technology;Georgia Institute of Technology;Alibaba Group;Alipay;Georgia Institute of Technology,Generative adversarial user model;Recommendation system;combinatorial recommendation policy;model-based reinforcement learning;deep Q-networks,13;13;-1;-1;13,33;33;-1;-1;33,-1;-1,usa,usa,n,5;4
2574,ICLR,2019,PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation,Perttu H√§m√§l√§inen;Amin Babadi;Xiaoxiao Ma;Jaakko Lehtinen,perttu.hamalainen@aalto.fi;amin.babadi@aalto.fi;xiaoxiao.ma@aalto.fi;jaakko.lehtinen@aalto.fi,4;9;4,4;3;2,Reject,0,6,0.0,yes,9/27/18,Aalto University;Aalto University;Aalto University;Aalto University,Continuous Control;Reinforcement Learning;Policy Optimization;Policy Gradient;Evolution Strategies;CMA-ES;PPO,116;116;116;116,190;190;190;190,-1;-1,europe,dk,n,
2575,ICLR,2019,Unsupervised Meta-Learning for Reinforcement Learning,Abhishek Gupta;Benjamin Eysenbach;Chelsea Finn;Sergey Levine,abhigupta@berkeley.edu;eysenbachbe@gmail.com;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,3;6;4,4;3;2,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;University of California Berkeley;University of California Berkeley,Meta-Learning;Reinforcement Learning;Exploration;Unsupervised,-1;1;-1;-1,18;24;18;18,m;m,usa,usa,n,6
2576,ICLR,2019,Set Transformer,Juho Lee;Yoonho Lee;Jungtaek Kim;Adam R. Kosiorek;Seungjin Choi;Yee Whye Teh,juho.lee@stats.ox.ac.uk;einet89@gmail.com;jtkim@postech.ac.kr;adamk@robots.ox.ac.uk;seungjin@postech.ac.kr;y.w.teh@stats.ox.ac.uk,6;5;6,5;4;3,Reject,0,5,0.0,yes,9/27/18,University of Oxford;AITRICS;POSTECH;University of Oxford;POSTECH;University of Oxford,attention;meta-learning;set-input neural networks;permutation invariant modeling,44;-1;136;44;136;44,1;-1;137;1;137;1,-1;-1,europe,uk,y,6;8
2577,ICLR,2019,Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning,Felipe Petroski Such;Vashisht Madhavan;Edoardo Conti;Joel Lehman;Kenneth O. Stanley;Jeff Clune,felipe.such@uber.com;vashisht@uber.com;edoardo@uber.com;joel.lehman@uber.com;kstanley@uber.com;jeffclune@uber.com,6;7;6;4;3,4;5;2;4;4,Reject,2,10,0.0,yes,9/27/18,Uber;Uber;Uber;Uber;Uber;Uber,Neuroevolution;Reinforcement Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,southamerica,br,n,
2578,ICLR,2019,A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations,Logan Engstrom;Brandon Tran;Dimitris Tsipras;Ludwig Schmidt;Aleksander Madry,engstrom@mit.edu;btran115@mit.edu;tsipras@mit.edu;ludwigs@mit.edu;madry@mit.edu,8;6;5,3;2;4,Reject,0,6,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,robustness;spatial transformations;invariance;rotations;data augmentation;robust optimization,6;6;6;6;6,5;5;5;5;5,-1;-1,usa,usa,n,4
2579,ICLR,2019,Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation,Roman F√∂ll;Bernard Haasdonk;Markus Hanselmann;Holger Ulmer,foell@mathematik.uni-stuttgart.de;haasdonk@mathematik.uni-stuttgart.de;markus.hanselmann@etas.com;holger.ulmer@etas.com,7;5;5,2;4;4,Reject,0,5,0.0,yes,9/27/18,University of Stuttgart;University of Stuttgart;ETAS GmbH;ETAS GmbH,Deep Gaussian Process Model;Recurrent Model;State-Space Model;Nonlinear system identification;Dynamical modeling,116;116;-1;-1,219;219;-1;-1,-1;-1,NAN,NAN,y,
2580,ICLR,2019,Analysis of Memory Organization for Dynamic Neural Networks,Ying Ma;Jose Principe,mayingbit2011@gmail.com;principe@cnel.ufl.edu,7;5;3,3;5;5,Reject,0,14,0.0,yes,9/27/18,University of Florida;University of Florida,memory analysis;recurrent neural network;LSTM;neural Turing machine;neural stack;differentiable neural computers,136;136,143;143,-1;-1,usa,usa,y,3
2581,ICLR,2019,Generative Ensembles for Robust Anomaly Detection,Hyunsun Choi;Eric Jang,hyunsunchoi@kaist.ac.kr;ejang@google.com,5;4;6,4;5;3,Reject,0,8,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Google,Anomaly Detection;Uncertainty;Out-of-Distribution;Generative Models,-1;-1,95;-1,-1;-1,NAN,NAN,n,3;5
2582,ICLR,2019,SHAMANN: Shared Memory Augmented Neural Networks,Cosmin I. Bercea;Olivier Pauly;Andreas K. Maier;Florin C. Ghesu,cosmin.bercea@fau.de;olivier.pauly@gmail.com;andreas.maier@fau.de;florin.ghesu@siemens-healthineers.com,4;5;4,5;3;5,Reject,0,0,0.0,yes,9/27/18,Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;;Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;Siemens Healthineers,memory networks;deep learning;medical image segmentation,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,2
2583,ICLR,2019,Novel positional encodings to enable tree-structured transformers,Vighnesh Leonardo Shiv;Chris Quirk,vishiv@microsoft.com;chrisq@microsoft.com,4;6;5,3;3;3,Reject,0,7,0.0,yes,9/27/18,Microsoft;Microsoft,program translation;tree structures;transformer,-1;-1,-1;-1,-1;-1,NAN,NAN,n,8
2584,ICLR,2019,Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching,Jiezhang Cao;Yong Guo;Langyuan Mo;Peilin Zhao;Junzhou Huang;Mingkui Tan,secaojiezhang@mail.scut.edu.cn;guoyongcs@gmail.com;selangyuanmo@mail.scut.edu.cn;peilinzhao@hotmail.com;jzhuang@uta.edu;mingkuitan@scut.edu.cn,6;4;5,4;4;4,Reject,0,4,0.0,yes,9/27/18,"South China University of Technology;;South China University of Technology;;University of Texas, Arlington;South China University of Technology",joint distribution matching;image-to-image translation;video-to-video synthesis;Wasserstein distance,-1;-1;-1;-1;-1;-1,576;-1;576;-1;-1;576,-1;-1,NAN,NAN,y,1
2585,ICLR,2019,Meta Learning with Fast/Slow Learners,zhuoyuan@fb.com,chengzhuoyuan07@gmail.com,5;5;6,3;4;3,Reject,0,0,0.0,yes,9/27/18,0,computer vision;meta learning,,,-1,NAN,NAN,y,6
2586,ICLR,2019,Domain Generalization via Invariant Representation under Domain-Class Dependency,Kei Akuzawa;Yusuke Iwasawa;Yutaka Matsuo,akuzawa-kei@weblab.t.u-tokyo.ac.jp;iwasawa@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,4;7;5,5;5;4,Reject,0,8,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo;The University of Tokyo,domain generalization;adversarial learning;invariant feature learning,59;59;59,45;45;45,-1;-1,NAN,NAN,n,1
2587,ICLR,2019,Hierarchical Attention: What Really Counts in Various NLP Tasks,Zehao Dou;Zhihua Zhang,zehaodou@pku.edu.cn;zhzhang@math.pku.edu.cn,4;3;4,4;5;3,Reject,1,0,0.0,yes,9/27/18,Peking University;Peking University,attention;hierarchical;machine reading comprehension;poem generation,14;14,27;27,-1;-1,asia,cn,n,3;8;1
2588,ICLR,2019,Learning with Reflective Likelihoods,Adji B. Dieng;Kyunghyun Cho;David M. Blei;Yann LeCun,abd2141@columbia.edu;kyunghyun.cho@nyu.edu;david.blei@columbia.edu;yann@fb.com,4;2;3,4;4;4,Reject,2,13,0.0,yes,9/27/18,Columbia University;New York University;Columbia University;Facebook,new learning criterion;penalized maximum likelihood;posterior inference in deep generative models;input forgetting issue;latent variable collapse issue,21;24;21;-1,14;27;14;-1,-1;-1,NAN,NAN,n,5
2589,ICLR,2019,Adapting Auxiliary Losses Using Gradient Similarity,Yunshu Du;Wojciech M. Czarnecki;Siddhant M. Jayakumar;Razvan Pascanu;Balaji Lakshminarayanan,yunshu.du@wsu.edu;lejlot@google.com;sidmj@google.com;razp@google.com;balajiln@google.com,4;6;6,5;4;3,Reject,0,11,0.0,yes,9/27/18,SUN YAT-SEN UNIVERSITY;Google;Google;Google;Google,auxiliary losses;transfer learning;task similarity;deep learning;deep reinforcement learning,-1;-1;-1;-1;-1,352;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2590,ICLR,2019,Model Comparison for Semantic Grouping,Francisco Vargas;Kamen Brestnichki;Nils Hammerla,francisco.vargas@babylonhealth.com;kamen.brestnichki@babylonhealth.com;nils.hammerla@babylonhealth.com,5;5;5,3;3;1,Reject,0,8,0.0,yes,9/27/18,babylon health;babylon health;babylon health,model comparison;semantic similarity;STS;von Mises-Fisher;Information Theoretic Criteria,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11;5
2591,ICLR,2019,Connecting the Dots Between MLE and RL for Sequence Generation,Bowen Tan*;Zhiting Hu*;Zichao Yang;Ruslan Salakhutdinov;Eric P. Xing,tanbowen@sjtu.edu.cn;zhitinghu@gmail.com;yangtze2301@gmail.com;rsalakhu@cs.cmu.edu;epxing@cs.cmu.edu,5;6;5,5;3;4,Reject,0,5,0.0,yes,9/27/18,"Shanghai Jiao Tong University;University of California, San Diego;;Carnegie Mellon University;Carnegie Mellon University",sequence generation;maximum likelihood learning;reinforcement learning;policy optimization;text generation;reward augmented maximum likelihood;exposure bias,36;-1;-1;1;1,188;31;-1;24;24,-1;-1,usa,usa,n,3
2592,ICLR,2019,DeepTwist: Learning Model Compression via Occasional Weight Distortion,Dongsoo Lee;Parichay Kapoor;Byeongwook Kim,dslee3@gmail.com;kparichay@gmail.com;quddnr145@gmail.com,4;5;4,4;3;3,Reject,0,17,0.0,yes,9/27/18,Samsung;;Samsung,deep learning;model compression;pruning;quantization;SVD;regularization;framework,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2593,ICLR,2019,Excitation Dropout: Encouraging Plasticity in Deep Neural Networks,Andrea Zunino;Sarah Adel Bargal;Pietro Morerio;Jianming Zhang;Stan Sclaroff;Vittorio Murino,andrea.zunino@iit.it;sbargal@bu.edu;pietro.morerio@iit.it;jianmzha@adobe.com;sclaroff@bu.edu;vittorio.murino@iit.it,5;5;5,4;3;4,Reject,0,9,0.0,yes,9/27/18,Istituto Italiano di Tecnologia;Boston University;Istituto Italiano di Tecnologia;Adobe Systems;Boston University;Istituto Italiano di Tecnologia,Dropout;Saliency;Deep Neural Networks,-1;77;-1;-1;77;-1,-1;70;-1;-1;70;-1,-1;-1,NAN,NAN,n,1
2594,ICLR,2019,Measuring Density and Similarity of Task Relevant Information in Neural Representations,Danish Pruthi;Mansi Gupta;Nitish Kumar Kulkarni;Graham Neubig;Eduard Hovy,ddanish@cs.cmu.edu;mansig1@cs.cmu.edu;nitishkk@andrew.cmu.edu;gneubig@cs.cmu.edu;hovy@cmu.edu,4;5;5,4;4;3,Reject,0,7,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Neural Networks;Representation;Information density;Transfer Learning,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,n,6;3
2595,ICLR,2019,ATTENTIVE EXPLAINABILITY FOR PATIENT TEMPORAL EMBEDDING,Daby Sow;Mohamed Ghalwash;Zach Shahn;Sanjoy Dey;Moulay Draidia;Li-wei Lehmann,sowdaby@us.ibm.com;mohamed.ghalwash@ibm.com;zach.shahn@ibm.com;deysa@us.ibm.com;mzdraidia@berkeley.edu;lilehman@mit.edu,4;3;2,4;4;3,Reject,0,3,1.0,yes,9/27/18,International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of California Berkeley;Massachusetts Institute of Technology,,-1;-1;-1;-1;-1;6,-1;-1;-1;-1;18;5,-1;-1,usa,usa,n,
2596,ICLR,2019,Feature prioritization and regularization improve standard accuracy and adversarial robustness,Chihuang Liu;Joseph JaJa,chliu@umd.edu;joseph@umiacs.umd.edu,5;5;4,5;2;3,Reject,0,4,0.0,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park",adversarial robustness;feature prioritization;regularization,12;12,69;69,-1;-1,usa,usa,n,8;4
2597,ICLR,2019,A Study of Robustness of Neural Nets Using Approximate Feature Collisions,Ke Li*;Tianhao Zhang*;Jitendra Malik,ke.li@eecs.berkeley.edu;bryanzhang@berkeley.edu;malik@eecs.berkeley.edu,6;4;4,3;4;4,Reject,0,4,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,4
2598,ICLR,2019,DEEP HIERARCHICAL MODEL FOR HIERARCHICAL SELECTIVE CLASSIFICATION AND ZERO SHOT LEARNING,Eliyahu Sason;Koby Crammer,sasonil@gmail.com;koby@ee.technion.ac.il,4;5;2,4;3;4,Reject,0,5,0.0,yes,9/27/18,"Technion, Technion;Technion, Technion",deep learning;large-scale classificaion;heirarchical classification;zero-shot learning,27;27,-1;-1,-1;-1,NAN,NAN,n,6;1
2599,ICLR,2019,Advocacy Learning,Ian Fox;Jenna Wiens,ifox@umich.edu;wiensj@umich.edu,4;4;8,4;4;2,Reject,0,4,0.0,yes,9/27/18,University of Michigan;University of Michigan,competition;supervision;deep learning;adversarial;debate,9;9,21;21,-1;-1,usa,usa,n,8
2600,ICLR,2019,Learning with Random Learning Rates.,L√©onard Blier;Pierre Wolinski;Yann Ollivier,leonardb@fb.com;pierre.wolinski@u-psud.fr;yol@fb.com,4;6;5,4;4;4,Reject,0,5,0.0,yes,9/27/18,Facebook;UPSud/INRIA University Paris-Saclay;Facebook,step size;stochastic gradient descent;hyperparameter tuning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2601,ICLR,2019,BLISS in Non-Isometric Embedding Spaces,Barun Patra;Joel Ruben Antony Moniz;Sarthak Garg;Matthew R Gormley;Graham Neubig,bpatra@andrew.cmu.edu;jrmoniz@andrew.cmu.edu;sarthakg@andrew.cmu.edu;mgormley@andrew.cmu.edu;gneubig@andrew.cmu.edu,4;6;6,5;5;4,Reject,0,6,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,bilingual lexicon induction;semi-supervised methods;embeddings,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,n,3
2602,ICLR,2019,Pumpout: A Meta Approach for Robustly Training Deep Neural Networks with Noisy Labels,Bo Han;Gang Niu;Jiangchao Yao;Xingrui Yu;Miao Xu;Ivor Tsang;Masashi Sugiyama,bo.han@riken.jp;gang.niu@riken.jp;jiangchao.yao@student.uts.edu.au;xingrui.yu@student.uts.edu.au;miao.xu@riken.jp;ivor.tsang@uts.edu.au;sugi@k.u-tokyo.ac.jp,6;5;3,3;5;4,Reject,12,11,0.0,yes,9/27/18,RIKEN;RIKEN;University of Technology Sydney;University of Technology Sydney;RIKEN;University of Technology Sydney;The University of Tokyo,Noisy Labels;Deep Learning;Meta Approach,-1;-1;67;67;-1;67;59,-1;-1;216;216;-1;216;45,-1;-1,NAN,NAN,y,1
2603,ICLR,2019,HAPPIER: Hierarchical Polyphonic Music Generative RNN,Tianyang Zhao;Xiaoxuan Ma;Honglin Ma;Yizhou Wang,zhaotianyang@pku.edu.cn;maxiaoxuan@pku.edu.cn;mahonglin_pku@outlook.com;yizhou.wang@pku.edu.cn,2;3;3,4;4;5,Reject,1,0,0.0,yes,9/27/18,Peking University;Peking University;;Peking University,hierarchical model;RNN;generative model;automatic composing,14;14;-1;14,27;27;-1;27,-1;-1,asia,cn,n,5
2604,ICLR,2019,A Modern Take on the Bias-Variance Tradeoff in Neural Networks,Brady Neal;Sarthak Mittal;Aristide Baratin;Vinayak Tantia;Matthew Scicluna;Simon Lacoste-Julien;Ioannis Mitliagkas,bradyneal11@gmail.com;sarthmit@gmail.com;aristidebaratin@hotmail.com;tantia.vinayak1@gmail.com;mattcscicluna@gmail.com;slacoste@iro.umontreal.ca;ioannis@iro.umontreal.ca,5;7;4,3;4;4,Reject,0,11,0.0,yes,9/27/18,University of Montreal;University of Montreal;University of Montreal;;;University of Montreal;University of Montreal,bias-variance tradeoff;deep learning theory;generalization;concentration,116;116;116;-1;-1;116;116,108;108;108;-1;-1;108;108,-1;-1,canada,ca,y,1
2605,ICLR,2019,Learning a Neural-network-based Representation for Open Set Recognition,Mehadi Hassen;Philip K. Chan,mhassen2005@my.fit.edu;pkc@cs.fit.edu,4;4;5,4;4;4,Reject,0,5,0.0,yes,9/27/18,Florida Institute of Technology;Florida Institute of Technology,open set recognition,419;419,750;750,-1;-1,usa,usa,n,
2606,ICLR,2019,Faster Training by Selecting Samples Using Embeddings,Santiago Gonzalez;Joshua Landgraf;Risto Miikkulainen,slgonzalez@utexas.edu;jland@cs.utexas.edu;risto@cs.utexas.edu,3;3;2,5;3;5,Reject,0,0,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Machine Learning;Embeddings;Training Time;Optimization;Autoencoders,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,
2607,ICLR,2019,Effective Path: Know the Unknowns of Neural Network,Yuxian Qiu;Jingwen Leng;Yuhao Zhu;Quan Chen;Chao Li;Minyi Guo,qiuyuxian@sjtu.edu.cn;leng-jw@sjtu.edu.cn;yzhu@rochester.edu;chen-quan@sjtu.edu.cn;lichao@cs.sjtu.edu.cn;guo-my@cs.sjtu.edu.cn,4;4;6,4;3;5,Reject,0,0,0.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of Rochester;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,,36;36;94;36;36;36,188;188;153;188;188;188,-1;-1,asia,cn,n,4
2608,ICLR,2019,Pseudosaccades: A simple ensemble scheme for improving classification performance of deep nets,Jin Sean Lim;Robert John Durrant,me@nicklim.com;bobd@waikato.ac.nz,5;4;4,4;4;5,Reject,0,0,0.0,yes,9/27/18,The University of Waikato;The University of Waikato,Ensemble classification;random subspace;data sketching,285;285,393;393,-1;-1,NAN,NAN,n,
2609,ICLR,2019,ADAPTIVE NETWORK SPARSIFICATION VIA DEPENDENT VARIATIONAL BETA-BERNOULLI DROPOUT,Juho Lee;Saehoon Kim;Jaehong Yoon;Hae Beom Lee;Eunho Yang;Sung Ju Hwang,juho.lee@stats.ox.ac.uk;shkim@aitrics.com;jaehong.yoon@kaist.ac.kr;haebeom.lee@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,5;5;7,4;4;4,Reject,0,6,0.0,yes,9/27/18,University of Oxford;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Bayesian deep learning;network pruning,44;-1;-1;-1;-1;-1,1;-1;95;95;95;95,-1;-1,NAN,NAN,n,11
2610,ICLR,2019,Curiosity-Driven Experience Prioritization via Density Estimation,Rui Zhao;Volker Tresp,zhaorui.in.germany@gmail.com;volker.tresp@siemens.com,6;4;6,3;4;4,Reject,0,4,0.0,yes,9/27/18,Tencent AI;Siemens Corporate Research,Curiosity-Driven;Experience Prioritization;Hindsight Experience;Reinforcement Learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2611,ICLR,2019,SEQUENCE MODELLING WITH AUTO-ADDRESSING AND RECURRENT MEMORY INTEGRATING NETWORKS,Zhangheng Li;Jia-Xing Zhong;Jingjia Huang;Tao Zhang;Thomas Li;Ge Li,zhanghengli@pku.edu.cn;jxzhong@pku.edu.cn;jjhuang@pku.edu.cn;t_zhang@pku.edu.cn;thomasli@pkusz.edu.cn;geli@ece.pku.edu.cn,5;4;4,4;5;4,Reject,0,6,0.0,yes,9/27/18,Peking University;Peking University;Peking University;Peking University;University of Science and Technology of China;Peking University,Memory Network;RNN;Sequence Modelling,14;14;14;14;-1;14,27;27;27;27;132;27,-1;-1,asia,cn,n,
2612,ICLR,2019,Log Hyperbolic Cosine Loss Improves Variational Auto-Encoder,Pengfei Chen;Guangyong Chen;Shengyu Zhang,chenpf.cuhk@gmail.com;gycchen@tencent.com;shengyuzhang@gmail.com,4;4;5,4;4;4,Reject,0,2,0.0,yes,9/27/18,The Chinese University of Hong Kong;Tencent AI Lab;Chinese University of Hong Kong,Unsupervised Generative Model;VAE;log hyperbolic cosine loss,285;-1;47,40;-1;58,-1;-1,asia,hk,n,5
2613,ICLR,2019,Computation-Efficient Quantization Method for Deep Neural Networks,Parichay Kapoor;Dongsoo Lee;Byeongwook Kim;Saehyung Lee,kparichay@gmail.com;dslee3@gmail.com;guddnr145@gmail.com;halo8218@gmail.com,4;5;5,4;4;4,Reject,0,8,1.0,yes,9/27/18,"Indian Institute of Technology, Delhi;Samsung;;Seoul National University",quantization;binary;ternary;flat minima;model compression;deep learning,-1;-1;-1;36,-1;-1;-1;74,-1;-1,asia,kr,n,
2614,ICLR,2019,EFFICIENT SEQUENCE LABELING WITH ACTOR-CRITIC TRAINING,Saeed Najafi;Colin Cherry;Greg Kondrak,snajafi@ualberta.ca;colin.a.cherry@gmail.com;gkondrak@ualberta.ca,5;4;4,4;3;5,Reject,0,4,0.0,yes,9/27/18,University of Alberta;Google;University of Alberta,Structured Prediction;Reinforcement Learning;NLP,94;-1;94,119;-1;119,-1;-1,canada,ca,n,
2615,ICLR,2019,Unsupervised Exploration with Deep Model-Based Reinforcement Learning,Kurtland Chua;Rowan McAllister;Roberto Calandra;Sergey Levine,kchua@berkeley.edu;rmcallister@berkeley.edu;roberto.calandra@berkeley.edu;svlevine@eecs.berkeley.edu,4;4;4,4;3;4,Reject,0,4,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,exploration;model based reinforcement learning,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,
2616,ICLR,2019,Unification of  Recurrent   Neural Network Architectures and Quantum Inspired Stable Design ,Murphy Yuezhen Niu;Lior Horesh;Michael O'Keeffe;Isaac Chuang,yzniu@mit.edu;lhoresh@us.ibm.com;michael.okeeffe@ll.mit.edu;ichuang@mit.edu,5;4;4;5,2;2;3;2,Reject,0,0,0.0,yes,9/27/18,Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology;Massachusetts Institute of Technology,theory and analysis of RNNs architectures;reversibe evolution;stability of deep neural network;learning representations of outputs or states;quantum inspired embedding,6;-1;6;6,5;-1;5;5,-1;-1,usa,usa,y,1
2617,ICLR,2019,Text Infilling,Wanrong Zhu;Zhiting Hu;Eric P. Xing,zhuwr56@gmail.com;zhitinghu@gmail.com;epxing@cs.cmu.edu,3;5;6,4;4;4,Reject,0,0,0.0,yes,9/27/18,"UC Santa Barbara;University of California, San Diego;Carnegie Mellon University",text generation;text infilling;self attention;sequence to sequence,-1;-1;1,-1;31;24,-1;-1,usa,usa,n,8
2618,ICLR,2019,Skip-gram word embeddings in hyperbolic space,Matthias Leimeister;Benjamin J. Wilson,matthias@lateral.io;benjamin@lateral.io,6;5;5,3;3;3,Reject,0,3,0.0,yes,9/27/18,Lateral GmbH;Lateral GmbH,word embeddings;hyperbolic;skip-gram,-1;-1,-1;-1,-1;-1,NAN,NAN,y,3;10
2619,ICLR,2019,EXPLORATION OF EFFICIENT ON-DEVICE ACOUSTIC MODELING WITH NEURAL NETWORKS,Wonyong Sung;Lukas Lee;Jinwhan Park,wysung@snu.ac.kr;proboscis@snu.ac.kr;bnoo@snu.ac.kr,4;4;4,5;4;4,Reject,0,0,0.0,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University,Parallelization;Speech Recognition;Sequence Modeling;Recurrent Neural Network;Embedded Systems,36;36;36,74;74;74,-1;-1,asia,kr,n,
2620,ICLR,2019,The Variational Deficiency Bottleneck,Pradeep Kr. Banerjee;Guido Montufar,pradeep@mis.mpg.de;montufar@math.ucla.edu,5;7;6,5;2;2,Reject,0,5,0.0,yes,9/27/18,"Max-Planck Institute;University of California, Los Angeles",Variational Information Bottleneck;Blackwell Sufficiency;Le Cam Deficiency;Information Channel,-1;-1,-1;15,-1;-1,usa,usa,y,1
2621,ICLR,2019,Dataset Distillation,Tongzhou Wang;Jun-Yan Zhu;Antonio Torralba;Alexei A. Efros,tongzhou.wang.1994@gmail.com;junyanz@mit.edu;torralba@mit.edu;efros@eecs.berkeley.edu,6;5;5,4;4;4,Reject,4,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley,knowledge distillation;deep learning;few-shot learning;adversarial attack,6;6;6;-1,5;5;5;18,m;m,usa,usa,n,
2622,ICLR,2019,DecayNet: A Study on the Cell States of Long Short Term Memories,Nicholas I.H. Kuo;Mehrtash T. Harandi;Hanna Suominen;Nicolas Fourrier;Christian Walder;Gabriela Ferraro,u6424547@anu.edu.au;mehrtash.harandi@monash.edu;hanna.suominen@anu.edu.au;nicolas.fourrier@devinci.fr;christian.walder@data61.csiro.au;gabriela.ferraro@csiro.au,8;4;4,3;4;4,Reject,0,10,2.0,yes,9/27/18,Australian National University;Monash University;Australian National University;Ecole Superieur d'Ingenieurs Leonard de Vinci;CSIRO;CSIRO,Long short term memory;Recurrent neural network;Dynamical systems;Difference equation,116;94;116;-1;-1;-1,48;80;48;-1;-1;-1,-1;-1,asia,in,n,
2623,ICLR,2019,k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks,Yiming Xu;Diego Klabjan,yimingxu2020@u.northwestern.edu;d-klabjan@northwestern.edu,6;5;4,4;4;4,Reject,0,7,0.0,yes,9/27/18,Northwestern University;Northwestern University,,50;50,20;20,-1;-1,usa,usa,n,
2624,ICLR,2019,Towards More Theoretically-Grounded Particle Optimization Sampling for Deep Learning,Jianyi Zhang;Ruiyi Zhang;Changyou Chen,15300180019@fudan.edu.cn;rz68@duke.edu;cchangyou@gmail.com,5;3;4,4;4;3,Reject,0,12,0.0,yes,9/27/18,"Fudan University;Duke University;State University of New York, Buffalo",,67;47;-1,116;17;-1,-1;-1,NAN,NAN,y,11;1
2625,ICLR,2019,Gaussian-gated LSTM: Improved convergence by reducing state updates,Matthew Thornton;Jithendar Anumula;Shih-Chii Liu,mattsthornton@gmail.com;anumula@ini.uzh.ch;shih@ini.uzh.ch,5;5;6,5;4;4,Reject,0,8,0.0,yes,9/27/18,Swiss Federal Institute of Technology;University of Zurich;University of Zurich,time gate;faster convergence;trainability;rnn;computational budget,-1;136;136,-1;136;136,-1;-1,europe,ch,n,
2626,ICLR,2019,Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data,Puyudi Yang;Jianbo Chen;Cho-Jui Hsieh;Jane-Ling Wang;Michael I. Jordan,pydyang@ucdavis.edu;jianbochen@berkeley.edu;chohsieh@ucdavis.edu;janelwang@ucdavis.edu;jordan@cs.berkeley.edu,3;6;8;7,4;4;2;4,Reject,0,22,5.0,yes,9/27/18,"University of California, Davis;University of California Berkeley;University of California, Davis;University of California, Davis;University of California Berkeley",Adversarial Examples,-1;-1;-1;-1;-1,54;18;54;54;18,-1;-1,usa,usa,n,4
2627,ICLR,2019,Characterizing Malicious Edges targeting on Graph Neural Networks,Xiaojun Xu;Yue Yu;Bo Li;Le Song;Chengfeng Liu;Carl Gunter,xuxiaojun1005@gmail.com;yue9yu@gmail.com;lxbosky@gmail.com;lsong@cc.gatech.edu;windsonliu@tencent.com;cgunter@illinois.edu,5;5;5,5;3;3,Reject,0,5,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;Georgia Institute of Technology;University of California Berkeley;Georgia Institute of Technology;Tencent AI Lab;University of Illinois, Urbana Champaign",,-1;13;-1;13;-1;-1,-1;33;18;33;-1;-1,-1;-1,usa,usa,n,10;4
2628,ICLR,2019,Graph2Seq: Scalable Learning Dynamics for Graphs,Shaileshh Bojja Venkatakrishnan;Mohammad Alizadeh;Pramod Viswanath,bjjvnkt@csail.mit.edu;alizadeh@csail.mit.edu;pramodv@illinois.edu,6;5;4,3;5;4,Reject,0,17,2.0,yes,9/27/18,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Illinois, Urbana Champaign",graph neural networks;scalable representations;combinatorial optimization;reinforcement learning,6;6;-1,5;5;-1,-1;-1,usa,usa,y,1;10
2629,ICLR,2019,Unsupervised Word Discovery with Segmental Neural Language Models,Kazuya Kawakami;Chris Dyer;Phil Blunsom,kawakamik@google.com;cdyer@google.com;pblunsom@google.com,6;4;3,4;3;5,Reject,8,5,0.0,yes,9/27/18,Google;Google;Google,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,3;2;11;1
2630,ICLR,2019,"A bird's eye view on coherence, and a worm's eye view on cohesion",Woon Sang Cho;Pengchuan Zhang;Yizhe Zhang;Xiujun Li;Mengdi Wang;Jianfeng Gao,woonsang@princeton.edu;penzhan@microsoft.com;yizhe.zhang@microsoft.com;xiul@microsoft.com;mengdiw@princeton.edu;jfgao@microsoft.com,2;2;4,4;4;4,Reject,0,5,0.0,yes,9/27/18,Princeton University;Microsoft;Microsoft;Microsoft;Princeton University;Microsoft,text generation;natural language processing;neural language model,31;-1;-1;-1;31;-1,7;-1;-1;-1;7;-1,-1;-1,NAN,NAN,n,8;3
2631,ICLR,2019,State-Regularized Recurrent Networks,Cheng Wang;Mathias Niepert,dr.rer.nat.chengwang@gmail.com;mathias.niepert@neclab.eu,6;6;5,4;5;5,Reject,0,4,0.0,yes,9/27/18,Amazon;NEC,recurrent network;finite state machines;state-regularized;interpretability and explainability,-1;-1,-1;324,-1;-1,europe,gr,y,
2632,ICLR,2019,DEEP GRAPH TRANSLATION,Xiaojie Guo;Lingfei Wu;Liang Zhao,xguo7@gmu.edu;lwu@email.wm.edu;lzhao9@gmu.edu,5;5;6,2;4;4,Reject,0,14,0.0,yes,9/27/18,George Mason University;College of William and Mary;George Mason University,,94;207;94,336;-1;336,m;m,usa,usa,n,10;5;4
2633,ICLR,2019,Canonical Correlation Analysis with Implicit Distributions,Yaxin Shi;Donna Xu;Yuangang Pan;Ivor Tsang,yaxin.shi@student.uts.edu.au;donna.xu@student.uts.edu.au;yuangang.pan@student.uts.edu.au;ivor.tsang@uts.edu.au,5;6;4,5;4;5,Reject,0,12,0.0,yes,9/27/18,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,Canonical Correlation Analysis;implicit probabilistic model;cross-view structure output prediction,67;67;67;67,216;216;216;216,-1;-1,australasia,au,n,5;4
2634,ICLR,2019,Neural Distribution Learning for generalized time-to-event prediction,Egil Martinsson;Adrian Kim;Jaesung Huh;Jaegul Choo;Jung-Woo Ha,egil.martinsson@gmail.com;adrian.kim@navercorp.com;jaesung.huh@navercorp.com;jchoo@korea.ac.kr;jungwoo.ha@navercorp.com,4;3;3,5;4;3,Reject,0,7,0.0,yes,9/27/18,Chalmers University;NAVER;NAVER;Korea University;NAVER,Deep Learning;Survival Analysis;Event prediction;Time Series;Probabilistic Programming;Density Networks,-1;-1;-1;169;-1,240;-1;-1;244;-1,-1;-1,europe,gr,n,
2635,ICLR,2019,Inference of unobserved event streams with neural Hawkes particle smoothing,Hongyuan Mei;Guanghui Qin;Jason Eisner,hmei@cs.jhu.edu;ghq@pku.edu.cn;jason@cs.jhu.edu,5;4;5,4;5;3,Reject,0,11,0.0,yes,9/27/18,Johns Hopkins University;Peking University;Johns Hopkins University,,67;14;67,13;27;13,-1;-1,usa,usa,y,
2636,ICLR,2019,Countdown Regression: Sharp and Calibrated Survival Predictions,Anand Avati;Tony Duan;Sharon Zhou;Kenneth Jung;Nigam Shah;Andrew Ng,avati@cs.stanford.edu;tonyduan@cs.stanford.edu;sharonz@cs.stanford.edu,4;4;5;4,5;4;3;4,Reject,0,4,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University,,4;4;4,3;3;3,-1;-1,usa,usa,n,1
2637,ICLR,2019,Discrete Structural Planning for Generating Diverse Translations,Raphael Shu;Hideki Nakayama,shu@nlab.ci.i.u-tokyo.ac.jp;nakayama@ci.i.u-tokyo.ac.jp,4;5;2,5;3;5,Reject,0,7,0.0,yes,9/27/18,The University of Tokyo;The University of Tokyo,machine translation;syntax;diversity;code learning,59;59,45;45,-1;-1,NAN,NAN,n,3
2638,ICLR,2019,Feature quantization for parsimonious and interpretable predictive models,Adrien EHRHARDT;Vincent VANDEWALLE;Christophe BIERNACKI;Philippe HEINRICH,adrien.ehrhardt@inria.fr;vincent.vandewalle@inria.fr;christophe.biernacki@inria.fr;philippe.heinrich@univ-lille.fr,2;3;4,4;3;2,Reject,0,4,0.0,yes,9/27/18,INRIA;INRIA;INRIA;Universit√© de Lille,discretization;grouping;interpretability;shallow neural networks,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2639,ICLR,2019,Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling,Ishani Chakraborty,ishani.chakrab@gmail.com,2;2;1;3;2,5;5;5;4;4,Reject,0,0,0.0,yes,9/27/18,0,Hierarchical Bayesian Modeling;Sparse sequence clustering;Group profiling;User group modeling,,,-1,NAN,NAN,n,11
2640,ICLR,2019,Clinical Risk: wavelet reconstruction networks for marked point processes,Jeremy C. Weiss,jeremy.weiss@gmail.com,7;4;5,4;4;4,Reject,0,11,0.0,yes,9/27/18,Carnegie Mellon University,point processes;wavelets;temporal neural networks;Hawkes processes,1,24,-1,usa,usa,n,
2641,ICLR,2019,Interpreting Layered Neural Networks via Hierarchical Modular Representation,Chihiro Watanabe,watanabe.chihiro@lab.ntt.co.jp,4;3;3,3;4;4,Reject,0,0,0.0,yes,9/27/18,NTT,interpretabile machine learning;neural network;hierarchical clustering,207,-1,-1,asia,bd,n,
2642,ICLR,2019,Learning Graph Representations by Dendrograms,Thomas Bonald;Bertrand Charpentier,thomas.bonald@telecom-paristech.fr;bertrand.charpentier@live.fr,4;5;5,4;4;3,Reject,0,3,0.0,yes,9/27/18,T√©l√©com ParisTech;Technical University of Munich,Graph;hierarchical clustering;dendrogram;quality metric;reconstruction;entropy,-1;-1,-1;-1,-1;-1,asia,in,n,10
2643,ICLR,2019,Fast Binary Functional Search on Graph,Shulong Tan;Zhixin Zhou;Zhaozhuo Xu;Ping Li,laos1984@gmail.com;zhixin0825@gmail.com;zhaozhuoxu@gmail.com;pingli98@gmail.com,5;4,5;4,Reject,0,6,0.0,yes,9/27/18,Baidu Research;;Rice University;Accel,Binary Functional Search;Large-scale Search;Approximate Nearest Neighbor Search,-1;-1;94;-1,-1;-1;86;-1,-1;-1,asia,in,y,10
2644,ICLR,2019,HyperGAN:  Exploring the Manifold of Neural Networks,Neale Ratzlaff;Li  Fuxin,ratzlafn@oregonstate.edu;lif@oregonstate.edu,5;6;4,4;5;3,Reject,2,5,0.0,yes,9/27/18,Oregon State University;Oregon State University,hypernetworks;generative adversarial networks;anomaly detection,77;77,318;318,-1;-1,usa,usa,n,5;4
2645,ICLR,2019,Correction Networks: Meta-Learning for Zero-Shot Learning,R. Lily Hu;Caiming Xiong;Richard Socher,rlilyhu@gmail.com;cxiong@salesforce.com;rsocher@salesforce.com,7;4;4,4;5;4,Reject,0,7,1.0,yes,9/27/18,SalesForce.com;SalesForce.com;SalesForce.com,zero-shot learning;image classification;fine-grained classification;meta-learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,6;3
2646,ICLR,2019,NUTS: Network for Unsupervised Telegraphic Summarization,Chanakya Malireddy;Tirth Maniar;Sajal Maheshwari;Manish Shrivastava,chanakya.malireddy@gmail.com;tirthmaniar1998@gmail.com;sajalmaheshwari624@gmail.com;m.shrivastava@iiit.ac.in,4;4;4,4;4;4,Reject,0,3,0.0,yes,9/27/18,International Institute of Information Technology Hyderabad;;;International Institute of Information Technology Hyderabad,nlp;summarization;unsupervised learning;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2647,ICLR,2019,The wisdom of the crowd: reliable deep reinforcement learning through ensembles of Q-functions,Daniel Elliott;Charles Anderson,daniel.elliott18@alumni.colostate.edu;chuck.anderson@colostate.edu,4;5;3,5;3;4,Reject,0,0,0.0,yes,9/27/18,Colorado State University;Colorado State University,reinforcement learning;ensembles;deep learning;neural network,419;419,356;356,-1;-1,usa,usa,n,
2648,ICLR,2019,Co-manifold learning with missing data,Gal Mishne;Eric C. Chi;Ronald R. Coifman,gal.mishne@yale.edu;eric_chi@ncsu.edu;coifman.ronald@yale.edu,7;4;4,4;4;3,Reject,0,8,0.0,yes,9/27/18,Yale University;SUN YAT-SEN UNIVERSITY;Yale University,nonlinear dimensionality reduction;missing data;manifold learning;co-clustering;optimization,67;-1;67,12;352;12,-1;-1,europe,fi,y,
2649,ICLR,2019,Training generative latent models  by variational f-divergence minimization,Mingtian Zhang;Thomas Bird;Raza Habib;Tianlin Xu;David Barber,mingtian.zhang.17@ucl.ac.uk;thomas.bird@cs.ucl.ac.uk;raza.habib@cs.ucl.ac.uk;t.xu12@lse.ac.uk;david.barber@ucl.ac.uk,6;5;5,3;4;3,Reject,0,3,0.0,yes,9/27/18,University College London;University College London;University College London;London School of Economics;University College London,variational inference;generative model;f divergence,50;50;50;-1;50,-1;-1;-1;26;-1,-1;-1,europe,uk,n,1;5
2650,ICLR,2019,Improved Gradient Estimators for Stochastic Discrete Variables,Evgeny Andriyash;Arash Vahdat;Bill Macready,eandriyash@dwavesys.com;avahdat@dwavesys.com;wgm@dwavesys.com,7;6;6,4;3;4,Reject,0,3,0.0,yes,9/27/18,D-Wave Systems;D-Wave Systems;D-Wave Systems,continuous relaxation;discrete stochastic variables;reparameterization trick;variational inference;discrete optimization;stochastic gradient estimation,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2651,ICLR,2019,AutoLoss: Learning Discrete Schedule for Alternate Optimization,Haowen Xu;Hao Zhang;Zhiting Hu;Xiaodan Liang;Ruslan Salakhutdinov;Eric Xing,haowen.will.xu@gmail.com;hao@cs.cmu.edu;zhitingh@cs.cmu.edu;xiaodan1@cs.cmu.edu;rsalakhu@cs.cmu.edu;eric.xing@petuum.com,6;7;7,3;4;3,Accept (Poster),0,9,2.0,yes,9/27/18,Tsinghua University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Petuum Inc.,Meta Learning;AutoML;Optimization Schedule,-1;1;1;1;1;-1,-1;24;24;24;24;-1,-1;-1,NAN,NAN,n,6;3;5
2652,ICLR,2019,Spread Divergences,David Barber;Mingtian Zhang;Raza Habib;Thomas Bird,d.barber@cs.ucl.ac.uk;mingtian.zhang.17@ucl.ac.uk;raza.habib.15@ucl.ac.uk;thomas.bird.17@ucl.ac.uk,5;4;6,4;4;4,Reject,0,3,0.0,yes,9/27/18,University College London;University College London;University College London;University College London,Generative Adversarial Network;Divergence,50;50;50;50,-1;-1;-1;-1,-1;-1,europe,uk,n,5
2653,ICLR,2019,Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task,Nat Dilokthanakul;Nick Pawlowski;Murray Shanahan,n.dilokthanakul14@imperial.ac.uk;n.pawlowski16@imperial.ac.uk;m.shanahan@imperial.ac.uk,5;6;7,4;4;4,Reject,0,7,0.0,yes,9/27/18,Imperial College London;Imperial College London;Imperial College London,disentanglement;vae;clustering;prior imposition;deep generative models,47;47;47,8;8;8,-1;-1,europe,uk,n,5
2654,ICLR,2019,Convergence Properties of Deep Neural Networks on Separable Data,Remi Tachet des Combes;Mohammad Pezeshki;Samira Shabanian;Aaron Courville;Yoshua Bengio,remi.tachet@microsoft.com;mohammad.pezeshki@umontreal.ca;s.shabanian@gmail.com;aaron.courville@gmail.com;yoshua.umontreal@gmail.com,5;5;5,4;4;3,Reject,0,5,0.0,yes,9/27/18,Microsoft;University of Montreal;Microsoft;University of Montreal;University of Montreal,learning dynamics;gradient descent;classification;optimization;cross-entropy;hinge loss;implicit regularization;gradient starvation,-1;116;-1;116;116,-1;108;-1;108;108,-1;-1,canada,ca,y,1;5;4
2655,ICLR,2019,Meta-Learning with Individualized Feature Space for Few-Shot Classification,Chunrui Han;Shiguang Shan;Meina Kan;Shuzhe Wu;Xilin Chen,chunrui.han@vipl.ict.ac.cn;sgshan@ict.ac.cn;kanmeina@ict.ac.cn;shuzhe.wu@vipl.ict.ac.cn;xlchen@ict.ac.cn,5;5;3,4;4;3,Reject,0,0,0.0,yes,9/27/18,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",few-shot classification;meta-learning;individualized feature space,31;31;31;31;31,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
2656,ICLR,2019,Neural Regression Tree,Wenbo Zhao;Shahan Ali Memon;Bhiksha Raj;Rita Singh,wzhao1@andrew.cmu.ecu;samemon@cs.cmu.edu;bhikshar@cs.cmu.edu;rsingh@cs.cmu.edu,5;3;4,3;4;5,Reject,0,0,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,regression-via-classification;discretization;regression tree;neural model;optimization,-1;1;1;1,-1;24;24;24,-1;-1,usa,usa,n,
2657,ICLR,2019,Learning Corresponded Rationales for Text Matching,Mo Yu;Shiyu Chang;Tommi S Jaakkola,shiyu.chang@ibm.com;yum@us.ibm.com;tommi@csail.mit.edu,6;4;3,4;4;5,Reject,0,3,0.0,yes,9/27/18,International Business Machines;International Business Machines;Massachusetts Institute of Technology,interpretability;rationalization;text matching;dependent selection,-1;-1;6,-1;-1;5,-1;-1,usa,usa,n,3
2658,ICLR,2019,Differentiable Expected BLEU for Text Generation,Wentao Wang;Zhiting Hu;Zichao Yang;Haoran Shi;Eric P. Xing,wwt10@pku.edu.cn;zhitinghu@gmail.com;yangtze2301@gmail.com;shr970423@gmail.com;epxing@cs.cmu.edu,4;4;6,4;5;4,Reject,2,0,0.0,yes,9/27/18,"Peking University;University of California, San Diego;;;Carnegie Mellon University",text generation;BLEU;differentiable;gradient descent;maximum likelihood learning;policy gradient;machine translation,14;-1;-1;-1;1,27;31;-1;-1;24,-1;-1,usa,usa,n,3
2659,ICLR,2019,Cautious Deep Learning,Yotam Hechtlinger;Barnabas Poczos;Larry Wasserman,yhechtli@andrew.cmu.edu;bapoczos@cs.cmu.edu;larry@cmu.edu,4;7;4,3;2;5,Reject,0,5,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Deep Learning;Classification;Prediction;Cautious Methods,1;1;1,24;24;24,-1;-1,usa,usa,y,
2660,ICLR,2019,Success at any cost: value constrained model-free continuous control,Steven Bohez;Abbas Abdolmaleki;Michael Neunert;Jonas Buchli;Nicolas Heess;Raia Hadsell,sbohez@google.com;aabdolmaleki@google.com;neunertm@google.com;buchli@google.com;heess@google.com;raia@google.com,6;7;5,4;4;4,Reject,0,11,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google,reinforcement learning;continuous control;robotics;constrained optimization;multi-objective optimization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2661,ICLR,2019,Learning Hash Codes via Hamming Distance Targets,Martin Loncaric;Ryan Weber;Bowei Liu,martin@thehive.ai;ryan@thehive.ai;liubowei@gmail.com,6;4;4,3;3;5,Reject,4,6,0.0,yes,9/27/18,Harvey Mudd College;;Stanford University,information retrieval;learning to hash;cbir,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,n,
2662,ICLR,2019,Interactive Parallel Exploration for Reinforcement Learning in Continuous Action Spaces,Whiyoung Jung;Giseung Park;Youngchul Sung,wy.jung@kaist.ac.kr;gs.park@kaist.ac.kr;ycsung@kaist.ac.kr,7;6;4,4;4;4,Reject,0,5,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,reinforcement learning;continuous action space RL,-1;-1;-1,95;95;95,m;m,NAN,NAN,n,
2663,ICLR,2019,A Proposed Hierarchy of Deep Learning Tasks,Joel Hestness;Sharan Narang;Newsha Ardalani;Heewoo Jun;Hassan Kianinejad;Md. Mostofa Ali Patwary;Yang Yang;Yanqi Zhou;Gregory Diamos;Kenneth Church,joel@baidu.com;sharan@baidu.com;ardalaninewsha@baidu.com;junheewoo@baidu.com;hassankianinejad@baidu.com;patwarymostofa@baidu.com;yangyang62@baidu.com;zhouyanqi@baidu.com;gregdiamos@baidu.com;kennethchurch@baidu.com,6;4;4,3;5;2,Reject,0,0,0.0,yes,9/27/18,Baidu;Baidu;Baidu;Baidu;Baidu;Baidu;Baidu;Baidu;Baidu;Baidu,Deep learning;scaling with data;computational complexity;learning curves;speech recognition;image recognition;machine translation;language modeling,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2664,ICLR,2019,Multi-Grained Entity Proposal Network for Named Entity Recognition,Congying Xia;Chenwei Zhang;Tao Yang;Yaliang Li;Nan Du;Xian Wu;Wei Fan;Fenglong Ma;Philip S. Yu,cxia8@uic.edu;czhang99@uic.edu;tytaoyang@tencent.com;yaliangli@tencent.com;ndu@tencent.com;kevinxwu@tencent.com;davidwfan@tencent.com;fenglong@buffalo.edu;psyu@uic.edu,5;5;4,4;3;4,Reject,0,3,0.0,yes,9/27/18,"University of Illinois, Chicago;University of Illinois, Chicago;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;State University of New York, Buffalo;University of Illinois, Chicago",,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,usa,usa,n,8
2665,ICLR,2019,Massively Parallel Hyperparameter Tuning,Liam Li;Kevin Jamieson;Afshin Rostamizadeh;Ekaterina Gonina;Moritz Hardt;Ben Recht;Ameet Talwalkar,jamieson@cs.washington.edu;rostami@google.com;kgonina@google.com;hardt@berkeley.edu;brecht@berkeley.edu;talwalkar@cmu.edu,5;6;5,4;4;4,Reject,0,5,0.0,yes,9/27/18,University of Washington;Google;Google;University of California Berkeley;University of California Berkeley;Carnegie Mellon University,hyperparameter optimization;automl,10;-1;-1;-1;-1;1,25;-1;-1;18;18;24,-1;-1,usa,usa,n,
2666,ICLR,2019,Dynamic Graph Representation Learning via Self-Attention Networks,Aravind Sankar;Yanhong Wu;Liang Gou;Wei Zhang;Hao Yang,asankar3@illinois.edu;yanwu@visa.com;ligou@visa.com;wzhan@visa.com;haoyang@visa.com,4;6;5,5;4;4,Reject,2,7,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;Visa Research;Visa Research;Visa Research;Visa Research",Graph Representation Learning;Dynamic Graphs;Attention;Self-Attention;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;10
2667,ICLR,2019,Denoise while Aggregating: Collaborative Learning in Open-Domain Question Answering,Haozhe Ji;Yankai Lin;Zhiyuan Liu;Maosong Sun,jihaozhe@gmail.com;mrlyk423@gmail.com;liuzy@tsinghua.edu.cn;sms@tsinghua.edu.cn,4;6;5,4;4;4,Reject,0,0,0.0,yes,9/27/18,"Tsinghua University;Tencent AI Lab;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",natural language processing;open-domain question answering;semi-supervised learning,-1;-1;4;4,-1;-1;30;30,-1;-1,NAN,NAN,n,
2668,ICLR,2019,Are Generative Classifiers More Robust to Adversarial Attacks?,Yingzhen Li;John Bradshaw;Yash Sharma,yl494@cam.ac.uk;jab255@cam.ac.uk;ysharma1126@gmail.com,4;6;4;8,4;3;5;3,Reject,0,13,2.0,yes,9/27/18,"University of Cambridge;University of Cambridge;Centre for Integrative Neuroscience, AG Bethge",generative models;adversarial attack;defence;detection;Bayes' rule,77;77;-1,2;2;-1,-1;-1,NAN,NAN,n,5;4
2669,ICLR,2019,Sentence Encoding with Tree-Constrained Relation Networks,Lei Yu;Cyprien de Masson d'Autume;Chris Dyer;Phil Blunsom;Lingpeng Kong;Wang Ling,leiyu@google.com;cyprien@google.com;cdyer@google.com;pblunsom@google.com;lingpenk@google.com;lingwang@google.com,5;5;3,4;4;4,Reject,0,4,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google,sentence encoder;relation networks;tree;machine translation,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2670,ICLR,2019,Exploiting Cross-Lingual Subword Similarities in Low-Resource Document Classification,Mozhi Zhang;Yoshinari Fujinuma;Jordan Boyd-Graber,mozhi@cs.umd.edu;yoshinari.fujinuma@colorado.edu;jbg@umiacs.umd.edu,6;4;6,3;3;4,Reject,0,4,0.0,yes,9/27/18,"University of Maryland, College Park;University of Colorado, Boulder;University of Maryland, College Park",cross-lingual transfer;character-based method;low-resource language,12;59;12,69;100;69,-1;-1,usa,usa,n,6
2671,ICLR,2019,Exploiting Environmental Variation to Improve Policy Robustness in  Reinforcement Learning,Siddharth Mysore;Robert Platt;Kate Saenko,sidmys@bu.edu;rplatt@ccs.neu.edu;saenko@bu.edu,5;3;6,3;4;4,Reject,0,3,0.0,yes,9/27/18,Boston University;Northeastern University;Boston University,Reinforcement Learning;Policy Robustness;Policy generalization;Automated Curriculum,77;15;77,70;839;70,-1;-1,europe,it,n,1
2672,ICLR,2019,DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING,Miaofeng Liu;Yan Song;Hongbin Zou;Tong Zhang,water3er@gmail.com;clksong@gmail.com;hbzou@xdu.edu.cn;bradymzhang@tencent.com,4;7;5,2;3;4,Reject,0,1,1.0,yes,9/27/18,University of Science and Technology of China;Tencent AI Lab;Shandong University;Tencent AI Lab,domain adaptation;training data selection;reinforcement learning;natural language processing,-1;-1;136;-1,-1;-1;569;-1,-1;-1,NAN,NAN,n,3
2673,ICLR,2019,Assumption Questioning: Latent Copying and Reward Exploitation in Question Generation,Tom Hosking;Sebastian Riedel,thomas.hosking.17@ucl.ac.uk;sebastian.riedel@gmail.com,3;4;5,4;4;4,Reject,0,3,0.0,yes,9/27/18,University College London;Facebook,question generation;answer questioning;pointer networks;reinforcement learning,50;-1,-1;-1,-1;-1,NAN,NAN,n,3;4
2674,ICLR,2019,Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks,Dhanush Dharmaretnam;Chris Foster;Alona Fyshe,dhanush987@gmail.com;chris.james.foster@gmail.com;alona@ualberta.ca,4;3;4,4;4;2,Reject,0,0,0.0,yes,9/27/18,University of Victoria;University of Victoria;University of Alberta,Distributional Semantics;word embeddings;cnns;interpretability,-1;207;94,-1;346;119,-1;-1,canada,ca,n,3;4
2675,ICLR,2019,Learning to control self-assembling morphologies: a study of generalization via modularity,Deepak Pathak;Chris Lu;Trevor Darrell;Philip Isola;Alexei A. Efros,pathak@berkeley.edu;chris.lu@berkeley.edu;trevor@eecs.berkeley.edu;phillip.isola@gmail.com;efros@eecs.berkeley.edu,4;4;7,4;3;3,Reject,2,8,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;;University of California Berkeley,modularity;compostionality;graphs;dynamics;network,-1;-1;-1;-1;-1,18;18;18;-1;18,-1;-1,usa,usa,n,10
2676,ICLR,2019,End-to-End Hierarchical Text Classification with Label Assignment Policy,Yuning Mao;Jingjing Tian;Jiawei Han;Xiang Ren,yuningm2@illinois.edu;tianjj97@pku.edu.cn;hanj@illinois.edu;xiangren@usc.edu,5;4;4,4;5;4,Reject,1,8,0.0,yes,9/27/18,"University of Illinois, Urbana Champaign;Peking University;University of Illinois, Urbana Champaign;University of Southern California",Hierarchical Classification;Text Classification,-1;14;-1;27,-1;27;-1;66,-1;-1,usa,usa,n,
2677,ICLR,2019,SynonymNet: Multi-context Bilateral Matching for Entity Synonyms,Chenwei Zhang;Yaliang Li;Nan Du;Wei Fan;Philip S. Yu,czhang99@uic.edu;yaliangli@tencent.com;ndu@tencent.com;davidwfan@tencent.com;psyu@uic.edu,5;7;4,4;5;4,Reject,0,4,0.0,yes,9/27/18,"University of Illinois, Chicago;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;University of Illinois, Chicago",deep learning;entity synonym,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,usa,usa,n,
2678,ICLR,2019,TopicGAN: Unsupervised Text Generation from Explainable Latent Topics,Yau-Shian Wang;Yun-Nung Chen;Hung-Yi Lee,king6101@gmail.com;y.v.chen@ieee.org;tlkagkb93901106@gmail.com,4;4;5,2;4;4,Reject,0,3,0.0,yes,9/27/18,Nanyang Technological University;Nanyang Technological University;National Taiwan University,unsupervised learning;topic model;text generation,44;44;-1,52;52;-1,-1;-1,asia,in,n,3;5;4
2679,ICLR,2019,ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING,Farzaneh Mahdisoltani;Guillaume Berger;Waseem Gharbieh;David Fleet;Roland Memisevic,farzaneh@cs.toronto.edu;guillaume.berger@twentybn.com;waseem.gharbieh@twentybn.com;fleet@cs.toronto.edu;roland.memisevic@twentybn.com,5;5;5,4;4;4,Reject,0,0,0.0,yes,9/27/18,University of Toronto;Twenty Billion Neurons;Twenty Billion Neurons;University of Toronto;Twenty Billion Neurons,Transfer Learning;Video Understanding;Fine-grained Video Classification;Video Captioning;Common Sense;Something-Something Dataset.,18;-1;-1;18;-1,22;-1;-1;22;-1,-1;-1,NAN,NAN,n,6
2680,ICLR,2019,Neural Networks for Modeling Source Code Edits,Rui Zhao;David Bieber;Kevin Swersky;Daniel Tarlow,oahziur@gmail.com;dbieber@google.com;kswersky@google.com;dtarlow@google.com,5;6;6;6,4;2;4;4,Reject,0,5,0.0,yes,9/27/18,Purdue University;Google;Google;Google,Neural Networks;Program Synthesis;Source Code Modeling,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;1;5
2681,ICLR,2019,COMPOSITION AND DECOMPOSITION OF GANS,Yeu-Chern Harn;Zhenghao Chen;Vladimir Jojic,ycharn@cs.unc.edu;chen.zhenghao@gmail.com;vjojic@gmail.com,4;5;4,5;5;4,Reject,0,5,0.0,yes,9/27/18,"University of North Carolina, Chapel Hill;;Calico Labs",,67;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,5;4
2682,ICLR,2019,"Unicorn: Continual learning with a universal, off-policy agent",Daniel J. Mankowitz;Augustin ≈Ω√≠dek;Andr√© Barreto;Dan Horgan;Matteo Hessel;John Quan;Junhyuk Oh;Hado van Hasselt;David Silver;Tom Schaul,dmankowitz@google.com;augustinzidek@google.com;andrebarreto@google.com;horgan@google.com;mtthss@google.com;johnquan@google.com;junhyuk@google.com;hado@google.com;davidsilver@google.com;schaul@google.com,4;5;6,5;4;4,Reject,0,3,0.0,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;continual learning;universal value functions;off-policy learning;multi-task,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2683,ICLR,2019,Understanding the Asymptotic Performance of Model-Based RL Methods,William Whitney;Rob Fergus,wfwhitney@gmail.com;fergus@cs.nyu.edu,5;6;4;2,3;4;3;4,Reject,0,5,0.0,yes,9/27/18,New York University;New York University,model-based reinforcement learning;mbrl;reinforcement learning;predictive models;predictive learning;forward models;deep learning,24;24,27;27,-1;-1,usa,usa,n,
2684,ICLR,2019,Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning,Jiaxi Liu;Yidong Zhang;Xiaoqing Wang;Yuming Deng;Xingyu Wu;Miaolan Xie,galiliu.ljx@alibaba-inc.com;tanfu.zyd@alibaba-inc.com;robin.wxq@alibaba-inc.com;yuming.dym@alibaba-inc.com;zhuyang.wxy@alibaba-inc.com;miaolan.xml@alibaba-inc.com,4;4;4,4;5;3,Reject,2,4,0.0,yes,9/27/18,Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group,reinforcement learning;dynamic pricing;e-commerce;revenue management;field experiment,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2685,ICLR,2019,Coupled Recurrent Models for Polyphonic Music Composition,John Thickstun;Zaid Harchaoui;Dean P. Foster;Sham M. Kakade,thickstn@cs.washington.edu;zaid@uw.edu;sham@cs.washington.edu;dean@foster.net,7;4;3,3;4;4,Reject,1,4,0.0,yes,9/27/18,"University of Washington;University of Washington, Seattle;University of Washington;University of Pennsylvania",music composition;music generation;polyphonic music modeling,10;10;10;-1,25;25;25;-1,-1;-1,asia,in,n,5
2686,ICLR,2019,From Nodes to Networks: Evolving Recurrent Neural Networks,Aditya Rawal;Jason Liang;Risto Miikkulainen,aditya@cs.utexas.edu;jasonzliang@utexas.edu;risto@cs.utexas.edu,5;4;4,4;4;4,Reject,0,0,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Recurrent neural networks;evolutionary algorithms;genetic programming,-1;-1;-1,-1;-1;-1,-1;-1,usa,usa,n,3
2687,ICLR,2019,Lyapunov-based Safe Policy Optimization,Yinlam Chow;Ofir Nachum;Mohammad Ghavamzadeh;Edgar Guzman-Duenez,yinlamchow@google.com;ofirnachum@google.com;mohammad.ghavamzadeh@inria.fr;duenez@google.com,6;5;6;8,2;3;2;3,Reject,0,6,0.0,yes,9/27/18,Google;Google;INRIA;Google,Reinforcement Learning;Safe Learning;Lyapunov Functions;Constrained Markov Decision Problems,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2688,ICLR,2019,Composing Entropic Policies using Divergence Correction,Jonathan J Hunt;Andre Barreto;Timothy P Lillicrap;Nicolas Heess,jjhunt@google.com;andrebarreto@google.com;countzero@google.com;heess@google.com,4;5;7,3;4;3,Reject,0,9,0.0,yes,9/27/18,Google;Google;Google;Google,maximum entropy RL;policy composition;deep rl,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,10
2689,ICLR,2019,Accelerated Gradient Flow for Probability Distributions,Amirhossein Taghvaei;Prashant G. Mehta,amirhoseintghv@gmail.com;mehtapg@illinois.edu,4;5;6,4;3;4,Reject,0,7,0.0,yes,9/27/18,"University of California, Irvine;University of Illinois, Urbana Champaign",Optimal transportation;Mean-field optimal control;Wasserstein gradient flow;Markov-chain Monte-Carlo,-1;-1,99;-1,-1;-1,usa,usa,y,1;9
2690,ICLR,2019,Constraining Action Sequences with Formal Languages for Deep Reinforcement Learning,Dong Xu;Eleanor Quint;Zeynep Hakguder;Haluk Dogan;Stephen Scott;Matthew Dwyer,dx@virginia.edu;pquint@cse.unl.edu;zeynep.hakguder@huskers.unl.edu;haluk.dogan@huskers.unl.edu;sscott@cse.unl.edu;matthewbdwyer@virginia.edu,5;4;3,4;3;4,Reject,0,1,0.0,yes,9/27/18,"University of Virginia;University of Nebraska, Lincoln;University of Nebraska, Lincoln;University of Nebraska, Lincoln;University of Nebraska, Lincoln;University of Virginia",reinforcement learning;constraints;finite state machines,59;207;207;207;207;59,113;337;337;337;337;113,-1;-1,usa,usa,n,
2691,ICLR,2019,What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning,Siddharth Reddy;Anca D. Dragan;Sergey Levine,sgr@berkeley.edu;anca@berkeley.edu;svlevine@eecs.berkeley.edu,5;6;5,3;4;4,Reject,3,12,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley,imitation learning;reinforcement learning,-1;-1;-1,18;18;18,-1;-1,usa,usa,n,4
2692,ICLR,2019,Boosting Trust Region Policy Optimization by Normalizing flows Policy,Yunhao Tang;Shipra Agrawal,yt2541@columbia.edu;sa3305@columbia.edu,4;6;4,4;4;4,Reject,0,3,0.0,yes,9/27/18,Columbia University;Columbia University,Reinforcement Learning;Normalizing Flows,21;21,14;14,-1;-1,usa,usa,n,
2693,ICLR,2019,Architecture Compression,Anubhav Ashok,anubhava@alumni.cmu.edu,4;6;4,3;4;4,Reject,0,5,0.0,yes,9/27/18,Carnegie Mellon University,compression;architecture search,1,24,-1,usa,usa,y,
2694,ICLR,2019,Super-Resolution via Conditional Implicit Maximum Likelihood Estimation,Ke Li*;Shichong Peng*;Jitendra Malik,ke.li@eecs.berkeley.edu;shichong.peng@mail.utoronto.ca;malik@eecs.berkeley.edu,5;6;6,3;5;5,Reject,6,5,0.0,yes,9/27/18,University of California Berkeley;Toronto University;University of California Berkeley,super-resolution,-1;-1;-1,18;-1;18,-1;-1,usa,usa,n,
2695,ICLR,2019,A Better Baseline for Second Order Gradient Estimation in Stochastic Computation Graphs,Jingkai Mao;Jakob Foerster;Tim Rockt√§schel;Gregory Farquhar;Maruan Al-Shedivat;Shimon Whiteson,jingkai.mao@gmail.com;jakobfoerster@gmail.com;tim.rocktaeschel@gmail.com;gregory.farquhar@cs.ox.ac.uk;alshedivat@cs.cmu.edu;shimon.whitesone@cs.ox.ac.uk,3;6;5;6,4;3;4;3,Reject,0,5,0.0,yes,9/27/18,University of Oxford;;Facebook AI Research;University of Oxford;Carnegie Mellon University;University of Oxford,Reinforcement learning;meta-learning;higher order derivatives;gradient estimation;stochastic computation graphs,-1;-1;-1;44;1;44,-1;-1;-1;1;24;1,-1;-1,europe,uk,y,6;10
2696,ICLR,2019,Reinforced Pipeline Optimization: Behaving Optimally with Non-Differentiabilities,Aijun Bai;Dongdong Chen;Gang Hua;Lu Yuan,aijunbai@gmail.com;cd722522@mail.ustc.edu.cn;ganghua@gmail.com;luyuan@microsoft.com,4;5;3,5;2;4,Reject,0,0,0.0,yes,9/27/18,Microsoft;University of Science and Technology of China;Wormpex AI Research;Microsoft,Pipeline Optimization;Reinforcement Learning;Stochastic Computation Graph;Faster R-CNN,-1;-1;-1;-1,-1;132;-1;-1,-1;-1,NAN,NAN,n,2
2697,ICLR,2019,An Active Learning Framework for Efficient Robust Policy Search,Sai Kiran Narayanaswami;Nandan Sudarsanam;Balaraman Ravindran,saikirann94@gmail.com;nandan@iitm.ac.in;ravi@cse.iitm.ac.in,5;6;5,3;3;4,Reject,0,4,0.0,yes,9/27/18,Indian Institute of Technology Madras;Indian Institute of Technology Madras;Indian Institute of Technology Madras,Deep Reinforcement Learning,-1;-1;-1,-1;625;625,-1;-1,NAN,NAN,n,
2698,ICLR,2019,Model-Agnostic Meta-Learning for Multimodal Task Distributions,Risto Vuorio;Shao-Hua Sun;Hexiang Hu;Joseph J. Lim,vuoristo@gmail.com;shaohuas@usc.edu;hexiangh@usc.edu;limjj@usc.edu,5;3;5,3;5;4,Reject,0,7,0.0,yes,9/27/18,University of Oxford;University of Southern California;University of Southern California;University of Southern California,Meta-learning;gradient-based meta-learning;model-based meta-learning,44;27;27;27,1;66;66;66,-1;-1,usa,usa,n,6
2699,ICLR,2019,Teaching to Teach by Structured Dark Knowledge,Ziliang Chen;Keze Wang;Liang Lin,c.ziliang@yahoo.com;kezewang@gmail.com;linliang@ieee.org,4;3;6,1;4;5,Reject,0,0,0.0,yes,9/27/18,"SUN YAT-SEN UNIVERSITY;University of California, Los Angeles;SUN YAT-SEN UNIVERSITY",teaching to teach;dark knowledge;curriculum learning;teaching,-1;-1;-1,-1;15;-1,-1;-1,asia,in,n,
2700,ICLR,2019,Constrained Bayesian Optimization for Automatic Chemical Design,Ryan-Rhys Griffiths;Jos√© Miguel Hern√°ndez-Lobato,rrg27@cam.ac.uk;jmh233@cam.ac.uk,3;4;5,4;3;4,Reject,0,0,0.0,yes,9/27/18,University of Cambridge;University of Cambridge,Bayesian Optimization;Generative Models,77;77,2;2,-1;-1,europe,uk,n,11
2701,ICLR,2019,Transfer Value or Policy? A Value-centric Framework Towards Transferrable Continuous Reinforcement Learning,Xingchao Liu;Tongzhou Mu;Hao Su,liuxc1996@gmail.com;t3mu@eng.ucsd.edu;haosu@eng.ucsd.edu,5;4;5,3;4;2,Reject,0,10,0.0,yes,9/27/18,"University of Texas, Austin;University of California, San Diego;University of California, San Diego",Reinforcement Learning;Transfer Learning;Control;Value function,-1;-1;-1,-1;31;31,-1;-1,usa,usa,y,6
2702,ICLR,2019,Understanding GANs via Generalization Analysis for Disconnected Support,Masaaki Imaizumi;Kenji Fukumizu,insou11@hotmail.com;fukumizu@ism.ac.jp,5;6;6,4;4;3,Reject,0,4,0.0,yes,9/27/18,"The University of Tokyo;The Institute of Statistical Mathematics, Japan",Generalization analysis;Statistical estimation;Understanding GANs;Disconnected support,59;-1,45;-1,-1;-1,NAN,NAN,y,1;5;4
2703,ICLR,2019,Ergodic Measure Preserving Flows,Yichuan Zhang;Jos√© Miguel Hern√°ndez-Lobato;Zoubin Ghahramani,yichuan.zhang@eng.cam.ac.uk;jmh233@cam.ac.uk;zoubin@eng.cam.ac.uk,5;5;4,4;3;5,Reject,4,16,0.0,yes,9/27/18,University of Cambridge;University of Cambridge;University of Cambridge,Markov chain Monte Carlo;variational inference;deep generative models,77;77;77,2;2;2,-1;-1,europe,uk,y,11;1;5
2704,ICLR,2019,Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication,Felix Sattler;Simon Wiedemann;Klaus-Robert M√ºller;Wojciech Samek,felix.sattler@hhi.fraunhofer.de;simon.wiedemann@hhi.fraunhofer.de;klaus-robert.mueller@tu-berlin.de;wojciech.samek@hhi.fraunhofer.de,6;3;5,4;4;4,Reject,0,2,0.0,yes,9/27/18,Fraunhofer IIS;Fraunhofer IIS;TU Berlin;Fraunhofer IIS,,-1;-1;136;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
2705,ICLR,2019,"S-System, Geometry, Learning, and Optimization: A Theory of Neural Networks",Shuai Li;Kui Jia,lishuai918@gmail.com;kuijia@scut.edu.cn,4;4,2;1,Reject,0,0,0.0,yes,9/27/18,The Chinese University of Hong Kong;South China University of Technology,neural network theory;probability measure theory;probability coupling theory;S-System;optimization;random matrix;renormalization group;information geometry;coarse graining;hierarchy;activation function;symmetry,-1;-1,-1;576,-1;-1,NAN,NAN,y,1
2706,ICLR,2019,Lorentzian Distance Learning,Marc T Law;Jake Snell;Richard S Zemel,law@cs.toronto.edu;jsnell@cs.toronto.edu;zemel@cs.toronto.edu,6;5;5,4;4;4,Reject,0,9,0.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto,distance learning;metric learning;hyperbolic geometry;hierarchy tree,18;18;18,22;22;22,-1;-1,canada,ca,y,
2707,ICLR,2019,W2GAN: RECOVERING AN OPTIMAL TRANSPORT MAP WITH A GAN,Leygonie Jacob*;Jennifer She*;Amjad Almahairi;Sai Rajeswar;Aaron Courville,jacob.leygonie@gmail.com;jennifershe123@gmail.com;amjadmahayri@gmail.com;rajsai24@gmail.com;aaron.courville@gmail.com,6;3;4,3;4;3,Reject,0,9,0.0,yes,9/27/18,University of Oxford;Stanford University;Facebook;;University of Montreal,Optimal Transportation;Deep Learning;Generative Adversarial Networks;Wasserstein Distance,-1;4;-1;-1;116,-1;3;-1;-1;108,-1;-1,canada,ca,y,1;5;4
2708,ICLR,2019,A Differentiable Self-disambiguated Sense Embedding Model via Scaled Gumbel Softmax,Fenfei Guo;Mohit Iyyer;Leah Findlater;Jordan Boyd-Graber,fenfeigo@cs.umd.edu;miyyer@cs.umass.edu;leahkf@uw.edu;jbg@umiacs.umd.edu,6;7;6,5;3;4,Reject,0,8,0.0,yes,9/27/18,"University of Maryland, College Park;University of Massachusetts, Amherst;University of Washington, Seattle;University of Maryland, College Park",unsupervised representation learning;sense embedding;word sense disambiguation;human evaluation,12;27;10;12,69;191;25;69,-1;-1,usa,usa,n,8
2709,ICLR,2019,On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent,Noah Golmant;Nikita Vemuri;Zhewei Yao;Vladimir Feinberg;Amir Gholami;Kai Rothauge;Michael Mahoney;Joseph Gonzalez,noah.golmant@berkeley.edu;nikitavemuri@berkeley.edu;zheweiy@berkeley.edu;vladf@berkeley.edu;amirgh@berkeley.edu;kai.rothauge@berkeley.edu;mmahoney@stat.berkeley.edu;jegonzal@cs.berkeley.edu,5;8;5,3;4;3,Reject,0,6,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Deep learning;large batch training;scaling rules;stochastic gradient descent,-1;-1;-1;-1;-1;-1;-1;-1,18;18;18;18;18;18;18;18,-1;-1,usa,usa,n,2;3
2710,ICLR,2019,Three continual learning scenarios and a case for generative replay,Gido M. van de Ven;Andreas S. Tolias,gidovandeven@gmail.com;astolias@bcm.edu,4;4;6,4;4;5,Reject,0,6,2.0,yes,9/27/18,University of Cambridge;Baylor College of Medicine,continual learning;generative models;replay;distillation;variational autoencoder,77;-1,2;-1,-1;-1,NAN,NAN,n,5
2711,ICLR,2019,A More Globally Accurate Dimensionality Reduction Method Using Triplets,Ehsan Amid;Manfred K. Warmuth,eamid@ucsc.edu;manfred@ucsc.edu,5;6;6,4;5;3,Reject,0,8,0.0,yes,9/27/18,University of Southern California;University of Southern California,Dimensionality Reduction;Visualization;Triplets;t-SNE;LargeVis,27;27,66;66,m;m,usa,usa,n,
2712,ICLR,2019,Learning Kolmogorov Models for Binary Random Variables,Hadi Ghauch;Hossein S. Ghadikolaei;Mikael Skoglund;Carlo Fischione,ghauch@kth.se;hshokri@kth.se;skoglund@kth.se;carlofi@kth.se,5;5;8,4;2;4,Reject,0,5,0.0,yes,9/27/18,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",Kolmogorov model;interpretable models;causal relations mining;non-convex optimization;relaxations,207;207;207;207,173;173;173;173,-1;-1,NAN,NAN,y,
2713,ICLR,2019,Laplacian Smoothing Gradient Descent,Stanley J. Osher;Bao Wang;Penghang Yin;Xiyang Luo;Minh Pham;Alex T. Lin,sjo@math.ucla.edu;wangbaonj@gmail.com;yph@g.ucla.edu;xylmath@gmail.com;minhrose@ucla.edu;atlin@math.ucla.edu,5;6;6,4;4;4,Reject,4,7,1.0,yes,9/27/18,"University of California, Los Angeles;University of Utah;University of California, Los Angeles;;University of California, Los Angeles;University of California, Los Angeles",Laplacian Smoothing;Nonconvex Optimization;Deep Learning,-1;67;-1;-1;-1;-1,15;200;15;-1;15;15,-1;-1,usa,usa,y,1;9
2714,ICLR,2019,Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis,Kelly W. Zhang;Samuel R. Bowman,kellywzhang@seas.harvard.edu;bowman@nyu.edu,6;5;7,4;4;4,Reject,0,7,0.0,yes,9/27/18,Harvard University;New York University,representation learning;recurrent neural networks;syntax;part-of-speech tagging,50;24,6;27,-1;-1,usa,usa,n,6;3
2715,ICLR,2019,Conscious Inference for Object Detection,Jiahuan Zhou;Nikolaos Karianakis;Ying Wu;Gang Hua,zhoujh09@gmail.com;nikolaos.karianakis@microsoft.com;yingwu@eecs.northwestern.edu;ganghua@gmail.com,4;6;4,4;4;5,Reject,0,3,0.0,yes,9/27/18,Northwestern University;Microsoft;Northwestern University;Wormpex AI Research,consciousness;conscious inference;object detection;object pose estimation,50;-1;50;-1,20;-1;20;-1,-1;-1,NAN,NAN,n,2
2716,ICLR,2019,Learning Gibbs-regularized GANs with variational discriminator reparameterization,Nicholas Rhinehart;Anqi Liu;Kihyuk Sohn;Paul Vernaza,nrhineha@cs.cmu.edu;anqiliu@caltech.edu;ksohn@nec-labs.com;pvernaza@nec-labs.com,5;5;4,5;3;4,Reject,0,4,0.0,yes,9/27/18,Carnegie Mellon University;California Institute of Technology;NEC-Labs;NEC-Labs,deep generative models;graphical models;trajectory forecasting;GANs;density estimation;structured prediction,1;136;-1;-1,24;3;-1;-1,-1;-1,NAN,NAN,n,10;5;4
2717,ICLR,2019,DynCNN: An Effective Dynamic Architecture on Convolutional Neural Network for Surveillance Videos,De-Qin Gao;Ping-Chen Tsai;Shanq-Jang Ruan,b10113120@gmail.com;pctsainb@gmail.com;sjruan@mail.ntust.edu.tw,3;4;4,4;4;3,Reject,2,0,0.0,yes,9/27/18,Facebook;;Hong Kong University of Science and Technology,CNN optimization;Reduction on convolution calculation;dynamic convolution;surveillance video,-1;-1;-1,-1;-1;44,-1;-1,NAN,NAN,n,
2718,ICLR,2019,Expressiveness in Deep Reinforcement Learning,Xufang Luo;Qi Meng;Di He;Wei Chen;Yunhong Wang;Tie-Yan Liu,luoxufang@buaa.edu.cn;meq@microsoft.com;dihe@microsoft.com;wche@microsoft.com;yhwang@buaa.edu.cn;tyliu@microsoft.com,6;4;4,4;3;4,Reject,0,7,0.0,yes,9/27/18,Beihang University;Microsoft;Microsoft;Microsoft;Beihang University;Microsoft,,94;-1;-1;-1;94;-1,658;-1;-1;-1;658;-1,-1;-1,NAN,NAN,n,
2719,ICLR,2019,Exploring Curvature Noise in Large-Batch Stochastic Optimization,Yeming Wen;Kevin Luk;Maxime Gazeau;Guodong Zhang;Harris Chan;Jimmy Ba,ywen@cs.toronto.edu;kevin.luk@borealisai.com;maxime.gazeau@borealisai.com;gdzhang.cs@gmail.com;hchan@cs.toronto.edu;jba@cs.toronto.edu,5;6;5,4;4;5,Reject,0,20,0.0,yes,9/27/18,University of Toronto;Borealis AI;Borealis AI;University of Toronto;University of Toronto;University of Toronto,optimization;large-batch training;generalization;noise covariance,18;-1;-1;18;18;18,22;-1;-1;22;22;22,-1;-1,canada,ca,y,1
2720,ICLR,2019,Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting,Peize Zhao;Danfeng Cai;Shaokun Zhang;Feng Chen;Zhemin Zhang;Cheng Wang;Jonathan Li,zhaopeize@sensetime.com;caidanfeng@sensetime.com;zhangshaokun@sensetime.com;chenfeng@xmu.edu.cn;zhangzhemin@xmu.edu.cn;cwang@xmu.edu.cn;junli@xmu.edu.cn,4;5;3,3;3;4,Reject,1,3,0.0,yes,9/27/18,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;Xiamen University;Xiamen University;Xiamen University;Xiamen University,traffic flow forecasting;spatiotemporal dependencies;deep learning;intelligent transportation system,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;490;490;490;490,-1;-1,NAN,NAN,n,1
2721,ICLR,2019,An experimental study of layer-level training speed and its impact on generalization,Simon Carbonnelle;Christophe De Vleeschouwer,simon.carbonnelle@uclouvain.be;christophe.devleeschouwer@uclouvain.be,6;5;5,3;4;2,Reject,0,10,0.0,yes,9/27/18,UCL;UCL,generalization;optimization;vanishing gradients;experimental;fundamental research,285;285,16;16,-1;-1,europe,gr,n,1
2722,ICLR,2019,DEEP ADVERSARIAL FORWARD MODEL,Morgan Funtowicz;Tomi Silander;Arnaud Sors;Julien Perez,morgan.funtowicz@naverlabs.com;tomi.silander@naverlabs.com;arnaud.sors@naverlabs.com;julien.perez@naverlabs.com,4;4;4,5;5;4,Reject,0,0,0.0,yes,9/27/18,Naver Labs Europe;Naver Labs Europe;Naver Labs Europe;Naver Labs Europe,forward model;adversarial learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
2723,ICLR,2019,Learning models for visual 3D localization with implicit mapping,Dan Rosenbaum;Frederic Besse;Fabio Viola;Danilo J. Rezende;S. M. Ali Eslami,danro@google.com;fbesse@google.com;fviola@google.com;danilor@google.com;aeslami@google.com,6;7;5,3;4;4,Reject,0,7,0.0,yes,9/27/18,Google;Google;Google;Google;Google,generative learning;generative models;generative query networks;camera re-localization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;5
2724,ICLR,2019,End-to-End Learning of Video Compression Using Spatio-Temporal Autoencoders,Jorge Pessoa;Helena Aidos;Pedro Tom√°s;M√°rio A. T. Figueiredo,jorge.pessoa@tecnico.ulisboa.pt;haidos@lx.it.pt;pedro.tomas@inesc-id.pt;mario.figueiredo@lx.it.pt,3;3;2,3;4;5,Reject,0,3,0.0,yes,9/27/18,"University of Lisbon;Instituto de Telecomunica√ß√µes, Portugal;INESC-ID;Instituto de Telecomunica√ß√µes, Portugal",,-1;-1;-1;-1,509;-1;-1;-1,-1;-1,NAN,NAN,n,
2725,ICLR,2019,Augment your batch: better training with larger batches,Elad Hoffer;Itay Hubara;Niv Giladi;Daniel Soudry,elad.hoffer@gmail.com;itayhubara@gmail.com;giladiniv@gmail.com;daniel.soudry@gmail.com,4;4;8,4;4;3,Reject,9,4,0.0,yes,9/27/18,"Habana Labs (Intel);;Technion, Technion;Technion, Technion",Large Batch Training;Augmentation;Deep Learning,-1;-1;27;27,-1;-1;-1;-1,-1;-1,NAN,NAN,y,1
2726,ICLR,2019,Unsupervised Neural Multi-Document Abstractive Summarization of Reviews,Eric Chu;Peter J. Liu,echu@mit.edu;peterjliu@google.com,4;5;9,4;4;4,Reject,1,6,0.0,yes,9/27/18,Massachusetts Institute of Technology;Google,unsupervised learning;abstractive summarization;reviews;text generation,6;-1,5;-1,-1;-1,NAN,NAN,n,
2727,ICLR,2019,Automatic generation of object shapes with desired functionalities,Mihai Andries;Atabak Dehban;Jose Santos-Victor,mandries@isr.tecnico.ulisboa.pt;adehban@isr.tecnico.ulisboa.pt;jasv@isr.tecnico.ulisboa.pt,5;3;3,3;4;4,Reject,0,4,0.0,yes,9/27/18,University of Lisbon;University of Lisbon;University of Lisbon,automated design;affordance learning,-1;-1;-1,509;509;509,-1;-1,NAN,NAN,n,
2728,ICLR,2019,Hybrid Policies Using Inverse Rewards for Reinforcement Learning,Yao Shi;Tian Xia;Guanjun Zhao;Xin Gao,yao.shi@huawei.com;xiatian14@huawei.com;zhaoguanjun1@huawei.com;gaoxin17@huawei.com,3;2;4,4;5;5,Reject,0,0,0.0,yes,9/27/18,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Reinforcement Learning;Rewards,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2729,ICLR,2019,Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space,Bin Zhou;Jiashi Feng,bin.zhou@u.nus.edu;elefjia@u.nus.edu,4;5;4,4;5;4,Reject,0,0,0.0,yes,9/27/18,National University of Singapore;National University of Singapore,Neuroevolution;Reinforcement Learning,18;18,22;22,-1;-1,asia,sg,n,5
2730,ICLR,2019,Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings,Ran Tian;Yash Agrawal;Kento Watanabe;Hiroya Takamura,robin.tianran@gmail.com;yashagrawal@iitkgp.ac.in;kento.watanabe@aist.go.jp;takamura.hiroya@aist.go.jp,6;6;6,3;3;3,Reject,0,3,0.0,yes,9/27/18,AIST;Indian Institute of Technology Kharagpur;AIST;AIST,,17;-1;17;17,95;506;95;95,-1;-1,europe,gr,n,3
2731,ICLR,2019,Teacher Guided Architecture Search,Pouya Bashivan;Mark Tensen;James J DiCarlo,bashivan@mit.edu;mark.tensen@student.uva.nl;dicarlo@mit.edu,6;6;5,4;4;4,Reject,0,8,0.0,yes,9/27/18,Massachusetts Institute of Technology;University of Amsterdam;Massachusetts Institute of Technology,hyperparameter search;architecture search;convolutional neural networks,6;136;6,5;59;5,-1;-1,usa,usa,n,
2732,ICLR,2019,A Convergent Variant of the Boltzmann Softmax Operator in Reinforcement Learning,Ling Pan;Qingpeng Cai;Qi Meng;Wei Chen;Tie-Yan Liu,v-lip@microsoft.com;cqp14@mails.tsinghua.edu.cn;v-qimeng@microsoft.com;wche@microsoft.com;tie-yan.liu@microsoft.com,4;4;5,5;4;4,Reject,0,6,2.0,yes,9/27/18,"Microsoft;Tsinghua University, Tsinghua University;Microsoft;Microsoft;Microsoft",Reinforcement Learning;Boltzmann Softmax Operator;Value Function Estimation,-1;4;-1;-1;-1,-1;30;-1;-1;-1,-1;-1,NAN,NAN,y,1;9
2733,ICLR,2019,GraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation,Guoshuai Zhao;Jun Li;Lu Wang;Xueming Qian;Yun Fu,zgs2012@stu.xjtu.edu.cn;junl.mldl@gmail.com;luwang@ccs.neu.edu;qianxm@mail.xjtu.edu.cn;yunfu@ece.neu.edu,6;6;6,5;4;3,Reject,0,5,0.0,yes,9/27/18,Xi'an Jiaotong University;Massachusetts Institute of Technology;Northeastern University;Xi'an Jiaotong University;Northeastern University,Neural Machine Translation;Natural Language Generation;Graph Embedding;LSTM,-1;6;15;-1;15,565;5;839;565;839,-1;-1,usa,usa,n,8;3;10
2734,ICLR,2019,Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets,Zhiming Zhou;Yuxuan Song;Lantao Yu;Hongwei Wang;Weinan Zhang;Zhihua Zhang;Yong Yu,heyohai@apex.sjtu.edu.cn;songyuxuan@apex.sjtu.edu.cn;yulantao@apex.sjtu.edu.cn;wanghongwei55@gmail.com;wnzhang@sjtu.edu.cn;zhzhang@math.pku.edu.cn;yyu@apex.sjtu.edu.cn,6;4;5,4;4;4,Reject,0,21,1.0,yes,9/27/18,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Stanford University;Shanghai Jiao Tong University;Peking University;Shanghai Jiao Tong University,GANs;Lipschitz-continuity;convergence,36;36;36;4;36;14;36,188;188;188;3;188;27;188,-1;-1,asia,cn,y,5
2735,ICLR,2019,Hierarchically-Structured Variational Autoencoders for Long Text Generation,Dinghan Shen;Asli Celikyilmaz;Yizhe Zhang;Liqun Chen;Xin Wang;Lawrence Carin,dinghan.shen@duke.edu;asli@ieee.org;yizhe.zhang@microsoft.com;liqun.chen@duke.edu;xwang@cs.ucsb.edu;lcarin@duke.edu,5;5;7,4;4;4,Reject,0,8,0.0,yes,9/27/18,Duke University;Facebook;Microsoft;Duke University;UC Santa Barbara;Duke University,Natural Language Processing;Text Generation;Variational Autoencoders,47;-1;-1;47;-1;47,17;-1;-1;17;-1;17,-1;-1,europe,se,n,8;3;5
2736,ICLR,2019,Learning Representations in Model-Free Hierarchical Reinforcement Learning,Jacob Rafati;David Noelle,jrafatiheravi@ucmerced.edu;dnoelle@ucmerced.edu,5;4;3,4;4;5,Reject,0,0,0.0,yes,9/27/18,University of California at Merced;University of California at Merced,Reinforcement Learning;Model-Free Hierarchical Reinforcement Learning;Subgoal Discovery;Unsupervised Learning;Temporal Difference;Temporal Abstraction;Intrinsic Motivation;Markov Decision Processes;Deep Reinforcement Learning;Optimization,-1;-1,-1;-1,-1;-1,usa,usa,n,
2737,ICLR,2019,Towards Decomposed Linguistic Representation with Holographic Reduced Representation,Jiaming Luo;Yuan Cao;Yonghui Wu,j_luo@csail.mit.edu;yuancao@google.com;yonghui@google.com,5;5;6,4;4;3,Reject,0,12,1.0,yes,9/27/18,Massachusetts Institute of Technology;Google;Google,,6;-1;-1,5;-1;-1,-1;-1,NAN,NAN,n,3
2738,ICLR,2019,Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality,Sukarna Barua;Xingjun Ma;Sarah Monazam Erfani;Michael Houle;James Bailey,sukarnab@student.unimelb.edu.au;xingjun.ma@unimelb.edu.au;sarah.erfani@unimelb.edu.au;meh@nii.ac.jp;baileyj@unimelb.edu.au,6;4;6,5;3;4,Reject,0,9,0.0,yes,9/27/18,The University of Melbourne;The University of Melbourne;The University of Melbourne;National Institute of Informatics;The University of Melbourne,Generative Adversarial Networks;Evaluation Metric;Local Intrinsic Dimensionality,77;77;77;-1;77,32;32;32;-1;32,-1;-1,NAN,NAN,n,5;4
2739,ICLR,2019,Deep processing of structured data,≈Åukasz Maziarka;Marek ≈ömieja;Aleksandra Nowak;Jacek Tabor;≈Åukasz Struski;Przemys≈Çaw Spurek,l.maziarka@gmail.com;marek.smieja@uj.edu.pl;aknoow@gmail.com;jacek.tabor@uj.edu.pl;lukasz.struski@uj.edu.pl;przemyslaw.spurek@uj.edu.pl,4;4;4,3;4;3,Reject,0,1,0.0,yes,9/27/18,Ardigen;Jagiellonian University;;Jagiellonian University;Jagiellonian University;Jagiellonian University,structured data;representation learning;deep neural networks,-1;-1;-1;-1;-1;-1,-1;695;-1;695;695;695,-1;-1,NAN,NAN,n,10
2740,ICLR,2019,Predictive Uncertainty through Quantization,Bastiaan S. Veeling;Rianne van den Berg;Max Welling,basveeling@gmail.com;welling.max@gmail.com,5;4;5,3;4;4,Reject,0,3,0.0,yes,9/27/18,"Google;University of California, Irvine",variational inference;information bottleneck;bayesian deep learning;latent variable models;amortized variational inference;uncertainty;learning non-linearities,-1;-1,-1;99,-1;-1,usa,usa,n,
2741,ICLR,2019,TherML: The Thermodynamics of Machine Learning,Alexander A. Alemi;Ian Fischer,alemi@google.com;iansf@google.com,7;3;5,3;4;3,Reject,0,3,0.0,yes,9/27/18,Google;Google,representation learning;information theory;information bottleneck;thermodynamics;predictive information,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2742,ICLR,2019,Countering Language Drift via Grounding,Jason Lee;Kyunghyun Cho;Douwe Kiela,jason@cs.nyu.edu;kyunghyun.cho@nyu.edu;dkiela@fb.com,6;6;6,3;4;4,Reject,0,10,9.0,yes,9/27/18,New York University;New York University;Facebook,grounding;policy gradient;language drift;reinforcement learning,24;24;-1,27;27;-1,-1;-1,NAN,NAN,n,3
2743,ICLR,2019,Amortized Context Vector Inference for Sequence-to-Sequence Networks,Sotirios Chatzis;Kyriacos Tolias;Aristotelis Charalampous,sotirios.chatzis@cut.ac.cy;k.v.tolias@edu.cut.ac.cy;aristotelis.charalampous@edu.cut.ac.cy,6;6;5,3;3;4,Reject,0,4,0.0,yes,9/27/18,Cyprus University of Technology;Cyprus University of Technology;Cyprus University of Technology,neural attention;sequence-to-sequence;variational inference,285;285;285,354;354;354,-1;-1,europe,cy,n,3;8;1
2744,ICLR,2019,Coverage and Quality Driven Training of Generative Image Models,Thomas LUCAS;Konstantin SHMELKOV;Karteek ALAHARI;Cordelia SCHMID;Jakob VERBEEK,thomas.lucas@inria.fr;konstantin.shmelkov@inria.fr;karteek.alahari@inria.fr;cordelia.schmid@inria.fr,7;5;4,4;4;5,Reject,0,19,0.0,yes,9/27/18,INRIA;INRIA;INRIA;INRIA,deep learning;generative modeling;unsupervised learning;maximum likelihood;adversarial learning;gan;vae,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,europe,gr,n,1;5;4
2745,ICLR,2019,Switching Linear Dynamics for Variational Bayes Filtering,Philip Becker-Ehmck;Jan Peters;Patrick van der Smagt,philip.becker-ehmck@volkswagen.de;peters@ias.tu-darmstadt.de;smagt@volkswagen.de,6;4;7,3;4;5,Reject,0,5,0.0,yes,9/27/18,"Machine Learning Research Lab, Volkswagen Group;TU Darmstadt;Machine Learning Research Lab, Volkswagen Group",sequence model;switching linear dynamical systems;variational bayes;filter;variational inference;stochastic recurrent neural network,-1;59;-1,-1;-1;-1,-1;-1,NAN,NAN,n,11;5
2746,ICLR,2019,SupportNet: solving catastrophic forgetting in class incremental learning with support data,Yu Li;Zhongxiao Li;Lizhong Ding;Yijie Pan;Chao Huang;Yuhui Hu;Wei Chen;Xin Gao,yu.li@kaust.edu.sa;zhongxiao.li@kaust.edu.sa;lizhong.ding@inceptioniai.org;pyj@nbicc.com;chuang@ict.ac.cn;huyh@sustc.edu.cn;chenw@sustc.edu.cn;xin.gao@kaust.edu.sa,5;6;4,4;4;4,Reject,0,12,0.0,yes,9/27/18,"KAUST;KAUST;Inception Institute of Artificial Intelligence;Nbicc;Institute of Computing Technology, Chinese Academy of Sciences;University of Science and Technology of China;University of Science and Technology of China;KAUST",,94;94;-1;-1;31;-1;-1;94,-1;-1;-1;-1;-1;132;132;-1,-1;-1,europe,gr,n,
2747,ICLR,2019,Unsupervised Learning  of Sentence Representations Using Sequence Consistency,Siddhartha Brahma,sidbrahma@gmail.com,7;5;5,4;4;4,Reject,0,8,0.0,yes,9/27/18,International Business Machines,sentence representation;unsupervised learning;LSTM,-1,-1,-1,NAN,NAN,n,6;3
2748,ICLR,2019,Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces,Philipp Becker;Harit Pandya;Gregor H.W. Gebhardt;Cheng Zhao;Gerhard Neumann,philippbecker93@googlemail.com;hpandya@lincoln.ac.uk;gebhardt@ias.tu-darmstadt.de;irobotcheng@gmail.com;gneumann@lincoln.ac.uk,6;6;6,4;4;3,Reject,0,3,0.0,yes,9/27/18,Karlsruhe Institute of Technology;University of Lincoln;TU Darmstadt;;University of Lincoln,state estimation;recurrent neural networks;Kalman Filter;deep learning,169;-1;59;-1;-1,133;757;-1;-1;757,-1;-1,NAN,NAN,n,5
2749,ICLR,2019,Shallow Learning For Deep Networks,Eugene Belilovsky;Michael Eickenberg;Edouard Oyallon,belilove@iro.umontreal.ca;michael.eickenberg@berkeley.edu;edouard.oyallon@centralesupelec.fr,6;5;7,4;4;4,Reject,5,20,1.0,yes,9/27/18,University of Montreal;University of California Berkeley;CentraleSupelec,CNN;greedy learning,116;-1;-1,108;18;452,-1;-1,NAN,NAN,n,
2750,ICLR,2019,A Solution to China Competitive Poker Using Deep Learning,Zhenxing Liu;Maoyu Hu;Zhangfei Zhang,liuzx@smzy.cc;humaoyu@smzy.cc;zzf@smzy.cc,3;2,4;3,Reject,28,7,1.0,yes,9/27/18,Harbin Engineering University;;Binghamton University,artificial intelligence;China competitive poker;Dou dizhu;CNN;imperfect information game,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,n,
2751,ICLR,2019,A NOVEL VARIATIONAL FAMILY FOR HIDDEN NON-LINEAR MARKOV MODELS,Daniel Hernandez Diaz;Antonio Khalil Moretti;Ziqiang Wei;Shreya Saxena;John Cunningham;Liam Paninski,dh2832@columbia.edu;amoretti@cs.columbia.edu;weiz@janelia.hhmi.org;ss5513@columbia.edu;jpcunni@gmail.com;liam.paninski@gmail.com,5;8;6,3;5;3,Reject,0,6,0.0,yes,9/27/18,Columbia University;Columbia University;HHMI Janelia Research Campus;Columbia University;;Columbia University,variational inference;time series;nonlinear dynamics;neuroscience,21;21;-1;21;-1;-1,14;14;-1;14;-1;-1,-1;-1,asia,in,n,
2752,ICLR,2019,GenEval: A Benchmark Suite for Evaluating Generative Models,Anton Bakhtin;Arthur Szlam;Marc'Aurelio Ranzato,yolo@fb.com;aszlam@fb.com;ranzato@fb.com,5;5;6,3;4;4,Reject,0,11,0.0,yes,9/27/18,Facebook;Facebook;Facebook,generative models;GAN;VAE;Real NVP,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5
2753,ICLR,2019,Making Convolutional Networks Shift-Invariant Again,Richard Zhang,rich.zhang@eecs.berkeley.edu,6;5;5,4;4;4,Reject,1,7,1.0,yes,9/27/18,University of California Berkeley,convolutional networks;signal processing;shift;translation;invariance;equivariance,-1,18,-1,usa,usa,n,
2754,ICLR,2019,Deconfounding Reinforcement Learning in Observational Settings,Chaochao Lu;Jos√© Miguel Hern√°ndez Lobato,cl641@cam.ac.uk;jmh233@cam.ac.uk,4;4;2,3;4;4,Reject,19,18,0.0,yes,9/27/18,University of Cambridge;University of Cambridge,confounder;causal inference;reinforcement learning,77;77,2;2,-1;-1,europe,uk,n,
2755,ICLR,2019,Incremental Hierarchical Reinforcement Learning with Multitask LMDPs,Adam C Earle;Andrew M Saxe;Benjamin Rosman,adamchristopherearle@gmail.com;andrew.saxe@psy.ox.ac.uk;benjros@gmail.com,3;4;5,4;4;4,Reject,0,0,0.0,yes,9/27/18,University of the Witwatersrand;University of Oxford;University of the Witwatersrand,Reinforcement learning;hierarchy;linear markov decision process;lmdl;subtask discovery;incremental,-1;44;-1,-1;1;293,-1;-1,NAN,NAN,n,
2756,ICLR,2019,Exploration by Uncertainty in Reward Space,Wei-Yang Qu;Yang Yu;Tang-Jie Lv;Ying-Feng Chen;Chang-Jie Fan,nju_qwy@163.com;yuy@nju.edu.cn;hzlvtangjie@corp.netease.com;chenyingfeng1@corp.netease.com;fanchangjie@corp.netease.com,5;5;3,3;2;5,Reject,0,0,0.0,yes,9/27/18,163;Zhejiang University;Fuxi AI Lab in Netease;Fuxi AI Lab in Netease;Fuxi AI Lab in Netease,Policy Exploration;Uncertainty in Reward Space,-1;36;-1;-1;-1,-1;177;-1;-1;-1,-1;-1,NAN,NAN,n,
2757,ICLR,2019,Shrinkage-based Bias-Variance Trade-off for Deep Reinforcement Learning,Yihao Feng;Hao Liu;Jian Peng;Qiang Liu,yihao@cs.utexas.edu;uestcliuhao@gmail.com;jianpeng@illinois.edu;lqiang@cs.utexas.edu,5;4;4,3;2;4,Reject,0,4,0.0,yes,9/27/18,"University of Texas, Austin;;University of Illinois, Urbana Champaign;University of Texas, Austin",bias-variance trade-off;James-stein estimator;reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,usa,usa,n,
2758,ICLR,2019,Improving On-policy Learning with Statistical Reward Accumulation,Yubin Deng;Ke Yu;Dahua Lin;Xiaoou Tang;Chen Change Loy,dy015@ie.cuhk.edu.hk;yk017@ie.cuhk.edu.hk;dhlin@ie.cuhk.edu.hk;xtang@ie.cuhk.edu.hk;ccloy@ieee.org,4;5,3;3,Reject,0,5,0.0,yes,9/27/18,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;Nanyang Technological University,,285;285;285;285;-1,40;40;40;40;-1,-1;-1,asia,in,n,
2759,ICLR,2019,Guided Exploration in Deep Reinforcement Learning,Sahisnu Mazumder;Bing Liu;Shuai Wang;Yingxuan Zhu;Xiaotian Yin;Lifeng Liu;Jian Li;Yongbing Huang,sahisnumazumder@gmail.com;liub@cs.uic.edu;gshuaishuai@gmail.com;yingxuan.zhu@huawei.com;xiaotian.yin@huawei.com;lifeng.liu1@huawei.com;jian.li1@huawei.com;huangyongbing@huawei.com,7;5;3,5;4;3,Reject,0,4,0.0,yes,9/27/18,"University of Illinois, Chicago;University of Illinois, Chicago;;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.",deep reinforcement learning;guided exploration;RL training speed up,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2760,ICLR,2019,Probabilistic Knowledge Graph Embeddings,Farnood Salehi;Robert Bamler;Stephan Mandt,farnood.salehi@epfl.ch;robert.bamler@gmail.com;stephan.mandt@gmail.com,5;6;5,2;3;3,Reject,0,3,0.0,yes,9/27/18,"Swiss Federal Institute of Technology Lausanne;University of Tuebingen;University of California, Irvine",knowledge graph;variational inference;probabilistic models;representation learning,-1;136;-1,-1;94;99,-1;-1,usa,usa,n,11;1;10
2761,ICLR,2019,Accelerated Value Iteration via Anderson Mixing,Yujun Li;Chengzhuo Ni;Guangzeng Xie;Wenhao Yang;Shuchang Zhou;Zhihua Zhang,liyujun145@gmail.com;hzxsncz@pku.edu.cn;smsxgz@pku.edu.cn;yangwenhaosms@pku.edu.cn;zsc@megvii.com;zhzhang@math.pku.edu.cn,7;4;4,4;4;3,Reject,0,8,0.0,yes,9/27/18,Shanghai Jiao Tong University;Peking University;Peking University;Peking University;Megvii Technology Inc.;Peking University,Reinforcement Learning,-1;14;14;14;-1;14,-1;27;27;27;-1;27,-1;-1,asia,cn,y,
2762,ICLR,2019,Safe Policy Learning from Observations,Elad Sarafian;Aviv Tamar;Sarit Kraus,elad.sarafian@gmail.com;avivt@berkeley.edu;sarit@cs.biu.ac.il,5;5;5,4;4;3,Reject,0,5,0.0,yes,9/27/18,Bar Ilan University;University of California Berkeley;Bar Ilan University,learning from observations;safe reinforcement learning;deep reinforcement learning,94;-1;94,456;18;456,-1;-1,europe,il,y,
2763,ICLR,2019,Importance Resampling for Off-policy Policy Evaluation,Matthew Schlegel;Wesley Chung;Daniel Graves;Martha White,mkschleg@ualberta.ca;wchung@ualberta.ca;daniel.graves@huawei.com;whitem@ualberta.ca,6;5;5,4;3;3,Reject,0,10,0.0,yes,9/27/18,University of Alberta;University of Alberta;Huawei Technologies Ltd.;University of Alberta,Reinforcement Learning;Off-policy policy evaluation;importance resampling;importance sampling,94;94;-1;94,119;119;-1;119,-1;-1,canada,ca,y,
2764,ICLR,2019,Mimicking actions is a good strategy for beginners: Fast Reinforcement Learning with Expert Action Sequences,Tharun Medini;Anshumali Shrivastava,tharun.medini@rice.edu;anshumali@rice.edu,5;5;6,3;2;4,Reject,0,5,0.0,yes,9/27/18,Rice University;Rice University,Reinforcement Learning;Imitation Learning;Atari;A3C;GA3C,94;94,86;86,-1;-1,australasia,au,n,
2765,ICLR,2019,Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective,Zhuoran Yang;Zuyue Fu;Kaiqing Zhang;Zhaoran Wang,zy6@princeton.edu;zuyuefu2022@u.northwestern.edu;kzhang66@illinois.edu;zhaoranwang@gmail.com,6;5;5;6,4;3;4;4,Reject,0,10,0.0,yes,9/27/18,"Princeton University;Northwestern University;University of Illinois, Urbana Champaign;Northwestern University",reinforcement learning;Deep Q-networks;actor-critic algorithm;ODE approximation,31;50;-1;50,7;20;-1;20,-1;-1,usa,usa,y,1
2766,ICLR,2019,Unsupervised Emergence of Spatial Structure from Sensorimotor Prediction,Alban Laflaqui√®re;Michael Garcia Ortiz,alban.laflaquiere@gmail.com;mgarciaortiz@softbankrobotics.com,6;7;4,3;3;4,Reject,0,21,2.0,yes,9/27/18,Softbank Robotics Europe;Softbank Robotics Europe,spatial perception;grounding;sensorimotor prediction;unsupervised learning;representation learning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2767,ICLR,2019,Where Off-Policy Deep Reinforcement Learning Fails,Scott Fujimoto;David Meger;Doina Precup,scott.fujimoto@mail.mcgill.ca;david.meger@mcgill.ca;dprecup@cs.mcgill.ca,7;5;5,4;4;3,Reject,5,10,0.0,yes,9/27/18,McGill University;McGill University;McGill University,reinforcement learning;off-policy;imitation;batch reinforcement learning,94;94;94,42;42;42,-1;-1,canada,ca,y,
2768,ICLR,2019,Exploration by random network distillation,Yuri Burda;Harrison Edwards;Amos Storkey;Oleg Klimov,yburda@openai.com;h.l.edwards@sms.ed.ac.uk;a.storkey@ed.ac.uk;oleg@openai.com,7;4;9;10,4;4;5;4,Accept (Poster),0,16,0.0,yes,9/27/18,OpenAI;University of Edinburgh;University of Edinburgh;OpenAI,reinforcement learning;exploration;curiosity,-1;36;36;-1,-1;27;27;-1,-1;-1,NAN,NAN,y,
2769,ICLR,2019,Learning State Representations in Complex Systems with Multimodal Data,Pavel Solovev;Vladimir Aliev;Pavel Ostyakov;Gleb Sterkin;Elizaveta Logacheva;Stepan Troeshestov;Roman Suvorov;Anton Mashikhin;Oleg Khomenko;Sergey I. Nikolenko,pavel.solovev.ilich@gmail.com;vldr.aliev@gmail.com;pavelosta@gmail.com;sterkin.gleb@gmail.com;elimohl@gmail.com;troeshust96@gmail.com;windj007@gmail.com;antonagoo@gmail.com;olegkhomenkoru@gmail.com;snikolenko@gmail.com,6;6;5,3;3;4,Reject,0,5,0.0,yes,9/27/18,Lomonosov Moscow State University;Yandex;Huawei Technologies Ltd.;Samsung;;;Samsung;;;Steklov Institute of Mathematics at St. Petersburg,deep learning;representation learning;state representation;disentangled representation;dataset;autonomous system;temporal multimodal data,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2770,ICLR,2019,EMI: Exploration with Mutual Information Maximizing State and Action Embeddings,Hyoungseok Kim;Jaekyeom Kim;Yeonwoo Jeong;Sergey Levine;Hyun Oh Song,harry2636@mllab.snu.ac.kr;jaekyeom@mllab.snu.ac.kr;yeonwoo@mllab.snu.ac.kr;svlevine@eecs.berkeley.edu;hyunoh@snu.ac.kr,5;7;7,4;4;3,Reject,1,9,0.0,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University;University of California Berkeley;Seoul National University,reinforcement learning;exploration;representation learning,36;36;36;-1;36,74;74;74;18;74,-1;-1,asia,kr,y,5
2771,ICLR,2019,P^2IR: Universal Deep Node Representation via Partial Permutation Invariant Set Functions,Shupeng Gui;Xiangliang Zhang;Shuang Qiu;Mingrui Wu;Jieping Ye;Ji Liu,sgui2@ur.rochester.edu;xiangliang.zhang@kaust.edu.sa;qiush@umich.edu;mingrui.wu@alibaba-inc.com;jieping@gmail.com;ji.liu.uwisc@gmail.com,4;5;7;5,4;3;4;5,Reject,0,0,0.0,yes,9/27/18,University of Rochester;KAUST;University of Michigan;Alibaba Group;;Kwai Inc,graph embedding;set function;representation learning,94;94;9;-1;-1;-1,153;-1;21;-1;-1;-1,-1;-1,asia,in,y,10
2772,ICLR,2019,Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection,Ying Liu;Cheng Zheng,summeryingl@gmail.com;zzhengccheng@gmail.com,3;4;6,4;4;3,Reject,0,9,0.0,yes,9/27/18,Medical College of Wisconsin;Facebook,Model-X Knockoff Generator;model-free FDR control;variable selection,-1;-1,-1;-1,-1;-1,asia,in,y,1
2773,ICLR,2019,Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model,Muthuraman Chidambaram;Yinfei Yang;Daniel Cer;Steve Yuan;Yun-Hsuan Sung;Brian Strope;Ray Kurzweil,mc4xf@virginia.edu;yinfeiy@google.com;cer@google.com;steveyuan@google.com;yhsung@google.com;bps@google.com;raykurzweil@google.com,7;4;6,4;4;5,Reject,0,5,0.0,yes,9/27/18,University of Virginia;Google;Google;Google;Google;Google;Google,sentence;embeddings;zero-shot;multilingual;multi-task;cross-lingual,59;-1;-1;-1;-1;-1;-1,113;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;3
2774,ICLR,2019,Graph Generation via Scattering,Dongmian Zou;Gilad Lerman,dzou@umn.edu;lerman@umn.edu,4;4;4,4;4;3,Reject,0,6,0.0,yes,9/27/18,"University of Minnesota, Minneapolis;University of Minnesota, Minneapolis",graph generative neural network;link prediction;graph and signal generation;scattering network,67;67,56;56,-1;-1,NAN,NAN,n,10;5
2775,ICLR,2019,Context Mover's Distance & Barycenters: Optimal transport of contexts for building representations,Sidak Pal Singh;Andreas Hug;Aymeric Dieuleveut;Martin Jaggi,sidak.singh@epfl.ch;andreas.hug@epfl.ch;aymeric.dieuleveut@epfl.ch;martin.jaggi@epfl.ch,7;4;6,4;4;4,Reject,0,14,1.0,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,representation learning;wasserstein distance;wasserstein barycenter;entailment,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2776,ICLR,2019,Pixel Chem: A Representation for Predicting Material Properties with Neural Network,Shuqian Ye;Yanheng Xu;Jiechun Liang;Hao Xu;Shuhong Cai;Shixin Liu;Xi Zhu,115010269@link.cuhk.edu.cn;115010252@link.cuhk.edu.cn;116010125@link.cuhk.edu.cn;115010250@link.cuhk.edu.cn;115010111@link.cuhk.edu.cn;115010194@link.cuhk.edu.cn;zhuxi@cuhk.edu.cn,3;1;3,3;5;5,Reject,0,7,0.0,yes,9/27/18,"The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen",material property prediction;neural network;material structure representation;chemistry,47;47;47;47;47;47;47,40;40;40;40;40;40;40,-1;-1,NAN,NAN,n,
2777,ICLR,2019,Using Deep Siamese Neural Networks to Speed up Natural Products Research,Nicholas Roberts;Poornav S. Purushothama;Vishal T. Vasudevan;Siddarth Ravichandran;Chen Zhang;William H. Gerwick;Garrison W. Cottrell,n3robert@ucsd.edu;poornavsargoor@gmail.com;vthanvan@eng.ucsd.edu;s2ravich@eng.ucsd.edu;beowulf.zc@gmail.com;wgerwick@ucsd.edu;gary@ucsd.edu,4;3;4,4;2;4,Reject,0,0,0.0,yes,9/27/18,"University of California, San Diego;;University of California, San Diego;University of California, San Diego;;University of California, San Diego;University of California, San Diego",clustering;deep learning;application;chemistry;natural products,-1;-1;-1;-1;-1;-1;-1,31;-1;31;31;-1;31;31,-1;-1,usa,usa,n,
2778,ICLR,2019,Modeling Dynamics of Biological Systems with Deep Generative Neural Networks,Scott Gigante;David van Dijk;Kevin R. Moon;Alexander Strzalkowski;Katie Ferguson;Guy Wolf;Smita Krishnaswamy,scott.gigante@yale.edu;david.vandijk@yale.edu;kevin.moon@usu.edu;alexander.strzalkowski@yale.edu;katie.ferguson@yale.edu;jess.cardin@yale.edu;guy.wolf@yale.edu;smita.krishnaswamy@yale.edu,6;4;3,2;5;5,Reject,0,0,0.0,yes,9/27/18,Yale University;Yale University;SUN YAT-SEN UNIVERSITY;Yale University;Yale University;Yale University;Yale University;Yale University,neural networks;markovian dynamics;single-cell biology;calcium imaging;stochastic dynamics;generative models,67;67;-1;67;67;67;67;67,12;12;352;12;12;12;12;12,-1;-1,europe,fi,n,5
2779,ICLR,2019,Zero-shot Learning for Speech Recognition with Universal Phonetic Model,Xinjian Li;Siddharth Dalmia;David R. Mortensen;Florian Metze;Alan W Black,xinjianl@andrew.cmu.edu;sdalmia@cs.cmu.edu;dmortens@cs.cmu.edu;fmetze@cs.cmu.edu;awb@cs.cmu.edu,7;5;4,4;4;4,Reject,0,9,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,zero-shot learning;speech recognition;acoustic modeling,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,n,6
2780,ICLR,2019,CAML: Fast Context Adaptation via Meta-Learning,Luisa M Zintgraf;Kyriacos Shiarlis;Vitaly Kurin;Katja Hofmann;Shimon Whiteson,lmzintgraf@gmail.com;kyriacos@latentlogic.com;vitaly.kurin@eng.ox.ac.uk;katja.hofmann@microsoft.com;shimon.whiteson@cs.ox.ac.uk,6;4;6;6,2;5;4;2,Reject,2,7,0.0,yes,9/27/18,University of Oxford;Latent Logic;University of Oxford;Microsoft;University of Oxford,,44;-1;44;-1;44,1;-1;1;-1;1,-1;-1,europe,uk,n,6
2781,ICLR,2019,Interactive Agent Modeling by Learning to Probe,Tianmin Shu;Caiming Xiong;Ying Nian Wu;Song-Chun Zhu,tianmin.shu@ucla.edu;cxiong@salesforce.com;ywu@stat.ucla.edu;sczhu@stat.ucla.edu,6;6;6;6,4;4;3;4,Reject,0,9,0.0,yes,9/27/18,"University of California, Los Angeles;SalesForce.com;University of California, Los Angeles;University of California, Los Angeles",Agent Modeling;Theory of Mind;Deep Reinforcement Learning;Multi-agent Reinforcement Learning,-1;-1;-1;-1,15;-1;15;15,-1;-1,usa,usa,n,
2782,ICLR,2019,Unified recurrent network for many feature types,Alexander Stec;Diego Klabjan;Jean Utke,stec@u.northwestern.edu;d-klabjan@northwestern.edu;jutke@allstate.com,4;6;4;7,4;3;4;2,Reject,0,8,0.0,yes,9/25/19,Northwestern University;Northwestern University;Allstate,sparse;recurrent;asynchronous;time;series,50;50;-1,20;20;-1,m;m,NAN,NAN,n,
2783,ICLR,2019,Differential Equation Networks,MohamadAli Torkamani;Phillip Wallis,torkamani@gmail.com;wallis.phillip@gmail.com,4;5;5,4;3;4,Reject,0,0,0.0,yes,9/27/18,University of Oregon;Microsoft,deep learning;activation function;differential equations,-1;-1,-1;-1,-1;-1,NAN,NAN,y,
2784,ICLR,2019,Adversarial Audio Super-Resolution with Unsupervised Feature Losses,Sung Kim;Visvesh Sathe,sungmk@umich.edu;sathe@uw.edu,4;5;6,4;4;4,Reject,0,6,1.0,yes,9/27/18,"University of Michigan;University of Washington, Seattle",,9;10,21;25,-1;-1,NAN,NAN,n,5;4
2785,ICLR,2019,Learning powerful policies and better dynamics models by encouraging consistency,Shagun Sodhani;Anirudh Goyal;Tristan Deleu;Yoshua Bengio;Jian Tang,sshagunsodhani@gmail.com;anirudhgoyal9119@gmail.com;tristan.deleu@gmail.com;yoshua.bengio@mila.quebec;tangjianpku@gmail.com,2;5;3,4;3;5,Reject,0,23,0.0,yes,9/27/18,Facebook;;University of Montreal;Mila;HEC Montreal,model-based reinforcement learning;deep learning;generative agents;policy gradient;imitation learning,-1;-1;116;136;-1,-1;-1;108;314;-1,-1;-1,canada,ca,n,
2786,ICLR,2019,Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet,Ella M. Gale;Anh Nguyen;Ryan Blything;Nicholas Martin and Jeffrey S. Bowers,ella.gale@gmail.com;anhnguyen@auburn.edu;ryan.blything@bristol.ac.uk;nm13850@bristol.ac.uk;j.bowers@bristol.ac.uk,5;6;3,3;3;5,Reject,0,6,0.0,yes,9/27/18,University of Bristol;Auburn University;University of Bristol;University of Bristol;University of Bristol,AlexNet;neural networks;selectivity;localist;distributed;represenataion;precision;measures of selectivity;object detectors;single directions;network analysis,-1;419;94;94;94,-1;652;76;76;76,-1;-1,europe,uk,n,
2787,ICLR,2019,Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics,Antonin Raffin;Ashley Hill;Ren√© Traor√©;Timoth√©e Lesort;Natalia D√≠az-Rodr√≠guez;David Filliat,antonin.raffin@ensta-paristech.fr;ashley.hill@u-psud.fr;krb.traore@protonmail.com;timothee.lesort@ensta-paristech.fr;diaz.rodriguez.natalia@gmail.com;david.filliat@ensta-paristech.fr,5;3;4,4;4;4,Reject,0,4,0.0,yes,9/27/18,ENSTA ParisTech;UPSud/INRIA University Paris-Saclay;Protonmail;ENSTA ParisTech;ENSTA ParisTech;ENSTA ParisTech,reinforcement learning;state representation learning;feature extraction;robotics;deep learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2788,ICLR,2019,Transferrable End-to-End Learning for Protein Interface Prediction,Raphael J. L. Townshend;Rishi Bedi;Ron O. Dror,raphael@cs.stanford.edu;rbedi@cs.stanford.edu;rondror@cs.stanford.edu,5;5;5,4;3;3,Reject,0,4,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University,transfer learning;protein interface prediction;deep learning;structural biology,4;4;4,3;3;3,-1;-1,usa,usa,n,6
2789,ICLR,2019,Visual Imitation Learning with Recurrent Siamese Networks,Glen Berseth;Christopher J. Pal,gberseth@gmail.com;christopher.pal@polymtl.ca,4;4;5,4;3;4,Reject,0,6,0.0,yes,9/27/18,University of California Berkeley;Polytechnique Montreal,Reinforcement Learning;Imitation Learning;Deep Learning,-1;285,18;-1,-1;-1,canada,ca,n,
2790,ICLR,2019,Self-Supervised Generalisation with Meta Auxiliary Learning,Shikun Liu;Edward Johns;Andrew Davison,shikun.liu17@imperial.ac.uk;e.johns@imperial.ac.uk;a.davison@imperial.ac.uk,4;4;6,3;4;4,Reject,0,3,0.0,yes,9/27/18,Imperial College London;Imperial College London;Imperial College London,meta learning;auxiliary learning;multi-task learning;self-supervised learning,47;47;47,8;8;8,-1;-1,europe,uk,n,
2791,ICLR,2019,GRAPH TRANSFORMATION POLICY NETWORK FOR CHEMICAL REACTION PREDICTION,Kien Do;Truyen Tran;Svetha Venkatesh,dkdo@deakin.edu.au;truyen.tran@deakin.edu.au;svetha.venkatesh@deakin.edu.au,6;5;5,5;4;4,Reject,0,11,0.0,yes,9/27/18,Deakin University;Deakin University;Deakin University,Chemical Reaction;Graph Transformation;Reinforcement Learning,-1;-1;-1,334;334;334,-1;-1,asia,cn,n,10
2792,ICLR,2019,DiffraNet: Automatic Classification of Serial Crystallography Diffraction Patterns,Artur Souza;Leonardo B. Oliveira;Sabine Hollatz;Matt Feldman;Kunle Olukotun;James M. Holton;Aina E. Cohen;Luigi Nardi,arturluis@dcc.ufmg.br;leob@dcc.ufmg.br;shollatz@slac.stanford.edu;mattfel@stanford.edu;kunle@stanford.edu;jmholton@slac.stanford.edu;acohen@slac.stanford.edu;lnardi@stanford.edu,5;3;8,4;5;4,Reject,0,9,0.0,yes,9/27/18,Universidade Federal de Minas Gerais;Universidade Federal de Minas Gerais;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Serial Crystallography;Deep Learning;Image Classification,-1;-1;4;4;4;4;4;4,-1;-1;3;3;3;3;3;3,-1;-1,usa,usa,n,2
2793,ICLR,2019,Exploring the interpretability of LSTM neural networks over multi-variable data,Tian Guo;Tao Lin,tian.guo@gess.ethz.ch;tao.lin@epfl.ch,6;6;5,5;5;3,Reject,0,5,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology Lausanne,Interpretability;recurrent neural network;attention,-1;-1,-1;-1,-1;-1,NAN,NAN,y,8
2794,ICLR,2019,Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization,Hesham Mostafa;Xin Wang,hesham.mostafa@intel.com;xin3.wang@intel.com,4;4;6,4;4;4,Reject,16,11,0.0,yes,9/27/18,Intel;Intel,sparse;reparameterization;overparameterization;convolutional neural network;training;compression;pruning,-1;-1,-1;-1,-1;-1,NAN,NAN,n,1
2795,ICLR,2019,An Energy-Based Framework for Arbitrary Label Noise Correction,Jaspreet Sahota;Divya Shanmugam;Janahan Ramanan;Sepehr Eghbali;Marcus Brubaker,sahotaj1@gmail.com;divyas@mit.edu;janahan.ramanan@borealisai.com;sepehr3pehr@gmail.com;mbrubake@cs.toronto.edu,5;5;5,4;4;5,Reject,0,2,0.0,yes,9/27/18,University of Toronto;Massachusetts Institute of Technology;Borealis AI;University of Waterloo;University of Toronto,label noise;feature dependent noise;label correction;unsupervised machine learning;semi-supervised machine learning,-1;6;-1;31;18,-1;5;-1;207;22,-1;-1,canada,ca,n,1;5
2796,ICLR,2019,Incremental Few-Shot Learning with Attention Attractor Networks,Mengye Ren;Renjie Liao;Ethan Fetaya;Richard S. Zemel,mren@cs.toronto.edu;rjliao@cs.toronto.edu;ethanf@cs.toronto.edu;zemel@cs.toronto.edu,5;5;5,4;5;3,Reject,4,9,0.0,yes,9/27/18,University of Toronto;University of Toronto;University of Toronto;University of Toronto,meta-learning;few-shot learning;incremental learning,18;18;18;18,22;22;22;22,-1;-1,canada,ca,n,6;8
2797,ICLR,2019,Targeted Adversarial Examples for Black Box Audio Systems,Rohan Taori;Amog Kamsetty;Brenton Chu;Nikita Vemuri,rohantaori@berkeley.edu;amogkamsetty@berkeley.edu;brentonlongchu@berkeley.edu;nikitavemuri@berkeley.edu,3;4;6,4;3;4,Reject,0,3,0.0,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,adversarial attack;adversarial examples;audio processing;speech to text;deep learning;adversarial audio;black box;machine learning,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,4
2798,ICLR,2019,End-to-End Multi-Lingual Multi-Speaker Speech Recognition,Hiroshi Seki;Takaaki Hori;Shinji Watanabe;Jonathan Le Roux;John R. Hershey,seki@slp.cs.tut.ac.jp;thori@merl.com;shinjiw@ieee.org;leilujp@gmail.com;johnhershey@google.com,3;3;3,4;5;4,Reject,0,0,0.0,yes,9/27/18,Meiji University;Mitsubishi Electric Research Labs;Carnegie Mellon University;;Google,end-to-end ASR;multi-lingual ASR;multi-speaker ASR;code-switching;encoder-decoder;connectionist temporal classification,-1;-1;1;-1;-1,978;-1;24;-1;-1,-1;-1,NAN,NAN,n,
2799,ICLR,2019,Policy Generalization In Capacity-Limited Reinforcement Learning,Rachel A. Lerch;Chris R. Sims,lerchr2@rpi.edu;simsc3@rpi.edu,7;7;5,4;3;4,Reject,0,4,0.0,yes,9/27/18,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute,reinforcement learning;generalization;capacity constraints;information theory,207;207,304;304,-1;-1,usa,usa,n,1;10
2800,ICLR,2019,Learning Neural Random Fields with Inclusive Auxiliary Generators,Yunfu Song;Zhijian Ou,769414284@qq.com;ozjthu@gmail.com,5;6;6,3;3;2,Reject,0,7,1.0,yes,9/27/18,"Tsinghua University;Tsinghua University, Tsinghua University",Neural random fields;Deep generative models;Unsupervised learning;Semi-supervised learning,-1;4,-1;30,-1;-1,NAN,NAN,y,5
2801,ICLR,2019,Learning Disentangled Representations with Reference-Based Variational Autoencoders,Adria Ruiz;Oriol Martinez;Xavier Binefa;Jakob Verbeek,adria.ruiz-ovejero@inria.fr;oriol.martinez@upf.edu;xavier.binefa@upf.edu;jakob.verbeek@inria.fr,7;6;6,4;4;3,Reject,0,8,1.0,yes,9/27/18,INRIA;Universitat Pompeu Fabra;Universitat Pompeu Fabra;INRIA,Disentangled representations;Variational Autoencoders;Adversarial Learning;Weakly-supervised learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,europe,gr,n,2;5;4
2802,ICLR,2019,Recycling the discriminator for improving the inference mapping of GAN,Duhyeon Bang;Hyunjung Shim,duhyeonbang@yonsei.ac.kr;kateshim@yonsei.ac.kr,3;3;7,5;4;4,Reject,0,4,0.0,yes,9/27/18,Yonsei University;Yonsei University,,169;169,231;231,-1;-1,asia,cn,n,5;4
2803,ICLR,2019,On Difficulties of Probability Distillation,Chin-Wei Huang;Faruk Ahmed;Kundan Kumar;Alexandre Lacoste;Aaron Courville,chin-wei.huang@umontreal.ca;faruk.ahmed.91@gmail.com;kundankumar2510@gmail.com;allac@elementai.com;aaron.courville@gmail.com,5;7;5,5;2;4,Reject,0,3,0.0,yes,9/27/18,University of Montreal;University of Montreal;University of Montreal;Element AI;University of Montreal,Probability distillation;Autoregressive models;normalizing flows;wavenet;pixelcnn,116;116;116;-1;116,108;108;108;-1;108,-1;-1,canada,ca,n,
2804,ICLR,2019,AIM: Adversarial Inference by Matching Priors and Conditionals,Hanbo Li;Yaqing Wang;Changyou Chen;Jing Gao,alexanderhanboli@gmail.com;yaqingwa@buffalo.edu;cchangyou@gmail.com;jing@buffalo.edu,6;7;4,4;4;5,Reject,0,4,1.0,yes,9/27/18,"Amazon;State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo",Generative adversarial network;inference;generative model,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2805,ICLR,2019,Deep Reinforcement Learning of Universal Policies with Diverse Environment Summaries,Felix Berkenkamp;Debadeepta Dey;Ashish Kapoor,befelix@inf.ethz.ch;dedey@microsoft.com;akapoor@microsoft.com,4;6;5,5;4;4,Reject,0,0,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Microsoft;Microsoft,Domain Randomization;Diverse Summaries;Reinforcement learning,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2806,ICLR,2019,Gradient Acceleration in Activation Functions,Sangchul Hahn;Heeyoul Choi,s.hahn@handong.edu;hchoi@handong.edu,3;5;2,4;3;5,Reject,0,4,0.0,yes,9/27/18,Handong Global University;Handong Global University,Gradient Acceleration;Saturation Areas;Dropout;Coadaptation,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2807,ICLR,2019,COLLABORATIVE MULTIAGENT REINFORCEMENT LEARNING  IN HOMOGENEOUS SWARMS,Arbaaz Khan;Clark Zhang;Vijay Kumar;Alejandro Ribeiro,arbaazk@seas.upenn.edu;vijay.kumar@seas.upenn.edu;aribeiro@seas.upenn.edu,6;4;5,3;4;4,Reject,0,0,0.0,yes,9/27/18,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,Reinforcement Learning;Multi Agent;policy gradient,21;21;21,10;10;10,-1;-1,usa,usa,n,
2808,ICLR,2019,Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourages convex latent distributions,Tim Sainburg;Marvin Thielk;Brad Thielman;Benjamin Migliori;Timothy Gentner,tsainbur@ucsd.edu;marvin.thielk@gmail.com;ben.migliori@lanl.gov;tgentner@ucsd.edu,4;5;4,4;4;5,Reject,2,12,0.0,yes,9/27/18,"University of California, San Diego;;Los Alamos National Laboratory;University of California, San Diego",convex;GAN;autoencoder;interpolation;stimuli generation;adversarial;latent distribution,-1;-1;-1;-1,31;-1;-1;31,-1;-1,usa,usa,n,5;4
2809,ICLR,2019,Beyond Winning and Losing: Modeling Human Motivations and Behaviors with Vector-valued Inverse Reinforcement Learning,Baoxiang Wang;Tongfang Sun;Xianjun Sam Zheng,wangbx66@gmail.com;tongfs@uw.edu;sam.zheng@deephow.com,5;4;4,3;4;4,Reject,0,3,0.0,yes,9/27/18,"The Chinese University of Hong Kong, Shenzhen;University of Washington, Seattle;Deephow",,47;10;-1,40;25;-1,-1;-1,NAN,NAN,n,
2810,ICLR,2019,MLPrune: Multi-Layer Pruning for Automated Neural Network Compression,Wenyuan Zeng;Raquel Urtasun,zengwenyuan1995@gmail.com;urtasun@uber.com,5;6;4,5;4;4,Reject,0,5,0.0,yes,9/27/18,Uber;Uber,Automated Model Compression;Neural Network Pruning,-1;-1,-1;-1,-1;-1,southamerica,br,n,
2811,ICLR,2019,Offline Deep models calibration with bayesian neural networks,Juan Maro√±as;Roberto Paredes;Daniel Ramos,jmaronasm@gmail.com;rparedes@dsic.upv.es;daniel.ramos@uam.es,4;3;3,4;4;4,Reject,1,12,0.0,yes,9/27/18,Universidad Politecnica de Valencia;Universidad Politecnica de Valencia;Universidad Aut√≥noma de Madrid,calibration;deep models;bayesian neural networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,2;11
2812,ICLR,2019,Successor Uncertainties: exploration and uncertainty in temporal difference learning,David Janz;Jiri Hron;Jos√© Miguel Hern√°ndez-Lobato;Katja Hofmann;Sebastian Tschiatschek,david.janz93@gmail.com;jh2084@cam.ac.uk;jmh233@cam.ac.uk;katja.hofmann@microsoft.com;sebastian.tschiatschek@microsoft.com,4;5;4,3;4;5,Reject,0,8,0.0,yes,9/27/18,University of Cambridge;University of Cambridge;University of Cambridge;Microsoft;Microsoft,,77;77;77;-1;-1,2;2;2;-1;-1,-1;-1,NAN,NAN,n,10
2813,ICLR,2019,Adversarially Robust Training through Structured Gradient Regularization,Kevin Roth;Aurelien Lucchi;Sebastian Nowozin;Thomas Hofmann,kevin.roth@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch;sebastian.nowozin@microsoft.com;thomas.hofmann@inf.ethz.ch,4;3;4,4;4;4,Reject,10,10,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Microsoft;Swiss Federal Institute of Technology,Adversarial Training;Gradient Regularization;Deep Learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
2814,ICLR,2019,MERCI: A NEW METRIC TO EVALUATE THE CORRELATION BETWEEN PREDICTIVE UNCERTAINTY AND TRUE ERROR,michel moukari;lo√Øc simon;sylvaine picard;fr√©d√©ric jurie,michel.moukari@unicaen.fr;loic.simon@ensicaen.fr;sylvaine.picard@safrangroup.com;frederic.jurie@unicaen.fr,4;5;3,4;3;4,Reject,0,5,0.0,yes,9/27/18,University of Caen Normandie;ENSICAEN;Safran;University of Caen Normandie,evaluation metric;predictive uncertainty;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;11
2815,ICLR,2019,Unsupervised Document Representation using Partition Word-Vectors Averaging,Vivek Gupta;Ankit Kumar Saw;Partha Pratim Talukdar;Praneeth Netrapalli,vgupta@cs.utah.edu;ankit.kgpian@gmail.com;ppt@iisc.ac.in;praneeth@microsoft.com,7;6;4,4;3;4,Reject,0,12,1.0,yes,9/27/18,University of Utah;;Indian Institute of Science;Microsoft,Unsupervised Learning;Natural Language Processing;Representation Learning;Document Embedding,67;-1;-1;-1,200;-1;273;-1,-1;-1,NAN,NAN,n,3
2816,ICLR,2019,Graph U-Net,Hongyang Gao;Shuiwang Ji,hongyang.gao@tamu.edu;sji@tamu.edu,7;4;7,5;4;4,Reject,6,12,2.0,yes,9/27/18,Texas A&M;Texas A&M,graph;pooling;unpooling;U-Net,50;50,160;160,-1;-1,NAN,NAN,n,2;10
2817,ICLR,2019,Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning,Ramtin Keramati;Jay Whang;Patrick Cho;Emma Brunskill,keramati@stanford.edu;jaywhang@cs.stanford.edu;patcho@cs.stanford.edu;ebrun@cs.stanford.edu,5;4,4;4,Reject,0,0,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University,Reinforcement Learning;Strategic Exploration;Model Based Reinforcement Learning,4;4;4;4,3;3;3;3,-1;-1,usa,usa,n,
2818,ICLR,2019,Evolutionary-Neural Hybrid Agents for Architecture Search,Krzysztof Maziarz;Andrey Khorlin;Quentin de Laroussilhe;Andrea Gesmundo,kmaziarz@google.com;akhorlin@google.com;underflow@google.com;agesmundo@google.com,4;5;4,4;2;4,Reject,0,1,0.0,yes,9/27/18,Google;Google;Google;Google,Evolutionary;Architecture Search;NAS,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2819,ICLR,2019,Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems,Christopher Stanton;Jeff Clune,cstanto3@uwyo.edu;jeffclune@uwyo.edu,5;5;5,3;1;3,Reject,0,4,0.0,yes,9/27/18,University of Wyoming;University of Wyoming,,285;285,-1;-1,-1;-1,usa,usa,n,
2820,ICLR,2019,Deep Probabilistic Video Compression,Jun Han;Salvator Lombardo;Christopher Schroers;Stephan Mandt,jun.han.gr@dartmouth.edu;sal.lombardo@disneyresearch.com;christopher.schroers@disneyresearch.com;stephan.mandt@gmail.com,6;5;6,5;4;5,Reject,0,5,0.0,yes,9/27/18,"Dartmouth College;Disney Research, Disney;Disney Research, Disney;University of California, Irvine",variational inference;video compression;deep generative models,169;-1;-1;-1,89;-1;-1;99,-1;-1,usa,usa,n,5
2821,ICLR,2019,Reduced-Gate Convolutional LSTM Design Using Predictive Coding for Next-Frame Video Prediction,Nelly Elsayed;Anthony S. Maida;Magdy Bayoumi,nelly.elsayed5@gmail.com;maida@louisiana.edu;mab0778@louisiana.edu,3;5;7,5;4;4,Reject,0,7,0.0,yes,9/27/18,University of Arizona;University of Arizona;University of Arizona,rgcLSTM;convolutional LSTM;unsupervised learning;predictive coding;video prediction;moving MNIST;KITTI datasets;deep learning,207;207;207,161;161;161,-1;-1,usa,usa,n,
2822,ICLR,2019,Playing the Game of Universal Adversarial Perturbations,Julien Perolet;Mateusz Malinowski;Bilal Piot;Olivier Pietquin,perolat@google.com;mateuszm@google.com;piot@google.com;pietquin@google.com,6;5;5,1;4;3,Reject,3,5,0.0,yes,9/27/18,Google;Google;Google;Google,adversarial perturbations;universal adversarial perturbations;game theory;robust machine learning,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,4
2823,ICLR,2019,Unsupervised Expectation Learning for Multisensory Binding,Pablo Barros;German I. Parisi;Manfred Eppe;Stefan Wermter,barros@informatik.uni-hamburg.de;parisi@informatik.uni-hamburg.de;eppe@informatik.uni-hamburg.de;wermter@informatik.uni-hamburg.de,4;5;5,4;3;2,Reject,0,5,0.0,yes,9/27/18,University of Hamburg;University of Hamburg;University of Hamburg;University of Hamburg,multisensory binding;expectation learning;unsupervised learning;Deep autoencoder;Growing-When-Required Network;animal recognition,207;207;207;207,207;207;207;207,-1;-1,europe,de,n,
2824,ICLR,2019,"The meaning of most"" for visual question answering models""",Alexander Kuhnle;Ann Copestake,aok25@cam.ac.uk;aac10@cam.ac.uk,7;5;5,4;5;4,Reject,0,8,0.0,yes,9/27/18,University of Cambridge;University of Cambridge,quantifier;evaluation methodology;psycholinguistics;visual question answering,77;77,2;2,-1;-1,europe,uk,n,
2825,ICLR,2019,Unsupervised Image to Sequence Translation with Canvas-Drawer Networks,Kevin Frans;Chin-Yi Cheng,kevinfrans2@gmail.com;chin-yi.cheng@autodesk.com,4;4;6,4;4;5,Reject,0,9,0.0,yes,9/27/18,Massachusetts Institute of Technology;Autodesk,image;translation;unsupervised;model-based,-1;-1,-1;-1,-1;-1,NAN,NAN,n,2
2826,ICLR,2019,NSGA-Net: A Multi-Objective Genetic Algorithm for Neural Architecture Search,Zhichao Lu;Ian Whalen;Vishnu Boddeti;Yashesh Dhebar;Kalyanmoy Deb;Erik Goodman;Wolfgang Banzhaf,mikelzc1990@gmail.com;whalenia@msu.edu;vishnu@msu.edu;dhebarya@egr.msu.edu;kdeb@egr.msu.edu;goodman@egr.msu.edu;banzhafw@msu.edu,5;6;5,4;4;3,Reject,0,5,0.0,yes,9/27/18,Michigan State University;Michigan State University;Michigan State University;Michigan State University;Michigan State University;Michigan State University;Michigan State University,neural architecture search;evolutionary algorithms,-1;116;116;116;116;116;116,-1;84;84;84;84;84;84,-1;-1,usa,usa,n,11
2827,ICLR,2019,PA-GAN: Improving GAN Training by Progressive Augmentation,Dan Zhang;Anna Khoreva,dan.zhang2@de.bosch.com;anna.khoreva@de.bosch.com,5;4;5,5;2;4,Reject,0,9,3.0,yes,9/27/18,Bosch;Bosch,Deep Learning;GANs;Augmentation;Generative Modelling,-1;-1,367;367,-1;-1,NAN,NAN,n,5;4
2828,ICLR,2019,Point Cloud GAN,Chun-Liang Li;Manzil Zaheer;Yang Zhang;Barnab√°s P√≥czos;Ruslan Salakhutdinov,chunlial@cs.cmu.edu;manzilz@cs.cmu.edu;yz6@andrew.cmu.edu;bapoczos@cs.cmu.edu;rsalakhu@cs.cmu.edu,5;5;6,4;4;4,Reject,4,7,0.0,yes,9/27/18,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Point Cloud;GAN,1;1;1;1;1,24;24;24;24;24,-1;-1,usa,usa,y,11;1;5;4
2829,ICLR,2019,Uncertainty-guided Lifelong Learning in Bayesian Networks,Sayna Ebrahimi;Mohamed Elhoseiny;Trevor Darrell;Marcus Rohrbach,sayna@eecs.berkeley.edu;elhoseiny@fb.com;trevor@eecs.berkeley.edu;maroffm@gmail.com,4;4;4,4;4;4,Reject,0,4,0.0,yes,9/27/18,University of California Berkeley;Facebook;University of California Berkeley;Facebook,lifelong learning;continual learning;sequential learning,-1;-1;-1;-1,18;-1;18;-1,-1;-1,NAN,NAN,n,11
2830,ICLR,2019,Rectified Gradient: Layer-wise Thresholding for Sharp and Coherent Attribution Maps,Beomsu Kim;Junghoon Seo;Jeongyeol Choe;Jamyoung Koo;Seunghyeon Jeon;Taegyun Jeon,1202kbs@gmail.com;sjh@satreci.com;cjy@si-analytics.ai;jmkoo@si-analytics.ai;jsh@satreci.com;tgjeon@si-analytics.ai,5;5;4,5;4;4,Reject,0,15,0.0,yes,9/27/18,Korea Advanced Institute of Science and Technology;Satrec Initiative co. Itd;SI Analytics;SI Analytics;Satrec Initiative co. Itd;SI Analytics,Interpretability;Attribution Method;Attribution Map,-1;-1;-1;-1;-1;-1,95;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2831,ICLR,2019,Successor Options : An Option Discovery Algorithm for Reinforcement Learning,Manan Tomar*;Rahul Ramesh*;Balaraman Ravindran,manan.tomar@gmail.com;rahul13ramesh@gmail.com;ravi@cse.iitm.ac.in,4;5;6;4,5;4;4;5,Reject,3,8,0.0,yes,9/27/18,University of Alberta;;Indian Institute of Technology Madras,Hierarchical Reinforcement Learning,-1;-1;-1,-1;-1;625,-1;-1,NAN,NAN,n,
2832,ICLR,2019,SnapQuant: A Probabilistic and Nested Parameterization for Binary Networks,Kuan Wang;Hao Zhao;Anbang Yao;Aojun Zhou;Dawei Sun;Yurong Chen,wangkuan15@mails.tsinghua.edu.cn;hao.zhao@intel.com;anbang.yao@intel.com;aojun.zhou@intel.com;dawei.sun@intel.com;yurong.chen@intel.com,4;6;5,5;3;4,Reject,0,3,0.0,yes,9/27/18,"Tsinghua University, Tsinghua University;Intel;Intel;Intel;Intel;Intel",Binary weight networks;neural network quantization;reinforcement learning,4;-1;-1;-1;-1;-1,30;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,11
2833,ICLR,2019,Learning Physics Priors for Deep Reinforcement Learing,Yilun Du;Karthik Narasimhan,yilundu@openai.com;karthikn@cs.princeton.edu,4;5;5,3;4;5,Reject,0,10,0.0,yes,9/27/18,OpenAI;Princeton University,Model-Based Reinforcement Learning;Intuitive Physics,-1;31,-1;7,-1;-1,usa,usa,n,6;1
2834,ICLR,2019,HC-Net: Memory-based Incremental Dual-Network System for Continual learning,Jangho Kim;Jeesoo Kim;Nojun Kwak,kjh91@snu.ac.kr;kimjiss0305@snu.ac.kr;nojunk@snu.ac.kr,4;4;4,3;4;5,Reject,0,5,0.0,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University,continual learning;lifelong learning;catastrophic forgetting,36;36;36,74;74;74,-1;-1,asia,kr,n,
2835,ICLR,2019,Feature Attribution As Feature Selection,Satoshi Hara;Koichi Ikeno;Tasuku Soma;Takanori Maehara,satohara@ar.sanken.osaka-u.ac.jp;k1keno@ar.sanken.osaka-u.ac.jp;tasuku_soma@mist.i.u-tokyo.ac.jp;takanori.maehara@riken.jp,4;4;3,2;4;3,Reject,0,3,0.0,yes,9/27/18,Osaka University;Osaka University;The University of Tokyo;RIKEN,feature attribution;feature selection,136;136;59;-1,236;236;45;-1,-1;-1,NAN,NAN,n,
2836,ICLR,2019,NECST: Neural Joint Source-Channel Coding,Kristy Choi;Kedar Tatwawadi;Tsachy Weissman;Stefano Ermon,kechoi@cs.stanford.edu;kedart@stanford.edu;tsachy@stanford.edu;ermon@cs.stanford.edu,6;4;7,5;3;4,Reject,0,8,0.0,yes,9/27/18,Stanford University;Stanford University;Stanford University;Stanford University,joint source-channel coding;deep generative models;unsupervised learning,4;4;4;4,3;3;3;3,-1;-1,usa,usa,y,1
2837,ICLR,2019,Generating Images from Sounds Using Multimodal Features and GANs,Jeonghyun Lyu;Takashi Shinozaki;Kaoru Amano,app@live.jp;tshino@nict.go.jp;kaoruamano@nict.go.jp,3;4;4,4;4;5,Reject,0,0,0.0,yes,9/27/18,"Osaka University;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology",deep learning;machine learning;multimodal;generative adversarial networks,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2838,ICLR,2019,Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations,Voot Tangkaratt;Masashi Sugiyama,voot.tangkaratt@riken.jp;sugi@k.u-tokyo.ac.jp,5;5;7;4,3;4;3;5,Reject,0,9,0.0,yes,9/27/18,RIKEN;The University of Tokyo,Imitation learning;Generative adversarial imitation learning,-1;59,-1;45,-1;-1,NAN,NAN,y,5;4
2839,ICLR,2019,Step-wise Sensitivity Analysis: Identifying Partially Distributed Representations for Interpretable Deep Learning,Botty Dimanov;Mateja Jamnik,botty.dimanov@cl.cam.ac.uk;mateja.jamnik@cl.cam.ac.uk,3;4;3,5;4;4,Reject,0,2,0.0,yes,9/27/18,University of Cambridge;University of Cambridge,Interpretability;Interpretable Deep Learning;XAI;dependency graph;sensitivity analysis;outlier detection;instance-specific;model-centric,77;77,2;2,-1;-1,europe,uk,n,10
2840,ICLR,2019,Noisy Information Bottlenecks for Generalization,Julius Kunze;Louis Kirsch;Hippolyt Ritter;David Barber,juliuskunze@gmail.com;mail@louiskirsch.com;j.ritter@cs.ucl.ac.uk;d.barber@cs.ucl.ac.uk,7;5;3,2;3;4,Reject,0,7,0.0,yes,9/27/18,University College London;Google;University College London;University College London,information theory;deep learning;generalization;information bottleneck;variational inference;approximate inference,50;-1;50;50,-1;-1;-1;-1,-1;-1,europe,uk,n,1;5
2841,ICLR,2019,GENERALIZED ADAPTIVE MOMENT ESTIMATION,Guoqiang Zhang;Kenta Niwa;W. Bastiaan Kleijn,guoqiang.zhang@uts.edu.au;niwa.kenta@lab.ntt.co.jp;bastiaan.kleijn@ecs.vuw.ac.nz,3;4;7,4;3;4,Reject,0,6,0.0,yes,9/27/18,University of Technology Sydney;NTT;Victoria University Wellington,adaptive moment estimation;SGD;AMSGrad,67;207;-1,216;-1;346,-1;-1,australasia,nz,y,9
2842,ICLR,2019,q-Neurons: Neuron Activations based on Stochastic Jackson's Derivative Operators,Frank Nielsen;Ke Sun,frank.nielsen@acm.org;sunk.edu@gmail.com,2;6;5,5;3;3,Reject,0,1,0.0,yes,9/27/18,"Ecole polytechnique;University of Nebraska, Kearney",q-calculus;neural activation function,-1;207,115;-1,-1;-1,NAN,NAN,n,1
2843,ICLR,2019,Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening,Merlin Sch√ºler;Hlynur Dav√≠√∞ Hlynsson;Laurenz Wiskott,merlin.schueler@ini.rub.de;hlynur.hlynsson@ini.rub.de;laurenz.wiskott@ini.rub.de,5;6;6,2;4;4,Reject,0,3,0.0,yes,9/27/18,Ruhr-Universt√§t Bochum;Ruhr-Universt√§t Bochum;Ruhr-Universt√§t Bochum,Slow Feature Analysis;Deep Learning;Spectral Embedding;Temporal Coherence,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2844,ICLR,2019,Unsupervised Conditional Generation using noise engineered mode matching GAN,Deepak Mishra;Prathosh AP;Aravind J;Prashant Pandey;Santanu Chaudhury,deemishra21@gmail.com;prathoshap@gmail.com;maxaravind@gmail.com;getprashant57@gmail.com;santanuc@ee.iitd.ac.in,5;5;6,3;3;4,Reject,0,7,0.0,yes,9/27/18,Indian Institute of Technology Delhi;Indian Institute of Technology Delhi;;Indian Institute of Technology Delhi;Indian Institute of Technology Delhi,Noise engineered GAN;Latent space engineering;Mode matching;Unsupervised learning,-1;-1;-1;-1;-1,529;529;-1;529;529,-1;-1,NAN,NAN,y,5;4
2845,ICLR,2019,Variadic Learning by Bayesian Nonparametric Deep Embedding,Kelsey R Allen;Hanul Shin;Evan Shelhamer;Josh B. Tenenbaum,krallen@mit.edu;skyshin@mit.edu;shelhamer@cs.berkeley.edu;jbt@mit.edu,5;4;4,4;2;4,Reject,0,13,0.0,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley;Massachusetts Institute of Technology,meta-learning;metric learning;bayesian nonparametrics;few-shot learning;deep learning,6;6;-1;6,5;5;18;5,-1;-1,usa,usa,n,6;11;1
2846,ICLR,2019,Fast adversarial training for semi-supervised learning,Dongha Kim;Yongchan Choi;Jae-Joon Han;Changkyu Choi;Yongdai Kim,dongha0718@hanmail.net;pminer32@gmail.com;jae-joon.han@samsung.com;changkyu_choi@samsung.com;ydkim0903@gmail.com,7;5;5,4;4;4,Reject,0,6,0.0,yes,9/27/18,Sungshin Women's University;;Samsung;Samsung;Seoul National University,Deep learning;Semi-supervised learning;Adversarial training,-1;-1;-1;-1;36,-1;-1;-1;-1;74,-1;-1,asia,kr,y,5;4
2847,ICLR,2019,Adversarially Learned Mixture Model,Andrew Jesson;C√©cile Low-Kam;Tanya Nair;Florian Soudan;Florent Chandelier;Nicolas Chapados,andrew.jesson@imagia.com;cecile.low-kam@imagia.com;tanya.nair@imagia.com;fsoudan21@gmail.com;florent.chandelier@imagia.com;nicolas.chapados@imagia.com,6;5;6,1;4;2,Reject,0,1,0.0,yes,9/27/18,Imagia;Imagia;Imagia;;Imagia;Imagia,Unsupervised;Semi-supervised;Generative;Adversarial;Clustering,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,5;4
2848,ICLR,2019,Theoretical and Empirical Study of Adversarial Examples,Fuchen Liu;Hongwei Shang;Hong Zhang,fuchenl@andrew.cmu.edu;shanghongwei@oath.com;hongz@oath.com,5;5;4,2;4;4,Reject,5,2,0.0,yes,9/27/18,Carnegie Mellon University;Oath;Oath,Adversarial examples;Feature smoothing;Data augmentation;Decision boundary,1;-1;-1,24;-1;-1,-1;-1,usa,usa,y,4
2849,ICLR,2019,microGAN: Promoting Variety through Microbatch Discrimination,Goncalo Mordido;Haojin Yang;Christoph Meinel,goncalo.mordido@hpi.de;haojin.yang@hpi.de;christoph.meinel@hpi.de,3;3;6,3;3;3,Reject,0,1,0.0,yes,9/27/18,Hasso Plattner Institute;Hasso Plattner Institute;Hasso Plattner Institute,adversarial training;gans,136;136;136,-1;-1;-1,-1;-1,europe,de,n,5;4
2850,ICLR,2019,Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks,Neale Ratzlaff;Li Fuxin,ratzlafn@oregonstate.edu;lif@oregonstate.edu,4;5;5,5;5;3,Reject,10,9,0.0,yes,9/27/18,Oregon State University;Oregon State University,Adversarial examples;Image denoising,77;77,318;318,-1;-1,usa,usa,n,4
2851,ICLR,2019,PPD: Permutation Phase Defense Against Adversarial Examples in Deep Learning,Mehdi Jafarnia-Jahromi;Tasmin Chowdhury;Hsin-Tai Wu;Sayandev Mukherjee,mjafarni@usc.edu;chowdt1@unlv.nevada.edu;hwu@docomoinnovations.com;sayandev.mukherjee@huawei.com,6;7;4,3;4;5,Reject,24,6,0.0,yes,9/27/18,University of Southern California;Nevada System of Higher Education;Docomoinnovations;Huawei Technologies Ltd.,permutation phase defense;adversarial attacks;deep learning,27;-1;-1;-1,66;-1;-1;-1,-1;-1,NAN,NAN,n,4
2852,ICLR,2019,Universal Attacks on Equivariant Networks,Amit Deshpande;Sandesh Kamath;K V Subrahmanyam,amitdesh@microsoft.com;ksandeshk@cmi.ac.in;kv@cmi.ac.in,5;4;4,4;5;5,Reject,0,3,0.0,yes,9/27/18,Microsoft;Chennai Mathematical Institute;Chennai Mathematical Institute,adversarial;equivariance;universal;rotation;translation;CNN;GCNN,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,y,4
2853,ICLR,2019,Detecting Adversarial Examples Via Neural Fingerprinting,Sumanth Dathathri;Stephan Zheng;Yisong Yue;Richard M. Murray,sdathath@caltech.edu;st.t.zheng@gmail.com;yyue@caltech.edu;murray@cds.caltech.edu,6;5;9,3;4;4,Reject,5,38,0.0,yes,9/27/18,California Institute of Technology;SalesForce.com;California Institute of Technology;California Institute of Technology,Adversarial Attacks;Deep Neural Networks,136;-1;136;136,3;-1;3;3,-1;-1,usa,usa,y,4
2854,ICLR,2019,Sorting out Lipschitz function approximation,Cem Anil;James Lucas;Roger B. Grosse,cem.anil@mail.utoronto.ca;jlucas@cs.toronto.edu;rgrosse@cs.toronto.edu,7;5;4,3;4;4,Reject,0,6,4.0,yes,9/27/18,Toronto University;University of Toronto;University of Toronto,deep learning;lipschitz neural networks;generalization;universal approximation;adversarial examples;generative models;optimal transport;adversarial robustness,-1;18;18,-1;22;22,-1;-1,canada,ca,y,1;4
2855,ICLR,2019,Adaptive Mixture of Low-Rank Factorizations for Compact Neural Modeling,Ting Chen;Ji Lin;Tian Lin;Song Han;Chong Wang;Denny Zhou,iamtingchen@gmail.com;lin-j14@mails.tsinghua.edu.cn;tianlin@google.com;chongw@google.com;dennyzhou@google.com;hansong8811@gmail.com,7;4;6,5;5;4,Reject,0,12,0.0,yes,9/27/18,"Google;Tsinghua University, Tsinghua University;Google;Google;Google;Google",Low-Rank Factorization;Compact Neural Nets;Efficient Modeling;Mixture models,-1;4;-1;-1;-1;-1,-1;30;-1;-1;-1;-1,-1;-1,asia,in,n,3
2856,ICLR,2019,ChoiceNet: Robust Learning by  Revealing Output Correlations,Sungjoon Choi;Sanghoon Hong;Kyungjae Lee;Sungbin Lim,sungjoon.s.choi@gmail.com;sanghoon.hong@kakaobrain.com;kyungjae.lee@cpslab.snu.ac.kr;sungbin.lim@kakaobrain.com,4;6;5,4;4;5,Reject,0,7,0.0,yes,9/27/18,"Disney Research, Disney;Kakao Brain;Seoul National University;Kakao Brain",Robust Deep Learning;weakly supervised learning,-1;-1;36;-1,-1;-1;74;-1,-1;-1,NAN,NAN,y,
2857,ICLR,2019,Iteratively Learning from the Best,Yanyao Shen;Sujay Sanghavi,shenyanyao@utexas.edu;sanghavi@mail.utexas.edu,6;3;6,3;5;4,Reject,0,3,0.0,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",noisy samples;deep learning;generative adversarial network,-1;-1,-1;-1,-1;-1,usa,usa,y,1
2858,ICLR,2019,Distilled Agent DQN for Provable Adversarial Robustness,Matthew Mirman;Marc Fischer;Martin Vechev,matthew.mirman@inf.ethz.ch;marcfisc@student.ethz.ch;martin.vechev@inf.ethz.ch,5;3;4,4;2;2,Reject,0,5,0.0,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,reinforcement learning;dqn;adversarial examples;robustness analysis;adversarial defense;robust learning;robust rl,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,4
2859,ICLR,2019,On Regularization and Robustness of Deep Neural Networks,Alberto Bietti*;Gr√©goire Mialon*;Julien Mairal,alberto.bietti@inria.fr;gregoire.mialon@inria.fr;julien.mairal@inria.fr,5;4;6,3;4;2,Reject,0,8,0.0,yes,9/27/18,INRIA;INRIA;INRIA,regularization;robustness;deep learning;convolutional networks;kernel methods,-1;-1;-1,-1;-1;-1,-1;-1,europe,gr,y,1;5;4
2860,ICLR,2019,Prior Networks for Detection of Adversarial Attacks,Andrey Malinin;Mark Gales,am969@cam.ac.uk;mjfg@eng.cam.ac.uk,3;4;4,4;4;5,Reject,4,0,0.0,yes,9/27/18,University of Cambridge;University of Cambridge,Uncertainty;Prior Networks;Adversarial Attacks;Detection,77;77,2;2,-1;-1,europe,uk,n,4
2861,ICLR,2019,A Rate-Distortion Theory of Adversarial Examples,Angus Galloway;Anna Golubeva;Graham W. Taylor,gallowaa@uoguelph.ca;agolubeva@perimeterinstitute.ca;gwtaylor@uoguelph.ca,4;3;2,4;3;3,Reject,0,1,0.0,yes,9/27/18,University of Guelph;Perimeter Institute;University of Guelph,adversarial examples;information bottleneck;robustness,285;-1;285,-1;-1;-1,-1;-1,canada,ca,n,1;4
2862,ICLR,2019,Generalization and Regularization in DQN,Jesse Farebrother;Marlos C. Machado;Michael Bowling,jfarebro@ualberta.ca;machado@ualberta.ca;mbowling@ualberta.ca,6;5;5,3;5;5,Reject,0,3,0.0,yes,9/27/18,University of Alberta;University of Alberta;University of Alberta,generalization;reinforcement learning;dqn;regularization;transfer learning;multitask,94;94;94,119;119;119,-1;-1,canada,ca,n,1
2863,ICLR,2019,Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations,Ozsel Kilinc;Giovanni Montana,ozsel.kilinc@warwick.ac.uk;g.montana@warwick.ac.uk,6;7;3,3;2;4,Reject,0,9,0.0,yes,9/27/18,The university of Warwick;The university of Warwick,Reinforcement learning;multi-agent;hierarchical;noisy observation;partial observability;deep learning,-1;-1,90;90,-1;-1,NAN,NAN,n,
2864,ICLR,2019,Characterizing Attacks on Deep Reinforcement Learning,Chaowei Xiao;Xinlei Pan;Warren He;Bo Li;Jian Peng;Mingjie Sun;Jinfeng Yi;Mingyan Liu;Dawn Song.,xiaocw@umich.edu;xinleipan@berkeley.edu;_w@eecs.berkeley.edu;lxbosky@gmail.com;jianpeng@illinois.edu;sunmj15@mails.tsinghua.com;jinfengyi.ustc@gmail.com;mingyan@umich.edu;dawnsong@gmail.com,5;6;5,4;3;4,Reject,0,8,3.0,yes,9/27/18,"University of Michigan;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Illinois, Urbana Champaign;Mails.tsinghua;JD AI Research;University of Michigan;University of California Berkeley",,9;-1;-1;-1;-1;-1;-1;9;-1,21;18;18;18;-1;-1;-1;21;18,-1;-1,usa,usa,n,4
2865,ICLR,2019,Dopamine: A Research Framework for Deep Reinforcement Learning,Pablo Samuel Castro;Subhodeep Moitra;Carles Gelada;Saurabh Kumar;Marc G. Bellemare,psc@google.com;smoitra@google.com;cgel@google.com;kumasaurabh@google.com;bellemare@google.com,3;3;3,4;2;3,Reject,0,2,0.0,yes,9/27/18,Google;Google;Google;Google;Google,reinforcement learning;software;framework;reproducibility,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2866,ICLR,2019,Probabilistic Program Induction for Intuitive Physics Game Play,Fahad Alhasoun,fha@mit.edu,3;4;2,4;2;4,Reject,0,0,0.0,yes,9/27/18,Massachusetts Institute of Technology,intuitive physics;probabilistic programming;computational cognitive science;probabilistic models,6,5,-1,usa,usa,n,
2867,ICLR,2019,Hallucinations in Neural Machine Translation,Katherine Lee;Orhan Firat;Ashish Agarwal;Clara Fannjiang;David Sussillo,katherinelee@google.com;orhanf@google.com;agarwal@google.com;clarafy@berkeley.edu;sussillo@google.com,6;4;7,5;4;4,Reject,0,12,0.0,yes,9/27/18,Google;Google;Google;University of California Berkeley;Google,nmt;translate;dynamics;rnn,-1;-1;-1;-1;-1,-1;-1;-1;18;-1,-1;-1,NAN,NAN,n,8;3
2868,ICLR,2019,On Inductive Biases in Deep Reinforcement Learning,Matteo Hessel;Hado van Hasselt;Joseph Modayil;David Silver,mtthss@google.com;hado@google.com;modayil@google.com;davidsilver@google.com,3;3;7,4;4;2,Reject,0,4,0.0,yes,9/27/18,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,
2869,ICLR,2019,Exponentially Decaying Flows for Optimization in Deep Learning,Mitsuharu Takeori;Kenta Nakamura,takeori.mitsuharu.d5s@jp.nssol.nssmc.com;nakamura.kenta.4n4@jp.nssol.nssmc.com,3;3;2,5;3;5,Withdrawn,0,0,,yes,9/27/18,Center;Center,optimization;deep learning;,94;94,491;491,-1;-1,NAN,NAN,y,1
2870,ICLR,2019,In search of theoretically grounded pruning,Filip Svoboda;Edgar Liberis;Nicholas D. Lane,filip.svoboda@stx.ox.ac.uk;edgar.liberis@chch.ox.ac.uk;nicholas.lane@cs.ox.ac.uk,4;3;5,3;4;3,Withdrawn,0,3,,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,,44;44;44,1;1;1,-1;-1,europe,uk,n,1
2871,ICLR,2019,Structured Content Preservation for Unsupervised Text Style Transfer,Youzhi Tian;Zhiting Hu;Zhou Yu,yztian@ucdavis.edu;zhitingh@cs.cmu.edu;joyu@ucdavis.edu,5;6;4,4;3;5,Withdrawn,0,0,,yes,9/27/18,"University of California, Davis;Carnegie Mellon University;University of California, Davis",Unsupervised text style transfer;,-1;1;-1,54;24;54,-1;-1,usa,usa,n,3
2872,ICLR,2019,Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks,Ahmed Aly;David Weikersdorfer;Claire Delaunay,aaa2cn@virginia.edu;dweikersdorfer@nvidia.com;cdelaunay@nvidia.com,1;1;5,5;5;4,Withdrawn,2,11,,yes,9/27/18,University of Virginia;NVIDIA;NVIDIA,Evolutionary Algorithm;Optimization;MNIST;,59;-1;-1,113;-1;-1,-1;-1,NAN,NAN,n,
2873,ICLR,2019,Bridging HMMs and RNNs through Architectural Transformations,Jan Buys;Yonatan Bisk;Yejin Choi,jbuys@cs.washington.edu;ybisk@yonatanbisk.com;yejin@cs.washington.edu,3;5;5,3;4;4,Withdrawn,0,7,,yes,9/27/18,University of Washington;SK Telecom;University of Washington,rnns;hmms;latent variable models;language modelling;interpretability;sequence modelling;,10;-1;10,25;-1;25,-1;-1,usa,usa,n,3
2874,ICLR,2019,Learning with Little Data: Evaluation of Deep Learning Algorithms,Andreas Look;Stefan Riedelbauch,andreas.look@ihs.uni-stuttgart.de;stefan.riedelbauch@ihs.uni-stuttgart.de,6;4;4,4;3;5,Withdrawn,0,3,,yes,9/27/18,University of Stuttgart;University of Stuttgart,semi-supervised learning;generative models;few shot learning;,116;116,219;219,-1;-1,europe,de,n,6;1;5;4
2875,ICLR,2019,Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games ,Huazhe Xu;Keiran Paster;Qibin Chen;Haoran Tang;Pieter Abbeel;Trevor Darrell;Sergey Levine,huazhe_xu@berkeley.edu;keirp@berkeley.edu;cqb@tsinghua.edu.cn;hrtang@math.berkeley.edu;pabbeel@cs.berkeley.edu;trevor@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,3;2;2,3;4;3,Withdrawn,0,0,,yes,9/27/18,"University of California Berkeley;University of California Berkeley;Tsinghua University, Tsinghua University;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley",deep reinforcement learning;self-play;real-time strategic game;multi-agent;,-1;-1;4;-1;-1;-1;-1,18;18;30;18;18;18;18,-1;-1,usa,usa,n,
2876,ICLR,2019,Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?,Ali Shafahi;Amin Ghiasi;Furong Huang;Tom Goldstein,ashafahi@cs.umd.edu;amin@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,7;4;2,5;3;5,Withdrawn,13,9,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",adversarial machine learning;machine learning security;,12;12;12;12,69;69;69;69,-1;-1,usa,usa,n,4
2877,ICLR,2019,Rotation Equivariant Networks via Conic Convolution and the DFT,Benjamin Chidester;Minh N. Do;Jian Ma,bchidest@andrew.cmu.edu;minhdo@illinois.edu;jianma@cs.cmu.edu,4;7;6,4;2;3,Withdrawn,0,1,,yes,9/27/18,"Carnegie Mellon University;University of Illinois, Urbana Champaign;Carnegie Mellon University",deep learning;rotation equivariance;bioimaging analysis;,1;-1;1,24;-1;24,-1;-1,usa,usa,n,
2878,ICLR,2019,GradMix: Multi-source Transfer across Domains and Tasks,Junnan Li;Ziwei Xu;Yongkang Wong;Qi Zhao;Mohan S. Kankanhalli,lijunnan@u.nus.edu;ziwei-xu@comp.nus.edu.sg;yongkang.wong@nus.edu.sg;qzhao@cs.umn.edu;mohan@comp.nus.edu.sg,3;5;3,5;4;5,Withdrawn,0,4,,yes,9/27/18,"National University of Singapore;National University of Singapore;National University of Singapore;University of Minnesota, Minneapolis;National University of Singapore",Transfer Learning;Domain Adaptation;Multi-source Learning;,18;18;18;67;18,22;22;22;56;22,-1;-1,asia,sg,n,6;2
2879,ICLR,2019,Understanding and Improving Sequence-Labeling NER with Self-Attentive LSTMs,Peng-Hsuan Li;Wei-Yun Ma,jacobvsdanniel@iis.sinica.edu.tw;ma@iis.sinica.edu.tw,4;3;3,4;5;4,Withdrawn,0,4,,yes,9/27/18,Academia Sinica;Academia Sinica,interpretability;sequence labeling;named entity recognition;LSTM;attention;,-1;-1,-1;-1,-1;-1,NAN,NAN,n,8
2880,ICLR,2019,Differentiable Greedy Networks,Thomas Powers;Rasool Fakoor;Siamak Shakeri;Abhinav Sethy;Amanjit Kainth;Abdel-rahman Mohamed;Ruhi Sarikaya,tcpowers@uw.edu;rasool.fakoor@mavs.uta.edu;siamaks@amazon.com;sethya@amazon.com;amanjitsingh.kainth@mail.utoronto.ca;asamir@cs.toronto.edu;rsarikay@amazon.com,5;2;4,4;5;4,Withdrawn,0,4,,yes,9/27/18,"University of Washington, Seattle;University of Texas, Arlington;Amazon;Amazon;Toronto University;University of Toronto;Amazon",submodular optimization;fact verification;differentiable module;deep unfolding;,10;-1;-1;-1;-1;18;-1,25;-1;-1;-1;-1;22;-1,-1;-1,NAN,NAN,n,10
2881,ICLR,2019,Efficient Federated Learning via Variational Dropout,Wei Du;Xiao Zeng;Ming Yan;Mi Zhang,duwei1@msu.edu;zengxia6@msu.edu;myan@msu.edu;mizhang@msu.edu,4;4;3,4;3;4,Withdrawn,0,1,,yes,9/27/18,Michigan State University;Michigan State University;Michigan State University;Michigan State University,federated learning;communication efficient;variational dropout;sparse model;,116;116;116;116,84;84;84;84,-1;-1,usa,usa,n,8
2882,ICLR,2019,Applications of Gaussian Processes in Finance,Rajbir S. Nirwan;Nils Bertschinger,nirwan@fias.uni-frankfurt.de;bertschinger@fias.uni-frankfurt.de,4;5;3,5;4;4,Withdrawn,0,2,,yes,9/27/18,Goethe University;Goethe University,Gaussian Processes;Latent Variable Model;Variational Bayes;Stan;Asset Pricing;Portfolio Allocation;Finance;CAPM;,285;285,293;293,-1;-1,NAN,NAN,n,11
2883,ICLR,2019,An Attention-Based Model for Learning Dynamic Interaction Networks,Sandro Cavallari;Vincent W Zheng;Hongyun Cai;Erik Cambria,sandro001@e.ntu.edu.sg;vincent.zheng@adsc-create.edu.sg;hongyun.c@adsc.com.sg;cambria@ntu.edu.sg,4;3;4,3;5;4,Withdrawn,0,0,,yes,9/27/18,Nanyang Technological University;ADSC;Advanced Digital Sciences Center;Nanyang Technological University,dynamic networks;interaction graphs;attention model;,44;-1;-1;44,52;-1;-1;52,-1;-1,asia,sg,n,8;10
2884,ICLR,2019,Modeling Evolution of Language Through Time with Neural Networks,Edouard Delasalles;Sylvain Lamprier;Ludovic Denoyer,edouard.delasalles@lip6.fr;sylvain.lamprier@lip6.fr;ludovic.denoyer@lip6.fr,3;4;4,5;5;4,Withdrawn,0,0,,yes,9/27/18,LIP6;LIP6;LIP6,language modeling;variational inference;dynamic model;temporal data;deep learning;,419;419;419,-1;-1;-1,-1;-1,asia,ir,n,3
2885,ICLR,2019,Knowledge Representation for Reinforcement Learning using General Value Functions,Gheorghe Comanici;Doina Precup;Andre Barreto;Daniel Kenji Toyama;Eser Ayg√ºn;Philippe Hamel;Sasha Vezhnevets;Shaobo Hou;Shibl Mourad,gcomanici@google.com;doinap@google.com;andrebarreto@google.com;kenjitoyama@google.com;eser@google.com;hamelphi@google.com;vezhnick@google.com;shaobohou@google.com;shibl@google.com,6;7;4,3;3;4,Withdrawn,0,0,,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google,Reinforcement Learning;General Value Functions;Policy Gradient;Hierarchical Reinforcement Learning;Successor Features;,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,y,
2886,ICLR,2019,,,vladymyrov@gmail.com,5;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,0,NA;,,,-1,NAN,NAN,pdf miss,
2887,ICLR,2019,Geometric Operator Convolutional Neural Network,Yangling Ma;Yixin Luo;Zhouwang Yang,yangma@mail.ustc.edu.cn;seeing@mail.ustc.edu.cn;yangzw@ustc.edu.cn,2;5;3,5;5;4,Withdrawn,2,0,,yes,9/27/18,University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China,Convolutional Neural Network;Geometric Operator;Image Classification;Theoretical Analysis;,-1;-1;-1,132;132;132,-1;-1,NAN,NAN,n,1;4
2888,ICLR,2019,Online Bellman Residue Minimization via Saddle Point Optimization,Zhuoran Yang;Cheng Zhou;Tong Zhang;Han Liu,zy6@princeton.edu;mikechzhou@tencent.com;tongzhang@tongzhang-ml.org;hanliu.cmu@gmail.com,5;5;4,4;4;4,Withdrawn,0,3,,yes,9/27/18,Princeton University;Tencent AI Lab;Google;Northwestern University,,31;-1;-1;-1,7;-1;-1;-1,-1;-1,asia,in,y,1
2889,ICLR,2019,Dual Importance Weight GAN,Gahye Lee;Seungkyu Lee,waldstein94@gmail.com;seungkyu@khu.ac.kr,4;3;5,4;5;4,Withdrawn,0,0,,yes,9/27/18,Kyung Hee University;Kyung Hee University,,-1;419,-1;407,-1;-1,asia,kr,n,5;4
2890,ICLR,2019,Explainable Adversarial Learning: Implicit Generative Modeling of Random Noise during Training for Adversarial Robustness,Priyadarshini Panda;Kaushik Roy,pandap@purdue.edu;kaushik@purdue.edu,3;5;5,4;4;4,Withdrawn,0,7,,yes,9/27/18,Purdue University;Purdue University,Adversarial Robustness;PCA variance;PCA subspace;Generative Noise Modeling;Adversarial attack;Adversarial Robustness Metric;,24;24,60;60,-1;-1,usa,usa,n,1;5;4
2891,ICLR,2019,Nonlinear Channels Aggregation Networks for Deep Action Recognition,Zhigang Zhu;Hongbing Ji;Wenbo Zhang;Cheng Ouyang,zgzhu_xidian@163.com;hbji@xidian.edu.cn;zwbsoul@163.com;ouoyc@aliyun.com,3;3;3,3;4;5,Withdrawn,0,0,,yes,9/27/18,163;Xidian University;163;Aliyun,action recognition;convolutional neural network;network training;,-1;-1;-1;-1,-1;917;-1;-1,-1;-1,NAN,NAN,n,1
2892,ICLR,2019,A SINGLE SHOT PCA-DRIVEN ANALYSIS OF NETWORK STRUCTURE TO REMOVE REDUNDANCY,Isha Garg;Priyadarshini Panda;Kaushik Roy,gargi@purdue.edu;pandap@purdue.edu;kaushik@purdue.edu,4;4;5,5;4;5,Withdrawn,0,0,,yes,9/27/18,Purdue University;Purdue University;Purdue University,deep learning;model compression;pruning;PCA;,24;24;24,60;60;60,-1;-1,usa,usa,n,2;3
2893,ICLR,2019,D2KE: From Distance to Kernel and Embedding via Random Features For Structured Inputs,Lingfei Wu;Ian E.H. Yen;Fangli Xu;Pradeep Ravikumar;Michael J. Witbrock,lwu@email.wm.edu;eyan@cs.cmu.edu;fxu02@email.wm.edu;pradeepr@cs.cmu.edu;witbrock@us.ibm.com,4;3;5,4;4;4,Withdrawn,0,0,,yes,9/27/18,College of William and Mary;Carnegie Mellon University;College of William and Mary;Carnegie Mellon University;International Business Machines,Distance Kernel;Embeddings;Random Features;Structured Inputs;,207;1;207;1;-1,-1;24;-1;24;-1,-1;-1,NAN,NAN,y,10
2894,ICLR,2019,Latent Transformations for Object  View Points Synthesis,Sangpil Kim;Nick Winovich;Hyung-gun Chi;Guang Lin;Karthik Ramani,kim2030@purdue.edu;nwinovic@purdue.edu;chi45@purdue.edu;guanglin@purdue.edu;ramani@purdue.edu,4;2;5,4;4;2,Withdrawn,0,2,,yes,9/27/18,Purdue University;Purdue University;Purdue University;Purdue University;Purdue University,conditional generative model;deep learning;fully-convolutional network;image attribute modification;multi-view reconstruction;view sythesis;,24;24;24;24;24,60;60;60;60;60,-1;-1,usa,usa,n,5;4
2895,ICLR,2019,Network Reparameterization for Unseen Class Categorization,Kai Li;Martin Renqiang Min;Bing Bai;Yun Fu;Hans Peter Graf,li.kai.gml@gmail.com;renqiang@nec-labs.com;bbai@nec-labs.com;yunfu@ece.neu.edu;hpg@nec-labs.com,5;3;5,5;5;3,Withdrawn,7,2,,yes,9/27/18,Northeastern University;NEC-Labs;NEC-Labs;Northeastern University;NEC-Labs,Unseen class categorization;network reparameterization;few-shot learning;zero-shot learning;,-1;-1;-1;15;-1,-1;-1;-1;839;-1,-1;-1,NAN,NAN,n,6
2896,ICLR,2019,Explaining Neural Networks Semantically and Quantitatively,Hao Chen;Runjin Chen;Quanshi Zhang,bridgechen@hust.edu.cn;chenrunjin@sjtu.edu.cn;zqs1022@sjtu.edu.cn,4;4;4,4;5;4,Withdrawn,0,4,,yes,9/27/18,Hong Kong University of Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Network interpretability;deep learning;knowledge distillation;convolutional neural networks;,-1;36;36,44;188;188,-1;-1,asia,cn,n,
2897,ICLR,2019,Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks,Zenan Ling;Haotian Ma;Yu Yang;Robert C. Qiu;Song-Chun Zhu;Quanshi Zhang,lingzenan@sjtu.edu.cn;11612807@mail.sustc.edu.cn;yy19970901@ucla.edu;rqiu@tntech.edu;sczhu@stat.ucla.edu;zqs1022@sjtu.edu.cn,3;4;4,5;4;5,Withdrawn,1,3,,yes,9/27/18,"Shanghai Jiao Tong University;University of Science and Technology of China;University of California, Los Angeles;Tennessee Technological University;University of California, Los Angeles;Shanghai Jiao Tong University",Interpretability;Deep learning;alphaGo;,36;-1;-1;-1;-1;36,188;132;15;-1;15;188,-1;-1,asia,cn,n,
2898,ICLR,2019,Deepstr√∂m Networks,Luc Giffon;Hachem Kadri;St√©phane Ayache;Thierry Arti√®res,luc.giffon@lis-lab.fr;hachem.kadri@lis-lab.fr;stephane.ayache@lis-lab.fr;thierry.artieres@lis-lab.fr,4;5;3,4;4;5,Withdrawn,0,1,,yes,9/27/18,Aix Marseille Universit√©;Aix Marseille Universit√©;Aix Marseille Universit√©;Aix Marseille Universit√©,kernels;Nystr√∂m approximation;deep convnets;,-1;-1;-1;-1,297;297;297;297,-1;-1,NAN,NAN,n,
2899,ICLR,2019,One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy,Jingkang Wang;Ruoxi Jia;Gerald Friedland;Bo Li;Costas Spanos,wangjksjtu_01@sjtu.edu.cn;ruoxijia@berkeley.edu;fractor@eecs.berkeley.edu;lxbosky@gmail.com;spanos@berkeley.edu,3;3;3,4;4;4,Withdrawn,2,1,,yes,9/27/18,Shanghai Jiao Tong University;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,adversarial examples;information theory;robust neural networks;,36;-1;-1;-1;-1,188;18;18;18;18,-1;-1,usa,usa,y,1;4
2900,ICLR,2019,,,samitha.herath@data61.csiro.au;u5505348@anu.edu.au;mehrtash.harandi@monash.edu,4;3;5,4;4;5,Withdrawn,0,3,,yes,,CSIRO;Australian National University;Monash University,NA;,-1;116;94,-1;48;80,-1,australasia,au,pdf miss,
2901,ICLR,2019,Context-aware Forecasting for Multivariate Stationary Time-series,Valentin Guiguet;Nicolas Baskiotis;Vincent Guigue;Patrick Gallinari,guiguetvalentin@gmail.com;nicolas.baskiotis@lip6.fr;vincent.guigue@lip6.fr;patrick.gallinari@lip6.fr,5;5;4,3;5;4,Withdrawn,0,1,,yes,9/27/18,LIP6;LIP6;LIP6;LIP6,,-1;419;419;419,-1;-1;-1;-1,-1;-1,asia,ir,n,
2902,ICLR,2019,HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING,Raihan Seraj;Negar Ghourchian;Michel Allegue-Martinez,raihan.seraj@mail.mcgill.ca;negar.gh@aerial.ai;michel.allegue@aerial.ai,2;3;4,1;4;4,Withdrawn,0,0,,yes,9/27/18,McGill University;Aerial Technologies Inc.;Aerial Technologies Inc.,concept drift;wifi localization;feature representation.;,94;-1;-1,42;-1;-1,-1;-1,NAN,NAN,n,
2903,ICLR,2019,Transfer Learning for Estimating Causal Effects Using Neural Networks,S√∂ren R. K√ºnzel;Bradly C. Stadie;Nikita Vemuri;Varsha Ramakrishnan;Jasjeet S. Sekhon;Pieter Abbeel,srk@berkeley.edu;bstadie@berkeley.edu;nikitavemuri@berkeley.edu;vio@berkeley.edu;sekhon@berkeley.edu;pabbeel@cs.berkeley.edu,7;5;3,3;4;3,Withdrawn,0,0,,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,machine learning;causal inference;causal neural networks;deep learning;CATE estimation;transfer learning;meta-learning;causal transfer;,-1;-1;-1;-1;-1;-1,18;18;18;18;18;18,-1;-1,usa,usa,n,6
2904,ICLR,2019,Variational Autoencoders for Text Modeling without Weakening the Decoder,Ryo Kamoi;Hiroyasu Fukutomi,ryo_kamoi_st@keio.jp;hiroyasu.fukutomi@datasection.co.jp,4;4;1,3;5;4,Withdrawn,6,1,,yes,9/27/18,Keio University;Meiji University,variational autoencoders;generative model;deep neural network;text modeling;unsupervised learning;multimodal;,285;-1,627;-1,-1;-1,asia,in,n,5
2905,ICLR,2019,A PRIVACY-PRESERVING IMAGE CLASSIFICATION FRAMEWORK WITH A LEARNABLE OBFUSCATOR,Xiangyi Meng;Zixuan Huang;Yuefeng Du;Antoni Chan;Cong Wang,xy.meng@my.cityu.edu.hk;zixuhuang3-c@my.cityu.edu.hk;yf.du@my.cityu.edu.hk;abchan@cityu.edu.hk;congwang@cityu.edu.hk,5;5;5,4;4;5,Withdrawn,2,0,,yes,9/27/18,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,privacy-preserving;image classification;adversarial training;learnable obfuscator;,136;136;136;136;136,182;182;182;182;182,-1;-1,asia,hk,n,4
2906,ICLR,2019,ODIN: Outlier Detection In Neural Networks,Rickard Sj√∂gren;Johan Trygg,rickard.sjoegren@sartorius-stedim.com;johan.trygg@sartorius-stedim.com,5;4;4,4;4;4,Withdrawn,1,4,,yes,9/27/18,Sartorius-stedim;Sartorius-stedim,Outlier Detection;Model Uncertainty;Safety;,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2907,ICLR,2019,Improving latent variable descriptiveness by modelling rather than ad-hoc factors,Alex Mansbridge;Roberto Fierimonte;Ilya Feige;David Barber,amansbridge@turing.ac.uk;roberto.fierimonte@gmail.com;ilya@asidatascience.com;david.barber@ucl.ac.uk,4;4;6,4;4;3,Withdrawn,0,3,,yes,9/27/18,Alan Turing Institute;;Asidatascience;University College London,generative modelling;latent variable modelling;variational autoencoders;variational inference;natural language processing;,-1;-1;-1;50,-1;-1;-1;-1,-1;-1,europe,uk,n,3;1;5
2908,ICLR,2019,Capacity of Deep Neural Networks under Parameter Quantization,Yoonho Boo;Sungho Shin;and Wonyong Sung,dnsgh337@snu.ac.kr;ssh9919@snu.ac.kr;wysung@snu.ac.kr,5;5;5,3;4;3,Withdrawn,0,0,,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University,quantization;network capacity;hardware implementation;network compression;,36;36;36,74;74;74,-1;-1,asia,kr,n,3
2909,ICLR,2019,Learning of Sophisticated Curriculums by viewing them as Graphs over Tasks,Lucas Willems;Yoshua Bengio,lcswillems@gmail.com;yoshua.bengio@umontreal.ca,3;2;4,1;2;4,Withdrawn,0,3,,yes,9/27/18,Ecole Normale Supérieure de Paris;University of Montreal,learning;curriculum learning;reinforcement learning;,-1;116,-1;108,-1;-1,canada,ca,n,
2910,ICLR,2019,RNNs with Private and Shared Representations for Semi-Supervised Sequence Learning,Ge Ya Luo;Jie Fu;Pengfei Liu;Zhi Hao Luo;Chris Pal,olga.xu@umontreal.ca;jie.fu@polymtl.ca;pfliu14@fudan.edu.cn;zhi-hao.luo@polymtl.ca;christopher.pal@polymtl.ca,3;5;4,5;5;4,Withdrawn,0,3,,yes,9/27/18,University of Montreal;Polytechnique Montreal;Fudan University;Polytechnique Montreal;Polytechnique Montreal,recurrent neural network;semi-supervised learning;,116;285;67;285;285,108;-1;116;-1;-1,-1;-1,canada,ca,n,
2911,ICLR,2019,MAJOR-MINOR LSTMS FOR WORD-LEVEL LANGUAGE MODEL,Kai Shuang;Rui Li;Mengyu Gu;Qianqian Yang;Jonathan;Sen Su,shuangk@bupt.edu.cn;lirui@bupt.edu.cn;pattygu0622@bupt.edu.cn;echo_yang@bupt.edu.cn;jonathan.loo@uwl.ac.uk;susen@bupt.edu.cn,4;3;3,5;4;5,Withdrawn,2,4,,yes,9/27/18,Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;;Beijing University of Post and Telecommunication,Language model;LSTM;Deep Learning;NLP;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;3
2912,ICLR,2019,SALSA-TEXT : SELF ATTENTIVE LATENT SPACE BASED ADVERSARIAL TEXT GENERATION,Jules Gagnon-Marchand;Hamed Sadeghi;Mehdi Rezagholizadeh;Md. Akmal Haider,jgagnonmarchand@gmail.com;haamed.sadeghi@gmail.com;mehdi.rezagholizadeh@gmail.com;md.akmal.haidar@huawei.com,4;4;5,3;4;4,Withdrawn,0,0,,yes,9/27/18,Huawei Technologies Ltd.;;;Huawei Technologies Ltd.,Self-attention;Transformer;generative adversarial networks;GAN;neural text generation;NTG;generative models;,-1;-1;-1;-1,-1;-1;-1;-1,-1;-1,NAN,NAN,n,8;5;4
2913,ICLR,2019,,Qingpeng Cai;Ling Pan;Pingzhong Tang,cqpcurry@gmail.com;penny.ling.pan@gmail.com;kenshinping@gmail.com,4;5;1,4;3;4,Withdrawn,0,2,,yes,,"Alibaba Group;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",NA;,-1;4;4,-1;30;30,-1;-1,NAN,NAN,pdf miss,
2914,ICLR,2019,Neuron Hierarchical Networks,Han Yue;De-An Wu;Lei Wu;Ji Xie,johnhany@163.com;wudean.cn@uestc.edu.cn;wulei@uestc.edu.cn;zonghengxs@163.com,5;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,163;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;163,neural network;architecture search;evolution strategy;,-1;-1;-1;-1,-1;843;843;-1,-1;-1,asia,in,n,10
2915,ICLR,2019,Linearizing Visual Processes with Deep Generative Models,Alexander Sagel;Hao Shen,a.sagel@tum.de;shen@fortiss.org,3;3;4,4;4;3,Withdrawn,0,3,,yes,9/27/18,Technical University Munich;Fortiss,Genearative Adversarial Network;Variational Autoencoder;Wasserstein GAN;Autoregressive Model;Dynamic Texture;Video;,-1;-1,-1;-1,-1;-1,NAN,NAN,y,5;4
2916,ICLR,2019,Inhibited Softmax for Uncertainty Estimation in Neural Networks,Marcin Mo≈ºejko;Mateusz Susik;Rafa≈Ç Karczewski,marcin@sigmoidal.io;msusik@sigmoidal.io;rafal@sigmoidal.io,4;4;3,4;3;4,Withdrawn,0,1,,yes,9/27/18,University of Warsaw;;Sigmoidal,uncertainty  estimation;out-of-distribution detection;inhibited softmax;,-1;-1;-1,-1;-1;-1,-1;-1,asia,in,n,
2917,ICLR,2019,Improving Gaussian mixture latent variable model convergence with Optimal Transport,Benoit Gaujac;Ilya Feige;David Barber,benoit.gaujac.16@ucl.ac.uk;ilya@asidatascience.com;david.barber@ucl.ac.uk,5;5;5,3;4;4,Withdrawn,0,3,,yes,9/27/18,University College London;Asidatascience;University College London,optimal transport;wasserstein autoencoder;variational autoencoder;latent variable modeling;generative modeling;discrete latent variables;,50;-1;50,-1;-1;-1,-1;-1,europe,uk,n,5
2918,ICLR,2019,From Amortised to Memoised Inference: Combining Wake-Sleep and Variational-Bayes for Unsupervised Few-Shot Program Learning,Luke B. Hewitt;Joshua B. Tenenbaum,lbh@mit.edu;jbt@mit.edu,3;3;3,5;5;4,Withdrawn,0,1,,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,wake-sleep;variational;amortised inference;hierarchical bayes;program learning;,6;6,5;5,-1;-1,usa,usa,n,11;5
2919,ICLR,2019,,,v-ziclin@microsoft.com;lizo@microsoft.com,6;2;4,2;5;3,Withdrawn,3,0,,yes,,Microsoft;Microsoft,NA;,-1;-1,-1;-1,-1,NAN,NAN,pdf miss,
2920,ICLR,2019,Encoder Discriminator Networks for Unsupervised Representation Learning,Nils Wandel,nils.wandel@ais.uni-bonn.de,3;4;3,4;4;5,Withdrawn,0,4,,yes,9/27/18,University of Bonn,representation learning;unsupervised;encoder discriminator;,136,100,-1,europe,uk,n,
2921,ICLR,2019,Geometry of Deep Convolutional Networks,Stefan Carlsson,stefanc@kth.se,2;4;3,5;4;2,Withdrawn,0,0,,yes,9/27/18,"KTH Royal Institute of Technology, Stockholm, Sweden",convolutional networks;geometry;,207,173,-1,NAN,NAN,n,
2922,ICLR,2019,Learning and Data Selection in Big Datasets,Hossein S. Ghadikolaei;Hadi Ghauch;Carlo Fischione;Mikael Skoglund,hshokri@kth.se;ghauch@kth.se;carlofi@kth.se;skoglund@kth.se,4;3;3,3;4;5,Withdrawn,0,0,,yes,9/27/18,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",Data selection;non-convex optimization;learning theory;active learning;,207;207;207;207,173;173;173;173,-1;-1,NAN,NAN,y,1
2923,ICLR,2019,Data Poisoning Attack against Unsupervised Node Embedding Methods,Mingjie Sun;Jian Tang;Huichen Li;Bo Li;Chaowei Xiao;Yao Chen;Dawn Song,sunmj15@gmail.com;tangjianpku@gmail.com;huichen3@illinois.edu;lxbosky@gmail.com;xiaocw@umich.edu;antoniechen@tencent.com;dawnsong@gmail.com,4;4;4,5;4;3,Withdrawn,0,0,,yes,9/27/18,"Carnegie Mellon University;HEC Montreal;University of Illinois, Urbana Champaign;University of California Berkeley;University of Michigan;Tencent AI Lab;University of California Berkeley",,-1;-1;-1;-1;9;-1;-1,-1;-1;-1;18;21;-1;18,-1;-1,usa,usa,n,10;4
2924,ICLR,2019,Shaping representations through communication,Olivier Tieleman;Angeliki Lazaridou;Shibl Mourad;Charles Blundell;Doina Precup,tieleman@google.com;angeliki@google.com;shibl@google.com;cblundell@google.com;doinap@google.com,5;4;5,4;4;4,Withdrawn,0,1,,yes,9/27/18,Google;Google;Google;Google;Google,communication;language;representation learning;autoencoders;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6
2925,ICLR,2019,,,hongyang.gao@wsu.edu,5;4;4,4;5;4,Withdrawn,6,3,,yes,9/27/18,SUN YAT-SEN UNIVERSITY,NA;,-1,352,-1,NAN,NAN,pdf miss,
2926,ICLR,2019,,,na@na.edu,3;5;5,4;4;4,Withdrawn,0,3,,yes,,University of Arizona,NA;,207,161,-1,usa,usa,pdf miss,
2927,ICLR,2019,Exploiting Invariant Structures for Compression in Neural Networks,Jiahao Su;Jingling Li;Bobby Bhattacharjee;Furong Huang,jiahaosu@terpmail.umd.edu;jingling@cs.umd.edu;bobby@cs.umd.edu;furongh@cs.umd.edu,4;4;4,4;4;4,Withdrawn,0,1,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",Neural Network Compression;Low Rank Approximation;Higher Order Tensor Decomposition;,12;12;12;12,69;69;69;69,-1;-1,usa,usa,n,9
2928,ICLR,2019,Evading Defenses to Transferable Adversarial Examples by Mitigating Attention Shift,Yinpeng Dong;Tianyu Pang;Hang Su;Jun Zhu,dyp17@mails.tsinghua.edu.cn;pty17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,4;4;4,3;4;3,Withdrawn,0,5,,yes,9/27/18,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",adversarial examples;black-box attack;transferability;,4;4;4;4,30;30;30;30,-1;-1,NAN,NAN,n,8;4
2929,ICLR,2019,Classification of Building Noise Type/Position via Supervised Learning,Hwiyong Choi;Haesang Yang;Seungjun Lee;Woojae Seong,its_me_chy@snu.ac.kr;coupon3@snu.ac.kr;tl7qns7ch@snu.ac.kr;wseong@snu.ac.kr,4;4;4,2;4;4,Withdrawn,0,0,,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University;Seoul National University,impact noise;noise type classification;noise position classification;convolutional neural networks;transfer learning;,36;36;36;36,74;74;74;74,-1;-1,asia,kr,n,
2930,ICLR,2019,Nesterov's method is the discretization of a differential equation with Hessian damping,Adam M. Oberman;Maxime Laborde,adam.oberman@mcgill.ca;maxime.laborde@mcgill.ca,4;5;6,5;4;5,Withdrawn,5,0,,yes,9/27/18,McGill University;McGill University,Nesterov's method;convex optimization;first-order methods;stochastic gradient descent;differential equations;Liapunov's method;,94;94,42;42,-1;-1,canada,ca,y,1
2931,ICLR,2019,"A Forensic Representation to Detect Non-Trivial Image Duplicates, and How it Applies to Semantic Segmentation",M. Cicconet;H. Elliott;D.L. Richmond;D. Wainstock;M. Walsh,cicconet@gmail.com;elliott.hunter@gmail.com;daverichmond@gmail.com;daniel_wainstock@hms.harvard.edu;mary_walsh@hms.harvard.edu,4;3;2,4;5;5,Withdrawn,0,0,,yes,9/27/18,Harvard University;;;Harvard University;Harvard University,metric learning;image similarity;image forensics;siamese network;semantic segmentation;,50;-1;-1;50;50,6;-1;-1;6;6,-1;-1,usa,usa,n,2
2932,ICLR,2019,End-to-end Learning of a Convolutional Neural Network via Deep Tensor Decomposition,Samet Oymak;Mahdi Soltanolkotabi,sametoymak@gmail.com;soltanol@usc.edu,5;5;5,3;3;3,Withdrawn,0,0,,yes,9/27/18,"University of California, Riverside;University of Southern California",convolutional neural network;tensor decomposition;sample complexity;approximation;,-1;27,197;66,-1;-1,usa,usa,y,
2933,ICLR,2019,Domain Adaptive Transfer Learning,Jiquan Ngiam;Daiyi Peng;Vijay Vasudevan;Simon Kornblith;Quoc Le;Ruoming Pang,jngiam@google.com;daiyip@google.com;vrv@google.com;skornblith@google.com;qvl@google.com;rpang@google.com,3;4;7,5;4;4,Withdrawn,0,3,,yes,9/27/18,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,6;2
2934,ICLR,2019,Deep clustering based on a mixture of autoencoders,Shlomo E. Chazan;Sharon Gannot;Jacob Goldberger,shlomi.chazan@biu.ac.il;sharon.gannot@biu.ac.il;jacob.goldberger@biu.ac.il,6;4;5,3;3;5,Withdrawn,0,1,,yes,9/27/18,Bar Ilan University;Bar Ilan University;Bar Ilan University,deep clustering;mixture of experts;mixture of autoencoders;,94;94;94,456;456;456,-1;-1,europe,il,n,
2935,ICLR,2019,Live Face De-Identification in Video,Oran Gafni;Lior Wolf;Yaniv Taigman,oran@fb.com;wolf@fb.com;yaniv@fb.com,6;4;6,4;4;4,Withdrawn,0,4,,yes,9/27/18,Facebook;Facebook;Facebook,,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2936,ICLR,2019,IMAGE DEFORMATION META-NETWORK FOR ONE-SHOT LEARNING,Zitian Chen;Yanwei Fu;Yu-Xiong Wang;Lin Ma;Wei Liu;Martial Hebert,tankche2@gmail.com;yanweifu@fudan.edu.cn;yuxiongw@cs.cmu.edu;forest.linma@gmail.com;wl2223@columbia.edu;hebert@ri.cmu.edu,5;7;6,4;1;4,Withdrawn,0,3,,yes,9/27/18,"University of Massachusetts, Amherst;Fudan University;Carnegie Mellon University;;Columbia University;Carnegie Mellon University",,-1;67;1;-1;21;1,-1;116;24;-1;14;24,-1;-1,usa,usa,n,6
2937,ICLR,2019,Towards Resisting Large Data Variations via Introspective Learning,Yunhan Zhao;Ye Tian;Wei Shen;Alan Yuille,yzhao83@jhu.edu;tytian@outlook.com;shenwei1231@gmail.com;alan.l.yuille@gmail.com,4;5;6,4;4;3,Withdrawn,0,7,,yes,9/27/18,Johns Hopkins University;;Shanghai Jiao Tong University;Johns Hopkins University,Introspective learning;Large variations resistance;Image classification;Generative models;,67;-1;36;67,13;-1;188;13,-1;-1,usa,usa,n,5
2938,ICLR,2019,Realistic Adversarial Examples in 3D Meshes,Chaowei Xiao;Dawei Yang;Bo Li;Jia Deng;Mingyan Liu,xiaocw@umich.edu;ydawei@umich.edu;lxbosky@gmail.com;jiadeng@cs.princeton.edu;mingyan@umich.edu,5;3;5,3;3;3,Withdrawn,0,0,,yes,9/27/18,University of Michigan;University of Michigan;University of California Berkeley;Princeton University;University of Michigan,,9;9;-1;31;9,21;21;18;7;21,-1;-1,usa,usa,n,4
2939,ICLR,2019,Representation Flow for Action Recognition,AJ Piergiovanni;Michael S. Ryoo,ajpiergi@indiana.edu;mryoo@indiana.edu,3;5;5,5;5;4,Withdrawn,2,10,,yes,9/27/18,Indiana University;Indiana University,,67;67,117;117,-1;-1,usa,usa,n,
2940,ICLR,2019,PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention,Yongbin Sun;Yue Wang;Ziwei Liu;Joshua E. Siegel;Sanjay Sarma,yb_sun@mit.edu;yuewang@csail.mit.edu;zwliu.hust@gmail.com;j_siegel@mit.edu;sesarma@mit.edu,3;6;6,4;4;5,Withdrawn,0,0,,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Nanyang Technological University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,point cloud generation;autoregressive models;self-attention;,6;6;44;6;6,5;5;52;5;5,-1;-1,usa,usa,n,8
2941,ICLR,2019,Stacked U-Nets: A No-Frills Approach to Natural Image Segmentation,Sohil Shah;Pallabi Ghosh;Larry S Davis;Tom Goldstein,sohilas@umd.edu;tomg@cs.umd.edu;pallabig@umd.edu;lsd@umiacs.umd.edu,5;3;5,5;5;5,Withdrawn,0,1,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",semantic segmentation;stacked u-nets;classification;,12;12;12;12,69;69;69;69,-1;-1,usa,usa,n,2
2942,ICLR,2019,UNSUPERVISED CONVOLUTIONAL NEURAL NETWORKS FOR ACCURATE VIDEO FRAME INTERPOLATION WITH INTEGRATION OF MOTION COMPONENTS,Thang Van Nguyen;Kyu-Joong Lee;Hyuk-Jae Lee,itmanhieu@snu.ac.kr;kyujoonglee@sunmoon.ac.kr;hjlee@capp.snu.ac.kr,3;5;4,4;4;5,Withdrawn,0,0,,yes,9/27/18,Seoul National University;Kyung Hee;Seoul National University,Frame Interpolation;Frame Rate Up Conversion;Convolutional Neural Networks;CNN;Unsupervised learning;,36;419;36,74;407;74,-1;-1,asia,kr,n,10
2943,ICLR,2019,Compositional GAN: Learning Conditional Image Composition,Samaneh Azadi;Deepak Pathak;Sayna Ebrahimi;Trevor Darrell,sazadi@berkeley.edu;pathak@berkeley.edu;sayna@berkeley.edu;trevor@eecs.berkeley.edu,4;4;5,5;4;4,Withdrawn,0,5,,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Image Composition;GAN;Conditional Image generation;,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,5;4
2944,ICLR,2019,PolyCNN: Learning Seed Convolutional Filters,Felix Juefei-Xu;Vishnu Naresh Boddeti;Marios Savvides,juefei.xu@gmail.com;vishnu@msu.edu;msavvide@ri.cmu.edu,3;4;4,4;2;3,Withdrawn,0,0,,yes,9/27/18,Alibaba Group;Michigan State University;Carnegie Mellon University,Efficient CNN;Seed convolutional filter;,-1;116;1,-1;84;24,-1;-1,usa,usa,n,
2945,ICLR,2019,A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks,Yinghao Xu;Xin Dong;Yudian Li;Hao Su,justimyhxu@zju.edu.cn;xindong@g.harvard.edu;daniellee2519@gmail.com;haosu@eng.ucsd.edu,5,4,Withdrawn,0,0,,yes,9/27/18,"Zhejiang University;Harvard University;;University of California, San Diego",efficient machine learningÔºåbinary neural network;,36;50;-1;-1,177;6;-1;31,-1;-1,usa,usa,n,
2946,ICLR,2019,A Teacher Student Network For Faster Video Classification,Shweta Bhardwaj;Mukundhan Srinivasan;Mitesh M. Khapra,cs16s003@cse.iitm.ac.in;msrinivasan@nvidia.com;miteshk@cse.iitm.ac.in,4;4;4,4;5;5,Withdrawn,0,0,,yes,9/27/18,Indian Institute of Technology Madras;NVIDIA;Indian Institute of Technology Madras,video classification;efficient computation;knowledge distillation;teacher-student;,-1;-1;-1,625;-1;625,-1;-1,NAN,NAN,n,8
2947,ICLR,2019,Data Interpretation and Reasoning Over Scientific Plots,Pritha Ganguly;Nitesh Methani;Mitesh M. Khapra,prithag@cse.iitm.ac.in;nmethani@cse.iitm.ac.in,6;6;3,4;4;4,Withdrawn,0,0,,yes,9/27/18,Indian Institute of Technology Madras;Indian Institute of Technology Madras,VQA;Data Interpretation;Parsing;Object Detection;,-1;-1,625;625,-1;-1,NAN,NAN,n,10
2948,ICLR,2019,Logit Regularization Methods for Adversarial Robustness,Cecilia Summers;Michael J. Dinneen,ceciliasummers07@gmail.com;mjd@cs.auckland.ac.nz,3;5;2,5;5;5,Withdrawn,10,5,,yes,9/27/18,University of Auckland;University of Auckland,adversarial;,285;285,191;191,f;m,australasia,nz,n,4
2949,ICLR,2019,Feature Matters: A Stage-by-Stage Approach for Task Independent Knowledge Transfer,Mengya Gao;Yujun Shen;Quanquan Li;Liang Wan;Xiaoou Tang,daisy@tju.edu.cn;sy116@ie.cuhk.edu.hk;liquanquan@sensetime.com;lwan@tju.edu.cn;xtang@ie.cuhk.edu.hk,5;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,Zhejiang University;The Chinese University of Hong Kong;SenseTime Group Limited;Zhejiang University;The Chinese University of Hong Kong,knowledge transfer;task independent;feature transfer;stage-by-stage;,36;285;-1;36;285,177;40;-1;177;40,-1;-1,NAN,NAN,n,
2950,ICLR,2019,Parametrizing Fully Convolutional Nets with a Single High-Order Tensor,Jean Kossaifi;Adrian Bulat;Georgios Tzimiropoulos;Maja Pantic,jean.kossaifi@gmail.com;bulat.adrian@gmail.com;yorgos.tzimiropoulos@nottingham.ac.uk;maja.pantic@gmail.com,4;3;4,4;4;5,Withdrawn,0,4,,yes,9/27/18,NVIDIA;Samsung;University of Nottingham;Imperial College London,,-1;-1;207;47,-1;-1;146;8,-1;-1,europe,uk,n,2
2951,ICLR,2019,Associate Normalization,Song-Hao Jia;Ding-Jie Chen;Hwann-Tzong Chen,gasoonjia@icloud.com;djchen.tw@gmail.com;htchen@cs.nthu.edu.tw,3;5;2,5;4;5,Withdrawn,0,0,,yes,9/27/18,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University,,207;207;207,323;323;323,-1;-1,asia,tw,n,
2952,ICLR,2019,Online abstraction with MDP homomorphisms for Deep Learning,Ondrej Biza;Robert Platt,bizaondr@fit.cvut.cz;rplatt@ccs.neu.edu,4;5,3;3,Withdrawn,0,0,,yes,9/27/18,Czech Technical University in Prague;Northeastern University,reinforcement learning;abstraction;mdp homomorphism;deep learning;robotics;,169;15,740;839,-1;-1,usa,usa,n,
2953,ICLR,2019,Generalized Label Propagation Methods for Semi-Supervised Learning,Qimai Li;Xiao-Ming Wu;Zhichao Guan.,csqmli@comp.polyu.edu.hk;xiao-ming.wu@polyu.edu.hk;zcguan@zju.edu.cn,4;3;6,4;4;5,Withdrawn,2,3,,yes,9/27/18,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Zhejiang University,semi-supervised learning;label propagation;graph convolutional networks;,136;136;36,182;182;177,-1;-1,asia,cn,n,10
2954,ICLR,2019,Rethinking Knowledge Graph Propagation for Zero-Shot Learning,Michael Kampffmeyer;Yinbo Chen;Xiaodan Liang;Hao Wang;Yujia Zhang;Eric P. Xing,michael.c.kampffmeyer@uit.no;cyvius96@gmail.com;xdliang328@gmail.com;hwang87@mit.edu;zhangyujia2014@ia.ac.cn;epxing@cs.cmu.edu,7;5;5,4;3;4,Withdrawn,0,3,,yes,9/27/18,"UiT The Arctic University of Norway;;;Massachusetts Institute of Technology;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Carnegie Mellon University",Dense graph propagation;zero-shot learning;,-1;-1;-1;6;31;1,467;-1;-1;5;-1;24,-1;-1,usa,usa,n,6;1;10
2955,ICLR,2019,A Unified View of Deep Metric Learning via Gradient Analysis,Xun Wang;Xintong Han;Weilin Huang;Dengke Dong;Matthew R. Scott,xunwang@malong.com;xinhan@malong.com;whuang@malong.com,3;6;5,4;4;4,Withdrawn,2,3,,yes,9/27/18,Malong Technologies;Malong Technologies;Malong Technologies,metric learning;gradient equivalence;image retrieval;,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n,
2956,ICLR,2019,Learning Spatio-Temporal Representations Using Spike-Based Backpropagation,Deboleena Roy;Priyadarshini Panda;Kaushik Roy,roy77@purdue.edu;pandap@purdue.edu;kaushik@purdue.edu,3;4;3,5;5;4,Withdrawn,0,0,,yes,9/27/18,Purdue University;Purdue University;Purdue University,spiking neural networks;autoencoders;representation learning;backpropagation;multimodal;,24;24;24,60;60;60,-1;-1,usa,usa,n,5
2957,ICLR,2019,withdrawn,withdrawn,aaron.chadha.14@ucl.ac.uk;i.andreopoulos@ucl.ac.uk,4;4;3,5;4;5,Withdrawn,0,0,,yes,9/27/18,University College London;University College London,,50;50,-1;-1,-1,europe,uk,pdf miss,
2958,ICLR,2019,Cosine similarity-based Adversarial process,Hee-Soo Heo;Hye-Jin Shim;Jee-Weon Jung;IL-Ho Yang;Sung-Hyun Yoon;Ha-Jin Yu,zhasgone@naver.com;shimhyejin930615@gmail.com;aberforth19@naver.com;heisco@hanmail.net;ysh901108@naver.com;hjyu@uos.ac.kr,4;3;5,3;5;4,Withdrawn,0,0,,yes,9/27/18,University of Seoul;;Naver;;Naver;University of Seoul,adversarial process;cosine similarity;speaker identification;domain adaptation;,-1;-1;-1;-1;-1;-1,798;-1;-1;-1;-1;798,-1;-1,NAN,NAN,n,4
2959,ICLR,2019,Low-Cost Parameterizations of Deep Convolutional Neural Networks,Eran Treister;Lars Ruthotto;Michal Sharoni;Sapir Zafrani;Eldad Haber,erant@bgu.ac.il;lruthotto@emory.edu;sharmic@post.bgu.ac.il;sapirza@post.bgu.ac.il;ehaber@eos.ubc.ca,4;4;5,3;4;5,Withdrawn,0,0,,yes,9/27/18,Ben Gurion University of the Negev;Emory University;Ben Gurion University of the Negev;Ben Gurion University of the Negev;University of British Columbia,Deep Learning;Classification;Partial Differential Equations;,169;207;169;169;59,627;98;627;627;34,-1;-1,canada,ca,n,
2960,ICLR,2019,Engaging Image Captioning Via Personality,Kurt Shuster;Samuel Humeau;Hexiang Hu;Antoine Bordes;Jason Weston,kshuster@fb.com;samuelhumeau@fb.com;hexianghu@fb.com;abordes@fb.com;jaseweston@gmail.com,5;5;5,5;5;5,Withdrawn,0,1,,yes,9/27/18,Facebook;Facebook;Facebook;Facebook;Facebook,image;captioning;captions;vision;language;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,asia,in,n,8
2961,ICLR,2019,Spectral Convolutional Networks on Hierarchical Multigraphs,Boris Knyazev;Xiao Lin;Mohamed R. Amer;Graham W. Taylor,bknyazev@uoguelph.ca;xiao.lin@sri.com;mohamed.amer@sri.com;gwtaylor@uoguelph.ca,4;3;4,4;5;4,Withdrawn,0,0,,yes,9/27/18,University of Guelph;SRI International;SRI International;University of Guelph,graph convolution;hierarchical models;neural networks;multigraph;deep learning;,285;-1;-1;285,-1;-1;-1;-1,-1;-1,canada,ca,n,1;10
2962,ICLR,2019,,,youngjoon.yoo@navercorp.com,4;4;6,4;5;5,Withdrawn,0,0,,yes,,NAVER,NA;,-1,-1,-1,europe,gr,pdf miss,
2963,ICLR,2019,,Dai Quoc Nguyen;Tu Dinh Nguyen;Dinh Phung,dai.nguyen@monash.edu;tu.dinh.nguyen@monash.edu;dinh.phung@monash.edu,4;5;5,4;3;4,Withdrawn,0,3,,yes,,Monash University;Monash University;Monash University,NA;,94;94;94,80;80;80,m;m,australasia,au,pdf miss,
2964,ICLR,2019,MCTSBug: Generating Adversarial Text Sequences via Monte Carlo Tree Search and Homoglyph Attack,Ji Gao;Jack Lanchantin;Yanjun Qi,jg6yd@virginia.edu;jjl5sw@virginia.edu;yanjun@virginia.edu,3;4,4;3,Withdrawn,0,1,,yes,9/27/18,University of Virginia;University of Virginia;University of Virginia,Adversarial sample;Text;Black-box;MCTS;Homoglyph;,59;59;59,113;113;113,-1;-1,usa,usa,n,4
2965,ICLR,2019,Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions,Huanrui Yang;Jingchi Zhang;Hsin-Pai Cheng;Wenhan Wang;Yiran Chen;Hai Li,huanrui.yang@duke.edu;jingchi.zhang@duke.edu;hc218@duke.edu;wenhanw@microsoft.com;yiran.chen@duke.edu;hai.li@duke.edu,4;3,3;5,Withdrawn,3,0,,yes,9/27/18,Duke University;Duke University;Duke University;Microsoft;Duke University;Duke University,DNN robustness;Adversarial attack;Data augmentation;,47;47;47;-1;47;47,17;17;17;-1;17;17,-1;-1,europe,se,n,4
2966,ICLR,2019,Learning Grounded Sentence Representations by Jointly Using Video and Text Information,Patrick Bordes;Eloi Zablocki;Laure Soulier;Benjamin Piwowarski;Patrick Gallinari,patrick.bordes@lip6.fr;eloi.zablocki@gmail.com;laure.soulier@lip6.fr;benjamin.piwowarski@lip6.fr;patrick.gallinari@lip6.fr,4;3;6,4;5;4,Withdrawn,0,1,,yes,9/27/18,LIP6;Valeo;LIP6;LIP6;LIP6,multimodal;sentence;representation;embedding;grounding;,419;-1;419;419;419,-1;-1;-1;-1;-1,-1;-1,asia,ir,n,
2967,ICLR,2019,Isolating effects of age with fair representation learning when assessing dementia,Zining Zhu;Jekaterina Novikova;Frank Rudzicz,zining.zhu@mail.utoronto.ca;jekaterina@winterlightlabs.com;frank@spoclab.com,4;4;5,3;3;4,Withdrawn,0,4,,yes,9/27/18,Toronto University;Winterlightlabs;University of Toronto,,-1;-1;18,-1;-1;22,-1;-1,canada,ca,n,7
2968,ICLR,2019,Diagnosing Language Inconsistency in Cross-Lingual Word Embeddings,Yoshinari Fujinuma;Jordan Boyd-Graber;Michael J. Paul,yoshinari.fujinuma@colorado.edu;jbg@umiacs.umd.edu;michael.j.paul@colorado.edu,6;4;4,4;4;5,Withdrawn,0,0,,yes,9/27/18,"University of Colorado, Boulder;University of Maryland, College Park;University of Colorado, Boulder",cross-lingual embeddings;evaluation;graph-based metric;modularity;,59;12;59,100;69;100,-1;-1,usa,usa,n,10
2969,ICLR,2019,Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin,Ahmad Rashid;Alan Do-Omri;Mehdi Rezagholizadeh;Md. Akmal Haidar;Hamed Sadeghi,ahmadrash@gmail.com;alan.do-omri@mail.mcgill.ca;mehdi.rezagholizadeh@gmail.com;md.akmal.haidar@huawei.com;haamed.sadeghi@gmail.com,3;4;4,5;3;5,Withdrawn,0,0,,yes,9/27/18,Huawei Technologies Ltd.;McGill University;;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Text Generation;Machine Translation;Deep Learning;GAN;,-1;94;-1;-1;-1,-1;42;-1;-1;-1,-1;-1,asia,in,n,8;5;4
2970,ICLR,2019,"Learning Robust, Transferable Sentence Representations for Text Classification",Wasi Uddin Ahmad;Xueying Bai;Nanyun Peng;Kai-Wei Chang,wasiahmad@cs.ucla.edu;xubai@cs.stonybrook.edu;npeng@isi.edu;kwchang@cs.ucla.edu,4;3;4,4;2;4,Withdrawn,0,2,,yes,9/27/18,"University of California, Los Angeles;State University of New York, Stony Brook;USC/ISI;University of California, Los Angeles",sentence representations learning;multi-task learning;transfer learning;,-1;-1;-1;-1,15;-1;-1;15,-1;-1,usa,usa,n,6
2971,ICLR,2019,,Masoud Faraki;Mahsa Baktashmotlagh;Tom Drummond;Mathieu Salzmann,masoud.faraki@monash.edu;m.baktashmotlagh@qut.edu.au;tom.drummond@monash.edu;mathieu.salzmann@epfl.ch,4;4;3,4;4;5,Withdrawn,2,0,,yes,,Monash University;South China University of Technology;Monash University;Swiss Federal Institute of Technology Lausanne,NA;,94;-1;94;-1,80;576;80;-1,-1;-1,NAN,NAN,pdf miss,
2972,ICLR,2019,Empirical observations on the instability of aligning word vector spaces with GANs,Mareike Hartmann;Yova Kementchedjhieva;Anders S√∏gaard,hartmann@di.ku.dk;yova@di.ku.dk;soegaard@di.ku.dk,4;6;5,4;3;4,Withdrawn,0,0,,yes,9/27/18,University of Copenhagen;University of Copenhagen;University of Copenhagen,natural language processing;bilingual dictionary induction;unsupervised learning;generative adversarial networks;,86;86;86,109;109;109,-1;-1,europe,dk,n,3;5;4
2973,ICLR,2019,Low-Rank Matrix Factorization of LSTM as Effective Model Compression,Genta Indra Winata;Andrea Madotto;Jamin Shin;Elham J. Barezi,giwinata@connect.ust.hk;amadotto@connect.ust.hk;jay.shin@connect.ust.hk;ejs@connect.ust.hk,5;5;4,4;2;4,Withdrawn,2,3,,yes,9/27/18,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,NLP;LSTM;Compression;Low Rank;Norm Analysis;,-1;-1;-1;-1,44;44;44;44,-1;-1,NAN,NAN,n,3
2974,ICLR,2019,Combining Global Sparse Gradients with Local Gradients,Alham Fikri Aji;Kenneth Heafield,a.fikri@ed.ac.uk;kheafiel@inf.ed.ac.uk,5;5;3,4;3;4,Withdrawn,0,0,,yes,9/27/18,University of Edinburgh;University of Edinburgh,Distributed training;stochastic gradient descent;machine translation;,36;36,27;27,-1;-1,europe,uk,n,3
2975,ICLR,2019,KNOWLEDGE DISTILL VIA LEARNING NEURON MANIFOLD,Zeyi Tao;Qi Xia;Qun Li,ztao@email.wm.edu;qxia01@email.wm.edu;liqun@cs.wm.edu,5;1;3,3;5;4,Withdrawn,0,0,,yes,9/27/18,College of William and Mary;College of William and Mary;College of William and Mary,Deep Learning;Machine Learning;Knowledge Distill;Model Compression;,207;207;207,-1;-1;-1,-1;-1,usa,usa,y,6
2976,ICLR,2019,Adversarial Decomposition of Text Representation,Alexey Romanov;Anna Rumshisky;Anna Rogers;David Donahue,jgc128@outlook.com;arum@cs.uml.edu;arogers@cs.uml.edu;david_donahue@student.uml.edu,3;6;4,4;3;3,Withdrawn,0,4,,yes,9/27/18,"University of Massachusetts, Lowell;University of Massachusetts, Lowell;University of Massachusetts, Lowell;University of Massachusetts, Lowell",learning representation;decomposition;adversarial training;style transfer;,-1;207;207;207,-1;191;191;191,-1;-1,usa,usa,n,4
2977,ICLR,2019,How to learn (and how not to learn) multi-hop reasoning with memory networks,Jifan Chen;Greg Durrett,jf_chen@utexas.edu;gdurrett@cs.utexas.edu,3;5;5,5;5;4,Withdrawn,0,0,,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",NLP;Reading Comprehension;Memory Networks;Multi-hop Reasoning;,-1;-1,-1;-1,-1;-1,usa,usa,n,8
2978,ICLR,2019,Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering,Jianmo Ni;Chenguang Zhu;Weizhu Chen;Julian McAuley,jin018@ucsd.edu;chezhu@microsoft.com;wzchen@microsoft.com;jmcauley@cs.ucsd.edu,4;5;5,4;4;4,Withdrawn,2,0,,yes,9/27/18,"University of California, San Diego;Microsoft;Microsoft;University of California, San Diego",Open-domain question answering;,-1;-1;-1;-1,31;-1;-1;31,-1;-1,usa,usa,n,
2979,ICLR,2019,The Missing Ingredient in Zero-Shot Neural Machine Translation,Naveen Arivazhagan;Ankur Bapna;Orhan Firat;Roee Aharoni;Melvin Johnson;Wolfgang Macherey,naveenariva@gmail.com;ankurbpn@google.com;orhanf@google.com;roee.aharoni@gmail.com;melvinp@google.com;wmach@google.com,5;4;3,5;3;3,Withdrawn,0,6,,yes,9/27/18,Google;Google;Google;Google;Google;Google,Machine Translation;Multi-lingual processing;Zero-Shot translation;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3;1;6
2980,ICLR,2019,Iterative Binary Decisions,Stephan Alaniz;Zeynep Akata,s.alaniz@uva.nl;z.akata@uva.nl,4;4;4,4;4;3,Withdrawn,0,1,,yes,9/27/18,University of Amsterdam;University of Amsterdam,explainable AI;interpretability;deep learning;decision tree;zero-shot learning;,136;136,59;59,-1;-1,europe,nl,n,6
2981,ICLR,2019,What Is in a Translation Unit?  Comparing Character and Subword Representations Beyond Translation,Nadir Durrani;Fahim Dalvi;Hassan Sajjad;Yonatan Belinkov;Preslav Nakov,ndurrani@qf.org.qa;faimaduddin@qf.org.qa;hsajjad@qf.org.qa;belinkov@mit.edu;pnakov@hbku.edu.qa,5;5;5,4;4;3,Withdrawn,0,0,,yes,9/27/18,IDKT-RDI QF;IDKT-RDI QF;IDKT-RDI QF;Massachusetts Institute of Technology;Peking University,subwords;representations;word embeddings;transfer learning;machine translation;natural language processing;,-1;-1;-1;6;14,-1;-1;-1;5;27,-1;-1,asia,cn,n,2;3
2982,ICLR,2019,Robust Text Classifier on Test-Time Budgets,Md Rizwan Parvez;Tolga Bolukbasi;Kai-Wei Chang;Venkatesh Saligrama,rizwan@cs.ucla.edu;tolgab@bu.edu;kwchang@cs.ucla.edu;srv@bu.edu,4;4;5,4;4;3,Withdrawn,0,0,,yes,9/27/18,"University of California, Los Angeles;Boston University;University of California, Los Angeles;Boston University",Data Aggregation;Budget Learning;Speed  Up;Faster Inference;Robust Classifier;,-1;77;-1;77,15;70;15;70,-1;-1,europe,it,n,
2983,ICLR,2019,Hiding Objects from Detectors: Exploring Transferrable Adversarial Patterns,Shangbang Long;Jie Fu;Chris Pal,longlongsb@pku.edu.cn;jie.fu@polymtl.ca;christopher.pal@polymtl.ca,6;4;3,4;4;3,Withdrawn,0,3,,yes,9/27/18,Peking University;Polytechnique Montreal;Polytechnique Montreal,adversarial;object detection;,14;285;285,27;-1;-1,-1;-1,canada,ca,n,8;1;4
2984,ICLR,2019,Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders ,Andrew Drozdov;Patrick Verga;Mohit Yadev;Mohit Iyyer;Andrew McCallum,adrozdov@cs.umass.edu;pat@cs.umass.edu;ymohit@cs.umass.edu;miyyer@cs.umass.edu;mccallum@cs.umass.edu,5;6;2,4;3;4,Withdrawn,0,5,,yes,9/27/18,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",latent-tree-learning;unsupervised-parsing;,27;27;27;27;27,191;191;191;191;191,-1;-1,usa,usa,n,2
2985,ICLR,2019,Tangent-Normal Adversarial Regularization for Semi-supervised Learning,Bing Yu;Jingfeng Wu;Jinwen Ma;Zhanxing Zhu,byu@pku.edu.cn;pkuwjf@pku.edu.cn;jwma@math.pku.edu.cn;zhanxing.zhu@pku.edu.cn,5;4;7,3;5;4,Withdrawn,0,1,,yes,9/27/18,Peking University;Peking University;Peking University;Peking University,semi-supervised learning;manifold regularization;adversarial training;,14;14;14;14,27;27;27;27,-1;-1,asia,cn,n,4
2986,ICLR,2019,Answer-based Adversarial Training for Generating Clarification Questions,Sudha Rao;Hal Daum√© III,raosudha@cs.umd.edu;hal@umiacs.umd.edu,4;4;6,4;5;4,Withdrawn,0,0,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park",natural language processing;text generation;generative adversarial network;,12;12,69;69,-1;-1,usa,usa,n,5;4
2987,ICLR,2019,IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles,Tianze Shi;Kedar Tatwawadi;Kaushik Chakrabarti;Yi Mao;Oleksandr Polozov;Weizhu Chen,tianze@cs.cornell.edu;kedart@stanford.edu;kaushik@microsoft.com;maoyi@microsoft.com;polozov@microsoft.com;wzchen@microsoft.com,4;6;3,4;3;5,Withdrawn,0,0,,yes,9/27/18,Cornell University;Stanford University;Microsoft;Microsoft;Microsoft;Microsoft,semantic parsing;non-deterministic oracles;natural language to SQL;incremental parsing;sequence prediction;,6;4;-1;-1;-1;-1,19;3;-1;-1;-1;-1,-1;-1,NAN,NAN,n,3
2988,ICLR,2019,Mitigating Bias in Natural Language Inference Using Adversarial Learning,Yonatan Belinkov;Adam Poliak;Stuart M. Shieber;Benjamin Van Durme,belinkov@seas.harvard.edu;azpoliak@cs.jhu.edu;shieber@seas.harvard.edu;vandurme@cs.jhu.edu,4;4;8,5;4;4,Withdrawn,0,5,,yes,9/27/18,Harvard University;Johns Hopkins University;Harvard University;Johns Hopkins University,natural language inference;adversarial learning;bias;artifacts;,50;67;50;67,6;13;6;13,-1;-1,usa,usa,n,3;4
2989,ICLR,2019,Multi-Modal Generative Adversarial Networks for Diverse Datasets,Matan Ben-Yosef;Daphna Weinshall,matan.benyosef@mail.huji.ac.il;daphna@cs.huji.ac.il,4;6,4;4,Withdrawn,0,0,,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem,generative adversarial networks;generative models;clustering;visual object recognition;,77;77,205;205,-1;-1,europe,il,n,5;4
2990,ICLR,2019,Few-Shot Learning by Exploiting Object Relation,Liangqu Long;Wei Wang;Jun Wen;Meihui  Zhang;Qian  Lin,liangqu.long@gmail.com;wangwei@comp.nus.edu.sg;jungel2star@gmail.com;meihui_zhang@bit.edu.cn;linqian@comp.nus.edu.sg,6;4;4,4;4;3,Withdrawn,0,0,,yes,9/27/18,"Central South University, China;National University of Singapore;;Beijing Institute of Technology;National University of Singapore",few-shot learning;relation learning;,-1;18;-1;-1;18,-1;22;-1;688;22,-1;-1,asia,sg,n,6
2991,ICLR,2019,CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks,Asma Nouira;Nataliya Sokolovska;Jean-Claude Crivello,asma.nouira.91@gmail.com;nataliya.sokolovska@upmc.fr;jccrivello@icmpe.cnrs.fr,3;7;4,4;2;2,Withdrawn,0,0,,yes,9/27/18,"Computer Science Lab  - Pierre and Marie Curie University, Paris, Franc;Computer Science Lab  - Pierre and Marie Curie University, Paris, France;CNRS",Generative Adversarial Nets;Cross-Domain Learning;Materials Science;Higher-order Complexity;,-1;-1;-1,-1;123;-1,-1;-1,asia,in,n,5;4
2992,ICLR,2019,Exploration using Distributional RL and UCB,Borislav Mavrin;Hengshuai Yao;Linglong Kong;ShangtongZhang,mavrin@ualberta.ca;hengshuai.yao@huawei.com;lkong@ualberta.ca;zhangshangtong.cpp@gmail.com,4;4;4,3;5;4,Withdrawn,0,3,,yes,9/27/18,University of Alberta;Huawei Technologies Ltd.;University of Alberta;University of Oxford,Distributional RL;UCB;exploration;Atari 2600;multi-armed bandits;,94;-1;94;44,119;-1;119;1,-1;-1,europe,uk,y,1
2993,ICLR,2019,The Body is not a Given: Joint Agent Policy Learning and Morphology Evolution,Dylan Banarse;Yoram Bachrach;Siqi Liu;Chrisantha Fernando;Nicolas Heess;Pushmeet Kohli;Guy Lever;Thore Graepel,dylski@google.com;yorambac@google.com;guylever@google.com;heess@google.com;pushmeet@google.com;liusiqi@google.com;chrisantha@google.com;thore@google.com,4;4;3;4,4;4;4;3,Withdrawn,0,1,,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,Reinforcement Learning;Continuous Control;Evolutionary Computation;Genetic Algorithms;Evolving Morphology;Baldwin Effect;Population Based Training;,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
2994,ICLR,2019,From Adversarial Training to Generative Adversarial Networks,Xuanqing Liu;Cho-Jui Hsieh,xqliu@cs.ucla.edu;chohsieh@cs.ucla.edu,3;6;4,3;3;4,Withdrawn,0,1,,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles",adversarial training;conditional GAN;,-1;-1,15;15,-1;-1,usa,usa,n,5;4
2995,ICLR,2019,An Efficient Network for Predicting Time-Varying Distributions,Connie Kou;Hwee Kuan Lee;Teck Khim Ng;Jorge Sanz,koukl@comp.nus.edu.sg;leehk@bii.a-star.edu.sg;ngtk@comp.nus.edu.sg;jorges@nus.edu.sg,5;4;5,4;3;4,Withdrawn,0,0,,yes,9/27/18,National University of Singapore;A*STAR;National University of Singapore;National University of Singapore,Distribution regression;Distribution sequence;Forward prediction;,18;-1;18;18,22;-1;22;22,-1;-1,asia,sg,n,
2996,ICLR,2019,Quantile Regression Reinforcement Learning with State Aligned Vector Rewards,Oliver Richter;Roger Wattenhofer,richtero@ethz.ch;wattenhofer@ethz.ch,4;3;4,4;3;4,Withdrawn,0,8,,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,deep reinforcement learning;quantile regression;vector reward;,-1;-1,-1;-1,-1;-1,NAN,NAN,n,
2997,ICLR,2019,Fatty and Skinny: A Joint Training Method of Watermark Encoder and Decoder,Sanghyun Hong;Mahmoud Mohammadi;Noseong Park,shhong@cs.umd.edu;mmoham12@uncc.edu;npark9@gmu.edu,4;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,"University of Maryland, College Park;University of North Carolina, Charlotte;George Mason University",Adversarial Machine Learning;Watermarking;Generative Adversarial Networks;,12;67;94,69;-1;336,-1;-1,usa,usa,n,8;1;5;4
2998,ICLR,2019,Transfer Learning via Unsupervised Task Discovery for Visual Question Answering,Hyeonwoo Noh;Taehoon Kim;Jonghwan Mun;Bohyung Han,shgusdngogo@postech.ac.kr;carpedm20@gmail.com;choco1916@postech.ac.kr;bhhan@snu.ac.kr,4;5;8,5;5;5,Withdrawn,0,0,,yes,9/27/18,POSTECH;OpenAI;POSTECH;Seoul National University,,136;-1;136;36,137;-1;137;74,-1;-1,asia,kr,n,
2999,ICLR,2019,Confidence Calibration in Deep Neural Networks through Stochastic Inferences,Seonguk Seo;Paul Hongsuck Seo;Bohyung Han,seonguk@snu.ac.kr;hsseo@postech.ac.kr;bhhan@snu.ac.kr,5;3;5,4;2;4,Withdrawn,0,0,,yes,9/27/18,Seoul National University;POSTECH;Seoul National University,Variance-Weighted Confidence-Integrated loss;Confidence Calibration;Stochastic Regularization;Stochastic Inferences;,36;136;36,74;137;74,-1;-1,asia,kr,n,11
3000,ICLR,2019,Noise-Tempered Generative Adversarial Networks,Simon Jenni;Paolo Favaro,jenni@inf.unibe.ch;paolo.favaro@inf.unibe.ch,4;5;5,5;4;4,Withdrawn,0,4,,yes,9/27/18,University of Bern;University of Bern,,285;285,105;105,-1;-1,europe,uk,n,5;4
3001,ICLR,2019,SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities,Diogo Pernes;Jaime S. Cardoso,dpc@inesctec.pt;jaime.cardoso@inesctec.pt,3;3;3,4;4;4,Withdrawn,0,3,,yes,9/27/18,University of Porto;University of Porto,multi-entity sequential data;hidden markov models;,-1;-1,501;501,-1;-1,europe,ee,n,10;5
3002,ICLR,2019,Self-Binarizing Networks,Fayez Lahoud;Radhakrishna Achanta;Pablo M√°rquez-Neila;Sabine S√ºsstrunk,fayez.lahoud@epfl.ch;radhakrishna.achanta@epfl.ch;pablo.marquez@artorg.unibe.ch;sabine.susstrunk@epfl.ch,5;5;5,4;4;4,Withdrawn,4,1,,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;University of Bern;Swiss Federal Institute of Technology Lausanne,Binarization;Convolutional Neural Networks;Deep Learning;Deep Neural Networks;,-1;-1;285;-1,-1;-1;105;-1,-1;-1,NAN,NAN,n,
3003,ICLR,2019,UNSUPERVISED MONOCULAR DEPTH ESTIMATION WITH CLEAR BOUNDARIES,Yihan Hu;Heng Luo;Yifeng Geng,y4hu@eng.ucsd.edu;heng.luo@horizon.ai;yifeng.geng@horizon.ai,4;4;3,3;5;4,Withdrawn,0,0,,yes,9/27/18,"University of California, San Diego;Horizon Robotics;Horizon Robotics",monocular depth estimation;unsupervised learning;image warping;,-1;-1;-1,31;-1;-1,-1;-1,NAN,NAN,n,
3004,ICLR,2019,Object-Contrastive Networks: Unsupervised Object Representations,Soeren Pirk;Mohi Khansari;Yunfei Bai;Corey Lynch;Pierre Sermanet,pirk@google.com;khansari@google.com;yunfeibai@google.com;coreylynch@google.com;sermanet@google.com,3;3;5,5;5;4,Withdrawn,0,0,,yes,9/27/18,Google;Google;Google;Google;Google,self-supervised robotics;object understanding;object representations;metric learning;unsupervised vision;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,
3005,ICLR,2019,TFGAN: Improving Conditioning for Text-to-Video Synthesis,Yogesh Balaji;Martin Renqiang Min;Bing Bai;Rama Chellappa;Hans Peter Graf,yogesh@cs.umd.edu;renqiang@nec-labs.com;bbai@nec-labs.com;rama@umiacs.umd.edu;hpg@nec-labs.com,6;3;5,3;5;4,Withdrawn,0,0,,yes,9/27/18,"University of Maryland, College Park;NEC-Labs;NEC-Labs;University of Maryland, College Park;NEC-Labs",Conditional GAN;Video Generation;Text-to-Video Synthesis;Conditional Generative Models;Deep Generative Models;,12;-1;-1;12;-1,69;-1;-1;69;-1,-1;-1,NAN,NAN,n,5;4
3006,ICLR,2019,Learning Graph Decomposition,Jie Song;Bjoern Andres;Michael Black;Otmar Hilliges;Siyu Tang,jsong@inf.ethz.ch;bjoern.andres@de.bosch.com;black@tuebingen.mpg.de;otmar.hilliges@inf.ethz.ch;stang@tuebingen.mpg.de,7;4;5,4;4;4,Withdrawn,0,0,,yes,9/27/18,Swiss Federal Institute of Technology;Bosch;Max-Planck Institute;Swiss Federal Institute of Technology;Max-Planck Institute,multicut graph decomposition;optimization by learning;pose estimation;clustering;,-1;-1;-1;-1;-1,-1;367;-1;-1;-1,-1;-1,NAN,NAN,n,2;10
3007,ICLR,2019,Logically-Constrained Neural Fitted Q-iteration,Mohammadhosein Hasanbeig;Alessandro Abate;Daniel Kroening,hosein.hasanbeig@cs.ox.ac.uk;aabate@cs.ox.ac.uk;kroening@cs.ox.ac.uk,5;4;5,2;5;4,Withdrawn,0,5,,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,,44;44;44,1;1;1,-1;-1,europe,uk,n,
3008,ICLR,2019,Distributed Deep Policy Gradient for Competitive Adversarial Environment,Denis Osipychev;Girish Chowdhary,deniso2@illinois.edu;girishc@illinois.edu,4;4;3,4;3;5,Withdrawn,0,0,,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",multi-agent;partially observable;reinforcement learning;deepRL;self play;competitive environment;,-1;-1,-1;-1,-1;-1,usa,usa,n,
3009,ICLR,2019,Found by NEMO: Unsupervised Object Detection from Negative Examples and Motion,Rico Jonschkowski,rjon@google.com,5;3;4,4;4;4,Withdrawn,0,1,,yes,9/27/18,Google,unsupervised learning;computer vision;object detection;,-1,-1,-1,NAN,NAN,n,2
3010,ICLR,2019,Visualizing and Discovering Behavioural Weaknesses in Deep Reinforcement Learning,Christian Rupprecht;Cyril Ibrahim;Chris Pal,christian.rupprecht@in.tum.de;cyril.ibrahim@elementai.com;christopher.pal@polymtl.ca,5;5;4,4;4;5,Withdrawn,0,2,,yes,9/27/18,Technical University Munich;Element AI;Polytechnique Montreal,Visualization;Deep Reinforcement Learning;,-1;-1;285,-1;-1;-1,-1;-1,canada,ca,n,5
3011,ICLR,2019,Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner,Bradly C. Stadie;S√∂ren R. K√ºnzel;Nikita Vemuri;Jasjeet S. Sekhon,bstadie@berkeley.edu;srk@berkeley.edu;nikitavemuri@berkeley.edu;sekhon@berkeley.edu,5;5;4,3;4;4,Withdrawn,0,0,,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,causal inference;CATE estimation;ITE;deep learning;,-1;-1;-1;-1,18;18;18;18,-1;-1,usa,usa,n,
3012,ICLR,2019,Generative Model For Material Irradiation Experiments Based On Prior Knowledge And Attention Mechanism,MinCong Luo;Li Liu,luomincong@foxmail.com;1920148271@qq.com,3;3,4;4,Withdrawn,0,0,,yes,9/27/18,Foxmail;QQ,Generative Model;Images of Irradiation Experiments;Prior Knowledge;Attention Mechanism;,-1;-1,-1;-1,-1;-1,asia,in,n,8;5;4
3013,ICLR,2019, Generating Text through Adversarial Training using Skip-Thought Vectors,Afroz Ahamad,afrozsahamad@gmail.com,3;2;2,5;5;5,Withdrawn,0,0,,yes,9/27/18,0,Natural Language Generation;Computation and Language;Machine Learning;Generative Adversarial Networks;Sentence Embeddings;,,,-1,NAN,NAN,n,3;5;4
3014,ICLR,2019,Evolving intrinsic motivations for altruistic behavior,Jane X. Wang;Edward Hughes;Chrisantha Fernando;Wojciech M. Czarnecki;Edgar A. Duenez-Guzman;Joel Z. Leibo,wangjane@google.com;edwardhughes@google.com;chrisantha@google.com;lejlot@google.com;duenez@google.com;jzl@google.com,5;6;3,3;2;4,Withdrawn,0,0,,yes,9/27/18,Google;Google;Google;Google;Google;Google,evolution;reinforcement learning;intrinsic reward;multi-agent;social dilemmas;cooperation;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,-1;-1,NAN,NAN,n,1
3015,ICLR,2020,Policy path programming,Daniel McNamee,daniel.c.mcnamee@gmail.com,3;3;3;1,,Reject,0,1,0.0,yes,9/25/19,causaLens,markov decision process;planning;hierarchical;reinforcement learning,-1,-1,m;m,NAN,NAN,n,1
3016,ICLR,2020,Meta-Learning Deep Energy-Based Memory Models,Sergey Bartunov;Jack Rae;Simon Osindero;Timothy Lillicrap,bartunov@google.com;jwrae@google.com;osindero@google.com;countzero@google.com,6;6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Google;Google;Google;Google,associative memory;energy-based memory;meta-learning;compressive memory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
3017,ICLR,2020,Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories,Tiange Luo;Kaichun Mo;Zhiao Huang;Jiarui Xu;Siyu Hu;Liwei Wang;Hao Su,luotg@pku.edu.cn;kaichun@cs.stanford.edu;z2huang@eng.ucsd.edu;jxuat@connect.ust.hk;sy89128@mail.ustc.edu.cn;wanglw@cis.pku.edu.cn;haosu@eng.ucsd.edu,8;6;3,,Accept (Poster),1,5,0.0,yes,9/25/19,"Peking University;Stanford University;University of California, San Diego;The Hong Kong University of Science and Technology;University of Science and Technology of China;Peking University;University of California, San Diego",Shape Segmentation;Zero-Shot Learning;Learning Representations,14;5;-1;-1;-1;14;-1,24;4;31;47;80;24;31,m;m,usa,usa,n,6;2
3018,ICLR,2020,VL-BERT: Pre-training of Generic Visual-Linguistic Representations,Weijie Su;Xizhou Zhu;Yue Cao;Bin Li;Lewei Lu;Furu Wei;Jifeng Dai,jackroos@mail.ustc.edu.cn;ezra0408@mail.ustc.edu.cn;yuecao@microsoft.com;binli@ustc.edu.cn;lewlu@microsoft.com;fuwei@microsoft.com;jifdai@microsoft.com,3;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;Microsoft;University of Science and Technology of China;Microsoft;Microsoft;Microsoft,Visual-Linguistic;Generic Representation;Pre-training,-1;-1;-1;-1;-1;-1;-1,80;80;-1;80;-1;-1;-1,m;m,NAN,NAN,n,8
3019,ICLR,2020,Episodic Reinforcement Learning with Associative Memory,Guangxiang Zhu*;Zichuan Lin*;Guangwen Yang;Chongjie Zhang,guangxiangzhu@outlook.com;linzc16@mails.tsinghua.edu.cn;ygw@tsinghua.edu.cn;chongjie@tsinghua.edu.cn,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Deep Reinforcement Learning;Episodic Control;Episodic Memory;Associative Memory;Non-Parametric Method;Sample Efficiency,-1;4;4;4,-1;23;23;23,m;m,NAN,NAN,n,10
3020,ICLR,2020,Independence-aware Advantage Estimation,Pushi Zhang;Li Zhao;Guoqing Liu;Jiang Bian;Minglie Huang;Tao Qin;Tie-Yan Liu,zpschang@gmail.com;lizo@microsoft.com;lgq1001@mail.ustc.edu.cn;jiang.bian@microsoft.com;aihuang@mails.tsinghua.edu.cn;taoqin@microsoft.com;tie-yan.liu@microsoft.com,6;6;3,,Reject,0,7,0.0,yes,9/25/19,"Tsinghua University;Microsoft;University of Science and Technology of China;Microsoft;Tsinghua University, Tsinghua University;Microsoft;Microsoft",Reinforcement Learning;Advantage Estimation,-1;-1;-1;-1;4;-1;-1,-1;-1;80;-1;23;-1;-1,u;m,NAN,NAN,n,
3021,ICLR,2020,Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets,Mingrui Liu;Youssef Mroueh;Jerret Ross;Wei Zhang;Xiaodong Cui;Payel Das;Tianbao Yang,mingrui-liu@uiowa.edu;mroueh@us.ibm.com;rossja@us.ibm.com;weiz@us.ibm.com;cuix@us.ibm.com;daspa@us.ibm.com;tianbao-yang@uiowa.edu,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Iowa;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Iowa,Generative Adversarial Nets;Adaptive Gradient Algorithms,168;-1;-1;-1;-1;-1;168,227;-1;-1;-1;-1;-1;227,m;m,europe,de,y,1;5;9
3022,ICLR,2020,Understanding Attention Mechanisms,Bingyuan Liu;Yogesh Balaji;Lingzhou Xue;Martin Renqiang Min,bul37@psu.edu;yogesh@cs.umd.edu;lzxue@psu.edu;renqiang@nec-labs.com,6;3;3,,Reject,0,5,0.0,yes,9/25/19,"Pennsylvania State University;University of Maryland, College Park;Pennsylvania State University;NEC-Labs",Attention;deep learning;sample complexity;self-attention,43;12;43;-1,-1;91;-1;-1,m;m,NAN,NAN,y,8
3023,ICLR,2020,Defending Against Adversarial Examples by Regularized Deep Embedding,Yao Li;Martin Renqiang Min;Wenchao Yu;Cho-Jui Hsieh;Thomas Lee;Erik Kruus,yaoli@ucdavis.edu;renqiang@nec-labs.com;yuwenchao@ucla.edu;chohsieh@cs.ucla.edu;tcmlee@ucdavis.edu;kruus@nec-labs.com,3;1;6,,Reject,2,11,0.0,yes,9/25/19,"University of California, Davis;NEC-Labs;University of California, Los Angeles;University of California, Los Angeles;University of California, Davis;NEC-Labs",,-1;-1;-1;-1;-1;-1,55;-1;17;17;55;-1,f;m,NAN,NAN,y,4
3024,ICLR,2020,A Learning-based Iterative Method for Solving Vehicle Routing Problems,Hao Lu;Xingwen Zhang;Shuang Yang,haolu@princeton.edu;xingwen.zhang@antfin.com;shuang.yang@antfin.com,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Princeton University;Antfin;Antfin,vehicle routing;reinforcement learning;optimization;heuristics,30;-1;-1,6;-1;-1,m;m,NAN,NAN,n,
3025,ICLR,2020,GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations,Martin Engelcke;Adam R. Kosiorek;Oiwi Parker Jones;Ingmar Posner,martin@robots.ox.ac.uk;adamk@robots.ox.ac.uk;oiwi@robots.ox.ac.uk;ingmar@robots.ox.ac.uk,8;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Generative modelling;object-centric representations;scene generation;variational inference,46;46;46;46,1;1;1;1,m;m,europe,uk,n,5
3026,ICLR,2020,Robust training with ensemble consensus,Jisoo Lee;Sae-Young Chung,jisoolee@kaist.ac.kr;schung@kaist.ac.kr,3;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Annotation noise;Noisy label;Robustness;Ensemble;Perturbation,-1;-1,110;110,f;m,NAN,NAN,n,
3027,ICLR,2020,Selection via Proxy: Efficient Data Selection for Deep Learning,Cody Coleman;Christopher Yeh;Stephen Mussmann;Baharan Mirzasoleiman;Peter Bailis;Percy Liang;Jure Leskovec;Matei Zaharia,cody@cs.stanford.edu;chrisyeh@stanford.edu;mussmann@stanford.edu;baharanm@stanford.edu;pbailis@cs.stanford.edu;pliang@cs.stanford.edu;jure@cs.stanford.edu;matei@cs.stanford.edu,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,data selection;active-learning;core-set selection;deep learning;uncertainty sampling,5;5;5;5;5;5;5;5,4;4;4;4;4;4;4;4,m;m,usa,usa,n,
3028,ICLR,2020,Estimating Gradients for Discrete Random Variables by Sampling without Replacement,Wouter Kool;Herke van Hoof;Max Welling,w.w.m.kool@uva.nl;h.c.vanhoof@uva.nl;m.welling@uva.nl,6;8;6,,Accept (Spotlight),0,6,0.0,yes,9/25/19,University of Amsterdam;University of Amsterdam;University of Amsterdam,gradient;estimator;discrete;categorical;sampling;without replacement;reinforce;baseline;variance;gumbel;vae;structured prediction,143;143;143,62;62;62,m;m,europe,nl,y,
3029,ICLR,2020,Graph Neural Networks Exponentially Lose Expressive Power for Node Classification,Kenta Oono;Taiji Suzuki,kenta_oono@mist.i.u-tokyo.ac.jp;taiji@mist.i.u-tokyo.ac.jp,8;6;8,,Accept (Spotlight),1,3,2.0,yes,9/25/19,The University of Tokyo;The University of Tokyo,Graph Neural Network;Deep Learning;Expressive Power,64;64,36;36,m;m,NAN,NAN,y,1;10
3030,ICLR,2020,Accelerating SGD with momentum for over-parameterized learning,Chaoyue Liu;Mikhail Belkin,liu.2656@buckeyemail.osu.edu;mbelkin@cse.ohio-state.edu,3;8;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"Ohio State University;University of California, San Diego",SGD;acceleration;momentum;stochastic;over-parameterized;Nesterov,59;-1,70;31,u;m,usa,usa,y,1;9
3031,ICLR,2020,On the Equivalence between Positional Node Embeddings and Structural Graph Representations,Balasubramaniam Srinivasan;Bruno Ribeiro,bsriniv@purdue.edu;ribeiro@cs.purdue.edu,8;8;6,,Accept (Poster),0,8,3.0,yes,9/25/19,Purdue University;Purdue University,Graph Neural Networks;Structural Graph Representations;Node Embeddings;Relational Learning;Invariant Theory;Theory;Deep Learning;Representational Power;Graph Isomorphism,24;24,88;88,m;m,usa,usa,y,1;10
3032,ICLR,2020,Robustness Verification for Transformers,Zhouxing Shi;Huan Zhang;Kai-Wei Chang;Minlie Huang;Cho-Jui Hsieh,zhouxingshichn@gmail.com;huan@huan-zhang.com;kw@kwchang.net;aihuang@tsinghua.edu.cn;chohsieh@cs.ucla.edu,3;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"University of California, Los Angeles;Carnegie Mellon University;University of California-Los Angeles;Tsinghua University, Tsinghua University;University of California, Los Angeles",Robustness;Verification;Transformers,-1;1;-1;4;-1,17;27;17;23;17,m;m,usa,usa,n,8;1;4
3033,ICLR,2020,DDSP: Differentiable Digital Signal Processing,Jesse Engel;Lamtharn (Hanoi) Hantrakul;Chenjie Gu;Adam Roberts,jesseengel@google.com;hanoih@google.com;gcj@google.com;adarob@google.com,6;8;8,,Accept (Spotlight),0,9,4.0,yes,9/25/19,Google;Google;Google;Google,dsp;audio;music;nsynth;wavenet;wavernn;vocoder;synthesizer;sound;signal;processing;tensorflow;autoencoder;disentanglement,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
3034,ICLR,2020,ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning,Weihao Yu;Zihang Jiang;Yanfei Dong;Jiashi Feng,weihaoyu6@gmail.com;jzihang@u.nus.edu;yanfei.dong43@gmail.com;elefjia@nus.edu.sg,6;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;National University of Singapore,reading comprehension;logical reasoning;natural language processing,17;17;17;17,25;25;25;25,m;m,asia,sg,n,3
3035,ICLR,2020,Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks,Haoran You;Chaojian Li;Pengfei Xu;Yonggan Fu;Yue Wang;Xiaohan Chen;Richard G. Baraniuk;Zhangyang Wang;Yingyan Lin,hy34@rice.edu;cl114@rice.edu;px5@rice.edu;yf22@rice.edu;yw68@rice.edu;chernxh@tamu.edu;richb@rice.edu;atlaswang@tamu.edu;yingyan.lin@rice.edu,8;6;6,,Accept (Spotlight),0,6,0.0,yes,9/25/19,Rice University;Rice University;Rice University;Rice University;Rice University;Texas A&M;Rice University;Texas A&M;Rice University,,92;92;92;92;92;46;92;46;92,105;105;105;105;105;177;105;177;105,m;f,australasia,au,n,
3036,ICLR,2020,Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning,Arsenii Ashukha;Alexander Lyzhov;Dmitry Molchanov;Dmitry Vetrov,ars.ashuha@gmail.com;alex.grig.lyzhov@gmail.com;dmolch111@gmail.com;vetrovd@yandex.ru,6;8;6,,Accept (Poster),0,6,1.0,yes,9/25/19,Samsung;Center for Long-Term Risk;Samsung;Higher School of Economics,uncertainty;in-domain uncertainty;deep ensembles;ensemble learning;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
3037,ICLR,2020,A Theory of Usable Information under Computational Constraints,Yilun Xu;Shengjia Zhao;Jiaming Song;Russell Stewart;Stefano Ermon,xuyilun@pku.edu.cn;sjzhao@stanford.edu;tsong@cs.stanford.edu;russell.sb.nebel@gmail.com;ermon@cs.stanford.edu,8;8,,Accept (Talk),0,3,0.0,yes,9/25/19,Peking University;Stanford University;Stanford University;;Stanford University,,14;5;5;-1;5,24;4;4;-1;4,m;m,usa,usa,y,1
3038,ICLR,2020,An Inductive Bias for Distances: Neural Nets that Respect the Triangle Inequality,Silviu Pitis;Harris Chan;Kiarash Jamali;Jimmy Ba,spitis@cs.toronto.edu;hchan@cs.toronto.edu;kiarash.jamali@mail.utoronto.ca;jba@cs.toronto.edu,8;3;8;8,,Accept (Poster),0,6,0.0,yes,9/25/19,University of Toronto;University of Toronto;Toronto University;University of Toronto,metric learning;deep metric learning;neural network architectures;triangle inequality;graph distances,18;18;-1;18,18;18;-1;18,m;m,canada,ca,y,1;10
3039,ICLR,2020,Stochastic AUC Maximization with Deep Neural Networks,Mingrui Liu;Zhuoning Yuan;Yiming Ying;Tianbao Yang,mingrui-liu@uiowa.edu;zhuoning-yuan@uiowa.edu;yying@albany.edu;tianbao-yang@uiowa.edu,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,"University of Iowa;University of Iowa;State University of New York, Albany;University of Iowa",Stochastic AUC Maximization;Deep Neural Networks,168;168;-1;168,227;227;350;227,m;m,europe,de,y,9
3040,ICLR,2020,Convolutional Conditional Neural Processes,Jonathan Gordon;Wessel P. Bruinsma;Andrew Y. K. Foong;James Requeima;Yann Dubois;Richard E. Turner,jg801@cam.ac.uk;wpb23@cam.ac.uk;ykf21@cam.ac.uk;jrr41@cam.ac.uk;yanndubois96@gmail.com;ret26@cam.ac.uk,8;8;6,,Accept (Talk),0,7,0.0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge;University of Toronto;University of Cambridge,Neural Processes;Deep Sets;Translation Equivariance,79;79;79;79;18;79,3;3;3;3;18;3,m;m,europe,uk,y,6;1
3041,ICLR,2020,On the interaction between supervision and self-play in emergent communication,Ryan Lowe*;Abhinav Gupta*;Jakob Foerster;Douwe Kiela;Joelle Pineau,rlowe1@cs.mcgill.ca;abhinav.gupta@umontreal.ca;jakobfoerster@gmail.com;dkiela@fb.com;jpineau@cs.mcgill.ca,6;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,McGill University;University of Montreal;;Facebook;McGill University,multi-agent communication;self-play;emergent languages,102;118;-1;-1;102,42;85;-1;-1;42,m;f,canada,ca,n,3
3042,ICLR,2020,TabFact: A Large-scale Dataset for Table-based Fact Verification,Wenhu Chen;Hongmin Wang;Jianshu Chen;Yunkai Zhang;Hong Wang;Shiyang Li;Xiyou Zhou;William Yang Wang,wenhuchen@ucsb.edu;hongmin@ucsb.edu;chenjianshu@gmail.com;yunkai_zhang@ucsb.edu;hongwang600@ucsb.edu;shiyangli@ucsb.edu;xiyou@ucsb.edu;william@cs.ucsb.edu,6;6;8,,Accept (Poster),0,6,1.0,yes,9/25/19,UC Santa Barbara;UC Santa Barbara;Tencent AI Lab;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara,Fact Verification;Tabular Data;Symbolic Reasoning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;10
3043,ICLR,2020,Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning,Noah Siegel;Jost Tobias Springenberg;Felix Berkenkamp;Abbas Abdolmaleki;Michael Neunert;Thomas Lampe;Roland Hafner;Nicolas Heess;Martin Riedmiller,siegeln@google.com;springenberg@google.com;befelix@inf.ethz.ch;aabdolmaleki@google.com;neunertm@google.com;thomaslampe@google.com;rhafner@google.com;heess@google.com;riedmiller@google.com,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Swiss Federal Institute of Technology;Google;Google;Google;Google;Google;Google,Reinforcement Learning;Off-policy;Multitask;Continuous Control,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3044,ICLR,2020,Scale-Equivariant Steerable Networks,Ivan Sosnovik;Micha≈Ç Szmaja;Arnold Smeulders,sosnovikivan@gmail.com;szmajamichal@gmail.com;a.w.m.smeulders@uva.nl,8;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Amsterdam;;University of Amsterdam,Scale Equivariance;Steerable Filters,143;-1;143,62;-1;62,m;m,europe,nl,n,8;1
3045,ICLR,2020,Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech,David Harwath*;Wei-Ning Hsu*;James Glass,dharwath@csail.mit.edu;wnhsu@mit.edu;glass@mit.edu,8;8;6,,Accept (Talk),0,6,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,visually-grounded speech;self-supervised learning;discrete representation learning;vision and language;vision and speech;hierarchical representation learning,5;5;5,5;5;5,m;m,usa,usa,n,
3046,ICLR,2020,Inductive and Unsupervised Representation Learning on Graph Structured Objects,Lichen Wang;Bo Zong;Qianqian Ma;Wei Cheng;Jingchao Ni;Wenchao Yu;Yanchi Liu;Dongjin Song;Haifeng Chen;Yun Fu,wanglichenxj@gmail.com;bzong@nec-labs.com;maqq@bu.edu;weicheng@nec-labs.com;jni@nec-labs.com;wyu@nec-labs.com;yanchi@nec-labs.com;dsong@nec-labs.com;haifeng@nec-labs.com;yunfu@ece.neu.edu,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Northeastern University;NEC-Labs;Boston University;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;Northeastern University,Graph representation learning;Graph isomorphism;Graph similarity learning,-1;-1;79;-1;-1;-1;-1;-1;-1;16,-1;-1;61;-1;-1;-1;-1;-1;-1;906,m;m,usa,usa,y,10
3047,ICLR,2020,Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach,Kimon Antonakopoulos;E. Veronica Belmega;Panayotis Mertikopoulos,kimon.antonakopoulos@inria.fr;veronica.belmega@ensea.fr;panayotis.mertikopoulos@imag.fr,8;6;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,INRIA;ETIS;French National Center for Scientific Research,Online optimization;stochastic optimization;Poisson inverse problems,-1;-1;-1,-1;-1;-1,u;u,NAN,NAN,y,9
3048,ICLR,2020,HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS,Elizabeth Dinella;Hanjun Dai;Ziyang Li;Mayur Naik;Le Song;Ke Wang,edinella@seas.upenn.edu;hadai@google.com;liby99@seas.upenn.edu;mhnaik@cis.upenn.edu;lsong@cc.gatech.edu;kewang@visa.com,6;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,University of Pennsylvania;Google;University of Pennsylvania;University of Pennsylvania;Georgia Institute of Technology;Visa Research,Bug Detection;Program Repair;Graph Neural Network;Graph Transformation,20;-1;20;20;13;-1,11;-1;11;11;38;-1,f;m,NAN,NAN,n,10
3049,ICLR,2020,Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering,Akari Asai;Kazuma Hashimoto;Hannaneh Hajishirzi;Richard Socher;Caiming Xiong,akari@cs.washington.edu;k.hashimoto@salesforce.com;hannaneh@washington.edu;richard@socher.org;cxiong@salesforce.com,6;8;6,,Accept (Poster),1,8,3.0,yes,9/25/19,University of Washington;SalesForce.com;University of Washington;SalesForce.com;SalesForce.com,Multi-hop Open-domain Question Answering;Graph-based Retrieval;Multi-step Retrieval,11;-1;11;-1;-1,26;-1;26;-1;-1,f;m,NAN,NAN,n,10
3050,ICLR,2020,Learning from Rules Generalizing Labeled Exemplars,Abhijeet Awasthi;Sabyasachi Ghosh;Rasna Goyal;Sunita Sarawagi,awasthi@cse.iitb.ac.in;sghosh@cse.iitb.ac.in;rasna.goyal66@gmail.com;sunita@iitb.ac.in,6;8;6,,Accept (Spotlight),1,5,0.0,yes,9/25/19,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;;Indian Institute of Technology Bombay,Learning from Rules;Learning from limited labeled data;Weakly Supervised Learning,-1;-1;-1;-1,480;480;-1;480,m;f,NAN,NAN,n,
3051,ICLR,2020,Mirror-Generative Neural Machine Translation,Zaixiang Zheng;Hao Zhou;Shujian Huang;Lei Li;Xin-Yu Dai;Jiajun Chen,zhengzx.142857@gmail.com;zhouhao.nlp@bytedance.com;huangsj@nju.edu.cn;lilei.02@bytedance.com;daixinyu@nju.edu.cn;chenjj@nju.edu.cn,8;8;8,,Accept (Talk),0,7,1.0,yes,9/25/19,Zhejiang University;ByteDance;Zhejiang University;ByteDance;Zhejiang University;Zhejiang University,neural machine translation;generative model;mirror,39;-1;39;-1;39;39,107;-1;107;-1;107;107,u;u,asia,cn,n,3;5
3052,ICLR,2020,Phase Transitions for the Information Bottleneck in Representation Learning,Tailin Wu;Ian Fischer,tailin@cs.stanford.edu;iansf@google.com,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Stanford University;Google,Information Theory;Representation Learning;Phase Transition,5;-1,4;-1,m;m,NAN,NAN,y,1
3053,ICLR,2020,Model-based reinforcement learning for biological sequence design,Christof Angermueller;David Dohan;David Belanger;Ramya Deshpande;Kevin Murphy;Lucy Colwell,christofa@google.com;ddohan@google.com;dbelanger@google.com;ramyadeshpande@google.com;lcolwell@google.com;kpmurphy@google.com,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,reinforcement learning;blackbox optimization;molecule design,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,5
3054,ICLR,2020,GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification,Xuwang Yin;Soheil Kolouri;Gustavo K Rohde,xy4cm@virginia.edu;skolouri@hrl.com;gustavo@virginia.edu,6;6;6,,Accept (Poster),1,5,0.0,yes,9/25/19,"University of Virginia;HRL Laboratories, LLC;University of Virginia",adversarial example detection;adversarial examples classification;robust optimization;ML security;generative modeling;generative classification,52;-1;52,107;-1;107,m;m,usa,usa,n,5;4
3055,ICLR,2020,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding,Wei Wang;Bin Bi;Ming Yan;Chen Wu;Jiangnan Xia;Zuyi Bao;Liwei Peng;Luo Si,hebian.ww@alibaba-inc.com;b.bi@alibaba-inc.com;ym119608@alibaba-inc.com;wuchen.wc@alibaba-inc.com;jiangnan.xjn@alibaba-inc.com;zuyi.bzy@alibaba-inc.com;liwei.peng@alibaba-inc.com;luo.si@alibaba-inc.com,3;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,8;3
3056,ICLR,2020,Restricting the Flow: Information Bottlenecks for Attribution,Karl Schulz;Leon Sixt;Federico Tombari;Tim Landgraf,karl.schulz@tum.de;leon.sixt@fu-berlin.de;tombari@in.tum.de;tim.landgraf@fu-berlin.de,8;8;8,,Accept (Talk),1,4,2.0,yes,9/25/19,Technical University Munich;Freie Universit√§t Berlin;Technical University Munich;Freie Universit√§t Berlin,Attribution;Informational Bottleneck;Interpretable Machine Learning;Explainable AI,-1;316;-1;316,-1;-1;-1;-1,m;m,europe,de,n,
3057,ICLR,2020,Oblique Decision Trees from Derivatives of ReLU Networks,Guang-He Lee;Tommi S. Jaakkola,guanghe@csail.mit.edu;tommi@csail.mit.edu,3;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,oblique decision trees;ReLU networks,5;5,5;5,m;m,usa,usa,y,
3058,ICLR,2020,DBA: Distributed Backdoor Attacks against Federated Learning,Chulin Xie;Keli Huang;Pin-Yu Chen;Bo Li,chulinxie@zju.edu.cn;nick_cooper@sjtu.edu.cn;pin-yu.chen@ibm.com;lbo@illinois.edu,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"Zhejiang University;Shanghai Jiao Tong University;International Business Machines;University of Illinois, Urbana Champaign",distributed backdoor attack;federated learning,39;30;-1;-1,107;157;-1;-1,f;f,usa,usa,n,4
3059,ICLR,2020,Understanding and Improving Information Transfer in Multi-Task Learning,Sen Wu;Hongyang R. Zhang;Christopher R√©,senwu@cs.stanford.edu;hongyang@cs.stanford.edu;chrismre@stanford.edu,6;6;8,,Accept (Poster),0,6,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University,Multi-Task Learning,5;5;5,4;4;4,m;m,usa,usa,y,6;1
3060,ICLR,2020,FSPool: Learning Set Representations with Featurewise Sort Pooling,Yan Zhang;Jonathon Hare;Adam Pr√ºgel-Bennett,yz5n12@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,6;8;8,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Southampton;University of Southampton;University of Southampton,set auto-encoder;set encoder;pooling,194;194;194,122;122;122,u;m,europe,uk,n,
3061,ICLR,2020,Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning,Ruqi Zhang;Chunyuan Li;Jianyi Zhang;Changyou Chen;Andrew Gordon Wilson,rz297@cornell.edu;chunyuan.li@duke.edu;jz318@duke.edu;cchangyou@gmail.com;andrewgw@cims.nyu.edu,8;8;6,,Accept (Talk),0,5,0.0,yes,9/25/19,"Cornell University;Duke University;Duke University;State University of New York, Buffalo;New York University",,7;46;46;-1;22,19;20;20;-1;29,f;m,usa,usa,y,11;1
3062,ICLR,2020,RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments,Roberta Raileanu;Tim Rockt√§schel,raileanu@cs.nyu.edu;tim.rocktaeschel@gmail.com,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,New York University;Facebook AI Research,reinforcement learning;exploration;curiosity,22;-1,29;-1,f;m,NAN,NAN,n,
3063,ICLR,2020,Counterfactuals uncover the modular structure of deep generative models,Michel Besserve;Arash Mehrjou;R√©my Sun;Bernhard Sch√∂lkopf,michel.besserve@tuebingen.mpg.de;mehrjou.arash@gmail.com;remy.sun@ens-rennes.fr;bs@tuebingen.mpg.de,8;8;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Ecole Normale Superieure de Rennes;Max-Planck Institute,generative models;causality;counterfactuals;representation learning;disentanglement;generalization;unsupervised learning,-1;-1;445;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,5
3064,ICLR,2020,Neural Machine Translation with Universal Visual Representation,Zhuosheng Zhang;Kehai Chen;Rui Wang;Masao Utiyama;Eiichiro Sumita;Zuchao Li;Hai Zhao,zhangzs@sjtu.edu.cn;khchen@nict.go.jp;wangrui@nict.go.jp;mutiyama@nict.go.jp;eiichiro.sumita@nict.go.jp;charlee@sjtu.edu.cn;zhaohai@cs.sjtu.edu.cn,6;8;6,,Accept (Spotlight),1,4,0.0,yes,9/25/19,"Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Neural Machine Translation;Visual Representation;Multimodal Machine Translation;Language Representation,30;-1;-1;-1;-1;30;30,157;-1;-1;-1;-1;157;157,m;m,asia,cn,n,8;3
3065,ICLR,2020,Once-for-All: Train One Network and Specialize it for Efficient Deployment,Han Cai;Chuang Gan;Tianzhe Wang;Zhekai Zhang;Song Han,hancai@mit.edu;ganchuang1990@gmail.com;usedtobe@mit.edu;zhangzk@mit.edu;songhan@mit.edu,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Efficient Deep Learning;Specialized Neural Network Architecture;AutoML,5;-1;5;5;5,5;-1;5;5;5,m;m,usa,usa,n,2
3066,ICLR,2020,Learning Nearly Decomposable Value Functions Via Communication Minimization,Tonghan Wang*;Jianhao Wang*;Chongyi Zheng;Chongjie Zhang,tonghanwang1996@gmail.com;1040594377@qq.com;chongyeezheng@gmail.com;chongjie@tsinghua.edu.cn,3;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Carnegie Mellon University;Tsinghua University, Tsinghua University",Multi-agent reinforcement learning;Nearly decomposable value function;Minimized communication;Multi-agent systems,4;4;1;4,23;23;27;23,m;m,NAN,NAN,n,
3067,ICLR,2020,Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,Pu Zhao;Pin-Yu Chen;Payel Das;Karthikeyan Natesan Ramamurthy;Xue Lin,zhao.pu@husky.neu.edu;pin-yu.chen@ibm.com;daspa@us.ibm.com;knatesa@us.ibm.com;xue.lin@northeastern.edu,8;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Northeastern University;International Business Machines;International Business Machines;International Business Machines;Northeastern University,mode connectivity;adversarial robustness;backdoor attack;error-injection attack;evasion attacks;loss landscapes,16;-1;-1;-1;16,906;-1;-1;-1;906,m;f,usa,usa,y,4
3068,ICLR,2020,The Break-Even Point on Optimization Trajectories of Deep Neural Networks,Stanislaw Jastrzebski;Maciej Szymczak;Stanislav Fort;Devansh Arpit;Jacek Tabor;Kyunghyun Cho*;Krzysztof Geras*,staszek.jastrzebski@gmail.com;msz93@o2.pl;stanislav.fort@gmail.com;devansharpit@gmail.com;jcktbr@gmail.com;kyunghyun.cho@nyu.edu;k.j.geras@nyu.edu,6;8;6,,Accept (Spotlight),1,7,0.0,yes,9/25/19,Jagiellonian University;Jagiellonian University;Stanford University;SalesForce.com;Jagiellonian University;New York University;New York University,generalization;sgd;learning rate;batch size;hessian;curvature;trajectory;optimization,-1;-1;5;-1;-1;22;22,610;610;4;-1;610;29;29,m;m,usa,usa,y,1
3069,ICLR,2020,Empirical Studies on the Properties of Linear Regions in Deep Neural Networks,Xiao Zhang;Dongrui Wu,xiao_zhang@hust.edu.cn;drwu@hust.edu.cn,6;3;8,,Accept (Poster),2,6,0.0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,deep learning;linear region;optimization,-1;-1,47;47,m;m,NAN,NAN,n,
3070,ICLR,2020,Learning Compositional Koopman Operators for Model-Based Control,Yunzhu Li;Hao He;Jiajun Wu;Dina Katabi;Antonio Torralba,liyunzhu@mit.edu;haohe@mit.edu;jiajunwu.cs@gmail.com;dina@csail.mit.edu;torralba@csail.mit.edu,6;8;6;6,,Accept (Spotlight),0,7,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Stanford University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Koopman operators;graph neural networks;compositionality,5;5;5;5;5,5;5;4;5;5,m;m,usa,usa,n,1;10
3071,ICLR,2020,Meta-Learning without Memorization,Mingzhang Yin;George Tucker;Mingyuan Zhou;Sergey Levine;Chelsea Finn,mzyin@utexas.edu;gjt@google.com;mingyuan.zhou@mccombs.utexas.edu;svlevine@eecs.berkeley.edu;cbfinn@cs.stanford.edu,6;8;8,,Accept (Spotlight),0,5,1.0,yes,9/25/19,"University of Texas, Austin;Google;University of Texas, Austin;University of California Berkeley;Stanford University",meta-learning;memorization;regularization;overfitting;mutually-exclusive,-1;-1;-1;-1;5,-1;-1;-1;13;4,m;f,usa,usa,y,6;1
3072,ICLR,2020,Guiding Program Synthesis by Learning to Generate Examples,Larissa Laich;Pavol Bielik;Martin Vechev,llaich@ethz.ch;pavol.bielik@inf.ethz.ch;martin.vechev@inf.ethz.ch,8;3;8,,Accept (Poster),0,9,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,program synthesis;programming by examples,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,
3073,ICLR,2020,Truth or backpropaganda? An empirical investigation of deep learning theory,Micah Goldblum;Jonas Geiping;Avi Schwarzschild;Michael Moeller;Tom Goldstein,goldblumcello@gmail.com;jonas.geiping@uni-siegen.de;avi1@umd.edu;michael.moeller@uni-siegen.de;tomg@cs.umd.edu,8;8;6,,Accept (Spotlight),3,4,0.0,yes,9/25/19,"University of Maryland, College Park;University of Siegen;University of Maryland, College Park;University of Siegen;University of Maryland, College Park",Deep learning;generalization;loss landscape;robustness,-1;316;12;316;12,-1;570;91;570;91,m;m,usa,usa,y,1
3074,ICLR,2020,What Can Neural Networks Reason About?,Keyulu Xu;Jingling Li;Mozhi Zhang;Simon S. Du;Ken-ichi Kawarabayashi;Stefanie Jegelka,keyulu@mit.edu;jingling@cs.umd.edu;mozhi@cs.umd.edu;ssdu@ias.edu;k_keniti@nii.ac.jp;stefje@mit.edu,8;8;6,,Accept (Spotlight),0,10,0.0,yes,9/25/19,"Massachusetts Institute of Technology;University of Maryland, College Park;University of Maryland, College Park;Institue for Advanced Study, Princeton;National Institute of Informatics;Massachusetts Institute of Technology",reasoning;deep learning theory;algorithmic alignment;graph neural networks,5;12;12;-1;-1;5,5;91;91;-1;-1;5,f;f,usa,usa,y,1;10
3075,ICLR,2020,U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation,Junho Kim;Minjae Kim;Hyeonwoo Kang;Kwang Hee Lee,takis0112@gmail.com;minjaekim@ncsoft.com;hwkang0131@ncsoft.com;lkwanghee@gmail.com,8;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,NAVER;NCSOFT;NCSOFT;Boeing Korea Engineering and Technology Center,Image-to-Image Translation;Generative Attentional Networks;Adaptive Layer-Instance Normalization,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8
3076,ICLR,2020,Learning to Learn by Zeroth-Order Oracle,Yangjun Ruan;Yuanhao Xiong;Sashank Reddi;Sanjiv Kumar;Cho-Jui Hsieh,ruanyj3107@zju.edu.cn;yhxiong@cs.ucla.edu;sashank@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,"Zhejiang University;University of California, Los Angeles;Google;Google;University of California, Los Angeles",learning to learn;zeroth-order optimization;black-box adversarial attack,39;-1;-1;-1;-1,107;17;-1;-1;17,m;m,usa,usa,n,9;4
3077,ICLR,2020,Lite Transformer with Long-Short Range Attention,Zhanghao Wu*;Zhijian Liu*;Ji Lin;Yujun Lin;Song Han,zhanghao.wu@outlook.com;zhijian@mit.edu;jilin@mit.edu;yujunlin@mit.edu;songhan@mit.edu,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of California Berkeley;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,efficient model;transformer,-1;5;5;5;5,13;5;5;5;5,m;m,usa,usa,n,8;3
3078,ICLR,2020,Regularizing activations in neural networks via distribution matching with the Wasserstein metric,Taejong Joo;Donggu Kang;Byunghoon Kim,tjoo@estsoft.com;emppunity@gmail.com;byungkim@hanyang.ac.kr,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,ESTsoft;;Hanyang University,regularization;Wasserstein metric;deep learning,-1;-1;194,-1;-1;393,m;u,asia,kr,n,3;1
3079,ICLR,2020,The Ingredients of Real World Robotic Reinforcement Learning,Henry Zhu;Justin Yu;Abhishek Gupta;Dhruv Shah;Kristian Hartikainen;Avi Singh;Vikash Kumar;Sergey Levine,henryzhu@berkeley.edu;justinvyu@berkeley.edu;abhigupta@berkeley.edu;shah@eecs.berkeley.edu;kristian.hartikainen@gmail.com;avisingh@cs.berkeley.edu;vikashplus@gmail.com;svlevine@eecs.berkeley.edu,8;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Oxford;University of California Berkeley;Facebook;University of California Berkeley,Reinforcement Learning;Robotics,-1;-1;-1;-1;46;-1;-1;-1,13;13;13;13;1;13;-1;13,m;m,usa,usa,n,
3080,ICLR,2020,Relational State-Space Model for Stochastic Multi-Object Systems,Fan Yang;Ling Chen;Fan Zhou;Yusong Gao;Wei Cao,fanyang01@zju.edu.cn;lingchen@cs.zju.edu.cn;fanzhou@zju.edu.cn;jianchuan.gys@alibaba-inc.com;mingsong.cw@alibaba-inc.com,6;3;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Alibaba Group;Alibaba Group,state-space model;time series;deep sequential model;graph neural network,39;39;39;-1;-1,107;107;107;-1;-1,m;m,NAN,NAN,n,10
3081,ICLR,2020,Empirical Bayes Transductive Meta-Learning with Synthetic Gradients,Shell Xu Hu;Pablo Garcia Moreno;Yang Xiao;Xi Shen;Guillaume Obozinski;Neil Lawrence;Andreas Damianou,dom343@gmail.com;morepabl@amazon.com;yang.xiao@enpc.fr;xi.shen@enpc.fr;guillaume.obozinski@epfl.ch;n.lawrence@sheffield.ac.uk;damianou@amazon.com,6;6;6,,Accept (Poster),0,5,1.0,yes,9/25/19,Ecole des Ponts ParisTech;Amazon;ENPC;ENPC;Swiss Federal Institute of Technology Lausanne;University of Sheffield;Amazon,Meta-learning;Empirical Bayes;Synthetic Gradient;Information Bottleneck,-1;-1;-1;-1;-1;194;-1,-1;-1;-1;-1;-1;117;-1,m;m,NAN,NAN,y,6;1
3082,ICLR,2020,Implicit Bias of Gradient Descent based Adversarial Training on Separable Data,Yan Li;Ethan X.Fang;Huan Xu;Tuo Zhao,yli939@gatech.edu;xxf13@psu.edu;huan.xu@isye.gatech.edu;tourzhao@gatech.edu,3;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Georgia Institute of Technology;Pennsylvania State University;Georgia Institute of Technology;Georgia Institute of Technology,implicit bias;adversarial training;robustness;gradient descent,13;43;13;13,38;-1;38;38,u;m,usa,usa,y,4
3083,ICLR,2020,word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement,Aliakbar Panahi;Seyran Saeedi;Tom Arodz,panahia@vcu.edu;saeedis@vcu.edu;tarodz@vcu.edu,8;8;3,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Virginia Commonwealth University;Virginia Commonwealth University;Virginia Commonwealth University,word embeddings;natural language processing;model reduction,248;248;248,-1;-1;-1,m;m,usa,usa,n,3
3084,ICLR,2020,Towards Fast Adaptation of Neural Architectures with Meta Learning,Dongze Lian;Yin Zheng;Yintao Xu;Yanxiong Lu;Leyu Lin;Peilin Zhao;Junzhou Huang;Shenghua Gao,liandz@shanghaitech.edu.cn;yzheng3xg@gmail.com;xuyt@shanghaitech.edu.cn;alanlu@tencent.com;goshawklin@tencent.com;masonzhao@tencent.com;jzhuang@uta.edu;gaoshh@shanghaitech.edu.cn,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"ShanghaiTech University;Tencent AI Lab;ShanghaiTech University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;University of Texas, Arlington;ShanghaiTech University",Fast adaptation;Meta learning;NAS,316;-1;316;-1;-1;-1;-1;316,-1;-1;-1;-1;-1;-1;-1;-1,m;m,asia,cn,n,6
3085,ICLR,2020,Hamiltonian Generative Networks,Peter Toth;Danilo J. Rezende;Andrew Jaegle;S√©bastien Racani√®re;Aleksandar Botev;Irina Higgins,petertoth@google.com;danilor@google.com;drewjaegle@google.com;sracaniere@google.com;botev@google.com;irinah@google.com,6;6;8,,Accept (Spotlight),0,9,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Hamiltonian dynamics;normalising flows;generative model;physics,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,5
3086,ICLR,2020,Residual Energy-Based Models for Text Generation,Yuntian Deng;Anton Bakhtin;Myle Ott;Arthur Szlam;Marc'Aurelio Ranzato,dengyuntian@seas.harvard.edu;yolo@fb.com;aszlam@fb.com;ranzato@fb.com,6;6;6,,Accept (Poster),0,3,1.0,yes,9/25/19,Harvard University;Facebook;Facebook;Facebook,energy-based models;text generation,52;-1;-1;-1,7;-1;-1;-1,m;m,NAN,NAN,y,3
3087,ICLR,2020,Plug and Play Language Models: A Simple Approach to Controlled Text Generation,Sumanth Dathathri;Andrea Madotto;Janice Lan;Jane Hung;Eric Frank;Piero Molino;Jason Yosinski;Rosanne Liu,dathathris@gmail.com;amadotto@connect.ust.hk;lan.janice.j@gmail.com;jane.hung@uber.com;mysterefrank@uber.com;piero@uber.com;yosinski@uber.com;rosanne@uber.com,6;3;6,,Accept (Poster),6,7,1.0,yes,9/25/19,California Institute of Technology;The Hong Kong University of Science and Technology;Facebook;Uber;Uber;Uber;Uber;Uber,controlled text generation;generative models;conditional generative models;language modeling;transformer,-1;-1;-1;-1;-1;-1;-1;-1,-1;47;-1;-1;-1;-1;-1;-1,m;f,southamerica,br,n,8;3
3088,ICLR,2020,"Deep 3D Pan via local adaptive t-shaped"" convolutions with global and local adaptive dilations""",Juan Luis Gonzalez Bello;Munchurl Kim,juanluisgb@kaist.ac.kr;mkimee@kaist.ac.kr,6;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Deep learning;Stereoscopic view synthesis;Monocular depth;Deep 3D Pan,-1;-1,110;110,m;m,NAN,NAN,n,1
3089,ICLR,2020,Conservative Uncertainty Estimation By Fitting  Prior Networks,Kamil Ciosek;Vincent Fortuin;Ryota Tomioka;Katja Hofmann;Richard Turner,kamil.ciosek@microsoft.com;fortuin@inf.ethz.ch;ryoto@microsoft.com;katja.hofmann@microsoft.com;ret26@cam.ac.uk,6;6;6,,Accept (Poster),2,13,0.0,yes,9/25/19,Microsoft;Swiss Federal Institute of Technology;Microsoft;Microsoft;University of Cambridge,uncertainty quantification;deep learning;Gaussian process;epistemic uncertainty;random network;prior;Bayesian inference,-1;-1;-1;-1;79,-1;-1;-1;-1;3,m;m,europe,uk,y,2;11
3090,ICLR,2020,Dynamics-Aware Unsupervised Discovery of Skills,Archit Sharma;Shixiang Gu;Sergey Levine;Vikash Kumar;Karol Hausman,architsh@google.com;shanegu@google.com;slevine@google.com;vikashplus@google.com;karolhausman@google.com,8;8;8,,Accept (Talk),0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google,reinforcement learning;unsupervised learning;model-based learning;deep learning;hierarchical reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6
3091,ICLR,2020,Implementation Matters in Deep RL: A Case Study on PPO and TRPO,Logan Engstrom;Andrew Ilyas;Shibani Santurkar;Dimitris Tsipras;Firdaus Janoos;Larry Rudolph;Aleksander Madry,ailyas@mit.edu;engstrom@mit.edu;shibani@mit.edu;tsipras@mit.edu;firdaus.janoos@twosigma.com;rudolph@csail.mit.edu;madry@mit.edu,8;8;8,,Accept (Talk),0,10,2.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Two Sigma;Massachusetts Institute of Technology;Massachusetts Institute of Technology,deep policy gradient methods;deep reinforcement learning;trpo;ppo,5;5;5;5;-1;5;5,5;5;5;5;-1;5;5,m;m,usa,usa,n,
3092,ICLR,2020,Mutual Information Gradient Estimation for  Representation Learning,Liangjian Wen;Yiji Zhou;Lirong He;Mingyuan Zhou;Zenglin Xu,wlj6816@gmail.com;zhouyiji@outlook.com;ronghe1217@gmail.com;mingyuan.zhou@mccombs.utexas.edu;zenglin@gmail.com,8;6;3;6,,Accept (Poster),0,14,0.0,yes,9/25/19,"Huawei Technologies Ltd.;;University of Electronic Science and Technology of China;University of Texas, Austin;Harbin Institute of Technology",Mutual Information;Score Estimation;Representation Learning;Information Bottleneck,-1;-1;-1;-1;168,-1;-1;628;-1;424,u;m,asia,cn,n,
3093,ICLR,2020,Minimizing FLOPs to Learn Efficient Sparse Representations,Biswajit Paria;Chih-Kuan Yeh;Ian E.H. Yen;Ning Xu;Pradeep Ravikumar;Barnab√°s P√≥czos,bparia@cs.cmu.edu;cjyeh@cs.cmu.edu;a061105@gmail.com;ningxu01@gmail.com;pradeepr@cs.cmu.edu;bapoczos@cs.cmu.edu,8;3;8,,Accept (Poster),0,7,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;;Amazon;Carnegie Mellon University;Carnegie Mellon University,sparse embeddings;deep representations;metric learning;regularization,1;1;-1;-1;1;1,27;27;-1;-1;27;27,m;m,usa,usa,y,
3094,ICLR,2020,Data-Independent Neural Pruning via Coresets,Ben Mussay;Margarita Osadchy;Vladimir Braverman;Samson Zhou;Dan Feldman,bengordoncshaifa@gmail.com;rita@cs.haifa.ac.il;vova@cs.jhu.edu;samsonzhou@gmail.com;dannyf.post@gmail.co,8;3;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Haifa;University of Haifa;Johns Hopkins University;Carnegie Mellon University;Massachusetts Institute of Technology,coresets;neural pruning;network compression,-1;194;73;1;-1,-1;544;12;27;-1,m;m,asia,in,y,4
3095,ICLR,2020,LEARNED STEP SIZE QUANTIZATION,Steven K. Esser;Jeffrey L. McKinstry;Deepika Bablani;Rathinakumar Appuswamy;Dharmendra S. Modha,sesser@us.ibm.com;jlmckins@us.ibm.com;deepika.bablani@ibm.com;rappusw@us.ibm.com;dmodha@us.ibm.com,6;8;6,,Accept (Poster),0,4,1.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,deep learning;low precision;classification;quantization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3096,ICLR,2020,Learning To Explore Using Active Neural SLAM,Devendra Singh Chaplot;Dhiraj Gandhi;Saurabh Gupta;Abhinav Gupta;Ruslan Salakhutdinov,chaplot@cs.cmu.edu;dhirajgandhi@fb.com;saurabhg@illinois.edu;abhinavg@cs.cmu.edu;rsalakhu@cs.cmu.edu,6;3;8,,Accept (Poster),0,5,0.0,yes,9/25/19,"Carnegie Mellon University;Facebook;University of Illinois, Urbana Champaign;Carnegie Mellon University;Carnegie Mellon University",Navigation;Exploration,1;-1;-1;1;1,27;-1;-1;27;27,m;m,usa,usa,n,
3097,ICLR,2020,Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization,Junjie Yan;Ruosi Wan;Xiangyu Zhang;Wei Zhang;Yichen Wei;Jian Sun,jjyan17@fudan.edu.cn;wanruosi@megvii.com;zhangxiangyu@megvii.com;weizh@fudan.edu.cn;weiyichen@megvii.com;sunjian@megvii.com,6;6;8,,Accept (Poster),0,3,1.0,yes,9/25/19,Fudan University;Megvii Technology Inc.;Megvii Technology Inc.;Fudan University;Megvii Technology Inc.;Megvii Technology Inc.,batch normalization;small batch size;backward propagation,73;-1;-1;73;-1;-1,109;-1;-1;109;-1;-1,m;m,NAN,NAN,y,2;1
3098,ICLR,2020,Tensor Decompositions for Temporal Knowledge Base Completion,Timoth√©e Lacroix;Guillaume Obozinski;Nicolas Usunier,timothee.lax@gmail.com;guillaume.obozinski@epfl.ch;usunier@fb.com,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Facebook;Swiss Federal Institute of Technology Lausanne;Facebook,knowledge base completion;temporal embeddings,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
3099,ICLR,2020,Generalization bounds for deep convolutional neural networks,Philip M. Long;Hanie Sedghi,plong@google.com;hsedghi@google.com,6;3;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Google;Google,generalization;convolutional networks;statistical learning theory,-1;-1,-1;-1,m;f,NAN,NAN,y,1
3100,ICLR,2020,Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples,Eleni Triantafillou;Tyler Zhu;Vincent Dumoulin;Pascal Lamblin;Utku Evci;Kelvin Xu;Ross Goroshin;Carles Gelada;Kevin Swersky;Pierre-Antoine Manzagol;Hugo Larochelle,eleni@cs.toronto.edu;tylerzhu@google.com;vdumoulin@google.com;lamblinp@google.com;evcu@google.com;kelvinxu@berkeley.edu;goroshin@google.com;cgel@google.com;kswersky@google.com;manzagop@google.com;hugolarochelle@google.com,3;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,University of Toronto;Google;Google;Google;Google;University of California Berkeley;Google;Google;Google;Google;Google,few-shot learning;meta-learning;few-shot classification,18;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,18;-1;-1;-1;-1;13;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,6;1
3101,ICLR,2020,Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings,Shweta Mahajan;Iryna Gurevych;Stefan Roth,mahajan@aiphes.tu-darmstadt.de;gurevych@ukp.informatik.tu-darmstadt.de;stefan.roth@visinf.tu-darmstadt.de,8;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,TU Darmstadt;TU Darmstadt;TU Darmstadt,,59;59;59,-1;-1;-1,f;m,europe,de,n,5
3102,ICLR,2020,Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution,Nikaash Puri;Sukriti Verma;Piyush Gupta;Dhruv Kayastha;Shripad Deshmukh;Balaji Krishnamurthy;Sameer Singh,nikpuri@adobe.com;dce.sukriti@gmail.com;piygupta@adobe.com;dhruvkayastha@iitkgp.ac.in;shripad@smail.iitm.ac.in;kbalaji@adobe.com;sameer@uci.edu,8;6;8,,Accept (Poster),0,11,1.0,yes,9/25/19,"Adobe Systems;Adobe Systems;Adobe Systems;Indian Institute of Technology Kharagpur;Indian Institute of Technology Madras;Adobe Systems;University of California, Irvine",Deep Reinforcement Learning;Saliency maps;Chess;Go;Atari;Interpretable AI;Explainable AI,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;476;641;-1;96,m;m,usa,usa,n,
3103,ICLR,2020,AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing     ,Xingzhe He;Helen Lu Cao;Bo Zhu,xingzhe.he95@gmail.com;helen.l.cao.22@dartmouth.edu;bo.zhu@dartmouth.edu,6;6;6,,Accept (Poster),0,1,1.0,yes,9/25/19,University of British Columbia;Dartmouth College;Dartmouth College,Point Cloud Processing;Physical Reservoir Learning;Eulerian-Lagrangian Method;PIC/FLIP,-1;168;168,-1;94;94,m;m,usa,usa,n,2
3104,ICLR,2020,Batch-shaping for learning conditional channel gated networks,Babak Ehteshami Bejnordi;Tijmen Blankevoort;Max Welling,behtesha@qti.qualcomm.com;tijmen@qti.qualcomm.com;mwelling@qti.qualcomm.com,8;6;6,,Accept (Poster),1,3,0.0,yes,9/25/19,"Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",Conditional computation;channel gated networks;gating;Batch-shaping;distribution matching;image classification;semantic segmentation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2
3105,ICLR,2020,A Closer Look at Deep Policy Gradients,Andrew Ilyas;Logan Engstrom;Shibani Santurkar;Dimitris Tsipras;Firdaus Janoos;Larry Rudolph;Aleksander Madry,ailyas@mit.edu;engstrom@mit.edu;shibani@mit.edu;tsipras@mit.edu;firdaus.janoos@twosigma.com;rudolph@csail.mit.edu;madry@mit.edu,8;6;8,,Accept (Talk),0,3,1.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Two Sigma;Massachusetts Institute of Technology;Massachusetts Institute of Technology,deep policy gradient methods;deep reinforcement learning;trpo;ppo,5;5;5;5;-1;5;5,5;5;5;5;-1;5;5,m;m,usa,usa,n,
3106,ICLR,2020,Provable robustness against all adversarial $l_p$-perturbations for $p\geq 1$,Francesco Croce;Matthias Hein,francesco91.croce@gmail.com;matthias.hein@uni-tuebingen.de,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Tuebingen;University of Tuebingen,adversarial robustness;provable guarantees,143;143,91;91,m;m,europe,de,y,4
3107,ICLR,2020,Distributionally Robust Neural Networks,Shiori Sagawa*;Pang Wei Koh*;Tatsunori B. Hashimoto;Percy Liang,ssagawa@cs.stanford.edu;koh.pangwei@gmail.com;thashim@stanford.edu;pliang@cs.stanford.edu,8;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Stanford University;;Stanford University;Stanford University,distributionally robust optimization;deep learning;robustness;generalization;regularization,5;-1;5;5,4;-1;4;4,f;m,usa,usa,y,3;1
3108,ICLR,2020,Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks,Jiadong Lin;Chuanbiao Song;Kun He;Liwei Wang;John E. Hopcroft,jdlin@hust.edu.cn;cbsong@hust.edu.cn;brooklet60@hust.edu.cn;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Peking University;Cornell University,adversarial examples;adversarial attack;transferability;Nesterov accelerated gradient;scale invariance,-1;-1;-1;14;7,47;47;47;24;19,m;m,usa,usa,n,4
3109,ICLR,2020,Fast Neural Network Adaptation via Parameter Remapping and Architecture Search,Jiemin Fang*;Yuzhu Sun*;Kangjian Peng*;Qian Zhang;Yuan Li;Wenyu Liu;Xinggang Wang,jaminfong@hust.edu.cn;yzsun@hust.edu.cn;kangjian.peng@horizon.ai;qian01.zhang@horizon.ai;yuan.li@horizon.ai;liuwy@hust.edu.cn;xgwang@hust.edu.cn,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Horizon Robotics;Horizon Robotics;Horizon Robotics;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,,-1;-1;-1;-1;-1;-1;-1,47;47;-1;-1;-1;47;47,m;m,NAN,NAN,n,2
3110,ICLR,2020,Understanding Generalization in Recurrent Neural Networks,Zhuozhuo Tu;Fengxiang He;Dacheng Tao,zhtu3055@uni.sydney.edu.au;fengxiang.he@sydney.edu.au;dacheng.tao@sydney.edu.au,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney,generalization;recurrent neural networks;learning theory,64;64;64,60;60;60,u;m,europe,uk,y,1
3111,ICLR,2020,Piecewise linear activations substantially shape the loss surfaces of neural networks,Fengxiang He;Bohan Wang;Dacheng Tao,fengxiang.he@sydney.edu.au;bhwangfy@gmail.com;dacheng.tao@sydney.edu.au,6;6;3,,Accept (Poster),0,19,0.0,yes,9/25/19,University of Sydney;Microsoft;University of Sydney,neural network;nonlinear activation;loss surface;spurious local minimum,64;-1;64,60;-1;60,m;m,europe,uk,y,1
3112,ICLR,2020,Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,Samuel Humeau;Kurt Shuster;Marie-Anne Lachaux;Jason Weston,samuelhumeau@fb.com;kshuster@fb.com;malachaux@fb.com;jaseweston@gmail.com,8;8;6,,Accept (Poster),0,1,0.0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n,8
3113,ICLR,2020,Understanding the Limitations of Variational Mutual Information Estimators,Jiaming Song;Stefano Ermon,jiaming.tsong@gmail.com;ermon@cs.stanford.edu,6;6;6,,Accept (Poster),0,0,0.0,yes,9/25/19,Stanford University;Stanford University,,5;5,4;4,m;m,usa,usa,y,
3114,ICLR,2020,A Baseline for Few-Shot Image Classification,Guneet Singh Dhillon;Pratik Chaudhari;Avinash Ravichandran;Stefano Soatto,guneetdhillon@utexas.edu;pratikac@seas.upenn.edu;avinash.a.ravichandran@gmail.com;soattos@amazon.com,6;6;6,,Accept (Poster),0,5,2.0,yes,9/25/19,"University of Texas, Austin;University of Pennsylvania;Amazon;Amazon",few-shot learning;transductive learning;fine-tuning;baseline;meta-learning,-1;20;-1;-1,-1;11;-1;-1,m;m,NAN,NAN,n,6
3115,ICLR,2020,Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation,Suraj Nair;Chelsea Finn,surajn@stanford.edu;chelseaf@google.com,6;6,,Accept (Poster),1,2,0.0,yes,9/25/19,Stanford University;Google,video prediction;reinforcement learning;planning,5;-1,4;-1,m;f,NAN,NAN,n,
3116,ICLR,2020,Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving,Yurong You;Yan Wang;Wei-Lun Chao;Divyansh Garg;Geoff Pleiss;Bharath Hariharan;Mark Campbell;Kilian Q. Weinberger,yy785@cornell.edu;yw763@cornell.edu;weilunchao760414@gmail.com;dg595@cornell.edu;gp346@cornell.edu;bharathh@cs.cornell.edu;mc288@cornell.edu;kqw4@cornell.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Cornell University;Cornell University;Ohio State University;Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,pseudo-LiDAR;3D-object detection;stereo depth estimation;autonomous driving,7;7;59;7;7;7;7;7,19;19;70;19;19;19;19;19,m;m,usa,usa,n,2
3117,ICLR,2020,V4D: 4D Convolutional Neural Networks for Video-level Representation Learning,Shiwen Zhang;Sheng Guo;Weilin Huang;Matthew R. Scott;Limin Wang,shizhang@malong.com;sheng@malong.com;whuang@malong.com;mscott@malong.com;07wanglimin@gmail.com,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Malong Technologies;Malong Technologies;Malong Technologies;Malong Technologies;Zhejiang University,video-level representation learning;video action recognition;4D CNNs,-1;-1;-1;-1;39,-1;-1;-1;-1;107,u;m,asia,cn,n,
3118,ICLR,2020,Certified Defenses for Adversarial Patches,Ping-yeh Chiang*;Renkun Ni*;Ahmed Abdelkader;Chen Zhu;Christoph Studor;Tom Goldstein,pchiang@cs.umd.edu;rn9zm@cs.umd.edu;akader@cs.umd.edu;chenzhu@cs.umd.edu;studer@cornell.edu;tomg@cs.umd.edu,6;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Cornell University;University of Maryland, College Park",certified defenses;patch attack;adversarial robustness;sparse defense,12;12;12;12;7;12,91;91;91;91;19;91,m;m,usa,usa,n,2;4
3119,ICLR,2020,Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation,Byung Hoon Ahn;Prannoy Pilligundla;Amir Yazdanbakhsh;Hadi Esmaeilzadeh,bhahn@eng.ucsd.edu;ppilligu@eng.ucsd.edu;ayazdan@google.com;hadi@eng.ucsd.edu,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;Google;University of California, San Diego",Reinforcement Learning;Learning to Optimize;Combinatorial Optimization;Compilers;Code Optimization;Neural Networks;ML for Systems;Learning for Systems,-1;-1;-1;-1,31;31;-1;31,m;m,usa,usa,n,
3120,ICLR,2020,Semantically-Guided Representation Learning for Self-Supervised Monocular Depth,Vitor Guizilini;Rui Hou;Jie Li;Rares Ambrus;Adrien Gaidon,vitor.guizilini@tri.global;rayhou@umich.edu;jie.li@tri.global;rares.ambrus@tri.global;adrien.gaidon@tri.global,6;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Toyota Research Institute;University of Michigan;Toyota Research Institute;Toyota Research Institute;Toyota Research Institute,computer vision;machine learning;deep learning;monocular depth estimation;self-supervised learning,-1;7;-1;-1;-1,-1;21;-1;-1;-1,m;m,NAN,NAN,n,2
3121,ICLR,2020,Target-Embedding Autoencoders for Supervised Representation Learning,Daniel Jarrett;Mihaela van der Schaar,daniel.jarrett@eng.ox.ac.uk;mv472@damtp.cam.ac.uk,8;6;6;8,,Accept (Talk),0,19,0.0,yes,9/25/19,University of Oxford;University of Cambridge,autoencoders;supervised learning;representation learning;target-embedding;label-embedding,46;79,1;3,m;f,europe,uk,y,1
3122,ICLR,2020,MetaPix: Few-Shot Video Retargeting,Jessica Lee;Deva Ramanan;Rohit Girdhar,jl5@cs.cmu.edu;deva@cs.cmu.edu;rgirdhar@cs.cmu.edu,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Meta-learning;Few-shot Learning;Generative Adversarial Networks;Video Retargeting,1;1;1,27;27;27,f;m,usa,usa,n,6;5
3123,ICLR,2020,Lazy-CFR: fast and near-optimal regret minimization for extensive games with imperfect information,Yichi Zhou;Tongzheng Ren;Jialian Li;Dong Yan;Jun Zhu,vofhqn@gmail.com;rtz19970824@gmail.com;lijialia16@mails.tsinghua.edu.cn;sproblvem@gmail.com;dcszj@mail.tsinghua.edu.cn,8;8;3,,Accept (Poster),0,5,0.0,yes,9/25/19,"Tsinghua University;;Tsinghua University, Tsinghua University;;Tsinghua University",,-1;-1;4;-1;4,-1;-1;23;-1;23,m;m,NAN,NAN,y,1
3124,ICLR,2020,Neural Module Networks for Reasoning over Text,Nitish Gupta;Kevin Lin;Dan Roth;Sameer Singh;Matt Gardner,gnnitish@gmail.com;kevinlin@eecs.berkeley.edu;danroth@seas.upenn.edu;sameer@uci.edu;mattg@allenai.org,6;6;8,,Accept (Poster),0,4,1.0,yes,9/25/19,"University of Pennsylvania;University of California Berkeley;University of Pennsylvania;University of California, Irvine;Allen Institute for Artificial Intelligence",question answering;compositionality;neural module networks;multi-step reasoning;reading comprehension,-1;-1;20;-1;-1,-1;13;11;96;-1,m;m,NAN,NAN,n,3
3125,ICLR,2020,Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks,Leopold Cambier;Anahita Bhiwandiwalla;Ting Gong;Oguz H. Elibol;Mehran Nekuii;Hanlin Tang,lcambier@stanford.edu;anahita.bhiwandiwalla@intel.com;ting.gong@intel.com;oguz.h.elibol@intel.com;mehran.nekuii@intel.com;hanlin.tang@intel.com,6;6;1;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Stanford University;Intel;Intel;Intel;Intel;Intel,Low-precision training;numerics;deep learning,5;-1;-1;-1;-1;-1,4;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
3126,ICLR,2020,ProxSGD: Training Structured Neural Networks under Regularization and Constraints,Yang Yang;Yaxiong Yuan;Avraam Chatzimichailidis;Ruud JG van Sloun;Lei Lei;Symeon Chatzinotas,yang.yang@itwm.fraunhofer.de;yaxiong.yuan@uni.lu;avraam.chatzimichailidis@itwm.fraunhofer.de;r.j.g.v.sloun@tue.nl;lei.lei@uni.lu;symeon.chatzinotas@uni.lu,3;6;6,,Accept (Poster),0,4,1.0,yes,9/25/19,"Fraunhofer IIS;Interdisciplinary Centre for Security, Reliability and Trust (SnT);Fraunhofer IIS;Eindhoven University of Technology;Interdisciplinary Centre for Security, Reliability and Trust (SnT);Interdisciplinary Centre for Security, Reliability and Trust (SnT)",stochastic gradient descent;regularization;constrained optimization;nonsmooth optimization,-1;-1;-1;-1;-1;-1,-1;-1;-1;185;-1;-1,m;m,NAN,NAN,y,9
3127,ICLR,2020,BayesOpt Adversarial Attack,Binxin Ru;Adam Cobb;Arno Blaas;Yarin Gal,robin@robots.ox.ac.uk;adam.cobb@worc.ox.ac.uk;arno@robots.ox.ac.uk;yarin@cs.ox.ac.uk,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Black-box Adversarial Attack;Bayesian Optimisation;Gaussian Process,46;46;46;46,1;1;1;1,m;m,europe,uk,n,11;4
3128,ICLR,2020,Distance-Based Learning from Errors for Confidence Calibration,Chen Xing;Sercan Arik;Zizhao Zhang;Tomas Pfister,xingchen1113@gmail.com;soarik@google.com;zizhaoz@google.com;tpfister@google.com,6;6;6,,Accept (Poster),0,3,1.0,yes,9/25/19,SalesForce.com;Google;Google;Google,Confidence Calibration;Uncertainty Estimation;Prototypical Learning,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,
3129,ICLR,2020,Compressive Transformers for Long-Range Sequence Modelling,Jack W. Rae;Anna Potapenko;Siddhant M. Jayakumar;Chloe Hillier;Timothy P. Lillicrap,jwrae@google.com;apotapenko@google.com;sidmj@google.com;chillier@google.com;countzero@google.com,8;8;6,,Accept (Poster),0,8,1.0,yes,9/25/19,Google;Google;Google;Google;Google,memory;language modeling;transformer;compression,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
3130,ICLR,2020,Symplectic Recurrent Neural Networks,Zhengdao Chen;Jianyu Zhang;Martin Arjovsky;L√©on Bottou,zc1216@nyu.edu;edzhang@tju.edu.cn;martinarjovsky@gmail.com;leonb@fb.com,8;8;6,,Accept (Spotlight),0,4,1.0,yes,9/25/19,New York University;Zhejiang University;;Facebook,Hamiltonian systems;learning physical laws;symplectic integrators;recurrent neural networks;inverse problems,22;39;-1;-1,29;107;-1;-1,m;m,NAN,NAN,n,
3131,ICLR,2020,Learning to Coordinate Manipulation Skills via Skill Behavior Diversification,Youngwoon Lee;Jingyun Yang;Joseph J. Lim,lee504@usc.edu;jingyuny@usc.edu;limjj@usc.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,reinforcement learning;hierarchical reinforcement learning;modular framework;skill coordination;bimanual manipulation,36;36;36,62;62;62,m;m,usa,usa,n,
3132,ICLR,2020,Learning Expensive Coordination: An Event-Based Deep RL Approach,Zhenyu Shi*;Runsheng Yu*;Xinrun Wang*;Rundong Wang;Youzhi Zhang;Hanjiang Lai;Bo An,shizhy6@mail2.sysu.edu.cn;runsheng.yu@ntu.edu.sg;xwang033@e.ntu.edu.sg;rundong001@e.ntu.edu.sg;yzhang137@e.ntu.edu.sg;laihanj3@mail.sysu.edu.cn;boan@ntu.edu.sg,6;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;SUN YAT-SEN UNIVERSITY;Nanyang Technological University,Multi-Agent Deep Reinforcement Learning;Deep Reinforcement Learning;Leader‚ÄìFollower Markov Game;Expensive Coordination,-1;43;43;43;43;-1;43,299;49;49;49;49;299;49,m;m,asia,sg,y,8
3133,ICLR,2020,Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML,Aniruddh Raghu;Maithra Raghu;Samy Bengio;Oriol Vinyals,aniruddhraghu@gmail.com;maithrar@gmail.com;bengio@google.com;vinyals@google.com,3;8;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Massachusetts Institute of Technology;Cornell University;Google;Google,deep learning analysis;representation learning;meta-learning;few-shot learning,-1;7;-1;-1,-1;19;-1;-1,m;m,NAN,NAN,n,6
3134,ICLR,2020,Iterative energy-based projection on a normal data manifold for anomaly localization,David Dehaene;Oriel Frigo;S√©bastien Combrexelle;Pierre Eline,david@anotherbrain.ai;oriel@anotherbrain.ai;sebastien@anotherbrain.ai;pierre@anotherbrain.ai,3;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,AnotherBrain;AnotherBrain;AnotherBrain;AnotherBrain,deep learning;visual inspection;unsupervised anomaly detection;anomaly localization;autoencoder;variational autoencoder;gradient descent;inpainting,-1;-1;-1;-1,-1;-1;-1;-1,u;u,NAN,NAN,n,2
3135,ICLR,2020,Harnessing Structures for Value-Based Planning and Reinforcement Learning,Yuzhe Yang;Guo Zhang;Zhi Xu;Dina Katabi,yuzhe@mit.edu;guozhang@mit.edu;zhixu@mit.edu;dina@csail.mit.edu,8;6;8,,Accept (Talk),0,8,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deep reinforcement learning;value-based reinforcement learning,5;5;5;5,5;5;5;5,m;f,usa,usa,n,
3136,ICLR,2020,A closer look at the approximation capabilities of neural networks,Kai Fong Ernest Chong,ernest_chong@sutd.edu.sg,8;6;6;6,,Accept (Poster),0,3,1.0,yes,9/25/19,Singapore University of Technology and Design,deep learning;approximation;universal approximation theorem,-1,-1,m,NAN,NAN,y,1
3137,ICLR,2020,Spectral  Embedding of Regularized Block Models,Nathan De Lara;Thomas Bonald,ndelara@enst.fr;bonald@enst.fr,6;8,,Accept (Spotlight),0,1,0.0,yes,9/25/19,T√©l√©com ParisTech;T√©l√©com ParisTech,Spectral embedding;regularization;block models;clustering,-1;-1,187;187,u;m,NAN,NAN,y,10
3138,ICLR,2020,MMA Training: Direct Input Space Margin Maximization through Adversarial Training,Gavin Weiguang Ding;Yash Sharma;Kry Yik Chau Lui;Ruitong Huang,gavin.w.ding@gmail.com;yash.sharma@bethgelab.org;yikchau.y.lui@borealisai.com;ruitong.huang@borealisai.com,3;6;6,,Accept (Poster),1,10,0.0,yes,9/25/19,"Borealis AI;Centre for Integrative Neuroscience, AG Bethge;Borealis AI;Borealis AI",adversarial robustness;perturbation;margin maximization;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,1;4
3139,ICLR,2020,Monotonic Multihead Attention,Xutai Ma;Juan Miguel Pino;James Cross;Liezl Puzon;Jiatao Gu,xutai_ma@jhu.edu;juancarabina@fb.com;jcross@fb.com;lie@fb.com;jgu@fb.com,6;6;8,,Accept (Poster),0,9,0.0,yes,9/25/19,Johns Hopkins University;Facebook;Facebook;Facebook;Facebook,Simultaneous Translation;Transformer;Monotonic Attention,73;-1;-1;-1;-1,12;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
3140,ICLR,2020,Learning representations for binary-classification without backpropagation,Mathias Lechner,mathias.lechner@ist.ac.at,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Institute of Science and Technology Austria,feedback alignment;alternatives to backpropagation;biologically motivated learning algorithms,-1,-1,m,NAN,NAN,y,1
3141,ICLR,2020,Action Semantics Network: Considering the Effects of Actions in Multiagent Systems,Weixun Wang;Tianpei Yang;Yong Liu;Jianye Hao;Xiaotian Hao;Yujing Hu;Yingfeng Chen;Changjie Fan;Yang Gao,wxwang@tju.edu.cn;tpyang@tju.edu.cn;lucasliunju@gmail.com;jianye.hao@tju.edu.cn;xiaotianhao@tju.edu.cn;huyujing@corp.netease.com;chenyingfeng1@corp.netease.com;fanchangjie@corp.netease.com;gaoy@nju.edu.cn,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;;Zhejiang University;Zhejiang University;Fuxi AI Lab in Netease;Fuxi AI Lab in Netease;Fuxi AI Lab in Netease;Zhejiang University,multiagent coordination;multiagent learning,39;39;-1;39;39;-1;-1;-1;39,107;107;-1;107;107;-1;-1;-1;107,u;m,asia,cn,n,
3142,ICLR,2020,Finite Depth and Width Corrections to the Neural Tangent Kernel,Boris Hanin;Mihai Nica,bhanin@math.tamu.edu;mnica@math.utoronto.ca,6;8;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Texas A&M;Toronto University,Neural Tangent Kernel;Finite Width Corrections;Random ReLU Net;Wide Networks;Deep Networks,46;-1,177;-1,m;m,NAN,NAN,y,1
3143,ICLR,2020,What graph neural networks cannot learn: depth vs width,Andreas Loukas,andreas.loukas@epfl.ch,6;8;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne,graph neural networks;capacity;impossibility results;lower bounds;expressive power,-1,-1,m,NAN,NAN,y,10
3144,ICLR,2020,Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data,Sergei Popov;Stanislav Morozov;Artem Babenko,sapopov@yandex-team.ru;stanis-morozov@yandex.ru;artem.babenko@phystech.edu,6;8;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Yandex;Yandex;Moscow Institute of Physics and Technology,tabular data;architectures;DNN,-1;-1;-1,-1;-1;234,m;m,NAN,NAN,n,3;10
3145,ICLR,2020,Gradient $\ell_1$ Regularization for Quantization Robustness,Milad Alizadeh;Arash Behboodi;Mart van Baalen;Christos Louizos;Tijmen Blankevoort;Max Welling,milada@qti.qualcomm.com;behboodi@qti.qualcomm.com;mart@qti.qualcomm.com;clouizos@qti.qualcomm.com;tijmen@qti.qualcomm.com;mwelling@qti.qualcomm.com,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",quantization;regularization;robustness;gradient regularization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3146,ICLR,2020,PairNorm: Tackling Oversmoothing in GNNs,Lingxiao Zhao;Leman Akoglu,lingxiao@cmu.edu;lakoglu@andrew.cmu.edu,8;3,,Accept (Poster),0,2,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Graph Neural Network;oversmoothing;normalization,1;1,27;27,m;f,usa,usa,n,10
3147,ICLR,2020,Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework,Zirui Wang*;Jiateng Xie*;Ruochen Xu;Yiming Yang;Graham Neubig;Jaime G. Carbonell,ziruiw@cs.cmu.edu;jiatengx@cs.cmu.edu;ruochenx@cs.cmu.edu;yiming@cs.cmu.edu;gneubig@cs.cmu.edu;jgc@cs.cmu.edu,8;8;6,,Accept (Poster),2,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Cross-lingual Representation,1;1;1;1;1;1,27;27;27;27;27;27,m;m,usa,usa,n,6
3148,ICLR,2020,Generalization of Two-layer Neural Networks: An Asymptotic Viewpoint,Jimmy Ba;Murat Erdogdu;Taiji Suzuki;Denny Wu;Tianzong Zhang,jba@cs.toronto.edu;erdogdu@cs.toronto.edu;taiji@mist.i.u-tokyo.ac.jp;dennywu@cs.toronto.edu;ztz16@mails.tsinghua.edu.cn,8;6;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,"University of Toronto;University of Toronto;The University of Tokyo;University of Toronto;Tsinghua University, Tsinghua University",Neural Networks;Generalization;High-dimensional Statistics,18;18;64;18;4,18;18;36;18;23,m;m,NAN,NAN,y,1
3149,ICLR,2020,LAMOL: LAnguage MOdeling for Lifelong Language Learning,Fan-Keng Sun*;Cheng-Hao Ho*;Hung-Yi Lee,fankeng@mit.edu;jojotenya@gmail.com;hungyilee@ntu.edu.tw,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;;Nanyang Technological University,NLP;Deep Learning;Lifelong Learning,5;-1;43,5;-1;49,m;m,asia,sg,n,3
3150,ICLR,2020,Neural Stored-program Memory,Hung Le;Truyen Tran;Svetha Venkatesh,lethai@deakin.edu.au;truyen.tran@deakin.edu.au;svetha.venkatesh@deakin.edu.au,8;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Deakin University;Deakin University;Deakin University,Memory Augmented Neural Networks;Universal Turing Machine;fast-weight,-1;-1;-1,332;332;332,m;f,asia,cn,n,6
3151,ICLR,2020,BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning,Yeming Wen;Dustin Tran;Jimmy Ba,ywen@cs.toronto.edu;trandustin@google.com;jba@cs.toronto.edu,6;3;6,,Accept (Poster),0,9,1.0,yes,9/25/19,University of Toronto;Google;University of Toronto,deep learning;ensembles,18;-1;18,18;-1;18,m;m,canada,ca,n,
3152,ICLR,2020,Neural Arithmetic Units,Andreas Madsen;Alexander Rosenberg Johansen,amwebdk@gmail.com;alexander@herhjemme.dk,6;8;6;3,,Accept (Spotlight),0,11,0.0,yes,9/25/19,Technical University of Denmark;Technical University of Denmark,,-1;-1,-1;-1,m;m,asia,in,n,
3153,ICLR,2020,"To Relieve Your Headache of Training an MRF, Take AdVIL",Chongxuan Li;Chao Du;Kun Xu;Max Welling;Jun Zhu;Bo Zhang,chongxuanli1991@gmail.com;duchao0726@gmail.com;kunxu.thu@gmail.com;m.welling@uva.nl;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Tsinghua University;;;University of Amsterdam;Tsinghua University;Tsinghua University,Markov Random Fields;Undirected Graphical Models;Variational Inference;Black-box Infernece,-1;-1;-1;143;4;4,-1;-1;-1;62;23;23,m;m,NAN,NAN,y,4
3154,ICLR,2020,State Alignment-based Imitation Learning,Fangchen Liu;Zhan Ling;Tongzhou Mu;Hao Su,fliu@eng.ucsd.edu;z6ling@eng.ucsd.edu;t3mu@eng.ucsd.edu;haosu@eng.ucsd.edu,6;3;8,,Accept (Poster),0,12,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",Imitation learning;Reinforcement Learning,-1;-1;-1;-1,31;31;31;31,f;m,usa,usa,n,
3155,ICLR,2020,Influence-Based Multi-Agent Exploration,Tonghan Wang*;Jianhao Wang*;Yi Wu;Chongjie Zhang,tonghanwang1996@gmail.com;1040594377@qq.com;jxwuyi@openai.com;chongjie@tsinghua.edu.cn,6;8;6,,Accept (Spotlight),3,4,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;OpenAI;Tsinghua University, Tsinghua University",Multi-agent reinforcement learning;Exploration,4;4;-1;4,23;23;-1;23,m;m,NAN,NAN,y,
3156,ICLR,2020,AE-OT: A NEW GENERATIVE MODEL BASED ON EXTENDED SEMI-DISCRETE OPTIMAL TRANSPORT,Dongsheng An;Yang Guo;Na Lei;Zhongxuan Luo;Shing-Tung Yau;Xianfeng Gu,doan@cs.stonybrook.edu;yangguo@cs.stonybrook.edu;nalei@dlut.edu.cn;zxluo@dlut.edu.cn;yau@math.harvard.edu;gu@cs.stonybrook.edu,3;3;8,,Accept (Poster),0,6,0.0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;South China University of Technology;South China University of Technology;Harvard University;State University of New York, Stony Brook",Generative model;auto-encoder;optimal transport;mode collapse;regularity,-1;-1;-1;-1;52;-1,-1;-1;501;501;7;-1,m;m,NAN,NAN,n,8;5;4;9;1
3157,ICLR,2020,CoPhy: Counterfactual Learning of Physical Dynamics,Fabien Baradel;Natalia Neverova;Julien Mille;Greg Mori;Christian Wolf,fabien.baradel@insa-lyon.fr;nneverova@fb.com;julien.mille@insa-cvl.fr;mori@cs.sfu.ca;christian.wolf@insa-lyon.fr,6;6;6,,Accept (Spotlight),0,6,0.0,yes,9/25/19,INSA de Lyon;Facebook;;Simon Fraser University;INSA de Lyon,intuitive physics;visual reasoning,-1;-1;-1;52;-1,-1;-1;-1;272;-1,m;m,NAN,NAN,n,
3158,ICLR,2020,Disentangling Factors of Variations Using Few Labels,Francesco Locatello;Michael Tschannen;Stefan Bauer;Gunnar R√§tsch;Bernhard Sch√∂lkopf;Olivier Bachem,flocatello@tuebingen.mpg.de;tschannen@google.com;stefan.bauer@tuebingen.mpg.de;raetsch@inf.ethz.ch;bs@tuebingen.mpg.de;bachem@google.com,1;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Max-Planck Institute;Google;Max-Planck Institute;Swiss Federal Institute of Technology;Max-Planck Institute;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3159,ICLR,2020,Uncertainty-guided Continual Learning with Bayesian Neural Networks,Sayna Ebrahimi;Mohamed Elhoseiny;Trevor Darrell;Marcus Rohrbach,sayna@berkeley.edu;mohamed.elhoseiny@gmail.com;trevor@eecs.berkeley.edu;maroffm@gmail.com,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,University of California Berkeley;KAUST;University of California Berkeley;Facebook,continual learning;catastrophic forgetting,-1;102;-1;-1,13;-1;13;-1,f;m,NAN,NAN,n,11
3160,ICLR,2020,Composing Task-Agnostic Policies with Deep Reinforcement Learning,Ahmed H. Qureshi;Jacob J. Johnson;Yuzhe Qin;Taylor Henderson;Byron Boots;Michael C. Yip,a1qureshi@ucsd.edu;jjj025@eng.ucsd.edu;y1qin@eng.ucsd.edu;tjwest@ucsd.edu;bboots@cs.washington.edu;yip@ucsd.edu,6;6;6,,Accept (Poster),0,13,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego;University of Washington;University of California, San Diego",composition;transfer learning;deep reinforcement learning,-1;-1;-1;-1;11;-1,31;31;31;31;26;31,m;m,usa,usa,n,6
3161,ICLR,2020,Making Sense of Reinforcement Learning and Probabilistic Inference,Brendan O'Donoghue;Ian Osband;Catalin Ionescu,bodonoghue85@gmail.com;iosband@google.com;cdi@google.com,6;8;6,,Accept (Spotlight),0,5,1.0,yes,9/25/19,DeepMind;Google;Google,Reinforcement learning;Bayesian inference;Exploration,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3162,ICLR,2020,The Logical Expressiveness of Graph Neural Networks,Pablo Barcel√≥;Egor V. Kostylev;Mikael Monet;Jorge P√©rez;Juan Reutter;Juan Pablo Silva,pbarcelo@gmail.com;egor.kostylev@cs.ox.ac.uk;mikael.monet@imfd.cl;jorge.perez.rojas@gmail.com;juan.reutter@gmail.com;jpsilvapena@gmail.com,8;8;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Pontificia Universidad Cat√≥lica;University of Oxford;Instituto Milenio Fundamentos de los Datos;Universidad de Chile;Pontificia Universidad Cat√≥lica;Universidad de Chile,Graph Neural Networks;First Order Logic;Expressiveness,-1;46;-1;316;-1;316,-1;1;-1;-1;-1;-1,m;m,southamerica,cl,y,10
3163,ICLR,2020,Language GANs Falling Short,Massimo Caccia;Lucas Caccia;William Fedus;Hugo Larochelle;Joelle Pineau;Laurent Charlin,massimo.p.caccia@gmail.com;lucas.page-caccia@mail.mcgill.ca;liam.fedus@gmail.com;hugolarochelle@google.com;jpineau@cs.mcgill.ca;lcharlin@gmail.com,6;8,,Accept (Poster),0,10,1.0,yes,9/25/19,University of Montreal;McGill University;;Google;McGill University;HEC Montreal,NLP;GAN;MLE;adversarial;text generation;temperature,118;102;-1;-1;102;-1,85;42;-1;-1;42;-1,m;m,canada,ca,n,3;5;4
3164,ICLR,2020,Directional Message Passing for Molecular Graphs,Johannes Klicpera;Janek Gro√ü;Stephan G√ºnnemann,klicpera@in.tum.de;grossja@in.tum.de;guennemann@in.tum.de,8;8;6,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,GNN;Graph neural network;message passing;graphs;equivariance;molecules,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
3165,ICLR,2020,A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning,Shahbaz Rezaei;Xin Liu,srezaei@ucdavis.edu;xinliu@ucdavis.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,"University of California, Davis;University of California, Davis",Machine learning security;Transfer learning;deep learning security;Softmax Vulnerability;Transfer learning Security,-1;-1,55;55,m;f,usa,usa,n,6;2;4
3166,ICLR,2020,At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima Selection in Asynchronous Training of Neural Networks?,Niv Giladi;Mor Shpigel Nacson;Elad Hoffer;Daniel Soudry,giladiniv@gmail.com;mor.shpigel@gmail.com;elad.hoffer@gmail.com;daniel.soudry@gmail.com,6;8;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,"Technion, Technion;Technion, Technion;Habana Labs (Intel);Technion, Technion",implicit bias;stability;neural networks;generalization gap;asynchronous SGD,27;27;-1;27,-1;-1;-1;-1,m;m,NAN,NAN,n,1;9
3167,ICLR,2020,Smoothness and Stability in GANs,Casey Chu;Kentaro Minami;Kenji Fukumizu,caseychu@stanford.edu;minami@preferred.jp;fukumizu@ism.ac.jp,8;6;1,,Accept (Poster),0,5,0.0,yes,9/25/19,"Stanford University;Preferred Networks, Inc.;The Institute of Statistical Mathematics, Japan",generative adversarial networks;stability;smoothness;convex conjugate,5;-1;-1,4;-1;-1,m;m,NAN,NAN,y,5;4
3168,ICLR,2020,Infinite-Horizon Differentiable Model Predictive Control,Sebastian East;Marco Gallieri;Jonathan Masci;Jan Koutnik;Mark Cannon,sebastian.east@bath.edu;marco@nnaisense.com;jonathan@nnaisense.com;jan@nnaisense.com;mark.cannon@eng.ox.ac.uk,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Oxford;NNAISENSE;NNAISENSE;NNAISENSE;University of Oxford,Model Predictive Control;Riccati Equation;Imitation Learning;Safe Learning,46;-1;-1;-1;46,1;-1;-1;-1;1,m;m,europe,uk,y,
3169,ICLR,2020,Observational Overfitting in Reinforcement Learning,Xingyou Song;Yiding Jiang;Stephen Tu;Yilun Du;Behnam Neyshabur,xsong@berkeley.edu;ydjiang@google.com;stephentu@google.com;yilundu@mit.edu;neyshabur@google.com,6;8;8,,Accept (Poster),0,6,0.0,yes,9/25/19,University of California Berkeley;Google;Google;Massachusetts Institute of Technology;Google,observational;overfitting;reinforcement;learning;generalization;implicit;regularization;overparametrization,-1;-1;-1;5;-1,13;-1;-1;5;-1,m;m,NAN,NAN,y,1
3170,ICLR,2020,Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin,Colin Wei;Tengyu Ma,colinwei@stanford.edu;tengyuma@cs.stanford.edu,3;8;8;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Stanford University;Stanford University,deep learning theory;generalization bounds;adversarially robust generalization;data-dependent generalization bounds,5;5,4;4,m;m,usa,usa,y,1;4
3171,ICLR,2020,SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards,Siddharth Reddy;Anca D. Dragan;Sergey Levine,sgr@berkeley.edu;anca@berkeley.edu;svlevine@eecs.berkeley.edu,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Imitation Learning;Reinforcement Learning,-1;-1;-1,13;13;13,m;m,usa,usa,n,1;5;4
3172,ICLR,2020,Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection,Michael Tsang;Dehua Cheng;Hanpeng Liu;Xue Feng;Eric Zhou;Yan Liu,tsangm@usc.edu;dehuacheng@fb.com;hanpengl@usc.edu;xfeng@fb.com;hanningz@fb.com;yanliu.cs@usc.edu,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Southern California;Facebook;University of Southern California;Facebook;Facebook;University of Southern California,Feature Interaction;Interpretability;Black Box;AutoML,36;-1;36;-1;-1;36,62;-1;62;-1;-1;62,m;f,usa,usa,n,
3173,ICLR,2020,Your classifier is secretly an energy based model and you should treat it like one,Will Grathwohl;Kuan-Chieh Wang;Joern-Henrik Jacobsen;David Duvenaud;Mohammad Norouzi;Kevin Swersky,wgrathwohl@cs.toronto.edu;wangkua1@cs.toronto.edu;j.jacobsen@vectorinstitute.ai;duvenaud@cs.toronto.edu;mnorouzi@google.com;kswersky@google.com,6;8;8,,Accept (Talk),0,10,3.0,yes,9/25/19,University of Toronto;University of Toronto;Vector Institute;University of Toronto;Google;Google,energy based models;adversarial robustness;generative models;out of distribution detection;outlier detection;hybrid models;robustness;calibration,18;18;-1;18;-1;-1,18;18;-1;18;-1;-1,m;m,NAN,NAN,n,5
3174,ICLR,2020,Pad√© Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks,Alejandro Molina;Patrick Schramowski;Kristian Kersting,molina@cs.tu-darmstadt.de;schramowski@cs.tu-darmstadt.de;kersting@cs.tu-darmstadt.de,6;6;8,,Accept (Poster),0,7,0.0,yes,9/25/19,TU Darmstadt;TU Darmstadt;TU Darmstadt,,59;59;59,-1;-1;-1,m;m,europe,de,y,
3175,ICLR,2020,Lipschitz constant estimation of Neural Networks via sparse polynomial optimization,Fabian Latorre;Paul Rolland;Volkan Cevher,fabian.latorre@epfl.ch;paul.rolland@epfl.ch;volkan.cevher@epfl.ch,8;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,robust networks;Lipschitz constant;polynomial optimization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
3176,ICLR,2020,AMRL: Aggregated Memory For Reinforcement Learning,Jacob Beck;Kamil Ciosek;Sam Devlin;Sebastian Tschiatschek;Cheng Zhang;Katja Hofmann,jacob_beck@alumni.brown.edu;kamil.ciosek@microsoft.com;sam.devlin@microsoft.com;sebastian.tschiatschek@microsoft.com;cheng.zhang@microsoft.com;katja.hofmann@microsoft.com,6;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Brown University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,deep learning;reinforcement learning;rl;memory;noise;machine learning,85;-1;-1;-1;-1;-1,53;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,3
3177,ICLR,2020,Memory-Based Graph Networks,Amir Hosein Khasahmadi;Kaveh Hassani;Parsa Moradi;Leo Lee;Quaid Morris,amirhosein.khasahmadi@mail.utoronto.ca;kaveh.hassani@autodesk.com;parsa.moradi73@gmail.com;ljlee@psi.toronto.edu;quaid.morris@utoronto.ca,6;6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Toronto University;Autodesk;;University of Toronto;Toronto University,Graph Neural Networks;Memory Networks;Hierarchial Graph Representation Learning,-1;-1;-1;18;-1,-1;-1;-1;18;-1,m;m,NAN,NAN,n,10
3178,ICLR,2020,One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation,Shunshi Zhang;Bradly C. Stadie,matthew.zhang@mail.utoronto.ca;bstadie@berkeley.edu,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Toronto University;University of California Berkeley,Pruning;RNNs;Sparsity,-1;-1,-1;13,m;m,usa,usa,n,
3179,ICLR,2020,Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning,Kimin Lee;Kibok Lee;Jinwoo Shin;Honglak Lee,kiminlee@kaist.ac.kr;kibok@umich.edu;jinwoos@kaist.ac.kr;honglak@eecs.umich.edu,6;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;University of Michigan;Korea Advanced Institute of Science and Technology;University of Michigan,Deep reinforcement learning;Generalization in visual domains,-1;7;-1;7,110;21;110;21,m;m,usa,usa,n,1
3180,ICLR,2020,On Mutual Information Maximization for Representation Learning,Michael Tschannen;Josip Djolonga;Paul K. Rubenstein;Sylvain Gelly;Mario Lucic,mi.tschannen@gmail.com;josip@djolonga.com;paruby@gmail.com;sylvaingelly@google.com;lucic@google.com,6;8;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Apple;Google;;Google;Google,mutual information;representation learning;unsupervised learning;self-supervised learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3181,ICLR,2020,Hypermodels for Exploration,Vikranth Dwaracherla;Xiuyuan Lu;Morteza Ibrahimi;Ian Osband;Zheng Wen;Benjamin Van Roy,vikranthd@google.com;lxlu@google.com;mibrahimi@google.com;iosband@google.com;zhengwen@google.com;benvanroy@google.com,6;8;3,,Accept (Poster),0,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,exploration;hypermodel;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
3182,ICLR,2020,GraphSAINT: Graph Sampling Based Inductive Learning Method,Hanqing Zeng;Hongkuan Zhou;Ajitesh Srivastava;Rajgopal Kannan;Viktor Prasanna,zengh@usc.edu;hongkuaz@usc.edu;ajiteshs@usc.edu;rajgopal.kannan.civ@mail.mil;prasanna@usc.edu,6;6;6,,Accept (Poster),1,5,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;Army Reserach laboratory;University of Southern California,Graph Convolutional Networks;Graph sampling;Network embedding,36;36;36;-1;36,62;62;62;-1;62,m;m,usa,usa,y,8;10
3183,ICLR,2020,Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks,Ziwei Ji;Matus Telgarsky,ziweiji2@illinois.edu;mjt@illinois.edu,6;8;8,,Accept (Poster),0,13,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",neural tangent kernel;polylogarithmic width;test error;gradient descent;classification,-1;-1,-1;-1,m;m,usa,usa,y,1
3184,ICLR,2020,Cross-Lingual Ability of Multilingual BERT: An Empirical Study,Karthikeyan K;Zihan Wang;Stephen Mayhew;Dan Roth,kkarthi@seas.upenn.edu;zihanw2@illinois.edu;mayhew@seas.upenn.edu;danroth@seas.upenn.edu,3;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,"University of Pennsylvania;University of Illinois, Urbana Champaign;University of Pennsylvania;University of Pennsylvania",Cross-Lingual Learning;Multilingual BERT,20;-1;20;20,11;-1;11;11,m;m,usa,usa,n,3
3185,ICLR,2020,Model Based Reinforcement Learning for Atari,≈Åukasz Kaiser;Mohammad Babaeizadeh;Piotr Mi≈Ços;B≈Ça≈ºej Osi≈Ñski;Roy H Campbell;Konrad Czechowski;Dumitru Erhan;Chelsea Finn;Piotr Kozakowski;Sergey Levine;Afroz Mohiuddin;Ryan Sepassi;George Tucker;Henryk Michalewski,lukaszkaiser@google.com;mbz@google.com;pmilos@mimuw.edu.pl;blazej.osinski@gmail.com;rhc@illinois.edu;konrad.czechowski@gmail.com;dumitru@google.com;chelseaf@google.com;kozak000@gmail.com;slevine@google.com;afrozm@google.com;rsepassi@google.com;gjt@google.com;henrykmichalewski@gmail.com,6;8;6,,Accept (Spotlight),0,4,0.0,yes,9/25/19,"Google;Google;University of Washington, Seattle;Lyft Inc.;University of Illinois, Urbana Champaign;University of Washington, Seattle;Google;Google;;Google;Google;Google;Google;Google",reinforcement learning;model based rl;video prediction model;atari,-1;-1;11;-1;-1;11;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;26;-1;-1;26;-1;-1;-1;-1;-1;-1;-1;-1,m;m,asia,in,n,
3186,ICLR,2020,InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization,Fan-Yun Sun;Jordan Hoffman;Vikas Verma;Jian Tang,sunfanyun@gmail.com;jhoffmann@g.harvard.edu;vikasverma.iitm@gmail.com;jian.tang@hec.ca,6;6;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Stanford University;Harvard University;Aalto University;HEC Montreal,graph-level representation learning;mutual information maximization,5;52;118;-1,4;7;182;-1,m;m,canada,ca,n,3;1;10
3187,ICLR,2020,Black-Box Adversarial Attack with Transferable Model-based Embedding,Zhichao Huang;Tong Zhang,zhuangbx@connect.ust.hk;tongzhang@tongzhang-ml.org,6;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,The Hong Kong University of Science and Technology;Google,adversarial examples;black-box attack;embedding,-1;-1,47;-1,m;m,NAN,NAN,n,4
3188,ICLR,2020,Inductive Matrix Completion Based on Graph Neural Networks,Muhan Zhang;Yixin Chen,muhan@wustl.edu;chen@cse.wustl.edu,6;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,"Washington University, St. Louis;Washington University, St. Louis",matrix completion;graph neural network,-1;-1,-1;-1,m;m,usa,usa,n,6;10
3189,ICLR,2020,Probability Calibration for Knowledge Graph Embedding Models,Pedro Tabacof;Luca Costabello,tabacof@gmail.com;luca.costabello@accenture.com,6;8;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Campinas;Accenture,knowledge graph embeddings;probability calibration;calibration;graph representation learning;knowledge graphs,-1;-1,-1;-1,m;m,NAN,NAN,n,10
3190,ICLR,2020,Intensity-Free Learning of Temporal Point Processes,Oleksandr Shchur;Marin Bilo≈°;Stephan G√ºnnemann,shchur@in.tum.de;bilos@in.tum.de;guennemann@in.tum.de,8;6;8,,Accept (Spotlight),0,5,4.0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,Temporal point process;neural density estimation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
3191,ICLR,2020,Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing,Jinyuan Jia;Xiaoyu Cao;Binghui Wang;Neil Zhenqiang Gong,jinyuan.jia@duke.edu;xiaoyu.cao@duke.edu;binghui.wang@duke.edu;neil.gong@duke.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,Certified Adversarial Robustness;Randomized Smoothing;Adversarial Examples,46;46;46;46,20;20;20;20,m;m,europe,se,y,1;4
3192,ICLR,2020,Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee,Wei Hu;Zhiyuan Li;Dingli Yu,huwei@cs.princeton.edu;zhiyuanli@cs.princeton.edu;dingliy@cs.princeton.edu,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Princeton University;Princeton University;Princeton University,deep learning theory;regularization;noisy labels,30;30;30,6;6;6,m;m,usa,usa,y,1
3193,ICLR,2020,"Understanding l4-based Dictionary Learning: Interpretation, Stability, and Robustness",Yuexiang Zhai;Hermish Mehta;Zhengyuan Zhou;Yi Ma,ysz@berkeley.edu;hermish@berkeley.edu;zyzhou@stanford.edu;yima@eecs.berkeley.edu,8;6,,Accept (Poster),0,2,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,L4-norm Maximization;Robust Dictionary Learning,-1;-1;5;-1,13;13;4;13,m;m,usa,usa,y,
3194,ICLR,2020,RGBD-GAN: Unsupervised 3D Representation Learning From Natural Image Datasets via RGBD Image Synthesis,Atsuhiro Noguchi;Tatsuya Harada,noguchi@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo,image generation;3D vision;unsupervised representation learning,64;64,36;36,u;m,NAN,NAN,n,5
3195,ICLR,2020,Estimating counterfactual treatment outcomes over time through adversarially balanced representations,Ioana Bica;Ahmed M Alaa;James Jordon;Mihaela van der Schaar,ioana.bica@eng.ox.ac.uk;a7med3laa@hotmail.com;james.jordon@wolfson.ox.ac.uk;mschaar@turing.ac.uk,6;6;8,,Accept (Spotlight),0,5,0.0,yes,9/25/19,University of Oxford;;University of Oxford;Alan Turing Institute,treatment effects over time;causal inference;counterfactual estimation,46;-1;46;-1,1;-1;1;-1,f;f,NAN,NAN,y,4
3196,ICLR,2020,Exploring Model-based Planning with Policy Networks,Tingwu Wang;Jimmy Ba,tingwuwang@cs.toronto.edu;jba@cs.toronto.edu,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Toronto;University of Toronto,reinforcement learning;model-based reinforcement learning;planning,18;18,18;18,m;m,canada,ca,n,
3197,ICLR,2020,LambdaNet: Probabilistic Type Inference using Graph Neural Networks,Jiayi Wei;Maruth Goyal;Greg Durrett;Isil Dillig,jiayi@cs.utexas.edu;maruth@utexas.edu;gdurrett@cs.utexas.edu;isil@cs.utexas.edu,6;8;8,,Accept (Poster),0,8,0.0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Type inference;Graph neural network;Programming languages;Pointer network,-1;-1;-1;-1,-1;-1;-1;-1,m;f,usa,usa,n,10
3198,ICLR,2020,Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations,Yichi Zhang;Ritchie Zhao;Weizhe Hua;Nayun Xu;G. Edward Suh;Zhiru Zhang,yz2499@cornell.edu;rz252@cornell.edu;wh399@cornell.edu;nx38@cornell.edu;edward.suh@cornell.edu;zhiruz@cornell.edu,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Cornell University;Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,deep learning;neural network;dynamic quantization;dual precision;efficient gating,7;7;7;7;7;7,19;19;19;19;19;19,m;m,usa,usa,n,
3199,ICLR,2020,Variational Template Machine for Data-to-Text Generation,Rong Ye;Wenxian Shi;Hao Zhou;Zhongyu Wei;Lei Li,rye18@fudan.edu.cn;shiwenxian@bytedance.com;zhouhao.nlp@bytedance.com;zywei@fudan.edu.cn;lileilab@bytedance.com,8;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Fudan University;ByteDance;ByteDance;Fudan University;ByteDance,,73;-1;-1;73;-1,109;-1;-1;109;-1,u;m,NAN,NAN,n,
3200,ICLR,2020,On Universal Equivariant Set Networks,Nimrod Segol;Yaron Lipman,nimrod.segol@weizmann.ac.il;yaron.lipman@weizmann.ac.il,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Weizmann Institute;Weizmann Institute,deep learning;universality;set functions;equivariance,118;118,-1;-1,m;m,NAN,NAN,y,2;1
3201,ICLR,2020,The Gambler's Problem and Beyond,Baoxiang Wang;Shuai Li;Jiajin Li;Siu On Chan,bxwang@cse.cuhk.edu.hk;shuaili8@sjtu.edu.cn;jjli@se.cuhk.edu.hk;siuon@cse.cuhk.edu.hk,6;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,"Department of Computer Science and Engineering, The Chinese University of Hong Kong;Shanghai Jiao Tong University;The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong",the gambler's problem;reinforcement learning;fractal;self-similarity;Bellman equation,46;30;316;46,35;157;35;35,m;m,NAN,NAN,y,
3202,ICLR,2020,Learning to Represent Programs with Property Signatures,Augustus Odena;Charles Sutton,augustusodena@google.com;csutton@inf.ed.ac.uk,6;6;1,,Accept (Poster),0,8,0.0,yes,9/25/19,Google;University of Edinburgh,Program Synthesis,-1;36,-1;30,m;m,europe,uk,n,
3203,ICLR,2020,Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks,Hae Beom Lee;Hayeon Lee;Donghyun Na;Saehoon Kim;Minseop Park;Eunho Yang;Sung Ju Hwang,haebeom.lee@kaist.ac.kr;hayeon926@kaist.ac.kr;donghyun.na@kaist.ac.kr;shkim@aitrics.com;mike_seop@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,8;8;8,,Accept (Talk),0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;AITRICS;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,meta-learning;few-shot learning;Bayesian neural network;variational inference;learning to learn;imbalanced and out-of-distribution tasks for few-shot learning,-1;-1;-1;-1;-1;-1;-1,110;110;110;-1;-1;110;110,m;m,NAN,NAN,n,6;11
3204,ICLR,2020,Smooth markets: A basic mechanism for organizing gradient-based learners,David Balduzzi;Wojciech M. Czarnecki;Tom Anthony;Ian Gemp;Edward Hughes;Joel Leibo;Georgios Piliouras;Thore Graepel,dbalduzzi@google.com;lejlot@google.com;edwardhughes@google.com;jzl@google.com;imgemp@google.com;twa@google.com;georgios.piliouras@gmail.com;thore@google.com,8;8,,Accept (Poster),0,2,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Singapore University of Technology and Design;Google,game theory;optimization;gradient descent;adversarial learning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1;5;4
3205,ICLR,2020,Thinking While Moving: Deep Reinforcement Learning with Concurrent Control,Ted Xiao;Eric Jang;Dmitry Kalashnikov;Sergey Levine;Julian Ibarz;Karol Hausman;Alexander Herzog,tedxiao@google.com;ejang@google.com;dkalashnikov@google.com;slevine@google.com;julianibarz@google.com;karolhausman@google.com;alexherzog@google.com,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,deep reinforcement learning;continuous-time;robotics,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3206,ICLR,2020,Demystifying Inter-Class Disentanglement,Aviv Gabbay;Yedid Hoshen,avivga@gmail.com;yedid@cs.huji.ac.il,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,disentanglement;latent optimization;domain translation,-1;85,-1;216,m;m,europe,il,n,4
3207,ICLR,2020,Self-Supervised Learning of Appliance Usage,Chen-Yu Hsu;Abbas Zeitoun;Guang-He Lee;Dina Katabi;Tommi Jaakkola,cyhsu@mit.edu;zeitoun@mit.edu;guanghe@csail.mit.edu;dina@csail.mit.edu;tommi@csail.mit.edu,6;3;8,,Accept (Poster),0,6,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Appliance usage;self-supervised learning;multi-modal learning;unsupervised learning,5;5;5;5;5,5;5;5;5;5,m;m,usa,usa,n,
3208,ICLR,2020,Higher-Order Function Networks for Learning Composable 3D Object Representations,Eric Mitchell;Selim Engin;Volkan Isler;Daniel D Lee,eric.anthony.mitchell95@gmail.com;engin003@umn.edu;isler@umn.edu;ddlee@seas.upenn.edu,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"Stanford University;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Pennsylvania",computer vision;3d reconstruction;deep learning;representation learning,-1;73;73;20,-1;79;79;11,m;m,usa,usa,n,
3209,ICLR,2020,Learning to solve the credit assignment problem,Benjamin James Lansdell;Prashanth Ravi Prakash;Konrad Paul Kording,ben.lansdell@gmail.com;prprak@seas.upenn.edu;koerding@gmail.com,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,biologically plausible deep learning;node perturbation;REINFORCE;synthetic gradients;feedback alignment,-1;20;20,-1;11;11,m;m,usa,usa,y,1;9
3210,ICLR,2020,Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks,Tribhuvanesh Orekondy;Bernt Schiele;Mario Fritz,orekondy@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de;fritz@cispa.saarland,8;3;6,,Accept (Poster),0,6,1.0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;CISPA Helmholtz Center for Information Security,model functionality stealing;adversarial machine learning,-1;-1;92,-1;-1;-1,m;m,NAN,NAN,n,4
3211,ICLR,2020,Difference-Seeking Generative Adversarial Network--Unseen Sample Generation,Yi Lin Sung;Sung-Hsien Hsieh;Soo-Chang Pei;Chun-Shien Lu,r06942076@ntu.edu.tw;parvaty316@hotmail.com;peisc@ntu.edu.tw;lcs@iis.sinica.edu.tw,6;3;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Nanyang Technological University;;Nanyang Technological University;Academia Sinica,generative adversarial network;semi-supervised learning;novelty detection,43;-1;43;-1,49;-1;49;-1,m;m,NAN,NAN,y,5;4
3212,ICLR,2020,Reducing Transformer Depth on Demand with Structured Dropout,Angela Fan;Edouard Grave;Armand Joulin,angelafan@fb.com;egrave@fb.com;ajoulin@fb.com,8;6;6,,Accept (Poster),1,10,0.0,yes,9/25/19,Facebook;Facebook;Facebook,reduction;regularization;pruning;dropout;transformer,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,8;3
3213,ICLR,2020,Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games,Zuyue Fu;Zhuoran Yang;Yongxin Chen;Zhaoran Wang,zuyuefu2022@u.northwestern.edu;zy6@princeton.edu;yongchen@gatech.edu;zhaoranwang@gmail.com,8;6;6,,Accept (Poster),0,16,0.0,yes,9/25/19,Northwestern University;Princeton University;Georgia Institute of Technology;Northwestern University,,46;30;13;46,22;6;38;22,m;m,usa,usa,y,1;9
3214,ICLR,2020,Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations,Pawel Korus;Nasir Memon,pkorus@nyu.edu;memon@nyu.edu,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,New York University;New York University,image forensics;photo manipulation detection;learned compression;lossy compression;image compression;entropy estimation,22;22,29;29,m;m,usa,usa,n,
3215,ICLR,2020,Multi-agent Reinforcement Learning for Networked System Control,Tianshu Chu;Sandeep Chinchali;Sachin Katti,cts198859@hotmail.com;csandeep@stanford.edu;skatti@stanford.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,VMware Research;Stanford University;Stanford University,deep reinforcement learning;multi-agent reinforcement learning;decision and control,-1;5;5,-1;4;4,m;m,usa,usa,y,
3216,ICLR,2020,Learning Space Partitions for Nearest Neighbor Search,Yihe Dong;Piotr Indyk;Ilya Razenshteyn;Tal Wagner,yihedong@gmail.com;indyk@mit.edu;ilyaraz@microsoft.com;tal.wagner@gmail.com,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Microsoft;Massachusetts Institute of Technology;Microsoft;Microsoft,space partition;lsh;locality sensitive hashing;nearest neighbor search,-1;5;-1;-1,-1;5;-1;-1,m;m,NAN,NAN,n,10
3217,ICLR,2020,On Computation and Generalization of Generative Adversarial Imitation Learning,Minshuo Chen;Yizhou Wang;Tianyi Liu;Zhuoran Yang;Xingguo Li;Zhaoran Wang;Tuo Zhao,mchen393@gatech.edu;wyzjack990122@gmail.com;tianyiliu@gatech.edu;zy6@princeton.edu;xingguol@princeton.edu;zhaoran.wang@northwestern.edu;tourzhao@gatech.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Georgia Institute of Technology;Northeastern University;Georgia Institute of Technology;Princeton University;Princeton University;Northwestern University;Georgia Institute of Technology,,13;16;13;30;30;46;13,38;906;38;6;6;22;38,m;m,usa,usa,y,1;5;4
3218,ICLR,2020,Evaluating The Search Phase of Neural Architecture Search,Kaicheng Yu;Christian Sciuto;Martin Jaggi;Claudiu Musat;Mathieu Salzmann,kaicheng.yu@epfl.ch;sciutochristian@gmail.com;martin.jaggi@epfl.ch;claudiu.musat@swisscom.com;mathieu.salzmann@epfl.ch,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;;Swiss Federal Institute of Technology Lausanne;Swisscom;Swiss Federal Institute of Technology Lausanne,Neural architecture search;parameter sharing;random search;evaluation framework,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3219,ICLR,2020,Critical initialisation in continuous approximations of binary neural networks,George Stamatescu;Federica Gerace;Carlo Lucibello;Ian Fuss;Langford White,george.stamatescu@gmail.com;federicagerace91@gmail.com;carlo.lucibello@gmail.com;ian.fuss@adelaide.edu.au;lang.white@adelaide.edu.au,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,The University of Adelaide;Swiss Federal Institute of Technology Lausanne;Bocconi University;The University of Adelaide;The University of Adelaide,,102;-1;316;102;102,120;-1;-1;120;120,m;m,NAN,NAN,n,1
3220,ICLR,2020,Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning,Qian Long*;Zihan Zhou*;Abhinav Gupta;Fei Fang;Yi Wu‚Ä†;Xiaolong Wang‚Ä†,qianlong@cs.cmu.edu;footoredo@sjtu.edu.cn;abhinavg@cs.cmu.edu;feif@cs.cmu.edu;jxwuyi@gmail.com;dragonwxl123@gmail.com,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,"Carnegie Mellon University;Shanghai Jiao Tong University;Carnegie Mellon University;Carnegie Mellon University;Tsinghua University, Tsinghua University;University of California, San Diego",multi-agent reinforcement learning;evolutionary learning;curriculum learning,1;30;1;1;4;-1,27;157;27;27;23;31,f;m,usa,usa,n,
3221,ICLR,2020,Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks,Xin Xing;Long Sha;Pengyu Hong;Zuofeng Shang;Jun S. Liu,xin_xing@fas.harvard.edu;longsha@brandeis.edu;hongpeng@brandeis.edu;zuofeng.shang@njit.edu;jliu@stat.harvard.edu,6;6;6,,Accept (Poster),0,10,0.0,yes,9/25/19,Harvard University;Brandeis University;Brandeis University;New Jersey Institute of Technology;Harvard University,,52;248;248;-1;52,7;244;244;564;7,m;m,usa,usa,y,
3222,ICLR,2020,Picking Winning Tickets Before Training by Preserving Gradient Flow,Chaoqi Wang;Guodong Zhang;Roger Grosse,cqwang@cs.toronto.edu;gdzhang@cs.toronto.edu;rgrosse@cs.toronto.edu,6;6;6,,Accept (Poster),0,12,0.0,yes,9/25/19,University of Toronto;University of Toronto;University of Toronto,neural network;pruning before training;weight pruning,18;18;18,18;18;18,m;m,canada,ca,n,1
3223,ICLR,2020,CAQL: Continuous Action Q-Learning,Moonkyung Ryu;Yinlam Chow;Ross Anderson;Christian Tjandraatmadja;Craig Boutilier,mkryu@google.com;yinlamchow@google.com;rander@google.com;ctjandra@google.com;cboutilier@google.com,6;6,,Accept (Poster),1,2,0.0,yes,9/25/19,Google;Google;Google;Google;Google,Reinforcement learning (RL);DQN;Continuous control;Mixed-Integer Programming (MIP),-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3224,ICLR,2020,Stable Rank Normalization for Improved Generalization in Neural Networks and GANs,Amartya Sanyal;Philip H. Torr;Puneet K. Dokania,amartya.sanyal@cs.ox.ac.uk;philip.torr@eng.ox.ac.uk;puneet@robots.ox.ac.uk,6;8;8,,Accept (Spotlight),0,9,1.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,Generelization;regularization;empirical lipschitz,46;46;46,1;1;1,m;m,europe,uk,y,1;5
3225,ICLR,2020,Dynamic Model Pruning with Feedback,Tao Lin;Sebastian U. Stich;Luis Barba;Daniil Dmitriev;Martin Jaggi,tao.lin@epfl.ch;sebastian.stich@epfl.ch;luis.barba@inf.ethz.ch;daniil.dmitriev@epfl.ch;martin.jaggi@epfl.ch,6;6;6,,Accept (Poster),2,5,1.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,network pruning;dynamic reparameterization;model compression,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3226,ICLR,2020,Emergent Tool Use From Multi-Agent Autocurricula,Bowen Baker;Ingmar Kanitscheider;Todor Markov;Yi Wu;Glenn Powell;Bob McGrew;Igor Mordatch,bowen@openai.com;ingmar@openai.com;todor@openai.com;jxwuyi@openai.com;glenn@openai.com;bmcgrew@openai.com;imordatch@google.com,6;8;3,,Accept (Spotlight),1,5,0.0,yes,9/25/19,OpenAI;OpenAI;OpenAI;OpenAI;OpenAI;OpenAI;Google,,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3227,ICLR,2020,Conditional Learning of Fair Representations,Han Zhao;Amanda Coston;Tameem Adel;Geoffrey J. Gordon,han.zhao@cs.cmu.edu;acoston@cs.cmu.edu;tah47@cam.ac.uk;ggordon@cs.cmu.edu,6;6;6,,Accept (Spotlight),0,6,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;University of Cambridge;Carnegie Mellon University,algorithmic fairness;representation learning,1;1;79;1,27;27;3;27,m;m,usa,usa,y,1;7
3228,ICLR,2020,You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings,Daniel Ruffinelli;Samuel Broscheit;Rainer Gemulla,daniel@informatik.uni-mannheim.de;broscheit@informatik.uni-mannheim.de;rgemulla@uni-mannheim.de,6;6;8,,Accept (Poster),6,4,0.0,yes,9/25/19,University of Mannheim;University of Mannheim;University of Mannheim,knowledge graph embeddings;hyperparameter optimization,248;248;248,157;157;157,m;m,europe,de,n,10
3229,ICLR,2020,Disagreement-Regularized Imitation Learning,Kiante Brantley;Wen Sun;Mikael Henaff,kdbrant@cs.umd.edu;wen.sun@microsoft.com;mihenaff@microsoft.com,8;8;6,,Accept (Spotlight),1,4,1.0,yes,9/25/19,"University of Maryland, College Park;Microsoft;Microsoft",imitation learning;reinforcement learning;uncertainty,12;-1;-1,91;-1;-1,m;u,NAN,NAN,y,1;5;4
3230,ICLR,2020,Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video,Miguel Jaques;Michael Burke;Timothy Hospedales,m.a.m.jaques@sms.ed.ac.uk;michael.burke@ed.ac.uk;t.hospedales@ed.ac.uk,6;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh,,36;36;36,30;30;30,m;m,europe,uk,n,
3231,ICLR,2020,Model-Augmented Actor-Critic: Backpropagating through Paths,Ignasi Clavera;Yao Fu;Pieter Abbeel,iclavera@berkeley.edu;violetfuyao@berkeley.edu;pabbeel@cs.berkeley.edu,3;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;model-based;actor-critic;pathwise,-1;-1;-1,13;13;13,m;m,usa,usa,y,
3232,ICLR,2020,Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN),Peter Sorrenson;Carsten Rother;Ullrich K√∂the,peter.sorrenson@gmail.com;carsten.rother@iwr.uni-heidelberg.de;ullrich.koethe@iwr.uni-heidelberg.de,6;6;8,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Heidelberg University;Heidelberg University;Heidelberg University,disentanglement;nonlinear ICA;representation learning;feature discovery;theoretical justification,194;194;194,44;44;44,m;m,europe,de,n,1;5
3233,ICLR,2020,Generative Ratio Matching Networks,Akash Srivastava;Kai Xu;Michael U. Gutmann;Charles Sutton,akash.srivastava@me.com;kai.xu@ed.ac.uk;michael.gutmann@ed.ac.uk;charlessutton@google.com,6;6;6,,Accept (Poster),0,10,0.0,yes,9/25/19,Massachusetts Institute of Technology;University of Edinburgh;University of Edinburgh;Google,deep generative model;deep learning;maximum mean discrepancy;density ratio estimation,5;36;36;-1,5;30;30;-1,m;m,NAN,NAN,y,5;4
3234,ICLR,2020,CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning,Jiachen Yang;Alireza Nakhaei;David Isele;Kikuo Fujimura;Hongyuan Zha,yjiachen@gmail.com;anakhaei@honda-ri.com;disele@honda-ri.com;kfujimura@honda-ri.com;zha@cc.gatech.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Georgia Institute of Technology;Honda Research Institute;Honda Research Institute;Honda Research Institute;Georgia Institute of Technology,multi-agent reinforcement learning,13;-1;-1;-1;13,38;-1;-1;-1;38,m;m,usa,usa,y,
3235,ICLR,2020,Order Learning and Its Application to Age Estimation,Kyungsun Lim;Nyeong-Ho Shin;Young-Yoon Lee;Chang-Su Kim,kslim@mcl.korea.ac.kr;nhshin@mcl.korea.ac.kr;yy77lee@gmail.com;changsukim@korea.ac.kr,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Korea University;Korea University;;Korea University,Order learning;age estimation;aesthetic assessment,168;168;-1;168,179;179;-1;179,u;m,asia,kr,n,2;10;7
3236,ICLR,2020,Learning to Link,Maria-Florina Balcan;Travis Dick;Manuel Lang,ninamf@cs.cmu.edu;tdick@ttic.edu;manuel.lang@student.kit.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Carnegie Mellon University;Toyota Technological Institute at Chicago;Karlsruhe Institute of Technology,Data-driven Algorithm Configuration;Metric Learning;Linkage Clustering;Learning Algorithms,1;-1;168,27;-1;174,f;m,europe,de,y,
3237,ICLR,2020,DiffTaichi: Differentiable Programming for Physical Simulation,Yuanming Hu;Luke Anderson;Tzu-Mao Li;Qi Sun;Nathan Carr;Jonathan Ragan-Kelley;Fredo Durand,yuanmhu@gmail.com;lukea@mit.edu;tzumao@berkeley.edu;qisu@adobe.com;ncarr@adobe.com;jrk@berkeley.edu;fredo@mit.edu,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley;Adobe Systems;Adobe Systems;University of California Berkeley;Massachusetts Institute of Technology,Differentiable programming;robotics;optimal control;physical simulation;machine learning system,5;5;-1;-1;-1;-1;5,5;5;13;-1;-1;13;5,m;m,usa,usa,n,
3238,ICLR,2020,Adaptive Structural Fingerprints for Graph Attention Networks,Kai Zhang;Yaokang Zhu;Jun Wang;Jie Zhang,kzhang980@gmail.com;52184501026@stu.ecnu.edu.cn;wongjun@gmail.com;jzhang080@gmail.com,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Temple University;East China Normal University;;Fudan University,Graph attention networks;graph neural networks;node classification,-1;-1;-1;73,-1;544;-1;109,m;m,asia,cn,n,8;10
3239,ICLR,2020,Kernelized Wasserstein Natural Gradient,M Arbel;A Gretton;W Li;G Montufar,michael.n.arbel@gmail.com;arthur.gretton@gmail.com;wcli@math.ucla.edu;guidomontufar@gmail.com,8;6;6,,Accept (Spotlight),0,6,1.0,yes,9/25/19,"University College London;;University of California, Los Angeles;Max Planck Institute MIS",kernel methods;natural gradient;information geometry;Wasserstein metric,52;-1;-1;-1,-1;-1;17;-1,m;m,NAN,NAN,y,
3240,ICLR,2020,DeepV2D: Video to Depth with Differentiable Structure from Motion,Zachary Teed;Jia Deng,zteed@princeton.edu;jiadeng@princeton.edu,8;6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Princeton University;Princeton University,Structure-from-Motion;Video to Depth;Dense Depth Estimation,30;30,6;6,m;m,usa,usa,n,
3241,ICLR,2020,Measuring the Reliability of Reinforcement Learning Algorithms,Stephanie C.Y. Chan;Samuel Fishman;Anoop Korattikara;John Canny;Sergio Guadarrama,scychan@google.com;sfishman@google.com;kbanoop@google.com;canny@google.com;sguada@google.com,8;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google,reinforcement learning;metrics;statistics;reliability,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,8;1
3242,ICLR,2020,SELF: Learning to Filter Noisy Labels with Self-Ensembling,Duc Tam Nguyen;Chaithanya Kumar Mummadi;Thi Phuong Nhung Ngo;Thi Hoai Phuong Nguyen;Laura Beggel;Thomas Brox,ductam.nguyen08@gmail.com;chaithanyakumar.mummadi@de.bosch.com;thiphuongnhung.ngo@de.bosch.com;hoai.phuong.nguyen198@gmail.com;laura.beggel@de.bosch.com;brox@cs.uni-freiburg.de,6;8;3,,Accept (Poster),0,6,1.0,yes,9/25/19,University of Freiburg;Bosch;Bosch;;Bosch;University of Freiburg,Ensemble Learning;Robust Learning;Noisy Labels;Labels Filtering,-1;-1;-1;-1;-1;-1,-1;297;297;-1;297;-1,m;m,NAN,NAN,n,
3243,ICLR,2020,Incorporating BERT into Neural Machine Translation,Jinhua Zhu;Yingce Xia;Lijun Wu;Di He;Tao Qin;Wengang Zhou;Houqiang Li;Tieyan Liu,teslazhu@mail.ustc.edu.cn;yingce.xia@gmail.com;wulijun3@mail2.sysu.edu.cn;di_he@pku.edu.cn;taoqin@microsoft.com;zhwg@ustc.edu.cn;lihq@ustc.edu.cn;tyliu@microsoft.com,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Science and Technology of China;Microsoft;SUN YAT-SEN UNIVERSITY;Peking University;Microsoft;University of Science and Technology of China;University of Science and Technology of China;Microsoft,BERT;Neural Machine Translation,-1;-1;-1;14;-1;-1;-1;-1,80;-1;299;24;-1;80;80;-1,u;m,NAN,NAN,n,8;3
3244,ICLR,2020,Mogrifier LSTM,G√°bor Melis;Tom√°≈° Koƒçisk√Ω;Phil Blunsom,melisgl@google.com;tkocisky@google.com;pblunsom@google.com,6;8;8,,Accept (Talk),0,3,0.0,yes,9/25/19,Google;Google;Google,lstm;language modelling,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3;8;1
3245,ICLR,2020,Transferring Optimality Across Data Distributions via Homotopy Methods,Matilde Gargiani;Andrea Zanelli;Quoc Tran Dinh;Moritz Diehl;Frank Hutter,gargiani@informatik.uni-freiburg.de;andrea.zanelli@imtek.uni-freiburg.de;quoctd@email.unc.edu;moritz.diehl@imtek.uni-freiburg.de;fh@cs.uni-freiburg.de,3;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,"Universit√§t Freiburg;Universit√§t Freiburg;University of North Carolina, Chapel Hill;Universit√§t Freiburg;Universit√§t Freiburg",deep learning;numerical optimization;transfer learning,-1;-1;64;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,y,9
3246,ICLR,2020,Quantum Algorithms for Deep Convolutional Neural Networks,Iordanis Kerenidis;Jonas Landman;Anupam Prakash,jkeren@gmail.com;landman@irif.fr;anupamprakash1@gmail.com,6;8;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Universite Paris Diderot;Universite Paris Diderot;Universite Paris Diderot,quantum computing;quantum machine learning;convolutional neural network;theory;algorithm,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
3247,ICLR,2020,Unrestricted Adversarial Examples via Semantic Manipulation,Anand Bhattad;Min Jin Chong;Kaizhao Liang;Bo Li;D. A. Forsyth,bhattad2@illinois.edu;mchong6@illinois.edu;kl2@illinois.edu;lbo@illinois.edu;daf@illinois.edu,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Adversarial Examples;Semantic Manipulation;Image Colorization;Texture Transfer,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n,4
3248,ICLR,2020,A Stochastic Derivative Free Optimization Method with Momentum,Eduard Gorbunov;Adel Bibi;Ozan Sener;El Houcine Bergou;Peter Richtarik,eduard.gorbunov@phystech.edu;adel.bibi@kaust.edu.sa;ozan.sener@intel.com;houcine.bergou@kaust.edu.sa;peter.richtarik@kaust.edu.sa,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Moscow Institute of Physics and Technology;KAUST;Intel;KAUST;KAUST,derivative-free optimization;stochastic optimization;heavy ball momentum;importance sampling,-1;102;-1;102;102,234;-1;-1;-1;-1,m;m,europe,gr,y,
3249,ICLR,2020,Learning The Difference That Makes A Difference With Counterfactually-Augmented Data,Divyansh Kaushik;Eduard Hovy;Zachary Lipton,dkaushik@cs.cmu.edu;hovy@cmu.edu;zlipton@cmu.edu,8;8;1;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,humans in the loop;annotation artifacts;text classification;sentiment analysis;natural language inference,1;1;1,27;27;27,m;m,usa,usa,n,3
3250,ICLR,2020,Fast is better than free: Revisiting adversarial training,Eric Wong;Leslie Rice;J. Zico Kolter,ericwong@cs.cmu.edu;larice@cs.cmu.edu;zkolter@cs.cmu.edu,6;6;8,,Accept (Poster),10,11,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,adversarial examples;adversarial training;fast gradient sign method,1;1;1,27;27;27,m;m,usa,usa,n,4
3251,ICLR,2020,Disentangling neural mechanisms for perceptual grouping,Junkyung Kim*;Drew Linsley*;Kalpit Thakkar;Thomas Serre,junkyung_kim@brown.edu;drew_linsley@brown.edu;kalpit_thakkar@brown.edu;thomas_serre@brown.edu,8;6;8,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Brown University;Brown University;Brown University;Brown University,Perceptual grouping;visual cortex;recurrent feedback;horizontal connections;top-down connections,85;85;85;85,53;53;53;53,m;m,usa,usa,n,
3252,ICLR,2020,How to 0wn the NAS in Your Spare Time,Sanghyun Hong;Michael Davinroy;Yi«ßitcan Kaya;Dana Dachman-Soled;Tudor Dumitra≈ü,shhong@cs.umd.edu;michael.davinroy@gmail.com;cankaya@umiacs.umd.edu;danadach@ece.umd.edu;tdumitra@umiacs.umd.edu,6;6;3,,Accept (Poster),0,6,0.0,yes,9/25/19,"University of Maryland, College Park;;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",Reconstructing Novel Deep Learning Systems,12;-1;12;12;12,91;-1;91;91;91,m;m,usa,usa,n,10;4
3253,ICLR,2020,Option Discovery using Deep Skill Chaining,Akhil Bagaria;George Konidaris,akhil_bagaria@brown.edu;gdk@cs.brown.edu,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Brown University;Brown University,Hierarchical Reinforcement Learning;Reinforcement Learning;Skill Discovery;Deep Learning;Deep Reinforcement Learning,85;85,53;53,m;m,usa,usa,n,
3254,ICLR,2020,Optimal Strategies Against Generative Attacks,Roy Mor;Erez Peterfreund;Matan Gavish;Amir Globerson,roy16mor@gmail.com;erezpeter@cs.huji.ac.il;matan.gavish@mail.huji.ac.il;amir.globerson@gmail.com,8;8;8;8,,Accept (Talk),0,4,0.0,yes,9/25/19,Tel Aviv University;Hebrew University of Jerusalem;Hebrew University of Jerusalem;Tel Aviv University,,-1;85;85;30,-1;216;216;188,m;m,europe,il,y,1;5;4
3255,ICLR,2020,Massively Multilingual Sparse Word Representations,G√°bor Berend,berendg@inf.u-szeged.hu,8;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Szeged,sparse word representations;multilinguality;sparse coding,445,874,m,europe,de,n,3;1
3256,ICLR,2020,RaPP: Novelty Detection with Reconstruction along Projection Pathway,Ki Hyun Kim;Sangwoo Shim;Yongsub Lim;Jongseob Jeon;Jeongwoo Choi;Byungchan Kim;Andre S. Yoon,khkim@makinarocks.ai;sangwoo@makinarocks.ai;yongsub@makinarocks.ai;jongseob.jeon@makinarocks.ai;jeongwoo@makinarocks.ai;kbc8894@makinarocks.ai;andre@makinarocks.ai,6;6;6,,Accept (Poster),0,8,1.0,yes,9/25/19,MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks,Novelty Detection;Anomaly Detection;Outlier Detection;Semi-supervised Learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3257,ICLR,2020,Domain Adaptive Multibranch Networks,R√≥ger Berm√∫dez-Chac√≥n;Mathieu Salzmann;Pascal Fua,roger.bermudez@epfl.ch;mathieu.salzmann@epfl.ch;pascal.fua@epfl.ch,6;3;8,,Accept (Poster),0,3,1.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Domain Adaptation;Computer Vision,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
3258,ICLR,2020,Continual learning with hypernetworks,Johannes von Oswald;Christian Henning;Jo√£o Sacramento;Benjamin F. Grewe,voswaldj@ethz.ch;henningc@ethz.ch;sacramento@ini.ethz.ch;bgrewe@ethz.ch,6;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Continual Learning;Catastrophic Forgetting;Meta Model;Hypernetwork,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
3259,ICLR,2020,Distributed Bandit Learning: Near-Optimal Regret with Efficient Communication,Yuanhao Wang;Jiachen Hu;Xiaoyu Chen;Liwei Wang,yuanhao-16@mails.tsinghua.edu.cn;nickh@pku.edu.cn;cxy30@pku.edu.cn;wanglw@cis.pku.edu.cn,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Peking University;Peking University;Peking University",Theory;Bandit Algorithms;Communication Efficiency,4;14;14;14,23;24;24;24,m;m,asia,cn,y,1
3260,ICLR,2020,SVQN: Sequential Variational Soft Q-Learning Networks,Shiyu Huang;Hang Su;Jun Zhu;Ting Chen,huangsy1314@163.com;suhangss@mail.tsinghua.edu.cn;dcszj@tsinghua.edu.cn;tingchen@tsinghua.edu.cn,8;3,,Accept (Poster),0,2,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",reinforcement learning;POMDP;variational inference;generative model,4;4;4;4,23;23;23;23,m;m,NAN,NAN,n,1;10
3261,ICLR,2020,PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS,Zhiyuan Li;Jaideep Vitthal Murkute;Prashnna Kumar Gyawali;Linwei Wang,zl7904@rit.edu;jvm6526@rit.edu;pkg2182@rit.edu;linwei.wang@rit.edu,8;6;8,,Accept (Spotlight),0,6,0.0,yes,9/25/19,Rochester Institute of Technology;Rochester Institute of Technology;Rochester Institute of Technology;Rochester Institute of Technology,generative model;disentanglement;progressive learning;VAE,118;118;118;118,843;843;843;843,m;f,usa,usa,n,5
3262,ICLR,2020,Learning transport cost from subset correspondence,Ruishan Liu;Akshay Balsubramani;James Zou,ruishan@stanford.edu;akshay7@gmail.com;jamesyzou@gmail.com,3;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Stanford University;;Stanford University,,5;-1;-1,4;-1;-1,f;m,asia,in,y,
3263,ICLR,2020,Meta Dropout: Learning to Perturb Latent Features for Generalization,Hae Beom Lee;Taewook Nam;Eunho Yang;Sung Ju Hwang,haebeom.lee@kaist.ac.kr;namsan@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,8;3;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n,6;1
3264,ICLR,2020,On Robustness of Neural Ordinary Differential Equations,Hanshu YAN;Jiawei DU;Vincent TAN;Jiashi FENG,hanshu.yan@u.nus.edu;dujiawei@u.nus.edu;vtan@nus.edu.sg;elefjia@nus.edu.sg,6;8;6,,Accept (Spotlight),0,11,1.0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;National University of Singapore,Neural ODE,17;17;17;17,25;25;25;25,m;m,asia,sg,y,8;4
3265,ICLR,2020,Towards neural networks that provably know when they don't know,Alexander Meinke;Matthias Hein,alexander.meinke@uni-tuebingen.de;matthias.hein@uni-tuebingen.de,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Tuebingen;University of Tuebingen,,143;143,91;91,m;m,europe,de,y,
3266,ICLR,2020,Exploration in Reinforcement Learning with Deep Covering Options,Yuu Jinnai;Jee Won Park;Marlos C. Machado;George Konidaris,yuu_jinnai@brown.edu;jee_won_park@brown.edu;marlosm@google.com;gdk@cs.brown.edu,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Brown University;Brown University;Google;Brown University,Reinforcement learning;temporal abstraction;exploration,85;85;-1;85,53;53;-1;53,m;m,usa,usa,n,1;10
3267,ICLR,2020,Mixed Precision DNNs: All you need is a good parametrization,Stefan Uhlich;Lukas Mauch;Fabien Cardinaux;Kazuki Yoshiyama;Javier Alonso Garcia;Stephen Tiedemann;Thomas Kemp;Akira Nakamura,stefan.uhlich@sony.com;lukas.mauch@sony.com;fabien.cardinaux@sony.com;kazuki.yoshiyama@sony.com;javier.alonso@sony.com;stephen.tiedemann@sony.com;thomas.kemp@sony.com;akira.b.nakamura@sony.com,6;6;6,,Accept (Poster),1,7,1.0,yes,9/25/19,Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation,Deep Neural Network Compression;Quantization;Straight through gradients,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3268,ICLR,2020,Depth-Width Trade-offs for ReLU Networks via Sharkovsky's Theorem,Vaggos Chatziafratis;Sai Ganesh Nagarajan;Ioannis Panageas;Xiao Wang,vaggos@cs.stanford.edu;sai_nagarajan@mymail.sutd.edu.sg;ioannis@sutd.edu.sg;xiao_wang@sutd.edu.sg,8;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Stanford University;Singapore University of Technology and Design;Singapore University of Technology and Design;Singapore University of Technology and Design,Depth-Width trade-offs;ReLU networks;chaos theory;Sharkovsky Theorem;dynamical systems,5;-1;-1;-1,4;-1;-1;-1,m;m,NAN,NAN,y,1
3269,ICLR,2020,Learning to Move with Affordance Maps,William Qi;Ravi Teja Mullapudi;Saurabh Gupta;Deva Ramanan,wq@cs.cmu.edu;raviteja.mullapudi@gmail.com;saurabhg@illinois.edu;deva@cs.cmu.edu,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;University of Illinois, Urbana Champaign;Carnegie Mellon University",navigation;exploration,1;1;-1;1,27;27;-1;27,m;m,usa,usa,n,
3270,ICLR,2020,Data-dependent Gaussian Prior Objective for Language Generation,Zuchao Li;Rui Wang;Kehai Chen;Masso Utiyama;Eiichiro Sumita;Zhuosheng Zhang;Hai Zhao,charlee@sjtu.edu.cn;wangrui@nict.go.jp;khchen@nict.go.jp;mutiyama@nict.go.jp;eiichiro.sumita@nict.go.jp;zhangzs@sjtu.edu.cn;zhaohai@cs.sjtu.edu.cn,8;8;8,,Accept (Talk),0,8,0.0,yes,9/25/19,"Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Gaussian Prior Objective;Language Generation,30;-1;-1;-1;-1;30;30,157;-1;-1;-1;-1;157;157,m;m,asia,cn,n,3;7
3271,ICLR,2020,Sign Bits Are All You Need for Black-Box Attacks,Abdullah Al-Dujaili;Una-May O'Reilly,ash.aldujaili@gmail.com;unamay@csail.mit.edu,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Analog Devices;Massachusetts Institute of Technology,Black-box adversarial attack models;Deep Nets;Adversarial Examples;Black-Box Optimization;Zeroth-Order Optimization,-1;5,-1;5,m;f,usa,usa,y,4
3272,ICLR,2020,Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks,Timothy Tadros;Giri Krishnan;Ramyaa Ramyaa;Maxim Bazhenov,tttadros@ucsd.edu;gkrishnan@ucsd.edu;ramyaa.ramyaa@gmail.com;mbazhenov@ucsd.edu,8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;;University of California, San Diego",Adversarial Robustness;Generalization;Neural Computing;Deep Learning,-1;-1;-1;-1,31;31;-1;31,m;m,usa,usa,n,1;4
3273,ICLR,2020,SNODE: Spectral Discretization of Neural ODEs for System Identification,Alessio Quaglino;Marco Gallieri;Jonathan Masci;Jan Koutn√≠k,alessio@nnaisense.com;marco@nnaisense.com;jonathan@nnaisense.com;jan@nnaisense.com,8;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,NNAISENSE;NNAISENSE;NNAISENSE;NNAISENSE,Recurrent neural networks;system identification;neural ODEs,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,1
3274,ICLR,2020,Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings,Hongyu Ren*;Weihua Hu*;Jure Leskovec,hyren@cs.stanford.edu;weihuahu@stanford.edu;jure@cs.stanford.edu,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University,knowledge graph embeddings;logical reasoning;query answering,5;5;5,4;4;4,m;m,usa,usa,y,1;10
3275,ICLR,2020,Theory and Evaluation Metrics for Learning Disentangled Representations,Kien Do;Truyen Tran,dkdo@deakin.edu.au;truyen.tran@deakin.edu.au,6;6;6,,Accept (Poster),0,3,1.0,yes,9/25/19,Deakin University;Deakin University,disentanglement;metrics,-1;-1,332;332,m;m,asia,cn,n,5
3276,ICLR,2020,Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees,Binghong Chen;Bo Dai;Qinjie Lin;Guo Ye;Han Liu;Le Song,binghong@gatech.edu;bodai@google.com;qinjielin2018@u.northwestern.edu;guoye2018@u.northwestern.edu;hanliu@northwestern.edu;lsong@cc.gatech.edu,8;6;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Georgia Institute of Technology;Google;Northwestern University;Northwestern University;Northwestern University;Georgia Institute of Technology,learning to plan;representation learning;learning to design algorithm;reinforcement learning;meta learning,13;-1;46;46;46;13,38;-1;22;22;22;38,m;m,usa,usa,n,8
3277,ICLR,2020,And the Bit Goes Down: Revisiting the Quantization of Neural Networks,Pierre Stock;Armand Joulin;R√©mi Gribonval;Benjamin Graham;Herv√© J√©gou,pstock@fb.com;ajoulin@fb.com;remi.gribonval@inria.fr;benjamingraham@fb.com;rvj@fb.com,6;8;6;8,,Accept (Spotlight),0,5,3.0,yes,9/25/19,Facebook;Facebook;INRIA;Facebook;Facebook,compression;quantization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3278,ICLR,2020,Continual Learning with Adaptive Weights (CLAW),Tameem Adel;Han Zhao;Richard E. Turner,tah47@cam.ac.uk;han.zhao@cs.cmu.edu;ret26@cam.ac.uk,3;8;3,,Accept (Poster),0,3,1.0,yes,9/25/19,University of Cambridge;Carnegie Mellon University;University of Cambridge,Continual learning,79;1;79,3;27;3,m;m,europe,uk,n,6
3279,ICLR,2020,Depth-Adaptive Transformer,Maha Elbayad;Jiatao Gu;Edouard Grave;Michael Auli,maha.elbayad@inria.fr;thomagram@gmail.com;egrave@fb.com;michael.auli@gmail.com,6;3;6,,Accept (Poster),0,7,1.0,yes,9/25/19,INRIA;Facebook;Facebook;Facebook,Deep learning;natural language processing;sequence modeling,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,8
3280,ICLR,2020,Robust Local Features for Improving the Generalization of Adversarial Training,Chuanbiao Song;Kun He;Jiadong Lin;Liwei Wang;John E. Hopcroft,cbsong@hust.edu.cn;brooklet60@hust.edu.cn;jdlin@hust.edu.cn;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,6;3;8,,Accept (Poster),0,7,0.0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Peking University;Cornell University,adversarial robustness;adversarial training;adversarial example;deep learning,-1;-1;-1;14;7,47;47;47;24;19,m;m,usa,usa,n,1;4
3281,ICLR,2020,Learning deep graph matching with channel-independent embedding and Hungarian attention,Tianshu Yu;Runzhong Wang;Junchi Yan;Baoxin Li,tianshuy@asu.edu;runzhong.wang@sjtu.edu.cn;yanjunchi@sjtu.edu.cn;baoxin.li@asu.edu,3;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Shanghai Jiao Tong University;Shanghai Jiao Tong University;SUN YAT-SEN UNIVERSITY,deep graph matching;edge embedding;combinatorial problem;Hungarian loss,-1;30;30;-1,299;157;157;299,m;m,NAN,NAN,n,8;10
3282,ICLR,2020,Large Batch Optimization for Deep Learning: Training BERT in 76 minutes,Yang You;Jing Li;Sashank Reddi;Jonathan Hseu;Sanjiv Kumar;Srinadh Bhojanapalli;Xiaodan Song;James Demmel;Kurt Keutzer;Cho-Jui Hsieh,youyang@cs.berkeley.edu;jingli@google.com;sashank@google.com;jhseu@google.com;sanjivk@google.com;bsrinadh@google.com;xiaodansong@google.com;demmel@berkeley.edu;keutzer@berkeley.edu;chohsieh@cs.ucla.edu,3;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of California Berkeley;Google;Google;Google;Google;Google;Google;University of California Berkeley;University of California Berkeley;University of California, Los Angeles",large-batch optimization;distributed training;fast optimizer,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,13;-1;-1;-1;-1;-1;-1;13;13;17,m;m,usa,usa,y,8;9
3283,ICLR,2020,Reanalysis of Variance Reduced Temporal Difference Learning,Tengyu Xu;Zhe Wang;Yi Zhou;Yingbin Liang,xu.3260@osu.edu;wang.10982@osu.edu;yi.zhou@utah.edu;liang.889@osu.edu,3;8;8;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Ohio State University;Ohio State University;University of Utah;Ohio State University,Reinforcement Learning;TD learning;Markovian sample;Variance Reduction,59;59;64;59,70;70;219;70,m;f,usa,usa,y,1;9
3284,ICLR,2020,Unsupervised Model Selection for Variational Disentangled Representation Learning,Sunny Duan;Loic Matthey;Andre Saraiva;Nick Watters;Chris Burgess;Alexander Lerchner;Irina Higgins,sunnyd@google.com;lmatthey@google.com;andresnds@google.com;nwatters@google.com;cpburgess@google.com;lerchner@google.com;irinah@google.com,6;6;6,,Accept (Poster),2,14,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,unsupervised disentanglement metric;disentangling;representation learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,7;5
3285,ICLR,2020,On the Weaknesses of Reinforcement Learning for Neural Machine Translation,Leshem Choshen;Lior Fox;Zohar Aizenbud;Omri Abend,leshem.choshen@mail.huji.ac.il;lior.fox@mail.huji.ac.il;zohar.aizenbud@mail.huji.ac.il;oabend@cs.huji.ac.il,6;3;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Reinforcement learning;MRT;minimum risk training;reinforce;machine translation;peakkiness;generation,85;85;85;85,216;216;216;216,m;m,europe,il,n,3;1;5;4
3286,ICLR,2020,Training binary neural networks with real-to-binary convolutions,Brais Martinez;Jing Yang;Adrian Bulat;Georgios Tzimiropoulos,brais.mart@gmail.com;psxjy3@nottingham.ac.uk;adrian@adrianbulat.com;yorgos.tzimiropoulos@nottingham.ac.uk,6;6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Samsung;University of Nottingham;Samsung;University of Nottingham,binary networks,-1;194;-1;194,-1;152;-1;152,m;m,europe,uk,n,8
3287,ICLR,2020,Mixed-curvature Variational Autoencoders,Ondrej Skopek;Octavian-Eugen Ganea;Gary B√©cigneul,oskopek@oskopek.com;oct@mit.edu;garyb@mit.edu,8;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology,variational autoencoders;riemannian manifolds;non-Euclidean geometry,-1;5;5,-1;5;5,m;m,usa,usa,y,5
3288,ICLR,2020,Program Guided Agent,Shao-Hua Sun;Te-Lin Wu;Joseph J. Lim,shaohuas@usc.edu;telinwu@usc.edu;limjj@usc.edu,6;8;8,,Accept (Spotlight),0,16,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,Program Execution;Program Executor;Program Understanding;Program Guided Agent;Learning to Execute;Deep Learning,36;36;36,62;62;62,m;m,usa,usa,n,3;1;6
3289,ICLR,2020,Revisiting Self-Training for Neural Sequence Generation,Junxian He;Jiatao Gu;Jiajun Shen;Marc'Aurelio Ranzato,junxianh@cs.cmu.edu;thomagram@gmail.com;jiajunshen@fb.com;ranzato@fb.com,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook,self-training;semi-supervised learning;neural sequence generatioin,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n,3
3290,ICLR,2020,"Ridge Regression: Structure, Cross-Validation, and Sketching",Sifan Liu;Edgar Dobriban,sfliu@stanford.edu;dobribanedgar@gmail.com,6;8,,Accept (Spotlight),0,2,0.0,yes,9/25/19,Stanford University;University of Pennsylvania,ridge regression;sketching;random matrix theory;cross-validation;high-dimensional asymptotics,5;20,4;11,f;m,usa,usa,y,
3291,ICLR,2020,Deep Network Classification by Scattering and Homotopy Dictionary Learning,John Zarka;Louis Thiry;Tomas Angles;Stephane Mallat,john.zarka@ens.fr;louis.thiry@ens.fr;tomas.angles@ens.fr;stephane.mallat@ens.fr,8;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Ecole Normale Superieure;Ecole Normale Superieure;Ecole Normale Superieure;Ecole Normale Superieure,dictionary learning;scattering transform;sparse coding;imagenet,118;118;118;118,-1;-1;-1;-1,m;f,europe,fr,y,1
3292,ICLR,2020,FreeLB: Enhanced Adversarial Training for Natural Language Understanding,Chen Zhu;Yu Cheng;Zhe Gan;Siqi Sun;Tom Goldstein;Jingjing Liu,chenzhu@cs.umd.edu;yu.cheng@microsoft.com;zhe.gan@microsoft.com;siqi.sun@microsoft.com;tomg@cs.umd.edu;jingjl@microsoft.com,8;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,"University of Maryland, College Park;Microsoft;Microsoft;Microsoft;University of Maryland, College Park;Microsoft",,12;-1;-1;-1;12;-1,91;-1;-1;-1;91;-1,m;f,NAN,NAN,n,3;8;1;4
3293,ICLR,2020,Reinforcement Learning with Competitive  Ensembles of Information-Constrained Primitives,Anirudh Goyal;Shagun Sodhani;Jonathan Binas;Xue Bin Peng;Sergey Levine;Yoshua Bengio,anirudhgoyal9119@gmail.com;sshagunsodhani@gmail.com;jbinas@gmail.com;xbpeng@berkeley.edu;svlevine@eecs.berkeley.edu;yoshua.bengio@mila.quebec,8;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Montreal;Facebook;University of Montreal;University of California Berkeley;University of California Berkeley;University of Montreal,Reinforcement Learning;Variational Information Bottleneck;Learning primitives,-1;-1;118;-1;-1;143,-1;-1;85;13;13;336,m;m,NAN,NAN,n,1
3294,ICLR,2020,Adversarially Robust Representations with Smooth Encoders,Taylan Cemgil;Sumedh Ghaisas;Krishnamurthy (Dj) Dvijotham;Pushmeet Kohli,taylancemgil@google.com;sumedhg@google.com;dvij@google.com;pushmeet@google.com,6;3;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Google;Google,Adversarial Learning;Robust Representations;Variational AutoEncoder;Wasserstein Distance;Variational Inference,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1;5;4
3295,ICLR,2020,Scalable Neural Methods for Reasoning With a Symbolic Knowledge   Base,William W. Cohen;Haitian Sun;R. Alex Hofer;Matthew Siegler,wcohen@google.com;haitiansun@google.com;rofer@google.com;msiegler@google.com,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Google;Google,question-answering;knowledge base completion;neuro-symbolic reasoning;multihop reasoning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
3296,ICLR,2020,Curriculum Loss: Robust Learning and Generalization  against Label Corruption,Yueming Lyu;Ivor W. Tsang,lv_yueming@outlook.com;ivor.tsang@uts.edu.au,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney,Curriculum Learning;deep learning,73;73,193;193,m;m,australasia,au,y,1
3297,ICLR,2020,Low-dimensional statistical manifold embedding of directed graphs,Thorben Funke;Tian Guo;Alen Lancic;Nino Antulov-Fantulin,fun@biba.uni-bremen.de;tian.guo0980@gmail.com;alen.lancic@math.hr;nino.antulov@gess.ethz.ch,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Universit√§t Bremen;;;Swiss Federal Institute of Technology,graph embedding;information geometry;graph representations,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,10
3298,ICLR,2020,VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation,Manoj Kumar;Mohammad Babaeizadeh;Dumitru Erhan;Chelsea Finn;Sergey Levine;Laurent Dinh;Durk Kingma,manojkumarsivaraj334@gmail.com;mb2@uiuc.edu;dumitru@google.com;cbfinn@eecs.berkeley.edu;slevine@google.com;laurentdinh@google.com;d.p.kingma@uva.nl,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,"Google;University of Illinois, Urbana-Champaign;Google;University of California Berkeley;Google;Google;University of Amsterdam",Video generation;flow-based generative models;stochastic video prediction,-1;-1;-1;-1;-1;-1;143,-1;-1;-1;13;-1;-1;62,m;m,europe,nl,n,5
3299,ICLR,2020,Self-Adversarial Learning with Comparative Discrimination for Text Generation,Wangchunshu Zhou;Tao Ge;Ke Xu;Furu Wei;Ming Zhou,v-waz@microsoft.com;tage@microsoft.com;kexu@nlsde.buaa.edu.cn;fuwei@microsoft.com;mingzhou@microsoft.com,8;3;8,,Accept (Poster),0,6,0.0,yes,9/25/19,Microsoft;Microsoft;Beihang University;Microsoft;Microsoft,adversarial learning;text generation,-1;-1;102;-1;-1,-1;-1;594;-1;-1,m;m,NAN,NAN,n,5;4
3300,ICLR,2020,Deep neuroethology of a virtual rodent,Josh Merel;Diego Aldarondo;Jesse Marshall;Yuval Tassa;Greg Wayne;Bence Olveczky,jsmerel@google.com;diegoaldarondo@g.harvard.edu;jesse_d_marshall@fas.harvard.edu;tassa@google.com;gregwayne@google.com;olveczky@fas.harvard.edu,6;8;6,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Google;Harvard University;Harvard University;Google;Google;Harvard University,computational neuroscience;motor control;deep RL,-1;52;52;-1;-1;52,-1;7;7;-1;-1;7,m;m,usa,usa,n,
3301,ICLR,2020,On the Global Convergence  of Training Deep Linear ResNets,Difan Zou;Philip M. Long;Quanquan Gu,knowzou@ucla.edu;plong@google.com;qgu@cs.ucla.edu,6;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,"University of California, Los Angeles;Google;University of California, Los Angeles",,-1;-1;-1,17;-1;17,m;m,usa,usa,y,1;9
3302,ICLR,2020,Measuring and Improving the Use of Graph Information in Graph Neural Networks,Yifan Hou;Jian Zhang;James Cheng;Kaili Ma;Richard T. B. Ma;Hongzhi Chen;Ming-Chang Yang,yfhou@cse.cuhk.edu.hk;jzhang@cse.cuhk.edu.hk;jcheng@cse.cuhk.edu.hk;klma@cse.cuhk.edu.hk;tbma@comp.nus.edu.sg;hzchen@cse.cuhk.edu.hk;mcyang@cse.cuhk.edu.hk,8;3;8,,Accept (Poster),0,5,0.0,yes,9/25/19,"Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;National University of Singapore;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong",,46;46;46;46;17;46;46,35;35;35;35;25;35;35,m;m,NAN,NAN,y,10
3303,ICLR,2020,AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures,Michael S. Ryoo;AJ Piergiovanni;Mingxing Tan;Anelia Angelova,mryoo@google.com;ajpiergi@indiana.edu;tanmingxing@google.com;anelia@google.com,8;8;6,,Accept (Poster),0,4,1.0,yes,9/25/19,Google;Indiana University;Google;Google,video representation learning;video understanding;activity recognition;neural architecture search,-1;64;-1;-1,-1;134;-1;-1,m;f,NAN,NAN,n,
3304,ICLR,2020,Identity Crisis: Memorization and Generalization Under Extreme Overparameterization,Chiyuan Zhang;Samy Bengio;Moritz Hardt;Michael C. Mozer;Yoram Singer,pluskid@gmail.com;bengio@google.com;moritzhardt@gmail.com;mcmozer@google.com;y.s@cs.princeton.edu,8;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;;Google;Princeton University,Generalization;Memorization;Understanding;Inductive Bias,-1;-1;-1;-1;30,-1;-1;-1;-1;6,m;m,usa,usa,y,1
3305,ICLR,2020,Spike-based causal inference for weight alignment,Jordan Guerguiev;Konrad Kording;Blake Richards,jordan.guerguiev@utoronto.ca;koerding@gmail.com;blake.richards@mcgill.ca,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Toronto University;University of Pennsylvania;McGill University,causal;inference;weight;transport;rdd;regression;discontinuity;design;cifar10;biologically;plausible,-1;20;102,-1;11;42,m;m,canada,ca,n,
3306,ICLR,2020,VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning,Luisa Zintgraf;Kyriacos Shiarlis;Maximilian Igl;Sebastian Schulze;Yarin Gal;Katja Hofmann;Shimon Whiteson,luisa.zintgraf@cs.ox.ac.uk;kikos1988@gmail.com;maximilian.igl@gmail.com;sebastian.schulze@eng.ox.ac.uk;yarin.gal@cs.ox.ac.uk;katja.hofmann@microsoft.com;shimon.whiteson@cs.ox.ac.uk,6;8;1;8,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Oxford;;;University of Oxford;University of Oxford;Microsoft;University of Oxford,Meta-Learning;Bayesian Reinforcement Learning;BAMDPs;Deep Reinforcement Learning,46;-1;-1;46;46;-1;46,1;-1;-1;1;1;-1;1,f;m,europe,uk,n,6;11
3307,ICLR,2020,Expected Information Maximization: Using the I-Projection for Mixture Density Estimation,Philipp Becker;Oleg Arenz;Gerhard Neumann,philippbecker93@googlemail.com;oleg@robot-learning.de;geri@robot-learning.de,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Karlsruhe Institute of Technology;TU Darmstadt;Karlsruhe Institute of Technology,density estimation;information projection;mixture models;generative learning;multimodal modeling,168;59;168,174;-1;174,m;m,europe,de,n,1;5;4
3308,ICLR,2020,Fast Task Inference with Variational Intrinsic Successor Features,Steven Hansen;Will Dabney;Andre Barreto;David Warde-Farley;Tom Van de Wiele;Volodymyr Mnih,stevenhansen@google.com;wdabney@google.com;andrebarreto@google.com;dwf@google.com;tvdwiele@gmail.com;vmnih@google.com,6;8;8,,Accept (Talk),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;;Google,Reinforcement Learning;Variational Intrinsic Control;Successor Features,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
3309,ICLR,2020,Kernel of CycleGAN as a principal homogeneous space,Nikita Moriakov;Jonas Adler;Jonas Teuwen,nikita.moriakov@radboudumc.nl;jonasadl@kth.se;jonas.teuwen@radboudumc.nl,3;6;8,,Accept (Poster),0,3,1.0,yes,9/25/19,"Radboud University Medical Center;KTH Royal Institute of Technology, Stockholm, Sweden;Radboud University Medical Center",Generative models;CycleGAN,248;194;248,-1;222;-1,f;m,NAN,NAN,y,4
3310,ICLR,2020,"Generative Models for Effective ML on Private, Decentralized Datasets",Sean Augenstein;H. Brendan McMahan;Daniel Ramage;Swaroop Ramaswamy;Peter Kairouz;Mingqing Chen;Rajiv Mathews;Blaise Aguera y Arcas,saugenst@google.com;mcmahan@google.com;dramage@google.com;swaroopram@google.com;kairouz@google.com;mingqing@google.com;mathews@google.com;blaisea@google.com,6;8;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,generative models;federated learning;decentralized learning;differential privacy;privacy;security;GAN,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,5
3311,ICLR,2020,Gradient-Based Neural DAG Learning,S√©bastien Lachapelle;Philippe Brouillard;Tristan Deleu;Simon Lacoste-Julien,sebastien.lachapelle@umontreal.ca;philippebrouillard@gmail.com;tristan.deleu@gmail.com;slacoste@iro.umontreal.ca,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Montreal;;University of Montreal;University of Montreal,Structure Learning;Causality;Density estimation,118;-1;118;118,85;-1;85;85,m;m,canada,ca,y,10
3312,ICLR,2020,DeepSphere: a graph-based spherical CNN,Micha√´l Defferrard;Martino Milani;Fr√©d√©rick Gusset;Nathana√´l Perraudin,michael.defferrard@epfl.ch;martino.milani@epfl.ch;frederick.gusset@epfl.ch;nathanael.perraudin@sdsc.ethz.ch,6;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology,spherical cnns;graph neural networks;geometric deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,10
3313,ICLR,2020,IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks,Michael Luo;Jiahao Yao;Richard Liaw;Eric Liang;Ion Stoica,michael.luo@berkeley.edu;jiahaoyao@berkeley.edu;rliaw@berkeley.edu;ekhliang@gmail.com;istoica@berkeley.edu,6;6;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Reinforcement Learning;Artificial Intelligence;Distributed Computing;Neural Networks,-1;-1;-1;-1;-1,13;13;13;13;13,m;m,usa,usa,n,
3314,ICLR,2020,Improving Neural Language Generation with Spectrum Control,Lingxiao Wang;Jing Huang;Kevin Huang;Ziniu Hu;Guangtao Wang;Quanquan Gu,lingxw@cs.ucla.edu;jing.huang@jd.com;kevin.huang3@jd.com;bull@cs.ucla.edu;guangtao.wang@jd.com;qgu@cs.ucla.edu,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"University of California, Los Angeles;JD AI Research;JD AI Research;University of California, Los Angeles;JD AI Research;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1,17;-1;-1;17;-1;17,m;m,usa,usa,y,8;3
3315,ICLR,2020,Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks,Sanjeev Arora;Simon S. Du;Zhiyuan Li;Ruslan Salakhutdinov;Ruosong Wang;Dingli Yu,arora@cs.princeton.edu;ssdu@ias.edu;zhiyuanli@cs.princeton.edu;rsalakhu@cs.cmu.edu;ruosongw@andrew.cmu.edu;dingliy@cs.princeton.edu,8;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,"Princeton University;Institue for Advanced Study, Princeton;Princeton University;Carnegie Mellon University;Carnegie Mellon University;Princeton University",small data;neural tangent kernel;UCI database;few-shot learning;kernel SVMs;deep learning theory;kernel design,30;-1;30;1;1;30,6;-1;6;27;27;6,m;m,usa,usa,n,6
3316,ICLR,2020,NAS evaluation is frustratingly hard,Antoine Yang;Pedro M. Esperan√ßa;Fabio M. Carlucci,antoineyang3@gmail.com;pedro.esperanca@huawei.com;fabiom.carlucci@gmail.com,8;1;8,,Accept (Poster),0,4,0.0,yes,9/25/19,ENS Paris-Saclay;Huawei Technologies Ltd.;Facebook,neural architecture search;nas;benchmark;reproducibility;harking,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
3317,ICLR,2020,Understanding and Robustifying Differentiable Architecture Search,Arber Zela;Thomas Elsken;Tonmoy Saikia;Yassine Marrakchi;Thomas Brox;Frank Hutter,zelaa@cs.uni-freiburg.de;thomas.elsken@de.bosch.com;saikiat@cs.uni-freiburg.de;marrakch@cs.uni-freiburg.de;brox@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,8;8;8,,Accept (Talk),1,5,0.0,yes,9/25/19,Universit√§t Freiburg;Bosch;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Neural Architecture Search;AutoML;AutoDL;Deep Learning;Computer Vision,-1;-1;-1;-1;-1;-1,-1;297;-1;-1;-1;-1,m;m,NAN,NAN,n,3;8;1
3318,ICLR,2020,Meta-Q-Learning,Rasool Fakoor;Pratik Chaudhari;Stefano Soatto;Alexander J. Smola,rasool.fakoor@mavs.uta.edu;pratikac@seas.upenn.edu;soatto@cs.ucla.edu;alex@smola.org,6;8;8,,Accept (Talk),0,10,0.0,yes,9/25/19,"University of Texas, Arlington;University of Pennsylvania;University of California, Los Angeles;Carnegie-Mellon University",meta reinforcement learning;propensity estimation;off-policy,-1;20;-1;1,-1;11;17;27,m;m,usa,usa,n,
3319,ICLR,2020,Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints,Mengtian Li;Ersin Yumer;Deva Ramanan,mtli@cs.cmu.edu;meyumer@gmail.com;deva@cs.cmu.edu,6;6;6,,Accept (Poster),0,4,1.0,yes,9/25/19,Carnegie Mellon University;Uber;Carnegie Mellon University,budgeted training;learning rate schedule;linear schedule;annealing;learning rate decay,1;-1;1,27;-1;27,f;m,usa,usa,n,2
3320,ICLR,2020,Training individually fair ML models with sensitive subspace robustness,Mikhail Yurochkin;Amanda Bower;Yuekai Sun,mikhail.yurochkin@ibm.com;amandarg@umich.edu;yuekai@umich.edu,6;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,International Business Machines;University of Michigan;University of Michigan,fairness;adversarial robustness,-1;7;7,-1;21;21,m;m,usa,usa,y,7;4
3321,ICLR,2020,Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation,Hang Gao;Xizhou Zhu;Stephen Lin;Jifeng Dai,hangg@berkeley.edu;ezra0408@mail.ustc.edu.cn;stevelin@microsoft.com;jifdai@microsoft.com,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of California Berkeley;University of Science and Technology of China;Microsoft;Microsoft,Effective Receptive Fields;Deformation Modeling;Dynamic Inference,-1;-1;-1;-1,13;80;-1;-1,m;m,NAN,NAN,n,
3322,ICLR,2020,From Variational to Deterministic Autoencoders,Partha Ghosh;Mehdi S. M. Sajjadi;Antonio Vergari;Michael Black;Bernhard Scholkopf,partha.ghosh@tuebingen.mpg.de;msajjadi@tue.mpg.de;antonio.vergari@tuebingen.mpg.de;black@tue.mpg.de;bs@tue.mpg.de,6;8;6,,Accept (Poster),0,11,0.0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,Unsupervised learning;Generative Models;Variational Autoencoders;Regularization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1;5
3323,ICLR,2020,GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation,Chence Shi*;Minkai Xu*;Zhaocheng Zhu;Weinan Zhang;Ming Zhang;Jian Tang,chenceshi@pku.edu.cn;mkxu@apex.sjtu.edu.cn;zhaocheng.zhu@umontreal.ca;wnzhang@sjtu.edu.cn;mzhang_cs@pku.edu.cn;jian.tang@hec.ca,6;6;6,,Accept (Poster),0,17,1.0,yes,9/25/19,Peking University;Shanghai Jiao Tong University;University of Montreal;Shanghai Jiao Tong University;Peking University;HEC Montreal,Molecular graph generation;deep generative models;normalizing flows;autoregressive models,14;30;118;30;14;-1,24;157;85;157;24;-1,m;m,canada,ca,n,8;10;5
3324,ICLR,2020,A Theoretical Analysis of the Number of Shots in Few-Shot Learning,Tianshi Cao;Marc T Law;Sanja Fidler,tianshi.cao@mail.utoronto.ca;law@cs.toronto.edu;fidler@cs.toronto.edu,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Toronto University;University of Toronto;University of Toronto,Few shot learning;Meta Learning;Performance Bounds,-1;18;18,-1;18;18,u;f,canada,ca,y,6
3325,ICLR,2020,Deep Learning of Determinantal Point Processes via Proper Spectral Sub-gradient,Tianshu Yu;Yikang Li;Baoxin Li,tianshuy@asu.edu;yikang.li@asu.edu;baoxin.li@asu.edu,3;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,determinantal point processes;deep learning;optimization,-1;-1;-1,299;299;299,m;m,NAN,NAN,n,2
3326,ICLR,2020,Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space,AkshatKumar Nigam;Pascal Friederich;Mario Krenn;Alan Aspuru-Guzik,akshat.nigam@mail.utoronto.ca;pascal.friederich@utoronto.ca;mario.krenn@utoronto.ca;alan@aspuru.com,8;3;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Toronto University;Toronto University;Toronto University;Toronto University,Generative model;Chemical Space;Inverse Molecular Design,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5
3327,ICLR,2020,Denoising and Regularization via Exploiting the Structural Bias of Convolutional Generators,Reinhard Heckel and Mahdi Soltanolkotabi,reinhard.heckel@tum.de;msoltoon@gmail.com,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Technical University Munich;University of Southern California,theory for deep learning;convolutional network;deep image prior;deep decoder;dynamics of gradient descent;overparameterization,-1;36,-1;62,m;m,usa,usa,y,1
3328,ICLR,2020,SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks,Chungkuk Yoo;Bumsoo Kang;Minsik Cho,ckyoo@ibm.com;steve.kang@kaist.ac.kr;thyeros@gmail.com,8;8;3,,Accept (Poster),0,6,0.0,yes,9/25/19,"International Business Machines;Korea Advanced Institute of Science and Technology;University of Texas, Austin",channel pooling;efficient training and inferencing;lifelong learning;transfer learning;multi task,-1;-1;-1,-1;110;-1,m;f,asia,in,n,
3329,ICLR,2020,A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms,Yoshua Bengio;Tristan Deleu;Nasim Rahaman;Nan Rosemary Ke;Sebastien Lachapelle;Olexa Bilaniuk;Anirudh Goyal;Christopher Pal,yoshua.bengio@mila.quebec;tristan.deleu@gmail.com;nasim.rahaman@tuebingen.mpg.de;rosemary.nan.ke@gmail.com;sebastien.lachapelle@umontreal.ca;obilaniu@gmail.com;anirudhgoyal9119@gmail.com;chris.j.pal@gmail.com,8;8;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Mila;University of Montreal;Max-Planck Institute;;University of Montreal;;;Polytechnique Montreal,meta-learning;transfer learning;structure learning;modularity;causality,143;118;-1;-1;118;-1;-1;316,336;85;-1;-1;85;-1;-1;-1,m;m,canada,ca,y,6;1;10
3330,ICLR,2020,Classification-Based Anomaly Detection for General Data,Liron Bergman;Yedid Hoshen,liron.bergman@mail.huji.ac.il;yedid@cs.huji.ac.il,6;8;8,,Accept (Poster),0,3,1.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,anomaly detection,85;85,216;216,m;m,europe,il,n,1
3331,ICLR,2020,B-Spline CNNs on Lie groups,Erik J Bekkers,e.j.bekkers@tue.nl,8;3;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Eindhoven University of Technology,equivariance;Lie groups;B-Splines;G-CNNs;deep learning;group convolution;computer vision;medical image analysis,-1,185,m,NAN,NAN,y,1
3332,ICLR,2020,Global Relational Models of Source Code,Vincent J. Hellendoorn;Charles Sutton;Rishabh Singh;Petros Maniatis;David Bieber,vjhellendoorn@gmail.com;charlessutton@google.com;rising@google.com;maniatis@google.com;dbieber@google.com,6;6;3,,Accept (Poster),1,8,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Google,Models of Source Code;Graph Neural Networks;Structured Learning,1;-1;-1;-1;-1,27;-1;-1;-1;-1,m;m,NAN,NAN,n,8;10
3333,ICLR,2020,NeurQuRI: Neural Question Requirement Inspector for Answerability Prediction in Machine Reading Comprehension,Seohyun Back;Sai Chetan Chinthakindi;Akhil Kedia;Haejun Lee;Jaegul Choo,scv.back@samsung.com;sai.chetan@samsung.com;akhil.kedia@samsung.com;haejun82.lee@samsung.com;jchoo@korea.ac.kr,6;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Korea University,Question Answering;Machine Reading Comprehension;Answerability Prediction;Neural Checklist,-1;-1;-1;-1;168,-1;-1;-1;-1;179,m;m,asia,kr,n,8
3334,ICLR,2020,Adjustable Real-time Style Transfer,Mohammad Babaeizadeh;Golnaz Ghiasi,mb2@uiuc.edu;golnazg@google.com,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Illinois, Urbana-Champaign;Google",Image Style Transfer;Deep Learning,-1;-1,-1;-1,m;f,NAN,NAN,n,
3335,ICLR,2020,Ranking Policy Gradient,Kaixiang Lin;Jiayu Zhou,linkaixi@msu.edu;jiayuz@msu.edu,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Michigan State University;Michigan State University,Sample-efficient reinforcement learning;off-policy learning.,102;102,84;84,m;m,usa,usa,y,1
3336,ICLR,2020,Neural Epitome Search for Architecture-Agnostic Network Compression,Daquan Zhou;Xiaojie Jin;Qibin Hou;Kaixin Wang;Jianchao Yang;Jiashi Feng,zhoudaquan21@gmail.com;jinxiaojie@bytedance.com;andrewhoux@gmail.com;kaixin.wang@u.nus.edu;yangjianchao@bytedance.com;elefjia@nus.edu.sg,6;3;6,,Accept (Poster),0,5,0.0,yes,9/25/19,National University of Singapore;ByteDance;National University of Singapore;National University of Singapore;ByteDance;National University of Singapore,Network Compression;Classification;Deep Learning;Weights Sharing,-1;-1;17;17;-1;17,-1;-1;25;25;-1;25,u;m,asia,sg,n,
3337,ICLR,2020,Learning to Guide Random Search,Ozan Sener;Vladlen Koltun,ozansener@gmail.com;vkoltun@gmail.com,6;8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Intel;Intel,Random search;Derivative-free optimization;Learning continuous control,-1;-1,-1;-1,m;m,NAN,NAN,y,11
3338,ICLR,2020,BERTScore: Evaluating Text Generation with BERT,Tianyi Zhang*;Varsha Kishore*;Felix Wu*;Kilian Q. Weinberger;Yoav Artzi,zty27x@gmail.com;vk352@cornell.edu;fw245@cornell.edu;kqw4@cornell.edu;yoav@cs.cornell.edu,8;3;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Stanford University;Cornell University;Cornell University;Cornell University;Cornell University,Metric;Evaluation;Contextual Embedding;Text Generation,5;7;7;7;7,4;19;19;19;19,m;m,usa,usa,n,3;4
3339,ICLR,2020,Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs,Aditya Paliwal;Felix Gimeno;Vinod Nair;Yujia Li;Miles Lubin;Pushmeet Kohli;Oriol Vinyals,adipal@google.com;fgimeno@google.com;vinair@google.com;yujiali@google.com;mlubin@google.com;pushmeet@google.com;vinyals@google.com,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,reinforcement learning;learning to optimize;combinatorial optimization;computation graphs;model parallelism;learning for systems,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,10
3340,ICLR,2020,Meta-Learning Acquisition Functions for Transfer Learning in Bayesian Optimization,Michael Volpp;Lukas P. Fr√∂hlich;Kirsten Fischer;Andreas Doerr;Stefan Falkner;Frank Hutter;Christian Daniel,mvolpp89@googlemail.com;lukas.froehlich@de.bosch.com;k.fischer-lotte@online.de;andreas.doerr3@de.bosch.com;stefan.falkner@de.bosch.com;fh@cs.uni-freiburg.de;christian.daniel@de.bosch.com,8;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Bosch;Bosch;Forschungszentrum J√ºlich;Bosch;Bosch;Universit√§t Freiburg;Bosch,Transfer Learning;Meta Learning;Bayesian Optimization;Reinforcement Learning,-1;-1;-1;-1;-1;-1;-1,297;297;-1;297;297;-1;297,m;m,NAN,NAN,n,6;11;1
3341,ICLR,2020,Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation,Xinjie Fan;Yizhe Zhang;Zhendong Wang;Mingyuan Zhou,xfan@utexas.edu;yizhe.zhang@microsoft.com;zw2533@columbia.edu;mingyuan.zhou@mccombs.utexas.edu,6;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Texas, Austin;Microsoft;Columbia University;University of Texas, Austin",binary softmax;discrete variables;policy gradient;pseudo actions;reinforcement learning;variance reduction,-1;-1;24;-1,-1;-1;16;-1,m;m,usa,usa,n,
3342,ICLR,2020,Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking,Yunhan Jia;Yantao Lu;Junjie Shen;Qi Alfred Chen;Hao Chen;Zhenyu Zhong;Tao Wei,jack0082010@gmail.com;ylu25@syr.edu;junjies1@uci.edu;alfchen@uci.edu;chen@ucdavis.edu;edwardzhong@baidu.com;lenx.wei@gmail.com,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Michigan;Syracuse University;University of California, Irvine;University of California, Irvine;University of California, Davis;Baidu;Peking University",Adversarial examples;object detection;object tracking;security;autonomous vehicle;deep learning,7;194;-1;-1;-1;-1;-1,21;292;96;96;55;-1;-1,m;m,asia,in,n,2;4
3343,ICLR,2020,Pre-training Tasks for Embedding-based Large-scale Retrieval,Wei-Cheng Chang;Felix X. Yu;Yin-Wen Chang;Yiming Yang;Sanjiv Kumar,wchang2@cs.cmu.edu;felixyu@google.com;yinwen@google.com;yiming@cs.cmu.edu;sanjivk@google.com,6;6;1,,Accept (Poster),0,8,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google;Carnegie Mellon University;Google,natural language processing;large-scale retrieval;unsupervised representation learning;paragraph-level pre-training;two-tower Transformer models,1;-1;-1;1;-1,27;-1;-1;27;-1,m;m,NAN,NAN,n,8
3344,ICLR,2020,MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius,Runtian Zhai;Chen Dan;Di He;Huan Zhang;Boqing Gong;Pradeep Ravikumar;Cho-Jui Hsieh;Liwei Wang,zhairuntian@pku.edu.cn;cdan@cs.cmu.edu;dihe@microsoft.com;huan@huan-zhang.com;boqinggo@outlook.com;pradeepr@cs.cmu.edu;chohsieh@cs.ucla.edu;wanglw@cis.pku.edu.cn,8;3;6,,Accept (Poster),0,6,0.0,yes,9/25/19,"Peking University;Carnegie Mellon University;Microsoft;Carnegie Mellon University;International Computer Science Institute;Carnegie Mellon University;University of California, Los Angeles;Peking University",Adversarial Robustness;Provable Adversarial Defense;Randomized Smoothing;Robustness Certification,14;1;-1;1;-1;1;-1;14,24;27;-1;27;-1;27;17;24,m;m,asia,cn,y,4
3345,ICLR,2020,R√©nyi Fair Inference,Sina Baharlouei;Maher Nouiehed;Ahmad Beirami;Meisam Razaviyayn,baharlou@usc.edu;nouiehed@usc.edu;beirami@mit.edu;razaviya@usc.edu,8;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Southern California;University of Southern California;Massachusetts Institute of Technology;University of Southern California,,36;36;5;36,62;62;5;62,m;m,usa,usa,y,7;4
3346,ICLR,2020,An Exponential Learning Rate Schedule for Deep Learning,Zhiyuan Li;Sanjeev Arora,zhiyuanli@cs.princeton.edu;arora@cs.princeton.edu,6;8;8;6,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Princeton University;Princeton University,batch normalization;weight decay;learning rate;deep learning theory,30;30,6;6,m;m,usa,usa,y,1
3347,ICLR,2020,Graph Convolutional Reinforcement Learning,Jiechuan Jiang;Chen Dun;Tiejun Huang;Zongqing Lu,jiechuan.jiang@pku.edu.cn;cd46@rice.edu;tjhuang@pku.edu.cn;zongqing.lu@pku.edu.cn,6;6;6,,Accept (Poster),1,12,0.0,yes,9/25/19,Peking University;Rice University;Peking University;Peking University,,14;92;14;14,24;105;24;24,u;m,asia,cn,n,10
3348,ICLR,2020,In Search for a SAT-friendly Binarized Neural Network Architecture,Nina Narodytska;Hongce Zhang;Aarti Gupta;Toby Walsh,n.narodytska@gmail.com;hongcez@princeton.edu;aartig@cs.princeton.edu;toby.walsh@data61.csiro.au,8;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,University of New South Wales;Princeton University;Princeton University;CSIRO,verification;Boolean satisfiability;Binarized Neural Networks,-1;30;30;-1,-1;6;6;-1,f;m,asia,in,n,
3349,ICLR,2020,A Constructive Prediction of the Generalization Error Across Scales,Jonathan S. Rosenfeld;Amir Rosenfeld;Yonatan Belinkov;Nir Shavit,jonsr@mit.edu;amir@eecs.yorku.ca;belinkov@mit.edu;shanir@csail.mit.edu,6;8;1,,Accept (Poster),0,5,0.0,yes,9/25/19,Massachusetts Institute of Technology;York University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,neural networks;deep learning;generalization error;scaling;scalability;vision;language,5;194;5;5,5;416;5;5,m;m,usa,usa,n,1
3350,ICLR,2020,Improving Generalization in Meta Reinforcement Learning using Learned Objectives,Louis Kirsch;Sjoerd van Steenkiste;Juergen Schmidhuber,louis@idsia.ch;sjoerd@idsia.ch;juergen@idsia.ch,6;6;8,,Accept (Spotlight),0,7,1.0,yes,9/25/19,IDSIA;IDSIA;IDSIA,meta reinforcement learning;meta learning;reinforcement learning,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
3351,ICLR,2020,Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning,Akanksha Atrey;Kaleigh Clary;David Jensen,aatrey@cs.umass.edu;kclary@cs.umass.edu;jensen@cs.umass.edu,8;3;1,,Accept (Poster),0,8,0.0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",explainability;saliency maps;representations;deep reinforcement learning,24;24;24,209;209;209,f;m,usa,usa,n,
3352,ICLR,2020,A Generalized Training Approach for Multiagent Learning,Paul Muller;Shayegan Omidshafiei;Mark Rowland;Karl Tuyls;Julien Perolat;Siqi Liu;Daniel Hennes;Luke Marris;Marc Lanctot;Edward Hughes;Zhe Wang;Guy Lever;Nicolas Heess;Thore Graepel;Remi Munos,pmuller@google.com;somidshafiei@google.com;markrowland@google.com;karltuyls@google.com;perolat@google.com;liusiqi@google.com;hennes@google.com;marris@google.com;lanctot@google.com;edwardhughes@google.com;zhewang@google.com;guylever@google.com;heess@google.com;thore@google.com;munos@google.com,8;8;8,,Accept (Talk),0,10,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,multiagent learning;game theory;training;games,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3353,ICLR,2020,Scalable Model Compression by Entropy Penalized Reparameterization,Deniz Oktay;Johannes Ball√©;Saurabh Singh;Abhinav Shrivastava,doktay@princeton.edu;jballe@google.com;saurabhsingh@google.com;abhinav@cs.umd.edu,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"Princeton University;Google;Google;University of Maryland, College Park",deep learning;model compression;computer vision;information theory,30;-1;-1;12,6;-1;-1;91,m;m,usa,usa,n,
3354,ICLR,2020,Rotation-invariant clustering of neuronal responses in primary visual cortex,Ivan Ustyuzhaninov;Santiago A. Cadena;Emmanouil Froudarakis;Paul G. Fahey;Edgar Y. Walker;Erick Cobos;Jacob Reimer;Fabian H. Sinz;Andreas S. Tolias;Matthias Bethge;Alexander S. Ecker,ivan.ustyuzhaninov@bethgelab.org;santiago.cadena@bethgelab.org;froudara@bcm.edu;paul.fahey@bcm.edu;eywalker@bcm.edu;ecobos@bcm.edu;reimer@bcm.edu;fabian.sinz@bcm.edu;astolias@bcm.edu;matthias@bethgelab.org;alexander.ecker@uni-tuebingen.de,8;8;8,,Accept (Talk),0,7,0.0,yes,9/25/19,"Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Centre for Integrative Neuroscience, AG Bethge;University of Tuebingen",computational neuroscience;neural system identification;functional cell types;deep learning;rotational equivariance,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;143,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;91,m;m,europe,de,n,5
3355,ICLR,2020,Ensemble Distribution Distillation,Andrey Malinin;Bruno Mlodozeniec;Mark Gales,am969@yandex-team.ru;bkm28@cam.ac.uk;mjfg@eng.cam.ac.uk,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Yandex;University of Cambridge;University of Cambridge,Ensemble Distillation;Knowledge Distillation;Uncertainty Estimation;Density Estimation,-1;79;79,-1;3;3,m;m,europe,uk,n,
3356,ICLR,2020,ES-MAML: Simple Hessian-Free Meta Learning,Xingyou Song;Wenbo Gao;Yuxiang Yang;Krzysztof Choromanski;Aldo Pacchiano;Yunhao Tang,xsong@berkeley.edu;wg2279@columbia.edu;yxyang@google.com;kchoro@google.com;pacchiano@berkeley.edu;yt2541@columbia.edu,8;8;1;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of California Berkeley;Columbia University;Google;Google;University of California Berkeley;Columbia University,ES;MAML;evolution;strategies;meta;learning;gaussian;perturbation;reinforcement;learning;adaptation,-1;24;-1;-1;-1;24,13;16;-1;-1;13;16,m;m,usa,usa,n,
3357,ICLR,2020,SAdam: A Variant of Adam for Strongly Convex Functions,Guanghui Wang;Shiyin Lu;Quan Cheng;Wei-wei Tu;Lijun Zhang,guhuwang@gmail.com;lsy1116@qq.com;chengquangm@gmail.com;tuwwcn@gmail.com;zljzju@gmail.com,8;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Nanjing University;Zhejiang University;Zhejiang University;4Paradigm Inc.;Zhejiang University,Online convex optimization;Adaptive online learning;Adam,-1;39;39;-1;39,-1;107;107;-1;107,m;m,asia,cn,y,1
3358,ICLR,2020,Continual Learning with Bayesian Neural Networks for Non-Stationary Data,Richard Kurle;Botond Cseke;Alexej Klushyn;Patrick van der Smagt;Stephan G√ºnnemann,richard.kurle@tum.de;botond.cseke@argmax.ai;a.klushyn@tum.de;smagt@argmax.ai;guennemann@in.tum.de,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,"Technical University Munich;Volkswagen Group, Machine Learning Research Lab (MLRL);Technical University Munich;Volkswagen Group, Machine Learning Research Lab (MLRL);Technical University Munich",Continual Learning;Online Variational Bayes;Non-Stationary Data;Bayesian Neural Networks;Variational Inference;Lifelong Learning;Concept Drift;Episodic Memory,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11
3359,ICLR,2020,Automated curriculum generation through setter-solver interactions,Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Timothy Lillicrap,lampinen@stanford.edu;sracaniere@google.com;adamsantoro@google.com;reichert@google.com;vladfi@google.com;countzero@google.com,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Stanford University;Google;Google;Google;Google;Google,Deep Reinforcement Learning;Automatic Curriculum,5;-1;-1;-1;-1;-1,4;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3360,ICLR,2020,NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search,Xuanyi Dong;Yi Yang,xuanyi.dxy@gmail.com;yi.yang@uts.edu.au,8;8;8,,Accept (Spotlight),0,14,2.0,yes,9/25/19,University of Technology Sydney;Zhejiang University,Neural Architecture Search;AutoML;Benchmark,-1;73,-1;193,m;m,australasia,au,n,10
3361,ICLR,2020,Dynamic Time Lag Regression: Predicting What & When,Mandar Chandorkar;Cyril Furtlehner;Bala Poduval;Enrico Camporeale;Michele Sebag,mandar.chandorkar@cwi.nl;furtlehn@lri.fr;bala.poduval@unh.edu;e.camporeale@cwi.nl;michele.sebag@lri.fr,6;6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,"Centrum voor Wiskunde en Informatica;CNRS, Universit√© Paris-Saclay;University of New Hampshire;Centrum voor Wiskunde en Informatica;CNRS, Universit√© Paris-Saclay",Dynamic Time-Lag Regression;Time Delay;Regression;Time Series,-1;-1;248;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,y,11;1
3362,ICLR,2020,Double Neural Counterfactual Regret Minimization,Hui Li;Kailiang Hu;Shaohua Zhang;Yuan Qi;Le Song,ken.lh@antfin.com;hkl163251@antfin.com;yaohua.zsh@antfin.com;yuan.qi@antfin.com;lsong@cc.gatech.edu,6;8,,Accept (Poster),0,2,0.0,yes,9/25/19,Antfin;Antfin;Antfin;Antfin;Georgia Institute of Technology,Counterfactual Regret Minimization;Imperfect Information game;Neural Strategy;Deep Learning;Robust Sampling,-1;-1;-1;-1;13,-1;-1;-1;-1;38,u;m,usa,usa,y,10
3363,ICLR,2020,Robust anomaly detection and backdoor attack detection via differential privacy,Min Du;Ruoxi Jia;Dawn Song,min.du@berkeley.edu;ruoxijia@berkeley.edu;dawnsong@berkeley.edu,6;3;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,outlier detection;novelty detection;backdoor attack detection;system log anomaly detection;differential privacy,-1;-1;-1,13;13;13,f;f,usa,usa,y,4
3364,ICLR,2020,Optimistic Exploration even with a Pessimistic Initialisation,Tabish Rashid;Bei Peng;Wendelin Boehmer;Shimon Whiteson,tabish.rashid@cs.ox.ac.uk;bei.peng@cs.ox.ac.uk;wendelin.boehmer@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Reinforcement Learning;Exploration;Optimistic Initialisation,46;46;46;46,1;1;1;1,m;m,europe,uk,y,10
3365,ICLR,2020,Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators,Daniel Stoller;Sebastian Ewert;Simon Dixon,d.stoller@qmul.ac.uk;sewert@spotify.com;s.e.dixon@qmul.ac.uk,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Queen Mary University London;Spotify;Queen Mary University London,Adversarial Learning;Semi-supervised Learning;Image generation;Image segmentation;Missing Data,-1;-1;-1,-1;-1;-1,m;m,europe,uk,y,2;5;4
3366,ICLR,2020,Mathematical Reasoning in Latent Space,Dennis Lee;Christian Szegedy;Markus Rabe;Sarah Loos;Kshitij Bansal,ldennis@google.com;szegedy@google.com;mrabe@google.com;smoos@google.com;kbk@google.com,8;8;8,,Accept (Talk),0,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google,machine learning;formal reasoning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;m,NAN,NAN,n,1;10
3367,ICLR,2020,Deep Symbolic Superoptimization Without Human Knowledge,Hui Shi;Yang Zhang;Xinyun Chen;Yuandong Tian;Jishen Zhao,hshi@ucsd.edu;yang.zhang2@ibm.com;xinyun.chen@berkeley.edu;yuandong@fb.com;jzhao@ucsd.edu,6;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,"University of California, San Diego;International Business Machines;University of California Berkeley;Facebook;University of California, San Diego",,-1;-1;-1;-1;-1,31;-1;13;-1;31,f;f,usa,usa,n,8
3368,ICLR,2020,Neural Execution of Graph Algorithms,Petar Veliƒçkoviƒá;Rex Ying;Matilde Padovano;Raia Hadsell;Charles Blundell,petarv@google.com;rexying@stanford.edu;mp861@cam.ac.uk;raia@google.com;cblundell@google.com,8;8;1,,Accept (Poster),0,4,0.0,yes,9/25/19,Google;Stanford University;University of Cambridge;Google;Google,Graph Neural Networks;Graph Algorithms;Learning to Execute;Program Synthesis;Message Passing Neural Networks;Deep Learning,-1;5;79;-1;-1,-1;4;3;-1;-1,m;m,NAN,NAN,n,10
3369,ICLR,2020,Encoding word order in complex embeddings,Benyou Wang;Donghao Zhao;Christina Lioma;Qiuchi Li;Peng Zhang;Jakob Grue Simonsen,wang@dei.unipd.it;zhaodh@tju.edu.cn;chrh@di.ku.dk;qiuchili@dei.unipd.it;pzhang@tju.edu.cn;simonsen@di.ku.dk,6;8;6;8,,Accept (Spotlight),0,9,0.0,yes,9/25/19,Universita' degli studi di Padova;Zhejiang University;University of Copenhagen;Universita' degli studi di Padova;Zhejiang University;University of Copenhagen,word embedding;complex-valued neural network;position embedding,-1;39;92;-1;39;92,-1;107;101;-1;107;101,m;m,europe,dk,y,8;3
3370,ICLR,2020,Deep Double Descent: Where Bigger Models and More Data Hurt,Preetum Nakkiran;Gal Kaplun;Yamini Bansal;Tristan Yang;Boaz Barak;Ilya Sutskever,preetum@cs.harvard.edu;galkaplun@g.harvard.edu;ybansal@g.harvard.edu;tristanyang@college.harvard.edu;b@boazbarak.org;ilyasu@openai.com,8;6;6,,Accept (Poster),0,4,1.0,yes,9/25/19,Harvard University;Harvard University;Harvard University;Harvard University;Harvard University;OpenAI,deep learning;double descent;optimization;SGD;complexity,52;52;52;52;52;-1,7;7;7;7;7;-1,m;m,NAN,NAN,n,
3371,ICLR,2020,The Early Phase of Neural Network Training,Jonathan Frankle;David J. Schwab;Ari S. Morcos,jfrankle@mit.edu;dschwab@gc.cuny.edu;arimorcos@gmail.com,8;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;The City University of New York;Facebook,empirical;learning dynamics;lottery tickets;critical periods;early,5;-1;-1,5;-1;-1,m;m,NAN,NAN,n,
3372,ICLR,2020,"Don't Use Large Mini-batches, Use Local SGD",Tao Lin;Sebastian U. Stich;Kumar Kshitij Patel;Martin Jaggi,tao.lin@epfl.ch;sebastian.stich@epfl.ch;kumarkshitijpatel@gmail.com;martin.jaggi@epfl.ch,6;6;6,,Accept (Poster),7,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
3373,ICLR,2020,A Closer Look at the Optimization Landscapes of Generative Adversarial Networks,Hugo Berard;Gauthier Gidel;Amjad Almahairi;Pascal Vincent;Simon Lacoste-Julien,berard.hugo@gmail.com;gauthier.gidel@umontreal.ca;amjadmahayri@gmail.com;vincentp@iro.umontreal.ca;slacoste@iro.umontreal.ca,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Facebook;University of Montreal;Facebook;University of Montreal;University of Montreal,Deep Learning;Generative models;GANs;Optimization;Visualization,-1;118;-1;118;118,-1;85;-1;85;85,m;m,canada,ca,y,1;5;4;9
3374,ICLR,2020,Learning to Control PDEs with Differentiable Physics,Philipp Holl;Nils Thuerey;Vladlen Koltun,philipp.holl@tum.de;nils.thuerey@tum.de;vkoltun@gmail.com,6;8;6,,Accept (Spotlight),0,6,0.0,yes,9/25/19,Technical University Munich;Technical University Munich;Intel,Differentiable physics;Optimal control;Deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3375,ICLR,2020,Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network,Taiji Suzuki;Hiroshi Abe;Tomoaki Nishimura,taiji@mist.i.u-tokyo.ac.jp;abe@ipride.co.jp;tomoaki.nishimura@nttdata.com,8;6;6,,Accept (Spotlight),0,8,0.0,yes,9/25/19,The University of Tokyo;;Nttdata,Generalization error;compression based bound;local Rademacher complexity,64;-1;-1,36;-1;-1,m;m,NAN,NAN,y,1
3376,ICLR,2020,Rethinking the Hyperparameters for Fine-tuning,Hao Li;Pratik Chaudhari;Hao Yang;Michael Lam;Avinash Ravichandran;Rahul Bhotika;Stefano Soatto,hao.li.ict@gmail.com;pratikac@seas.upenn.edu;lancelot365@gmail.com;michlam@amazon.com;avinash.a.ravichandran@gmail.com;bhotikar@amazon.com;soatto@ucla.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,"Amazon;University of Pennsylvania;Amazon;Amazon;Amazon;Amazon;University of California, Los Angeles",fine-tuning;hyperparameter search;transfer learning,-1;20;-1;-1;-1;-1;-1,-1;11;-1;-1;-1;-1;17,m;m,usa,usa,n,6;2
3377,ICLR,2020,PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction,Sangdon Park;Osbert Bastani;Nikolai Matni;Insup Lee,sangdonp@cis.upenn.edu;obastani@seas.upenn.edu;nmatni@seas.upenn.edu;lee@cis.upenn.edu,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,PAC;confidence sets;classification;regression;reinforcement learning,20;20;20;20,11;11;11;11,m;m,usa,usa,y,1
3378,ICLR,2020,Deep Semi-Supervised Anomaly Detection,Lukas Ruff;Robert A. Vandermeulen;Nico G√∂rnitz;Alexander Binder;Emmanuel M√ºller;Klaus-Robert M√ºller;Marius Kloft,contact@lukasruff.com;vandermeulen@cs.uni-kl.de;nico.goernitz@tu-berlin.de;alexander_binder@sutd.edu.sg;mueller@bit.uni-bonn.de;klaus-robert.mueller@tu-berlin.de;kloft@cs.uni-kl.de,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Aignostics GmbH;TU Kaiserslautern;TU Berlin;Singapore University of Technology and Design;University of Bonn;TU Berlin;TU Kaiserslautern,anomaly detection;deep learning;semi-supervised learning;unsupervised learning;outlier detection;one-class classification;deep anomaly detection;deep one-class classification,-1;194;118;-1;143;118;194,-1;-1;-1;-1;106;-1;-1,m;m,europe,de,n,
3379,ICLR,2020,AtomNAS: Fine-Grained End-to-End Neural Architecture Search,Jieru Mei;Yingwei Li;Xiaochen Lian;Xiaojie Jin;Linjie Yang;Alan Yuille;Jianchao Yang,meijieru@gmail.com;yingwei.li@jhu.edu;xiaochen.lian@bytedance.com;jinxiaojie@bytedance.com;linjie.yang@bytedance.com;alan.l.yuille@gmail.com;yangjianchao@bytedance.com,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;ByteDance;ByteDance;ByteDance;Johns Hopkins University;ByteDance,Neural Architecture Search;Image Classification,73;73;-1;-1;-1;73;-1,12;12;-1;-1;-1;12;-1,m;m,NAN,NAN,n,
3380,ICLR,2020,"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference",Ting-Kuei Hu;Tianlong Chen;Haotao Wang;Zhangyang Wang,tkhu@tamu.edu;wiwjp619@tamu.edu;htwang@tamu.edu;atlaswang@tamu.edu,8;8;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;Texas A&M,adversarial robustness;efficient inference,46;46;46;46,177;177;177;177,m;m,NAN,NAN,n,4
3381,ICLR,2020,CLEVRER: Collision Events for Video Representation and Reasoning,Kexin Yi*;Chuang Gan*;Yunzhu Li;Pushmeet Kohli;Jiajun Wu;Antonio Torralba;Joshua B. Tenenbaum,kyi@g.harvard.edu;ganchuang1990@gmail.com;liyunzhu@mit.edu;pushmeet@google.com;jiajunwu@mit.edu;torralba@mit.edu;jbt@mit.edu,6;8;6,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Harvard University;;Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neuro-symbolic;Reasoning,52;-1;5;-1;5;5;5,7;-1;5;-1;5;5;5,u;m,usa,usa,n,1
3382,ICLR,2020,Computation Reallocation for Object Detection,Feng Liang;Chen Lin;Ronghao Guo;Ming Sun;Wei Wu;Junjie Yan;Wanli Ouyang,liangfeng@sensetime.com;linchen@sensetime.com;guoronghao@sensetime.com;sunming1@sensetime.com;wuwei@sensetime.com;yanjunjie@sensetime.com;wanli.ouyang@sydney.edu.au,3;6;6;8,,Accept (Poster),0,6,0.0,yes,9/25/19,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;University of Sydney,Neural Architecture Search;Object Detection,-1;-1;-1;-1;-1;-1;64,-1;-1;-1;-1;-1;-1;60,m;m,europe,uk,n,2
3383,ICLR,2020,Making Efficient Use of Demonstrations to Solve Hard Exploration Problems,Caglar Gulcehre;Tom Le Paine;Bobak Shahriari;Misha Denil;Matt Hoffman;Hubert Soyer;Richard Tanburn;Steven Kapturowski;Neil Rabinowitz;Duncan Williams;Gabriel Barth-Maron;Ziyu Wang;Nando de Freitas;Worlds Team,caglarg@google.com;tpaine@google.com;bshahr@google.com;mdenil@google.com;mwhoffman@google.com;soyer@google.com;tanburn@google.com;skapturowski@google.com;ncr@google.com;duncanwilliams@google.com;gabrielbm@google.com;ziyu@google.com;nandodefreitas@google.com;deepmind-worlds-team@google.com,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,imitation learning;deep learning;reinforcement learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3384,ICLR,2020,Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks,Sreyas Mohan;Zahra Kadkhodaie;Eero P. Simoncelli;Carlos Fernandez-Granda,sm7582@nyu.edu;zk388@nyu.edu;eero.simoncelli@nyu.edu;cfgranda@cims.nyu.edu,6;6;6,,Accept (Poster),0,4,1.0,yes,9/25/19,New York University;New York University;New York University;New York University,denoising;overfitting;generalization;robustness;interpretability;analysis of neural networks,22;22;22;22,29;29;29;29,m;m,usa,usa,y,1
3385,ICLR,2020,Permutation Equivariant Models for Compositional Generalization in Language,Jonathan Gordon;David Lopez-Paz;Marco Baroni;Diane Bouchacourt,jg801@cam.ac.uk;dlp@fb.com;mbaroni@fb.com;dianeb@fb.com,8;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Cambridge;Facebook;Facebook;Facebook,Compositionality;Permutation Equivariance;Language Processing,79;-1;-1;-1,3;-1;-1;-1,m;f,NAN,NAN,n,3;1
3386,ICLR,2020,Automated Relational Meta-learning,Huaxiu Yao;Xian Wu;Zhiqiang Tao;Yaliang Li;Bolin Ding;Ruirui Li;Zhenhui Li,huaxiuyao@psu.edu;xwu9@nd.edu;zqtao@ece.neu.edu;yaliangl.ub@gmail.com;bolin.ding@alibaba-inc.com;rrli@cs.ucla.edu;jessieli@ist.psu.edu,8;8;3,,Accept (Poster),0,5,0.0,yes,9/25/19,"Pennsylvania State University;University of Notre Dame;Northeastern University;Alibaba Group;Alibaba Group;University of California, Los Angeles;Pennsylvania State University",meta-learning;task heterogeneity;meta-knowledge graph,43;118;16;-1;-1;-1;43,-1;157;906;-1;-1;17;-1,m;f,usa,usa,n,6;10
3387,ICLR,2020,A Probabilistic Formulation of Unsupervised Text Style Transfer,Junxian He;Xinyi Wang;Graham Neubig;Taylor Berg-Kirkpatrick,junxianh@cs.cmu.edu;xinyiw1@cs.cmu.edu;gneubig@cs.cmu.edu;tberg@eng.ucsd.edu,6;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;University of California, San Diego",unsupervised text style transfer;deep latent sequence model,1;1;1;-1,27;27;27;31,m;m,usa,usa,n,3;5;4
3388,ICLR,2020,Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth,Igor Lovchinsky;Alon Daks;Israel Malkin;Pouya Samangouei;Ardavan Saeedi;Yang Liu;Swami Sankaranarayanan;Tomer Gafner;Ben Sternlieb;Patrick Maher;Nathan Silberman,ilovchinsky@butterflynetwork.com;adaks@butterflynetwork.com;imalkin@butterflynetwork.com;psamangouei@butterflynetwork.com;asaeedi@butterflynetwork.com;yliu@butterflynetwork.com;ssankaranarayanan@butterflynetwork.com;tgafner@butterflynetwork.com;bsternlieb@butterflynetwork.com;pmaher@butterflynetwork.com;nsilberman@butterflynetwork.com,8;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc,Evaluation Metrics;Medical Imaging,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3389,ICLR,2020,Combining Q-Learning and Search with Amortized Value Estimates,Jessica B. Hamrick;Victor Bapst;Alvaro Sanchez-Gonzalez;Tobias Pfaff;Theophane Weber;Lars Buesing;Peter W. Battaglia,jhamrick@google.com;vbapst@google.com;alvarosg@google.com;tpfaff@google.com;theophane@google.com;lbuesing@google.com;peterbattaglia@google.com,6;6;6,,Accept (Poster),0,10,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,model-based RL;Q-learning;MCTS;search,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
3390,ICLR,2020,Generalized Convolutional Forest Networks for Domain Generalization and Visual Recognition,Jongbin Ryu;Gitaek Kwon;Ming-Hsuan Yang;Jongwoo Lim,jongbin.ryu@gmail.com;kwongitack@gmail.com;mhyang@ucmerced.edu;jlim@hanyang.ac.kr,6;3;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Ajou University;;University of California at Merced;Hanyang University,,-1;-1;-1;194,852;-1;-1;393,m;m,asia,kr,n,1
3391,ICLR,2020,Graph Constrained Reinforcement Learning for Natural Language Action Spaces,Prithviraj Ammanabrolu;Matthew Hausknecht,raj.ammanabrolu@gatech.edu;matthew.hausknecht@microsoft.com,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Georgia Institute of Technology;Microsoft,natural language generation;deep reinforcement learning;knowledge graphs;interactive fiction,13;-1,38;-1,m;m,NAN,NAN,n,3;10
3392,ICLR,2020,Improved memory in recurrent neural networks with sequential non-normal dynamics,Emin Orhan;Xaq Pitkow,aeminorhan@gmail.com;xaq@rice.edu,6;8;3,,Accept (Poster),0,5,0.0,yes,9/25/19,New York University;Rice University,recurrent neural networks;memory;non-normal dynamics,22;92,29;105,m;m,australasia,au,n,
3393,ICLR,2020,Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks,Christopher J. Cueva;Peter Y. Wang;Matthew Chin;Xue-Xin Wei,ccueva@gmail.com;peterwang724@gmail.com;mattchin35@gmail.com;weixxpku@gmail.com,6;8;6,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Columbia University;;;Columbia University,recurrent network;head direction system;neural circuits;neural coding,24;-1;-1;-1,16;-1;-1;-1,m;m,asia,in,n,
3394,ICLR,2020,GenDICE: Generalized Offline Estimation of Stationary Values,Ruiyi Zhang*;Bo Dai*;Lihong Li;Dale Schuurmans,ryzhang@cs.duke.edu;bodai@google.com;lihongli.cs@gmail.com;schuurmans@google.com,8;8;8,,Accept (Talk),0,6,0.0,yes,9/25/19,Duke University;Google;Amazon;Google,Off-policy Policy Evaluation;Reinforcement Learning;Stationary Distribution Correction Estimation;Fenchel Dual,46;-1;-1;-1,20;-1;-1;-1,m;m,NAN,NAN,y,1
3395,ICLR,2020,Adversarially robust transfer learning,Ali Shafahi;Parsa Saadatpanah;Chen Zhu;Amin Ghiasi;Christoph Studer;David Jacobs;Tom Goldstein,ashafahi@cs.umd.edu;parsa@cs.umd.edu;chenzhu@cs.umd.edu;amin@cs.umd.edu;studer@cornell.edu;djacobs@cs.umd.edu;tomg@cs.umd.edu,8;8;1,,Accept (Poster),0,6,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Cornell University;University of Maryland, College Park;University of Maryland, College Park",,12;12;12;12;7;12;12,91;91;91;91;19;91;91,m;m,usa,usa,n,6;1;4
3396,ICLR,2020,Learning from Explanations with Neural Execution Tree,Ziqi Wang*;Yujia Qin*;Wenxuan Zhou;Jun Yan;Qinyuan Ye;Leonardo Neves;Zhiyuan Liu;Xiang Ren,ziqi-wan16@mails.tsinghua.edu.cn;qinyj16@mails.tsinghua.edu.cn;zhouwenx@usc.edu;yanjun@usc.edu;qinyuany@usc.edu;lneves@snap.com;liuzy@tsinghua.edu.cn;xiangren@usc.edu,8;8;3,,Accept (Poster),0,6,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Southern California;University of Southern California;University of Southern California;Snap Inc.;Tsinghua University, Tsinghua University;University of Southern California",,4;4;36;36;36;-1;4;36,23;23;62;62;62;-1;23;62,m;m,usa,usa,n,3;1
3397,ICLR,2020,Universal Approximation with Certified Networks,Maximilian Baader;Matthew Mirman;Martin Vechev,mbaader@inf.ethz.ch;matthew.mirman@inf.ethz.ch;martin.vechev@inf.ethz.ch,3;8;6,,Accept (Poster),1,7,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,adversarial robustness;universal approximation;certified network;interval bound propagation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;4
3398,ICLR,2020,Extreme Classification via Adversarial Softmax Approximation,Robert Bamler;Stephan Mandt,rbamler@uci.edu;stephan.mandt@gmail.com,6;3;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of California, Irvine;University of California, Irvine",Extreme classification;negative sampling,-1;-1,96;96,m;m,usa,usa,y,1;4
3399,ICLR,2020,Synthesizing Programmatic Policies that Inductively Generalize,Jeevana Priya Inala;Osbert Bastani;Zenna Tavares;Armando Solar-Lezama,jinala@csail.mit.edu;obastani@seas.upenn.edu;zenna@mit.edu;asolar@csail.mit.edu,8;6;6,,Accept (Poster),0,11,0.0,yes,9/25/19,Massachusetts Institute of Technology;University of Pennsylvania;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Program synthesis;reinforcement learning;inductive generalization,5;20;5;5,5;11;5;5,f;m,usa,usa,n,1
3400,ICLR,2020,Image-guided Neural Object Rendering,Justus Thies;Michael Zollh√∂fer;Christian Theobalt;Marc Stamminger;Matthias Nie√üner,justus.thies@tum.de;michael@zollhoefer.com;marc.stamminger@fau.de;theobalt@mpi-inf.mpg.de;niessner@tum.de,6;8;3;6,,Accept (Poster),0,1,0.0,yes,9/25/19,Technical University Munich;Facebook;Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;Max-Planck Institute;Technical University Munich,Neural Rendering;Neural Image Synthesis,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
3401,ICLR,2020,Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?,Simon S. Du;Sham M. Kakade;Ruosong Wang;Lin F. Yang,ssdu@ias.edu;sham@cs.washington.edu;ruosongw@andrew.cmu.edu;linyang@ee.ucla.edu,6;8;8,,Accept (Spotlight),0,6,0.0,yes,9/25/19,"Institue for Advanced Study, Princeton;University of Washington;Carnegie Mellon University;University of California, Los Angeles",reinforcement learning;function approximation;lower bound;representation,-1;11;1;-1,-1;26;27;17,m;m,usa,usa,y,
3402,ICLR,2020,Interpretable Complex-Valued Neural Networks for Privacy Protection,Liyao Xiang;Hao Zhang;Haotian Ma;Yifan Zhang;Jie Ren;Quanshi Zhang,xiangliyao08@sjtu.edu.cn;1603023-zh@sjtu.edu.cn;11612807@mail.sustc.edu.cn;zhangyf_sjtu@sjtu.edu.cn;ariesrj@sjtu.edu.cn;zqs1022@sjtu.edu.cn,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Deep Learning;Privacy Protection;Complex-Valued Neural Networks,30;30;-1;30;30;30,157;157;80;157;157;157,f;m,asia,cn,n,4
3403,ICLR,2020,The Shape of Data: Intrinsic Distance for Data Distributions,Anton Tsitsulin;Marina Munkhoeva;Davide Mottin;Panagiotis Karras;Alex Bronstein;Ivan Oseledets;Emmanuel Mueller,tsitsulin@bit.uni-bonn.de;marina.munkhoeva@skolkovotech.ru;davide@cs.au.dk;piekarras@gmail.com;bron@cs.technion.ac.il;i.oseledets@skoltech.ru;mueller@bit.uni-bonn.de,6;6;6,,Accept (Poster),1,4,0.0,yes,9/25/19,"University of Bonn;Skolkovo Institute of Science and Technology;Aarhus University;Aarhus University;Technion, Technion;Skolkovo Institute of Science and Technology;University of Bonn",Deep Learning;Generative Models;Nonlinear Dimensionality Reduction;Manifold Learning;Similarity and Distance Learning;Spectral Methods,143;-1;92;92;27;-1;143,106;-1;115;115;-1;-1;106,m;m,europe,uk,y,5
3404,ICLR,2020,Dynamics-Aware Embeddings,William Whitney;Rajat Agarwal;Kyunghyun Cho;Abhinav Gupta,wfwhitney@gmail.com;ra2630@nyu.edu;kyunghyun.cho@nyu.edu;abhinavg@cs.cmu.edu,8;8;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,New York University;New York University;New York University;Carnegie Mellon University,representation learning;reinforcement learning;rl,22;22;22;1,29;29;29;27,m;m,usa,usa,n,
3405,ICLR,2020,Extreme Tensoring for Low-Memory Preconditioning ,Xinyi Chen;Naman Agarwal;Elad Hazan;Cyril Zhang;Yi Zhang,xinyic@google.com;namanagarwal@google.com;ehazan@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,8;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Google;Google;Princeton University;Princeton University;Princeton University,optimization;deep learning,-1;-1;30;30;30,-1;-1;6;6;6,f;m,usa,usa,y,3
3406,ICLR,2020,Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue,Byeongchang Kim;Jaewoo Ahn;Gunhee Kim,byeongchang.kim@vision.snu.ac.kr;jaewoo.ahn@vision.snu.ac.kr;gunhee@snu.ac.kr,8;6;8,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University,dialogue;knowledge;language;conversation,39;39;39,64;64;64,m;m,asia,kr,n,8
3407,ICLR,2020,Geom-GCN: Geometric Graph Convolutional Networks,Hongbin Pei;Bingzhe Wei;Kevin Chen-Chuan Chang;Yu Lei;Bo Yang,gspeihongbing@163.com;bwei6@illinois.edu;kcchang@illinois.edu;csylei@comp.polyu.edu.hk;ybo@jlu.edu.cn,6;8;6,,Accept (Spotlight),2,6,2.0,yes,9/25/19,"Xi'an Jiaotong University;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;The Hong Kong Polytechnic University;Jilin University",Deep Learning;Graph Convolutional Network;Network Geometry,-1;-1;-1;118;-1,555;-1;-1;171;952,m;m,NAN,NAN,n,10
3408,ICLR,2020,Compositional languages emerge in a neural iterated learning model,Yi Ren;Shangmin Guo;Matthieu Labeau;Shay B. Cohen;Simon Kirby,y.ren-18@sms.ed.ac.uk;s.guo-16@sms.ed.ac.uk;matthieu.labeau@gmail.com;scohen@inf.ed.ac.uk;simon.kirby@ed.ac.uk,6;6;6,,Accept (Poster),0,17,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh;T√©l√©com ParisTech;University of Edinburgh;University of Edinburgh,Compositionality;Multi-agent;Emergent language;Iterated learning,36;36;-1;36;36,30;30;187;30;30,m;m,europe,uk,n,3;1
3409,ICLR,2020,Knowledge Consistency between Neural Networks and Beyond,Ruofan Liang;Tianlin Li;Longfei Li;Jing Wang;Quanshi Zhang,nexuslrf@sjtu.edu.cn;litl@act.buaa.edu.cn;1776752575@sjtu.edu.cn;wangjing215@huawei.com;zqs1022@sjtu.edu.cn,8;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Shanghai Jiao Tong University;Beihang University;Shanghai Jiao Tong University;Huawei Technologies Ltd.;Shanghai Jiao Tong University,Deep Learning;Interpretability;Convolutional Neural Networks,30;102;30;-1;30,157;594;157;-1;157,m;m,asia,cn,n,
3410,ICLR,2020,Differentially Private Meta-Learning,Jeffrey Li;Mikhail Khodak;Sebastian Caldas;Ameet Talwalkar,jwl3@andrew.cmu.edu;khodak@cs.cmu.edu;scaldas@cs.cmu.edu;talwalkar@cmu.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Differential Privacy;Meta-Learning;Federated Learning,1;1;1;1,27;27;27;27,m;m,usa,usa,y,6;3
3411,ICLR,2020,Stochastic Conditional Generative Networks with Basis Decomposition,Ze Wang;Xiuyuan Cheng;Guillermo Sapiro;Qiang Qiu,ze.w@duke.edu;xiuyuan.cheng@duke.edu;guillermo.sapiro@duke.edu;qiang.qiu@duke.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,,46;46;46;46,20;20;20;20,m;m,europe,se,y,5;4
3412,ICLR,2020,Meta-Learning with Warped Gradient Descent,Sebastian Flennerhag;Andrei A. Rusu;Razvan Pascanu;Francesco Visin;Hujun Yin;Raia Hadsell,flennerhag@google.com;andreirusu@google.com;razp@google.com;visin@google.com;hujun.yin@manchester.ac.uk;raia@google.com,8;8;8,,Accept (Talk),2,3,0.0,yes,9/25/19,Google;Google;Google;Google;University of Manchester;Google,meta-learning;transfer learning,-1;-1;-1;-1;248;-1,-1;-1;-1;-1;55;-1,m;f,NAN,NAN,n,6
3413,ICLR,2020,Neural Text Generation With Unlikelihood Training,Sean Welleck;Ilia Kulikov;Stephen Roller;Emily Dinan;Kyunghyun Cho;Jason Weston,wellecks@nyu.edu;kulikov@cs.nyu.edu;roller@fb.com;edinan@fb.com;kyunghyun.cho@nyu.edu;jase@fb.com,6;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,New York University;New York University;Facebook;Facebook;New York University;Facebook,language modeling;machine learning,22;22;-1;-1;22;-1,29;29;-1;-1;29;-1,m;m,NAN,NAN,n,3
3414,ICLR,2020,Duration-of-Stay Storage Assignment under Uncertainty,Michael Lingzhi Li;Elliott Wolf;Daniel Wintz,mlli@mit.edu;ewolf@lineagelogistics.com;dwintz@lineagelogistics.com,6;3;6,,Accept (Spotlight),0,16,0.0,yes,9/25/19,Massachusetts Institute of Technology;Lineagelogistics;Lineagelogistics,Storage Assignment;Deep Learning;Duration-of-Stay;Application;Natural Language Processing;Parallel Network,5;-1;-1,5;-1;-1,m;m,NAN,NAN,y,
3415,ICLR,2020,Non-Autoregressive Dialog State Tracking,Hung Le;Richard Socher;Steven C.H. Hoi,l.hung1610@gmail.com;rsocher@salesforce.com;shoi@salesforce.com,6;1;6,,Accept (Poster),1,3,0.0,yes,9/25/19,Singapore Management University;SalesForce.com;SalesForce.com,task-oriented;dialogues;dialogue state tracking;non-autoregressive,79;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3416,ICLR,2020,Scalable and Order-robust Continual Learning with Additive Parameter Decomposition,Jaehong Yoon;Saehoon Kim;Eunho Yang;Sung Ju Hwang,jaehong.yoon@kaist.ac.kr;shkim@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,1;6;8,,Accept (Poster),0,16,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Continual Learning;Lifelong Learning;Catastrophic Forgetting;Deep Learning,-1;-1;-1;-1,110;-1;110;110,m;m,NAN,NAN,n,7
3417,ICLR,2020,Automatically Discovering and Learning New Visual Categories with Ranking Statistics,Kai Han;Sylvestre-Alvise Rebuffi;Sebastien Ehrhardt;Andrea Vedaldi;Andrew Zisserman,khan@robots.ox.ac.uk;srebuffi@robots.ox.ac.uk;hyenal@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk;az@robots.ox.ac.uk,3;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,deep learning;classification;novel classes;transfer learning;clustering;incremental learning,46;46;46;46;46,1;1;1;1;1,m;m,europe,uk,n,
3418,ICLR,2020,On Identifiability in Transformers,Gino Brunner;Yang Liu;Damian Pascual;Oliver Richter;Massimiliano Ciaramita;Roger Wattenhofer,brunnegi@ethz.ch;liu.yang@alumni.ethz.ch;dpascual@ethz.ch;richtero@ethz.ch;massi@google.com;wattenhofer@ethz.ch,8;6;6,,Accept (Poster),0,7,1.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Google;Swiss Federal Institute of Technology,Self-attention;interpretability;identifiability;BERT;Transformer;NLP;explanation;gradient attribution,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
3419,ICLR,2020,Robust Reinforcement Learning for Continuous Control with Model Misspecification,Daniel J. Mankowitz;Nir Levine;Rae Jeong;Abbas Abdolmaleki;Jost Tobias Springenberg;Yuanyuan Shi;Jackie Kay;Todd Hester;Timothy Mann;Martin Riedmiller,dmankowitz@google.com;nirlevine@google.com;raejeong@google.com;aabdolmaleki@google.com;springenberg@google.com;yyshi@google.com;kayj@google.com;toddhester@google.com;timothymann@google.com;riedmiller@google.com,8;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;robustness,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3420,ICLR,2020,Enhancing Adversarial Defense by k-Winners-Take-All,Chang Xiao;Peilin Zhong;Changxi Zheng,chang@cs.columbia.edu;pz2225@columbia.edu;cxz@cs.columbia.edu,8;8;8,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Columbia University;Columbia University;Columbia University,adversarial defense;activation function;winner takes all,24;24;24,16;16;16,m;m,usa,usa,y,4
3421,ICLR,2020,Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction,Taeuk Kim;Jihun Choi;Daniel Edmiston;Sang-goo Lee,taeuk@europa.snu.ac.kr;jhchoi@europa.snu.ac.kr;danedmiston@uchicago.edu;sglee@europa.snu.ac.kr,6;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Seoul National University;Seoul National University;University of Chicago;Seoul National University,,39;39;51;39,64;64;9;64,m;m,asia,kr,n,3
3422,ICLR,2020,Neural Policy Gradient Methods: Global Optimality and Rates of Convergence,Lingxiao Wang;Qi Cai;Zhuoran Yang;Zhaoran Wang,lingxiaowang2022@u.northwestern.edu;qicai2022@u.northwestern.edu;zy6@princeton.edu;zhaoranwang@gmail.com,8;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,Northwestern University;Northwestern University;Princeton University;Northwestern University,,46;46;30;46,22;22;6;22,f;m,usa,usa,y,1;9
3423,ICLR,2020,Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier,Connie Kou;Hwee Kuan Lee;Ee-Chien Chang;Teck Khim Ng,conniekoukl@gmail.com;leehk@bii.a-star.edu.sg;changec@comp.nus.edu.sg;ngtk@comp.nus.edu.sg,6;6;3,,Accept (Poster),0,11,0.0,yes,9/25/19,National University of Singapore;A*STAR;National University of Singapore;National University of Singapore,adversarial attack;transformation defenses;distribution classifier,17;-1;17;17,25;-1;25;25,f;m,asia,sg,n,8;4
3424,ICLR,2020,Sample Efficient Policy Gradient Methods with Recursive Variance Reduction,Pan Xu;Felicia Gao;Quanquan Gu,panxu@cs.ucla.edu;fxgao1160@engineering.ucla.edu;qgu@cs.ucla.edu,6;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Policy Gradient;Reinforcement Learning;Sample Efficiency,-1;-1;-1,17;17;17,m;m,usa,usa,y,9
3425,ICLR,2020,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,Zhenzhong Lan;Mingda Chen;Sebastian Goodman;Kevin Gimpel;Piyush Sharma;Radu Soricut,lanzhzh@google.com;mchen@ttic.edu;seabass@google.com;kgimpel@ttic.edu;piyushsharma@google.com;rsoricut@google.com,6;8;8,,Accept (Spotlight),8,8,0.0,yes,9/25/19,Google;Toyota Technological Institute at Chicago;Google;Toyota Technological Institute at Chicago;Google;Google,Natural Language Processing;BERT;Representation Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3
3426,ICLR,2020,State-only Imitation with Transition Dynamics Mismatch,Tanmay Gangwani;Jian Peng,gangwan2@illinois.edu;jianpeng@illinois.edu,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Imitation learning;Reinforcement Learning;Inverse Reinforcement Learning,-1;-1,-1;-1,m;m,usa,usa,y,4
3427,ICLR,2020,Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search,Anji Liu;Jianshu Chen;Mingze Yu;Yu Zhai;Xuewen Zhou;Ji Liu,anjiliu219@gmail.com;chenjianshu@gmail.com;yumingze@kuaishou.com;zhaiyu@kuaishou.com;zhouxuewen@kuaishou.com;ji.liu.uwisc@gmail.com,6;8;8,,Accept (Talk),0,9,0.0,yes,9/25/19,"University of California, Los Angeles;Tencent AI Lab;Kuaishou Technology;Kuaishou Technology;Kuaishou Technology;Kwai Inc.",parallel Monte Carlo Tree Search (MCTS);Upper Confidence bound for Trees (UCT);Reinforcement Learning (RL),-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;m,asia,in,n,
3428,ICLR,2020,Gradientless Descent: High-Dimensional Zeroth-Order Optimization,Daniel Golovin;John Karro;Greg Kochanski;Chansoo Lee;Xingyou Song;Qiuyi Zhang,dgg@google.com;karro@google.com;gpk@google.com;chansoo@google.com;xingyousong@google.com;qiuyiz@google.com,6;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Zeroth Order Optimization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3429,ICLR,2020,Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning,Ali Mousavi;Lihong Li;Qiang Liu;Denny Zhou,ali.mousavi1988@gmail.com;lihongli.cs@gmail.com;dennyzhou@google.com;lqiang@cs.utexas.edu,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,"Apple;Amazon;Google;University of Texas, Austin",reinforcement learning;off-policy estimation;importance sampling;propensity score,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,y,1
3430,ICLR,2020,Hyper-SAGNN: a self-attention based graph neural network for hypergraphs,Ruochi Zhang;Yuesong Zou;Jian Ma,ruochiz@andrew.cmu.edu;logic.zys@gmail.com;jianma@cs.cmu.edu,8;8,,Accept (Poster),0,3,1.0,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University,graph neural network;hypergraph;representation learning,1;-1;1,27;-1;27,m;m,usa,usa,n,8;10
3431,ICLR,2020,Unpaired Point Cloud Completion on Real Scans using Adversarial Training,Xuelin Chen;Baoquan Chen;Niloy J. Mitra,xuelin.chen.sdu@gmail.com;baoquan.chen@gmail.com;n.mitra@cs.ucl.ac.uk,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Shandong University;Peking University;University College London,point cloud completion;generative adversarial network;real scans,-1;14;52,-1;24;-1,m;m,europe,uk,n,
3432,ICLR,2020,The intriguing role of module criticality in the generalization of deep networks,Niladri Chatterji;Behnam Neyshabur;Hanie Sedghi,niladri.chatterji@berkeley.edu;neyshabur@google.com;hsedghi@google.com,8;6;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,University of California Berkeley;Google;Google,Module Criticality Phenomenon;Complexity Measure;Deep Learning,-1;-1;-1,13;-1;-1,m;f,NAN,NAN,y,1
3433,ICLR,2020,SpikeGrad: An ANN-equivalent Computation Model for Implementing Backpropagation with Spikes,Johannes C. Thiele;Olivier Bichler;Antoine Dupret,johannes.thiele@cea.fr;olivier.bichler@cea.fr;antoine.dupret@cea.fr,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,CEA;CEA;CEA,spiking neural network;neuromorphic engineering;backpropagation,194;194;194,1027;1027;1027,m;m,europe,gr,n,
3434,ICLR,2020,Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics,Sungyong Seo*;Chuizheng Meng*;Yan Liu,sungyons@usc.edu;chuizhem@usc.edu;yanliu.cs@usc.edu,6;8;8,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,physics-aware learning;spatial difference operators;sparsely-observed dynamics,36;36;36,62;62;62,m;f,usa,usa,n,10
3435,ICLR,2020,Neural Network Branching for Neural Network Verification ,Jingyue Lu;M. Pawan Kumar,jingyue.lu@spc.ox.ac.uk;pawan@robots.ox.ac.uk,6;8;8,,Accept (Talk),0,7,0.0,yes,9/25/19,University of Oxford;University of Oxford,Neural Network Verification;Branch and Bound;Graph Neural Network;Learning to branch,46;46,1;1,f;m,europe,uk,n,1;10
3436,ICLR,2020,DivideMix: Learning with Noisy Labels as Semi-supervised Learning,Junnan Li;Richard Socher;Steven C.H. Hoi,junnan.li@salesforce.com;rsocher@salesforce.com;shoi@salesforce.com,6;6;6,,Accept (Poster),1,4,1.0,yes,9/25/19,SalesForce.com;SalesForce.com;SalesForce.com,label noise;semi-supervised learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3437,ICLR,2020,Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,6;6;8,,Accept (Poster),0,6,1.0,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,deep learning;reinforcement learning;graph neural networks;natural language processing;question generation,248;194;248,438;-1;438,f;m,usa,usa,n,10
3438,ICLR,2020,Bayesian Meta Sampling for Fast Uncertainty Adaptation,Zhenyi Wang;Yang Zhao;Ping Yu;Ruiyi Zhang;Changyou Chen,zhenyiwa@buffalo.edu;yzhao63@buffalo.edu;pingyu@buffalo.edu;ryzhang@cs.duke.edu;changyou@buffalo.edu,6;6;3,,Accept (Poster),0,6,0.0,yes,9/25/19,"State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo;Duke University;State University of New York, Buffalo",Bayesian Sampling;Uncertainty Adaptation;Meta Learning;Variational Inference,-1;-1;-1;46;-1,-1;-1;-1;20;-1,u;m,NAN,NAN,y,11
3439,ICLR,2020,BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES,Amin Ghiasi;Ali Shafahi;Tom Goldstein,amin@cs.umd.edu;ashafahi@cs.umd.edu;tomg@cs.umd.edu,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",,12;12;12,91;91;91,m;m,usa,usa,n,4
3440,ICLR,2020,Progressive Memory Banks for Incremental Domain Adaptation,Nabiha Asghar;Lili Mou;Kira A. Selby;Kevin D. Pantasdo;Pascal Poupart;Xin Jiang,nasghar@uwaterloo.ca;doublepower.mou@gmail.com;kaselby@uwaterloo.ca;kevin.pantasdo@uwaterloo.ca;ppoupart@uwaterloo.ca;jiang.xin@huawei.com,6;6;6,,Accept (Poster),0,0,0.0,yes,9/25/19,University of Waterloo;University of Alberta;University of Waterloo;University of Waterloo;University of Waterloo;Huawei Technologies Ltd.,natural language processing;domain adaptation,30;102;30;30;30;-1,235;136;235;235;235;-1,f;m,NAN,NAN,y,8;3
3441,ICLR,2020,Deep Learning For Symbolic Mathematics,Guillaume Lample;Fran√ßois Charton,guillaume.lample@gmail.com;fcharton@fb.com,8;6;8,,Accept (Spotlight),7,8,0.0,yes,9/25/19,Facebook;Facebook,symbolic;math;deep learning;transformers,-1;-1,-1;-1,m;m,NAN,NAN,n,
3442,ICLR,2020,Contrastive Learning of Structured World Models,Thomas Kipf;Elise van der Pol;Max Welling,t.n.kipf@uva.nl;e.e.vanderpol@uva.nl;m.welling@uva.nl,8;8;8,,Accept (Talk),0,10,1.0,yes,9/25/19,University of Amsterdam;University of Amsterdam;University of Amsterdam,state representation learning;graph neural networks;model-based reinforcement learning;relational learning;object discovery,143;143;143,62;62;62,m;m,europe,nl,n,10
3443,ICLR,2020,Decentralized Deep Learning with Arbitrary Communication Compression,Anastasia Koloskova*;Tao Lin*;Sebastian U Stich;Martin Jaggi,anastasia.koloskova@epfl.ch;tao.lin@epfl.ch;sebastian.stich@epfl.ch;martin.jaggi@epfl.ch,3;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,y,
3444,ICLR,2020,Masked Based Unsupervised Content Transfer,Ron Mokady;Sagie Benaim;Lior Wolf;Amit Bermano,sagiebenaim@gmail.com;ron.mokady@gmail.com;wolf@fb.com;amit.bermano@gmail.com,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Tel Aviv University;;Facebook;Tel-Aviv University,,30;-1;-1;-1,188;-1;-1;-1,m;m,asia,in,n,8;2
3445,ICLR,2020,Fair Resource Allocation in Federated Learning,Tian Li;Maziar Sanjabi;Ahmad Beirami;Virginia Smith,tianli@cmu.edu;maziar.sanjabi@gmail.com;ahmad.beirami@gmail.com;smithv@cmu.edu,6;3;3,,Accept (Poster),0,5,0.0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Carnegie Mellon University,federated learning;fairness;distributed optimization,1;-1;-1;1,27;-1;-1;27,f;f,usa,usa,y,7
3446,ICLR,2020,Gap-Aware Mitigation of Gradient Staleness,Saar Barkai;Ido Hakimi;Assaf Schuster,saarbarkai@gmail.com;idohakimi@gmail.com;assaf@cs.technion.ac.il,6;3;3,,Accept (Poster),0,6,0.0,yes,9/25/19,Technion;Technion;Technion,distributed;asynchronous;large scale;gradient staleness;staleness penalization;sgd;deep learning;neural networks;optimization,-1;27;27,-1;-1;-1,u;m,NAN,NAN,y,1;9
3447,ICLR,2020,A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES,Krishnamurthy (Dj) Dvijotham;Jamie Hayes;Borja Balle;Zico Kolter;Chongli Qin;Andras Gyorgy;Kai Xiao;Sven Gowal;Pushmeet Kohli,dvij@google.com;j.hayes@cs.ucl.ac.uk;bballe@google.com;zkolter@cs.cmu.edu;chongliqin@google.com;agyorgy@google.com;kaix@mit.edu;sgowal@google.com;pushmeet@google.com,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Google;University College London;Google;Carnegie Mellon University;Google;Google;Massachusetts Institute of Technology;Google;Google,verification of machine learning;certified robustness of neural networks,-1;52;-1;1;-1;-1;5;-1;-1,-1;-1;-1;27;-1;-1;5;-1;-1,m;m,NAN,NAN,y,1;4
3448,ICLR,2020,I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively,Haotao Wang;Tianlong Chen;Zhangyang Wang;Kede Ma,htwang@tamu.edu;wiwjp619@tamu.edu;atlaswang@tamu.edu;kede.ma@cityu.edu.hk,3;8;3,,Accept (Poster),0,9,0.0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;The Hong Kong Polytechnic University,model comparison,46;46;46;118,177;177;177;171,m;m,asia,hk,n,
3449,ICLR,2020,Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification,Bennet Breier;Arno Onken,b.breier@sms.ed.ac.uk;aonken@inf.ed.ac.uk,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh,convolutional neural networks;neural network transparency;AI explainability;deep Taylor decomposition;supervised classification;zebrafish;transparency;behavioral research;optical flow,36;36,30;30,m;m,europe,uk,n,8
3450,ICLR,2020,"On the steerability"" of generative adversarial networks""",Ali Jahanian*;Lucy Chai*;Phillip Isola,jahanian@mit.edu;lrchai@mit.edu;phillipi@mit.edu,8;8;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,generative adversarial network;latent space interpolation;dataset bias;model generalization,5;5;5,5;5;5,m;m,usa,usa,n,1;5;4
3451,ICLR,2020,Imitation Learning via Off-Policy Distribution Matching,Ilya Kostrikov;Ofir Nachum;Jonathan Tompson,kostrikov@cs.nyu.edu;ofirnachum@google.com;tompson@google.com,6;6;6,,Accept (Poster),0,5,1.0,yes,9/25/19,New York University;Google;Google,reinforcement learning;deep learning;imitation learning;adversarial learning,22;-1;-1,29;-1;-1,m;m,NAN,NAN,n,
3452,ICLR,2020,A Function Space View of Bounded Norm Infinite Width ReLU Nets: The Multivariate Case,Greg Ongie;Rebecca Willett;Daniel Soudry;Nathan Srebro,gongie@uchicago.edu;willett@uchicago.edu;daniel.soudry@technion.ac.il;nati@ttic.edu,8;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Chicago;University of Chicago;Technion, Technion;Toyota Technological Institute at Chicago",inductive bias;regularization;infinite-width networks;ReLU networks,51;51;27;-1,9;9;-1;-1,m;m,NAN,NAN,y,
3453,ICLR,2020,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,Kevin Clark;Minh-Thang Luong;Quoc V. Le;Christopher D. Manning,kevclark@cs.stanford.edu;thangluong@google.com;qvl@google.com;manning@cs.stanford.edu,8;6;8,,Accept (Poster),1,6,0.0,yes,9/25/19,Stanford University;Google;Google;Stanford University,Natural Language Processing;Representation Learning,5;-1;-1;5,4;-1;-1;4,m;m,usa,usa,n,3
3454,ICLR,2020,Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel,Xin Qiu;Elliot Meyerson;Risto Miikkulainen,qiuxin.nju@gmail.com;elliot.meyerson@cognizant.com;risto@cognizant.com,6;6;8;6,,Accept (Poster),0,11,0.0,yes,9/25/19,Cognizant;Cognizant;Cognizant,Uncertainty Estimation;Neural Networks;Gaussian Process,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,11
3455,ICLR,2020,Span Recovery for Deep Neural Networks with Applications to Input Obfuscation,Rajesh Jayaram;David P. Woodruff;Qiuyi Zhang,rkjayara@cs.cmu.edu;dwoodruf@andrew.cmu.edu;qiuyiz@google.com,3;6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Google,Span recovery;low rank neural networks;adversarial attack,1;1;-1,27;27;-1,m;m,NAN,NAN,y,4
3456,ICLR,2020,Posterior sampling for multi-agent reinforcement learning: solving extensive games with imperfect information,Yichi Zhou;Jialian Li;Jun Zhu,vofhqn@gmail.com;lijialia16@mails.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,6;6;8,,Accept (Talk),0,8,0.0,yes,9/25/19,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",,-1;4;4,-1;23;23,m;m,NAN,NAN,y,
3457,ICLR,2020,Co-Attentive Equivariant Neural Networks: Focusing Equivariance On Transformations Co-Occurring in Data,David W. Romero;Mark Hoogendoorn,d.w.romeroguzman@vu.nl;m.hoogendoorn@vu.nl,6;8;6,,Accept (Poster),0,11,0.0,yes,9/25/19,VU University Amsterdam;VU University Amsterdam,Equivariant Neural Networks;Attention Mechanisms;Deep Learning,-1;-1,-1;-1,m;m,NAN,NAN,n,8
3458,ICLR,2020,Explanation  by Progressive  Exaggeration,Sumedha Singla;Brian Pollack;Junxiang Chen;Kayhan Batmanghelich,sumedha.singla@pitt.edu;kayhan@pitt.edu;cjx880409@gmail.com;kayhan@pitt.edu,8;6,,Accept (Spotlight),0,3,0.0,yes,9/25/19,University of Pittsburgh;University of Pittsburgh;;University of Pittsburgh,Explain;deep learning;black box;GAN;counterfactual,79;79;-1;79,113;113;-1;113,f;m,usa,usa,n,
3459,ICLR,2020,Principled Weight Initialization for Hypernetworks,Oscar Chang;Lampros Flokas;Hod Lipson,oscar.chang@columbia.edu;lamflokas@cs.columbia.edu;hod.lipson@columbia.edu,8;8;8,,Accept (Talk),0,6,1.0,yes,9/25/19,Columbia University;Columbia University;Columbia University,hypernetworks;initialization;optimization;meta-learning,24;24;24,16;16;16,m;m,usa,usa,n,11
3460,ICLR,2020,On the Variance of the Adaptive Learning Rate and Beyond,Liyuan Liu;Haoming Jiang;Pengcheng He;Weizhu Chen;Xiaodong Liu;Jianfeng Gao;Jiawei Han,ll2@illinois.edu;jianghm@gatech.edu;penhe@microsoft.com;wzchen@microsoft.com;xiaodl@microsoft.com;jfgao@microsoft.com;hanj@illinois.edu,6;6;6,,Accept (Poster),4,5,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;Georgia Institute of Technology;Microsoft;Microsoft;Microsoft;Microsoft;University of Illinois, Urbana Champaign",warmup;adam;adaptive learning rate;variance,-1;13;-1;-1;-1;-1;-1,-1;38;-1;-1;-1;-1;-1,u;m,usa,usa,y,3;1
3461,ICLR,2020,Curvature Graph Network,Ze Ye;Kin Sum Liu;Tengfei Ma;Jie Gao;Chao Chen,yeze16159@gmail.com;kiliu@cs.stonybrook.edu;tengfei.ma1@ibm.com;jgao@cs.stonybrook.edu;chao.chen.1@stonybrook.edu,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;International Business Machines;State University of New York, Stony Brook;State University of New York, Stony Brook",Deep Learning;Graph Convolution;Ricci Curvature.,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;m,NAN,NAN,n,10
3462,ICLR,2020,"Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds",Jordan T. Ash;Chicheng Zhang;Akshay Krishnamurthy;John Langford;Alekh Agarwal,jordanta@cs.princeton.edu;chichengz@cs.arizona.edu;akshay.krishnamurthy@microsoft.com;jcl@microsoft.com;alekha@microsoft.com,8;6;8,,Accept (Talk),0,4,0.0,yes,9/25/19,Princeton University;University of Arizona;Microsoft;Microsoft;Microsoft,deep learning;active learning;batch active learning,30;194;-1;-1;-1,6;103;-1;-1;-1,m;m,NAN,NAN,y,
3463,ICLR,2020,StructPool: Structured Graph Pooling via Conditional Random Fields,Hao Yuan;Shuiwang Ji,hao.yuan@tamu.edu;sji@tamu.edu,6;6;6,,Accept (Poster),0,5,1.0,yes,9/25/19,Texas A&M;Texas A&M,Graph Pooling;Representation Learning;Graph Analysis,46;46,177;177,u;m,NAN,NAN,n,10
3464,ICLR,2020,Weakly Supervised Clustering by Exploiting Unique Class Count,Mustafa Umit Oner;Hwee Kuan Lee;Wing-Kin Sung,umitoner@comp.nus.edu.sg;leehk@bii.a-star.edu.sg;ksung@comp.nus.edu.sg,6;1;8,,Accept (Poster),0,8,0.0,yes,9/25/19,National University of Singapore;A*STAR;National University of Singapore,weakly supervised clustering;weakly supervised learning;multiple instance learning,17;-1;17,25;-1;25,m;m,asia,sg,y,2;1
3465,ICLR,2020,Gradients as Features for Deep Representation Learning,Fangzhou Mu;Yingyu Liang;Yin Li,fmu@cs.wisc.edu;yliang@cs.wisc.edu;yin.li@wisc.edu,6;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,representation learning;gradient features;deep learning,36;36;36,62;62;62,u;u,usa,usa,n,
3466,ICLR,2020,Composition-based Multi-Relational Graph Convolutional Networks,Shikhar Vashishth;Soumya Sanyal;Vikram Nitin;Partha Talukdar,shikhar@iisc.ac.in;sanyal.soumya8@gmail.com;vikram.nitin@columbia.edu;ppt@iisc.ac.in,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Indian Institute of Science;;Columbia University;Indian Institute of Science,Graph Convolutional Networks;Multi-relational Graphs;Knowledge Graph Embeddings;Link Prediction,-1;-1;24;-1,301;-1;16;301,m;m,NAN,NAN,y,10
3467,ICLR,2020,Behaviour Suite for Reinforcement Learning,Ian Osband;Yotam Doron;Matteo Hessel;John Aslanides;Eren Sezener;Andre Saraiva;Katrina McKinney;Tor Lattimore;Csaba Szepesvari;Satinder Singh;Benjamin Van Roy;Richard Sutton;David Silver;Hado Van Hasselt,ian.osband@gmail.com;ydoron@google.com;mtthss@google.com;jaslanides@google.com;esezener@google.com;andresnds@google.com;mckinneyk@google.com;lattimore@google.com;szepi@google.com;baveja@google.com;benvanroy@google.com;suttonr@google.com;davidsilver@google.com;hado@google.com,8;6;3,,Accept (Spotlight),0,11,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;benchmark;core issues;scalability;reproducibility,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;u,NAN,NAN,n,
3468,ICLR,2020,Identifying through Flows for Recovering Latent Representations,Shen Li;Bryan Hooi;Gim Hee Lee,maths.shenli@gmail.com;bhooi@comp.nus.edu.sg;dcslgh@nus.edu.sg,6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Amsterdam;National University of Singapore;National University of Singapore,Representation learning;identifiable generative models;nonlinear-ICA,-1;17;17,-1;25;25,u;m,asia,sg,y,1;5
3469,ICLR,2020,Federated Adversarial Domain Adaptation,Xingchao Peng;Zijun Huang;Yizhe Zhu;Kate Saenko,xpeng@bu.edu;zijun.huang@columbia.edu;yizhe.zhu@rutgers.edu;saenko@bu.edu,6;6;3,,Accept (Poster),2,5,0.0,yes,9/25/19,Boston University;Columbia University;Rutgers University;Boston University,Federated Learning;Domain Adaptation;Transfer Learning;Feature Disentanglement,79;24;30;79,61;16;-1;61,m;f,europe,it,y,8;4
3470,ICLR,2020,High Fidelity Speech Synthesis with Adversarial Networks,Miko≈Çaj Bi≈Ñkowski;Jeff Donahue;Sander Dieleman;Aidan Clark;Erich Elsen;Norman Casagrande;Luis C. Cobo;Karen Simonyan,mikbinkowski@gmail.com;jeffdonahue@google.com;sedielem@google.com;aidanclark@google.com;eriche@google.com;ncasagrande@google.com;luisca@google.com;simonyan@google.com,8;6;8,,Accept (Talk),1,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,texttospeech;speechsynthesis;audiosynthesis;gans;generativeadversarialnetworks;implicitgenerativemodels,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;u,NAN,NAN,n,8;5;4
3471,ICLR,2020,Why Not to Use Zero Imputation? Correcting Sparsity Bias in Training Neural Networks,Joonyoung Yi;Juhyuk Lee;Kwang Joon Kim;Sung Ju Hwang;Eunho Yang,joonyoung.yi@kaist.ac.kr;sehkmg@kaist.ac.kr;preppie@yuhs.ac;sjhwang82@kaist.ac.kr;eunhoy@kaist.ac.kr,6;6;6,,Accept (Poster),0,12,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Missing Data;Collaborative Filtering;Health Care;Tabular Data;High Dimensional Data;Deep Learning;Neural Networks,-1;-1;-1;-1;-1,110;110;-1;110;110,m;m,NAN,NAN,y,4
3472,ICLR,2020,Adversarial Training and Provable Defenses: Bridging the Gap,Mislav Balunovic;Martin Vechev,bmislav@student.ethz.ch;martin.vechev@inf.ethz.ch,8;6;8,,Accept (Talk),2,8,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,adversarial examples;adversarial training;provable defense;convex relaxations;deep learning,-1;-1,-1;-1,m;m,NAN,NAN,n,4
3473,ICLR,2020,Can gradient clipping mitigate label noise?,Aditya Krishna Menon;Ankit Singh Rawat;Sashank J. Reddi;Sanjiv Kumar,adityakmenon@google.com;ankitsrawat@google.com;sashank@google.com;sanjivk@google.com,6;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,1;9
3474,ICLR,2020,Comparing Rewinding and Fine-tuning in Neural Network Pruning,Alex Renda;Jonathan Frankle;Michael Carbin,renda@csail.mit.edu;jfrankle@csail.mit.edu;mcarbin@csail.mit.edu,8;8;6,,Accept (Talk),0,4,1.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,pruning;sparsity;fine-tuning;lottery ticket,5;5;5,5;5;5,m;m,usa,usa,n,
3475,ICLR,2020,Meta-learning curiosity algorithms,Ferran Alet*;Martin F. Schneider*;Tomas Lozano-Perez;Leslie Pack Kaelbling,ferranalet@gmail.com;martinfs@mit.edu;tlp@csail.mit.edu;lpk@csail.mit.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,meta-learning;exploration;curiosity,5;5;5;5,5;5;5;5,m;m,usa,usa,n,6;1
3476,ICLR,2020,Lookahead: A Far-sighted Alternative of Magnitude-based Pruning,Sejun Park*;Jaeho Lee*;Sangwoo Mo;Jinwoo Shin,sejun.park@kaist.ac.kr;jaeho-lee@kaist.ac.kr;swmo@kaist.ac.kr;jinwoos@kaist.ac.kr,6;6;6;6,,Accept (Poster),0,13,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,network magnitude-based pruning,-1;-1;-1;-1,110;110;110;110,u;m,NAN,NAN,n,1
3477,ICLR,2020,Fantastic Generalization Measures and Where to Find Them,Yiding Jiang*;Behnam Neyshabur*;Hossein Mobahi;Dilip Krishnan;Samy Bengio,ydjiang@google.com;neyshabur@google.com;dilipkay@google.com;hmobahi@google.com;bengio@google.com,8;3;8,,Accept (Poster),1,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google,Generalization;correlation;experiments,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
3478,ICLR,2020,Convergence of Gradient Methods on Bilinear Zero-Sum Games,Guojun Zhang;Yaoliang Yu,guojun.zhang@uwaterloo.ca;yaoliang.yu@uwaterloo.ca,8;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Waterloo;University of Waterloo,GAN;gradient algorithm;convergence;min-max optimization;bilinear game,30;30,235;235,m;m,canada,ca,y,8;5;4;9
3479,ICLR,2020,Multi-Agent Interactions Modeling with Correlated Policies,Minghuan Liu;Ming Zhou;Weinan Zhang;Yuzheng Zhuang;Jun Wang;Wulong Liu;Yong Yu,minghuanliu@sjtu.edu.cn;mingak@sjtu.edu.cn;wnzhang@sjtu.edu.cn;zhuangyuzheng@huawei.com;w.j@huawei.com;liuwulong@huawei.com;yyu@apex.sjtu.edu.cn,8;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Shanghai Jiao Tong University,Multi-agent reinforcement learning;Imitation learning,30;30;30;-1;-1;-1;30,157;157;157;-1;-1;-1;157,m;m,asia,cn,n,4
3480,ICLR,2020,"Real or Not Real, that is the Question",Yuanbo Xiangli*;Yubin Deng*;Bo Dai*;Chen Change Loy;Dahua Lin,xy019@ie.cuhk.edu.hk;danny.s.deng.ds@gmail.com;doubledaibo@gmail.com;ccloy@ntu.edu.sg;dhlin@ie.cuhk.edu.hk,6;6;8,,Accept (Spotlight),0,9,0.0,yes,9/25/19,The Chinese University of Hong Kong;;Nanyang Technological University;Nanyang Technological University;The Chinese University of Hong Kong,GAN;generalization;realness;loss function,316;-1;43;43;316,35;-1;49;49;35,m;m,NAN,NAN,n,5;4
3481,ICLR,2020,Structured Object-Aware Physics Prediction for Video Modeling and Planning,Jannik Kossen;Karl Stelzner;Marcel Hussing;Claas Voelcker;Kristian Kersting,kossen@stud.uni-heidelberg.de;stelzner@cs.tu-darmstadt.de;marcel.hussing@stud.tu-darmstadt.de;c.voelcker@stud.tu-darmstadt.de;kersting@cs.tu-darmstadt.de,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Heidelberg University;TU Darmstadt;TU Darmstadt;TU Darmstadt;TU Darmstadt,self-supervised learning;probabilistic deep learning;structured models;video prediction;physics prediction;planning;variational auteoncoders;model-based reinforcement learning;VAEs;unsupervised;variational;graph neural networks;tractable probabilistic models;attend-infer-repeat;relational learning;AIR;sum-product networks;object-oriented;object-centric;object-aware;MCTS,194;59;59;59;59,44;-1;-1;-1;-1,m;m,europe,de,n,
3482,ICLR,2020,Gradient Descent Maximizes the Margin of Homogeneous Neural Networks,Kaifeng Lyu;Jian Li,vfleaking@gmail.com;lijian83@mail.tsinghua.edu.cn,6;8;8,,Accept (Talk),0,3,0.0,yes,9/25/19,"Princeton University;Tsinghua University, Tsinghua University",margin;homogeneous;gradient descent,30;4,6;23,u;u,NAN,NAN,y,1
3483,ICLR,2020,Implementing Inductive bias for different navigation tasks through diverse RNN attrractors,Tie XU;Omri Barak,fexutie@gmail.com;omri.barak@gmail.com,6;6;3,,Accept (Poster),0,6,0.0,yes,9/25/19,Technion;Technion,navigation;Recurrent Neural Networks;dynamics;inductive bias;pre-training;reinforcement learning,-1;27,-1;-1,m;m,NAN,NAN,n,
3484,ICLR,2020,End to End Trainable Active Contours via Differentiable Rendering,Shir Gur;Tal Shaharabany;Lior Wolf,shiretzet@gmail.com;shaharabany@mail.tau.ac.il;wolf@fb.com,8;8;6,,Accept (Poster),0,6,2.0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Facebook,,30;30;-1,188;188;-1,m;m,NAN,NAN,n,2
3485,ICLR,2020,ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring,David Berthelot;Nicholas Carlini;Ekin D. Cubuk;Alex Kurakin;Kihyuk Sohn;Han Zhang;Colin Raffel,dberth@google.com;ncarlini@google.com;cubuk@google.com;kurakin@google.com;kihyuks@google.com;zhanghan@google.com;craffel@google.com,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,semi-supervised learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3486,ICLR,2020,DropEdge: Towards Deep Graph Convolutional Networks on Node Classification,Yu Rong;Wenbing Huang;Tingyang Xu;Junzhou Huang,yu.rong@hotmail.com;hwenbing@126.com;tingyangxu@tencent.com;jzhuang@uta.edu,3;3;6,,Accept (Poster),7,3,2.0,yes,9/25/19,"Tencent AI Lab;126;Tencent AI Lab;University of Texas, Arlington",graph neural network;over-smoothing;over-fitting;dropedge;graph convolutional networks,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,y,1;10
3487,ICLR,2020,Neural Tangents: Fast and Easy Infinite Neural Networks in Python,Roman Novak;Lechao Xiao;Jiri Hron;Jaehoon Lee;Alexander A. Alemi;Jascha Sohl-Dickstein;Samuel S. Schoenholz,romann@google.com;xlc@google.com;jh2084@cam.ac.uk;jaehlee@google.com;alemi@google.com;jaschasd@google.com;schsam@google.com,8;3;6,,Accept (Spotlight),0,12,0.0,yes,9/25/19,Google;Google;University of Cambridge;Google;Google;Google;Google,Infinite Neural Networks;Gaussian Processes;Neural Tangent Kernel;NNGP;NTK;Software Library;Python;JAX,-1;-1;79;-1;-1;-1;-1,-1;-1;3;-1;-1;-1;-1,m;m,NAN,NAN,n,11
3488,ICLR,2020,FasterSeg: Searching for Faster Real-time Semantic Segmentation,Wuyang Chen;Xinyu Gong;Xianming Liu;Qian Zhang;Yuan Li;Zhangyang Wang,wuyang.chen@tamu.edu;xy_gong@tamu.edu;xianming.liu@horizon.ai;qian01.zhang@horizon.ai;yuan.li@horizon.ai;atlaswang@tamu.edu,8;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Texas A&M;Texas A&M;Horizon Robotics;Horizon Robotics;Horizon Robotics;Texas A&M,neural architecture search;real-time;segmentation,46;46;-1;-1;-1;46,177;177;-1;-1;-1;177,m;m,NAN,NAN,n,2
3489,ICLR,2020,Understanding Knowledge Distillation in Non-autoregressive Machine Translation,Chunting Zhou;Jiatao Gu;Graham Neubig,chuntinz@andrew.cmu.edu;jgu@fb.com;gneubig@cs.cmu.edu,8;8;3,,Accept (Poster),0,5,2.0,yes,9/25/19,Carnegie Mellon University;Facebook;Carnegie Mellon University,knowledge distillation;non-autoregressive neural machine translation,1;-1;1,27;-1;27,f;m,usa,usa,n,3
3490,ICLR,2020,Building Deep Equivariant Capsule Networks,Sai Raam Venkataraman;S. Balasubramanian;R. Raghunatha Sarma,vsairaam@sssihl.edu.in;sbalasubramanian@sssihl.edu.in;rraghunathasarma@sssihl.edu.in,8;6,,Accept (Talk),0,10,0.0,yes,9/25/19,Sri Sathya Sai Institute of Higher Learning;Sri Sathya Sai Institute of Higher Learning;Sri Sathya Sai Institute of Higher Learning,Capsule networks;equivariance,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
3491,ICLR,2020,Understanding Architectures Learnt by Cell-based Neural Architecture Search,Yao Shu;Wei Wang;Shaofeng Cai,shuyao@comp.nus.edu.sg;wangwei@comp.nus.edu.sg;shaofeng@comp.nus.edu.sg,8;6;3,,Accept (Poster),0,6,0.0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore,Neural Architecture Search;connection pattern;optimization;convergence;Lipschitz smoothness;gradient variance;generalization,17;17;17,25;25;25,f;m,asia,sg,y,3;8;1
3492,ICLR,2020,Dynamically Pruned Message Passing Networks for Large-scale Knowledge Graph Reasoning,Xiaoran Xu;Wei Feng;Yunsheng Jiang;Xiaohui Xie;Zhiqing Sun;Zhi-Hong Deng,xiaoran.xu@hulu.com;wei.feng@hulu.com;yunsheng.jiang@hulu.com;xiaohui.xie@hulu.com;zhiqings@andrew.cmu.edu;zhdeng@pku.edu.cn,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Hulu LLC.;Hulu LLC.;Hulu LLC.;Hulu LLC.;Carnegie Mellon University;Peking University,knowledge graph reasoning;graph neural networks;attention mechanism,-1;-1;-1;-1;1;14,-1;-1;-1;-1;27;24,m;m,asia,cn,n,8;10
3493,ICLR,2020,Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model,Wenhan Xiong;Jingfei Du;William Yang Wang;Veselin Stoyanov,xwhan@cs.ucsb.edu;jingfeidu@fb.com;william@cs.ucsb.edu;ves@fb.com,8;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,UC Santa Barbara;Facebook;UC Santa Barbara;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
3494,ICLR,2020,Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware,Xiandong Zhao;Ying Wang;Xuyi Cai;Cheng Liu;Lei Zhang,zhaoxiandong@ict.ac.cn;wangying2009@ict.ac.cn;caixuyi18s@ict.ac.cn;liucheng@ict.ac.cn;zlei@ict.ac.cn,6;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",quantization;integer-arithmetic-only DNN accelerator;acceleration,30;30;30;30;30,-1;-1;-1;-1;-1,u;m,NAN,NAN,n,2
3495,ICLR,2020,Consistency Regularization for Generative Adversarial Networks,Han Zhang;Zizhao Zhang;Augustus Odena;Honglak Lee,zhanghan@google.com;zizhaoz@google.com;augustusodena@google.com;honglak@google.com,6;6;8,,Accept (Poster),0,5,1.0,yes,9/25/19,Google;Google;Google;Google,Generative Adversarial Networks;Consistency Regularization;GAN,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n,5;4
3496,ICLR,2020,Short and Sparse Deconvolution --- A Geometric Approach,Yenson Lau;Qing Qu;Han-Wen Kuo;Pengcheng Zhou;Yuqian Zhang;John Wright,y.lau@columbia.edu;qq213@nyu.edu;hk2673@columbia.edu;pz2230@columbia.edu;yz2557@cornell.edu;jw2966@columbia.edu,6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Columbia University;New York University;Columbia University;Columbia University;Cornell University;Columbia University,,24;22;24;24;7;24,16;29;16;16;19;16,u;m,usa,usa,n,1
3497,ICLR,2020,BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by Coupling Binary Activations,Hyungjun Kim;Kyungsu Kim;Jinseok Kim;Jae-Joon Kim,hyungjun.kim@postech.ac.kr;kyungsu.kim@postech.ac.kr;jinseok.kim@postech.ac.kr;jaejoon@postech.ac.kr,6;6;6,,Accept (Poster),1,7,1.0,yes,9/25/19,POSTECH;POSTECH;POSTECH;POSTECH,,118;118;118;118,146;146;146;146,m;m,asia,kr,n,
3498,ICLR,2020,Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention,Chen Zhao;Chenyan Xiong;Corby Rosset;Xia Song;Paul Bennett;Saurabh Tiwary,chenz@cs.umd.edu;chenyan.xiong@microsoft.com;corbin.rosset@microsoft.com;xiaso@microsoft.com;paul.n.bennett@microsoft.com;satiwary@microsoft.com,8;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,"University of Maryland, College Park;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft",Transformer-XH;multi-hop QA;fact verification;extra hop attention;structured modeling,12;-1;-1;-1;-1;-1,91;-1;-1;-1;-1;-1,u;u,NAN,NAN,n,8;3;10
3499,ICLR,2020,Sub-policy Adaptation for Hierarchical Reinforcement Learning,Alexander Li;Carlos Florensa;Ignasi Clavera;Pieter Abbeel,alexli1@berkeley.edu;florensa@berkeley.edu;iclavera@berkeley.edu;pabbeel@berkeley.edu,8;3,,Accept (Poster),0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Hierarchical Reinforcement Learning;Transfer;Skill Discovery,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,y,
3500,ICLR,2020,"Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards",Allan Zhou;Eric Jang;Daniel Kappler;Alex Herzog;Mohi Khansari;Paul Wohlhart;Yunfei Bai;Mrinal Kalakrishnan;Sergey Levine;Chelsea Finn,ayz@stanford.edu;ejang@google.com;kappler@google.com;alexherzog@google.com;khansari@google.com;wohlhart@google.com;yunfeibai@google.com;kalakris@google.com;slevine@google.com;cbfinn@cs.stanford.edu,6;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Stanford University;Google;Google;Google;Google;Google;Google;Google;Google;Stanford University,meta-learning;reinforcement learning;imitation learning,5;-1;-1;-1;-1;-1;-1;-1;-1;5,4;-1;-1;-1;-1;-1;-1;-1;-1;4,m;f,usa,usa,n,
3501,ICLR,2020,Deep Orientation Uncertainty Learning based on a Bingham Loss,Igor Gilitschenski;Roshni Sahoo;Wilko Schwarting;Alexander Amini;Sertac Karaman;Daniela Rus,igilitschenski@mit.edu;rsahoo@mit.edu;wilkos@mit.edu;amini@mit.edu;sertac@mit.edu;rus@csail.mit.edu,6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Orientation Estimation;Directional Statistics;Bingham Distribution,5;5;5;5;5;5,5;5;5;5;5;5,m;f,usa,usa,n,2
3502,ICLR,2020,Overlearning Reveals Sensitive Attributes,Congzheng Song;Vitaly Shmatikov,cs2296@cornell.edu;shmat@cs.cornell.edu,6;1;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Cornell University;Cornell University,privacy;censoring representation;transfer learning,7;7,19;19,m;m,usa,usa,n,3;7
3503,ICLR,2020,Understanding the Limitations of Conditional Generative Models,Ethan Fetaya;Joern-Henrik Jacobsen;Will Grathwohl;Richard Zemel,ethanf@cs.toronto.edu;j.jacobsen@vectorinstitute.ai;wgrathwohl@cs.toronto.edu;zemel@cs.toronto.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Toronto;Vector Institute;University of Toronto;University of Toronto,Conditional Generative Models;Generative Classifiers;Robustness;Adversarial Examples,18;-1;18;18,18;-1;18;18,m;m,canada,ca,n,5;4
3504,ICLR,2020,Learning Disentangled Representations for CounterFactual Regression,Negar Hassanpour;Russell Greiner,hassanpo@ualberta.ca;rgreiner@ualberta.ca,8;8;3,,Accept (Poster),0,5,1.0,yes,9/25/19,University of Alberta;University of Alberta,Counterfactual Regression;Causal Effect Estimation;Selection Bias;Off-policy Learning,102;102,136;136,f;m,canada,ca,n,
3505,ICLR,2020,Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery,Kristian Hartikainen;Xinyang Geng;Tuomas Haarnoja;Sergey Levine,kristian.hartikainen@gmail.com;young.geng@berkeley.edu;tuomash@google.com;svlevine@eecs.berkeley.edu,6;6;6,,Accept (Poster),0,9,3.0,yes,9/25/19,University of Oxford;University of California Berkeley;Google;University of California Berkeley,reinforcement learning;semi-supervised learning;unsupervised learning;robotics;deep learning,46;-1;-1;-1,1;13;-1;13,m;m,usa,usa,n,
3506,ICLR,2020,Learning-Augmented Data Stream Algorithms,Tanqiu Jiang;Yi Li;Honghao Lin;Yisong Ruan;David P. Woodruff,taj320@lehigh.edu;yili@ntu.edu.sg;honghao_lin@sjtu.edu.cn;24320152202802@stu.xmu.edu.cn;dwoodruf@andrew.cmu.edu,8;8;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Lehigh University;Nanyang Technological University;Shanghai Jiao Tong University;Xiamen University;Carnegie Mellon University,streaming algorithms;heavy hitters;F_p moment;distinct elements;cascaded norms,248;43;30;-1;1,633;49;157;579;27,u;m,usa,usa,y,
3507,ICLR,2020,"Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps",Tri Dao;Nimit Sohoni;Albert Gu;Matthew Eichhorn;Amit Blonder;Megan Leszczynski;Atri Rudra;Christopher R√©,trid@stanford.edu;nims@stanford.edu;albertgu@stanford.edu;mae226@cornell.edu;amitblon@buffalo.edu;mleszczy@stanford.edu;atri@buffalo.edu;chrismre@cs.stanford.edu,6;8;8,,Accept (Spotlight),0,5,1.0,yes,9/25/19,"Stanford University;Stanford University;Stanford University;Cornell University;State University of New York, Buffalo;Stanford University;State University of New York, Buffalo;Stanford University",structured matrices;efficient ML;algorithms;butterfly matrices;arithmetic circuits,5;5;5;7;-1;5;-1;5,4;4;4;19;-1;4;-1;4,m;m,usa,usa,y,8;1
3508,ICLR,2020,Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP,Haonan Yu;Sergey Edunov;Yuandong Tian;Ari S. Morcos,haonanu@gmail.com;edunov@fb.com;yuandong@fb.com;arimorcos@gmail.com,6;3;3,,Accept (Poster),0,2,0.0,yes,9/25/19,Purdue University;Facebook;Facebook;Facebook,lottery tickets;nlp;transformer;rl;reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
3509,ICLR,2020,Learning the Arrow of Time for Problems in Reinforcement Learning,Nasim Rahaman;Steffen Wolf;Anirudh Goyal;Roman Remme;Yoshua Bengio,nasim.rahaman@tuebingen.mpg.de;steffen.wolf@iwr.uni-heidelberg.de;anirudhgoyal9119@gmail.com;roman.remme@iwr.uni-heidelberg.de;yoshua.bengio@mila.quebec,6;8;6,,Accept (Poster),0,16,0.0,yes,9/25/19,Max-Planck Institute;Heidelberg University;;Heidelberg University;Mila,Arrow of Time;Reinforcement Learning;AI-Safety,-1;194;-1;194;143,-1;44;-1;44;336,m;m,NAN,NAN,y,
3510,ICLR,2020,DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames,Erik Wijmans;Abhishek Kadian;Ari Morcos;Stefan Lee;Irfan Essa;Devi Parikh;Manolis Savva;Dhruv Batra,etw@gatech.edu;akadian@fb.com;arimorcos@gmail.com;leestef@oregonstate.edu;irfan@gatech.edu;parikh@gatech.edu;msavva@sfu.ca;dbatra@gatech.edu,8;8;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Georgia Institute of Technology;Facebook;Facebook;Oregon State University;Georgia Institute of Technology;Georgia Institute of Technology;Simon Fraser University;Georgia Institute of Technology,autonomous navigation;habitat;embodied AI;pointgoal navigation;reinforcement learning,13;-1;-1;79;13;13;52;13,38;-1;-1;373;38;38;272;38,m;m,usa,usa,n,
3511,ICLR,2020,Information Geometry of Orthogonal Initializations and Training,Piotr Aleksander Sok√≥≈Ç;Il Memming Park,piotr.sokol@stonybrook.edu;memming.park@stonybrook.edu,6;8;6,,Accept (Poster),0,8,0.0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook",Fisher;mean-field;deep learning,-1;-1,-1;-1,m;m,NAN,NAN,y,1
3512,ICLR,2020,Strategies for Pre-training Graph Neural Networks,Weihua Hu*;Bowen Liu*;Joseph Gomes;Marinka Zitnik;Percy Liang;Vijay Pande;Jure Leskovec,weihuahu@stanford.edu;liubowen@stanford.edu;joegomes@stanford.edu;marinka@cs.stanford.edu;pliang@cs.stanford.edu;pande@stanford.edu;jure@cs.stanford.edu,6;6;6,,Accept (Spotlight),1,3,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Pre-training;Transfer learning;Graph Neural Networks,5;5;5;5;5;5;5,4;4;4;4;4;4;4,m;m,usa,usa,n,1;10
3513,ICLR,2020,Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation,Hung-Yu Tseng;Hsin-Ying Lee;Jia-Bin Huang;Ming-Hsuan Yang,htseng6@ucmerced.edu;hlee246@ucmerced.edu;jbhuang@vt.edu;mhyang@ucmerced.edu,6;6;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,University of California at Merced;University of California at Merced;Virginia Tech;University of California at Merced,,-1;-1;64;-1,-1;-1;-1;-1,u;m,usa,usa,n,6;1
3514,ICLR,2020,How much Position Information Do Convolutional Neural Networks Encode?,Md Amirul Islam*;Sen Jia*;Neil D. B. Bruce,amirul@scs.ryerson.ca;sen.jia@ryerson.ca;bruce@ryerson.ca,8;8;8,,Accept (Spotlight),0,3,6.0,yes,9/25/19,Ryerson University;Ryerson University;Ryerson University,network understanding;absolute position information,316;316;316,739;739;739,m;m,canada,ca,n,
3515,ICLR,2020,Generalization through Memorization: Nearest Neighbor Language Models,Urvashi Khandelwal;Omer Levy;Dan Jurafsky;Luke Zettlemoyer;Mike Lewis,urvashik@stanford.edu;omerlevy@gmail.com;jurafsky@stanford.edu;lsz@fb.com;mikelewis@fb.com,3;6;6,,Accept (Poster),1,8,0.0,yes,9/25/19,Stanford University;Tel Aviv University;Stanford University;Facebook;Facebook,language models;k-nearest neighbors,5;30;5;-1;-1,4;188;4;-1;-1,f;m,NAN,NAN,n,3
3516,ICLR,2020,On the Relationship between Self-Attention and Convolutional Layers,Jean-Baptiste Cordonnier;Andreas Loukas;Martin Jaggi,jean-baptiste.cordonnier@epfl.ch;andreas.loukas@epfl.ch;martin.jaggi@epfl.ch,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,self-attention;attention;transformers;convolution;CNN;image;expressivity;capacity,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,8;1
3517,ICLR,2020,On Bonus Based Exploration Methods In The Arcade Learning Environment,Adrien Ali Taiga;William Fedus;Marlos C. Machado;Aaron Courville;Marc G. Bellemare,adrien.alitaiga@gmail.com;liamfedus@google.com;marlosm@google.com;aaron.courville@gmail.com;bellemare@google.com,6;6,,Accept (Poster),0,2,0.0,yes,9/25/19,Google;Google;Google;University of Montreal;Google,exploration;arcade learning environment;bonus-based methods,-1;-1;-1;118;-1,-1;-1;-1;85;-1,u;m,NAN,NAN,n,
3518,ICLR,2020,The Curious Case of Neural Text Degeneration,Ari Holtzman;Jan Buys;Li Du;Maxwell Forbes;Yejin Choi,ahai@cs.washington.edu;jbuys@cs.uct.ac.za;dul2@cs.washington.edu;mbforbes@cs.washington.edu;yejin@cs.washington.edu,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Washington;University of Cape Town;University of Washington;University of Washington;University of Washington,generation;text;NLG;NLP;natural language;natural language generation;language model;neural;neural language model,11;445;11;11;11,26;136;26;26;26,m;f,usa,usa,n,3
3519,ICLR,2020,A Mutual Information Maximization Perspective of Language Representation Learning,Lingpeng Kong;Cyprien de Masson d'Autume;Lei Yu;Wang Ling;Zihang Dai;Dani Yogatama,lingpenk@google.com;cyprien@google.com;leiyu@google.com;lingwang@google.com;zihangd@google.com;dyogatama@google.com,8;8;6,,Accept (Spotlight),0,5,1.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;2;1
3520,ICLR,2020,Measuring Compositional Generalization: A Comprehensive Method on Realistic Data,Daniel Keysers;Nathanael Sch√§rli;Nathan Scales;Hylke Buisman;Daniel Furrer;Sergii Kashubin;Nikola Momchev;Danila Sinopalnikov;Lukasz Stafiniak;Tibor Tihon;Dmitry Tsarkov;Xiao Wang;Marc van Zee;Olivier Bousquet,keysers@google.com;schaerli@google.com;nkscales@google.com;hylke@google.com;danielfurrer@google.com;sergik@google.com;nikola@google.com;sinopalnikov@google.com;lukstafi@google.com;ttihon@google.com;tsar@google.com;wangxiao@google.com;marcvanzee@google.com;obousquet@google.com,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,compositionality;generalization;natural language understanding;benchmark;compositional generalization;compositional modeling;semantic parsing;generalization measurement,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;1
3521,ICLR,2020,GLAD: Learning Sparse Graph Recovery,Harsh Shrivastava;Xinshi Chen;Binghong Chen;Guanghui Lan;Srinivas Aluru;Han Liu;Le Song,hshrivastava3@gatech.edu;xinshi.chen@gatech.edu;binghong@gatech.edu;george.lan@isye.gatech.edu;aluru@cc.gatech.edu;hanliu@northwestern.edu;lsong@cc.gatech.edu,8;8;6,,Accept (Poster),0,9,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Northwestern University;Georgia Institute of Technology,Meta learning;automated algorithm design;learning structure recovery;Gaussian graphical models,13;13;13;13;13;46;13,38;38;38;38;38;22;38,m;m,usa,usa,y,10;9
3522,ICLR,2020,Query-efficient Meta Attack to Deep Neural Networks,Jiawei Du;Hu Zhang;Joey Tianyi Zhou;Yi Yang;Jiashi Feng,dujiawei@u.nus.edu;hu.zhang-1@student.uts.edu.au;joey.tianyi.zhou@gmail.com;yi.yang@uts.edu.au;elefjia@nus.edu.sg,8;6;6,,Accept (Poster),1,7,0.0,yes,9/25/19,National University of Singapore;University of Technology Sydney;;University of Technology Sydney;National University of Singapore,Adversarial attack;Meta learning,17;73;-1;73;17,25;193;-1;193;25,m;m,asia,sg,n,4
3523,ICLR,2020,Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks,Arsalan Sharifnassab;Saber Salehkaleybar;S. Jamaloddin Golestani,a.sharifnassab@gmail.com;saber.salehk@gmail.com;golestani@sharif.edu,6;6,,Accept (Poster),0,2,0.0,yes,9/25/19,Sharif University of Technology;Sharif University of Technology;Sharif University of Technology,Spurious local minima;Loss landscape;Over-parameterization;Theory of deep learning;Optimization;Descent path,-1;316;316,-1;564;564,m;u,asia,ir,y,
3524,ICLR,2020,"A critical analysis of self-supervision, or what we can learn from a single image",Asano YM.;Rupprecht C.;Vedaldi A.,yuki@robots.ox.ac.uk;chrisr@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk,6;6;1,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,self-supervision;feature representation learning;CNN,46;46;46,1;1;1,m;m,europe,uk,n,
3525,ICLR,2020,Geometric Insights into the Convergence of Nonlinear TD Learning,David Brandfonbrener;Joan Bruna,david.brandfonbrener@nyu.edu;bruna@cims.nyu.edu,8;6;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,New York University;New York University,TD;nonlinear;convergence;value estimation;reinforcement learning,22;22,29;29,m;m,usa,usa,y,1;9
3526,ICLR,2020,Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning,Qing Qu;Yuexiang Zhai;Xiao Li;Yuqian Zhang;Zhihui Zhu,qingqu1006@gmail.com;ysz@berkeley.edu;xli@ee.cuhk.edu.hk;yqz.zhang@gmail.com;zzhu29@jhu.edu,8;8;8,,Accept (Talk),0,5,0.0,yes,9/25/19,University of Michigan;University of California Berkeley;The Chinese University of Hong Kong;Rutgers University;Johns Hopkins University,dictionary learning;sparse representations;nonconvex optimization,7;-1;316;30;73,21;13;35;-1;12,m;m,usa,usa,y,9
3527,ICLR,2020,Network Deconvolution,Chengxi Ye;Matthew Evanusa;Hua He;Anton Mitrokhin;Tom Goldstein;James A. Yorke;Cornelia Fermuller;Yiannis Aloimonos,yechengxi@gmail.com;mevanusa@umd.edu;huah@umd.edu;amitrokh@umd.edu;tomg@cs.umd.edu;yorke@umd.edu;fer@umiacs.umd.edu;yiannis@cs.umd.edu,8;8;6,,Accept (Spotlight),0,3,0.0,yes,9/25/19,"Amazon;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",convolutional networks;network deconvolution;whitening,-1;12;12;12;12;12;12;12,-1;91;91;91;91;91;91;91,m;m,usa,usa,n,
3528,ICLR,2020,Pure and Spurious Critical Points: a Geometric Study of Linear Networks,Matthew Trager;Kathl√©n Kohn;Joan Bruna,matthew.trager@cims.nyu.edu;kathlen.korn@gmail.com;bruna@cims.nyu.edu,8;3;3,,Accept (Poster),0,5,0.0,yes,9/25/19,New York University;;New York University,Loss landscape;linear networks;algebraic geometry,22;-1;22,29;-1;29,u;m,usa,usa,y,
3529,ICLR,2020,PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search,Yuhui Xu;Lingxi Xie;Xiaopeng Zhang;Xin Chen;Guo-Jun Qi;Qi Tian;Hongkai Xiong,yuhuixu@sjtu.edu.cn;198808xc@gmail.com;zxphistory@gmail.com;1410452@tongji.edu.cn;guojunq@gmail.com;tian.qi1@huawei.com;xionghongkai@sjtu.edu.cn,6;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Shanghai Jiao Tong University;;;Tongji University;University of Central Florida;Huawei Technologies Ltd.;Shanghai Jiao Tong University,Neural Architecture Search;DARTS;Regularization;Normalization,30;-1;-1;316;73;-1;30,157;-1;-1;441;609;-1;157,m;m,asia,cn,n,
3530,ICLR,2020,Towards a Deep Network Architecture for Structured Smoothness,Haroun Habeeb;Oluwasanmi Koyejo,haroun7@gmail.com;sanmi@illinois.edu,6;6,,Accept (Poster),0,2,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1,-1;-1,m;m,usa,usa,n,
3531,ICLR,2020,RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?,Anil Kag;Ziming Zhang;Venkatesh Saligrama,anilkag@bu.edu;zzhang@merl.com;srv@bu.edu,8;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Boston University;Mitsubishi Electric Research Labs;Boston University,novel recurrent neural architectures;learning representations of outputs or states,79;-1;79,61;-1;61,m;m,europe,it,y,
3532,ICLR,2020,"Deep Imitative Models for Flexible Inference, Planning, and Control",Nicholas Rhinehart;Rowan McAllister;Sergey Levine,nrhineha@cs.cmu.edu;rmcallister@berkeley.edu;svlevine@eecs.berkeley.edu,8;8;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Carnegie Mellon University;University of California Berkeley;University of California Berkeley,imitation learning;planning;autonomous driving,1;-1;-1,27;13;13,m;m,usa,usa,n,
3533,ICLR,2020,The Implicit Bias of Depth: How Incremental Learning Drives Generalization,Daniel Gissin;Shai Shalev-Shwartz;Amit Daniely,daniel.gissin@mail.huji.ac.il;shais@cs.huji.ac.il;amit.daniely@mail.huji.ac.il,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,gradient flow;gradient descent;implicit regularization;implicit bias;generalization;optimization;quadratic network;matrix sensing,85;85;85,216;216;216,m;m,europe,il,y,1
3534,ICLR,2020,BackPACK: Packing more into Backprop,Felix Dangel;Frederik Kunstner;Philipp Hennig,felix.dangel@tuebingen.mpg.de;kunstner@cs.ubc.ca;philipp.hennig@uni-tuebingen.de,8;8;8,,Accept (Talk),0,3,0.0,yes,9/25/19,Max-Planck Institute;University of British Columbia;University of Tuebingen,,-1;64;143,-1;34;91,m;m,europe,de,n,1
3535,ICLR,2020,Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality,Saurabh Khanna;Vincent Y. F. Tan,elesaur@nus.edu.sg;vtan@nus.edu.sg,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,National University of Singapore;National University of Singapore,Recurrent neural networks;Granger causality;Causal inference;Statistical Recurrent Unit,17;17,25;25,m;m,asia,sg,n,8
3536,ICLR,2020,Detecting Extrapolation with Local Ensembles,David Madras;James Atwood;Alexander D'Amour,david.madras@mail.utoronto.ca;atwoodj@google.com;alexdamour@google.com,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Toronto University;Google;Google,extrapolation;reliability;influence functions;laplace approximation;ensembles;Rashomon set,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3537,ICLR,2020,Few-shot Text Classification with Distributional Signatures,Yujia Bao;Menghua Wu;Shiyu Chang;Regina Barzilay,yujia@csail.mit.edu;rmwu@mit.edu;shiyu.chang@ibm.com;regina@csail.mit.edu,6;1;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology,text classification;meta learning;few shot learning,5;5;-1;5,5;5;-1;5,m;f,usa,usa,y,6;2;8;3
3538,ICLR,2020,Scaling Autoregressive Video Models,Dirk Weissenborn;Oscar T√§ckstr√∂m;Jakob Uszkoreit,diwe@google.com;oscar.tackstrom@gmail.com;usz@google.com,8;6;8,,Accept (Spotlight),0,6,0.0,yes,9/25/19,Google;Sana Labs;Google,autoregressive models;video prediction;generative models;video generation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;4
3539,ICLR,2020,Reformer: The Efficient Transformer,Nikita Kitaev;Lukasz Kaiser;Anselm Levskaya,kitaev@cs.berkeley.edu;lukaszkaiser@google.com;levskaya@google.com,8;6;8,,Accept (Talk),4,3,0.0,yes,9/25/19,University of California Berkeley;Google;Google,attention;locality sensitive hashing;reversible layers,-1;-1;-1,13;-1;-1,f;m,NAN,NAN,n,8
3540,ICLR,2020,Robust Subspace Recovery Layer for Unsupervised Anomaly Detection,Chieh-Hsin Lai;Dongmian Zou;Gilad Lerman,laixx313@umn.edu;dzou@umn.edu;lerman@umn.edu,8;6;8,,Accept (Poster),0,6,0.0,yes,9/25/19,"University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis",robust subspace recovery;unsupervised anomaly detection;outliers;latent space;autoencoder,73;73;73,79;79;79,m;m,NAN,NAN,y,
3541,ICLR,2020,SCALOR: Generative World Models with Scalable Object Representations,Jindong Jiang*;Sepehr Janghorbani*;Gerard De Melo;Sungjin Ahn,jindong.jiang@rutgers.edu;sj620@scarletmail.rutgers.edu;gdm@demelo.org;sjn.ahn@gmail.com,6;6;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Rutgers University;Rutgers University;Rutgers University;Rutgers University,,30;30;30;30,-1;-1;-1;-1,m;f,usa,usa,n,8;5
3542,ICLR,2020,Learning Robust Representations via Multi-View Information Bottleneck,Marco Federici;Anjan Dutta;Patrick Forr√©;Nate Kushman;Zeynep Akata,m.federici@uva.nl;duttanjan@gmail.com;patrickforre@gmail.com;nate@kushman.org;zeynepakata@gmail.com,8;6;8,,Accept (Poster),0,5,1.0,yes,9/25/19,University of Amsterdam;University of Exeter;University of Amsterdam;Google;University of Tuebingen,Information Bottleneck;Multi-View Learning;Representation Learning;Information Theory,143;316;143;-1;143,62;146;62;-1;91,m;f,europe,de,n,1
3543,ICLR,2020,Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks,Tianyu Pang*;Kun Xu*;Jun Zhu,pty17@mails.tsinghua.edu.cn;kunxu.thu@gmail.com;dcszj@mail.tsinghua.edu.cn,6;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University",Trustworthy Machine Learning;Adversarial Robustness;Inference Principle;Mixup,4;-1;4,23;-1;23,m;m,NAN,NAN,n,1;4
3544,ICLR,2020,Adversarial Lipschitz Regularization,D√°vid Terj√©k,david.terjek92@gmail.com,6;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,Alfr√©d R√©nyi Institute of Mathematics,generative adversarial networks;wasserstein generative adversarial networks;lipschitz regularization;adversarial training,-1,-1,m;u,NAN,NAN,n,5;4
3545,ICLR,2020,Are Transformers universal approximators of sequence-to-sequence functions?,Chulhee Yun;Srinadh Bhojanapalli;Ankit Singh Rawat;Sashank Reddi;Sanjiv Kumar,chulheey@mit.edu;bsrinadh@google.com;ankitsrawat@google.com;sashank@google.com;sanjivk@google.com,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Massachusetts Institute of Technology;Google;Google;Google;Google,Transformer;universal approximation;contextual mapping;expressive power;permutation equivariance,5;-1;-1;-1;-1,5;-1;-1;-1;-1,m;m,NAN,NAN,y,3;8;1
3546,ICLR,2020,Escaping Saddle Points Faster with Stochastic Momentum,Jun-Kun Wang;Chi-Heng Lin;Jacob Abernethy,jimwang@gatech.edu;cl3385@gatech.edu;prof@gatech.edu,3;6;6,,Accept (Poster),0,9,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,SGD;momentum;escaping saddle point,13;13;13,38;38;38,m;m,usa,usa,y,9
3547,ICLR,2020,SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum,Jianyu Wang;Vinayak Tantia;Nicolas Ballas;Michael Rabbat,jianyuw1@andrew.cmu.edu;tantia@fb.com;ballasn@fb.com;mikerabbat@fb.com,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook,distributed optimization;decentralized training methods;communication-efficient distributed training with momentum;large-scale parallel SGD,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,y,3;1;9
3548,ICLR,2020,SUMO: Unbiased Estimation of Log Marginal Probability for Latent Variable Models,Yucen Luo;Alex Beatson;Mohammad Norouzi;Jun Zhu;David Duvenaud;Ryan P. Adams;Ricky T. Q. Chen,luoyc15@mails.tsinghua.edu.cn;abeatson@cs.princeton.edu;mnorouzi@google.com;dcszj@mail.tsinghua.edu.cn;duvenaud@cs.toronto.edu;rpa@princeton.edu;rtqichen@cs.toronto.edu,8;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Princeton University;Google;Tsinghua University, Tsinghua University;University of Toronto;Princeton University;University of Toronto",,4;30;-1;4;18;30;18,23;6;-1;23;18;6;18,f;m,canada,ca,y,
3549,ICLR,2020,Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control,Yaofeng Desmond Zhong;Biswadip Dey;Amit Chakraborty,y.zhong@princeton.edu;biswadip.dey@siemens.com;amit.chakraborty@siemens.com,8;6;8,,Accept (Poster),0,6,0.0,yes,9/25/19,Princeton University;Siemens Corporate Research;Siemens Corporate Research,Deep Model Learning;Physics-based Priors;Control of Mechanical Systems,30;-1;-1,6;-1;-1,m;m,NAN,NAN,n,1;10
3550,ICLR,2020,Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems,Chris Reinke;Mayalen Etcheverry;Pierre-Yves Oudeyer,chris.reinke@inria.fr;mayalen.etcheverry@inria.fr;chris.reinke@inria.fr;pierre-yves.oudeyer@inria.fr,8;6;6,,Accept (Talk),0,5,0.0,yes,9/25/19,INRIA;INRIA;INRIA;INRIA,deep learning;unsupervised Learning;self-organization;game-of-life,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,gr,n,
3551,ICLR,2020,On the Convergence of FedAvg on Non-IID Data,Xiang Li;Kaixuan Huang;Wenhao Yang;Shusen Wang;Zhihua Zhang,smslixiang@pku.edu.cn;hackyhuang@pku.edu.cn;yangwhsms@gmail.com;shusen.wang@stevens.edu;zhzhang@math.pku.edu.cn,8;8;6,,Accept (Talk),0,3,0.0,yes,9/25/19,Peking University;Peking University;Peking University;Stevens Institute of Technology;Peking University,Federated Learning;stochastic optimization;Federated Averaging,14;14;14;143;14,24;24;24;605;24,m;m,asia,cn,y,1;9
3552,ICLR,2020,The asymptotic spectrum of the Hessian of DNN throughout training,Arthur Jacot;Franck Gabriel;Clement Hongler,arthur.jacot@epfl.ch;franck.gabriel@epfl.ch;clement.hongler@epfl.ch,3;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,theory of deep learning;loss surface;training;fisher information matrix,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
3553,ICLR,2020,AutoQ: Automated Kernel-Wise Neural Network Quantization ,Qian Lou;Feng Guo;Minje Kim;Lantao Liu;Lei Jiang.,louqian@iu.edu;fengguo@iu.edu;minje@indiana.edu;lantao@iu.edu;jiang60@iu.edu,6;3;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"Indiana University, Bloomington;Indiana University, Bloomington;Indiana University;Indiana University, Bloomington;Indiana University, Bloomington",AutoML;Kernel-Wise Neural Networks Quantization;Hierarchical Deep Reinforcement Learning,64;64;64;64;64,134;134;134;134;134,m;m,NAN,NAN,n,
3554,ICLR,2020,Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling,Yuping Luo;Huazhe Xu;Tengyu Ma,yupingl@cs.princeton.edu;huazhe_xu@eecs.berkeley.edu;tengyuma@stanford.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Princeton University;University of California Berkeley;Stanford University,imitation learning;model-based imitation learning;model-based RL;behavior cloning;covariate shift,30;-1;5,6;13;4,m;m,usa,usa,y,
3555,ICLR,2020,Projection-Based Constrained Policy Optimization,Tsung-Yen Yang;Justinian Rosca;Karthik Narasimhan;Peter J. Ramadge,ty3@princeton.edu;justinian.rosca@siemens.com;karthikn@cs.princeton.edu;ramadge@princeton.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Princeton University;Siemens Corporate Research;Princeton University;Princeton University,Reinforcement learning with constraints;Safe reinforcement learning,30;-1;30;30,6;-1;6;6,f;m,usa,usa,y,1;7
3556,ICLR,2020,Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities,Baichuan Yuan;Xiaowei Wang;Jianxin Ma;Chang Zhou;Andrea L. Bertozzi;Hongxia Yang,ybcmath@gmail.com;daemon.wxw@alibaba-inc.com;majx13fromthu@gmail.com;ericzhou.zc@alibaba-inc.com;bertozzi@math.ucla.edu;yang.yhx@alibaba-inc.com,6;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of California, Los Angeles;Alibaba Group;Alibaba Group;Alibaba Group;University of California, Los Angeles;Alibaba Group",VAE;collaborative filtering;recommender systems;spatial point process,-1;-1;-1;-1;-1;-1,17;-1;-1;-1;17;-1,m;f,NAN,NAN,y,1;5
3557,ICLR,2020,Single Episode Policy Transfer in Reinforcement Learning,Jiachen Yang;Brenden Petersen;Hongyuan Zha;Daniel Faissol,yjiachen@gmail.com;petersen33@llnl.gov;zha@cc.gatech.edu;faissol1@llnl.gov,8;8;3,,Accept (Poster),0,7,0.0,yes,9/25/19,Georgia Institute of Technology;Lawrence Livermore National Labs;Georgia Institute of Technology;Lawrence Livermore National Labs,transfer learning;reinforcement learning,13;-1;13;-1,38;-1;38;-1,m;m,NAN,NAN,n,
3558,ICLR,2020,Transferable Perturbations of Deep Feature Distributions,Nathan Inkawhich;Kevin Liang;Lawrence Carin;Yiran Chen,nathan.inkawhich@duke.edu;kevin.liang@duke.edu;lcarin@duke.edu;yiran.chen@duke.edu,3;8;8,,Accept (Poster),0,6,0.0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,adversarial attacks;transferability;interpretability,46;46;46;46,20;20;20;20,m;m,europe,se,n,4
3559,ICLR,2020,Pruned Graph Scattering Transforms,Vassilis N. Ioannidis;Siheng Chen;Georgios B. Giannakis,ioann006@umn.edu;schen@merl.com;georgios@umn.edu,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,"University of Minnesota, Minneapolis;Mitsubishi Electric Research Labs;University of Minnesota, Minneapolis",Graph scattering transforms;pruning;graph convolutional networks;stability;deep learning,73;-1;73,79;-1;79,m;m,NAN,NAN,y,1;10
3560,ICLR,2020,Efficient Probabilistic Logic Reasoning with Graph Neural Networks,Yuyu Zhang;Xinshi Chen;Yuan Yang;Arun Ramamurthy;Bo Li;Yuan Qi;Le Song,yuyu@gatech.edu;xinshi.chen@gatech.edu;yuanyang@gatech.edu;arun.ramamurthy@siemens.com;lbo@illinois.edu;yuan.qi@antfin.com;lsong@cc.gatech.edu,3;3;1,,Accept (Poster),0,3,4.0,yes,9/25/19,"Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Siemens Corporate Research;University of Illinois, Urbana Champaign;Antfin;Georgia Institute of Technology",probabilistic logic reasoning;Markov Logic Networks;graph neural networks,13;13;13;-1;-1;-1;13,38;38;38;-1;-1;-1;38,m;m,usa,usa,n,10
3561,ICLR,2020,Decoupling Representation and Classifier for Long-Tailed Recognition,Bingyi Kang;Saining Xie;Marcus Rohrbach;Zhicheng Yan;Albert Gordo;Jiashi Feng;Yannis Kalantidis,kang@u.nus.edu;xiesaining@gmail.com;maroffm@gmail.com;zhicheng.yan@live.com;albert.gordo.s@gmail.com;elefjia@nus.edu.sg;ykalant@image.ntua.gr,6;8;6,,Accept (Poster),0,4,1.0,yes,9/25/19,National University of Singapore;Facebook;Facebook;;Facebook;National University of Singapore;National Technical University of Athens,long-tailed recognition;classification,17;-1;-1;-1;-1;17;316,25;-1;-1;-1;-1;25;776,m;m,NAN,NAN,n,6
3562,ICLR,2020,Coherent Gradients: An Approach to Understanding Generalization in Gradient Descent-based Optimization,Satrajit Chatterjee,satrajit@gmail.com,8;8;3,,Accept (Poster),0,21,0.0,yes,9/25/19,Google,generalization;deep learning,-1,-1,m,NAN,NAN,n,
3563,ICLR,2020,Environmental drivers of systematicity and generalization in a situated agent,Felix Hill;Andrew Lampinen;Rosalia Schneider;Stephen Clark;Matthew Botvinick;James L. McClelland;Adam Santoro,felixhill@google.com;lampinen@stanford.edo;rgschneider@google.com;clarkstephen@google.com;botvinick@google.com;jlmcc@google.com;adamsantoro@google.com,6;6;6,,Accept (Poster),0,19,0.0,yes,9/25/19,Google;;Google;Google;Google;Google;Google,systematicitiy;systematic;generalization;combinatorial;agent;policy;language;compositionality,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
3564,ICLR,2020,Compositional Language Continual Learning,Yuanpeng Li;Liang Zhao;Kenneth Church;Mohamed Elhoseiny,yuanpeng16@gmail.com;lzhao4ever@gmail.com;kenneth.ward.church@gmail.com;mohamed.elhoseiny@gmail.com,3;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,"Shanghai Jiao Tong University, Tsinghua University;Samsung;Baidu;KAUST",Compositionality;Continual Learning;Lifelong Learning;Sequence to Sequence Modeling,-1;-1;-1;102,-1;-1;-1;-1,m;m,europe,gr,n,3
3565,ICLR,2020,Vid2Game: Controllable Characters Extracted from Real-World Videos,Oran Gafni;Lior Wolf;Yaniv Taigman,oran.gafni@gmail.com;wolf@fb.com;yaniv@fb.com,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Facebook;Facebook;Facebook,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3566,ICLR,2020,Infinite-horizon Off-Policy Policy Evaluation with Multiple Behavior Policies,Xinyun Chen;Lu Wang;Yizhe Hang;Heng Ge;Hongyuan Zha,chenxinyun@cuhk.edu.cn;luwang@stu.ecnu.edu.cn;hangyhan@mail.ustc.edu.cn;hengge@mail.sdu.edu.cn;zhahy@cuhk.edu.cn,6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen;East China Normal University;University of Science and Technology of China;Shandong University;The Chinese University of Hong Kong, Shenzhen",off-policy policy evaluation;multiple importance sampling;kernel method;variance reduction,46;-1;-1;143;46,35;544;80;658;35,m;m,NAN,NAN,y,
3567,ICLR,2020,Learning Efficient Parameter Server Synchronization Policies for Distributed SGD,Rong Zhu;Sheng Yang;Andreas Pfadler;Zhengping Qian;Jingren Zhou,red.zr@alibaba-inc.com;yangsheng@hit.edu.cn;andreaswernerrober@alibaba-inc.com;zhengping.qzp@alibaba-inc.com;jingren.zhou@alibaba-inc.com,6;3;6,,Accept (Poster),0,9,0.0,yes,9/25/19,Alibaba Group;Harbin Institute of Technology;Alibaba Group;Alibaba Group;Alibaba Group,Distributed SGD;Paramter-Server;Synchronization Policy;Reinforcement Learning,-1;168;-1;-1;-1,-1;424;-1;-1;-1,m;m,NAN,NAN,n,
3568,ICLR,2020,Unsupervised Clustering using Pseudo-semi-supervised Learning,Divam Gupta;Ramachandran Ramjee;Nipun Kwatra;Muthian Sivathanu,divam@cmu.edu;ramjee@microsoft.com;nipun.kwatra@microsoft.com;muthian@microsoft.com,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Carnegie Mellon University;Microsoft;Microsoft;Microsoft,Unsupervised Learning;Unsupervised Clustering;Deep Learning,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n,10
3569,ICLR,2020,Tree-Structured Attention with Hierarchical Accumulation,Xuan-Phi Nguyen;Shafiq Joty;Steven Hoi;Richard Socher,nxphi47@gmail.com;sjoty@salesforce.com,8;6;6,,Accept (Poster),0,0,0.0,yes,9/25/19,Nanyang Technological University;SalesForce.com,Tree;Constituency Tree;Hierarchical Accumulation;Machine Translation;NMT;WMT;IWSLT;Text Classification;Sentiment Analysis,-1;-1,-1;-1,m;m,NAN,NAN,y,8;3
3570,ICLR,2020,Sparse Coding with Gated Learned ISTA,Kailun Wu;Yiwen Guo;Ziang Li;Changshui Zhang,wukl14@mails.tsinghua.edu.cn;guoyiwen.ai@bytedance.com;liza19@mails.tsinghua.edu.cn;zcs@mail.tsinghua.edu.cn,8;8;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;ByteDance;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Sparse coding;deep learning;learned ISTA;convergence analysis,4;-1;4;4,23;-1;23;23,m;m,NAN,NAN,y,
3571,ICLR,2020,A Signal Propagation Perspective for Pruning Neural Networks at Initialization,Namhoon Lee;Thalaiyasingam Ajanthan;Stephen Gould;Philip H. S. Torr,namhoon@robots.ox.ac.uk;thalaiyasingam.ajanthan@anu.edu.au;stephen.gould@anu.edu.au;phst@robots.ox.ac.uk,8;3;6,,Accept (Spotlight),0,3,0.0,yes,9/25/19,University of Oxford;Australian National University;Australian National University;University of Oxford,neural network pruning;signal propagation perspective;sparse neural networks,46;102;102;46,1;50;50;1,m;m,europe,uk,y,
3572,ICLR,2020,Functional vs. parametric equivalence of ReLU networks,Mary Phuong;Christoph H. Lampert,bphuong@ist.ac.at;chl@ist.ac.at,3;8;6,,Accept (Poster),1,4,0.0,yes,9/25/19,Institute of Science and Technology Austria;Institute of Science and Technology Austria,ReLU networks;symmetry;functional equivalence;over-parameterization,-1;-1,-1;-1,f;m,NAN,NAN,y,1
3573,ICLR,2020,Jacobian Adversarially Regularized Networks for Robustness,Alvin Chan;Yi Tay;Yew Soon Ong;Jie Fu,guoweial001@e.ntu.edu.sg;ytay017@e.ntu.edu.sg;asysong@ntu.edu.sg;jie.fu@polymtl.ca,6;3;6,,Accept (Poster),0,5,1.0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Polytechnique Montreal,adversarial examples;robust machine learning;deep learning,43;43;43;316,49;49;49;-1,m;m,canada,ca,y,5;4
3574,ICLR,2020,Reinforced active learning for image segmentation,Arantxa Casanova;Pedro O. Pinheiro;Negar Rostamzadeh;Christopher J. Pal,arantxa.casanova-paga@polymtl.ca;pedro@opinheiro.com;negar@elementai.com;chris.j.pal@gmail.com,6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Polytechnique Montreal;Deep Genomics;Element AI;Polytechnique Montreal,semantic segmentation;active learning;reinforcement learning,316;-1;-1;316,-1;-1;-1;-1,f;m,canada,ca,n,2;1
3575,ICLR,2020,Maximum Likelihood Constraint Inference for Inverse Reinforcement Learning,Dexter R.R. Scobee;S. Shankar Sastry,dscobee@eecs.berkeley.edu;sastry@eecs.berkeley.edu,3;6;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley,learning from demonstration;inverse reinforcement learning;constraint inference,-1;-1,13;13,m;m,usa,usa,y,
3576,ICLR,2020,Weakly Supervised Disentanglement with Guarantees,Rui Shu;Yining Chen;Abhishek Kumar;Stefano Ermon;Ben Poole,ruishu@stanford.edu;cynnjjs@stanford.edu;abhishk@google.com;ermon@cs.stanford.edu;pooleb@google.com,8;8;3,,Accept (Poster),1,10,0.0,yes,9/25/19,Stanford University;Stanford University;Google;Stanford University;Google,disentanglement;theory of disentanglement;representation learning;generative models,5;5;-1;5;-1,4;4;-1;4;-1,m;m,NAN,NAN,y,1
3577,ICLR,2020,PCMC-Net: Feature-based Pairwise Choice Markov Chains,Alix Lh√©ritier,alherit@gmail.com,8;6;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,Amadeus IT Group,choice modeling;pairwise choice Markov chains;deep learning;amortized inference;automatic differentiation;airline itinerary choice modeling,-1,-1,m;u,NAN,NAN,y,
3578,ICLR,2020,Capsules with Inverted Dot-Product Attention Routing,Yao-Hung Hubert Tsai;Nitish Srivastava;Hanlin Goh;Ruslan Salakhutdinov,yaohungt@cs.cmu.edu;nitish_srivastava@apple.com;hanlin@apple.com;rsalakhutdinov@apple.com,3;6;8,,Accept (Poster),1,4,0.0,yes,9/25/19,Carnegie Mellon University;Apple;Apple;Apple,capsule networks;routing;attention,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n,8
3579,ICLR,2020,Contrastive Representation Distillation,Yonglong Tian;Dilip Krishnan;Phillip Isola,yonglong@mit.edu;dilipkay@google.com;phillipi@mit.edu,3;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,Knowledge Distillation;Representation Learning;Contrastive Learning;Mutual Information,5;-1;5,5;-1;5,m;m,usa,usa,n,
3580,ICLR,2020,Variance Reduction With Sparse Gradients,Melih Elibol;Lihua Lei;Michael I. Jordan,elibol@cs.berkeley.edu;lihualei@stanford.edu;jordan@cs.berkeley.edu,6;3;8,,Accept (Poster),0,6,0.0,yes,9/25/19,University of California Berkeley;Stanford University;University of California Berkeley,optimization;variance reduction;machine learning;deep neural networks,-1;5;-1,13;4;13,m;m,usa,usa,y,3
3581,ICLR,2020,FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary,Yingzhen Yang;Jiahui Yu;Nebojsa Jojic;Jun Huan;Thomas S. Huang,superyyzg@gmail.com;jyu79@illinois.edu;jojic@microsoft.com;lukehuan@shenshangtech.com;t-huang1@illinois.edu,8;6;6,,Accept (Poster),0,2,0.0,yes,9/25/19,"Arizona State University;University of Illinois, Urbana Champaign;Microsoft;Shenshangtech;University of Illinois, Urbana Champaign",Compression of Convolutional Neural Networks;Filter Summary CNNs;Weight Sharing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n,2
3582,ICLR,2020,RNA Secondary Structure Prediction By Learning Unrolled Algorithms,Xinshi Chen;Yu Li;Ramzan Umarov;Xin Gao;Le Song,xinshi.chen@gatech.edu;yu.li@kaust.edu.sa;ramzan.umarov@kaust.edu.sa;xin.gao@kaust.edu.sa;lsong@cc.gatech.edu,8;6;8;8,,Accept (Talk),0,12,0.0,yes,9/25/19,Georgia Institute of Technology;KAUST;KAUST;KAUST;Georgia Institute of Technology,RNA secondary structure prediction;learning algorithm;deep architecture design;computational biology,13;102;102;102;13,38;-1;-1;-1;38,f;m,usa,usa,n,
3583,ICLR,2020,The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget,Anirudh Goyal;Yoshua Bengio;Matthew Botvinick;Sergey Levine,anirudhgoyal9119@gmail.com;yoshua.bengio@mila.quebec;botvinick@google.com;svlevine@eecs.berkeley.edu,6;6,,Accept (Poster),0,10,1.0,yes,9/25/19,University of Montreal;Mila;Google;University of California Berkeley,Variational Information Bottleneck;Reinforcement learning,-1;143;-1;-1,-1;336;-1;13,m;m,usa,usa,n,1
3584,ICLR,2020,Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models,Cheolhyoung Lee;Kyunghyun Cho;Wanmo Kang,bloodwass@kaist.ac.kr;kyunghyun.cho@nyu.edu;wanmo.kang@kaist.edu,6;6;8,,Accept (Poster),0,5,1.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;New York University;KAIST,regularization;finetuning;dropout;dropconnect;adaptive L2-penalty;BERT;pretrained language model,-1;22;15,110;29;110,m;m,asia,in,y,3;1
3585,ICLR,2020,Novelty Detection Via Blurring,Sungik Choi;Sae-Young Chung,si_choi@kaist.ac.kr;schung@kaist.ac.kr,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,novelty;anomaly;uncertainty,-1;-1,110;110,m;m,NAN,NAN,n,5;4
3586,ICLR,2020,Locality and Compositionality in Zero-Shot Learning,Tristan Sylvain;Linda Petrini;Devon Hjelm,tristan.sylvain@gmail.com;lindapetrini@gmail.com;devon.hjelm@microsoft.com,6;8;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Microsoft;;Microsoft,Zero-shot learning;Compositionality;Locality;Deep Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,6;1
3587,ICLR,2020,"Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control",Nir Levine;Yinlam Chow;Rui Shu;Ang Li;Mohammad Ghavamzadeh;Hung Bui,nirlevine@google.com;yinlamchow@google.com;ruishu@stanford.edu;anglili@google.com;mgh@fb.com;v.hungbh1@vinai.io,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Stanford University;Google;Facebook;VinAI Research,Embed-to-Control;Representation Learning;Stochastic Optimal Control;VAE;iLQR,-1;-1;5;-1;-1;-1,-1;-1;4;-1;-1;-1,m;m,NAN,NAN,y,1
3588,ICLR,2020,Federated Learning with Matched Averaging,Hongyi Wang;Mikhail Yurochkin;Yuekai Sun;Dimitris Papailiopoulos;Yasaman Khazaeni,hongyiwang@cs.wisc.edu;mikhail.yurochkin@ibm.com;yuekai@umich.edu;dimitris@papail.io;yasaman.khazaeni@us.ibm.com,8;8;6,,Accept (Talk),0,5,1.0,yes,9/25/19,University of Southern California;International Business Machines;University of Michigan;University of Wisconsin - Madison;International Business Machines,federated learning,36;-1;7;18;-1,62;-1;21;51;-1,m;f,NAN,NAN,n,
3589,ICLR,2020,Efficient and Information-Preserving Future Frame Prediction and Beyond,Wei Yu;Yichao Lu;Steve Easterbrook;Sanja Fidler,gnosis@cs.toronto.edu;yichao@cs.toronto.edu;sme@cs.toronto.edu;fidler@cs.toronto.edu,6;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Toronto;University of Toronto;University of Toronto;University of Toronto,self-supervised learning;generative pre-training;video prediction;reversible architecture,18;18;18;18,18;18;18;18,m;f,canada,ca,n,2;5
3590,ICLR,2020,Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds,Lukas Prantl;Nuttapong Chentanez;Stefan Jeschke;Nils Thuerey,lukas.prantl@tum.de;nuttapong26@gmail.com;jeschke@stefan-jeschke.com;nils.thuerey@tum.de,6;8;6,,Accept (Spotlight),0,3,0.0,yes,9/25/19,Technical University Munich;;Stefan-jeschke;Technical University Munich,point clouds;spatio-temporal representations;Lagrangian data;temporal coherence;super-resolution;denoising,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5
3591,ICLR,2020,Asymptotics of Wide Networks from Feynman Diagrams,Ethan Dyer;Guy Gur-Ari,edyer@google.com;guyga@google.com,6;6;8,,Accept (Spotlight),0,4,0.0,yes,9/25/19,Google;Google,,-1;-1,-1;-1,m;m,NAN,NAN,y,
3592,ICLR,2020,Unbiased Contrastive Divergence Algorithm for Training Energy-Based Latent Variable Models,Yixuan Qiu;Lingsong Zhang;Xiao Wang,yixuanq@andrew.cmu.edu;lingsong@purdue.edu;wangxiao@purdue.edu,6;8;8,,Accept (Spotlight),0,3,2.0,yes,9/25/19,Carnegie Mellon University;Purdue University;Purdue University,energy model;restricted Boltzmann machine;contrastive divergence;unbiased Markov chain Monte Carlo;distribution coupling,1;24;24,27;88;88,m;f,usa,usa,y,1
3593,ICLR,2020,Frequency-based Search-control in Dyna,Yangchen Pan;Jincheng Mei;Amir-massoud Farahmand,pan6@ualberta.ca;jmei2@ualberta.ca;farahmand@vectorinstitute.ai,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Alberta;University of Alberta;Vector Institute,Model-based reinforcement learning;search-control;Dyna;frequency of a signal,102;102;-1,136;136;-1,m;m,NAN,NAN,y,1
3594,ICLR,2020,Energy-based models for atomic-resolution protein conformations,Yilun Du;Joshua Meier;Jerry Ma;Rob Fergus;Alexander Rives,yilundu@mit.edu;jmeier@fb.com;maj@fb.com;robfergus@fb.com;arives@cs.nyu.edu,8;8;6,,Accept (Spotlight),0,5,0.0,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook;New York University,energy-based model;transformer;energy function;protein conformation,5;-1;-1;-1;22,5;-1;-1;-1;29,m;m,usa,usa,n,
3595,ICLR,2020,Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and Strategic Dialog History,Yiheng Zhou;Yulia Tsvetkov;Alan W Black;Zhou Yu,yihengz1@cs.cmu.edu;ytsvetko@cs.cmu.edu;awb@cs.cmu.edu;joyu@ucdavis.edu,6;3;6,,Accept (Poster),0,3,0.0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;University of California, Davis",dialog systems;history tracking,1;1;1;-1,27;27;27;55,m;f,usa,usa,n,
3596,ICLR,2020,Discovering Motor Programs by Recomposing Demonstrations,Tanmay Shankar;Shubham Tulsiani;Lerrel Pinto;Abhinav Gupta,tanmayshankar@fb.com;shubhtuls@fb.com;lerrel.pinto@gmail.com;abhinavg@cs.cmu.edu,3;8;6,,Accept (Poster),0,9,0.0,yes,9/25/19,Facebook;Facebook;New York University;Carnegie Mellon University,Learning from Demonstration;Imitation Learning;Motor Primitives,-1;-1;22;1,-1;-1;29;27,m;m,usa,usa,n,
3597,ICLR,2020,Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers,Junjie LIU;Zhe XU;Runbin SHI;Ray C. C. Cheung;Hayden K.H. So,jjliu@eee.hku.hk;zhexu22-c@my.cityu.edu.hk;rbshi@eee.hku.hk;r.cheung@cityu.edu.hk;hso@eee.hku.hk,6;3;6,,Accept (Poster),0,6,3.0,yes,9/25/19,The University of Hong Kong;The Hong Kong Polytechnic University;The University of Hong Kong;The Hong Kong Polytechnic University;The University of Hong Kong,neural network pruning;sparse learning;network compression;architecture search,92;118;92;118;92,35;171;35;171;35,m;m,NAN,NAN,n,
3598,ICLR,2020,RTFM: Generalising to New Environment Dynamics via Reading,Victor Zhong;Tim Rockt√§schel;Edward Grefenstette,victor@victorzhong.com;tim.rocktaeschel@gmail.com;egrefen@gmail.com,6;6;6,,Accept (Poster),1,4,0.0,yes,9/25/19,University of Washington;Facebook AI Research;Facebook,reinforcement learning;policy learning;reading comprehension;generalisation,11;-1;-1,26;-1;-1,m;m,NAN,NAN,n,
3599,ICLR,2020,Causal Discovery with Reinforcement Learning,Shengyu Zhu;Ignavier Ng;Zhitang Chen,zhushengyu@huawei.com;ignavierng@cs.toronto.edu;chenzhitang2@huawei.com,8;8;8,,Accept (Talk),0,6,2.0,yes,9/25/19,Huawei Technologies Ltd.;University of Toronto;Huawei Technologies Ltd.,causal discovery;structure learning;reinforcement learning;directed acyclic graph,-1;18;-1,-1;18;-1,m;m,NAN,NAN,y,10
3600,ICLR,2020,FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES,Jatin Chauhan;Deepak Nathani;Manohar Kaul,chauhanjatin100@gmail.com;deepakn1019@gmail.com;mkaul@iith.ac.in,6;3;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Indian Institute of Technology Hyderabad;Google;Indian Institute of Technology Hyderabad,Few shot graph classification;graph spectral measures;super-classes,-1;-1;-1,-1;-1;713,u;u,NAN,NAN,n,6;10
3601,ICLR,2020,Controlling generative models with continuous factors of variations,Antoine Plumerault;Herv√© Le Borgne;C√©line Hudelot,antoine.plumerault@cea.fr;herve.le-borgne@cea.fr;celine.hudelot@centralesupelec.fr,6;6;8,,Accept (Poster),0,4,0.0,yes,9/25/19,CEA;CEA;CentraleSupelec,Generative models;factor of variation;GAN;beta-VAE;interpretable representation;interpretability,194;194;-1,1027;1027;534,m;f,NAN,NAN,n,2;3;5
3602,ICLR,2020,Defending Against Physically Realizable Attacks on Image Classification,Tong Wu;Liang Tong;Yevgeniy Vorobeychik,tongwu@wustl.edu;liangtong@wustl.edu;yvorobeychik@wustl.edu,8;8;3,,Accept (Spotlight),0,9,0.0,yes,9/25/19,"Washington University, St. Louis;Washington University, St. Louis;Washington University, St. Louis",defense against physical attacks;adversarial machine learning,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,4
3603,ICLR,2020,A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning,Soochan Lee;Junsoo Ha;Dongsu Zhang;Gunhee Kim,soochan.lee@vision.snu.ac.kr;junsooha@hanyang.ac.kr;96lives@snu.ac.kr;gunhee@snu.ac.kr,6;6;8,,Accept (Poster),0,4,1.0,yes,9/25/19,Seoul National University;Hanyang University;Seoul National University;Seoul National University,continual learning;task-free;task-agnostic,39;194;39;39,64;393;64;64,m;m,asia,kr,n,11;5
3604,ICLR,2020,HiLLoC: lossless image compression with hierarchical latent variable models,James Townsend;Thomas Bird;Julius Kunze;David Barber,james.townsend@cs.ucl.ac.uk;thomas.bird@cs.ucl.ac.uk;julius.kunze@cs.ucl.ac.uk;david.barber@ucl.ac.uk,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University College London;University College London;University College London;University College London,compression;variational inference;lossless compression;deep latent variable models,52;52;52;52,-1;-1;-1;-1,m;m,europe,uk,n,5
3605,ICLR,2020,Multilingual Alignment of Contextual Word Representations,Steven Cao;Nikita Kitaev;Dan Klein,stevencao@berkeley.edu;kitaev@berkeley.edu;klein@berkeley.edu,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,multilingual;natural language processing;embedding alignment;BERT;word embeddings;transfer,-1;-1;-1,13;13;13,m;m,usa,usa,n,6
3606,ICLR,2020,Jelly Bean World: A Testbed for Never-Ending Learning,Emmanouil Antonios Platanios;Abulhair Saparov;Tom Mitchell,e.a.platanios@cs.cmu.edu;asaparov@cs.cmu.edu;tom.mitchell@cs.cmu.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1,27;27;27,m;m,usa,usa,n,
3607,ICLR,2020,V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control,H. Francis Song;Abbas Abdolmaleki;Jost Tobias Springenberg;Aidan Clark;Hubert Soyer;Jack W. Rae;Seb Noury;Arun Ahuja;Siqi Liu;Dhruva Tirumala;Nicolas Heess;Dan Belov;Martin Riedmiller;Matthew M. Botvinick,songf@google.com;aabdolmaleki@google.com;springenberg@google.com;aidanclark@google.com;soyer@google.com;jwrae@google.com;snoury@google.com;arahuja@google.com;liusiqi@google.com;dhruvat@google.com;heess@google.com;danbelov@google.com;riedmiller@google.com;botvinick@google.com,6;6;6,,Accept (Poster),1,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;policy iteration;multi-task learning;continuous control,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3608,ICLR,2020,Deep Graph Matching Consensus,Matthias Fey;Jan E. Lenssen;Christopher Morris;Jonathan Masci;Nils M. Kriege,matthias.fey@tu-dortmund.de;janeric.lenssen@udo.edu;christopher.morris@tu-dortmund.de;jonathan@nnaisense.com;nils.kriege@tu-dortmund.de,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,TU Dortmund;TU Dortmund University;TU Dortmund;NNAISENSE;TU Dortmund,graph matching;graph neural networks;neighborhood consensus;deep learning,248;248;248;-1;248,354;354;354;-1;354,m;m,europe,de,y,2;10
3609,ICLR,2020,CATER: A diagnostic dataset for Compositional Actions & TEmporal Reasoning,Rohit Girdhar;Deva Ramanan,rgirdhar@cs.cmu.edu;deva@cs.cmu.edu,8;8;8,,Accept (Talk),0,3,1.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Video Understanding;Temporal Reasoning,1;1,27;27,m;m,usa,usa,n,2
3610,ICLR,2020,Differentiable Reasoning over a Virtual Knowledge Base,Bhuwan Dhingra;Manzil Zaheer;Vidhisha Balachandran;Graham Neubig;Ruslan Salakhutdinov;William W. Cohen,bdhingra@andrew.cmu.edu;manzilzaheer@google.com;vbalacha@andrew.cmu.edu;gneubig@cs.cmu.edu;rsalakhu@cs.cmu.edu;wcohen@google.com,8;8;8,,Accept (Talk),0,6,0.0,yes,9/25/19,Carnegie Mellon University;Google;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Google,Question Answering;Multi-Hop QA;Deep Learning;Knowledge Bases;Information Extraction;Data Structures for QA,1;-1;1;1;1;-1,27;-1;27;27;27;-1,m;m,NAN,NAN,n,3
3611,ICLR,2020,Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents,Christian Rupprecht;Cyril Ibrahim;Christopher J. Pal,christian.rupprecht@eng.ox.ac.uk;cyril.ibrahim@elementai.com;christopher.pal@polymtl.ca,6;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,University of Oxford;Element AI;Polytechnique Montreal,Visualization;Reinforcement Learning;Safety,46;-1;316,1;-1;-1,m;m,canada,ca,n,5
3612,ICLR,2020,Intriguing Properties of Adversarial Training at Scale,Cihang Xie;Alan Yuille,cihangxie306@gmail.com;alan.l.yuille@gmail.com,6;8;6,,Accept (Poster),0,4,1.0,yes,9/25/19,University of Southern California;Johns Hopkins University,adversarial defense;adversarial machine learning,36;73,62;12,m;m,usa,usa,n,1;4
3613,ICLR,2020,Four Things Everyone Should Know to Improve Batch Normalization,Cecilia Summers;Michael J. Dinneen,ceciliasummers07@gmail.com;mjd@cs.auckland.ac.nz,6;3;6,,Accept (Poster),0,5,2.0,yes,9/25/19,University of Auckland;University of Auckland,batch normalization,248;248,177;177,f;m,australasia,nz,n,
3614,ICLR,2020,Effect of Activation Functions on the Training of Overparametrized Neural Nets,Abhishek Panigrahi;Abhishek Shetty;Navin Goyal,abhishekpanigrahi034@gmail.com;ashetty1995@gmail.com;navingo@microsoft.com,8;6,,Accept (Poster),0,2,0.0,yes,9/25/19,Princeton University;Cornell University;Microsoft,activation functions;deep learning theory;neural networks,-1;7;-1,-1;19;-1,m;m,NAN,NAN,y,1
3615,ICLR,2020,Differentiation of Blackbox Combinatorial Solvers,Marin Vlastelica Poganƒçiƒá;Anselm Paulus;Vit Musil;Georg Martius;Michal Rolinek,marin.vlastelica@tue.mpg.de;anselm.paulus@tuebingen.mpg.de;vejtek@atrey.karlin.mff.cuni.cz;georg.martius@tuebingen.mpg.de;michal.rolinek@tuebingen.mpg.de,8;8;8,,Accept (Spotlight),0,6,0.0,yes,9/25/19,"Max-Planck Institute;Max-Planck Institute;Charles University, Prague;Max-Planck Institute;Max-Planck Institute",combinatorial algorithms;deep learning;representation learning;optimization,-1;-1;316;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3616,ICLR,2020,Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning,Gil Lederman;Markus Rabe;Sanjit Seshia;Edward A. Lee,gilled@berkeley.edu;mrabe@google.com;sshesia@eecs.berkeley.edu;eal@eecs.berkeley.edu,3;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,University of California Berkeley;Google;University of California Berkeley;University of California Berkeley,Logic;QBF;Logical Reasoning;SAT;Graph;Reinforcement Learning;GNN,-1;-1;-1;-1,13;-1;13;13,m;m,usa,usa,n,
3617,ICLR,2020,Inductive representation learning on temporal graphs,da Xu;chuanwei ruan;evren korpeoglu;sushant kumar;kannan achan,da.xu@walmartlabs.com;ruanchuanwei@gmail.com;ekorpeoglu@walmart.com;skumar4@walmartlabs.com;kachan@walmartlabs.com,8;6;6,,Accept (Poster),1,4,0.0,yes,9/25/19,Walmart Labs;;Walmart;Walmart Labs;Walmart Labs,temporal graph;inductive representation learning;functional time encoding;self-attention,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,8;1;10
3618,ICLR,2020,Multi-Scale Representation Learning  for Spatial Feature Distributions using Grid Cells,Gengchen Mai;Krzysztof Janowicz;Bo Yan;Rui Zhu;Ling Cai;Ni Lao,gengchen_mai@geog.ucsb.edu;janowicz@ucsb.edu;boyan1@linkedin.com;ruizhu@geog.ucsb.edu;lingcai@ucsb.edu;noon99@gmail.com,8;6;6,,Accept (Spotlight),0,7,1.0,yes,9/25/19,UC Santa Barbara;UC Santa Barbara;LinkedIn;UC Santa Barbara;UC Santa Barbara;mosaix.ai,Grid cell;space encoding;spatially explicit model;multi-scale periodic representation;unsupervised learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,3
3619,ICLR,2020,Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley Transform,Jun Li;Fuxin Li;Sinisa Todorovic,liju2@oregonstate.edu;fuxin.li@oregonstate.edu;sinisa@oregonstate.edu,3;6;6,,Accept (Poster),0,9,2.0,yes,9/25/19,Oregon State University;Oregon State University;Oregon State University,Orthonormality;Efficient Riemannian Optimization;the Stiefel manifold.,79;79;79,373;373;373,m;m,usa,usa,y,9
3620,ICLR,2020,"Neural tangent kernels, transportation mappings, and universal approximation",Ziwei Ji;Matus Telgarsky;Ruicheng Xian,ziweiji2@illinois.edu;mjt@illinois.edu;rxian2@illinois.edu,6;8,,Accept (Poster),0,4,1.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Neural Tangent Kernel;universal approximation;Barron;transport mapping,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y,1
3621,ICLR,2020,Dream to Control: Learning Behaviors by Latent Imagination,Danijar Hafner;Timothy Lillicrap;Jimmy Ba;Mohammad Norouzi,mail@danijar.com;countzero@google.com;jba@cs.toronto.edu;mnorouzi@google.com,6;8;6;8,,Accept (Spotlight),1,6,1.0,yes,9/25/19,"Department of Computer Science, University of Toronto;Google;University of Toronto;Google",world model;latent dynamics;imagination;planning by backprop;policy optimization;planning;reinforcement learning;control;representations;latent variable model;visual control;value function,18;-1;18;-1,18;-1;18;-1,m;m,NAN,NAN,n,
3622,ICLR,2020,From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech,Hyeong-Seok Choi;Changdae Park;Kyogu Lee,kekepa15@snu.ac.kr;cdpark@connect.ust.hk;kglee@snu.ac.kr,8;6;3,,Accept (Poster),1,5,0.0,yes,9/25/19,Seoul National University;The Hong Kong University of Science and Technology;Seoul National University,Multi-modal learning;Self-supervised learning;Voice profiling;Conditional GANs,39;-1;39,64;47;64,m;m,asia,kr,n,5
3623,ICLR,2020,Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension,Xinyun Chen;Chen Liang;Adams Wei Yu;Denny Zhou;Dawn Song;Quoc V. Le,xinyun.chen@berkeley.edu;crazydonkey@google.com;adamsyuwei@google.com;dennyzhou@google.com;dawnsong.travel@gmail.com;qvl@google.com,8;6;6,,Accept (Spotlight),0,8,0.0,yes,9/25/19,University of California Berkeley;Google;Google;Google;University of California Berkeley;Google,neural symbolic;reading comprehension;question answering,-1;-1;-1;-1;-1;-1,13;-1;-1;-1;13;-1,f;m,NAN,NAN,n,
3624,ICLR,2020,Population-Guided Parallel Policy Search for Reinforcement Learning,Whiyoung Jung;Giseung Park;Youngchul Sung,wy.jung@kaist.ac.kr;gs.park@kaist.ac.kr;ycsung@kaist.ac.kr,6;8;3,,Accept (Poster),0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Parallel Learning;Population Based Learning,-1;-1;-1,110;110;110,m;m,NAN,NAN,y,
3625,ICLR,2020,Abstract Diagrammatic Reasoning with Multiplex Graph Networks,Duo Wang;Mateja Jamnik;Pietro Lio,wd263@cam.ac.uk;mateja.jamnik@cl.cam.ac.uk;pietro.lio@cl.cam.ac.uk,6;3;6,,Accept (Poster),0,7,0.0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge,reasoning;Raven Progressive Matrices;graph neural networks;multiplex graphs,79;79;79,3;3;3,m;m,europe,uk,n,10
3626,ICLR,2020,Logic and the 2-Simplicial Transformer,James Clift;Dmitry Doryn;Daniel Murfet;James Wallbridge,jamesedwardclift@gmail.com;dmitry.doryn@gmail.com;d.murfet@unimelb.edu.au;james.wallbridge@gmail.com,3;3;8,,Accept (Poster),0,8,0.0,yes,9/25/19,The University of Melbourne;;The University of Melbourne;Kavli IPMU,transformer;logic;reinforcement learning;reasoning,-1;-1;85;-1,-1;-1;32;-1,m;m,asia,in,n,8
3627,ICLR,2020,Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies,Sungryull Sohn;Hyunjae Woo;Jongwook Choi;Honglak Lee,srsohn@umich.edu;hjwoo@umich.edu;jwook@umich.edu;honglak@eecs.umich.edu,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,University of Michigan;University of Michigan;University of Michigan;University of Michigan,Meta reinforcement learning;subtask graph,7;7;7;7,21;21;21;21,m;m,usa,usa,n,6;1;10
3628,ICLR,2020,A Latent Morphology Model for Open-Vocabulary Neural Machine Translation,Duygu Ataman;Wilker Aziz;Alexandra Birch,duyguataman@gmail.com;will.aziz@gmail.com;a.birch@ed.ac.uk,6;6;8,,Accept (Spotlight),0,0,0.0,yes,9/25/19,University of Zurich;University of Amsterdam;University of Edinburgh,neural machine translation;low-resource languages;latent-variable models,118;143;36,90;62;30,f;f,europe,uk,n,3;2;1
3629,ICLR,2020,Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification,Yixiao Ge;Dapeng Chen;Hongsheng Li,yxge@link.cuhk.edu.hk;chendapeng@sensetime.com;hsli@ee.cuhk.edu.hk,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,The Chinese University of Hong Kong;SenseTime Group Limited;The Chinese University of Hong Kong,Label Refinery;Unsupervised Domain Adaptation;Person Re-identification,316;-1;316,35;-1;35,m;m,NAN,NAN,n,
3630,ICLR,2020,Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling,Hao Zhang;Bo Chen;Long Tian;Zhengjue Wang;Mingyuan Zhou,zhanghao_xidian@163.com;bchen@mail.xidian.edu.cn;tianlong_xidian@163.com;zhengjuewang@163.com;mingyuan.zhou@mccombs.utexas.edu,6;3;8,,Accept (Poster),0,4,0.0,yes,9/25/19,"163;Xidian University;163;163;University of Texas, Austin",Deep topic model;image generation;text generation;raster-scan-GAN;zero-shot learning,-1;-1;-1;-1;-1,-1;919;-1;-1;-1,m;m,usa,usa,n,11;5;4
3631,ICLR,2020,Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control,Tsui-Wei Weng;Krishnamurthy (Dj) Dvijotham*;Jonathan Uesato*;Kai Xiao*;Sven Gowal*;Robert Stanforth*;Pushmeet Kohli,twweng@mit.edu;dvij@google.com;juesato@google.com;kaix@mit.edu;sgowal@google.com;stanforth@google.com;pushmeet@google.com,6;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Massachusetts Institute of Technology;Google;Google;Massachusetts Institute of Technology;Google;Google;Google,deep learning;reinforcement learning;robustness;adversarial examples,5;-1;-1;5;-1;-1;-1,5;-1;-1;5;-1;-1;-1,f;m,NAN,NAN,n,4
3632,ICLR,2020,BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget,Jack Turner;Elliot J. Crowley;Michael O'Boyle;Amos Storkey;Gavin Gray,jack.turner@ed.ac.uk;elliot.j.crowley@ed.ac.uk;mob@inf.ed.ac.uk;a.storkey@ed.ac.uk;g.d.b.gray@ed.ac.uk,6;3;6,,Accept (Poster),0,3,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh;University of Edinburgh;University of Edinburgh,model compression;architecture search;efficiency;budget;convolutional neural networks,36;36;36;36;36,30;30;30;30;30,m;m,europe,uk,n,
3633,ICLR,2020,Decoding As Dynamic Programming For Recurrent Autoregressive Models,Najam Zaidi;Trevor Cohn;Gholamreza Haffari,syed.zaidi1@monash.edu;t.cohn@unimelb.edu.au;reza.haffari@gmail.com,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Monash University;The University of Melbourne;Monash University,Decoding,92;85;-1,75;32;-1,m;m,asia,in,n,10
3634,ICLR,2020,LEARNING EXECUTION THROUGH NEURAL CODE FUSION,Zhan Shi;Kevin Swersky;Daniel Tarlow;Parthasarathy Ranganathan;Milad Hashemi,zshi17@cs.utexas.edu;kswersky@google.com;dtarlow@google.com;parthas@google.com;miladh@google.com,6;8;3,,Accept (Poster),0,3,0.0,yes,9/25/19,"University of Texas, Austin;Google;Google;Google;Google",code understanding;graph neural networks;learning program execution;execution traces;program performance,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;10
3635,ICLR,2020,Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions,Yao Qin;Nicholas Frosst;Sara Sabour;Colin Raffel;Garrison Cottrell;Geoffrey Hinton,yaq007@eng.ucsd.edu;frosst@google.com;sasabour@google.com;craffel@google.com;gary@eng.ucsd.edu;geoffhinton@google.com,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"University of California, San Diego;Google;Google;Google;University of California, San Diego;Google",Adversarial Examples;Detection of adversarial attacks,-1;-1;-1;-1;-1;-1,31;-1;-1;-1;31;-1,f;m,NAN,NAN,n,4
3636,ICLR,2020,Reconstructing continuous distributions of 3D protein structure from cryo-EM images,Ellen D. Zhong;Tristan Bepler;Joseph H. Davis;Bonnie Berger,zhonge@mit.edu;tbepler@mit.edu;jhdavis@mit.edu;bab@mit.edu,8;8;6,,Accept (Spotlight),0,3,1.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,generative models;proteins;3D reconstruction;cryo-EM,5;5;5;5,5;5;5;5,f;f,usa,usa,n,5
3637,ICLR,2020,Sampling-Free Learning of Bayesian Quantized Neural Networks,Jiahao Su;Milan Cvitkovic;Furong Huang,jiahaosu@terpmail.umd.edu;mcvitkov@caltech.edu;furongh@cs.umd.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"University of Maryland, College Park;California Institute of Technology;University of Maryland, College Park",Bayesian neural networks;Quantized neural networks,12;143;12,91;2;91,m;f,usa,usa,y,11
3638,ICLR,2020,On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach,Yuanhao Wang*;Guodong Zhang*;Jimmy Ba,yuanhao-16@mails.tsinghua.edu.cn;gdzhang@cs.toronto.edu;jba@cs.toronto.edu,6;6;6,,Accept (Poster),1,21,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;University of Toronto;University of Toronto",minimax optimization;smooth differentiable games;local convergence;generative adversarial networks;optimization,4;18;18,23;18;18,m;m,canada,ca,y,5
3639,ICLR,2020,Lagrangian Fluid Simulation with Continuous Convolutions,Benjamin Ummenhofer;Lukas Prantl;Nils Thuerey;Vladlen Koltun,benjamin.ummenhofer@intel.com;lukas.prantl@tum.de;nils.thuerey@tum.de;vkoltun@gmail.com,8;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Intel;Technical University Munich;Technical University Munich;Intel,particle-based physics;fluid mechanics;continuous convolutions;material estimation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,10
3640,ICLR,2020,Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well,Vipul Gupta;Santiago Akle Serrano;Dennis DeCoste,vipul_gupta@berkeley.edu;sakle@apple.com;ddecoste@apple.com,6;6;3,,Accept (Poster),0,3,0.0,yes,9/25/19,University of California Berkeley;Apple;Apple,Large batch training;Distributed neural network training;Stochastic Weight Averaging,-1;-1;-1,13;-1;-1,m;m,NAN,NAN,n,2;1
3641,ICLR,2020,Adversarial AutoAugment,Xinyu Zhang;Qiang Wang;Jian Zhang;Zhao Zhong,zhangxinyu10@huawei.com;wangqiang168@huawei.com;zhangjian157@huawei.com;zorro.zhongzhao@huawei.com,6;6;6,,Accept (Poster),0,10,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Automatic Data Augmentation;Adversarial Learning;Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1;4
3642,ICLR,2020,NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search,Arber Zela;Julien Siems;Frank Hutter,zelaa@cs.uni-freiburg.de;siemsj@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,1;8;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Neural Architecture Search;Deep Learning;Computer Vision,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
3643,ICLR,2020,You Only Train Once: Loss-Conditional Training of Deep Networks,Alexey Dosovitskiy;Josip Djolonga,adosovitskiy@gmail.com;josip@djolonga.com,6;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Google;Google,deep learning;image generation,-1;-1,-1;-1,m;m,NAN,NAN,y,5
3644,ICLR,2020,Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP,Yuanhao Wang;Kefan Dong;Xiaoyu Chen;Liwei Wang,yuanhao-16@mails.tsinghua.edu.cn;dkf16@mails.tsinghua.edu.cn;cxy30@pku.edu.cn;wanglw@cis.pku.edu.cn,6;6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Peking University;Peking University",theory;reinforcement learning;sample complexity,4;4;14;14,23;23;24;24,m;m,asia,cn,y,1;5
3645,ICLR,2020,Deep Audio Priors Emerge From Harmonic Convolutional Networks,Zhoutong Zhang;Yunyun Wang;Chuang Gan;Jiajun Wu;Joshua B. Tenenbaum;Antonio Torralba;William T. Freeman,ztzhang@mit.edu;wyy@mit.edu;ganchuang1990@gmail.com;jiajunwu@mit.edu;jbt@mit.edu;torralba@mit.edu;billf@mit.edu,6;6;6,,Accept (Poster),0,6,2.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Audio;Deep Prior,5;5;-1;5;5;5;5,5;5;-1;5;5;5;5,m;m,usa,usa,n,1
3646,ICLR,2020,Abductive Commonsense Reasoning,Chandra Bhagavatula;Ronan Le Bras;Chaitanya Malaviya;Keisuke Sakaguchi;Ari Holtzman;Hannah Rashkin;Doug Downey;Wen-tau Yih;Yejin Choi,chandrab@allenai.org;ronanlb@allenai.org;chaitanyam@allenai.org;keisukes@allenai.org;arih@allenai.org;hrashkin@uw.edu;dougd@allenai.org;scottyih@fb.com;yejinc@allenai.org,8;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;University of Washington, Seattle;Allen Institute for Artificial Intelligence;Facebook;Allen Institute for Artificial Intelligence",Abductive Reasoning;Commonsense Reasoning;Natural Language Inference;Natural Language Generation,-1;-1;-1;-1;-1;11;-1;-1;-1,-1;-1;-1;-1;-1;26;-1;-1;-1,m;f,NAN,NAN,n,3
3647,ICLR,2020,DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures,Huanrui Yang;Wei Wen;Hai Li,huanrui.yang@duke.edu;wei.wen@duke.edu;hai.li@duke.edu,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Duke University;Duke University;Duke University,Deep neural network;Sparsity inducing regularizer;Model compression,46;46;46,20;20;20,m;f,europe,se,n,
3648,ICLR,2020,DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling,Sachin Mehta;Rik Koncel-Kedziorski;Mohammad Rastegari;Hannaneh Hajishirzi,sacmehta@uw.edu;kedzior@uw.edu;mohammadr@allenai.org;hannaneh@washington.edu,6;6;3,,Accept (Poster),0,13,1.0,yes,9/25/19,"University of Washington, Seattle;University of Washington, Seattle;Allen Institute for Artificial Intelligence;University of Washington",sequence modeling;input representations;language modeling;word embedding,11;11;-1;11,26;26;-1;26,m;f,usa,usa,n,8;3
3649,ICLR,2020,Never Give Up: Learning Directed Exploration Strategies,Adri√† Puigdom√®nech Badia;Pablo Sprechmann;Alex Vitvitskyi;Daniel Guo;Bilal Piot;Steven Kapturowski;Olivier Tieleman;Martin Arjovsky;Alexander Pritzel;Andrew Bolt;Charles Blundell,adriap@google.com;psprechmann@google.com;avlife@google.com;danielguo@google.com;piot@google.com;skapturowski@google.com;tieleman@google.com;martinarjovsky@gmail.com;apritzel@google.com;abolt@google.com;cblundell@google.com,6;8;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;;Google;Google;Google,deep reinforcement learning;exploration;intrinsic motivation,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3650,ICLR,2020,Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks,Yu Bai;Jason D. Lee,yubai.pku@gmail.com;jasondlee88@gmail.com,6;6;6,,Accept (Poster),0,4,1.0,yes,9/25/19,SalesForce.com;Princeton University,Neural Tangent Kernels;over-parametrized neural networks;deep learning theory,-1;30,-1;6,m;m,usa,usa,y,1
3651,ICLR,2020,Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity,Jingzhao Zhang;Tianxing He;Suvrit Sra;Ali Jadbabaie,jzhzhang@mit.edu;tianxing@mit.edu;suvrit@mit.edu;jadbabai@mit.edu,8;8;8,,Accept (Talk),0,8,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Adaptive methods;optimization;deep learning,5;5;5;5,5;5;5;5,m;m,usa,usa,y,1
3652,ICLR,2020,Thieves on Sesame Street! Model Extraction of BERT-based APIs,Kalpesh Krishna;Gaurav Singh Tomar;Ankur P. Parikh;Nicolas Papernot;Mohit Iyyer,kalpesh@cs.umass.edu;gtomar@google.com;aparikh@google.com;papernot@google.com;miyyer@cs.umass.edu,8;6;8,,Accept (Poster),0,3,1.0,yes,9/25/19,"University of Massachusetts, Amherst;Google;Google;Google;University of Massachusetts, Amherst",model extraction;BERT;natural language processing;pretraining language models;model stealing;deep learning security,24;-1;-1;-1;24,209;-1;-1;-1;209,m;m,usa,usa,n,6;3;4
3653,ICLR,2020,GraphZoom: A Multi-level Spectral Approach for Accurate and Scalable Graph Embedding,Chenhui Deng;Zhiqiang Zhao;Yongyu Wang;Zhiru Zhang;Zhuo Feng,cd574@cornell.edu;qzzhao@mtu.edu;yongyuw@mtu.edu;zhiruz@cornell.edu;zfeng12@stevens.edu,6;8;8,,Accept (Talk),0,7,0.0,yes,9/25/19,Cornell University;Michigan Technological University;Michigan Technological University;Cornell University;Stevens Institute of Technology,graph embedding;unsupervised learning;multi-level optimization;spectral graph theory,7;316;316;7;143,19;-1;-1;19;605,m;m,usa,usa,n,10
3654,ICLR,2020,Low-Resource Knowledge-Grounded Dialogue Generation,Xueliang Zhao;Wei Wu;Chongyang Tao;Can Xu;Dongyan Zhao;Rui Yan,xl.zhao@pku.edu.cn;wuwei@microsoft.com;chongyangtao@pku.edu.cn;can.xu@microsoft.com;zhaody@pku.edu.cn;ruiyan@pku.edu.cn,6;8;8,,Accept (Poster),0,4,0.0,yes,9/25/19,Peking University;Microsoft;Peking University;Microsoft;Peking University;Peking University,,14;-1;14;-1;14;14,24;-1;24;-1;24;24,m;m,asia,cn,n,
3655,ICLR,2020,Diverse Trajectory Forecasting with Determinantal Point Processes,Ye Yuan;Kris M. Kitani,yyuan2@cs.cmu.edu;kkitani@cs.cmu.edu,6;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Diverse Inference;Generative Models;Trajectory Forecasting,1;1,27;27,m;m,usa,usa,n,5
3656,ICLR,2020,Maxmin Q-learning: Controlling the Estimation Bias of Q-learning,Qingfeng Lan;Yangchen Pan;Alona Fyshe;Martha White,qlan3@ualberta.ca;pan6@ualberta.ca;alona@ualberta.ca;whitem@ualberta.ca,6;3;8,,Accept (Poster),0,11,0.0,yes,9/25/19,University of Alberta;University of Alberta;University of Alberta;University of Alberta,reinforcement learning;bias and variance reduction,102;102;102;102,136;136;136;136,u;f,canada,ca,y,1;10
3657,ICLR,2020,Editable Neural Networks,Anton Sinitsin;Vsevolod Plokhotnyuk;Dmitry Pyrkin;Sergei Popov;Artem Babenko,ant.sinitsin@gmail.com;vsevolod-pl@yandex.ru;alagaster@yandex.ru;sapopov@yandex-team.ru;artem.babenko@phystech.edu,6;3;8,,Accept (Poster),0,8,0.0,yes,9/25/19,Higher School of Economics;Higher School of Economics;;Yandex;Moscow Institute of Physics and Technology,editing;editable;meta-learning;maml,-1;-1;-1;-1;-1,-1;-1;-1;-1;234,m;m,NAN,NAN,n,3
3658,ICLR,2020,Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness,Tianyu Pang;Kun Xu;Yinpeng Dong;Chao Du;Ning Chen;Jun Zhu,pty17@mails.tsinghua.edu.cn;kunxu.thu@gmail.com;dyp17@mails.tsinghua.edu.cn;duchao0726@gmail.com;ningchen@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,6;6;8;6,,Accept (Poster),0,14,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Trustworthy Machine Learning;Adversarial Robustness;Training Objective;Sample Density,4;-1;4;-1;4;4,23;-1;23;-1;23;23,m;m,NAN,NAN,y,1;4
3659,ICLR,2020,Self-labelling via simultaneous clustering and representation learning,Asano YM.;Rupprecht C.;Vedaldi A.,yuki@robots.ox.ac.uk;chrisr@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk,8;3;8,,Accept (Spotlight),0,5,4.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,self-supervision;feature representation learning;clustering,46;46;46,1;1;1,m;m,europe,uk,n,
3660,ICLR,2020,Semi-Supervised Generative Modeling for Controllable Speech Synthesis,Raza Habib;Soroosh Mariooryad;Matt Shannon;Eric Battenberg;RJ Skerry-Ryan;Daisy Stanton;David Kao;Tom Bagby,raza.habib@cs.ucl.ac.uk;soroosh@google.com;mattshannon@google.com;ebattenberg@google.com;rjryan@google.com;daisy@google.com;davidkao@google.com;tombagby@google.com,6;8;6,,Accept (Poster),0,9,0.0,yes,9/25/19,University College London;Google;Google;Google;Google;Google;Google;Google,TTS;Speech Synthesis;Semi-supervised Models;VAE;disentanglement,52;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
3661,ICLR,2020,EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks,Sanchari Sen;Balaraman Ravindran;Anand Raghunathan,sen9@purdue.edu;ravi@cse.iitm.ac.in;raghunathan@purdue.edu,6;6;1,,Accept (Poster),0,3,0.0,yes,9/25/19,Purdue University;Indian Institute of Technology Madras;Purdue University,ensembles;mixed precision;robustness;adversarial attacks,24;-1;24,88;641;88,f;m,usa,usa,n,4
3662,ICLR,2020,Training Recurrent Neural Networks Online by Learning Explicit State Variables,Somjit Nath;Vincent Liu;Alan Chan;Xin Li;Adam White;Martha White,somjit@ualberta.ca;vliu1@ualberta.ca;achan4@ualberta.ca;xzli@ualberta.ca;amw8@ualberta.ca;whitem@ualberta.ca,6;6;3,,Accept (Poster),0,9,0.0,yes,9/25/19,University of Alberta;University of Alberta;University of Alberta;University of Alberta;University of Alberta;University of Alberta,Recurrent Neural Network;Partial Observability;Online Prediction;Incremental Learning,102;102;102;102;102;102,136;136;136;136;136;136,m;f,canada,ca,y,9
3663,ICLR,2020,MEMO: A Deep Network for Flexible Combination of Episodic Memories,Andrea Banino;Adri√† Puigdom√®nech Badia;Raphael K√∂ster;Martin J. Chadwick;Vinicius Zambaldi;Demis Hassabis;Caswell Barry;Matthew Botvinick;Dharshan Kumaran;Charles Blundell,abanino@google.com;adriap@google.com;rkoster@google.com;mjchadwick@google.com;vzambaldi@google.com;dhteam@google.com;caswell.barry@ucl.ac.uk;botvinick@google.com;dkumaran@google.com;cblundell@google.com,8;6,,Accept (Poster),0,2,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;University College London;Google;Google;Google,Memory Augmented Neural Networks;Deep Learning,-1;-1;-1;-1;-1;-1;52;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3664,ICLR,2020,Differentiable learning of numerical rules in knowledge graphs,Po-Wei Wang;Daria Stepanova;Csaba Domokos;J. Zico Kolter,poweiw@cs.cmu.edu;daria.stepanova@de.bosch.com;csaba.domokos@de.bosch.com;zkolter@cs.cmu.edu,3;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Carnegie Mellon University;Bosch;Bosch;Carnegie Mellon University,knowledge graphs;rule learning;differentiable neural logic,1;-1;-1;1,27;297;297;27,m;m,usa,usa,n,10
3665,ICLR,2020,Multiplicative Interactions and Where to Find Them,Siddhant M. Jayakumar;Wojciech M. Czarnecki;Jacob Menick;Jonathan Schwarz;Jack Rae;Simon Osindero;Yee Whye Teh;Tim Harley;Razvan Pascanu,sidmj@google.com;lejlot@google.com;jmenick@google.com;schwarzjn@google.com;jwrae@google.com;osindero@google.com;ywteh@google.com;tharley@google.com;razp@google.com,8;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google,multiplicative interactions;hypernetworks;attention,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
3666,ICLR,2020,Recurrent neural circuits for contour detection,Drew Linsley*;Junkyung Kim*;Alekh Ashok;Thomas Serre,drew_linsley@brown.edu;junkyung_kim@brown.edu;alekh_karkada_ashok@brown.edu;thomas_serre@brown.edu,6;8;6,,Accept (Poster),0,7,0.0,yes,9/25/19,Brown University;Brown University;Brown University;Brown University,Contextual illusions;visual cortex;recurrent feedback;neural circuits,85;85;85;85,53;53;53;53,m;m,usa,usa,n,2
3667,ICLR,2020,Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks,Wei Hu;Lechao Xiao;Jeffrey Pennington,huwei@cs.princeton.edu;xlc@google.com;jpennin@google.com,6;8;3,,Accept (Poster),0,3,0.0,yes,9/25/19,Princeton University;Google;Google,deep learning theory;non-convex optimization;orthogonal initialization,30;-1;-1,6;-1;-1,m;m,NAN,NAN,y,1
3668,ICLR,2020,Sliced Cramer Synaptic Consolidation for Preserving Deeply Learned Representations,Soheil Kolouri;Nicholas A. Ketz;Andrea Soltoggio;Praveen K. Pilly,skolouri@hrl.com;naketz@hrl.com;a.soltoggio@lboro.ac.uk;pkpilly@hrl.com,8;6,,Accept (Spotlight),0,2,0.0,yes,9/25/19,"HRL Laboratories, LLC;HRL Laboratories, LLC;Loughborough University;HRL Laboratories, LLC",selective plasticity;catastrophic forgetting;intransigence,-1;-1;445;-1,-1;-1;374;-1,m;m,NAN,NAN,n,
3669,ICLR,2020,Neural Outlier Rejection for Self-Supervised Keypoint Learning,Jiexiong Tang;Hanme Kim;Vitor Guizilini;Sudeep Pillai;Rares Ambrus,jiexiong@kth.se;hanme.kim@tri.global;vitor.guizilini@tri.global;sudeep.pillai@tri.global;rares.ambrus@tri.global,6;8;6,,Accept (Poster),0,8,0.0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;Toyota Research Institute;Toyota Research Institute;Toyota Research Institute;Toyota Research Institute",Self-Supervised Learning;Keypoint Detection;Outlier Rejection;Deep Learning,194;-1;-1;-1;-1,222;-1;-1;-1;-1,m;m,NAN,NAN,n,
3670,ICLR,2020,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,Alexei Baevski;Steffen Schneider;Michael Auli,alexei.b@gmail.com;stes@fb.com;michael.auli@gmail.com,8;8;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,Facebook;Facebook;Facebook,speech recognition;speech representation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3
3671,ICLR,2020,A Fair Comparison of Graph Neural Networks for Graph Classification,Federico Errica;Marco Podda;Davide Bacciu;Alessio Micheli,federico.errica@phd.unipi.it;marco.podda@di.unipi.it;bacciu@di.unipi.it;micheli@di.unipi.it,8;6;6,,Accept (Poster),0,12,0.0,yes,9/25/19,University of Pisa;University of Pisa;University of Pisa;University of Pisa,graph neural networks;graph classification;reproducibility;graph representation learning,248;248;248;248,366;366;366;366,m;m,europe,il,n,8;1;10
3672,ICLR,2020,Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models,Xisen Jin;Zhongyu Wei;Junyi Du;Xiangyang Xue;Xiang Ren,xisenjin@usc.edu;zywei@fudan.edu.cn;junyidu@usc.edu;xyxue@fudan.edu.cn;xiangren@usc.edu,6;8;6,,Accept (Spotlight),0,7,0.0,yes,9/25/19,University of Southern California;Fudan University;University of Southern California;Fudan University;University of Southern California,natural language processing;interpretability,36;73;36;73;36,62;109;62;109;62,m;m,usa,usa,n,8;3
3673,ICLR,2020,Understanding Why Neural Networks Generalize Well Through GSNR of Parameters,Jinlong Liu;Yunzhi Bai;Guoqing Jiang;Ting Chen;Huayan Wang,ljlwykqh@126.com;yunzhi.bai@outlook.fr;jianggq@pku.edu.cn;roushi0322@sina.cn;wanghuayan@kuaishou.com,6;6;3,,Accept (Spotlight),0,4,0.0,yes,9/25/19,126;Kuaishou Technology;Peking University;;Kuaishou Technology,DNN;generalization;GSNR;gradient descent,-1;-1;14;-1;-1,-1;-1;24;-1;-1,m;m,NAN,NAN,n,1
3674,ICLR,2020,Intrinsic Motivation for Encouraging Synergistic Behavior,Rohan Chitnis;Shubham Tulsiani;Saurabh Gupta;Abhinav Gupta,ronuchit@mit.edu;shubhtuls@fb.com;saurabhg@illinois.edu;abhinavg@cs.cmu.edu,6;8;6,,Accept (Poster),0,4,0.0,yes,9/25/19,"Massachusetts Institute of Technology;Facebook;University of Illinois, Urbana Champaign;Carnegie Mellon University",reinforcement learning;intrinsic motivation;synergistic;robot manipulation,5;-1;-1;1,5;-1;-1;27,m;m,usa,usa,n,
3675,ICLR,2020,Sharing Knowledge in Multi-Task Deep Reinforcement Learning,Carlo D'Eramo;Davide Tateo;Andrea Bonarini;Marcello Restelli;Jan Peters,carlo@robot-learning.de;davide@robot-learning.de;andrea.bonarini@polimi.it;marcello.restelli@polimi.it;peters@ias.tu-darmstadt.de,6;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,TU Darmstadt;TU Darmstadt;Politecnico di Milano;Politecnico di Milano;TU Darmstadt,Deep Reinforcement Learning;Multi-Task,59;59;143;143;59,-1;-1;-1;-1;-1,m;m,europe,de,y,1
3676,ICLR,2020,Provable Filter Pruning for Efficient Neural Networks,Lucas Liebenwein;Cenk Baykal;Harry Lang;Dan Feldman;Daniela Rus,lucasl@mit.edu;baykal@mit.edu;hlang08@gmail.com;dannyf.post@gmail.com;rus@csail.mit.edu,3;6;3,,Accept (Poster),0,5,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Haifa;Massachusetts Institute of Technology,theory;compression;filter pruning;neural networks,5;5;5;194;5,5;5;5;544;5,m;f,usa,usa,y,
3677,ICLR,2020,Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks,Yuhang Li;Xin Dong;Wei Wang,loafyuhang@gmail.com;xindong@g.harvard.edu;wangwei@comp.nus.edu.sg,6;3;6,,Accept (Poster),0,4,1.0,yes,9/25/19,Yale University;Harvard University;National University of Singapore,Quantization;Efficient Inference;Neural Networks,-1;52;17,-1;7;25,u;m,asia,sg,n,
3678,ICLR,2020,Variational Recurrent Models for Solving Partially Observable Control Tasks,Dongqi Han;Kenji Doya;Jun Tani,dongqi.han@oist.jp;doya@oist.jp;jun.tani@oist.jp,6;8;6,,Accept (Poster),0,6,0.0,yes,9/25/19,Okinawa Institute of Science and Technology (OIST);Okinawa Institute of Science and Technology (OIST);Okinawa Institute of Science and Technology (OIST),Reinforcement Learning;Deep Learning;Variational Inference;Recurrent Neural Network;Partially Observable;Robotic Control;Continuous Control,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3679,ICLR,2020,SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference,Lasse Espeholt;Rapha√´l Marinier;Piotr Stanczyk;Ke Wang;Marcin Michalski‚Äé,lespeholt@google.com;raphaelm@google.com;stanczyk@google.com;kewa@google.com;michalski@google.com,8;6;8,,Accept (Talk),0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google,machine learning;reinforcement learning;scalability;distributed;DeepMind Lab;ALE;Atari-57;Google Research Football,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3680,ICLR,2020,Discriminative Particle Filter Reinforcement Learning for Complex Partial observations,Xiao Ma;Peter Karkus;David Hsu;Wee Sun Lee;Nan Ye,xiao-ma@comp.nus.edu.sg;karkus@comp.nus.edu.sg;dyhsu@comp.nus.edu.sg;leews@comp.nus.edu.sg;nan.ye@uq.edu.au,8;6;8,,Accept (Poster),0,5,0.0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;National University of Singapore;University of Queensland,Reinforcement Learning;Partial Observability;Differentiable Particle Filtering,17;17;17;17;248,25;25;25;25;66,f;m,australasia,au,n,5
3681,ICLR,2020,White Noise Analysis of Neural Networks,Ali Borji;Sikun Lin,aliborji@gmail.com;sikun@ucsb.edu,3;8;6;6,,Accept (Spotlight),0,7,0.0,yes,9/25/19,HCL America;UC Santa Barbara,Classification images;spike triggered analysis;deep learning;network visualization;adversarial attack;adversarial defense;microstimulation;computational neuroscience,-1;-1,-1;-1,m;f,NAN,NAN,n,2;4
3682,ICLR,2020,RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering ,Sam Lobel*;Chunyuan Li*;Jianfeng Gao;Lawrence Carin,samuel_lobel@brown.edu;chunyuan.li@microsoft.com;jfgao@microsoft.com;lcarin@duke.edu,8;6;6,,Accept (Poster),0,3,0.0,yes,9/25/19,Brown University;Microsoft;Microsoft;Duke University,Collaborative Filtering;Recommender Systems;Actor-Critic;Learned Metrics,85;-1;-1;46,53;-1;-1;20,m;m,europe,se,n,
3683,ICLR,2020,Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets,Dongxian Wu;Yisen Wang;Shu-Tao Xia;James Bailey;Xingjun Ma,wu-dx16@mails.tsinghua.edu.cn;eewangyisen@gmail.com;xiast@sz.tsinghua.edu.cn;baileyj@unimelb.edu.au;xingjun.ma@unimelb.edu.au,8;6;6,,Accept (Spotlight),0,4,1.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Peking University;Tsinghua University, Tsinghua University;The University of Melbourne;The University of Melbourne",Adversarial Example;Transferability;Skip Connection;Neural Network,4;14;4;85;85,23;24;23;32;32,m;m,NAN,NAN,n,4
3684,ICLR,2020,The Local Elasticity of Neural Networks,Hangfeng He;Weijie Su,hangfeng@seas.upenn.edu;suw@wharton.upenn.edu,6;6;6,,Accept (Poster),0,6,0.0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania,,20;20,11;11,m;m,usa,usa,n,
3685,ICLR,2020,Deep probabilistic subsampling for task-adaptive compressed sensing,Iris A.M. Huijben;Bastiaan S. Veeling;Ruud J.G. van Sloun,i.a.m.huijben@tue.nl;basveeling@gmail.com;r.j.g.v.sloun@tue.nl,6;6;6,,Accept (Poster),0,8,1.0,yes,9/25/19,Eindhoven University of Technology;Google;Eindhoven University of Technology,,-1;-1;-1,185;-1;185,f;m,NAN,NAN,n,
3686,ICLR,2020,Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning,Hengyuan Hu;Jakob N Foerster,hengyuan@fb.com;jakobfoerster@gmail.com,8;8;8,,Accept (Spotlight),0,9,0.0,yes,9/25/19,Facebook;University of Toronto,multi-agent RL;theory of mind,-1;-1,-1;-1,m;m,asia,in,n,1;4
3687,ICLR,2020,On the Need for Topology-Aware Generative Models for Manifold-Based Defenses,Uyeong Jang;Susmit Jha;Somesh Jha,wjang@cs.wisc.edu;susmit.jha@sri.com;jha@cs.wisc.edu,8;6;3,,Accept (Poster),0,6,0.0,yes,9/25/19,University of Southern California;SRI International;University of Southern California,Manifold-based Defense;Robust Learning;Adversarial Attacks,36;-1;36,62;-1;62,m;m,usa,usa,y,5;4
3688,ICLR,2020,Functional Regularisation for  Continual Learning with Gaussian Processes,Michalis K. Titsias;Jonathan Schwarz;Alexander G. de G. Matthews;Razvan Pascanu;Yee Whye Teh,mtitsias@google.com;schwarzjn@google.com;alexmatthews@google.com;razp@google.com;ywteh@google.com,3;6;6,,Accept (Poster),0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google,Continual Learning;Gaussian Processes;Lifelong learning;Incremental Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11
3689,ICLR,2020,Graph inference learning for semi-supervised classification,Chunyan Xu;Zhen Cui;Xiaobin Hong;Tong Zhang;Jian Yang;Wei Liu,cyx@njust.edu.cn;zhen.cui@njust.edu.cn;xbhong@njust.edu.cn;tong.zhang@njust.edu.cn;csjyang@njust.edu.cn;wl2223@columbia.edu,6;6;6,,Accept (Poster),0,0,0.0,yes,9/25/19,Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Columbia University,semi-supervised classification;graph inference learning,52;52;52;52;52;24,144;144;144;144;144;16,f;m,usa,usa,n,10
3690,ICLR,2020,Input Complexity and Out-of-distribution Detection with Likelihood-based Generative Models,Joan Serr√†;David √Ålvarez;Vicen√ß G√≥mez;Olga Slizovskaia;Jos√© F. N√∫√±ez;Jordi Luque,joansj@gmail.com;davidalvarezdlt@gmail.com;vicen.gomez@upf.edu;oslizovskaia@gmail.com;jfn237@nyu.edu;jordi.luqueserrano@telefonica.com,6;3;3,,Accept (Poster),0,5,0.0,yes,9/25/19,Dolby Laboratories;;Universitat Pompeu Fabra;;New York University;Telefonica Research,OOD;generative models;likelihood,-1;-1;-1;-1;22;-1,-1;-1;-1;-1;29;-1,m;m,NAN,NAN,n,11;5
3691,ICLR,2020,AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty,Dan Hendrycks*;Norman Mu*;Ekin Dogus Cubuk;Barret Zoph;Justin Gilmer;Balaji Lakshminarayanan,hendrycks@berkeley.edu;normanmu@google.com;cubuk@google.com;barretzoph@google.com;gilmer@google.com;balajiln@google.com,8;8;3,,Accept (Poster),0,14,0.0,yes,9/25/19,University of California Berkeley;Google;Google;Google;Google;Google,robustness;uncertainty,-1;-1;-1;-1;-1;-1,13;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3692,ICLR,2020,Learn to Explain Efficiently via Neural Logic Inductive Learning,Yuan Yang;Le Song,yyang754@gatech.edu;lsong@cc.gatech.edu,6;8;3,,Accept (Poster),0,14,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology,inductive logic programming;interpretability;attention,13;13,38;38,m;m,usa,usa,n,
3693,ICLR,2020,Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation,Ziyang Tang*;Yihao Feng*;Lihong Li;Dengyong Zhou;Qiang Liu,ztang@cs.utexas.edu;yihao@cs.utexas.edu;lihongli.cs@gmail.com;dennyzhou@google.com;lqiang@cs.utexas.edu,8;8;6,,Accept (Spotlight),0,10,0.0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin;Amazon;Google;University of Texas, Austin",off-policy evaluation;infinite horizon;doubly robust;reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,y,
3694,ICLR,2020,Towards Stable and Efficient Training of Verifiably Robust Neural Networks,Huan Zhang;Hongge Chen;Chaowei Xiao;Sven Gowal;Robert Stanforth;Bo Li;Duane Boning;Cho-Jui Hsieh,huan@huan-zhang.com;chenhg@mit.edu;xiaocw@umich.edu;sgowal@google.com;stanforth@google.com;lbo@illinois.edu;boning@mtl.mit.edu;chohsieh@cs.ucla.edu,6;3;8,,Accept (Poster),3,7,0.0,yes,9/25/19,"Carnegie Mellon University;Massachusetts Institute of Technology;University of Michigan;Google;Google;University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;University of California, Los Angeles",Robust Neural Networks;Verifiable Training;Certified Adversarial Defense,1;5;7;-1;-1;-1;5;-1,27;5;21;-1;-1;-1;5;17,m;m,usa,usa,n,1;4
3695,ICLR,2020,Adversarial Policies: Attacking Deep Reinforcement Learning,Adam Gleave;Michael Dennis;Cody Wild;Neel Kant;Sergey Levine;Stuart Russell,gleave@berkeley.edu;michael_dennis@berkeley.edu;codywild@berkeley.edu;kantneel@berkeley.edu;svlevine@eecs.berkeley.edu;russell@cs.berkeley.edu,6;6;6,,Accept (Poster),0,8,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,deep RL;adversarial examples;security;multi-agent,-1;-1;-1;-1;-1;-1,13;13;13;13;13;13,m;m,usa,usa,n,4
3696,ICLR,2020,Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation,Nitin Rathi;Gopalakrishnan Srinivasan;Priyadarshini Panda;Kaushik Roy,rathi2@purdue.edu;srinivg@purdue.edu;priya.panda@yale.edu;kaushik@purdue.edu,6;6;6,,Accept (Poster),0,4,0.0,yes,9/25/19,Purdue University;Purdue University;Yale University;Purdue University,spiking neural networks;ann-snn conversion;spike-based backpropagation;imagenet,24;24;73;24,88;88;8;88,m;m,usa,usa,n,
3697,ICLR,2020,Towards Verified Robustness under Text Deletion Interventions,Johannes Welbl;Po-Sen Huang;Robert Stanforth;Sven Gowal;Krishnamurthy (Dj) Dvijotham;Martin Szummer;Pushmeet Kohli,johannes.welbl.14@ucl.ac.uk;posenhuang@google.com;stanforth@google.com;sgowal@google.com;dvij@google.com;szummer@google.com;pushmeet@google.com,8;6;6;3,,Accept (Poster),0,4,0.0,yes,9/25/19,University College London;Google;Google;Google;Google;Google;Google,natural language processing;specification;verification;model undersensitivity;adversarial;interval bound propagation,52;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;8;1
3698,ICLR,2020,N-BEATS: Neural basis expansion analysis for interpretable time series forecasting,Boris N. Oreshkin;Dmitri Carpov;Nicolas Chapados;Yoshua Bengio,boris@elementai.com;dmitri.carpov@elementai.com;chapados@elementai.com;yoshua.bengio@mila.quebec,6;8;6,,Accept (Poster),0,8,0.0,yes,9/25/19,Element AI;Element AI;Element AI;Mila,time series forecasting;deep learning,-1;-1;-1;143,-1;-1;-1;336,m;m,NAN,NAN,n,
3699,ICLR,2020,Improving Adversarial Robustness Requires Revisiting Misclassified Examples,Yisen Wang;Difan Zou;Jinfeng Yi;James Bailey;Xingjun Ma;Quanquan Gu,eewangyisen@gmail.com;knowzou@ucla.edu;jinfengyi.ustc@gmail.com;baileyj@unimelb.edu.au;xingjun.ma@unimelb.edu.au;qgu@cs.ucla.edu,6;6;8,,Accept (Poster),0,5,1.0,yes,9/25/19,"Peking University;University of California, Los Angeles;JD AI Research;The University of Melbourne;The University of Melbourne;University of California, Los Angeles",Robustness;Adversarial Defense;Adversarial Training,14;-1;-1;85;85;-1,24;17;-1;32;32;17,m;m,usa,usa,n,4
3700,ICLR,2020,On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning,Jian Li;Xuanyuan Luo;Mingda Qiao,ljiian83@mail.tsinghua.edu.cn;luo-xy19@mails.tsinghua.edu.cn;mqiao@stanford.edu,6;6;6,,Accept (Poster),1,9,1.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Stanford University",learning theory;generalization;nonconvex learning;stochastic gradient descent;Langevin dynamics,4;4;5,23;23;4,f;m,usa,usa,y,8;11;1
3701,ICLR,2020,SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition,Zhixuan Lin;Yi-Fu Wu;Skand Vishwanath Peri;Weihao Sun;Gautam Singh;Fei Deng;Jindong Jiang;Sungjin Ahn,zxlin@zju.edu.cn;yifu.wu@gmail.com;pvskand@protonmail.com;ws383@scarletmail.rutgers.edu;singh.gautam.iitg@gmail.com;fei.deng@rutgers.edu;jindong.jiang@rutgers.edu;sjn.ahn@gmail.com,6;6;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Zhejiang University;Rutgers University;Oregon State University;Rutgers University;;Rutgers University;Rutgers University;Rutgers University,Generative models;Unsupervised scene representation;Object-oriented representation;spatial attention,39;30;79;30;-1;30;30;30,107;-1;373;-1;-1;-1;-1;-1,m;f,usa,usa,n,8;5
3702,ICLR,2020,Learning from Unlabelled Videos Using Contrastive Predictive Neural 3D Mapping,Adam W. Harley;Shrinidhi K. Lakshmikanth;Fangyu Li;Xian Zhou;Hsiao-Yu Fish Tung;Katerina Fragkiadaki,aharley@cmu.edu;kowshika@cmu.edu;fangyul@cmu.edu;zhouxian@cmu.edu;htung@cs.cmu.edu;katef@cs.cmu.edu,6;6;6;3,,Accept (Poster),0,8,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,3D feature learning;unsupervised learning;inverse graphics;object discovery,1;1;1;1;1;1,27;27;27;27;27;27,m;f,usa,usa,n,2
3703,ICLR,2020,CLN2INV: Learning Loop Invariants with Continuous Logic Networks,Gabriel Ryan;Justin Wong;Jianan Yao;Ronghui Gu;Suman Jana,gabe@cs.columbia.edu;justin.wong@columbia.edu;jy3022@columbia.edu;ronghui.gu@columbia.edu;suman@cs.columbia.edu,3;8,,Accept (Poster),0,6,1.0,yes,9/25/19,Columbia University;Columbia University;Columbia University;Columbia University;Columbia University,loop invariants;deep learning;logic learning,24;24;24;24;24,16;16;16;16;16,m;m,usa,usa,y,
3704,ICLR,2020,"Pay Attention to Features, Transfer Learn Faster CNNs",Kafeng Wang;Xitong Gao;Yiren Zhao;Xingjian Li;Dejing Dou;Cheng-Zhong Xu,kf.wang@siat.ac.cn;xt.gao@siat.ac.cn;yiren.zhao@cl.cam.ac.uk;lixingjian@baidu.com;doudejing@baidu.com;czxu@um.edu.mo,6;6;8,,Accept (Poster),0,3,0.0,yes,9/25/19,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;University of Cambridge;Baidu;Baidu;University of Macau",transfer learning;pruning;faster CNNs,30;30;79;-1;-1;-1,-1;-1;3;-1;-1;307,m;m,europe,de,n,6
3705,ICLR,2020,Sign-OPT: A Query-Efficient Hard-label Adversarial Attack,Minhao Cheng;Simranjit Singh;Patrick H. Chen;Pin-Yu Chen;Sijia Liu;Cho-Jui Hsieh,mhcheng@ucla.edu;simranjit@cs.ucla.edu;patrickchen@ucla.edu;pin-yu.chen@ibm.com;sijia.liu@ibm.com;chohsieh@cs.ucla.edu,6;3,,Accept (Poster),0,2,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;International Business Machines;International Business Machines;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1,17;17;17;-1;-1;17,m;m,usa,usa,y,4
3706,ICLR,2020,GraphQA: Protein Model Quality Assessment using Graph Convolutional Network,Federico Baldassarre;David Men√©ndez Hurtado;Arne Elofsson;Hossein Azizpour,baldassarre.fe@gmail.com;david.menendez.hurtado@scilifelab.se;arne@bioinfo.se;azizpour@kth.se,3;6;3,,Reject,1,6,0.0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;Science for Life Laboratory;;KTH Royal Institute of Technology, Stockholm, Sweden",Protein Quality Assessment;Graph Networks;Representation Learning,194;-1;-1;194,222;-1;-1;222,m;m,NAN,NAN,n,10
3707,ICLR,2020,Compositional Embeddings: Joint Perception and Comparison of Class Label Sets,Zeqian Li;Jacob Whitehill,zli14@wpi.edu;jrwhitehill@wpi.edu,6;6;3,,Reject,0,4,0.0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute,Embedding;One-shot Learning;Compositional Representation,143;143,628;628,m;m,usa,usa,n,2
3708,ICLR,2020,Generating Multi-Sentence Abstractive Summaries of Interleaved Texts,Sanjeev Kumar Karn;Francine Chen;Yan-Ying Chen;Ulli Waltinger;Hinrich Sch√ºtze,skarn@cis.lmu.de;chen@fxpal.com;yanying@fxpal.com;ulli.waltinger@siemens.com;hinrich@hotmail.com,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Institut f√ºr Informatik;FX Palo Alto Laboratory;FX Palo Alto Laboratory;Siemens Corporate Research;Centrum fuer Informations- und Sprachverarbeitung,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,asia,in,n,8
3709,ICLR,2020,Generalizing Reinforcement Learning to Unseen Actions,Ayush Jain*;Andrew Szot*;Jincheng Zhou;Joseph J. Lim,ayushj@usc.edu;szot@usc.edu;jinchenz@usc.edu;limjj@usc.edu,6;6;3,,Reject,0,5,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;University of Southern California,reinforcement learning;unsupervised representation learning;generalization,36;36;36;36,62;62;62;62,m;m,usa,usa,n,6;1
3710,ICLR,2020,Mixture-of-Experts Variational Autoencoder for clustering and generating from similarity-based representations,Andreas Kopf;Vincent Fortuin;Vignesh Ram Somnath;Manfred Claassen,akopf@ethz.ch;fortuin@inf.ethz.ch;vsomnath@student.ethz.ch;mclaassen@ethz.ch,3;6;6,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Variational Autoencoder;Clustering;Generative model,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5
3711,ICLR,2020,On Symmetry and Initialization for Neural Networks,Ido Nachum;Amir Yehudayoff,ido0808@gmail.com;amir.yehudayoff@gmail.com,3;3,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Technion,Neural Network Theory;Symmetry,-1;-1,-1;-1,m;m,asia,in,y,1
3712,ICLR,2020,Training Interpretable Convolutional Neural Networks towards Class-specific Filters,Haoyu Liang;Zhihao Ouyang;Hang Su;Yuyuan Zeng;Zihao He;Shu-tao Xia;Jun Zhu;Bo Zhang,lianghy18@mails.tsinghua.edu.cn;oyzh18@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;zengyy19@mails.tsinghua.edu.cn;zihaoh@usc.edu;xiast@sz.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,6;6;3,,Reject,0,8,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Southern California;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",class-specific filters;interpretability;disentangled representation;filter ambiguity;gate,4;4;4;4;36;4;4;4,23;23;23;23;62;23;23;23,m;m,NAN,NAN,n,8
3713,ICLR,2020,InfoCNF: Efficient Conditional Continuous Normalizing Flow Using Adaptive Solvers,Tan M. Nguyen;Animesh Garg;Richard G. Baraniuk;Anima Anandkumar,mn15@rice.edu;garg@cs.toronto.edu;richb@rice.edu;anima@caltech.edu,3;3;6;1,,Reject,0,10,0.0,yes,9/25/19,Rice University;University of Toronto;Rice University;California Institute of Technology,continuous normalizing flows;conditioning;adaptive solvers;gating networks,92;18;92;143,105;18;105;2,m;f,usa,usa,n,5
3714,ICLR,2020,All SMILES Variational Autoencoder for Molecular Property Prediction and Optimization,Zaccary Alperstein;Artem Cherkasov;Jason Rolfe,zalperst@gmail.com;artc@interchange.ubc.ca;rolfe22@gmail.com,3;6;3,,Reject,2,7,0.0,yes,9/25/19,University of British Columbia;University of British Columbia;D-Wave Systems,generative modelling;variational autoencoder;chemistry;cheminformatics;chemoinformatics;molecular property optimization,-1;64;-1,-1;34;-1,m;m,NAN,NAN,n,8;10;5
3715,ICLR,2020,On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints,Damien Teney;Ehsan Abbasnejad;Anton van den Hengel,damien.teney@adelaide.edu.au;ehsan.abbasnejad@adelaide.edu.au;anton.vandenhengel@adelaide.edu.au,6;3;3,,Reject,0,5,0.0,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,regularizers;vision;language;vqa;visual question answering,102;102;102,120;120;120,m;m,NAN,NAN,n,
3716,ICLR,2020,Learning Latent Representations for Inverse Dynamics using Generalized Experiences,Aditi Mavalankar;Sicun Gao,amavalan@eng.ucsd.edu;sicung@ucsd.edu,3;3;3,,Reject,0,4,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego",deep reinforcement learning;continuous control;inverse dynamics model,-1;-1,31;31,f;m,usa,usa,n,
3717,ICLR,2020,Differentiable Architecture Compression,Shashank Singh;Ashish Khetan;Zohar Karnin,sss1@andrew.cmu.edu;khetan2@illinois.edu;zkarnin@gmail.com,3;6;6,,Reject,0,3,0.0,yes,9/25/19,"Carnegie Mellon University;University of Illinois, Urbana Champaign;Amazon",,1;-1;-1,27;-1;-1,m;m,NAN,NAN,y,1
3718,ICLR,2020,On Stochastic Sign Descent Methods,Mher Safaryan;Peter Richt√°rik,mher.safaryan@gmail.com;peter.richtarik@kaust.edu.sa,6;3;3,,Reject,0,4,0.0,yes,9/25/19,KAUST;KAUST,non-convex optimization;stochastic optimization;gradient compression,102;102,-1;-1,m;m,europe,gr,y,1;9
3719,ICLR,2020,The Generalization-Stability Tradeoff in Neural Network Pruning,Brian R. Bartoldson;Ari S. Morcos;Adrian Barbu;Gordon Erlebacher,bbartoldson@fsu.edu;arimorcos@gmail.com;abarbu@stat.fsu.edu;gerlebacher@fsu.edu,3;1;1,,Reject,0,7,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Facebook;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,pruning;generalization;stability;dynamics;regularization,-1;-1;-1;-1,299;-1;299;299,m;m,NAN,NAN,n,1
3720,ICLR,2020,Evaluations and Methods for Explanation through Robustness Analysis,Cheng-Yu Hsieh;Chih-Kuan Yeh;Xuanqing Liu;Pradeep Ravikumar;Seungyeon Kim;Sanjiv Kumar;Cho-Jui Hsieh,r05922048@ntu.edu.tw;cjyeh@cs.cmu.edu;xqliu@cs.ucla.edu;pradeepr@cs.cmu.edu;seungyeonk@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;3,,Reject,1,6,0.0,yes,9/28/20,"Nanyang Technological University;Carnegie Mellon University;University of California, Los Angeles;Carnegie Mellon University;Google;Google;University of California, Los Angeles",Interpretability;Explanations;Adversarial Robustness,43;1;-1;1;-1;-1;-1,49;27;17;27;-1;-1;17,m;m,usa,usa,n,4
3721,ICLR,2020,Unsupervised Meta-Learning for Reinforcement Learning,Abhishek Gupta;Benjamin Eysenbach;Chelsea Finn;Sergey Levine,abhigupta@berkeley.edu;beysenba@cs.cmu.edu;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,3;1;3,,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;University of California Berkeley;University of California Berkeley,Meta-Learning;Reinforcement Learning,-1;1;-1;-1,13;27;13;13,m;m,usa,usa,y,6
3722,ICLR,2020,A General Upper Bound for Unsupervised Domain Adaptation,Dexuan Zhang;Tatsuya Harada,dexuan.zhang@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,1;3;6,,Reject,0,10,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo,unsupervised domain adaptation;upper bound;joint error;hypothesis space constraint;cross margin discrepancy,64;64,36;36,m;m,NAN,NAN,n,1;4
3723,ICLR,2020,FoveaBox: Beyound Anchor-based Object Detection,Tao Kong;Fuchun Sun;Huaping Liu;Yuning Jiang;Lei Li;Jianbo Shi,taokongcn@gmail.com;fcsun@tsinghua.edu.cn;hpliu@tsinghua.edu.cn;jiangyuning@bytedance.com;lileilab@bytedance.com;jshi@seas.upenn.edu,6;6;3,,Reject,1,4,0.0,yes,9/25/19,"ByteDance;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;ByteDance;ByteDance;University of Pennsylvania",,-1;4;4;-1;-1;20,-1;23;23;-1;-1;11,m;m,usa,usa,n,2;1
3724,ICLR,2020,CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting,Chaoyun Zhang;Marco Fiore;Iain Murray;Paul Patras,chaoyun.zhang@ed.ac.uk;marco.fiore@ieiit.cnr.it;i.murray@ed.ac.uk;paul.patras@ed.ac.uk,8;3;3,,Reject,0,7,0.0,yes,9/25/19,University of Edinburgh;;University of Edinburgh;University of Edinburgh,spatio-temporal forecasting;point cloud stream forecasting;recurrent neural network,36;-1;36;36,30;-1;30;30,m;m,europe,uk,n,8
3725,ICLR,2020,Step Size Optimization,Gyoung S. Na;Dongmin Hyeon;Hwanjo Yu,ngs0726@gmail.com;dmhyeon@postech.ac.kr;hwanjoyu@postech.ac.kr,3;3,,Reject,1,4,0.0,yes,9/25/19,POSTECH;POSTECH;POSTECH,Deep Learning;Step Size Adaptation;Nonconvex Optimization,-1;118;118,-1;146;146,u;m,asia,kr,n,
3726,ICLR,2020,Neural Arithmetic Unit by reusing many small pre-trained networks,Ammar Ahmad;Oneeb Babar;Murtaza Taj,ammarahmad977@gmail.com;oneebalibabar@gmail.com;murtaza.taj@lums.edu.pk,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Boston University;Lahore University of Management Sciences;Lahore University of Management Sciences,NALU;feed forward NN,-1;-1;-1,-1;932;932,u;m,NAN,NAN,n,
3727,ICLR,2020,OvA-INN: Continual Learning with Invertible Neural Networks,HOCQUET Guillaume;BICHLER Olivier;QUERLIOZ Damien,guillaume.hocquet@live.fr;olivier.bichler@cea.fr;damien.querlioz@c2n.upsaclay.fr,6;6;3,,Reject,0,5,0.0,yes,9/25/19,CEA;CEA; University of Paris-Sud,Deep Learning;Continual Learning;Invertible Neural Networks,-1;194;-1,-1;1027;-1,u;u,asia,in,n,
3728,ICLR,2020,Amortized Nesterov's Momentum: Robust and Lightweight  Momentum for Deep Learning,Kaiwen Zhou;Yanghua Jin;Qinghua Ding;James Cheng,kwzhou@cse.cuhk.edu.hk;jinyh@preferred.jp;qhding@cse.cuhk.edu.hk;jcheng@cse.cuhk.edu.hk,3;8;3;1,,Reject,0,9,0.0,yes,9/25/19,"Department of Computer Science and Engineering, The Chinese University of Hong Kong;Preferred Networks, Inc.;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong",momentum;nesterov;optimization;deep learning;neural networks,46;-1;46;46,35;-1;35;35,u;m,NAN,NAN,y,1;9
3729,ICLR,2020,Improving Sample Efficiency in Model-Free Reinforcement Learning from Images,Denis Yarats;Amy Zhang;Ilya Kostrikov;Brandon Amos;Joelle Pineau;Rob Fergus,denisyarats@cs.nyu.edu;amyzhang@fb.com;ik1078@nyu.edu;brandon.amos.cs@gmail.com;jpineau@fb.com;robfergus@fb.com,6;3;6,,Reject,0,2,0.0,yes,9/25/19,New York University;Facebook;New York University;Facebook;Facebook;Facebook,reinforcement learning;model-free;off-policy;image-based reinforcement learning;continuous control,22;-1;22;-1;-1;-1,29;-1;29;-1;-1;-1,m;m,NAN,NAN,n,
3730,ICLR,2020,Curriculum Learning for Deep Generative Models with Clustering,Deli Zhao;Jiapeng Zhu;Zhenfang Guo;Bo Zhang,zhaodeli@gmail.com;jengzhu0@gmail.com;guozhenfang@pku.edu.cn;zhangbo@xiaomi.com,6;1,,Reject,0,3,0.0,yes,9/25/19,Alibaba Group;Hong Kong University of Science and Technology;Peking University;Xiaomi,curriculum learning;generative adversarial network,-1;-1;14;-1,-1;47;24;-1,m;m,NAN,NAN,y,5;4
3731,ICLR,2020,Autoencoder-based Initialization for Recurrent Neural Networks with a Linear Memory,Antonio Carta;Alessandro Sperduti;Davide Bacciu,antonio.carta@di.unipi.it;sperduti@math.unipd.it;bacciu@di.unipi.it,3;1;3,,Reject,0,3,0.0,yes,9/25/19,University of Pisa;Universita' degli studi di Padova;University of Pisa,recurrent neural networks;autoencoders;orthogonal RNNs,248;-1;248,366;-1;366,m;m,europe,il,n,
3732,ICLR,2020,Universal Approximation with Deep Narrow Networks,Patrick Kidger;Terry Lyons,kidger@maths.ox.ac.uk;tlyons@maths.ox.ac.uk,6;8;3,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford,deep learning;universal approximation;deep narrow networks,46;46,1;1,m;m,europe,uk,y,1
3733,ICLR,2020,Probing Emergent Semantics in Predictive Agents via Question Answering,Abhishek Das;Federico Carnevale;Hamza Merzic;Laura Rimell;Rosalia Schneider;Alden Hung;Josh Abramson;Arun Ahuja;Stephen Clark;Greg Wayne;Felix Hill,abhshkdz@gatech.edu;fedecarnev@google.com;hamzamerzic@google.com;laurarimell@google.com;rgschneider@google.com;aldenhung@google.com;jabramson@google.com;arahuja@google.com;clarkstephen@google.com;gregwayne@google.com;felixhill@google.com,3;8;6,,Reject,0,9,0.0,yes,9/25/19,Georgia Institute of Technology;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,question-answering;predictive models,13;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,38;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3734,ICLR,2020,Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically Motivated Exploration,Jingwei Zhang;Niklas Wetzel;Nicolai Dorka;Joschka Boedecker;Wolfram Burgard,zhang@cs.uni-freiburg.de;wetzel@cs.uni-freiburg.de;dorka@informatik.uni-freiburg.de;jboedeck@cs.uni-freiburg.de;burgard@informatik.uni-freiburg.de,3;8;6;3,,Reject,0,8,0.0,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Reinforcement Learning;Exploration;Intrinsic Motivation;Sparse Rewards,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3735,ICLR,2020,Stein Bridging: Enabling Mutual Reinforcement between Explicit and Implicit Generative Models,Qitian Wu;Rui Gao;Hongyuan Zha,echo740@sjtu.edu.cn;rui.gao@mccombs.utexas.edu;zha@cc.gatech.edu,3;1;3,,Reject,0,7,0.0,yes,9/25/19,"Shanghai Jiao Tong University;University of Texas, Austin;Georgia Institute of Technology",generative models;generative adversarial networks;energy models,30;-1;13,157;-1;38,m;m,usa,usa,y,5;4
3736,ICLR,2020,New Loss Functions for Fast Maximum Inner Product Search,Ruiqi Guo;Quan Geng;David Simcha;Felix Chern;Phil Sun;Sanjiv Kumar,guorq@google.com;qgeng@google.com;dsimcha@google.com;fchern@google.com;sunphil@google.com;sanjivk@google.com,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3737,ICLR,2020,End-to-end named entity recognition and relation extraction using pre-trained language models,John Giorgi;Xindi Wang;Nicola Sahar;Won Young Shin;Gary Bader;Bo Wang,john.giorgi@utoronto.ca;xindi.wang@uhnresearch.ca;nicola.sahar@mail.utoronto.ca;wonyoung.shin@mail.utoronto.ca;gary.bader@utoronto.ca;bowang@vectorinstitute.ai,6;3;1,,Reject,1,4,1.0,yes,9/25/19,Toronto University;University Health Network;Toronto University;Toronto University;Toronto University;Vector Institute,named entity recognition;relation extraction;information extraction;information retrival;transfer learning;multi-task learning;BERT;transformers;language models,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,8;3
3738,ICLR,2020,AdaGAN: Adaptive GAN for Many-to-Many Non-Parallel Voice Conversion,Maitreya Patel;Mirali Purohit;Mihir Parmar;Nirmesh J. Shah;Hemant A. Patil,maitreya_patel@daiict.ac.in;purohit_mirali@daiict.ac.in;mihirparmar@asu.edu;nirmesh88_shah@daiict.ac.in;hemant_patil@daiict.ac.in,1;1;6,,Reject,1,3,0.0,yes,9/25/19,"Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar;Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar;SUN YAT-SEN UNIVERSITY;Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar;Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar",Voice Conversion;Deep Learning;Non parallel;GAN;AdaGAN;AdaIN,-1;-1;-1;-1;-1,-1;-1;299;-1;-1,m;m,NAN,NAN,y,6;5;4
3739,ICLR,2020,Goal-Conditioned Video Prediction,Oleh Rybkin;Karl Pertsch;Frederik Ebert;Dinesh Jayaraman;Chelsea Finn;Sergey Levine,oleh@seas.upenn.edu;pertsch@usc.edu;febert@berkeley.edu;dineshjayaraman@berkeley.edu;cbfinn@cs.stanford.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,4,0.0,yes,9/25/19,University of Pennsylvania;University of Southern California;University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,predictive models;video prediction;latent variable models,20;36;-1;-1;5;-1,11;62;13;13;4;13,m;m,usa,usa,n,5
3740,ICLR,2020,wMAN: WEAKLY-SUPERVISED MOMENT ALIGNMENT NETWORK FOR TEXT-BASED VIDEO SEGMENT RETRIEVAL,Reuben Tan;Huijuan Xu;Kate Saenko;Bryan A. Plummer,rxtan@bu.edu;huijuan@berkeley.edu;saenko@bu.edu;bplumme2@illinois.edu,6;6;3;3,,Reject,0,5,0.0,yes,9/25/19,"Boston University;University of California Berkeley;Boston University;University of Illinois, Urbana Champaign",vision;language;video moment retrieval,79;-1;79;-1,61;13;61;-1,m;m,usa,usa,n,8;10
3741,ICLR,2020,Data augmentation instead of explicit regularization,Alex Hernandez-Garcia;Peter K√∂nig,alexhg15@gmail.com;pkoenig@uos.de,3;1;3,,Reject,0,9,0.0,yes,9/25/19,University of Montreal;University of Osnabr√ºck,data augmentation;implicit regularization;explicit regularization;object recognition;convolutional neural networks,-1;316,-1;-1,m;m,europe,de,n,1
3742,ICLR,2020,Implicit Œª-Jeffreys Autoencoders: Taking the Best of Both Worlds,Aibek Alanov;Max Kochurov;Artem Sobolev;Daniil Yashkov;Dmitry Vetrov,alanov.aibek@gmail.com;maxim.v.kochurov@gmail.com;asobolev@bayesgroup.ru;daniil.yashkov@phystech.edu;vetrovd@yandex.ru,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Higher School of Economics;;;Moscow Institute of Physics and Technology;Higher School of Economics,Variational Inference;Generative Adversarial Networks,-1;-1;-1;-1;-1,-1;-1;-1;234;-1,m;m,NAN,NAN,n,5;4
3743,ICLR,2020,LOSSLESS SINGLE IMAGE SUPER RESOLUTION FROM LOW-QUALITY JPG IMAGES,Yong Shi;Biao Li;Bo Wang;Zhiquan Qi;Jiabin Liu;Fan Meng,yshi@unomaha.edu;libiao17@mails.ucas.ac.cn;wangbo@uibe.edu.cn;qizhiquan@foxmail.com;liujiabin008@126.com;mengfan@cufe.edu.cn,3;6;1,,Reject,0,1,0.0,yes,9/25/19,"University of Nebraska, Omaha;Chinese Academy of Sciences;University of Science and Technology of China;University of Science and Technology of China;126;University of Science and Technology of China",Super Resolution;Low-quality JPG;Recovering details,194;30;-1;-1;-1;-1,-1;-1;80;80;-1;80,m;m,NAN,NAN,n,2
3744,ICLR,2020,Improving Batch Normalization with Skewness Reduction for Deep Neural Networks,Pak Lun Kevin Ding;Sarah Martin;Baoxin Li,kevinding@asu.edu;samart44@asu.edu;baoxin.li@asu.edu,3;3;3,,Reject,0,0,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Batch Normalization;Deep Learning,-1;-1;-1,299;299;299,m;m,NAN,NAN,n,
3745,ICLR,2020,Cascade Style Transfer,Zhizhong Wang;Lei Zhao;Qihang Mo;Sihuan Lin;Zhiwen Zuo;Wei Xing;Dongming Lu,endywon@zju.edu.cn;cszhl@zju.edu.cn;moqihang@zju.edu.cn;linsh@zju.edu.cn;zzwcs@zju.edu.cn;wxing@zju.edu.cn;ldm@zju.edu.cn,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,style transfer;cascade;quality;flexibility;domain-independent;serial;parallel,39;39;39;39;39;39;39,107;107;107;107;107;107;107,u;u,asia,cn,n,
3746,ICLR,2020,Recurrent Hierarchical Topic-Guided Neural Language Models,Dandan Guo;Bo Chen;Ruiying Lu;Mingyuan Zhou,gdd_xidian@126.com;bchen@mail.xidian.edu.cn;ruiyinglu_xidian@163.com;mingyuan.zhou@mccombs.utexas.edu,1;1;8;8;8,,Reject,0,8,4.0,yes,9/25/19,"126;Xidian University;Xidian University;University of Texas, Austin",Bayesian deep learning;recurrent gamma belief net;larger-context language model;variational inference;sentence generation;paragraph generation,-1;-1;-1;-1,-1;919;919;-1,u;m,usa,usa,n,3
3747,ICLR,2020,The Frechet Distance of training and test distribution predicts the generalization gap,Julian Zilly;Hannes Zilly;Oliver Richter;Roger Wattenhofer;Andrea Censi;Emilio Frazzoli,jzilly@ethz.ch;hzilly@ethz.ch;richtero@ethz.ch;wattenhofer@ethz.ch;acensi@ethz.ch;emilio.frazzoli@idsc.mavt.ethz.ch,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Generalization;Transfer learning;Frechet distance;Optimal transport;Domain adaptation;Distribution shift;Invariance,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;1
3748,ICLR,2020,Objective Mismatch in Model-based Reinforcement Learning,Nathan Lambert;Brandon Amos;Omry Yadan;Roberto Calandra,nol@berkeley.edu;brandon.amos.cs@gmail.com;omry@fb.com;rcalandra@fb.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;Facebook;Facebook;Facebook,Model-based Reinforcement learning;dynamics model;reinforcement learning,-1;-1;-1;-1,13;-1;-1;-1,m;m,NAN,NAN,n,
3749,ICLR,2020,Learning Explainable Models Using Attribution Priors,Gabriel Erion;Joseph D. Janizek;Pascal Sturmfels;Scott M. Lundberg;Su-In Lee,erion@cs.washington.edu;jjanizek@cs.washington.edu;psturm@cs.washington.edu;slund1@cs.washington.edu;suinlee@cs.washington.edu,8;3;1,,Reject,0,6,0.0,yes,9/25/19,University of Washington;University of Washington;University of Washington;University of Washington;University of Washington,Deep Learning;Interpretability;Attributions;Explanations;Biology;Health;Computational Biology,11;11;11;11;11,26;26;26;26;26,m;f,usa,usa,n,1
3750,ICLR,2020,Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models,Anand Ramakrishnan;Warren B. Jackson;Kent Evans,aramakrishnan@wpi.edu;jackson@parc.com;kent.evans@parc.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Worcester Polytechnic Institute;Palo Alto Research Center (Xerox PARC);Palo Alto Research Center (Xerox PARC),Composition;extrapolation;boosting;autocorrelation;systematic errors,143;-1;-1,628;-1;-1,m;m,NAN,NAN,n,
3751,ICLR,2020,Semi-supervised 3D Face Reconstruction with Nonlinear Disentangled Representations,Zhongpai Gao;Juyong Zhang;Yudong Guo;Chao Ma;Guangtao Zhai;Xiaokang Yang,gaozhongpai@sjtu.edu.cn;juyong@ustc.edu.cn;gyd2011@mail.ustc.edu.cn;chaoma@sjtu.edu.cn;zhaiguangtao@sjtu.edu.cn;xkyang@sjtu.edu.cn,3;1;3,,Reject,0,0,0.0,yes,9/25/19,Shanghai Jiao Tong University;University of Science and Technology of China;University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,3D face reconstruction;semi-supervised learning;disentangled representation;inverse rendering;graph convolutional networks,30;-1;-1;30;30;30,157;80;80;157;157;157,m;m,asia,cn,n,7;4
3752,ICLR,2020,Efficient Exploration via State Marginal Matching,Lisa Lee;Benjain Eysenbach;Emilio Parisotto;Erix Xing;Sergey Levine;Ruslan Salakhutdinov,lslee@cs.cmu.edu;beysenba@cs.cmu.edu;eparisot@cs.cmu.edu;epxing@cs.cmu.edu;svlevine@eecs.berkeley.edu;rsalakhu@cs.cmu.edu,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;University of California Berkeley;Carnegie Mellon University,reinforcement learning;exploration;distribution matching;robotics,1;1;1;1;-1;1,27;27;27;27;13;27,f;m,usa,usa,y,
3753,ICLR,2020,Adversarial Filters of Dataset Biases,Ronan Le Bras;Swabha Swayamdipta;Chandra Bhagavatula;Rowan Zellers;Matthew Peters;Ashish Sabharwal;Yejin Choi,ronanlb@allenai.org;swabhas@allenai.org;chandrab@allenai.org;rowanz@cs.washington.edu;matthewp@allenai.org;ashishs@allenai.org;yejinc@allenai.org,6;6;6,,Reject,0,4,1.0,yes,9/25/19,Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;University of Washington;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence,,-1;-1;-1;11;-1;-1;-1,-1;-1;-1;26;-1;-1;-1,m;f,NAN,NAN,n,3;4
3754,ICLR,2020,Insights on Visual Representations for Embodied Navigation Tasks,Erik Wijmans;Julian Straub;Irfan Essa;Dhruv Batra;Judy Hoffman;Ari Morcos,etw@gatech.edu;julian.straub@oculus.com;irfan@gatech.edu;dbatra@gatech.edu;judy@gatech.edu;arimorcos@gmail.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Georgia Institute of Technology;Oculus;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Facebook,,13;-1;13;13;13;-1,38;-1;38;38;38;-1,m;m,NAN,NAN,n,
3755,ICLR,2020,Crafting Data-free Universal Adversaries with Dilate Loss,Deepak Babu Sam;ABINAYA K;Sudharsan K A;Venkatesh Babu RADHAKRISHNAN,deepaksam@iisc.ac.in;abinayak@iisc.ac.in;sudharsanka16@gmail.com;venky@iisc.ac.in,8;3;6;3,,Reject,0,4,0.0,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;;Indian Institute of Science,,-1;-1;-1;-1,301;301;-1;301,m;u,NAN,NAN,y,4
3756,ICLR,2020,Stochastic Gradient Descent with Biased but Consistent Gradient Estimators,Jie Chen;Ronny Luss,chenjie@us.ibm.com;rluss@us.ibm.com,6;1;3;3,,Reject,0,15,0.0,yes,9/25/19,International Business Machines;International Business Machines,Stochastic optimization;biased gradient estimator;graph convolutional networks,-1;-1,-1;-1,m;m,NAN,NAN,y,1;10
3757,ICLR,2020,Wasserstein Robust Reinforcement Learning,Mohammed Amin Abdullah;Hang Ren;Haitham Bou-Ammar;Vladimir Milenkovic;Rui Luo;Mingtian Zhang;Jun Wang,mohammed.abdullah@huawei.com;hang.ren1@huawei.com;haitham.ammar@huawei.com;vladimir.milenkovic@huawei.com;ruiluo@huawei.com;w.j@huawei.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Reinforcement Learning;Robustness;Wasserstein distance,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3758,ICLR,2020,A Training Scheme for the Uncertain Neuromorphic Computing Chips,Qingtian Zhang;Bin Gao;Huaqiang Wu,zhangqt0103@mail.tsinghua.edu.cn;gaob1@tsinghua.edu.cn;wuhq@tsinghua.edu.cn,1;6;1,,Reject,0,2,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",deep learning;neuromorphic computing;uncertainty;training,4;4;4,23;23;23,u;m,NAN,NAN,n,
3759,ICLR,2020,A Stochastic Trust Region Method for Non-convex Minimization,Zebang Shen;Pan Zhou;Cong Fang;Jiahao Xie;Alejandro Ribeiro,shenzebang@zju.edu.cn;pzhou@u.nus.edu;fangcong@pku.edu.cn;xiejh@zju.edu.cn;aribeiro@seas.upenn.edu,3;6;8;3,,Reject,0,7,0.0,yes,9/25/19,Zhejiang University;National University of Singapore;Peking University;Zhejiang University;University of Pennsylvania,,39;17;14;39;20,107;25;24;107;11,m;m,usa,usa,y,1;9
3760,ICLR,2020,MoET: Interpretable and Verifiable Reinforcement Learning via Mixture of Expert Trees,Marko Vasic;Andrija Petrovic;Kaiyuan Wang;Mladen Nikolic;Rishabh Singh;Sarfraz Khurshid,vasic@utexas.edu;aapetrovic@mas.bg.ac.rs;kaiyuanw@google.com;nikolic@matf.bg.ac.rs;rising@google.com;khurshid@ece.utexas.edu,3;6;6,,Reject,0,7,0.0,yes,9/25/19,"University of Texas, Austin;University of Belgrade - Faculty of Organizational Sciences;Google;University of Belgrade - Faculty of Organizational Sciences;Google;University of Texas, Austin",explainable machine learning;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,usa,usa,n,1
3761,ICLR,2020,Deceptive Opponent Modeling with Proactive Network Interdiction for Stochastic Goal Recognition Control,Junren Luo;Wei Gao;Zhiyong Liao;Weilin Yuan;Wanpeng Zhang;Shaofei Chen,luojunren17@nudt.edu.cn;gaowei14@nudt.edu.cn,1;1;1,,Reject,0,0,0.0,yes,9/25/19,National University of Defense Technology;National University of Defense Technology,,-1;-1,-1;-1,m;m,NAN,NAN,n,
3762,ICLR,2020,Regularization Matters in Policy Optimization,Zhuang Liu;Xuanlin Li;Bingyi Kang;Trevor Darrell,zhuangl@berkeley.edu;xuanlinli17@berkeley.edu;kang@u.nus.edu;trevor@eecs.berkeley.edu,3;3;6,,Reject,0,12,1.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;National University of Singapore;University of California Berkeley,Regularization;Policy Optimization;Reinforcement Learning,-1;-1;17;-1,13;13;25;13,m;m,usa,usa,n,8
3763,ICLR,2020,Sentence embedding with contrastive multi-views learning,Antoine Simoulin,antoine.simoulin@gmail.com,1;1;3,,Reject,0,0,0.0,yes,9/25/19,0,contrastive;multi-views;linguistic;embedding,,,m;u,NAN,NAN,n,
3764,ICLR,2020,Robust Domain Randomization for Reinforcement Learning,Reda Bahi Slaoui;William R. Clements;Jakob N. Foerster;S√©bastien Toth,reda.bahi.slaoui@gmail.com;william.clements@unchartech.com;jakobfoerster@gmail.com;sebastien.toth@unchartech.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Ecole Normale Superieure;Uncharted Technologies;;Uncharted Technologies,reinforcement learning;domain randomization;domain adaptation,-1;-1;-1;-1,-1;-1;-1;-1,m;u,NAN,NAN,y,1
3765,ICLR,2020,Regularizing Trajectories to Mitigate Catastrophic Forgetting,Paul Michel;Elisabeth Salesky;Graham Neubig,pmichel1@cs.cmu.edu;esalesky@gmail.com;gneubig@cs.cmu.edu,6;1;3,,Reject,0,6,0.0,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University,Continual Learning;Regularization;Adaptation;Natural Gradient,1;-1;1,27;-1;27,m;m,usa,usa,n,
3766,ICLR,2020,Coloring graph neural networks for node disambiguation,George Dasoulas;Ludovic Dos Santos;Kevin Scaman;Aladin Virmaux,george.dasoulas1@gmail.com;kevin.scaman@gmail.com;ludovic.dos.santos@huawei.com;aladin.virmaux@huawei.com,6;1;3,,Reject,0,5,0.0,yes,9/25/19,Ecole polytechnique;INRIA;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Graph neural networks;separability;node disambiguation;universal approximation;representation learning,-1;-1;-1;-1,93;-1;-1;-1,m;m,NAN,NAN,y,10
3767,ICLR,2020,Undersensitivity in Neural Reading Comprehension,Johannes Welbl;Pasquale Minervini;Max Bartolo;Pontus Stenetorp;Sebastian Riedel,johannes.welbl.14@ucl.ac.uk;p.minervini@gmail.com;maxbartolo@gmail.com;pontus.stenetorp@gmail.com;s.riedel@ucl.ac.uk,6;3;6,,Reject,0,3,0.0,yes,9/25/19,University College London;University College London;University College London;University College London;University College London,reading comprehension;undersensitivity;adversarial questions;adversarial training;robustness;biased data setting,52;52;52;52;52,-1;-1;-1;-1;-1,m;m,europe,uk,n,4
3768,ICLR,2020,RotationOut as a Regularization Method for Neural Network,Kai Hu;Barnabas Poczos,kaihu@cmu.edu;bapoczos@cs.cmu.edu,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Neural Network;Regularization,1;1,27;27,m;m,usa,usa,y,
3769,ICLR,2020,Meta-Learning with Network Pruning for Overfitting Reduction,Hongduan Tian;Bo Liu;Xiao-Tong Yuan;Qingshan Liu,hongduan_tian@nuist.edu.cn;kfliubo@gmail.com;xtyuan1980@gmail.com;qsliu@nuist.edu.cn,3;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Science and Technology of China;Rutgers University;University of Science and Technology of China;University of Science and Technology of China,Meta-Learning;Few-shot Learning;Network Pruning;Generalization Analysis,-1;30;-1;-1,80;-1;80;80,m;m,NAN,NAN,y,6;1
3770,ICLR,2020,An implicit function learning approach for parametric modal regression,Yangchen Pan;Martha White;Amir-massoud Farahmand,pan6@ualberta.ca;whitem@ualberta.ca;farahmand@vectorinstitute.ai,1;3;6,,Reject,0,3,0.0,yes,9/25/19,University of Alberta;University of Alberta;Vector Institute,regression;modal regression;implicit function theorem;multivalue function,102;102;-1,136;136;-1,u;m,NAN,NAN,y,1
3771,ICLR,2020,On the Evaluation of Conditional GANs,Terrance DeVries;Adriana Romero;Luis Pineda;Graham W. Taylor;Michal Drozdzal,terrance@uoguelph.ca;adrianars@fb.com;lep@fb.com;gwtaylor@uoguelph.ca;mdrozdzal@fb.com,3;1;3,,Reject,0,5,0.0,yes,9/25/19,University of Guelph;Facebook;Facebook;University of Guelph;Facebook,FJD;Frechet Joint Distance;GAN;cGAN;generative adversarial network;conditional;evaluation;metric;FID;Frechet Inception Distance,248;-1;-1;248;-1,558;-1;-1;558;-1,m;m,NAN,NAN,n,1;5;4
3772,ICLR,2020,CZ-GEM:  A  FRAMEWORK  FOR DISENTANGLED REPRESENTATION LEARNING,Akash Srivastava;Yamini Bansal;Yukun Ding;Bernhard Egger;Prasanna Sattigeri;Josh Tenenbaum;David D. Cox;Dan Gutfreund,akash.srivastava@me.com;ybansal@g.harvard.edu;yding5@nd.edu;egger@mit.edu;psattig@us.ibm.com;jbt@mit.edu;david.d.cox@ibm.com;dgutfre@us.ibm.com,1;1;3,,Reject,0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Harvard University;University of Notre Dame;Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology;International Business Machines;International Business Machines,disentangled representation learning;gan;generative model;simulator,5;52;118;5;-1;5;-1;-1,5;7;157;5;-1;5;-1;-1,m;m,NAN,NAN,n,5
3773,ICLR,2020,On Weight-Sharing and Bilevel Optimization in Architecture Search,Mikhail Khodak;Liam Li;Maria-Florina Balcan;Ameet Talwalkar,khodak@cmu.edu;me@liamcli.com;ninamf@cs.cmu.edu;talwalkar@cmu.edu,3;3,,Reject,0,2,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,neural architecture search;weight-sharing;bilevel optimization;non-convex optimization;hyperparameter optimization;model selection,1;1;1;1,27;27;27;27,m;m,usa,usa,y,3;1
3774,ICLR,2020,Are there any 'object detectors' in the hidden layers of CNNs trained to identify objects or scenes?,Ella M. Gale;Nicholas Martin;Ryan Blything;Anh Nguyen;Jeffrey S. Bowers,ella.gale@bristol.ac.uk;nm13850@bristol.ac.uk;ryan.blything@bristol.ac.uk;anhnguyen@auburn.edu;j.bowers@bristol.ac.uk,3;3;8,,Reject,0,3,0.0,yes,9/25/19,University of Bristol;University of Bristol;University of Bristol;Auburn University;University of Bristol,neural networks;localist coding;selectivity;object detectors;CCMAS;CNNs;activation maximisation;information representation;network dissection;interpretabillity;signal detection,118;118;118;445;118,87;87;87;651;87,f;m,europe,uk,n,
3775,ICLR,2020,Dimensional Reweighting Graph Convolution Networks,Xu Zou;Qiuye Jia;Jianwei Zhang;Chang Zhou;Zijun Yao;Hongxia Yang;Jie Tang,zoux18@mails.tsinghua.edu.cn;jqy@stanford.edu;zhangjianwei.zjw@alibaba-inc.com;ericzhou.zc@alibaba-inc.com;yaozijun@bupt.edu.cn;yang.yhx@alibaba-inc.com;jietang@tsinghua.edu.cn,3;6;3,,Reject,0,7,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Stanford University;Alibaba Group;Alibaba Group;Beijing University of Post and Telecommunication;Alibaba Group;Tsinghua University, Tsinghua University",graph convolutional networks;representation learning;mean field theory;variance reduction;node classification,4;5;-1;-1;-1;-1;4,23;4;-1;-1;-1;-1;23,m;m,NAN,NAN,y,1;10
3776,ICLR,2020,Leveraging inductive bias of neural networks for learning without explicit human annotations,Fatih Furkan Yilmaz;Reinhard Heckel,fy11@rice.edu;rh43@rice.edu,6;3,,Reject,0,2,0.0,yes,9/25/19,Rice University;Rice University,dataset construction;deep learning;candidate examples,92;92,105;105,m;m,australasia,au,n,4
3777,ICLR,2020,XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and Question Answering,Jasdeep Singh;Bryan McCann;Nitish Shirish Keskar;Caiming Xiong;Richard Socher,jasdeep@cs.stanford.edu;bmccann@salesforce.com;nkeskar@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,1;8;3,,Reject,0,0,0.0,yes,9/25/19,Stanford University;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,cross-lingual;transfer learning;BERT,5;-1;-1;-1;-1,4;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
3778,ICLR,2020,Ergodic Inference: Accelerate Convergence by Optimisation,Yichuan Zhang;Jos√© Miguel Hern√°ndez-Lobato,yichuan.zhang@eng.cam.ac.uk;jmh233@cam.ac.uk,3;8;3,,Reject,0,3,2.0,yes,9/25/19,University of Cambridge;University of Cambridge,MCMC;variational inference;statistical inference,79;79,3;3,m;m,europe,uk,n,
3779,ICLR,2020,Synthetic vs Real: Deep Learning on Controlled Noise,Lu Jiang;Di Huang;Weilong Yang,lujiang@google.com;dihuang@google.com;weilongyang@google.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google,controlled experiments;robust deep learning;corrupted label;real-world noisy data,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3780,ICLR,2020,Layerwise Learning Rates for Object Features in Unsupervised and Supervised Neural Networks And Consequent Predictions for the Infant Visual System,Rhodri Cusack;Cliona O'Doherty;Anna Birbeck;Anna Truzzi,cusackrh@tcd.ie;odoherc1@tcd.ie;birbecka@tcd.ie;truzzia@tcd.ie,3;3;3,,Reject,0,5,0.0,yes,9/25/19,"Trinity College, Dublin;Trinity College, Dublin;Trinity College, Dublin;Trinity College, Dublin",deep learning;unsupervised;supervised;infant learning;age of acquisition;DeepCluster;CORnet;AlexNet,-1;-1;-1;-1,164;164;164;164,m;f,NAN,NAN,n,
3781,ICLR,2020,Non-Sequential Melody Generation,Mitchell Billard;Robert Bishop;Moustafa Elsisy;Laura Graves;Antonina Kolokolova;Vineel Nagisetty;Zachary Northcott;Heather Patey,mlb238@mun.ca;r.bishop@mun.ca;mmatelsisy@mun.ca;cmgraves@mun.ca;kol@mun.ca;vnagisetty@mun.ca;zmnorthcott@mun.ca;hpatey@gmail.com,1;3;1,,Reject,0,3,0.0,yes,9/25/19,Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;,melody generation;DCGAN;dilated convolutions,445;445;445;445;445;445;445;-1,557;557;557;557;557;557;557;-1,m;u,asia,in,n,5;4
3782,ICLR,2020,A Dynamic Approach to Accelerate Deep Learning Training,John Osorio;Adri√† Armejach;Eric Petit;Marc Casas,john.osorio@bsc.es;adria.armejach@bsc.es;eric.petit@intel.com;marc.casas@bsc.es,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Barcelona Supercomputing Center;Barcelona Supercomputing Center;Intel;Barcelona Supercomputing Center,reduced precision;bfloat16;CNN;DNN;dynamic precision;mixed precision,445;445;-1;445,-1;-1;-1;-1,u;u,NAN,NAN,n,
3783,ICLR,2020,Emergence of Compositional Language with Deep Generational Transmission,Michael Cogswell;Jiasen Lu;Stefan Lee;Devi Parikh;Dhruv Batra,cogswell@gatech.edu;jiasenlu@gatech.edu;steflee@gatech.edu;parikh@gatech.edu;dbatra@gatech.edu,6;1;6,,Reject,0,6,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Cultural Evolution;Deep Learning;Language Emergence,13;13;13;13;13,38;38;38;38;38,m;m,usa,usa,n,1
3784,ICLR,2020,AutoGrow: Automatic Layer Growing in Deep Convolutional Networks,Wei Wen;Feng Yan;Hai Li,wei.wen@duke.edu;fyan@unr.edu;hai.li@duke.edu,3;3;3,,Reject,0,3,1.0,yes,9/25/19,"Duke University;University of Nevada, Reno;Duke University",Growing;depth;neural networks;automation,46;248;46,20;-1;20,m;f,europe,se,n,
3785,ICLR,2020,Model-Agnostic Feature Selection with Additional Mutual Information,Mukund Sudarshan;Aahlad Manas Puli;Lakshmi Subramanian;Sriram Sankararaman;Rajesh Ranganath,ms7490@nyu.edu;apm470@nyu.edu;lakshmi@cs.nyu.edu;sriram@cs.ucla.edu;rajeshr@cims.nyu.edu,6;3;3,,Reject,0,5,0.0,yes,9/25/19,"New York University;New York University;New York University;University of California, Los Angeles;New York University",feature selection;interpretability;randomization;fdr control;p-values,22;22;22;-1;22,29;29;29;17;29,m;m,usa,usa,y,
3786,ICLR,2020,Certifying Neural Network Audio Classifiers,Wonryong Ryou;Mislav Balunovic;Gagandeep Singh;Martin Vechev,wryou@student.ethz.ch;bmislav@student.ethz.ch;gsingh@inf.ethz.ch;martin.vechev@inf.ethz.ch,6;1;3,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Adversarial Examples;Audio Classifier;Speech Recognition;Certified Robustness;Deep Learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,
3787,ICLR,2020,Wasserstein-Bounded Generative Adversarial Networks,Peng Zhou;Bingbing Ni;Lingxi Xie;Xiaopeng Zhang;Hang Wang;Cong Geng;Qi Tian,zhoupengcv@sjtu.edu.cn;nibingbing@sjtu.edu.cn;198808xc@gmail.com;zxphistory@gmail.com;wang--hang@sjtu.edu.cn;gengcong@sjtu.edu.cn;tian.qi1@huawei.com,1;3;6,,Reject,0,0,0.0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;;;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Huawei Technologies Ltd.,GAN;WGAN;GENERATIVE ADVERSARIAL NETWORKS,30;30;-1;-1;30;30;-1,157;157;-1;-1;157;157;-1,m;m,NAN,NAN,y,1;5;4
3788,ICLR,2020,An Explicitly Relational Neural Network Architecture,Murray Shanahan;Kyriacos Nikiforou;Antonia Creswell;Christos Kaplanis;David Barrett;Marta Garnelo,mshanahan@google.com;knikiforou@google.com;tonicreswell@google.com;christos.kaplanis14@imperial.ac.uk;barrettdavid@google.com;garnelo@google.com,6;6;6,,Reject,0,4,1.0,yes,9/25/19,Google;Google;Google;Imperial College London;Google;Google,relational representation,-1;-1;-1;52;-1;-1,-1;-1;-1;10;-1;-1,m;f,NAN,NAN,n,
3789,ICLR,2020,Do Deep Neural Networks for Segmentation Understand Insideness?,Kimberly M Villalobos;Vilim Stih;Amineh Ahmadinejad;Jamell Dozier;Andrew Francl;Frederico Azevedo;Tomotake Sasaki;Xavier Boix,kimvc@mit.edu;vilim@neuro.mpg.de;amineh@mit.edu;jamell@mit.edu;francl@mit.edu;fazevedo@mit.edu;tomotake.sasaki@fujitsu.com;xboix@mit.edu,6;6;3,,Reject,0,7,1.0,yes,9/25/19,Massachusetts Institute of Technology;Max-Planck Institute;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Fujitsu Laboratories Ltd.;Massachusetts Institute of Technology,Image Segmentation;Deep Networks for Spatial Relationships;Visual Routines;Recurrent Neural Networks,5;-1;5;5;5;5;-1;5,5;-1;5;5;5;5;-1;5,f;m,usa,usa,y,2
3790,ICLR,2020,Split LBI for Deep Learning: Structural Sparsity via Differential Inclusion Paths,Yanwei Fu;Chen Liu;Donghao Li;Xinwei Sun;Jinshan ZENG;Yuan Yao,yanweifu@fudan.edu.cn;corwinliu9669@gmail.com;donghao.li@connect.ust.hk;xinsun@microsoft.com;jsh.zeng@gmail.com;yuany@ust.hk,3;8;6,,Reject,0,7,0.0,yes,9/25/19,Fudan University;;The Hong Kong University of Science and Technology;Microsoft;Australian National University;The Hong Kong University of Science and Technology,,73;-1;-1;-1;102;-1,109;-1;47;-1;50;47,m;m,NAN,NAN,y,1;9
3791,ICLR,2020,Contextual Text Style Transfer,Yu Cheng;Zhe Gan;Yizhe Zhang;Oussama Elachqar;Dianqi Li;Jingjing Liu,yu.cheng@microsoft.com;zhe.gan@microsoft.com;yizhe.zhang@microsoft.com;ouelachq@microsoft.com;dianqili@uw.edu;jingjl@microsoft.com,3;3;6,,Reject,0,0,0.0,yes,9/25/19,"Microsoft;Microsoft;Microsoft;Microsoft;University of Washington, Seattle;Microsoft",,-1;-1;-1;-1;11;-1,-1;-1;-1;-1;26;-1,m;f,NAN,NAN,n,
3792,ICLR,2020,FLAT MANIFOLD VAES,Nutan Chen;Alexej Klushyn;Francesco Ferroni;Justin Bayer;Patrick van der Smagt,nutan.chen@gmail.com;a.klushyn@gmail.com;francescoferroni1@gmail.com;bayer.justin@googlemail.com;smagt@argmax.ai,1;6;6,,Reject,0,11,0.0,yes,9/25/19,"Machine Learning Research Lab, Volkswagen Group;Technical University Munich;Argo AI;Machine Learning Research Lab, Volkswagen Group;Volkswagen Group, Machine Learning Research Lab (MLRL)",,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3793,ICLR,2020,An Information Theoretic Approach to Distributed Representation Learning,Abdellatif Zaidi;Inaki Estella Aguerri,abdellatif.zaidi@u-pem.fr;inaki.estella@huawei.com,3;3;8;6,,Reject,0,0,0.0,yes,9/25/19,Universit√© Paris-Est;Huawei Technologies Ltd.,Information Bottleneck;Distributed Learning,-1;-1,-1;-1,m;m,NAN,NAN,y,1
3794,ICLR,2020,LIA: Latently Invertible Autoencoder with Adversarial Learning,Jiapeng Zhu;Deli Zhao;Bolei Zhou;Bo Zhang,jengzhu0@gmail.com;zhaodeli@gmail.com;bzhou@ie.cuhk.edu.hk;zhangbo@xiaomi.com,3;3;3;3,,Reject,0,5,0.0,yes,9/25/19,Hong Kong University of Science and Technology;Alibaba Group;The Chinese University of Hong Kong;Xiaomi,variational autoencoder;generative adversarial network,-1;-1;316;-1,47;-1;35;-1,m;m,NAN,NAN,n,2;5;4
3795,ICLR,2020,Connecting the Dots Between MLE and RL for Sequence Prediction,Bowen Tan;Zhiting Hu;Zichao Yang;Ruslan Salakhutdinov;Eric Xing,bwkevintan@gmail.com;zhitinghu@gmail.com;yangtze2301@gmail.com;rsalakhu@cs.cmu.edu;epxing@cs.cmu.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,"Carnegie Mellon University;University of California, San Diego;;Carnegie Mellon University;Carnegie Mellon University",Sequence generation;sequence prediction;reinforcement learning,-1;-1;-1;1;1,-1;31;-1;27;27,m;m,usa,usa,n,3
3796,ICLR,2020,BEYOND SUPERVISED LEARNING: RECOGNIZING UNSEEN ATTRIBUTE-OBJECT PAIRS WITH VISION-LANGUAGE FUSION AND ATTRACTOR NETWORKS,Hui Chen;Zhixiong Nan;Nanning Zheng,chenhui0622@stu.xjtu.edu.cn;nanzhixiong@stu.xjtu.edu.cn;nnzheng@mail.xjtu.edu.cn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,image understanding,-1;-1;-1,555;555;555,m;m,NAN,NAN,n,5
3797,ICLR,2020,Distance-based Composable Representations with Neural Networks,Graham Spinks;Marie-Francine Moens,graham.spinks@cs.kuleuven.be;sien.moens@cs.kuleuven.be,3;3;6,,Reject,0,4,0.0,yes,9/25/19,KU Leuven;KU Leuven,Representation learning;Wasserstein distance;Composability;Templates,143;143,45;45,m;m,europe,be,n,
3798,ICLR,2020,Efficient Deep Representation Learning by Adaptive Latent Space Sampling,Yuanhan Mo;Shuo Wang;Chengliang Dai;Rui Zhou;Zhongzhao Teng;Wenjia Bai;Yike Guo,y.mo16@imperial.ac.uk;shuo.wang@imperial.ac.uk;c.dai@imperial.ac.uk;rui.zhou18@imperial.ac.uk;zt215@cam.ac.uk;w.bai@imperial.ac.uk;y.guo@imperial.ac.uk,8;3;6,,Reject,0,4,0.0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London;University of Cambridge;Imperial College London;Imperial College London,Deep learning;Data efficiency,52;52;52;52;79;52;52,10;10;10;10;3;10;10,m;m,europe,uk,n,2;5
3799,ICLR,2020,Out-of-Distribution Detection Using Layerwise Uncertainty in Deep Neural Networks,Hirono Okamoto;Masahiro Suzuki;Yutaka Matsuo,h-okamoto@weblab.t.u-tokyo.ac.jp;masa@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,3;1;1,,Reject,0,6,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo,out-of-distribution;uncertainty,64;64;64,36;36;36,m;m,NAN,NAN,n,
3800,ICLR,2020,Effect of top-down connections in Hierarchical Sparse Coding,Victor Boutin;Angelo Franciosini;Franck Ruffier;Laurent Perrinet,victor.boutin@univ-amu.fr;angelo.franciosini@univ-amu.fr;franck.ruffier@univ-amu.fr;laurent.perrinet@univ-amu.fr,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Aix Marseille Univ;Aix Marseille Univ;Aix Marseille Univ;Aix Marseille Univ,Hierarchical Sparse Coding;Convolutional Sparse Coding;Top-down connections,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n,1
3801,ICLR,2020,Multitask Soft Option Learning,Maximilian Igl;Andrew Gambardella;Jinke He;Nantas Nardelli;N. Siddharth;Wendelin B√∂hmer;Shimon Whiteson,maximilian.igl@gmail.com;gambs@robots.ox.ac.uk;jinkehe1996@gmail.com;nantas@robots.ox.ac.uk;nsid@robots.ox.ac.uk;wendelin.boehmer@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk,8;3,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Hierarchical Reinforcement Learning;Reinforcement Learning;Control as Inference;Options;Multitask Learning,-1;46;-1;46;46;46;46,-1;1;-1;1;1;1;1,m;m,europe,uk,n,
3802,ICLR,2020,Compositional Transfer in Hierarchical Reinforcement Learning,Markus Wulfmeier;Abbas Abdolmaleki;Roland Hafner;Jost Tobias Springenberg;Michael Neunert;Tim Hertweck;Thomas Lampe;Noah Siegel;Nicolas Heess;Martin Riedmiller,mwulfmeier@google.com;aabdolmaleki@google.com;rhafner@google.com;springenberg@google.com;neunertm@google.com;thertweck@google.com;thomaslampe@google.com;heess@google.com;riedmiller@google.com,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google,Multitask;Transfer Learning;Reinforcement Learning;Hierarchical Reinforcement Learning;Compositional;Off-Policy,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3803,ICLR,2020,Federated User Representation Learning,Duc Bui;Kshitiz Malik;Jack Goetz;Seungwhan Moon;Honglei Liu;Anuj Kumar;Kang G. Shin,ducbui@umich.edu;kmalik2@fb.com;jrgoetz@umich.edu;shanemoon@fb.com;honglei@fb.com;anujk@fb.com;kgshin@umich.edu,8;3;1,,Reject,0,3,0.0,yes,9/25/19,University of Michigan;Facebook;University of Michigan;Facebook;Facebook;Facebook;University of Michigan,Machine Learning;Federated Learning;Personalization;User Representation,7;-1;7;-1;-1;-1;7,21;-1;21;-1;-1;-1;21,m;m,usa,usa,n,
3804,ICLR,2020,Fairness with Wasserstein Adversarial Networks,serrurier Mathieu;Loubes Jean-Michel;Edouard Pauwels,mathieu.serrurier@irit.fr;loubes@math.univ-toulouse.fr;edouard.pauwels@irit.fr,1;1;1,,Reject,0,0,0.0,yes,9/25/19,"IRIT, CNRS;Universit√© de Toulouse;IRIT, CNRS",,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,7;5;4
3805,ICLR,2020,Quantum Expectation-Maximization for Gaussian Mixture Models,Iordanis Kerenidis;Anupam Prakash;Alessandro Luongo,jkeren@gmail.com;anupamprakash1@gmail.com;aluongo@irif.fr,3;3;1,,Reject,0,7,0.0,yes,9/25/19,Universit√© Paris Diderot;;Universite Paris Diderot,Quantum;ExpectationMaximization;Unsupervised;QRAM,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,5
3806,ICLR,2020,Deep Evidential Uncertainty,Alexander Amini;Wilko Schwarting;Ava Soleimany;Daniela Rus,amini@mit.edu;wilkos@mit.edu;asolei@mit.edu;rus@csail.mit.edu,6;6;3,,Reject,0,12,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Evidential deep learning;Uncertainty estimation;Epistemic uncertainty,5;5;5;5,5;5;5;5,m;f,usa,usa,n,2;4
3807,ICLR,2020,Variational Information Bottleneck for Unsupervised Clustering: Deep Gaussian Mixture Embedding,Yigit Ugur;George Arvanitakis;Abdellatif Zaidi,ygtugur@gmail.com;george.arvanitakis@huawei.com;abdellatif.zaidi@u-pem.fr,3;3;3,,Reject,1,0,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Universit√© Paris-Est,clustering;Variational Information Bottleneck;Gaussian Mixture Model,-1;-1;-1,-1;-1;-1,u;m,NAN,NAN,y,1;5
3808,ICLR,2020,Multi-scale Attributed Node Embedding,Benedek Rozemberczki;Carl Allen;Rik Sarkar,benedek.rozemberczki@gmail.com;carl.allen@ed.ac.uk;rsarkar@inf.ed.ac.uk,6;6;3,,Reject,0,5,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh,network embedding;graph embedding;node embedding;network science;graph representation learning,36;36;36,30;30;30,m;m,europe,uk,y,1
3809,ICLR,2020,Model Inversion Networks for Model-Based Optimization,Aviral Kumar;Sergey Levine,aviralkumar2907@gmail.com;svlevine@eecs.berkeley.edu,6;3;1,,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley,data-driven optimization;model-based optimization,-1;-1,13;13,m;m,usa,usa,y,
3810,ICLR,2020,Variational Autoencoders with Normalizing Flow Decoders,Rogan Morrow;Wei-Chen Chiu,rogan.o.morrow@gmail.com;walon@cs.nctu.edu.tw,3;3;6,,Reject,0,4,0.0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,,118;118,564;564,u;m,asia,tw,n,5
3811,ICLR,2020,Adversarial Attacks on Copyright Detection Systems,Parsa Saadatpanah;Ali Shafahi;Tom Goldstein,parsa@cs.umd.edu;ashafahi@cs.umd.edu;tomg@cs.umd.edu,3;3;3;6,,Reject,0,5,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",,12;12;12,91;91;91,m;m,usa,usa,n,1;4
3812,ICLR,2020,MODiR: Multi-Objective Dimensionality Reduction for Joint Data Visualisation,Tim Repke;Ralf Krestel,tim.repke@hpi.uni-potsdam.de;ralf.krestel@hpi.de,1;3,,Reject,0,0,0.0,yes,9/25/19,University of Potsdam;Hasso Plattner Institute,dimensionality reduction;visualisation;text visualisation;network drawing,445;143,272;-1,u;m,europe,de,n,3;10
3813,ICLR,2020,Actor-Critic Approach for Temporal Predictive Clustering,Changhee Lee;Mihaela van der Schaar,chl8856@gmail.com;mihaela@ee.ucla.edu,3;3;6,,Reject,0,4,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",Temporal Clustering;Predictive Clustering;Actor-Critic,-1;-1,-1;17,m;f,usa,usa,n,
3814,ICLR,2020,NeuroFabric: Identifying Ideal Topologies for Training A Priori Sparse Networks,Mihailo Isakov;Michel A. Kinsy,mihailo@bu.edu;mkinsy@bu.edu,3;3;3;3,,Reject,0,5,0.0,yes,9/25/19,Boston University;Boston University,Sparsity;model compression;training;topology,79;79,61;61,m;m,europe,it,y,
3815,ICLR,2020,Chart Auto-Encoders for Manifold Structured  Data,Stephan Schonsheck;Jie Chen;Rongjie Lai,schons@rpi.edu;chenjie@us.ibm.com;lair@rpi.edu,6;3;3,,Reject,0,7,0.0,yes,9/25/19,Rensselaer Polytechnic Institute;International Business Machines;Rensselaer Polytechnic Institute,Auto-encoder;differential manifolds;multi-charted latent space,248;-1;248,438;-1;438,m;m,usa,usa,n,5
3816,ICLR,2020,Putting Machine Translation in Context with the Noisy Channel Model,Lei Yu;Laurent Sartran;Wojciech Stokowiec;Wang Ling;Lingpeng Kong;Phil Blunsom;Chris Dyer,leiyu@google.com;lsartran@google.com;wstokowiec@google.com;lingwang@google.com;lingpenk@google.com;pblunsom@google.com;cdyer@google.com,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,machine translation;context-aware machine translation;bayes rule,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,8;3
3817,ICLR,2020,Optimizing Data Usage via Differentiable Rewards,Xinyi Wang;Hieu Pham;Paul Michel;Antonios Anastasopoulos;Graham Neubig;Jaime Carbonell,xinyiw1@cs.cmu.edu;hyhieu@cmu.edu;pmichel1@cs.cmu.edu;aanastas@andrew.cmu.edu;gneubig@cs.cmu.edu;jgc@cs.cmu.edu,3;6;6,,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,data selection;multilingual neural machine translation;data usage optimzation;transfer learning;classification,1;1;1;1;1;1,27;27;27;27;27;27,f;m,usa,usa,n,8;3
3818,ICLR,2020,Representing Model Uncertainty of Neural Networks in Sparse Information Form,Jongseok Lee;Rudolph Triebel,jongseok.lee@dlr.de;rudolph.triebel@dlr.de,3;1;3;6,,Reject,0,9,0.0,yes,9/25/19,German Aerospace Center (DLR);German Aerospace Center (DLR),Model Uncertainty;Neural Networks;Sparse representation,-1;-1,-1;-1,m;m,NAN,NAN,y,11
3819,ICLR,2020,Unsupervised Learning of Efficient and Robust Speech Representations,Kazuya Kawakami;Luyu Wang;Chris Dyer;Phil Blunsom;Aaron van den Oord,kawakamik@google.com;luyuwang@google.com;cdyer@google.com;pblunsom@google.com;avdnoord@google.com,6;6;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3820,ICLR,2020,A Kolmogorov Complexity Approach to Generalization in Deep Learning,Hazar Yueksel;Kush R. Varshney;Brian Kingsbury,hazar.yueksel@ibm.com;krvarshn@us.ibm.com;bedk@us.ibm.com,1;8;3;3,,Reject,0,9,0.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines,Kolmogorov complexity;information distance;generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;4
3821,ICLR,2020,Learning Invariants through Soft Unification,Nuri Cingillioglu;Alessandra Russo,nuri.cingillioglu13@imperial.ac.uk;a.russo@imperial.ac.uk,1;3;3,,Reject,0,3,0.0,yes,9/25/19,Imperial College London;Imperial College London,representation learning;neural networks;unification,52;52,10;10,m;f,europe,uk,n,
3822,ICLR,2020,Collapsed amortized variational inference for switching nonlinear dynamical systems,Zhe Dong;Bryan A. Seybold;Kevin P. Murphy;Hung H. Bui,zhedong@google.com;baseybold@gmail.com;kpmurphy@google.com;bui.h.hung@gmail.com,8;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
3823,ICLR,2020,ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring  for Minimax Problems and GANs,Ernest K. Ryu;Kun Yuan;Wotao Yin,eryu@math.ucla.edu;kunyuan@ucla.edu;wotaoyin@math.ucla.edu,1;6;6,,Reject,0,4,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",GAN;minimax problems;stochastic gradients,-1;-1;-1,17;17;17,m;m,usa,usa,y,1;5;4
3824,ICLR,2020,Event Discovery for History Representation in Reinforcement Learning,Aleksandr Ermolov;Enver Sangineto;Nicu Sebe,aleksandr.ermolov@unitn.it;enver.sangineto@unitn.it;niculae.sebe@unitn.it,3;6;1,,Reject,0,25,0.0,yes,9/25/19,University of Trento;University of Trento;University of Trento,reinforcement learning;self-supervision;POMDP,143;143;143,307;307;307,m;m,europe,gr,n,
3825,ICLR,2020,Learning to Rank Learning Curves,Martin Wistuba;Tejaswini Pedapati,martin.wistuba@ibm.com;tejaswinip@us.ibm.com,6;3;6,,Reject,0,5,0.0,yes,9/25/19,International Business Machines;International Business Machines,,-1;-1,-1;-1,m;f,NAN,NAN,n,6
3826,ICLR,2020,Scoring-Aggregating-Planning: Learning task-agnostic priors from interactions and sparse rewards for zero-shot generalization,Huazhe Xu;Boyuan Chen;Yang Gao;Trevor Darrell,huazhe_xu@eecs.berkeley.edu;boyuanchen@berkeley.edu;yg@eecs.berkeley.edu;trevordarrell@eecs.berkeley.edu,3;6;6,,Reject,0,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,learning priors from exploration data;policy zero-shot generalization;reward shaping;model-based,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n,6
3827,ICLR,2020,Topic Models with Survival Supervision: Archetypal Analysis and Neural Approaches,George H. Chen;Linhong Li;Ren Zuo;Amanda Coston;Jeremy C. Weiss,georgechen@cmu.edu;linhongl@andrew.cmu.edu;renzuo.wren@gmail.com;acoston@cs.cmu.edu;jeremyweiss@cmu.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;;Carnegie Mellon University;Carnegie Mellon University,,1;1;-1;1;1,27;27;-1;27;27,m;m,usa,usa,n,
3828,ICLR,2020,Way Off-Policy Batch Deep Reinforcement Learning of Human Preferences in Dialog,Natasha Jaques;Asma Ghandeharioun;Judy Hanwen Shen;Craig Ferguson;Agata Lapedriza;Noah Jones;Shixiang Gu;Rosalind Picard,jaquesn@mit.edu;asma_gh@mit.edu;judyshen@mit.edu;fergusoc@mit.edu;agata@mit.edu;ncjones@mit.edu;shanegu@google.com;picard@media.mit.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,batch reinforcement learning;deep learning;dialog;off-policy;human preferences,5;5;5;5;5;5;-1;5,5;5;5;5;5;5;-1;5,f;f,usa,usa,n,1
3829,ICLR,2020,Well-Read Students Learn Better: On the Importance of Pre-training Compact Models,Iulia Turc;Ming-Wei Chang;Kenton Lee;Kristina Toutanova,iuliaturc@google.com;mingweichang@google.com;kentonl@google.com;kristout@google.com,1;6;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google,NLP;self-supervised learning;language model pre-training;knowledge distillation;BERT;compact models,-1;-1;-1;-1,-1;-1;-1;-1,f;f,NAN,NAN,n,3
3830,ICLR,2020,Model Imitation for Model-Based Reinforcement Learning,Yueh-Hua Wu;Ting-Han Fan;Peter J. Ramadge;Hao Su,kriswu8021@gmail.com;tinghanf@princeton.edu;ramadge@princeton.edu;haosu@eng.ucsd.edu,6;6;6,,Reject,0,5,0.0,yes,9/25/19,"National Taiwan University;Princeton University;Princeton University;University of California, San Diego",Model-Based Reinforcement Learning,-1;30;30;-1,-1;6;6;31,m;m,usa,usa,y,
3831,ICLR,2020,Black Box Recursive Translations for Molecular Optimization,Farhan Damani;Vishnu Sresht;Stephen Ra,farhand7@gmail.com;vishnu.sresht@pfizer.com;stephen.ra@pfizer.com,6;3;3;6,,Reject,0,9,0.0,yes,9/25/19,Princeton University;Pfizer R&D;Pfizer R&D,molecules;chemistry;drug design;generative models;application;translation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
3832,ICLR,2020,Improving the Generalization of Visual Navigation Policies using Invariance Regularization,Michel Aractingi;Christopher Dance;Julien Perez;Tomi Silander,michel.aractingi@naverlabs.com;christopher.dance@naverlabs.com;julien.perez@naverlabs.com;tomi.silander@naverlabs.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Naver Labs Europe;Naver Labs Europe;Naver Labs Europe;Naver Labs Europe,Generalization;Deep Reinforcement Learning;Invariant Representation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
3833,ICLR,2020,PatchFormer: A neural architecture for self-supervised representation learning on images,Aravind Srinivas;Pieter Abbeel,aravind@cs.berkeley.edu;pabbeel@cs.berkeley.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley,Unsupervised Learning;Representation Learning;Transformers,-1;-1,13;13,m;m,usa,usa,n,5
3834,ICLR,2020,Learning from Positive and Unlabeled Data  with Adversarial Training,Wenpeng Hu;Ran Le;Bing Liu;Feng Ji;Haiqing Chen;Dongyan Zhao;Jinwen Ma;Rui Yan,wenpeng.hu@pku.edu.cn;leran.pku@gmail.com;dcsliub@pku.edu.cn;zhongxiu.jf@alibaba-inc.com;zhaody@pku.edu.cn;jinwen.ma@pku.edu.cn;rui.yan@pku.edu.cn,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Peking University;;Peking University;Alibaba Group;Peking University;Peking University;Peking University,Positive and Unlabeled learning,14;-1;14;-1;14;14;14,24;-1;24;-1;24;24;24,m;m,asia,cn,y,5;4
3835,ICLR,2020,PNAT: Non-autoregressive Transformer by Position Learning,Yu Bao;Hao Zhou;Jiangtao Feng;Mingxuan Wang;Shujian Huang;Jiajun Chen;Lei Li,baoy@smail.nju.edu.cn;zhouhao.nlp@bytedance.com;fengjiangtao@bytedance.com;wangmingxuan.89@bytedance.com;huangsj@nju.edu.cn;chenjj@nju.edu.cn;lilei.02@bytedance.com,3;3;6,,Reject,2,9,0.0,yes,9/25/19,Zhejiang University;ByteDance;ByteDance;ByteDance;Zhejiang University;Zhejiang University;ByteDance,Text Generation,39;-1;-1;-1;39;39;-1,107;-1;-1;-1;107;107;-1,m;m,NAN,NAN,n,3
3836,ICLR,2020,Learning Boolean Circuits with Neural Networks,Eran Malach;Shai Shalev-Shwartz,eran.malach@mail.huji.ac.il;shais@cs.huji.ac.il,6;3;6,,Reject,0,4,0.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,neural-networks;deep learning theory,85;85,216;216,u;m,europe,il,y,
3837,ICLR,2020,Stagnant zone segmentation with U-net,Selam Waktola;Laurent Babout;Krzysztof Grudzien,selam.waktola@gmail.com,1;1;1,,Reject,0,1,0.0,yes,9/25/19,0,,,,m;m,NAN,NAN,n,2
3838,ICLR,2020,Model-based Saliency for the Detection of Adversarial Examples,Lisa Schut;Yarin Gal,lisaschut94@gmail.com;yarin.gal@cs.ox.ac.uk,6;1;3,,Reject,0,6,0.0,yes,9/25/19,University of Oxford;University of Oxford,Adversarial Examples;Defense;Model-based Saliency,46;46,1;1,f;m,europe,uk,n,4
3839,ICLR,2020,Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation,Mengyu Chu;You Xie;Jonas Mayer;Laura Leal-Taix√©;Nils Th√ºrey,mengyu.chu@tum.de;you.xie@tum.de;jonas.a.mayer@tum.de;leal.taixe@tum.de;nils.thuerey@tum.de,3;8;6;3,,Reject,0,9,0.0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich,adversarial training;generative models;unpaired video translation;video super-resolution;temporal coherence;self-supervision;cycle-consistency,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,5;4
3840,ICLR,2020,R-TRANSFORMER: RECURRENT NEURAL NETWORK ENHANCED TRANSFORMER,Zhiwei Wang;Yao Ma;Zitao Liu;Jiliang Tang,wangzh65@msu.edu;mayao4@msu.edu;liuzitao@100tal.com;tangjili@msu.edu,3;3;6,,Reject,0,0,0.0,yes,9/25/19,Michigan State University;Michigan State University;TAL Education Group;Michigan State University,Sequence Modeling;Multi-head Attention;RNNs,102;102;-1;102,84;84;-1;84,m;m,usa,usa,n,8
3841,ICLR,2020,A closer look at network resolution for efficient network design,Taojiannan Yang;Sijie Zhu;Yan Shen;Mi Zhang;Andrew Willis;Chen Chen,tyang30@uncc.edu;szhu3@uncc.edu;yanshen6@msu.edu;mizhang@msu.edu;arwillis@uncc.edu;chen.chen@uncc.edu,3;6;3,,Reject,0,10,0.0,yes,9/25/19,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;Michigan State University;Michigan State University;University of North Carolina, Charlotte;University of North Carolina, Charlotte",deep learning;computer vision;efficient network design;dynamic neural networks,64;64;102;102;64;64,-1;-1;84;84;-1;-1,m;m,NAN,NAN,n,6;2
3842,ICLR,2020,Learning in Confusion: Batch Active Learning with Noisy Oracle,Gaurav Gupta;Anit Kumar Sahu;Wan-Yi Lin,ggaurav@usc.edu;anit.sahu@gmail.com;wan-yi.lin@us.bosch.com,1;1;6,,Reject,0,4,0.0,yes,9/25/19,University of Southern California;Amazon;Bosch,Active Learning;Noisy Oracle;Model Uncertainty;Image classification,36;-1;-1,62;-1;297,m;f,NAN,NAN,n,
3843,ICLR,2020,On Predictive Information Sub-optimality of RNNs,Zhe Dong;Deniz Oktay;Ben Poole;Alexander A. Alemi,zhedong@google.com;doktay@princeton.edu;pooleb@google.com;alemi@google.com,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Google;Princeton University;Google;Google,,-1;30;-1;-1,-1;6;-1;-1,m;m,NAN,NAN,y,
3844,ICLR,2020,Match prediction from group comparison data using neural networks,Sunghyun Kim;Minje jang;Changho Suh,koishkim@gmail.com;jmj427@lunit.io;chsuh@kaist.ac.kr,3;1;6;6,,Reject,0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Lunit Inc.;Korea Advanced Institute of Science and Technology,Neural networks;Group comparison;Match prediction;Rank aggregation,-1;-1;-1,-1;-1;110,m;m,NAN,NAN,n,
3845,ICLR,2020,Feature Partitioning for Efficient Multi-Task Architectures,Alejandro Newell;Lu Jiang;Chong Wang;Li-Jia Li;Jia Deng,anewell@cs.princeton.edu;lujiang@google.com;chong.wang@bytedance.com;lijiali@cs.stanford.edu;jiadeng@princeton.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Princeton University;Google;ByteDance;Stanford University;Princeton University,multi-task learning;neural architecture search;multi-task architecture search,30;-1;-1;5;30,6;-1;-1;4;6,m;m,usa,usa,n,
3846,ICLR,2020,Learnable Group Transform For Time-Series,Romain Cosentino;Behnaam Aazhang,rc57@rice.edu;aaz@rice.edu,8;3;3,,Reject,0,9,0.0,yes,9/25/19,Rice University;Rice University,Group Transform;Time-Frequency Representation;Wavelet Transform;Group Theory;Representation Theory;Time-Series,92;92,105;105,u;m,australasia,au,y,
3847,ICLR,2020,SesameBERT: Attention for Anywhere,Ta-Chun Su;Hsiang-Chih Cheng,gene11117@gmail.com;musicmilif@gmail.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,National Taiwan University;Stanford University,Natural Language Processing;Deep Learning;Self Attention,-1;-1,-1;-1,m;m,asia,in,n,8;1
3848,ICLR,2020,Towards A Unified Min-Max Framework for Adversarial Exploration and Robustness,Jingkang Wang;Tianyun Zhang;Sijia Liu;Pin-Yu Chen;Jiacen Xu;Makan Fardad;Bo Li,wangjksjtu@gmail.com;tzhan120@syr.edu;sijia.liu@ibm.com;pin-yu.chen@ibm.com;coldstudy@sjtu.edu.cn;makan@syr.edu;lxbosky@gmail.com,3;8;3,,Reject,0,8,0.0,yes,9/25/19,University of Toronto;Syracuse University;International Business Machines;International Business Machines;Shanghai Jiao Tong University;Syracuse University;University of California Berkeley,Ensemble attack;adversarial training;diversity promotion,18;194;-1;-1;30;194;-1,18;292;-1;-1;157;292;13,m;f,usa,usa,y,1;4
3849,ICLR,2020,Towards Scalable Imitation Learning for Multi-Agent Systems with Graph Neural Networks,Siyu Zhou;Chaitanya Rajasekhar;Mariano J. Phielipp;Heni Ben Amor,siyu.zhou.ac@gmail.com;crajase1@asu.edu;mariano.j.phielipp@intel.com;hbenamor@asu.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Arizona State University;SUN YAT-SEN UNIVERSITY;Intel;SUN YAT-SEN UNIVERSITY,Graph Neural Networks;Scalability;Swarms;Imitation,-1;-1;-1;-1,-1;299;-1;299,m;m,NAN,NAN,n,6;10
3850,ICLR,2020,Dual-module Inference for Efficient Recurrent Neural Networks,Liu Liu;Lei Deng;Shuangchen Li;Jingwei Zhang;Yihua Yang;Zhenyu Gu;Yufei Ding;Yuan Xie,liu_liu@ucsb.edu;leideng@ucsb.edu;shuangchen.li@alibaba-inc.com;jingwei.zhang@alibaba-inc.com;yihua.yang@alibaba-inc.com;zhenyu.gu@alibaba-inc.com;yufeiding@cs.ucsb.edu;yuanxie@ece.ucsb.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,UC Santa Barbara;UC Santa Barbara;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;UC Santa Barbara;UC Santa Barbara,memory-efficient RNNs;dynamic execution;computation skipping,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
3851,ICLR,2020,On Federated Learning of Deep Networks from Non-IID Data: Parameter Divergence and the Effects of Hyperparametric Methods,Heejae Kim;Taewoo Kim;Chan-Hyun Youn,kim881019@kaist.ac.kr;taewoo_kim@kaist.ac.kr;chyoun@kaist.ac.kr,3;3;1,,Reject,1,15,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Federated learning;Iterative parameter averaging;Deep networks;Decentralized non-IID data;Hyperparameter optimization methods,-1;-1;-1,110;110;110,m;m,NAN,NAN,y,
3852,ICLR,2020,DeepXML: Scalable & Accurate Deep Extreme Classification for Matching User Queries to Advertiser Bid Phrases,Kunal Dahiya;Anshul Mittal;Deepak Saini;Kushal Dave;Himanshu Jain;Sumeet Agarwal;Manik Varma,kunalsdahiya@gmail.com;anshulmittal71@gmail.com;desaini@microsoft.com;kudave@microsoft.com;himanshu.j689@gmail.com;sumeet@iitd.ac.in;manik@microsoft.com,6;3;6,,Reject,0,5,0.0,yes,9/25/19,Indian Institute of Technology Delhi;Indian Institute of Technology Delhi;Microsoft;Microsoft;;Indian Institute of Technology Delhi;Microsoft,extreme multi label learning;extreme classification;deep extreme multi label learning;deep extreme classification;large output space,-1;-1;-1;-1;-1;-1;-1,441;441;-1;-1;-1;441;-1,m;m,NAN,NAN,n,8;3
3853,ICLR,2020,Few-Shot Regression via Learning Sparsifying Basis Functions,Yi Loo;Yiluan Guo;Ngai-Man Cheung,loo_yi@sutd.edu.sg;guoyl1990@outlook.com;ngaiman_cheung@sutd.edu.sg,3;3;3,,Reject,1,3,0.0,yes,9/25/19,Singapore University of Technology and Design;;Singapore University of Technology and Design,meta-learning;few-shot learning;regression;learning basis functions;self-attention,-1;-1;-1,-1;-1;-1,u;m,NAN,NAN,n,6
3854,ICLR,2020,Address2vec: Generating vector embeddings for blockchain analytics,Ali Hussein;Samiiha Nalwooga,ali.hussein@ronininstitute.org;nsamiiha@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Ronin Institute;Stockholm University,crypto-currency;bitcoin;blockchain;2vec,-1;-1,-1;-1,m;f,asia,in,n,10
3855,ICLR,2020,Energy-Aware Neural Architecture Optimization with Fast Splitting Steepest Descent,Dilin Wang;Meng Li;Lemeng Wu;Vikas Chandra;Qiang Liu,dilin@cs.utexas.edu;meng.li@fb.com;lmwu@cs.utexas.edu;vchandra@fb.com;lqiang@cs.utexas.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,"University of Texas, Austin;Facebook;University of Texas, Austin;Facebook;University of Texas, Austin",Neural architecture optimization;splitting steepest descent,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n,
3856,ICLR,2020,Equilibrium Propagation with Continual Weight Updates,Maxence Ernoult;Julie Grollier;Damien Querlioz;Yoshua Bengio;Benjamin Scellier,maxence.ernoult@u-psud.fr;julie.grollier@cnrs-thales.fr;damien.querlioz@u-psud.fr;yoshua.bengio@mila.quebec;benjamin.scellier@umontreal.ca,3;3;8,,Reject,0,5,0.0,yes,9/25/19,UPSud/INRIA University Paris-Saclay;;UPSud/INRIA University Paris-Saclay;Mila;University of Montreal,Biologically Plausible Neural Networks;Equilibrium Propagation,-1;-1;-1;143;118,-1;-1;-1;336;85,m;m,canada,ca,y,1
3857,ICLR,2020,IsoNN: Isomorphic Neural Network for Graph Representation Learning and Classification,Lin Meng;Jiawei Zhang,lin@ifmlab.org;jiawei@ifmlab.org,6;3;1,,Reject,1,4,0.0,yes,9/25/19,Florida State University;SUN YAT-SEN UNIVERSITY,Deep Learning;Graph Neural Network,-1;-1,-1;299,u;u,NAN,NAN,y,2;3;10
3858,ICLR,2020,LDMGAN: Reducing Mode Collapse in GANs with Latent Distribution Matching,Zhiwen Zuo;Lei Zhao;Huiming Zhang;Qihang Mo;Haibo Chen;Zhizhong Wang;AiLin Li;Lihong Qiu;Wei Xing;Dongming Lu,zzwcs@zju.edu.cn;cszhl@zju.edh.cn;qinglanwuji@zju.edu.cn;moqihang@zju.edu.cn;feng123@zju.edu.cn;endywon@zju.edu.cn;11921050@zju.edu.cn;zjusheldon@zju.edu.cn;wxing@zju.edu.cn;ldm@zju.edu.cn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,Zhejiang University;;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,Deep Learning;Unsupervised Learning;Generative Adversarial Networks;Mode Collapse;AutoEncoder,39;-1;39;39;39;39;39;39;39;39,107;-1;107;107;107;107;107;107;107;107,m;m,asia,cn,n,5;4
3859,ICLR,2020,Reinforcement Learning with Chromatic Networks,Xingyou Song;Krzysztof Choromanski;Jack Parker-Holder;Yunhao Tang;Wenbo Gao;Aldo Pacchiano;Tamas Sarlos;Deepali Jain;Yuxiang Yang,xingyousong@google.com;kchoro@google.com;jh3764@columbia.edu;yt2541@columbia.edu;wg2279@columbia.edu;pacchiano@berkeley.edu;stamas@google.com;jaindeepali@google.com;yxyang@google.com,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Google;Google;Columbia University;Columbia University;Columbia University;University of California Berkeley;Google;Google;Google,reinforcement;learning;chromatic;networks;partitioning;efficient;neural;architecture;search;weight;sharing;compactification,-1;-1;24;24;24;-1;-1;-1;-1,-1;-1;16;16;16;13;-1;-1;-1,m;m,NAN,NAN,n,1
3860,ICLR,2020,Generalized Natural Language Grounded Navigation via Environment-agnostic Multitask Learning,Xin Wang;Vihan Jain;Eugene Ie;William Wang;Zornitsa Kozareva;Sujith Ravi,xwang@cs.ucsb.edu;vihanjain@google.com;eugeneie@google.com;william@cs.ucsb.edu;kozareva@google.com;sravi@google.com,6;3;6,,Reject,0,6,0.0,yes,9/25/19,UC Santa Barbara;Google;Google;UC Santa Barbara;Google;Google,Natural Language Grounded Navigation;Multitask Learning;Agnostic Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3
3861,ICLR,2020,Mincut Pooling in Graph Neural Networks,Filippo Maria Bianchi;Daniele Grattarola;Cesare Alippi,fibi@norceresearch.no;grattd@usi.ch;alippc@usi.ch,3;8;3,,Reject,0,5,0.0,yes,9/25/19,NORCE the Norwegian Research Center;Universit√† della Svizzera Italiana;Universit√† della Svizzera Italiana,Graph Neural Networks;Pooling;Graph Cuts;Spectral Clustering,-1;194;194,-1;341;341,m;m,europe,ch,n,10
3862,ICLR,2020,Off-Policy Actor-Critic with Shared Experience Replay,Simon Schmitt;Matteo Hessel;Karen Simonyan,suschmitt@google.com;mtthss@google.com;simonyan@google.com,6;6;6,,Reject,0,4,1.0,yes,9/25/19,Google;Google;Google,Reinforcement Learning;Off-Policy Learning;Experience Replay,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
3863,ICLR,2020,Striving for Simplicity in Off-Policy Deep Reinforcement Learning,Rishabh Agarwal;Dale Schuurmans;Mohammad Norouzi,rishabhagarwal@google.com;schuurmans@google.com;mnorouzi@google.com,3;3;3,,Reject,0,7,1.0,yes,9/25/19,Google;Google;Google,reinforcement learning;off-policy;batch RL;offline RL;benchmark,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
3864,ICLR,2020,Scheduling the Learning Rate Via Hypergradients: New Insights and a New Algorithm,Michele Donini;Luca Franceschi;Orchid Majumder;Massimiliano Pontil;Paolo Frasconi,mikko108382892@gmail.com;luca.franceschi@iit.it;orchid@amazon.com;massimiliano.pontil@gmail.com;paolo.frasconi@unifi.it,6;1,,Reject,0,6,0.0,yes,9/25/19,Amazon;Istituto Italiano di Tecnologia;Amazon;;Universit√† di Firenze,automl;hyperparameter optimization;learning rate;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
3865,ICLR,2020,Improving Federated Learning Personalization via Model Agnostic Meta Learning,Yihan Jiang;Jakub Koneƒçn√Ω;Keith Rush;Sreeram Kannan,yihanrogerjiang@gmail.com;konkey@google.com;krush@google.com;ksreeram@uw.edu,1;1;3,,Reject,1,4,0.0,yes,9/25/19,"University of Washington, Seattle;Google;Google;University of Washington, Seattle",Federated Learning;Model Agnostic Meta Learning;Personalization,-1;-1;-1;11,-1;-1;-1;26,m;m,NAN,NAN,n,6
3866,ICLR,2020,Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View,Yiping Lu;Zhuohan Li;Di He;Zhiqing Sun;Bin Dong;Tao Qin;Liwei Wang;Tie-Yan Liu,yplu@stanford.edu;zhuohan@berkeley.edu;di_he@pku.edu.cn;zhiqings@andrew.cmu.edu;bindong@math.pku.edu.cn;taoqin@microsoft.com;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,3;1;3,,Reject,0,1,0.0,yes,9/25/19,Stanford University;University of California Berkeley;Peking University;Carnegie Mellon University;Peking University;Microsoft;Peking University;Microsoft,Transformer;Ordinary Differential Equation;Multi-Particle Dynamic System;Natural Language Processing,5;-1;14;1;14;-1;14;-1,4;13;24;27;24;-1;24;-1,m;m,NAN,NAN,n,8;3
3867,ICLR,2020,Optimising Neural Network Architectures for Provable Adversarial Robustness,Henry Gouk;Timothy M. Hospedales,hgouk@inf.ed.ac.uk;t.hospedales@ed.ac.uk,3;1;1,,Reject,0,0,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh,Provable adversarial robustness;Lipschitz neural networks;network architectures,36;36,30;30,m;m,europe,uk,y,1;4
3868,ICLR,2020,AN EFFICIENT HOMOTOPY TRAINING ALGORITHM FOR NEURAL NETWORKS,Qipin Chen;Wenrui Hao,qzc18@psu.edu;wxh64@psu.edu,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Pennsylvania State University;Pennsylvania State University,Homotopy training algorithm;Convergence analysis;Neural networks,43;43,-1;-1,m;m,usa,usa,y,
3869,ICLR,2020,Improving End-to-End Object Tracking Using Relational Reasoning,Fabian B. Fuchs;Adam R. Kosiorek;Li Sun;Oiwi Parker Jones;Ingmar Posner,fabian@robots.ox.ac.uk;adamk@robots.ox.ac.uk;kevin@robots.ox.ac.uk;oiwi.parkerjones@jesus.ox.ac.uk;ingmar@robots.ox.ac.uk,6;3;3,,Reject,0,5,1.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Relational Reasoning;Tracking;Intuitive Physics;Real-World Application;Permutation Invariance,46;46;46;46;46,1;1;1;1;1,m;m,europe,uk,n,8
3870,ICLR,2020,Bandlimiting Neural Networks Against Adversarial Attacks,Yuping Lin;Kasra Ahmadi K. A.;Hui Jiang,yuping@eecs.yorku.ca;kasraah@eecs.yorku.ca;hj@cse.yorku.ca,1;3;6,,Reject,0,0,0.0,yes,9/25/19,York University;York University;York University,adversarial examples;adversarial attack defense;neural network;Fourier analysis,194;194;194,416;416;416,m;m,asia,kr,y,4
3871,ICLR,2020,NoiGAN: NOISE AWARE KNOWLEDGE GRAPH EMBEDDING WITH GAN,Kewei Cheng;Yikai Zhu;Ming Zhang;Yizhou Sun,viviancheng@cs.ucla.edu;zhuyikai.zyk@gmail.com;mzhang_cs@pku.edu.cn;yzsun@cs.ucla.edu,3;3;1,,Reject,0,3,0.0,yes,9/25/19,"University of California, Los Angeles;;Peking University;University of California, Los Angeles",Knowledge graph embedding;Noise aware,-1;-1;14;-1,17;-1;24;17,f;f,usa,usa,n,8;10;5;4
3872,ICLR,2020,Gradient Surgery for Multi-Task Learning,Tianhe Yu;Saurabh Kumar;Abhishek Gupta;Karol Hausman;Sergey Levine;Chelsea Finn,tianheyu@cs.stanford.edu;szk@stanford.edu;abhigupta@berkeley.edu;hausmankarol@gmail.com;svlevine@eecs.berkeley.edu;cbfinn@cs.stanford.edu,3;6;3,,Reject,0,6,0.0,yes,9/25/19,Stanford University;Stanford University;University of California Berkeley;Google;University of California Berkeley;Stanford University,multi-task learning;deep learning,5;5;-1;-1;-1;5,4;4;13;-1;13;4,m;f,usa,usa,y,
3873,ICLR,2020,Filter redistribution templates for iteration-lessconvolutional model reduction,Ramon Izquierdo Cordova;Walterio Mayol Cuevas,ri16164@bristol.ac.uk;walterio.mayol-cuevas@bristol.ac.uk,3;6;3;6,,Reject,0,6,0.0,yes,9/25/19,University of Bristol;University of Bristol,Model reduction;Pruning;filter distribution,118;118,87;87,m;m,europe,uk,n,
3874,ICLR,2020,Value-Driven Hindsight Modelling,Arthur Guez;Fabio Viola;Theophane Weber;Lars Buesing;Steven Kapturowski;Doina Precup;David Silver;Nicolas Heess,aguez@google.com;fviola@google.com;theophane@google.com;lbuesing@google.com;skapturowski@google.com;doinap@google.com;davidsilver@google.com;heess@google.com,6;6;6,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
3875,ICLR,2020,JAUNE: Justified And Unified Neural language Evaluation,Hassan Kan√©;Yusuf Kocyigit;Ali Abdalla;Pelkins Ajanoh;Mohamed Coulibali,hassanmohamed@alum.mit.edu;yusuf.kocyigit@boun.edu.tr;aabdalla@alum.mit.edu;pelkins@alum.mit.edu;mohamed-konoufo.coulibali.1@ulaval.ca,1;1;1,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Bogazici University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Laval university,NLP;Evaluation Metrics;Summarization;Translation;BLEU;ROUGE;Transformers,5;316;5;5;-1,5;672;5;5;272,m;m,NAN,NAN,n,8;3
3876,ICLR,2020,Extreme Values are Accurate and Robust in Deep Networks,Jianguo Li;Mingjie Sun;Changshui Zhang,jianguo.li@intel.com;sunmj15@gmail.com;zcs@tsinghua.edu.cn,3;3;8,,Reject,0,4,0.0,yes,9/25/19,"Intel;;Tsinghua University, Tsinghua University",Biological inspired CNN architecture design;Adversarial Robustness Architecture,-1;-1;4,-1;-1;23,m;m,NAN,NAN,n,4
3877,ICLR,2020,"Scaling Laws for the Principled Design, Initialization, and Preconditioning of ReLU Networks",Aaron Defazio;Leon Bottou,aaron.defazio@gmail.com;leon@bottou.org,3;1;3,,Reject,0,4,0.0,yes,9/25/19,Facebook;Facebook,initialization;mlp;relu,-1;-1,-1;-1,m;m,NAN,NAN,y,1
3878,ICLR,2020,Overcoming Catastrophic Forgetting via Hessian-free Curvature Estimates,Leonid Butyrev;Georgios Kontes;Christoffer L√∂ffler;Christopher Mutschler,butyreld@iis.fraunhofer.de;georgios.kontes@iis.fraunhofer.de;christoffer.loeffler@iis.fraunhofer.de;christopher.mutschler@iis.fraunhofer.de,3;1;3,,Reject,0,1,0.0,yes,9/25/19,Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS,catastrophic forgetting;multi-task learning;continual learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
3879,ICLR,2020,Learning Functionally Decomposed Hierarchies for Continuous Navigation Tasks,Lukas Jendele;Sammy Christen;Emre Aksan;Otmar Hilliges,lukas.jendele@gmail.com;sammy.christen@inf.ethz.ch;eaksan@inf.ethz.ch;otmar.hilliges@inf.ethz.ch,6;6;3,,Reject,0,8,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Hierarchical reinforcement learning;planning;navigation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
3880,ICLR,2020,Hindsight Trust Region Policy Optimization,Hanbo Zhang;Site Bai;Xuguang Lan;Nanning Zheng,zhanghanbo163@stu.xjtu.edu.cn;best99317@stu.xjtu.edu.cn;xglan@xjtu.edu.cn;nnzheng@xjtu.edu.cn,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,Hindsight;Sparse Reward;Reinforcement Learning;Policy Gradients,-1;-1;-1;-1,555;555;555;555,m;m,NAN,NAN,y,
3881,ICLR,2020,The Probabilistic Fault Tolerance of Neural Networks in the Continuous Limit,El-Mahdi El-Mhamdi;Rachid Guerraoui;Andrei Kucharavy;Sergei Volodin,elmahdi.elmhamdi@epfl.ch;rachid.guerraoui@epfl.ch;andrei.kucharavy@epfl.ch;sergei.volodin@epfl.ch,1;3;8,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Robustness;theory of neural networks;fault tolerance;continuous limit;Taylor expansion;error bound;neuromorphic computing;continuous networks;functional derivative,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,1
3882,ICLR,2020,Parallel Neural Text-to-Speech,Kainan Peng;Wei Ping;Zhao Song;Kexin Zhao,pengkainan@baidu.com;weiping.thu@gmail.com;zhaosong02@baidu.com;zhaokexin01@baidu.com,3;6;1,,Reject,1,3,0.0,yes,9/25/19,Baidu;NVIDIA;Baidu;Baidu,text-to-speech;non-autoregressive model;parallel decoding,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8
3883,ICLR,2020,"Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation",Jiawei Ma*;Zheng Shou*;Alireza Zareian;Hassan Mansour;Anthony Vetro;Shih-Fu Chang,jm4743@columbia.edu;zs2262@columbia.edu;alireza@cs.columbia.edu;mansour@merl.com;avetro@merl.com;sc250@columbia.edu,6;1;3,,Reject,0,5,0.0,yes,9/25/19,Columbia University;Columbia University;Columbia University;Mitsubishi Electric Research Labs;Mitsubishi Electric Research Labs;Columbia University,self-attention;cross-dimensional;multivariate time series;imputation,24;24;24;-1;-1;24,16;16;16;-1;-1;16,m;m,usa,usa,n,8;3
3884,ICLR,2020,Differential Privacy in Adversarial Learning with Provable Robustness,NhatHai Phan;My T. Thai;Ruoming Jin;Han Hu;Dejing Dou,phan@njit.edu;mythai@cise.ufl.edu;rjin1@kent.edu;hh255@njit.edu;dou@cs.uoregon.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,New Jersey Institute of Technology;University of Florida;Bilkent University;New Jersey Institute of Technology;University of Oregon,differential privacy;adversarial learning;robustness bound;adversarial example,-1;168;316;-1;194,564;174;548;564;288,m;m,europe,de,y,1;4
3885,ICLR,2020,On Layer Normalization in the Transformer Architecture,Ruibin Xiong;Yunchang Yang;Di He;Kai Zheng;Shuxin Zheng;Huishuai Zhang;Yanyan Lan;Liwei Wang;Tie-Yan Liu,xiongruibin18@mails.ucas.ac.cn;1500010650@pku.edu.cn;dihe@microsoft.com;zhengk92@pku.edu.cn;shuxin.zheng@microsoft.com;huishuai.zhang@microsoft.com;lanyanyan@ict.ac.cn;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,6;6;6,,Reject,2,11,0.0,yes,9/25/19,"Chinese Academy of Sciences;Peking University;Microsoft;Peking University;Microsoft;Microsoft;Institute of Computing Technology, Chinese Academy of Sciences;Peking University;Microsoft",Transformer;BERT;Layer Normalization;Natural Language Processing,30;14;-1;14;-1;-1;30;14;-1,-1;24;-1;24;-1;-1;-1;24;-1,m;m,NAN,NAN,y,8;3
3886,ICLR,2020,Learning RNNs with Commutative State Transitions,Edo Cohen-Karlik;Amir Globerson,edocoh@gmail.com;amir.globerson@gmail.com,1;1;3,,Reject,0,3,0.0,yes,9/25/19,Tel Aviv University;Tel Aviv University,,-1;30,-1;188,m;m,europe,il,y,
3887,ICLR,2020,Deep Bayesian Structure Networks,Zhijie Deng;Yucen Luo;Jun Zhu;Bo Zhang,dzj17@mails.tsinghua.edu.cn;luoyc15@mails.tsinghua.edu.cn;dcszj@tsinghua.edu.cn;dcszb@tsinghua.edu.cn,3;3;6,,Reject,0,8,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",,4;4;4;4,23;23;23;23,m;m,NAN,NAN,n,2;11
3888,ICLR,2020,RPGAN: random paths as a latent space for GAN interpretability,Andrey Voynov;Artem Babenko,an.voynov@gmail.com;artem.babenko@phystech.edu,3;3;8,,Reject,0,3,0.0,yes,9/25/19,Yandex;Moscow Institute of Physics and Technology,generative models;GAN;interpretability,-1;-1,-1;234,m;m,NAN,NAN,n,5;4
3889,ICLR,2020,MissDeepCausal: causal inference from incomplete data using deep latent variable models,Julie Josse;Imke Mayer;Jean-Philippe Vert,julie.josse@polytechnique.edu;imke.mayer@polytechnique.edu;jpvert@google.com,6;6;6,,Reject,0,5,0.0,yes,9/25/19,Ecole polytechnique;Ecole polytechnique;Google,treatment effect estimation;missing values;variational autoencoders;importance sampling;double robustness,-1;-1;-1,93;93;-1,f;m,NAN,NAN,n,5
3890,ICLR,2020,Active Learning Graph Neural Networks via Node Feature Propagation,Yuexin Wu;Yichong Xu;Aarti Singh;Artur Dubrawski;Yiming Yang,yuexinw@andrew.cmu.edu;yichongx@cs.cmu.edu;aarti@cs.cmu.edu;awd@cs.cmu.edu;yiming@cs.cmu.edu,3;1;8,,Reject,2,4,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Graph Learning;Active Learning,1;1;1;1;1,27;27;27;27;27,m;f,usa,usa,y,8;1;10
3891,ICLR,2020,DUAL ADVERSARIAL MODEL FOR GENERATING 3D POINT CLOUD,Yuhang Zhang;Zhenwei Miao;Tiebin Mi;Robert Caiming Qiu,hang_universe@sjtu.edu.cn;zhenwei.mzw@alibaba-inc.com;mitiebin@sjtu.edu.cn;rcqiu@sjtu.edu.cn,1;6;6,,Reject,0,4,0.0,yes,9/25/19,Shanghai Jiao Tong University;Alibaba Group;Shanghai Jiao Tong University;Shanghai Jiao Tong University,point cloud;generative;latent space,30;-1;30;30,157;-1;157;157,m;m,asia,cn,n,5;4
3892,ICLR,2020,LabelFool: A Trick in the Label Space,Yujia Liu;Tingting Jiang;Ming Jiang,yujia_liu@pku.edu.cn;ttjiang@pku.edu.cn;ming-jiang@pku.edu.cn,3;3;1,,Reject,0,10,0.0,yes,9/25/19,Peking University;Peking University;Peking University,Adversarial attack;LabelFool;Imperceptibility;Label space,14;14;14,24;24;24,f;m,asia,cn,n,4
3893,ICLR,2020,Unsupervised Generative 3D Shape Learning from Natural Images,Attila Szabo;Givi Meishvili;Paolo Favaro,attila.szabo@inf.unibe.ch;givi.meishvili@inf.unibe.ch;paolo.favaro@inf.unibe.ch,3;3;8,,Reject,2,5,0.0,yes,9/25/19,University of Bern;University of Bern;University of Bern,unsupervised;3D;differentiable;rendering;disentangling;interpretable,316;316;316,113;113;113,m;m,europe,uk,n,5;4
3894,ICLR,2020,Prestopping: How Does Early Stopping Help Generalization Against Label Noise?,Hwanjun Song;Minseok Kim;Dongmin Park;Jae-Gil Lee,songhwanjun@kaist.ac.kr;minseokkim@kaist.ac.kr;dongminpark@kaist.ac.kr;jaegil@kaist.ac.kr,3;3;6;3,,Reject,2,9,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,noisy label;label noise;robustness;deep learning;early stopping,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n,1
3895,ICLR,2020,Deep Reinforcement Learning with Implicit Human Feedback,Duo Xu;Mohit Agarwal;Raghupathy Sivakumar;Faramarz Fekri,dxu3016@gatech.edu;me.agmohit@gatech.edu;siva@ece.gatech.edu;faramarz.fekri@ece.gatech.edu,3;1;3,,Reject,0,1,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Error-Potentials;Implicit Human Feedback;Deep Reinforcement Learning;Human-assistance,13;13;13;13,38;38;38;38,m;m,usa,usa,n,
3896,ICLR,2020,"Manifold Modeling in Embedded Space: A Perspective for Interpreting Deep Image Prior""""",Tatsuya Yokota;Hidekata Hontani;Qibin Zhao;Andrzej Cichocki,t.yokota@nitech.ac.jp;hontani@nitech.ac.jp;qibin.zhao@riken.jp;a.cichocki@riken.jp,6;6;6,,Reject,0,10,0.0,yes,9/25/19,Nagoya Institute of Technology;Nagoya Institute of Technology;RIKEN;RIKEN,Deep image prior;Manifold model;Auto-encoder;Convolutional neural network;Delay-embedding;Hankelization;Tensor completion;Image inpainting;Supperresolution,-1;-1;-1;-1,1157;1157;-1;-1,m;m,NAN,NAN,n,8;2
3897,ICLR,2020,Self-Imitation Learning via Trajectory-Conditioned Policy for Hard-Exploration Tasks,Yijie Guo;Jongwook Choi;Marcin Moczulski;Samy Bengio;Mohammad Norouzi;Honglak Lee,guoyijie@umich.edu;jwook@umich.edu;moczulski@google.com;bengio@google.com;mnorouzi@google.com;honglak@google.com,6;1;3,,Reject,0,5,0.0,yes,9/25/19,University of Michigan;University of Michigan;Google;Google;Google;Google,imitation learning;hard-exploration tasks;exploration and exploitation,7;7;-1;-1;-1;-1,21;21;-1;-1;-1;-1,f;m,NAN,NAN,n,
3898,ICLR,2020,Improving Semantic Parsing with Neural Generator-Reranker Architecture,Huseyin A. Inan;Gaurav Singh Tomar;Huapu Pan,hinan1@stanford.edu;gtomar@google.com;huapupan@google.com,3;1;3,,Reject,0,5,0.0,yes,9/25/19,Stanford University;Google;Google,Natural Language Processing;Semantic Parsing;Neural Reranking,5;-1;-1,4;-1;-1,m;m,NAN,NAN,n,3
3899,ICLR,2020,Learning to Make Generalizable and Diverse Predictions for Retrosynthesis,Benson Chen;Tianxiao Shen;Tommi S. Jaakkola;Regina Barzilay,bensonc@mit.edu;tianxiao@mit.edu;tommi@csail.mit.edu;regina@csail.mit.edu,6;6;1,,Reject,0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Chemistry;Retrosynthesis;Transformer;Pre-training;Diversity,5;5;5;5,5;5;5;5,m;f,usa,usa,n,8;5
3900,ICLR,2020,Benefit of Interpolation in Nearest Neighbor Algorithms,Yue Xing;Qifan Song;Guang Cheng,xing49@purdue.edu;qfsong@purdue.edu;chengg@purdue.edu,6;1;3,,Reject,0,5,0.0,yes,9/25/19,Purdue University;Purdue University;Purdue University,Data Interpolation;Multiplicative Constant;W-Shaped Double Descent;Nearest Neighbor Algorithm,24;24;24,88;88;88,f;m,usa,usa,y,8
3901,ICLR,2020,Learning to Reach Goals Without Reinforcement Learning,Dibya Ghosh;Abhishek Gupta;Justin Fu;Ashwin Reddy;Coline Devin;Benjamin Eysenbach;Sergey Levine,dibya.ghosh@berkeley.edu;abhigupta@berkeley.edu;justinjfu@eecs.berkeley.edu;adreddy@berkeley.edu;coline@berkeley.edu;beysenba@cs.cmu.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,8,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Carnegie Mellon University;University of California Berkeley,Reinforcement Learning;Goal Reaching;Imitation Learning,-1;-1;-1;-1;-1;1;-1,13;13;13;13;13;27;13,m;m,usa,usa,y,
3902,ICLR,2020,Refining the variational posterior through iterative optimization,Marton Havasi;Jasper Snoek;Dustin Tran;Jonathan Gordon;Jos√© Miguel Hern√°ndez-Lobato,mh740@cam.ac.uk;jsnoek@google.com;trandustin@google.com;jg801@cam.ac.uk;jmh233@cam.ac.uk,6;3;6;6,,Reject,0,8,0.0,yes,9/25/19,University of Cambridge;Google;Google;University of Cambridge;University of Cambridge,uncertainty estimation;variational inference;auxiliary variables;Bayesian neural networks,79;-1;-1;79;79,3;-1;-1;3;3,m;m,europe,uk,n,11;1
3903,ICLR,2020,Off-policy Bandits with Deficient Support,Noveen Sachdeva;Yi Su;Thorsten Joachims,ernoveen@gmail.com;ys756@cornell.edu;tj@cs.cornell.edu,6;3;3,,Reject,0,5,0.0,yes,9/25/19,International Institute of Information Technology Hyderabad;Cornell University;Cornell University,Recommender System;Search Engine;Counterfactual Learning,-1;7;7,-1;19;19,m;m,usa,usa,y,
3904,ICLR,2020,iSparse: Output Informed Sparsification of Neural Networks,Yash Garg;K. Selcuk Candan,ygarg@asu.edu;candan@asu.edu,1;3;3,,Reject,0,3,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,dropout;dropconnect;sparsification;deep learning;neural network,-1;-1,299;299,m;m,NAN,NAN,n,
3905,ICLR,2020,Towards understanding the true loss surface of deep neural networks using random matrix theory and iterative spectral methods,Diego Granziol;Timur Garipov;Dmitry Vetrov;Stefan Zohren;Stephen Roberts;Andrew Gordon Wilson,diego@robots.ox.ac.uk;timgaripov@gmail.com;vetrovd@yandex.ru;zohren@robots.ox.ac.uk;sjrob@robots.ox.ac.uk;andrewgw@cims.nyu.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Oxford;Massachusetts Institute of Technology;Higher School of Economics;University of Oxford;University of Oxford;New York University,Random Matrix theory;deep learning;deep learning theory;hessian eigenvalues;true risk,46;5;-1;46;46;22,1;5;-1;1;1;29,m;m,usa,usa,y,1
3906,ICLR,2020,PROTOTYPE-ASSISTED ADVERSARIAL LEARNING FOR UNSUPERVISED DOMAIN ADAPTATION,Dapeng Hu;Jian Liang*;Qibin Hou;Hanshu Yan;Jiashi Feng,dapeng.hu@u.nus.edu;liangjian92@gmail.com;andrewhoux@gmail.com;hanshu.yan@u.nus.edu;elefjia@nus.edu.sg,3;3,,Reject,0,5,0.0,yes,9/25/19,National University of Singapore;;National University of Singapore;National University of Singapore;National University of Singapore,Domain Adaptation;Transfer Learning;Adversarial Learning,17;-1;17;17;17,25;-1;25;25;25,m;m,asia,sg,n,2;1;4
3907,ICLR,2020,Likelihood Contribution based Multi-scale Architecture for Generative Flows,Hari Prasanna Das;Pieter Abbeel;Costas J. Spanos,hpdas@eecs.berkeley.edu;pabbeel@cs.berkeley.edu;spanos@eecs.berkeley.edu,3;3;3,,Reject,0,10,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Generative Flow;Normalizing Flow;Multi-scale Architecture;RealNVP;Dimension Factorization,-1;-1;-1,13;13;13,m;m,usa,usa,n,5
3908,ICLR,2020,Understanding Top-k Sparsification in Distributed Deep Learning,Shaohuai Shi;Xiaowen Chu;Ka Chun Cheung;Simon See,csshshi@comp.hkbu.edu.hk;chxw@comp.hkbu.edu.hk;chcheung@nvidia.com;ssee@nvidia.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Boston University;Boston University;NVIDIA;NVIDIA,Distributed Deep Learning;SGD;Gradient Sparsification;Communication-efficient SGD;Top-k,79;79;-1;-1,61;61;-1;-1,m;m,NAN,NAN,n,1
3909,ICLR,2020,AN ATTENTION-BASED DEEP NET FOR LEARNING TO RANK,Diego Klabjan;Baiyang Wang,d-klabjan@northwestern.edu;baiyang@u.northwestern.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Northwestern University;Northwestern University,learning to rank;deep learning,46;46,22;22,m;m,usa,usa,n,8
3910,ICLR,2020,Modeling question asking using neural program generation,Ziyun Wang;Brenden M. Lake,ziyunw@nyu.edu;brenden@nyu.edu,6;1;6,,Reject,0,5,0.0,yes,9/25/19,New York University;New York University,question asking;language generation;program induction;reinforcement learning;density estimation;cognitive science,22;22,29;29,m;m,usa,usa,n,
3911,ICLR,2020,Acutum: When Generalization Meets Adaptability,Xunpeng Huang;Zhengyang Liu;Zhe Wang;Yue Yu;Lei Li,huangxunpeng@bytedance.com;liuzhengyang.lozycs@bytedance.com;wang.10982@osu.edu;yuyue.elaine@bytedance.com;lilei.02@bytedance.com,3;1;6,,Reject,0,5,0.0,yes,9/25/19,ByteDance;ByteDance;Ohio State University;ByteDance;ByteDance,optimization;momentum;adaptive gradient methods,-1;-1;59;-1;-1,-1;-1;70;-1;-1,u;m,NAN,NAN,y,8;1;9
3912,ICLR,2020,Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning,Eric Arazo;Diego Ortego;Paul Albert;Noel E. O'Connor;Kevin McGuinness,eric.arazo@insight-centre.org;diego.ortego@insight-centre.org;paul.albert@insight-centre.org;noel.oconnor@dcu.ie;kevin.mcguinness@dcu.ie,3;8;3,,Reject,0,5,0.0,yes,9/25/19,Insight Centre for Data Analytics;Insight Centre for Data Analytics;Insight Centre for Data Analytics;Dublin City University;Dublin City University,Semi-supervised learning;pseudo-labeling;deep semi-supervised learning;confirmation bias;image classification,-1;-1;-1;-1;-1,-1;-1;-1;601;601,m;m,NAN,NAN,n,
3913,ICLR,2020,Revisiting the Generalization of Adaptive Gradient Methods,Naman Agarwal;Rohan Anil;Elad Hazan;Tomer Koren;Cyril Zhang,namanagarwal@google.com;rohananil@google.com;ehazan@cs.princeton.edu;tkoren@google.com;cyril.zhang@princeton.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Google;Google;Princeton University;Google;Princeton University,Adaptive Methods;AdaGrad;Generalization,-1;-1;30;-1;30,-1;-1;6;-1;6,m;m,usa,usa,y,1
3914,ICLR,2020,ConQUR: Mitigating Delusional Bias in Deep Q-Learning,DiJia-Andy Su;Jayden Ooi;Tyler Lu;Dale Schuurmans;Craig Boutilier‚Äé,andy.2008.su@gmail.com;jayden@alum.mit.edu;tyler.lu@gmail.com;schuurmans@google.com;cboutilier@google.com,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Princeton University;Massachusetts Institute of Technology;Google;Google;Google,reinforcement learning;q-learning;deep reinforcement learning;Atari,-1;5;-1;-1;-1,-1;5;-1;-1;-1,m;m,NAN,NAN,y,10
3915,ICLR,2020,Weight-space symmetry in neural network loss landscapes revisited,Berfin Simsek;Johanni Brea;Bernd Illing;Wulfram Gerstner,berfin.simsek@epfl.ch;johanni.brea@epfl.ch;bernd.illing@epfl.ch;wulfram.gerstner@epfl.ch,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Weight-space symmetry;neural network landscapes,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,y,1
3916,ICLR,2020,Collaborative Filtering With A Synthetic Feedback Loop,Wenlin Wang;Hongteng Xu;Ruiyi Zhang;Wenqi Wang;Lawrence Carin,wlwang616@gmail.com;hongtengxu313@gmail.com;ryzhang@cs.duke.edu;wenqiwang@fb.com,6;3;3,,Reject,0,0,0.0,yes,9/25/19,"Duke University;University of Illinois, Urbana-Champaign;Duke University;Facebook",,-1;-1;46;-1,-1;-1;20;-1,m;m,NAN,NAN,n,
3917,ICLR,2020,Empowering Graph Representation Learning with Paired Training and Graph Co-Attention,Andreea Deac;Yu-Hsiang Huang;Petar Velickovic;Pietro Lio;Jian Tang,deacandr@mila.quebec;huang.yu-hsiang@courrier.uqam.ca;petar.velickovic@cst.cam.ac.uk;pl219@cam.ac.uk;jian.tang@hec.ca,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Mila;UQAM;University of Cambridge;University of Cambridge;HEC Montreal,graph neural networks;graph co-attention;paired graphs;molecular properties;drug-drug interaction,143;-1;79;79;-1,336;-1;3;3;-1,f;m,canada,ca,n,8;10
3918,ICLR,2020,Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models,Yiding Feng;Ekaterina Khmelnitskaya;Denis Nekipelov,yidingfeng2021@u.northwestern.edu;eak5rf@virginia.edu;denis@virginia.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Northwestern University;University of Virginia;University of Virginia,Reinforcement learning;Policy Gradient;Global Concavity;Dynamic Discrete Choice Model,46;52;52,22;107;107,m;m,usa,usa,y,
3919,ICLR,2020,Training Provably Robust Models by Polyhedral Envelope Regularization,Chen Liu;Mathieu Salzmann;Sabine S√ºsstrunk,chen.liu@epfl.ch;mathieu.salzmann@epfl.ch;sabine.susstrunk@epfl.ch,3;8;3,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,deep learning;adversarial attack;robust certification,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,y,1;4
3920,ICLR,2020,Unifying Graph Convolutional Networks as Matrix Factorization,Zhaocheng Liu;Qiang Liu;Haoli Zhang;Jun Zhu,zhaocheng.liu@realai.ai;qiang.liu@realai.ai;haoli.zhang@realai.ai;dcszj@mail.tsinghua.edu.cn,1;6;1,,Reject,0,7,0.0,yes,9/25/19,"RealAI;RealAI;RealAI;Tsinghua University, Tsinghua University",graph convolutional networks;matrix factorization;unification,-1;-1;-1;4,-1;-1;-1;23,u;m,NAN,NAN,n,10
3921,ICLR,2020,Adversarial Inductive Transfer Learning with input and output space adaptation,Hossein Sharifi-Noghabi;Shuman Peng;Olga Zolotareva;Colin C. Collins;Martin Ester,hsharifi@sfu.ca;shumanp@sfu.ca;ozolotareva@techfak.uni-bielefeld.de;ccollins@prostatecentre.com;ester@sfu.ca,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Simon Fraser University;Simon Fraser University;Bielefeld University;Prostatecentre;Simon Fraser University,Inductive transfer learning;adversarial learning;multi-task learning;pharmacogenomics;precision oncology,52;52;316;-1;52,272;272;166;-1;272,m;m,canada,ca,n,6;4
3922,ICLR,2020,Leveraging Simple Model Predictions for Enhancing its Performance,Amit Dhurandhar;Karthikeyan Shanmugam;Ronny Luss,adhuran@us.ibm.com;karthikeyan.shanmugam2@ibm.com;rluss@us.ibm.com,6;6;6;1,,Reject,1,5,0.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines,simple models;interpretability;resource constraints,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3923,ICLR,2020,Learning to Transfer via Modelling Multi-level Task Dependency,Haonan Wang;Zhenbang Wu;Ziniu Hu;Yizhou Sun,haonan3@illinois.edu;zw12@illinois.edu;bull@cs.ucla.edu;yzsun@cs.ucla.edu,1;3;3;3,,Reject,0,4,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of California, Los Angeles;University of California, Los Angeles",multi-task learning;attention mechanism,-1;-1;-1;-1,-1;-1;17;17,m;f,usa,usa,n,8
3924,ICLR,2020,Disentangling Style and Content in Anime Illustrations,Sitao Xiang;Hao Li,sitaoxia@usc.edu;hao@hao-li.com,3;6;3,,Reject,0,6,0.0,yes,9/25/19,University of Southern California;Hao-li,Adversarial Training;Generative Models;Style Transfer;Anime,36;-1,62;-1,u;u,NAN,NAN,n,5;4
3925,ICLR,2020,Targeted sampling of enlarged neighborhood via Monte Carlo tree search for TSP,Zhang-Hua Fu;Kai-Bin Qiu;Meng Qiu;Hongyuan Zha,fuzhanghua@cuhk.edu.cn;20150008030@m.scnu.edu.cn;qiumeng.sz@gmail.com;zhahy@cuhk.edu.cn,1;1;3,,Reject,0,0,0.0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen;East China Normal University;;The Chinese University of Hong Kong, Shenzhen",Travelling salesman problem;Monte Carlo tree search;Reinforcement learning;Variable neighborhood search,46;-1;-1;46,35;544;-1;35,u;m,NAN,NAN,n,
3926,ICLR,2020,S2VG: Soft Stochastic Value Gradient method,Xiaoyu Tan;Chao Qu;Junwu Xiong;James Zhang,xiaoyu_tan@u.nus.edu;chaoqu.technion@gmail.com;junwu.xjw@antfin.com;james.z@antfin.com,1;1;3,,Reject,0,3,0.0,yes,9/25/19,National University of Singapore;;Antfin;Antfin,Model-based reinforcement learning;soft stochastic value gradient,17;-1;-1;-1,25;-1;-1;-1,u;u,NAN,NAN,n,
3927,ICLR,2020,Learning to Defense by Learning to Attack,Zhehui Chen;Haoming Jiang;Yuyang Shi;Bo Dai;Tuo Zhao,zhchen@gatech.edu;jianghm@gatech.edu;yyshi@gatech.edu;bodai@google.com;tourzhao@gatech.edu,6;3;6,,Reject,0,5,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Google;Georgia Institute of Technology,,13;13;13;-1;13,38;38;38;-1;38,m;m,usa,usa,n,5;4
3928,ICLR,2020,Model Architecture Controls Gradient Descent Dynamics: A Combinatorial Path-Based Formula,Xin Zhou;Newsha Ardalani,chow459@gmail.com;newsha@baidu.com,3;6;3,,Reject,0,5,0.0,yes,9/25/19,University of Michigan;Baidu,,-1;-1,-1;-1,u;f,NAN,NAN,y,9
3929,ICLR,2020,Natural- to formal-language generation using Tensor Product Representations,Kezhen Chen;Qiuyuan Huang;Hamid Palangi;Paul Smolensky;Kenneth D. Forbus;Jianfeng Gao,kezhenchen2021@u.northwestern.edu;qihua@microsoft.com;hpalangi@microsoft.com;paul.smolensky@gmail.com;forbus@northwestern.edu;jfgao@microsoft.com,8;3;3,,Reject,0,8,0.0,yes,9/25/19,Northwestern University;Microsoft;Microsoft;Microsoft;Northwestern University;Microsoft,Neural Symbolic Reasoning;Deep Learning;Natural Language Processing;Structural Representation;Interpretation of Learned Representations,46;-1;-1;-1;46;-1,22;-1;-1;-1;22;-1,u;m,NAN,NAN,n,
3930,ICLR,2020,Unsupervised Out-of-Distribution Detection with Batch Normalization,Jiaming Song;Yang Song;Stefano Ermon,jiaming.tsong@gmail.com;yangsong@cs.stanford.edu;ermon@cs.stanford.edu,1;6;1,,Reject,0,0,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University,,5;5;5,4;4;4,m;m,usa,usa,y,5
3931,ICLR,2020,Distribution Matching Prototypical Network for Unsupervised Domain Adaptation,Lei Zhu;Wei Wang;Mei Hui Zhang;Beng Chin Ooi;Chang Yao,e0203764@u.nus.edu;wangwei@comp.nus.edu.sg;meihui_zhang@bit.edu.cn;ooibc@comp.nus.edu.sg;yaochang@zjuici.com,3;3;1,,Reject,0,10,0.0,yes,9/25/19,National University of Singapore;National University of Singapore;Beijing Institute of Technology;National University of Singapore;Zjuici,Deep Learning;Unsupervised Domain Adaptation;Distribution Modeling,17;17;-1;17;-1,25;25;661;25;-1,m;m,NAN,NAN,n,
3932,ICLR,2020,Deep Hierarchical-Hyperspherical Learning (DH^2L),Youngsung Kim;Jae-Joon Han,yskim.ee@gmail.com;jae-joon.han@samsung.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Samsung;Samsung,,-1;-1,-1;-1,m;m,NAN,NAN,n,1
3933,ICLR,2020,Neural Markov Logic Networks,Giuseppe Marra;Ond≈ôej Ku≈æelka,g.marra@unifi.it;kuzelo1@gmail.com,6;1;6,,Reject,0,3,0.0,yes,9/25/19,Universit√† di Firenze;Czech Technical University in Prague,Statistical Relational Learning;Markov Logic Networks,-1;168,-1;956,m;m,NAN,NAN,n,1
3934,ICLR,2020,Deep Randomized Least Squares Value Iteration,Guy Adam;Tom Zahavy;Oron Anschel;Nahum Shimkin,guyadam3@gmail.com;tomzahavy@gmail.com;oronanschel@gmail.com;shimkin@ee.technion.ac.il,1;3;1,,Reject,0,6,0.0,yes,9/25/19,"Technion, Technion;DeepMind;Amazon;Technion, Technion",Thompson Sampling;Deep Learning;Reinforcement Learning,27;-1;-1;27,-1;-1;-1;-1,m;m,NAN,NAN,n,
3935,ICLR,2020,Safe Policy Learning for Continuous Control,Yinlam Chow;Ofir Nachum;Aleksandra Faust;Edgar Duenez-Guzman;Mohammad Ghavamzadeh,yinlamchow@google.com;ofirnachum@google.com;sandrafaust@google.com;duenez@google.com;mgh@fb.com,6;8;6,,Reject,0,6,2.0,yes,9/25/19,Google;Google;Google;Google;Facebook,reinforcement learning;policy gradient;safety,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
3936,ICLR,2020,Unsupervised Distillation of Syntactic Information from Contextualized Word Representations,Shauli Ravfogel;Yanai Elazar;Jacob Goldberger;Yoav Goldberg,shauli.ravfogel@gmail.com;yanaiela@gmail.com;jacob.goldberger@biu.ac.il;yogo@cs.biu.ac.il,6;8;6;1,,Reject,0,12,0.0,yes,9/25/19,Bar Ilan University;Bar Ilan University;Bar Ilan University;Bar Ilan University,dismantlement;contextualized word representations;language models;representation learning,-1;102;102;102,-1;513;513;513,m;m,europe,il,n,6;3
3937,ICLR,2020,Discriminator Based Corpus Generation for General Code Synthesis,Alexander Wild;Barry Porter,a.wild3@lancaster.ac.uk;b.f.porter@lancaster.ac.uk,1;1;1,,Reject,2,1,0.0,yes,9/25/19,Lancaster University;Lancaster University,Code Synthesis;Neural Code Synthesis,248;248,140;140,m;m,europe,uk,n,
3938,ICLR,2020,Situating Sentence Embedders with Nearest Neighbor Overlap,Lucy H. Lin;Noah A. Smith,lucylin@cs.washington.edu;nasmith@cs.washington.edu,3;1;1,,Reject,0,2,0.0,yes,9/25/19,University of Washington;University of Washington,sentence embeddings;nearest neighbors;semantic similarity,11;11,26;26,f;m,usa,usa,n,3
3939,ICLR,2020,Lattice Representation Learning,Luis A Lastras,lastrasl@us.ibm.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,International Business Machines,lattices;representation learning;coding theory;lossy source coding;information theory,-1,-1,m;u,NAN,NAN,y,1
3940,ICLR,2020,Towards Understanding the Transferability of Deep Representations,Hong Liu;Mingsheng Long;Jianmin Wang;Michael I. Jordan,h-l17@mails.tsinghua.edu.cn;mingsheng@tsinghua.edu.cn;jimwang@tsinghua.edu.cn;jordan@cs.berkeley.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of California Berkeley",Transfer Learning;Fine-tuning;Deep Neural Networks,4;4;4;-1,23;23;23;13,m;m,usa,usa,y,1
3941,ICLR,2020,Improved Training of Certifiably Robust Models,Chen Zhu;Renkun Ni;Ping-yeh Chiang;Hengduo Li;Furong Huang;Tom Goldstein,chenzhu@cs.umd.edu;rn9zm@cs.umd.edu;pingyeh.chiang@gmail.com;hdli@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,6;3;3,,Reject,0,6,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",Convex Relaxation;Certified Robustness;Regularization,12;12;12;12;12;12,91;91;91;91;91;91,m;m,usa,usa,y,4
3942,ICLR,2020,Learning from Label Proportions with Consistency Regularization,Kuen-Han Tsai;Hsuan-Tien Lin,r06922066@csie.ntu.edu.tw;htlin@csie.ntu.edu.tw,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University,learning from label proportions;consistency regularization;semi-supervised learning,43;43,49;49,u;m,asia,sg,n,8
3943,ICLR,2020,Learning Compact Embedding Layers via Differentiable Product Quantization,Ting Chen;Lala Li;Yizhou Sun,iamtingchen@gmail.com;lala@google.com;yzsun@cs.ucla.edu,3;6;3,,Reject,0,6,0.0,yes,9/25/19,"Google;Google;University of California, Los Angeles",efficient modeling;compact embedding;embedding table compression;differentiable product quantization,-1;-1;-1,-1;-1;17,m;f,usa,usa,y,
3944,ICLR,2020,{COMPANYNAME}11K: An Unsupervised Representation Learning Dataset for Arrhythmia Subtype Discovery,Shawn Tan;Guillaume Androz;Ahmad Chamseddine;Pierre Fecteau;Aaron Courville;Yoshua Bengio;Joseph Paul Cohen,shawn@wtf.sg;guillaume.androz@icentia.com;doctor.ahmad89@gmail.com;pierre.fecteau@icentia.com;aaron.courville@gmail.com;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,3;3,,Reject,0,2,1.0,yes,9/25/19,University of Montreal;Icentia Inc.;;Icentia;University of Montreal;Mila;Stanford University,representation learning;healthcare;medical;clinical;dataset;ecg;cardiology;heart;discovery;anomaly detection;out of distribution,-1;-1;-1;-1;118;143;5,-1;-1;-1;-1;85;336;4,m;m,usa,usa,n,
3945,ICLR,2020,NADS: Neural Architecture Distribution Search for Uncertainty Awareness,Randy Ardywibowo;Shahin Boluki;Xinyu Gong;Zhangyang Wang;Xiaoning Qian,randyardywibowo@tamu.edu;s.boluki@tamu.edu;gong1994@tamu.edu;atlaswang@tamu.edu;xqian@tamu.edu,8;1;3,,Reject,0,4,1.0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;Texas A&M;Texas A&M,Neural Architecture Search;Bayesian ensembling;out-of-distribution detection;uncertainty quantification;density estimation,46;46;46;46;46,177;177;177;177;177,m;m,NAN,NAN,n,11
3946,ICLR,2020,Learning World Graph Decompositions To Accelerate Reinforcement Learning,Wenling Shang;Alex Trott;Stephan Zheng;Caiming Xiong;Richard Socher,w.shang@uva.nl;atrott@salesforce.com;stephan.zheng@salesforce.com;cxiong@salesforce.com;richard@socher.org,6;3;3,,Reject,0,8,0.0,yes,9/25/19,University of Amsterdam;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,environment decomposition;subgoal discovery;generative modeling;reinforcement learning;unsupervised learning,143;-1;-1;-1;-1,62;-1;-1;-1;-1,f;m,NAN,NAN,n,10;5
3947,ICLR,2020,Group-Transformer: Towards A Lightweight Character-level Language Model,Sungrae Park;Geewook Kim;Junyeop Lee;Junbum Cha;Ji-Hoon Kim Hwalsuk Lee,sungrae.park@navercorp.com;geewook@sys.i.kyoto-u.ac.jp;junyeop.lee@navercorp.com;junbum.cha@navercorp.com;genesis.kim@navercorp.com;hwalsuk.lee@navercorp.com,6;6;1,,Reject,0,10,0.0,yes,9/25/19,NAVER;Kyoto University;NAVER;NAVER;NAVER;NAVER,Transformer;Lightweight model;Language Modeling;Character-level language modeling,-1;168;-1;-1;-1;-1,-1;65;-1;-1;-1;-1,m;m,europe,gr,n,8;3
3948,ICLR,2020,Learning DNA folding patterns with Recurrent Neural Networks ,Michal Rozenwald;Aleksandra Galitsyna;Ekaterina Khrameeva;Grigory Sapunov;Mikhail S. Gelfand,michal.rozenwald@gmail.com;agalitzina@gmail.com;ekhrameeva@gmail.com;grigory.sapunov@gmail.codelfm;mikhail.gelfand@gmail.com,1;3;3,,Reject,0,5,0.0,yes,9/25/19,Higher School of Economics;;;;Higher School of Economics,Machine Learning;Recurrent Neural Networks;3D chromatin structure;topologically associating domains;computational biology.,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,asia,in,n,
3949,ICLR,2020,TSInsight: A local-global attribution framework for interpretability in time-series data,Shoaib Ahmed Siddiqui;Dominique Mercier;Andreas Dengel;Sheraz Ahmed,shoaib_ahmed.siddiqui@dfki.de;dominique.mercier@dfki.de;andreas.dengel@dfki.de;sheraz.ahmed@dfki.de,3;1;1,,Reject,0,7,0.0,yes,9/25/19,German Research Center for AI;German Research Center for AI;German Research Center for AI;German Research Center for AI,Deep Learning;Representation Learning;Convolutional Neural Networks;Time-Series Analysis;Feature Importance;Visualization;Demystification,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,4
3950,ICLR,2020,Imagining the Latent Space of a Variational Auto-Encoders,Zezhen Zeng;Jonathon Hare;Adam Pr√ºgel-Bennett,zz8n17@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,3;3;1,,Reject,0,5,0.0,yes,9/25/19,University of Southampton;University of Southampton;University of Southampton,VAE;GAN,194;194;194,122;122;122,m;m,europe,uk,n,5
3951,ICLR,2020,Quantum Semi-Supervised Kernel Learning,Seyran Saeedi;Aliakbar Panahi;Tom Arodz,saeedis@vcu.edu;panahia@vcu.edu;tarodz@vcu.edu,6;6;6,,Reject,0,3,0.0,yes,9/25/19,Virginia Commonwealth University;Virginia Commonwealth University;Virginia Commonwealth University,quantum machine learning;semi-supervised learning;support vector machines,248;248;248,-1;-1;-1,f;m,usa,usa,n,
3952,ICLR,2020,Interpretable Network Structure for Modeling Contextual Dependency,Xindian Ma;Peng Zhang;Xiaoliu Mao;Yehua Zhang;Nan Duan;Yuexian Hou;Ming Zhou.,xindianma@tju.edu.cn;pzhang@tju.edu.cn;xiaoliumao@tju.edu.cn;yehua_zhang@tju.edu.cn;nanduan@microsoft.com;yxhou@tju.edu.cn;mingzhou@microsoft.com,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Microsoft;Zhejiang University;Microsoft,Language Model;Recurrent Neural Network;Separation Rank,39;39;39;39;-1;39;-1,107;107;107;107;-1;107;-1,u;m,NAN,NAN,n,3;1
3953,ICLR,2020,Frequency Principle: Fourier Analysis Sheds Light on Deep Neural Networks,Zhi-Qin John Xu;Yaoyu Zhang;Tao Luo;Yanyang Xiao;Zheng Ma,xuzhiqin@sjtu.edu.cn;yaoyu@ias.edu;luo196@purdue.edu;xyy82148@gmail.com;ma531@purdue.edu,6;3;3,,Reject,0,5,0.0,yes,9/25/19,"Shanghai Jiao Tong University;Institue for Advanced Study, Princeton;Purdue University;;Purdue University",deep learning;training behavior;Fourier analysis;generalization,30;-1;24;-1;24,157;-1;88;-1;88,m;m,usa,usa,n,1
3954,ICLR,2020,S-Flow GAN,Miron Yakov;Coscas Yona,yakov.miron@gmail.com;yona.coscas@gmail.com,1;3;1,,Reject,0,0,0.0,yes,9/25/19,Tel Aviv University;Elbit Systems Ltd,GAN;Image Generation;AI;Generative Models;CV,-1;-1,-1;-1,m;m,asia,in,n,10;5;4
3955,ICLR,2020,Role of two learning rates in convergence of model-agnostic meta-learning,Shiro Takagi;Yoshihiro Nagano;Yuki Yoshida;Masato Okada,takagi@mns.k.u-tokyo.ac.jp;nagano@mns.k.u-tokyo.ac.jp;yoshida@mns.k.u-tokyo.ac.jp;okada@edu.k.u-tokyo.ac.jp,3;3;1,,Reject,0,8,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,meta-learning;convergence,64;64;64;64,36;36;36;36,m;m,NAN,NAN,n,6;1
3956,ICLR,2020,Neural Subgraph Isomorphism Counting,Xin Liu;Haojie Pan;Mutian He;Yangqiu Song;Xin Jiang,xliucr@cse.ust.hk;hpanad@cse.ust.hk;mhear@cse.ust.hk;yqsong@cse.ust.hk;jiang.xin@huawei.com,6;3;3;3,,Reject,0,5,0.0,yes,9/25/19,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Huawei Technologies Ltd.,subgraph isomorphism;graph neural networks,-1;-1;-1;-1;-1,47;47;47;47;-1,m;m,NAN,NAN,n,8;10
3957,ICLR,2020,Semantic Hierarchy Emerges in the Deep Generative Representations for Scene Synthesis,Ceyuan Yang;Yujun Shen;Bolei Zhou,limbo0066@gmail.com;sy116@ie.cuhk.edu.hk;bzhou@ie.cuhk.edu.hk,6;3;6,,Reject,0,5,0.0,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,Feature visualization;feature interpretation;generative models,-1;316;316,-1;35;35,m;m,NAN,NAN,n,5;4
3958,ICLR,2020,Decoupling Adaptation from Modeling with Meta-Optimizers for Meta Learning,S√©bastien M.R. Arnold;Shariq Iqbal;Fei Sha,arnolds@usc.edu;shariqiqbal2810@gmail.com;fsha@google.com,3;3;6,,Reject,0,7,0.0,yes,9/25/19,University of Southern California;University of Southern California;Google,meta-learning;MAML;analysis;depth;meta-optimizers,36;36;-1,62;62;-1,m;f,NAN,NAN,n,6
3959,ICLR,2020,Black-box Adversarial Attacks with Bayesian Optimization,Satya Narayan Shukla;Anit Kumar Sahu;Devin Willmott;J. Zico Kolter,snshukla@cs.umass.edu;anit.sahu@gmail.com;devin.willmott@uky.edu;zkolter@cs.cmu.edu,6;3;1,,Reject,0,6,0.0,yes,9/25/19,"University of Massachusetts, Amherst;Amazon;University of Kentucky;Carnegie Mellon University",black-box adversarial attacks;bayesian optimization,24;-1;194;1,209;-1;490;27,m;m,usa,usa,n,11;4
3960,ICLR,2020,Adversarial Imitation Attack,Mingyi Zhou;Jing Wu;Yipeng Liu;Xiaolin Huang;Shuaicheng Liu;Liaqat Ali;Xiang Zhang;Ce Zhu,zhoumingyi@std.uestc.edu.cn;wujing@std.uestc.edu.cn;yipengliu@uestc.edu.cn;xiaolinhuang@sjtu.edu.cn;liushuaicheng@uestc.edu.cn;engr_liaqat183@yahoo.com;uestchero@uestc.edu.cn;eczhu@uestc.edu.cn,6;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Shanghai Jiao Tong University;University of Electronic Science and Technology of China;;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China,Adversarial examples;Security;Machine learning;Deep neural network;Computer vision,-1;-1;-1;30;-1;-1;-1;-1,628;628;628;157;628;-1;628;628,u;m,NAN,NAN,n,5;4
3961,ICLR,2020,LOGAN:  Latent Optimisation for Generative Adversarial Networks,Yan Wu;Jeff Donahue;David Balduzzi;Karen Simonyan;Timothy Lillicrap,yanwu@google.com;jeffdonahue@google.com;dbalduzzi@google.com;simonyan@google.com;countzero@google.com,6;6,,Reject,0,2,2.0,yes,9/25/19,Google;Google;Google;Google;Google,GAN;adversarial training;generative model;game theory,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
3962,ICLR,2020,Searching for Stage-wise Neural Graphs In the Limit,Xin Zhou;Dejing Dou;Boyang Li,chow459@gmail.com;doudejing@baidu.com;libo0001@gmail.com,3;1,,Reject,0,3,0.0,yes,9/25/19,University of Michigan;Baidu;Nanyang Technological University,neural architecture search;graphon;random graphs,-1;-1;43,-1;-1;49,m;m,asia,sg,y,10
3963,ICLR,2020,Attention Interpretability Across NLP Tasks,Shikhar Vashishth;Shyam Upadhyay;Gaurav Singh Tomar;Manaal Faruqui,shikhar@iisc.ac.in;shyamupa@google.com;gtomar@google.com;mfaruqui@google.com,6;6;1,,Reject,1,5,0.0,yes,9/25/19,Indian Institute of Science;Google;Google;Google,Attention;NLP;Interpretability,-1;-1;-1;-1,301;-1;-1;-1,m;m,NAN,NAN,y,8;3
3964,ICLR,2020,LSTOD: Latent Spatial-Temporal Origin-Destination prediction model and its applications in ride-sharing platforms,Fan Zhou;Haibo Zhou;Hongtu Zhu,zhoufan@mail.shufe.edu.cn;zhou@bios.unc.edu;zhuhongtu@didiglobal.com,1;6;1,,Reject,0,3,0.0,yes,9/25/19,"Shanghai University of Finance and Economics;University of North Carolina, Chapel Hill;Didi Chuxing",Origin-Destination Flow;Spatial Adjacent Convolution Network;Periodically Shift Attention Mechanism,-1;64;-1,852;-1;-1,m;m,NAN,NAN,n,8;10
3965,ICLR,2020,Unsupervised Universal Self-Attention Network for Graph Classification,Dai Quoc Nguyen;Tu Dinh Nguyen;Dinh Phung,dai.nguyen@monash.edu;tu.dinh.nguyen@monash.edu;dinh.phung@monash.edu,3;1;3,,Reject,6,7,0.0,yes,9/25/19,Monash University;Monash University;Monash University,Graph embedding;graph classification;universal self-attention network;graph neural network,92;92;92,75;75;75,m;m,australasia,au,n,8;10
3966,ICLR,2020,Efficacy of Pixel-Level OOD Detection for Semantic Segmentation,Matt Angus;Krzysztof Czarnecki;Rick Salay,m2angus@gsd.uwaterloo.ca;rsalay@gsd.uwaterloo.ca;k2czarne@gsd.uwaterloo.ca,3;1;3,,Reject,0,0,0.0,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo,Out-of-Distribution Detection;Semantic Segmentation;Deep Learning,30;30;30,235;235;235,m;m,canada,ca,n,2
3967,ICLR,2020,CURSOR-BASED ADAPTIVE QUANTIZATION FOR DEEP NEURAL NETWORK,Bapu Li(*);Yanwen Fan(*);Zhiyu Cheng;Yingze Bao (* means equal contribution),baopuli@baidu.com;fanyanwen@baidu.com;zhiyucheng@baidu.com;baoyingze@baidu.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Baidu;Baidu;Baidu;Baidu,,-1;-1;-1;-1,-1;-1;-1;-1,u;u,NAN,NAN,n,9
3968,ICLR,2020,MMD GAN with Random-Forest Kernels,Tao Huang;Zhen Han;Xu Jia;Hanyuan Hang,tao.huang2018@ruc.edu.cn;handarkholme@ruc.edu.cn;jiayushenyang@gmail.com;hanyuan0725@gmail.com,1;1;3,,Reject,0,0,0.0,yes,9/25/19,"University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;South China University of Technology;University of Twente",GANs;MMD;kernel;random forest;unbiased gradients,-1;-1;-1;143,-1;-1;501;247,u;u,europe,gr,y,5
3969,ICLR,2020,Hyperparameter Tuning and Implicit Regularization in Minibatch SGD,Samuel L Smith;Erich Elsen;Soham De,slsmith@google.com;eriche@google.com;sohamde@google.com,3;3;3,,Reject,1,4,0.0,yes,9/25/19,Google;Google;Google,SGD;momentum;batch size;learning rate;noise;temperature;implicit regularization;optimization;generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
3970,ICLR,2020,Quantum Optical Experiments Modeled by Long Short-Term Memory,Thomas Adler;Manuel Erhard;Mario Krenn;Johannes Brandstetter;Johannes Kofler;Sepp Hochreiter,adler@ml.jku.at;manuel.erhard@univie.ac.at;mario.krenn@univie.ac.at;brandstetter@ml.jku.at;kofler@ml.jku.at;hochreit@ml.jku.at,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Johannes Kepler University Linz;University of Vienna;University of Vienna;Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz,Recurrent Networks;LSTM;Sequence Analysis;Binary Classification,-1;194;194;-1;-1;-1,-1;134;134;-1;-1;-1,m;m,NAN,NAN,n,5
3971,ICLR,2020,Variational Hashing-based Collaborative Filtering with Self-Masking,Casper Hansen;Christian Hansen;Jakob Grue Simonsen;Stephen Alstrup;Christina Lioma,c.hansen@di.ku.dk;chrh@di.ku.dk;simonsen@di.ku.dk;s.alstrup@di.ku.dk;c.lioma@di.ku.dk,3;3;1,,Reject,0,4,0.0,yes,9/25/19,University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen,hashing;collaborative filtering;information retrieval;supervised learning,92;92;92;92;92,101;101;101;101;101,m;f,europe,dk,n,
3972,ICLR,2020,Customizing Sequence Generation with Multi-Task Dynamical Systems,Alex Bird;Christopher K. I. Williams,abird@turing.ac.uk;ckiw@inf.ed.ac.uk,6;6;6,,Reject,0,4,0.0,yes,9/25/19,Alan Turing Institute;University of Edinburgh,Time-series modelling;Dynamical systems;RNNs;Multi-task learning,-1;36,-1;30,m;m,europe,uk,n,
3973,ICLR,2020,Batch Normalization is a Cause of Adversarial Vulnerability,Angus Galloway;Anna Golubeva;Thomas Tanay;Medhat Moussa;Graham W. Taylor,gallowaa@uoguelph.ca;agolubeva@perimeterinstitute.ca;thomas.tanay.13@ucl.ac.uk;mmoussa@uoguelph.ca;gwtaylor@uoguelph.ca,3;1;3,,Reject,3,8,0.0,yes,9/25/19,University of Guelph;Perimeter Institute;University College London;University of Guelph;University of Guelph,batch normalization;adversarial examples;robustness,248;-1;52;248;248,558;-1;-1;558;558,m;m,canada,ca,n,4
3974,ICLR,2020,Enhancing Language Emergence through Empathy,Marie Ossenkopf,mos@vs.uni-kassel.de,1;1;1,,Reject,0,1,0.0,yes,9/25/19,University of Kassel,multi-agent deep reinforcement learning;emergent communication;auxiliary tasks,445,94,f;u,europe,uk,n,3
3975,ICLR,2020,A Data-Efficient Mutual Information Neural Estimator for Statistical Dependency Testing,Xiao Lin;Indranil Sur;Samuel A. Nastase;Uri Hasson;Ajay Divakaran;Mohamed R. Amer,xiao.lin@sri.com;indranil.sur@sri.com;mohamed.rabie.amer@gmail.com;ajay.divakaran@sri.com;snastase@princeton.edu;hasson@princeton.edu,1;6;3,,Reject,0,4,0.0,yes,9/25/19,SRI International;SRI International;Robust.AI;SRI International;Princeton University;Princeton University,mutual information;fMRI;inter-subject correation;mutual information neural estimation;meta-learning;statistical test of dependency,-1;-1;-1;-1;30;30,-1;-1;-1;-1;6;6,m;m,usa,usa,y,6;1
3976,ICLR,2020,SMiRL: Surprise Minimizing RL in Entropic Environments,Glen Berseth;Daniel Geng;Coline Devin;Dinesh Jayaraman;Chelsea Finn;Sergey Levine,gberseth@gmail.com;dangengdg@berkeley.edu;coline.devin@gmail.com;dinesh.jayaraman123@gmail.com;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;DeepMind;University of Pennsylvania;University of California Berkeley;University of California Berkeley,intrinsic motivation;reinforcement learning;unsurpervised RL,-1;-1;-1;20;-1;-1,13;13;-1;11;13;13,m;m,usa,usa,n,11
3977,ICLR,2020,The Role of Embedding Complexity in Domain-invariant Representations,Ching-Yao Chuang;Antonio Torralba;Stefanie Jegelka,cychuang@mit.edu;torralba@mit.edu;stefje@mit.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,domain adaptation;domain-invariant representations;model complexity;theory;deep learning,5;5;5,5;5;5,m;f,usa,usa,y,1
3978,ICLR,2020,Learning to Infer User Interface Attributes from Images,Philippe Schlattner;Pavol Bielik;Martin Vechev,pschlatt@ethz.ch;pavol.bielik@inf.ethz.ch;martin.vechev@inf.ethz.ch,1;3;8,,Reject,0,8,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
3979,ICLR,2020,Semi-supervised Learning by Coaching,Hieu Pham;Quoc V. Le,hyhieu@cmu.edu;qvl@google.com,3;3;3,,Reject,0,7,0.0,yes,9/25/19,Carnegie Mellon University;Google,semi-supervised;teacher;student;label propagation;image classification,1;-1,27;-1,m;m,NAN,NAN,n,
3980,ICLR,2020,Learning Representations in Reinforcement Learning: an Information Bottleneck Approach,Yingjun Pei;Xinwen Hou,peiyingjun4@gmail.com;xwhou@nlpr.ia.ac.cn,3;6;3,,Reject,0,4,0.0,yes,9/25/19,"Beijing University of Post and Telecommunication;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",representation learning;reinforcement learning;information bottleneck,-1;30,-1;-1,u;u,NAN,NAN,y,1
3981,ICLR,2020,Evaluating Lossy Compression Rates of Deep Generative Models,Sicong Huang;Alireza Makhzani;Yanshuai Cao;Roger Grosse,huang@cs.toronto.edu;a.makhzani@gmail.com;yanshuai.cao@borealisai.com;rgrosse@cs.toronto.edu,3;8;3,,Reject,0,4,0.0,yes,9/25/19,University of Toronto;;Borealis AI;University of Toronto,Deep Learning;Generative Models;Information Theory;Rate Distortion Theory,18;-1;-1;18,18;-1;-1;18,m;m,canada,ca,n,5;4
3982,ICLR,2020,Kronecker Attention Networks,Hongyang Gao;Zhengyang Wang;Shuiwang Ji,hongyang.gao@tamu.edu;zhengyang.wang@tamu.edu;sji@tamu.edu,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M,,46;46;46,177;177;177,m;m,NAN,NAN,y,8
3983,ICLR,2020,Stochastic Neural Physics Predictor,Piotr Tatarczyk;Damian Mrowca;Li Fei-Fei;Daniel L. K. Yamins;Nils Thuerey,piotr.tatarczyk@tum.de;mrowca@stanford.edu;feifeili@cs.stanford.edu;yamins@stanford.edu;nils.thuerey@tum.de,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Technical University Munich;Stanford University;Stanford University;Stanford University;Technical University Munich,physics prediction;forward dynamics;stochastic environments;dropout,-1;5;5;5;-1,-1;4;4;4;-1,m;m,NAN,NAN,n,10
3984,ICLR,2020,Spectral Nonlocal Block for Neural Network,Lei Zhu;Qi She;Lidan Zhang;Ping guo,lei1.zhu@intel.com;qi.she@intel.com;lidan.zhang@intel.com;ping.guo@intel.com,6;6;3;1,,Reject,0,6,0.0,yes,9/25/19,Intel;Intel;Intel;Intel,Nonlocal Neural Network;Image Classification;Action Recgonition,-1;-1;-1;-1,-1;-1;-1;-1,m;u,NAN,NAN,n,2;10
3985,ICLR,2020,Metagross: Meta Gated Recursive Controller Units for Sequence Modeling,Yi Tay;Yikang Shen;Alvin Chan;Yew Soon Ong,ytay017@e.ntu.edu.sg;yikang.shn@gmail.com;guoweial001@e.ntu.edu.sg;asysong@ntu.edu.sg,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Nanyang Technological University;University of Montreal;Nanyang Technological University;Nanyang Technological University,Deep Learning;Natural Language Processing;Recurrent Neural Networks,43;118;43;43,49;85;49;49,m;m,asia,sg,n,3
3986,ICLR,2020,Diving into Optimization of Topology in Neural Networks,Kun Yuan;Quanquan Li;Yucong Zhou;Jing Shao;Junjie Yan,yuankun@sensetime.com;liquanquan@sensetime.com;zhouyucong@sensetime.com;shaojing@sensetime.com;yanjunjie@sensetime.com,6;6;3;3,,Reject,0,7,0.0,yes,9/25/19,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
3987,ICLR,2020,The Usual Suspects? Reassessing Blame for VAE Posterior Collapse,Bin Dai;Ziyu Wang;David Wipf,daib13@mails.tsinghua.edu.cn;wzy196@gmail.com;davidwipf@gmail.com,3;8;3,,Reject,0,8,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Amazon",variational autoencoder;posterior collapse,4;4;-1,23;23;-1,m;m,NAN,NAN,y,1;5
3988,ICLR,2020,Generative Restricted Kernel Machines,Arun Pandey;Joachim Schreurs;Johan A.K. Suykens,arun.pandey@esat.kuleuven.be;joachim.schreurs@esat.kuleuven.be;johan.suykens@esat.kuleuven.be,6;3;3,,Reject,0,5,1.0,yes,9/25/19,KU Leuven;KU Leuven;KU Leuven,Generative models;Kernel methods;Deep learning,143;143;143,45;45;45,m;m,europe,be,n,5
3989,ICLR,2020,GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation,Marc Brockschmidt,mabrocks@microsoft.com,6;8;3,,Reject,0,14,0.0,yes,9/25/19,Microsoft,Graph Neural Networks,-1,-1,m;u,NAN,NAN,n,10
3990,ICLR,2020,Which Tasks Should Be Learned Together in Multi-task Learning?,Trevor Standley;Amir R. Zamir;Dawn Chen;Leonidas Guibas;Jitendra Malik;Silvio Savarese,tstand@cs.stanford.edu;zamir@cs.stanford.edu;sdawnchen@gmail.com;guibas@cs.stanford.edu;malik@eecs.berkeley.edu;ssilvio@stanford.edu,6;6;6,,Reject,0,4,0.0,yes,9/25/19,Stanford University;Stanford University;;Stanford University;University of California Berkeley;Stanford University,multi-task learning;Computer Vision,5;5;-1;5;-1;5,4;4;-1;4;13;4,m;m,usa,usa,n,2
3991,ICLR,2020,Distillation $\approx$ Early Stopping? Harvesting Dark Knowledge Utilizing Anisotropic Information Retrieval For Overparameterized NN,Bin Dong;Jikai Hou;Yiping Lu;Zhihua Zhang,dongbin@math.pku.edu.cn;houjikai@pku.edu.cn;yplu@stanford.edu;zhzhang@math.pku.edu.cn,3;8;1,,Reject,0,10,0.0,yes,9/25/19,Peking University;Peking University;Stanford University;Peking University,Distillation;Learning Thoery;Corrupted Label,14;14;5;14,24;24;4;24,m;m,asia,cn,y,1
3992,ICLR,2020,How Does Learning Rate Decay Help Modern Neural Networks?,Kaichao You;Mingsheng Long;Jianmin Wang;Michael I. Jordan,youkaichao@gmail.com;mingsheng@tsinghua.edu.cn;jimwang@tsinghua.edu.cn;jordan@cs.berkeley.edu,3;1;1,,Reject,0,0,0.0,yes,9/25/19,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of California Berkeley",Learning rate decay;Optimization;Explainability;Deep learning;Transfer learning,-1;4;4;-1,-1;23;23;13,m;m,usa,usa,n,1
3993,ICLR,2020,Incorporating Horizontal Connections in Convolution by Spatial Shuffling,Ikki Kishida;Hideki Nakayama,kishida@nlab.ci.i.u-tokyo.ac.jp;nakayama@nlab.ci.i.u-tokyo.ac.jp,3;3;3,,Reject,0,0,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo,shuffle;convolution;receptive field;classification;horizontal connections,64;64,36;36,m;m,NAN,NAN,n,
3994,ICLR,2020,Learning Cluster Structured Sparsity by Reweighting,Yulun Jiang;Lei Yu;Haijian Zhang;Zhou Liu,yljblues@whu.edu.cn;ly.wd@whu.edu.cn;haijian.zhang@whu.edu.cn;liuzhou@whu.edu.cn,1;6;3,,Reject,0,3,0.0,yes,9/25/19,Wuhan University;Wuhan University;Wuhan University;Wuhan University,Sparse Recovery;Sparse Representation;Structured Sparsity,194;194;194;194,354;354;354;354,u;u,europe,uk,n,
3995,ICLR,2020,Continuous Meta-Learning without Tasks,James Harrison;Apoorva Sharma;Chelsea Finn;Marco Pavone,jharrison@stanford.edu;apoorva@stanford.edu;cbfinn@cs.stanford.edu;pavone@stanford.edu,3;6;8,,Reject,0,4,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,Meta-learning;Continual learning;changepoint detection;Bayesian learning,5;5;5;5,4;4;4;4,m;m,usa,usa,n,6;2;11
3996,ICLR,2020,Generative Adversarial Networks For Data Scarcity Industrial Positron Images With Attention,Mingwei Zhu;Min Zhao;Min Yao;Ruipeng Guo,zhumingwei@nuaa.edu.cn;xymzhao@126.com;ym_nuaa@163.com;rpguo@nuaa.edu.cn,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Nanjing University of Aeronautics and Astronautics;126;163;Nanjing University of Aeronautics and Astronautics,,52;-1;-1;52,1024;-1;-1;1024,u;u,NAN,NAN,n,6;8;4
3997,ICLR,2020,Support-guided Adversarial Imitation Learning,Ruohan Wang;Carlo Ciliberto;Pierluigi Amadori;Yiannis Demiris,r.wang16@ic.ac.uk;c.ciliberto@imperial.ac.uk;p.amadori@imperial.ac.uk;y.demiris@imperial.ac.uk,6;6;1,,Reject,0,3,0.0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,Adversarial Imitation Learning;Reinforcement Learning;Learning from Demonstrations,52;52;52;52,10;10;10;10,m;m,europe,uk,y,4
3998,ICLR,2020,IS THE LABEL TRUSTFUL: TRAINING BETTER DEEP LEARNING MODEL VIA UNCERTAINTY MINING NET,Yang Sun;Abhishek Kolagunda;Steven Eliuk;Xiaolong Wang,yang.sun1@ibm.com;abhishek.kolagunda@ibm.com;steven.eliuk@ibm.com;visionxiaolong@gmail.com,3;1;6,,Reject,0,5,0.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines,Semi-supervised Learning;Robust Learning;Deep Generative Model,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n,5
3999,ICLR,2020,Learning with Social Influence through  Interior Policy Differentiation,Hao Sun;Bo Dai;Jiankai Sun;Zhenghao Peng;Guodong Xu;Dahua Lin;Bolei Zhou,sh018@ie.cuhk.edu.hk;doubledaibo@gmail.com;sunjiankai@sensetime.com;pengzh@ie.cuhk.edu.hk;xg018@ie.cuhk.edu.hk;dhlin@ie.cuhk.edu.hk;bzhou@ie.cuhk.edu.hk,3;3;3,,Reject,1,4,0.0,yes,9/25/19,The Chinese University of Hong Kong;Nanyang Technological University;SenseTime Group Limited;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,Reinforcement Learning;Social Uniqueness;Policy Differentiation,316;43;-1;316;316;316;316,35;49;-1;35;35;35;35,m;m,NAN,NAN,y,
4000,ICLR,2020,Selfish Emergent Communication,Michael Noukhovitch;Travis LaCroix;Aaron Courville,michael.noukhovitch@umontreal.ca;tlacroix@uci.edu;aaron.courville@gmail.com,3;1;6,,Reject,0,23,0.0,yes,9/25/19,"University of Montreal;University of California, Irvine;University of Montreal",multi agent reinforcement learning;emergent communication;game theory,118;-1;118,85;96;85,m;m,canada,ca,n,
4001,ICLR,2020,Coordinated Exploration via Intrinsic Rewards for Multi-Agent Reinforcement Learning,Shariq Iqbal;Fei Sha,shariqiqbal2810@gmail.com;fsha@google.com,6;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Southern California;Google,multi-agent reinforcement learning;multi-agent;exploration;intrinsic motivation;MARL;coordinated exploration,36;-1,62;-1,m;m,NAN,NAN,n,
4002,ICLR,2020,Mutual Exclusivity as a Challenge for Deep Neural Networks,Kanishk Gandhi;Brenden Lake,kanishk.gandhi@nyu.edu;brenden@nyu.edu,6;8;6,,Reject,0,8,0.0,yes,9/25/19,New York University;New York University,Cognitive Science;Deep Learning;Word Learning;Lifelong Learning,22;22,29;29,m;m,usa,usa,n,
4003,ICLR,2020,The Differentiable Cross-Entropy Method,Brandon Amos;Denis Yarats,brandon.amos.cs@gmail.com;denisyarats@cs.nyu.edu,3;3;3,,Reject,1,6,0.0,yes,9/25/19,Facebook;New York University,machine learning;differentiable optimization;control;reinforcement learning,-1;22,-1;29,m;m,usa,usa,y,9
4004,ICLR,2020,DS-VIC: Unsupervised Discovery of Decision States for Transfer in RL,Nirbhay Modhe;Prithvijit Chattopadhyay;Mohit Sharma;Abhishek Das;Devi Parikh;Dhruv Batra;Ramakrishna Vedantam,nirbhaym@gatech.edu;prithvijit3@gatech.edu;sharma.mohit.916@gmail.com;abhshkdz@gatech.edu;parikh@gatech.edu;dbatra@gatech.edu;ramav@fb.com,3;3;3;3,,Reject,0,6,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Facebook,reinforcement learning;probabilistic inference;variational inference;intrinsic control;transfer learning,13;13;-1;13;13;13;-1,38;38;-1;38;38;38;-1,m;m,NAN,NAN,y,1
4005,ICLR,2020,Exploration Based Language Learning for Text-Based Games,Andrea Madotto;Mahdi Namazifar;Joost Huizinga;Piero Molino;Adrien Ecoffet;Huaixiu Zheng;Alexandros Papangelis;Dian Yu;Chandra Khatri;Gokhan Tur,amadotto@connect.ust.hk;mahdin@uber.com;jhuizinga@uber.com;piero@uber.com;adrienle@uber.com;huaixiu.zheng@uber.com;apapangelis@uber.com;dianyu@ucdavis.edu;chandrak@uber.com;gokhan@uber.com,6;3;3,,Reject,0,5,0.0,yes,9/25/19,"The Hong Kong University of Science and Technology;Uber;Uber;Uber;Uber;Uber;Uber;University of California, Davis;Uber;Uber",Text-Based Games;Exploration;Language Learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,47;-1;-1;-1;-1;-1;-1;55;-1;-1,m;m,southamerica,br,n,3
4006,ICLR,2020,Representation Learning with Multisets,Vasco Portilheiro,vascop@stanford.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Stanford University,multisets;fuzzy sets;permutation invariant;representation learning;containment;partial order;clustering,5,4,m;u,usa,usa,y,1
4007,ICLR,2020,Deep Gradient Boosting -- Layer-wise Input Normalization of Neural Networks,Erhan Bilal,ebilal@us.ibm.com,3;3;3,,Reject,1,3,0.0,yes,9/25/19,International Business Machines,sgd;dgb;boosting;batch norm;input norm,-1,-1,m;u,NAN,NAN,n,1
4008,ICLR,2020,Multi-Dimensional Explanation of Reviews,Diego Antognini;Claudiu Musat;Boi Faltings,diego.antognini@epfl.ch;claudiu.musat@swisscom.com;boi.faltings@epfl.ch,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swisscom;Swiss Federal Institute of Technology Lausanne,deep learning;explanation;interpretability;reviews;multi-aspect;sentiment analysis;mask,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3
4009,ICLR,2020,ISBNet: Instance-aware Selective Branching Networks,Shaofeng Cai;Yao Shu;Wei Wang;Gang Chen;Beng Chin Ooi,shaofeng@comp.nus.edu.sg;shuyao@comp.nus.edu.sg;wangwei@comp.nus.edu.sg;cg@zju.edu.cn;ooibc@comp.nus.edu.sg,3;3,,Reject,0,2,0.0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;Zhejiang University;National University of Singapore,neural networks;neural architecture search;efficient inference,17;17;17;39;17,25;25;25;107;25,m;m,asia,sg,n,
4010,ICLR,2020,Inferring Dynamical Systems with Long-Range Dependencies through Line Attractor Regularization,Dominik Schmidt;Georgia Koppe;Max Beutelspacher;Daniel Durstewitz,dominik.schmidt@zi-mannheim.de;georgia.koppe@zi-mannheim.de;max.beutelspacher@mailbox.org;daniel.durstewitz@zi-mannheim.de,3;6;1,,Reject,0,4,0.0,yes,9/25/19,Central Institute of Mental Health;Central Institute of Mental Health;;Central Institute of Mental Health,Recurrent Neural Networks;Nonlinear State Space Models;Generative Models;Long short-term memory;vanishing/exploding gradient problem;Nonlinear dynamics;Interpretable machine learning;Time series analysis,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4011,ICLR,2020,SoftAdam: Unifying SGD and Adam for better stochastic gradient descent,Abraham J. Fetterman;Christina H. Kim;Joshua Albrecht,abe@sourceress.co;christina@sourceress.co;josh@sourceress.co,3;1;3,,Reject,1,3,0.0,yes,9/25/19,Princeton University;;University of Pittsburgh,Optimization;SGD;Adam;Generalization;Deep Learning,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,3
4012,ICLR,2020,BERT-AL: BERT for Arbitrarily Long Document Understanding,Ruixuan Zhang;Zhuoyu Wei;Yu Shi;Yining Chen,903276268@pku.edu.cn;zhuoyu.wei@microsoft.com;yushi@microsoft.com;yining.chen@microsoft.com,3;3;3;6,,Reject,0,0,0.0,yes,9/25/19,Peking University;Microsoft;Microsoft;Microsoft,,14;-1;-1;-1,24;-1;-1;-1,u;u,NAN,NAN,n,8;3
4013,ICLR,2020,NEURAL EXECUTION ENGINES,Yujun Yan;Kevin Swersky;Danai Koutra;Parthasarathy Ranganathan;Milad Hashemi,yujunyan@umich.edu;kswersky@google.com;dkoutra@umich.edu;parthas@google.com;miladh@google.com,3;3;1,,Reject,0,4,0.0,yes,9/25/19,University of Michigan;Google;University of Michigan;Google;Google,neural computation;strong generalization;numerical reasoning,7;-1;7;-1;-1,21;-1;21;-1;-1,f;m,NAN,NAN,n,8;1;10
4014,ICLR,2020,Learning Good Policies By Learning Good Perceptual Models,Yilun Du;Phillip Isola,yilundu@mit.edu;phillipi@mit.edu,1;3;1,,Reject,0,0,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,visual representation learning;reinforcement learning;curiosity,5;5,5;5,m;m,usa,usa,n,
4015,ICLR,2020,Quaternion Equivariant Capsule Networks for 3D Point Clouds,Yongheng Zhao;Tolga Birdal;Jan Eric Lenssen;Emanuele Menegatti;Leonidas Guibas;Federico Tombari,zhao@dei.unipd.it;tbirdal@stanford.edu;janeric.lenssen@udo.edu;emg@dei.unipd.it;guibas@cs.stanford.edu;tombari@google.com,3;6;6,,Reject,0,4,0.0,yes,9/25/19,Universita' degli studi di Padova;Stanford University;TU Dortmund University;Universita' degli studi di Padova;Stanford University;Google,3d;capsule networks;pointnet;quaternion;equivariant networks;rotations;local reference frame,-1;5;248;-1;5;-1,-1;4;354;-1;4;-1,m;m,NAN,NAN,y,2
4016,ICLR,2020,Informed Temporal Modeling via Logical Specification of Factorial LSTMs,Hongyuan Mei;Guanghui Qin;Minjie Xu;Jason Eisner,hongyuanmei@gmail.com;gqin@jhu.edu;chokkyvista06@gmail.com;jason@cs.jhu.edu,3;3;1,,Reject,0,1,0.0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;Bloomberg LP;Johns Hopkins University,factorized LSTM;temporal point process;event streams;structural bias;Datalog,73;73;-1;73,12;12;-1;12,m;m,usa,usa,n,1;10
4017,ICLR,2020,Needles in Haystacks: On Classifying Tiny Objects in Large Images,Nick Pawlowski;Suvrat Bhooshan;Nicolas Ballas;Francesco Ciompi;Ben Glocker;Michal Drozdzal,pawlowski.nick@gmail.com;sbh@fb.com;ballasn@fb.com;f.ciompi@gmail.com;b.glocker@imperial.ac.uk;mdrozdzal@fb.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Google;Facebook;Facebook;Radboud University Medical Center;Imperial College London;Facebook,computer vision;CNNs;small objects;low signal-to-noise image classification,-1;-1;-1;248;52;-1,-1;-1;-1;-1;10;-1,m;m,NAN,NAN,n,2;1
4018,ICLR,2020,Probabilistic View of Multi-agent Reinforcement Learning: A Unified Approach,Shubham Gupta;Ambedkar Dukkipati,shubhamg@iisc.ac.in;ambedkar@iisc.ac.in,3;1;3,,Reject,1,3,0.0,yes,9/25/19,Indian Institute of Science;Indian Institute of Science,multi-agent reinforcement learning;maximum entropy reinforcement learning,-1;-1,301;301,m;m,NAN,NAN,n,10
4019,ICLR,2020,Hope For The Best But Prepare For The Worst: Cautious Adaptation In RL Agents,Jesse Zhang;Brian Cheung;Chelsea Finn;Dinesh Jayaraman;Sergey Levine,jessezhang@berkeley.edu;bcheung@berkeley.edu;cbfinn@cs.stanford.edu;dineshjayaraman@berkeley.edu;svlevine@eecs.berkeley.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley;University of California Berkeley,safety;risk;uncertainty;adaptation,-1;-1;5;-1;-1,13;13;4;13;13,m;m,usa,usa,n,
4020,ICLR,2020,Abstractive Dialog Summarization with Semantic Scaffolds,Lin Yuan;Zhou Yu,yuanlinzju@gmail.com;joyu@ucdavis.edu,1;1;3,,Reject,0,0,0.0,yes,9/25/19,"Zhejiang University;University of California, Davis",Abstractive Summarization;Dialog;Multi-task Learning,-1;-1,-1;55,m;f,usa,usa,n,
4021,ICLR,2020,Relative Pixel Prediction For Autoregressive Image Generation,Wang Ling;Chris Dyer;Lei Yu;Lingpeng Kong;Dani Yogatama;Susannah Young,lingwang@google.com;cdyer@google.com;leiyu@google.com;lingpenk@google.com;dyogatama@google.com;susannahy@google.com,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Image Generation;Autoregressive,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,
4022,ICLR,2020,Integrative Tensor-based Anomaly Detection System For Satellites,Youjin Shin;Sangyup Lee;Shahroz Tariq;Myeong Shin Lee;OkchulJung;Daewon Chung;Simon Woo,youjin.shin.1@stonybrook.edu;shahroz@g.skku.edu;sangyup.lee@g.skku.edu;mslee@kari.re.kr;ocjung@kari.re.kr;dwchung@kari.re.kr;swoo@g.skku.edu,1;3,,Reject,0,0,0.0,yes,9/25/19,"State University of New York, Stony Brook;Peking University;Peking University;;;;Peking University",Tensor decomposition;Anomaly detection,-1;14;14;-1;-1;-1;14,-1;24;24;-1;-1;-1;24,f;m,asia,cn,n,
4023,ICLR,2020,Gram-Gauss-Newton Method: Learning Overparameterized Neural Networks for Regression Problems,Tianle Cai*;Ruiqi Gao*;Jikai Hou*;Siyu Chen;Dong Wang;Di He;Zhihua Zhang;Liwei Wang,caitianle1998@pku.edu.cn;grq@pku.edu.cn;1600010681@pku.edu.cn;siyuchen@pku.edu.cn;wangdongcis@pku.edu.cn;di_he@pku.edu.cn;zhzhang@math.pku.edu.cn;wanglw@cis.pku.edu.cn,3;3;3;6;1,,Reject,0,6,0.0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;Peking University;Peking University;Peking University;Peking University,Deep learning;Optimization;Second-order method;Neural Tangent Kernel regression,14;14;14;14;14;14;14;14,24;24;24;24;24;24;24;24,m;m,asia,cn,y,9
4024,ICLR,2020,A Greedy Approach to Max-Sliced Wasserstein GANs,Andr√°s Horv√°th,horvath.andras@itk.ppke.hu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Pazmany Peter catholic University,GEnerative Adversarial Networks;GANs;Wasserstein distances;Sliced Wasserstein Distance;Max-sliced Wasserstein distance,-1,-1,m,NAN,NAN,n,5;4
4025,ICLR,2020,Improving Sequential Latent Variable Models with Autoregressive Flows,Joseph Marino;Lei Chen;Jiawei He;Stephan Mandt,jmarino@caltech.edu;lei_chen_4@sfu.ca;jiawei_he_2@sfu.ca;stephan.mandt@gmail.com,6;3;6,,Reject,0,4,0.0,yes,9/25/19,"California Institute of Technology;Simon Fraser University;Simon Fraser University;University of California, Irvine",Autoregressive Flows;Sequence Modeling;Latent Variable Models;Video Modeling;Variational Inference,143;52;52;-1,2;272;272;96,m;m,usa,usa,n,
4026,ICLR,2020,Symmetry and Systematicity,Jeff Mitchell;Jeff Bowers,jeff.mitchell@bristol.ac.uk;j.bowers@bristol.ac.uk,1;1;3,,Reject,0,9,0.0,yes,9/25/19,University of Bristol;University of Bristol,symmetry;systematicity;convolution;symbols;generalisation,118;118,87;87,m;m,europe,uk,n,
4027,ICLR,2020,Towards Interpretable Evaluations: A Case Study of Named Entity Recognition,Jinlan Fu;Pengfei Liu;Xuanjing Huang,fujl16@fudan.edu.cn;pfliu14@fudan.edu.cn;xjhuang@fudan.edu.cn,3;3;8,,Reject,0,7,0.0,yes,9/25/19,Fudan University;Fudan University;Fudan University,interpretable evaluation;dataset biases;model biases;NER,73;73;73,109;109;109,f;f,asia,cn,n,3
4028,ICLR,2020,Bootstrapping the Expressivity with Model-based Planning,Kefan Dong;Yuping Luo;Tengyu Ma,dkf16@mails.tsinghua.edu.cn;yupingl@cs.princeton.edu;tengyuma@cs.stanford.edu,6;3;3,,Reject,0,5,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Princeton University;Stanford University",reinforcement learning theory;model-based reinforcement learning;planning;expressivity;approximation theory;deep reinforcement learning theory,4;30;5,23;6;4,m;m,usa,usa,y,1
4029,ICLR,2020,Score and Lyrics-Free Singing Voice Generation,Jen-Yu Liu;Yu-Hua Chen;Yin-Cheng Yeh;Yi-Hsuan Yang,ciauaishere@gmail.com;r08946011@ntu.edu.tw;deanyeh.ee01@g2.nctu.edu.tw;affige@gmail.com,3;3;1;3,,Reject,0,7,0.0,yes,9/25/19,National Taiwan University;Nanyang Technological University;National Chiao Tung University;National Tsing Hua University,singing voice generation;GAN;generative adversarial network,-1;43;118;194,-1;49;564;365,u;m,asia,tw,n,5;4
4030,ICLR,2020,RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling,Jinsung Yoon;Sercan O. Arik;Tomas Pfister,jsyoon0823@gmail.com;soarik@google.com;tpfister@google.com,6;3,,Reject,0,3,0.0,yes,9/25/19,Google;Google;Google,Interpretability;Explanable AI;Explanability,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4031,ICLR,2020,Characterizing Missing Information in Deep Networks Using Backpropagated Gradients,Gukyeong Kwon;Mohit Prabhushankar;Dogancan Temel;Ghassan AlRegib,gukyeong.kwon@gatech.edu;mohit.p@gatech.edu;cantemel@gatech.edu;alregib@gatech.edu,3;1;3,,Reject,0,0,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Representation learning;Missing Information in Deep Networks;Gradient-based Representation,13;13;13;13,38;38;38;38,m;m,usa,usa,n,
4032,ICLR,2020,Improving Multi-Manifold GANs with a Learned Noise Prior,Matthew Amodio;Smita Krishnaswamy,matthew.amodio@yale.edu;smita.krishnaswamy@yale.edu,3;8;6,,Reject,0,3,0.0,yes,9/25/19,Yale University;Yale University,GAN;generative adversarial network;ensemble,73;73,8;8,m;f,europe,fi,n,5;4
4033,ICLR,2020,Unsupervised Domain Adaptation through Self-Supervision,Yu Sun;Eric Tzeng;Trevor Darrell;Alexei A. Efros,yusun@berkeley.edu;etzeng@eecs.berkeley.edu;trevor@eecs.berkeley.edu;efros@eecs.berkeley.edu,6;6;3,,Reject,2,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,unsupervised domain adaptation,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n,2
4034,ICLR,2020,Adversarial Paritial Multi-label Learning,Yan Yan;Yuhong Guo,yanyan.nwpu@gmail.com;yuhongguo.cs@gmail.com,8;3;3,,Reject,0,0,0.0,yes,9/25/19,Northwestern Polytechnical University;Carleton University,,-1;194,-1;535,m;f,canada,ca,y,8;5;4
4035,ICLR,2020,Iterative Target Augmentation for Effective Conditional Generation,Kevin Yang;Wengong Jin;Kyle Swanson;Regina Barzilay;Tommi Jaakkola,yangk@berkeley.edu;wengong@csail.mit.edu;swansonk.14@gmail.com;regina@csail.mit.edu;tommi@csail.mit.edu,3;6;6,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology,data augmentation;generative models;self-training;molecular optimization;program synthesis,-1;5;-1;5;5,13;5;-1;5;5,m;m,usa,usa,n,5
4036,ICLR,2020,Hyperbolic Discounting and Learning Over Multiple Horizons,William Fedus;Carles Gelada;Yoshua Bengio;Marc G. Bellemare;Hugo Larochelle,liam.fedus@gmail.com;carlesgelada@hotmail.com;yoshua.bengio@mila.quebec;bellemare@google.com;hugolarochelle@google.com,6;6;3,,Reject,0,7,0.0,yes,9/25/19,University of Montreal;;Mila;Google;Google,Deep learning;reinforcement learning;discounting;hyperbolic discounting;auxiliary tasks,-1;-1;143;-1;-1,-1;-1;336;-1;-1,m;m,NAN,NAN,y,
4037,ICLR,2020,Can I Trust the Explainer? Verifying Post-Hoc Explanatory Methods,Oana-Maria Camburu*;Eleonora Giunchiglia*;Jakob Foerster;Thomas Lukasiewicz;Phil Blunsom,ocamburu@gmail.com;eleonora.giunchiglia@cs.ox.ac.uk;jakobfoerster@gmail.com;thomas.lukasiewicz@gmail.com;philblunsom@gmail.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;;University of Oxford;University of Oxford,explainability;neural networks,46;46;-1;46;-1,1;1;-1;1;-1,f;m,asia,in,n,
4038,ICLR,2020,A Fine-Grained Spectral Perspective on Neural Networks,Greg Yang;Hadi Salman,gregyang@microsoft.com;hadicsalman@gmail.com,6;3;6,,Reject,0,7,0.0,yes,9/25/19,Microsoft;Massachusetts Institute of Technology,Neural Tangent Kernel;Neural Network Gaussian Process;Spectral theory;Eigenvalues;Harmonic analysis,-1;5,-1;5,m;m,usa,usa,n,1
4039,ICLR,2020,Low Rank Training of Deep Neural Networks for Emerging Memory Technology,Albert Gural;Phillip Nadeau;Mehul Tikekar;Boris Murmann,agural@stanford.edu;phillip.nadeau@analog.com;mehul.tikekar@analog.com;murmann@stanford.edu,3;3;3;6,,Reject,0,5,0.0,yes,9/25/19,Stanford University;Analog Devices;Analog Devices;Stanford University,low rank training;kronecker sum;emerging memory;non-volatile memory;rram;reram;federated learning,5;-1;-1;5,4;-1;-1;4,m;m,usa,usa,n,
4040,ICLR,2020,Cyclic Graph Dynamic Multilayer Perceptron for Periodic Signals,Mikio Furokawa;Erik Gest;Takayuki Hirano;Kamal Youcef-Toumi,mikiof@mit.edu;erikgest@mit.edu;takayuki_hirano@jsw.co.jp;youcef@mit.edu,3;6;3;3,,Reject,0,0,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology,,5;5;-1;5,5;5;-1;5,m;m,usa,usa,n,10
4041,ICLR,2020,Atomic Compression Networks,Jonas Falkner;Josif Grabocka;Lars Schmidt-Thieme,falkner@ismll.uni-hildesheim.de;josif@ismll.uni-hildesheim.de;schmidt-thieme@ismll.uni-hildesheim.de,6;1;1,,Reject,0,4,0.0,yes,9/25/19,University of Hildesheim;University of Hildesheim;University of Hildesheim,Network Compression,445;445;445,-1;-1;-1,m;m,europe,de,n,
4042,ICLR,2020,Simplicial Complex Networks,Mohammad Firouzi;Sadra Boreiri;Hamed Firouzi,mfirouzi@alphabist.com;sadra.boreiri@epfl.ch;hfirouzi@alphabist.com,1;1,,Reject,0,0,0.0,yes,9/25/19,Alphabist;Swiss Federal Institute of Technology Lausanne;Alphabist,topological data analysis;supervised learning;simplicial approximation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
4043,ICLR,2020,A Non-asymptotic comparison of SVRG and SGD: tradeoffs between compute and speed,Qingru Zhang;Yuhuai Wu;Fartash Faghri;Tianzong Zhang;Jimmy Ba,qrzhang98@gmail.com;ywu@cs.toronto.edu;faghri@cs.toronto.edu;ztz16@mails.tsinghua.edu.cn;jba@cs.toronto.edu,6;3;1,,Reject,0,5,0.0,yes,9/25/19,"Georgia Institute of Technology;University of Toronto;University of Toronto;Tsinghua University, Tsinghua University;University of Toronto",variance reduction;non-asymptotic analysis;trade-off;computational cost;convergence speed,13;18;18;4;18,38;18;18;23;18,m;m,canada,ca,y,
4044,ICLR,2020,PAC-Bayesian Neural Network Bounds,Yossi Adi;Alex Schwing;Tamir Hazan,yossiadidrum@gmail.com;aschwing@illinois.edu;tamir.hazan@technion.ac.il,3;6;3,,Reject,0,5,0.0,yes,9/25/19,"Facebook;University of Illinois, Urbana Champaign;Technion, Technion",PAC-Bayesian bounds;PAC-Bayes;Generalization bounds;Bayesian inference,-1;-1;27,-1;-1;-1,m;m,NAN,NAN,y,11;1
4045,ICLR,2020,Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning,Paul Barde;Julien Roy;F√©lix G. Harvey;Derek Nowrouzezahrai;Christopher Pal,paul.b.barde@gmail.com;jul.roy1311@gmail.com;c212.felixh@gmail.com;derek@cim.mcgill.ca;christopher.pal@polymtl.ca,6;8;3,,Reject,1,10,0.0,yes,9/25/19,INRIA;;Unity Technologies;McGill University;Polytechnique Montreal,Reinforcement Learning;Multi-Agent;Continuous Control;Regularization;Coordination;Inductive biases,-1;-1;-1;102;316,-1;-1;-1;42;-1,m;m,canada,ca,n,
4046,ICLR,2020,Stabilizing Transformers for Reinforcement Learning,Emilio Parisotto;Francis Song;Jack Rae;Razvan Pascanu;Caglar Gulcehre;Siddhant Jayakumar;Max Jaderberg;Rapha√´l Lopez Kaufman;Aidan Clark;Seb Noury;Matt Botvinick;Nicolas Heess;Raia Hadsell,eparisot@cs.cmu.edu;songf@google.com;jwrae@google.com;razp@google.com;caglarg@google.com;sidmj@google.com;jaderberg@google.com;rlopezkaufman@google.com;aidanclark@google.com;snoury@google.com;botvinick@google.com;heess@google.com;raia@google.com,1;3;3,,Reject,0,7,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Deep Reinforcement Learning;Transformer;Reinforcement Learning;Self-Attention;Memory;Memory for Reinforcement Learning,1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,27;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;3
4047,ICLR,2020,Deep k-NN for Noisy Labels,Dara Bahri;Heinrich Jiang;Maya Gupta,dbahri@google.com;heinrichj@google.com;mayagupta@google.com,1;1;6,,Reject,0,2,0.0,yes,9/25/19,Google;Google;Google,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,y,
4048,ICLR,2020,Annealed Denoising score matching: learning Energy based model in high-dimensional spaces,Zengyi Li;Yubei Chen;Friedrich T. Sommer,zengyi_li@berkeley.edu;yubeic@eecs.berkeley.edu;fsommer@berkeley.edu,3;6;3,,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Energy based models;score matching;annealing;likelihood;generative model;unsupervised learning,-1;-1;-1,13;13;13,m;m,usa,usa,y,11;5
4049,ICLR,2020,Sparse Networks from Scratch: Faster Training without Losing Performance,Tim Dettmers;Luke Zettlemoyer,dettmers@cs.washington.edu;lsz@cs.washington.edu,6;3;6,,Reject,0,6,0.0,yes,9/25/19,University of Washington;University of Washington,sparse learning;sparse networks;sparsity;efficient deep learning;efficient training,11;11,26;26,m;m,usa,usa,n,
4050,ICLR,2020,TPO: TREE SEARCH POLICY OPTIMIZATION FOR CONTINUOUS ACTION SPACES,Amir Yazdanbakhsh;Ebrahim Songhori;Robert Ormandi;Anna Goldie;Azalia Mirhoseini,ayazdan@google.com;esonghori@google.com;ormandi@google.com;agoldie@google.com;azalia@google.com,1;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google,monte-carlo tree search;reinforcement learning;tree search;policy optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n,
4051,ICLR,2020,Sample-Based Point Cloud Decoder Networks,Erich Merrill;Alan Fern,merriler@oregonstate.edu;alan.fern@oregonstate.edu,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Oregon State University;Oregon State University,point cloud;autoencoder,79;79,373;373,m;m,usa,usa,n,
4052,ICLR,2020,Bayesian Residual Policy Optimization: Scalable Bayesian Reinforcement Learning with Clairvoyant Experts,Gilwoo Lee;Brian Hou;Sanjiban Choudhury;Siddhartha S. Srinivasa,gilwoo@cs.uw.edu;bhou@cs.uw.edu;sanjibac@cs.uw.edu;siddh@cs.uw.edu,3;3;6,,Reject,0,4,0.0,yes,9/25/19,"University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle",Bayesian Residual Reinforcement Learning;Residual Reinforcement Learning;Bayes Policy Optimization,11;11;11;11,26;26;26;26,u;u,NAN,NAN,n,11
4053,ICLR,2020,Efficient Inference and Exploration for Reinforcement Learning,Yi Zhu;Jing Dong;Henry Lam,yizhu2020@u.northwestern.edu;jing.dong@gsb.columbia.edu;khl2114@columbia.edu,3;1;6,,Reject,0,4,0.0,yes,9/25/19,Northwestern University;Columbia University;Columbia University,Reinforcement Learning;Efficient Exploration;Asymptotic Analysis;Statistical Inference,46;24;24,22;16;16,m;m,usa,usa,y,
4054,ICLR,2020,Poisoning Attacks with Generative Adversarial Nets,Luis Mu√±oz-Gonz√°lez;Bjarne Pfitzner;Matteo Russo;Javier Carnerero-Cano;Emil C. Lupu,l.munoz@imperial.ac.uk;bjarne.pfitzner@hpi.de;matteor@princeton.edu;j.carnerero-cano18@imperial.ac.uk;e.c.lupu@imperial.ac.uk,6;6;3,,Reject,0,3,0.0,yes,9/25/19,Imperial College London;Hasso Plattner Institute;Princeton University;Imperial College London;Imperial College London,data poisoning;adversarial machine learning;generative adversarial nets,52;143;30;52;52,10;-1;6;10;10,m;m,europe,uk,n,5;4
4055,ICLR,2020,Keyframing the Future: Discovering Temporal Hierarchy with Keyframe-Inpainter Prediction,Karl Pertsch;Oleh Rybkin;Jingyun Yang;Konstantinos G. Derpanis;Kostas Daniilidis;Joseph J. Lim;Andrew Jaegle,pertsch@usc.edu;oleh@seas.upenn.edu;jingyuny@usc.edu;kosta@ryerson.ca;kostas@seas.upenn.edu;limjj@usc.edu;ajaegle@upenn.edu,3;3;6,,Reject,0,7,0.0,yes,9/25/19,University of Southern California;University of Pennsylvania;University of Southern California;Ryerson University;University of Pennsylvania;University of Southern California;University of Pennsylvania,representation learning;variational inference;video generation;temporal hierarchy,36;20;36;316;20;36;20,62;11;62;739;11;62;11,m;m,usa,usa,n,
4056,ICLR,2020,An Empirical Study on Post-processing Methods for Word Embeddings,Shuai Tang;Mahta Mousavi;Virginia R. de Sa,shuaitang93@ucsd.edu;mahta@ucsd.edu;desa@ucsd.edu,1;6;3,,Reject,0,1,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego",word vectors;post-processing method;centralised kernel alignment;shrinkage,-1;-1;-1,31;31;31,m;f,usa,usa,n,3
4057,ICLR,2020,Winning the Lottery with Continuous Sparsification,Pedro Savarese;Hugo Silva;Michael Maire,savarese@ttic.edu;hugoandradesilva664@gmail.com;mmaire@uchicago.edu,3;6;3,,Reject,0,6,0.0,yes,9/25/19,Toyota Technological Institute at Chicago;;University of Chicago,,-1;-1;51,-1;-1;9,m;m,usa,usa,n,6
4058,ICLR,2020,Rethinking Curriculum Learning With Incremental Labels And Adaptive Compensation,Madan Ravi Ganesh;Jason J. Corso,madantrg@umich.edu;jjcorso@umich.edu,3;1;6,,Reject,0,4,0.0,yes,9/25/19,University of Michigan;University of Michigan,Curriculum Learning;Incremental Label Learning;Label Smoothing;Deep Learning,7;7,21;21,m;m,usa,usa,n,
4059,ICLR,2020,Zero-Shot Policy Transfer with Disentangled Attention,Josh Roy;George Konidaris,josh_roy@brown.edu;gdk@cs.brown.edu,1;1;1,,Reject,0,3,0.0,yes,9/25/19,Brown University;Brown University,Transfer Learning;Reinforcement Learning;Attention;Domain Adaptation;Representation Learning;Feature Extraction,85;85,53;53,m;m,usa,usa,n,8;5
4060,ICLR,2020,P-BN: Towards Effective Batch Normalization in the Path Space,Xufang Luo;Qi Meng;Wei Chen;Tie-Yan Liu,luoxufang@buaa.edu.cn;meq@microsoft.com;wche@microsoft.com;tyliu@microsoft.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Beihang University;Microsoft;Microsoft;Microsoft,,102;-1;-1;-1,594;-1;-1;-1,f;m,NAN,NAN,y,
4061,ICLR,2020,Convolutional Tensor-Train LSTM for Long-Term Video Prediction,Jiahao Su;Wonmin Byeon;Furong Huang;Jan Kautz;Animashree Anandkumar,jiahaosu@terpmail.umd.edu;wonmin.byeon@gmail.com;furongh@cs.umd.edu;jkautz@nvidia.com;animakumar@gmail.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,"University of Maryland, College Park;NVIDIA;University of Maryland, College Park;NVIDIA;California Institute of Technology",Tensor decomposition;Video prediction,12;-1;12;-1;143,91;-1;91;-1;2,m;f,usa,usa,n,
4062,ICLR,2020,Task-Based Top-Down Modulation Network for Multi-Task-Learning Applications,Hila Levi;Shimon Ullman,hila.levi@weizmann.ac.il;shimon.ullman@weizmann.ac.il,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Weizmann Institute;Weizmann Institute,deep learning;multi-task learning,118;118,-1;-1,f;m,NAN,NAN,n,8
4063,ICLR,2020,Variational Constrained Reinforcement Learning with Application to Planning at Roundabout,Yuan Tian;Minghao Han;Lixian Zhang;Wulong Liu;Jun Wang;Wei Pan,yuantian013@163.com;mhhan@hit.edu.cn;lixianzhang@hit.edu.cn;liuwulong@huawei.com;jun.wang@cs.ucl.ac.uk;wei.pan@tudelft.nl,1;1;1,,Reject,0,0,0.0,yes,9/25/19,163;Harbin Institute of Technology;Harbin Institute of Technology;Huawei Technologies Ltd.;University College London;Delft University of Technology,Safe reinforcement learning;Autonomous driving;obstacle avoidance,-1;168;168;-1;52;-1,-1;424;424;-1;-1;67,m;m,NAN,NAN,n,
4064,ICLR,2020,Learning a Spatio-Temporal Embedding for Video Instance Segmentation,Anthony Hu;Alex Kendall;Roberto Cipolla,ah2029@cam.ac.uk;alex@wayve.ai;rc10001@cam.ac.uk,3;6;3,,Reject,0,4,0.0,yes,9/25/19,University of Cambridge;Wayve;University of Cambridge,computer;vision;video;instance;segmentation;metric;learning,79;-1;79,3;-1;3,m;m,europe,uk,n,2
4065,ICLR,2020,Deep Ensembles: A Loss Landscape Perspective,Stanislav Fort;Clara Huiyi Hu;Balaji Lakshminarayanan,stanislav.fort@gmail.com;clarahu@google.com;balajiln@google.com,8;3;3,,Reject,0,5,0.0,yes,9/25/19,Stanford University;Google;Google,loss landscape;deep ensemble;subspace;tunnel;low loss;connector;weight averaging;dropout;gaussian;connectivity;diversity;function space,5;-1;-1,4;-1;-1,m;m,NAN,NAN,n,11;1
4066,ICLR,2020,Adversarial Privacy Preservation under Attribute Inference Attack,Han Zhao;Jianfeng Chi;Yuan Tian;Geoffrey J. Gordon,han.zhao@cs.cmu.edu;jc6ub@virginia.edu;yuant@virginia.edu;geoff.gordon@microsoft.com,3;6;3,,Reject,0,4,1.0,yes,9/25/19,Carnegie Mellon University;University of Virginia;University of Virginia;Microsoft,,1;52;52;-1,27;107;107;-1,m;m,NAN,NAN,y,1;4
4067,ICLR,2020,Deep Innovation Protection,Sebastian Risi;Kenneth O. Stanley,sebr@itu.dk;kstanley@uber.com,6;6;3,,Reject,0,3,0.0,yes,9/25/19,IT University of Copenhagen;Uber,Neuroevolution;innovation protection;world models;genetic algorithm,168;-1,101;-1,m;m,southamerica,br,n,
4068,ICLR,2020,Meta-Learning Runge-Kutta,Nadine Behrmann;Patrick Schramowski;Kristian Kersting,nadine.behrmann@freenet.de;schramowski@cs.tu-darmstadt.de;kersting@cs.tu-darmstadt.de,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Bosch;TU Darmstadt;TU Darmstadt,,-1;59;59,297;-1;-1,f;m,europe,de,y,6
4069,ICLR,2020,"Credible Sample Elicitation by Deep Learning, for Deep Learning",Yang Liu;Zuyue Fu;Zhuoran Yang;Zhaoran Wang,yangliu@ucsc.edu;zuyuefu2022@u.northwestern.edu;zy6@princeton.edu;zhaoranwang@gmail.com,6;1,,Reject,0,3,0.0,yes,9/25/19,University of Southern California;Northwestern University;Princeton University;Northwestern University,,36;46;30;46,62;22;6;22,m;m,usa,usa,y,5;4
4070,ICLR,2020,Continuous Graph Flow,Zhiwei Deng;Megha Nawhal;Lili Meng;Greg Mori,zhiweid@princeton.edu;mnawhal@sfu.ca;lilimeng1103@gmail.com;mori@cs.sfu.ca,3;3;3,,Reject,1,3,0.0,yes,9/25/19,Princeton University;Simon Fraser University;University of British Columbia;Simon Fraser University,graph flow;normalizing flow;continuous message passing;reversible graph neural networks,30;52;64;52,6;272;34;272,m;m,canada,ca,n,10;1;5
4071,ICLR,2020,Extreme Value k-means Clustering,Sixiao Zheng;Yanxi Hou;Yanwei Fu;Jianfeng Feng,sxzheng18@fudan.edu.cn;yxhou@fudan.edu.cn;yanweifu@fudan.edu.cn;jffeng@fudan.edu.cn,3;3;1;6,,Reject,0,0,0.0,yes,9/25/19,Fudan University;Fudan University;Fudan University;Fudan University,unsupervised learning;clustering;k-means;Extreme Value Theory,73;73;73;73,109;109;109;109,m;m,asia,cn,y,1
4072,ICLR,2020,Hallucinative Topological Memory for Zero-Shot Visual Planning,Kara Liu;Thanard Kurutach;Pieter Abbeel;Aviv Tamar,karamarieliu@berkeley.edu;thanard.kurutach@berkeley.edu;pabbeel@cs.berkeley.edu;aviv.tamar.mail@gmail.com,1;8;6,,Reject,0,5,0.0,yes,9/25/19,"University of California Berkeley;University of California Berkeley;University of California Berkeley;Technion, Technion",Visual Planning;Model-Based RL;Representation Learning,-1;-1;-1;27,13;13;13;-1,f;m,NAN,NAN,n,6;10;1;5
4073,ICLR,2020,On the Decision Boundaries of Deep Neural Networks: A Tropical Geometry Perspective,Motasem Alfarra;Adel Bibi;Hasan Hammoud;Mohamed Gaafar;Bernard Ghanem,motasem.alfarra@kaust.edu.sa;adel.bibi@kaust.edu.sa;hasan.hammoud@kaust.edu.sa;muhamed.gaafar@gmail.com;bernard.ghanem@kaust.edu.sa,1;8;3,,Reject,1,9,0.0,yes,9/25/19,KAUST;KAUST;KAUST;Zalando SE;KAUST,Decision boundaries;Neural Network;Tropical Geometry;Network Pruning;Adversarial Attacks;Lottery Ticket Hypothesis,102;102;102;-1;102,-1;-1;-1;-1;-1,m;m,europe,gr,y,4
4074,ICLR,2020,Encoder-decoder Network as Loss Function for Summarization,Glen Jeh,glenjeh@gmail.com,1;6;1,,Reject,0,4,0.0,yes,9/25/19,0,encoder-decoder;summarization;loss functions,,,m,NAN,NAN,n,
4075,ICLR,2020,Unsupervised Learning of Automotive 3D Crash Simulations using LSTMs,Amin Abbasloo;Jochen Garcke;Rodrigo Iza-Teran,amin.abbasloo@scai.fraunhofer.de;garcke@ins.uni-bonn.de;rodrigo.iza-teran@scai.fraunhofer.de,3;3;3,,Reject,0,1,0.0,yes,9/25/19,Fraunhofer IIS;University of Bonn;Fraunhofer IIS,LSTM;surface data;geometric deep learning;numerical simulation,-1;143;-1,-1;106;-1,m;m,NAN,NAN,n,
4076,ICLR,2020,Dynamic Instance Hardness,Tianyi Zhou;Shengjie Wang;Jeff A. Bilmes,tianyizh@uw.edu;wangsj@cs.washington.edu;bilmes@uw.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,"University of Washington, Seattle;University of Washington;University of Washington, Seattle",training dynamics;instance hardness;curriculum learning;neural nets memorization,11;11;11,26;26;26,m;m,NAN,NAN,y,1
4077,ICLR,2020,Beyond Classical Diffusion: Ballistic Graph Neural Network,Yimeng Min,minyimen@mila.quebec,3;3;1,,Reject,0,4,0.0,yes,9/25/19,Mila,Graph Convolutional Network;Diffusion;Transportation;Machine Learning,143,336,m;m,NAN,NAN,n,10
4078,ICLR,2020,INSTANCE CROSS ENTROPY FOR DEEP METRIC LEARNING,Xinshao Wang;Elyor Kodirov;Yang Hua;Neil M. Robertson,xwang39@qub.ac.uk;elyor@anyvision.co;y.hua@qub.ac.uk;n.robertson@qub.ac.uk,3;1;8,,Reject,0,7,1.0,yes,9/25/19,Queen's University Belfast;Anyvision;Queen's University Belfast;Queen's University Belfast,Deep Metric Learning;Instance Cross Entropy;Sample Mining/Weighting;Image Retrieval,248;-1;248;248,204;-1;204;204,m;m,europe,uk,n,
4079,ICLR,2020,Retrieving Signals in the Frequency Domain with Deep Complex Extractors,Chiheb Trabelsi;Olexa Bilaniuk;Ousmane Dia;Ying Zhang;Mirco Ravanelli;Jonathan Binas;Negar Rostamzadeh;Christopher  J Pal,chiheb.trabelsi@polymtl.ca;olexa.bilaniuk@umontreal.ca;ousmane@elementai.com;ying@elementai.com;mirco.ravanelli@gmail.com;jbinas@gmail.com;negar@elementai.com;christopher.pal@elementai.com,6;3;6,,Reject,0,7,0.0,yes,9/25/19,Polytechnique Montreal;University of Montreal;Element AI;Element AI;University of Montreal;University of Montreal;Element AI;Element AI,Deep Complex Networks;Signal Extraction,316;118;-1;-1;118;118;-1;-1,-1;85;-1;-1;85;85;-1;-1,m;m,NAN,NAN,n,
4080,ICLR,2020,A Copula approach for hyperparameter transfer learning,David Salinas;Huibin Shen;Valerio Perrone,david.salinas.pro@gmail.com;huibishe@amazon.com;vperrone@amazon.com,3;1;6,,Reject,0,4,0.0,yes,9/25/19,Amazon;Amazon;Amazon,Hyperparameter optimization;Bayesian Optimization;Gaussian Process;Copula;Transfer-learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,6;11
4081,ICLR,2020,Out-of-distribution Detection in Few-shot Classification,Kuan-Chieh Wang;Paul Vicol;Eleni Triantafillou;Chia-Cheng Liu;Richard Zemel,wangkua1@cs.toronto.edu;pvicol@cs.toronto.edu;eleni@cs.toronto.edu;cc.liu2018@gmail.com;zemel@cs.toronto.edu,3;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Toronto;University of Toronto;University of Toronto;;University of Toronto,few-shot classification;out-of-distribution detection;uncertainty estimate,18;18;18;-1;18,18;18;18;-1;18,m;m,canada,ca,n,6
4082,ICLR,2020,GQ-Net: Training Quantization-Friendly Deep Networks,Rundong Li;Rui Fan,lird@shanghaitech.edu.cn;fanrui@shanghaitech.edu.cn,3;3;6,,Reject,0,8,0.0,yes,9/25/19,ShanghaiTech University;ShanghaiTech University,Network quantization;Efficient deep learning,316;316,-1;-1,m;m,asia,cn,n,
4083,ICLR,2020,The divergences minimized by non-saturating GAN training,Matt Shannon,matt.shannon.personal@gmail.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Google,GAN,-1,-1,m,NAN,NAN,n,5;4
4084,ICLR,2020,"Translation Between Waves,  wave2wave",Tsuyoshi Okita;Hirotaka Hachiya;Sozo Inoue;Naonori Ueda,tsuyoshi.okita@gmail.com;hirotaka.hachiya@riken.jp;sozo.inoue@riken.jp;naonori.ueda@riken.jp,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Kyushu Institute of Technology;RIKEN;RIKEN;RIKEN,sequence to sequence model;signal to signal;deep learning;RNN;encoder-decoder model,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3
4085,ICLR,2020,MixUp as Directional Adversarial Training,Guillaume Perrault-Archambault;Yongyi Mao;Hongyu Guo;Richong Zhang,gperr050@uottawa.ca;yymao@eecs.uottawa.ca;hongyu.guo@nrc-cnrc.gc.ca;zhangrc@act.buaa.edu.cn,1;3;3,,Reject,0,8,0.0,yes,9/25/19,University of Ottawa;University of Ottawa;National Research Council Canada;Beihang University,MixUp;Adversarial Training;Untied MixUp,248;248;-1;102,141;141;-1;594,m;m,asia,cn,y,1;4
4086,ICLR,2020,Deep Multiple Instance Learning with Gaussian Weighting,Basura Fernando;Hakan Bilen,basura.fernando@anu.edu.au;hbilen@ed.ac.uk,8;3;3,,Reject,0,3,0.0,yes,9/25/19,Australian National University;University of Edinburgh,Multiple instance learning;deep learning,102;36,50;30,m;m,europe,uk,n,
4087,ICLR,2020,DyNet: Dynamic Convolution for Accelerating Convolution Neural Networks,Kane Zhang;Jian Zhang;Qiang Wang;Zhao Zhong,zhangyikang5@huawei.com;zhangjian157@huawei.com;wangqiang168@huawei.com;zorro.zhongzhao@huawei.com,6;3;3,,Reject,0,8,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,CNNs;dynamic convolution kernel,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,2
4088,ICLR,2020,Growing Action Spaces,Gregory Farquhar;Laura Gustafson;Zeming Lin;Shimon Whiteson;Nicolas Usunier;Gabriel Synnaeve,gregory.farquhar@cs.ox.ac.uk;lgustafson@fb.com;zlin@fb.com;shimon.whiteson@cs.ox.ac.uk;usunier@fb.com;gab@fb.com,3;3;6,,Reject,0,3,0.0,yes,9/25/19,University of Oxford;Facebook;Facebook;University of Oxford;Facebook;Facebook,reinforcement learning;curriculum learning;multi-agent reinforcement learning,46;-1;-1;46;-1;-1,1;-1;-1;1;-1;-1,m;m,NAN,NAN,n,1
4089,ICLR,2020,Model Ensemble-Based Intrinsic Reward for Sparse Reward Reinforcement Learning,Giseung Park;Whiyoung Jung;Sungho Choi;Youngchul Sung,gs.park@kaist.ac.kr;wy.jung@kaist.ac.kr;sungho.choi@kaist.ac.kr;ycsung@kaist.ac.kr,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Intrinsic Reward;Dynamics Model;Ensemble,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,y,
4090,ICLR,2020,Differentiable Hebbian Consolidation for Continual Learning,Vithursan Thangarasa;Thomas Miconi;Graham W. Taylor,vthangar@uoguelph.ca;tmiconi@uber.com;gwtaylor@uoguelph.ca,3;6;6,,Reject,0,7,0.0,yes,9/25/19,University of Guelph;Uber;University of Guelph,continual learning;catastrophic forgetting;Hebbian learning;synaptic plasticity;neural networks,248;-1;248,558;-1;558,m;m,canada,ca,n,
4091,ICLR,2020,Meta-Graph: Few shot Link Prediction via Meta Learning,Avishek Joey Bose;Ankit Jain;Piero Molino;William L. Hamilton,joey.bose@mail.mcgill.ca;ankit.jain@uber.com;piero.molino@uber.com;wlh@cs.mcgill.ca,6;6;6,,Reject,0,5,0.0,yes,9/25/19,McGill University;Uber;Uber;McGill University,Meta Learning;Link Prediction;Graph Representation Learning;Graph Neural Networks,102;-1;-1;102,42;-1;-1;42,m;m,canada,ca,n,6;10
4092,ICLR,2020,EXPLOITING SEMANTIC COHERENCE TO IMPROVE PREDICTION IN SATELLITE SCENE IMAGE ANALYSIS: APPLICATION TO DISEASE DENSITY ESTIMATION,Rahman Sanya;Gilbert Maiga;Ernest Mwebaze,hbasanya@gmail.com;gilmaiga@gmail.com;emwebaze@gmail.com,1;3;1,,Reject,0,1,0.0,yes,9/25/19,Makerere University;;Google AI,semantic coherence;satellite scene image analysis;convolutional neural networks;disease density,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
4093,ICLR,2020,VAENAS: Sampling Matters in Neural Architecture Search,Shizheng Qin;Yichen Zhu;Pengfei Hou;Xiangyu Zhang;Wenqiang Zhang;Jian Sun,szqin17@fudan.edu.cn;k.zhu@mail.utoronto.ca;houpengfei@megvii.com;zhangxiangyu@megvii.com;wqzhang@fudan.edu.cn;sunjian@megvii.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Fudan University;Toronto University;Megvii Technology Inc.;Megvii Technology Inc.;Fudan University;Megvii Technology Inc.,,73;-1;-1;-1;73;-1,109;-1;-1;-1;109;-1,m;m,NAN,NAN,n,2;5
4094,ICLR,2020,Aggregating explanation methods for neural networks stabilizes explanations,Laura Rieger;Lars Kai Hansen,lauri@dtu.dk,8;3;8,,Reject,0,7,0.0,yes,9/25/19,Technical University of Denmark,explainability;deep learning;interpretability;XAI,-1,182,m;f,NAN,NAN,n,1
4095,ICLR,2020,Towards Stable and comprehensive Domain Alignment: Max-Margin Domain-Adversarial Training,Jianfei Yang;Han Zou;Yuxun Zhou;Lihua Xie,yang0478@e.ntu.edu.sg;hanzou@berkeley.edu;yxzhou@berkeley.edu;elhxie@ntu.edu.sg,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Nanyang Technological University;University of California Berkeley;University of California Berkeley;Nanyang Technological University,domain adaptation;transfer learning;adversarial training,43;-1;-1;43,49;13;13;49,m;m,asia,sg,n,4
4096,ICLR,2020,In-Domain Representation Learning For Remote Sensing,Maxim Neumann;Andre Susano Pinto;Xiaohua Zhai;Neil Houlsby,maximneumann@google.com;andresp@google.com;xzhai@google.com;neilhoulsby@google.com,3;3;1,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google,Representation learning;remote sensing,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8
4097,ICLR,2020,Ternary MobileNets via Per-Layer Hybrid Filter Banks,Dibakar Gope;Jesse G Beu;Urmish Thakker;Matthew Mattina,dibakar.gope@arm.com;jesse.beu@arm.com;urmish.thakker@arm.com;matthew.mattina@arm.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,arm;arm;arm;arm,Model compression;ternary quantization;energy-efficient models,59;59;59;59,289;289;289;289,m;m,asia,in,n,2
4098,ICLR,2020,Avoiding Negative Side-Effects and Promoting Safe Exploration with Imaginative Planning,Dhruv Ramani;Benjamin Eysenbach,dhruvramani98@gmail.com;beysenba@cs.cmu.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,National Institute of Technology Warangal;Carnegie Mellon University,Reinforcement Learning;AI-Safety;Model-Based Reinforcement Learning;Safe-Exploration,-1;1,-1;27,m;m,usa,usa,n,10
4099,ICLR,2020,Exploring the Correlation between Likelihood of Flow-based Generative Models and Image Semantics,Xin WANG;SiuMing Yiu,xwang@cs.hku.hk;smyiu@cs.hku.hk,3;1;3,,Reject,0,8,0.0,yes,9/25/19,The University of Hong Kong;The University of Hong Kong,flow-based generative models;out-of-distribution samples detection;likelihood robustness,92;92,35;35,u;m,NAN,NAN,n,8;5
4100,ICLR,2020,Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization,Ali Ramezani-Kebrya;Fartash Faghri;Ilya Markov;Vitalii Aksenov;Dan Alistarh;Daniel M. Roy,alir@vectorinstitute.ai;faghri@cs.toronto.edu;droy@utstat.toronto.edu;dan.alistarh@ist.ac.at;markovilya197@gmail.com;vitalii.aksenov@ist.ac.at,3;6;3,,Reject,0,5,0.0,yes,9/25/19,Vector Institute;University of Toronto;University of Toronto;Institute of Science and Technology Austria;;Institute of Science and Technology Austria,,-1;18;18;-1;-1;-1,-1;18;18;-1;-1;-1,m;m,NAN,NAN,y,
4101,ICLR,2020,Scalable Neural Learning for Verifiable Consistency with Temporal Specifications,Sumanth Dathathri;Johannes Welbl;Krishnamurthy (Dj) Dvijotham;Ramana Kumar;Aditya Kanade;Jonathan Uesato;Sven Gowal;Po-Sen Huang;Pushmeet Kohli,sdathath@caltech.edu;johannes.welbl.14@ucl.ac.uk;dvij@google.com;ramanakumar@google.com;akanade@google.com;juesato@google.com;sgowal@google.com;posenhuang@google.com;pushmeet@google.com,3;6;8;1,,Reject,0,9,0.0,yes,9/25/19,California Institute of Technology;University College London;Google;Google;Google;Google;Google;Google;Google,Verification;Recurrent Neural Networks;Reinforcement Learning;Temporal Logic;Adversarial Robustness,143;52;-1;-1;-1;-1;-1;-1;-1,2;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,8;3;4
4102,ICLR,2020,EvoNet: A Neural Network for Predicting the Evolution of Dynamic Graphs,Changmin Wu;Giannis Nikolentzos;Michalis Vazirgiannis,changmin.wu@polytechnique.edu;giannisnik@hotmail.com;mvazirg@lix.polytechnique.fr,3;3;1,,Reject,0,0,0.0,yes,9/25/19,"Ecole polytechnique;Ecole polytechnique;Ecole Polytechnique, France",temporal graphs;graph neural network;graph generative model;graph topology prediction,-1;-1;-1,93;93;-1,m;m,NAN,NAN,n,10;5
4103,ICLR,2020,SGD Learns One-Layer Networks in WGANs,Qi Lei;Jason D. Lee;Alexandros G. Dimakis;Constantinos Daskalakis,leiqi@ices.utexas.edu;jasondlee88@gmail.com;dimakis@austin.utexas.edu;costis@csail.mit.edu,3;6;3,,Reject,0,3,0.0,yes,9/25/19,"University of Texas, Austin;Princeton University;University of Texas, Austin;Massachusetts Institute of Technology",Wasserstein GAN;global min-max;one-layer network,-1;30;-1;5,-1;6;-1;5,f;m,usa,usa,y,5;4
4104,ICLR,2020,Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation,Raphael Gontijo Lopes;Dong Yin;Ben Poole;Justin Gilmer;Ekin D. Cubuk,iraphael@google.com;dongyin@berkeley.edu;pooleb@google.com;gilmer@google.com;cubuk@google.com,3;3;8,,Reject,0,5,0.0,yes,9/25/19,Google;University of California Berkeley;Google;Google;Google,Data Augmentation;Out-of-distribution;Robustness;Generalization;Computer Vision;Corruption,-1;-1;-1;-1;-1,-1;13;-1;-1;-1,m;m,NAN,NAN,n,1;4
4105,ICLR,2020,Tensorized Embedding Layers for Efficient Model Compression,Oleksii Hrinchuk;Valentin Khrulkov;Leyla Mirvakhabova;Ivan Oseledets,oleksii.hrinchuk@skoltech.ru;khrulkov.v@gmail.com;leyla.mirvakhabova@skoltech.ru;i.oseledets@skoltech.ru,8;3;6,,Reject,0,4,0.0,yes,9/25/19,Skolkovo Institute of Science and Technology;Yandex;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology,Embedding layers compression;tensor networks;low-rank factorization,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,russia,n,8;3
4106,ICLR,2020,Training Deep Networks with Stochastic Gradient Normalized by Layerwise Adaptive Second Moments,Boris Ginsburg;Patrice Castonguay;Oleksii Hrinchuk;Oleksii Kuchaiev;Vitaly Lavrukhin;Ryan Leary;Jason Li;Huyen Nguyen;Yang Zhang;Jonathan M. Cohen,boris.ginsburg@gmail.com;pcastonguay@nvidia.com;grinchuk.alexey@gmail.com;kuchaev@gmail.com;vlavrukhin@yahoo.com;rleary@nvidia.com;jasoli@nvidia.com;huyenntkvn@gmail.com;yangzhang@nvidia.com;jocohen@nvidia.com,6;3;3,,Reject,0,3,0.0,yes,9/25/19,NVIDIA;NVIDIA;Moscow Institute of Physics and Technology;NVIDIA;;NVIDIA;NVIDIA;;NVIDIA;NVIDIA,deep learning;optimization;SGD;Adam;NovoGrad;large batch training,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;234;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3
4107,ICLR,2020,Learning Time-Aware Assistance Functions for Numerical Fluid Solvers,Kiwon Um;Yun (Raymond) Fei;Philipp Holl;Nils Thuerey,kiwon.um@tum.de;yf2320@columbia.edu;philipp.holl@tum.de;nils.thuerey@tum.de,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Technical University Munich;Columbia University;Technical University Munich;Technical University Munich,PDEs;convolutional neural networks;numerical simulation;fluids,-1;24;-1;-1,-1;16;-1;-1,m;m,NAN,NAN,n,
4108,ICLR,2020,Why do These Match? Explaining the Behavior of Image Similarity Models,Bryan A. Plummer;Mariya I. Vasileva;Vitali Petsiuk;Kate Saenko;David Forsyth,bplumme2@illinois.edu;mvasile2@illinois.edu;vpetsiuk@bu.edu;saenko@bu.edu;daf@illinois.edu,6;6;3,,Reject,0,5,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Boston University;Boston University;University of Illinois, Urbana Champaign",explainable artificial intelligence;image similarity;artificial intelligence for fashion,-1;-1;79;79;-1,-1;-1;61;61;-1,m;m,usa,usa,n,
4109,ICLR,2020,Towards an Adversarially Robust Normalization Approach,Muhammad Awais;Fahad Shamshad;Sung-Ho Bae,awais@khu.ac.kr;fahad.shamshad@itu.edu.pk;shbae@khu.ac.kr,3;3;6,,Reject,3,0,0.0,yes,9/25/19,"Kyung Hee University;ITU of Punjab Lahore, Pakistan;Kyung Hee University",robustness;BatchNorm;adversarial,445;-1;445,319;-1;319,m;m,asia,kr,n,4
4110,ICLR,2020,When Does Self-supervision Improve Few-shot Learning?,Jong-Chyi Su;Subhransu Maji;Bharath Hariharan,jcsu@cs.umass.edu;smaji@cs.umass.edu;bharathh@cs.cornell.edu,3;3;8,,Reject,0,4,0.0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;Cornell University",Few-shot learning;Self-supervised learning;Meta-learning;Multi-task learning,24;24;7,209;209;19,m;m,usa,usa,n,6;1
4111,ICLR,2020,D3PG: Deep Differentiable Deterministic Policy Gradients,Tao Du;Yunfei Li;Jie Xu;Andrew Spielberg;Kui Wu;Daniela Rus;Wojciech Matusik,taodu@csail.mit.edu;l-yf16@mails.tsinghua.edu.cn;jiex@csail.mit.edu;aespielberg@csail.mit.edu;walker.kui.wu@gmail.com;rus@csail.mit.edu;wojciech@csail.mit.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,"Massachusetts Institute of Technology;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology",differentiable simulator;model-based control;policy gradients,5;4;5;5;5;5;5,5;23;5;5;5;5;5,m;m,usa,usa,n,9
4112,ICLR,2020,Sparse Transformer: Concentrated Attention Through Explicit Selection,Guangxiang Zhao;Junyang Lin;Zhiyuan Zhang;Xuancheng Ren;Xu Sun,1701214310@pku.edu.cn;junyang.ljy@alibaba-inc.com;zzy1210@pku.edu.cn;renxc@pku.edu.cn;xusun@pku.edu.cn,1;3;6,,Reject,1,7,0.0,yes,9/25/19,Peking University;Alibaba Group;Peking University;Peking University;Peking University,Attention;Transformer;Machine Translation;Natural Language Processing;Sparse;Sequence to sequence learning,14;-1;14;14;14,24;-1;24;24;24,m;m,asia,cn,n,8;3
4113,ICLR,2020,SAFE-DNN: A Deep Neural Network with Spike Assisted Feature Extraction for Noise Robust Inference,Xueyuan She;Priyabrata Saha;Daehyun Kim;Yun Long;Saibal Mukhopadhyay,xshe6@gatech.edu;priyabratasaha@gatech.edu;daehyun.kim@gatech.edu;yunlong@gatech.edu;saibal.mukhopadhyay@ece.gatech.edu,3;6;3,,Reject,1,4,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Noise robust;deep learning;DNN;image classification,13;13;13;13;13,38;38;38;38;38,m;m,usa,usa,n,
4114,ICLR,2020,TWIN GRAPH CONVOLUTIONAL NETWORKS: GCN WITH DUAL GRAPH SUPPORT FOR SEMI-SUPERVISED LEARNING,Feng Shi;Yizhou Zhao;Ziheng Xu;Tianyang Liu;Song-Chun Zhu,shi.feng@cs.ucla.edu;yizhouzhao@ucla.edu;lawrencexu@ucla.edu,3;1;3,,Reject,0,0,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Graph;Neural Networks;Deep Learning;semi-supervised learning,-1;-1;-1,17;17;17,m;m,usa,usa,n,10
4115,ICLR,2020,"Calibration, Entropy Rates, and Memory in Language Models",Mark Braverman;Xinyi Chen;Sham Kakade;Karthik Narasimhan;Cyril Zhang;Yi Zhang,mbraverm@cs.princeton.edu;xinyic@google.com;sham@cs.washington.edu;karthikn@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,6;6;3,,Reject,0,4,0.0,yes,9/25/19,Princeton University;Google;University of Washington;Princeton University;Princeton University;Princeton University,information theory;natural language processing;calibration,30;-1;11;30;30;30,6;-1;26;6;6;6,m;m,usa,usa,y,8;3;5
4116,ICLR,2020,Deep End-to-end Unsupervised Anomaly Detection ,Li Tangqing;Wang Zheng;Liu Siying;Daniel Lin Wen-Yan,li_tangqing@u.nus.edu;sliu50@illinois.edu;zhwang@i2r.a-star.edu.sg;daniellin@smu.edu.sg,3;6;1,,Reject,0,5,0.0,yes,9/25/19,"National University of Singapore;University of Illinois, Urbana Champaign;Institute for Infocomm Research, A*STAR;Singapore Management University",,17;-1;-1;79,25;-1;-1;-1,u;m,asia,sg,n,
4117,ICLR,2020,Role-Wise Data Augmentation for Knowledge Distillation,Jie Fu;Xue Geng;Bohan Zhuang;Xingdi Yuan;Adam Trischler;Jie Lin;Vijay Chandrasekhar;Chris Pal,jie.fu@polymtl.ca;geng_xue@i2r.a-star.edu.sg;bohan.zhuang@adelaide.edu.au;eryua@microsoft.com;adam.trischler@microsoft.com;lin-j@i2r.a-star.edu.sg;vijay@i2r.a-star.edu.sg;christopher.pal@polymtl.ca,3;3;6,,Reject,0,4,0.0,yes,9/25/19,"Polytechnique Montreal;Institute for Infocomm Research, A*STAR;The University of Adelaide;Microsoft;Microsoft;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Polytechnique Montreal",Data Augmentation;Knowledge Distillation,316;-1;102;-1;-1;-1;-1;316,-1;-1;120;-1;-1;-1;-1;-1,m;m,canada,ca,n,
4118,ICLR,2020,HighRes-net: Multi-Frame Super-Resolution by Recursive Fusion,Michel Deudon;Alfredo Kalaitzis;Md Rifat Arefin;Israel Goytom;Zhichao Lin;Kris Sankaran;Vincent Michalski;Samira E Kahou;Julien Cornebise;Yoshua Bengio,michel.deudon@elementai.com;freddie@element.ai;rifat.arefin515@gmail.com;isrugeek@gmail.com;zhichao.lin@elementai.com;sankaran.kris@gmail.com;vincent.michalski@gmx.de;samira.ebrahimi-kahou@polymtl.ca;julien@elementai.com;yoshua.bengio@mila.quebec,8;3;1,,Reject,0,17,1.0,yes,9/25/19,Element AI;Element AI;;;Element AI;;University of Montreal;Polytechnique Montreal;Element AI;Mila,multi-frame super-resolution;super-resolution;remote sensing;fusion;de-aliasing;deep learning;registration,-1;-1;-1;-1;-1;-1;118;316;-1;143,-1;-1;-1;-1;-1;-1;85;-1;-1;336,m;m,NAN,NAN,n,5
4119,ICLR,2020,Sparse and Structured Visual Attention,Pedro Henrique Martins;Vlad Niculae;Zita Marinho;Andr√© F.T. Martins,pedrohenriqueamartins@gmail.com;vlad@vene.ro;zita.marinho@priberam.pt;andre.martins@unbabel.com,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Instituto Superior T√©cnico;University of Amsterdam;;Unbabel,Sparsity;attention;structured attention;total variation;fused lasso;image captioning,-1;143;-1;-1,-1;62;-1;-1,m;m,NAN,NAN,y,8
4120,ICLR,2020,Policy Tree Network,Zac Wellmer;Sepanta Zeighami;James Kwok,zac@1984.ai;szeighami@connect.ust.hk;jamesk@cse.ust.hk,3;1;3,,Reject,0,8,0.0,yes,9/25/19,Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Reinforcement Learning,-1;-1;-1,-1;47;47,m;m,NAN,NAN,y,1
4121,ICLR,2020,Bias-Resilient Neural Network,Ehsan Adeli;Qingyu Zhao;Adolf Pfefferbaum;Edith V. Sullivan;Fei-Fei Li;Juan Carlos Niebles;Kilian M. Pohl,eadeli@stanford.edu;qingyuz@stanford.edu;edie@stanford.edu;dolfp@stanford.edu;feifeili@cs.stanford.edu;jniebles@cs.stanford.edu;kilian.pohl@stanford.edu,8;1;3,,Reject,0,8,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Invariant Feature Learning;Vanished Correlation;Generative Adversarial Networks;Gender Shades;Fairness in Machine Learning,5;5;5;5;5;5;5,4;4;4;4;4;4;4,m;m,usa,usa,n,2;7;4
4122,ICLR,2020,ASYNCHRONOUS MULTI-AGENT GENERATIVE ADVERSARIAL IMITATION LEARNING,Xin Zhang;Weixiao Huang;Renjie Liao;Yanhua Li,xzhang17@wpi.edu;whuang2@wpi.edu;rjliao@cs.toronto.edu;yli15@wpi.edu,1;6;6,,Reject,1,20,0.0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute;University of Toronto;Worcester Polytechnic Institute,Multi-agent;Imitation Learning;Inverse Reinforcement Learning,143;143;18;143,628;628;18;628,f;m,usa,usa,y,5;4
4123,ICLR,2020,Efficient Training of Robust and Verifiable Neural Networks,Akhilan Boopathy;Lily Weng;Sijia Liu;Pin-Yu Chen;Luca Daniel,akhilan@mit.edu;twweng@mit.edu;sijia.liu@ibm.com;pin-yu.chen@ibm.com;dluca@mit.edu,1;1;3,,Reject,0,6,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;International Business Machines;International Business Machines;Massachusetts Institute of Technology,,5;5;-1;-1;5,5;5;-1;-1;5,m;m,usa,usa,y,1;4
4124,ICLR,2020,Adversarial Video Generation on Complex Datasets,Aidan Clark;Jeff Donahue;Karen Simonyan,aidanclark@google.com;jeffdonahue@google.com;simonyan@google.com,3;3;6,,Reject,1,4,0.0,yes,9/25/19,Google;Google;Google,GAN;generative model;generative adversarial network;video prediction,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,5;4
4125,ICLR,2020,Data Augmentation in Training CNNs: Injecting Noise to Images,Murtaza Eren Akbiyik,erenakbiyik@gmail.com,3;1;3,,Reject,2,0,0.0,yes,9/25/19,International Business Machines,deep learning;data augmentation;convolutional neural networks;noise;image processing;SSIM,-1,-1,m,NAN,NAN,n,
4126,ICLR,2020,Variational Diffusion Autoencoders with Random Walk Sampling,Henry Li;Ofir Lindenbaum;Xiuyuan Cheng;Alexander Cloninger,henryli@eng.ucsd.edu;ofir.lindenbaum@yale.edu;xiuyuan.cheng@duke.edu;acloninger@ucsd.edu,8;3;1,,Reject,0,4,0.0,yes,9/25/19,"University of California, San Diego;Yale University;Duke University;University of California, San Diego",generative models;variational inference;manifold learning;diffusion maps,-1;73;46;-1,31;8;20;31,m;m,usa,usa,y,1;5
4127,ICLR,2020,"INFERENCE, PREDICTION, AND ENTROPY RATE OF CONTINUOUS-TIME, DISCRETE-EVENT PROCESSES",Sarah Marzen;James P. Crutchfield,smarzen@cmc.edu;chaos@cse.ucdavis.edu,1;3;1,,Reject,0,0,0.0,yes,9/25/19,"Central Methodist College;University of California, Davis",continuous-time prediction,-1;-1,-1;55,f;m,usa,usa,n,11
4128,ICLR,2020,Scale-Equivariant Neural Networks with Decomposed Convolutional Filters,Wei Zhu;Qiang Qiu;Robert Calderbank;Guillermo Sapiro;Xiuyuan Cheng,zhu@math.duke.edu;qiang.qiu@duke.edu;robert.calderbank@duke.edu;guillermo.sapiro@duke.edu;xiuyuan.cheng@duke.edu,6;3;6,,Reject,1,5,0.0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University;Duke University,scale-equivariant;convolutional neural network;deformation robustness,46;46;46;46;46,20;20;20;20;20,m;m,europe,se,y,
4129,ICLR,2020,Dynamic Scale Inference by Entropy Minimization,Dequan Wang;Evan Shelhamer;Bruno Olshausen;Trevor Darrell,dqwang@eecs.berkeley.edu;shelhamer@cs.berkeley.edu;baolshausen@berkeley.edu;trevor@eecs.berkeley.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,unsupervised learning;dynamic inference;equivariance;entropy,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n,2
4130,ICLR,2020,The Effect of Residual Architecture on the Per-Layer Gradient of Deep Networks,Etai Littwin;Lior Wolf,etai.littwin@gmail.com;wolf@fb.com,1;6;6,,Reject,0,4,1.0,yes,9/25/19,Tel Aviv University;Facebook,,30;-1,188;-1,m;m,NAN,NAN,n,
4131,ICLR,2020,City Metro Network Expansion with Reinforcement Learning,Yu Wei;Minjia Mao;Xi Zhao;Jianhua Zou,weiyu123112@163.com;maominjia@foxmail.com;zhaoxi1@mail.xjtu.edu.cn;jhzou@sei.xjtu.edu.cn,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Xi'an Jiaotong University;Foxmail;Xi'an Jiaotong University;Xi'an Jiaotong University,,-1;-1;-1;-1,555;-1;555;555,m;m,NAN,NAN,n,8
4132,ICLR,2020,Dropout: Explicit Forms and Capacity Control,Raman Arora;Peter L. Bartlett;Poorya Mianjy;Nathan Srebro,arora@cs.jhu.edu;bartlett@cs.berkeley.edu;mianjy@jhu.edu;nati@ttic.edu,1;1;3;1,,Reject,0,5,0.0,yes,9/25/19,Johns Hopkins University;University of California Berkeley;Johns Hopkins University;Toyota Technological Institute at Chicago,,73;-1;73;-1,12;13;12;-1,m;m,NAN,NAN,y,1
4133,ICLR,2020,Verification of Generative-Model-Based Visual Transformations,Matthew Mirman;Timon Gehr;Martin Vechev,matthew.mirman@inf.ethz.ch;timon.gehr@inf.ethz.ch;martin.vechev@inf.ethz.ch,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,robustness certification;formal verification;robustness analysis;latent space interpolations,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5
4134,ICLR,2020,Beyond GANs: Transforming without a Target Distribution,Matthew Amodio;David van Dijk;Ruth Montgomery;Guy Wolf;Smita Krishnaswamy,matthew.amodio@yale.edu;david.vandijk@yale.edu;ruth.montgomery@yale.edu;guy.wolf@umontreal.ca;smita.krishnaswamy@yale.edu,6;6;3,,Reject,0,3,0.0,yes,9/25/19,Yale University;Yale University;Yale University;University of Montreal;Yale University,GAN;domain transfer;computational biology;latent space manipulations,73;73;73;118;73,8;8;8;85;8,m;f,europe,fi,n,7;5;4
4135,ICLR,2020,On Variational Learning of Controllable Representations for Text without Supervision,Peng Xu;Yanshuai Cao;Jackie Chi Kit Cheung,pxu4@ualberta.ca;yanshuaicao@gmail.com;jcheung@cs.mcgill.ca,8;3;6,,Reject,0,5,1.0,yes,9/25/19,University of Alberta;;McGill University,sequence variational autoencoders;unsupervised learning;controllable text generation;text style transfer,102;-1;102,136;-1;42,m;m,canada,ca,n,5
4136,ICLR,2020,Demystifying Graph Neural Network Via Graph Filter Assessment,Yewen Wang;Ziniu Hu;Yusong Ye;Yizhou Sun,wyw10804@gmail.com;bull@cs.ucla.edu;yusongye@g.ucla.edu;yzsun@cs.ucla.edu,8;1;3,,Reject,3,6,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Graph Neural Networks;Graph convolutional filter analysis;representational power,-1;-1;-1;-1,17;17;17;17,u;f,usa,usa,y,8;10
4137,ICLR,2020,Individualised Dose-Response Estimation using Generative Adversarial Nets,Ioana Bica;James Jordon;Mihaela van der Schaar,ioana.bica@eng.ox.ac.uk;james.jordon@wolfson.ox.ac.uk;mschaar@turing.ac.uk,1;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;Alan Turing Institute,individualised dose-response estimation;treatment effects;causal inference;generative adversarial networks,46;46;-1,1;1;-1,f;f,NAN,NAN,n,5;4
4138,ICLR,2020,"``Best-of-Many-Samples"" Distribution Matching""",Apratim Bhattacharyya;Mario Fritz;Bernt Schiele,abhattac@mpi-inf.mpg.de;fritz@cispa.saarland;schiele@mpi-inf.mpg.de,3;3;6,,Reject,0,0,0.0,yes,9/25/19,Max-Planck Institute;CISPA Helmholtz Center for Information Security;Max-Planck Institute,Distribution Matching;Generative Adversarial Networks;Variational Autoencoders,-1;92;-1,-1;-1;-1,m;m,NAN,NAN,n,5;4
4139,ICLR,2020,Swoosh! Rattle! Thump! - Actions that Sound,Dhiraj Gandhi;Abhinav Gupta;Lerrel Pinto,g.prakashchand@gmail.com;abhinavg@cs.cmu.edu;lerrel.pinto@gmail.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;New York University,Sound;Action;Audio Representations,-1;1;22,-1;27;29,m;m,usa,usa,n,
4140,ICLR,2020,Near-Zero-Cost Differentially Private Deep Learning with Teacher Ensembles,Lichao Sun;Yingbo Zhou;Jia Li;Richard Socher;Philip S. Yu;Caiming Xiong,james.lichao.sun@gmail.com;yingbo.zhou@salesforce.com;jia.li@salesforce.com;rsocher@salesforce.com;psyu@uic.edu;cxiong@salesforce.com,1;1;1,,Reject,0,3,0.0,yes,9/25/19,"Lehigh University;SalesForce.com;SalesForce.com;SalesForce.com;University of Illinois, Chicago;SalesForce.com",,248;-1;-1;-1;-1;-1,633;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
4141,ICLR,2020,On the Tunability of Optimizers in Deep Learning,Prabhu Teja S*;Florian Mai*;Thijs Vogels;Martin Jaggi;Francois Fleuret,prabhu.teja@idiap.ch;florian.mai@idiap.ch;thijs.vogels@epfl.ch;martin.jaggi@epfl.ch;francois.fleuret@idiap.ch,3;3,,Reject,0,10,0.0,yes,9/25/19,Idiap Research Institute;Idiap Research Institute;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Idiap Research Institute,Optimization;Benchmarking;Hyperparameter optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4142,ICLR,2020,GUIDEGAN:  ATTENTION  BASED  SPATIAL  GUIDANCE FOR  IMAGE-TO-IMAGE TRANSLATION,Yu Lin;Yigong Wang;Yifan Li;Zhuoyi Wang;Yang Gao;Latifur Khan,yxl163430@utdallas.edu;yxw158830@utdallas.edu;yli@utdallas.edu;zhuoyi.wang1@utdallas.edu;yxg122530@utdallas.edu;lkhan@utdallas.edu,3;3;3,,Reject,0,5,0.0,yes,9/25/19,"University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas",Image-to-Image translation;Attention Learning;GAN,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,f;m,usa,usa,n,8;5;4
4143,ICLR,2020,ROBUST GENERATIVE ADVERSARIAL NETWORK,Shufei Zhang;Zhuang Qian;Kaizhu Huang;Rui Zhang;Jimin Xiao,shufei.zhang@xjtlu.edu.cn;qz2009425@gmail.com;kaizhu.huang@xjtlu.edu.cn;rui.zhang02@xjtlu.edu.cn;jimin.xiao@xjtlu.edu.cn,1;3;3,,Reject,0,0,0.0,yes,9/25/19,Xi'an Jiaotong-Liverpool University;;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University,Generative Adversarial Network;Robustness;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;u,NAN,NAN,y,1;5;4
4144,ICLR,2020,Decoupling Hierarchical Recurrent Neural Networks With Locally Computable Losses,Asier Mujika;Felix Weissenberger;Angelika Steger,asierm@inf.ethz.ch;felix.weissenberger@inf.ethz.ch;steger@inf.ethz.ch,1;1;1,,Reject,0,1,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,
4145,ICLR,2020,Branched Multi-Task Networks: Deciding What Layers To Share,Simon Vandenhende;Stamatios Georgoulis;Bert De Brabandere;Luc Van Gool,simon.vandenhende@kuleuven.be;georgous@ee.ethz.ch;bert.debrabandere@esat.kuleuven.be;vangool@vision.ee.ethz.ch,3;6;1,,Reject,0,5,0.0,yes,9/25/19,KU Leuven;Swiss Federal Institute of Technology;KU Leuven;Swiss Federal Institute of Technology,Multi-Task Learning;Neural Network Architectures;Deep learning;Efficient Architectures,143;-1;143;-1,45;-1;45;-1,m;m,NAN,NAN,n,
4146,ICLR,2020,Variational pSOM: Deep Probabilistic Clustering with Self-Organizing Maps,Laura Manduchi;Matthias H√ºser;Gunnar R√§tsch;Vincent Fortuin,lauraman@student.ethz.ch;matthias.hueser@inf.ethz.ch;gunnar.ratsch@ratschlab.org;fortuin@inf.ethz.ch,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;MSKCC New York;Swiss Federal Institute of Technology,Self-organizing maps;Generative models;Unsupervised representation learning,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,
4147,ICLR,2020,Tensor Graph Convolutional Networks for Prediction on Dynamic Graphs,Osman Asif Malik;Shashanka Ubaru;Lior Horesh;Misha E. Kilmer;Haim Avron,osman.malik.87@gmail.com;shashanka.ubaru@ibm.com;lhoresh@us.ibm.com;misha.kilmer@tufts.edu;haimav@tauex.tau.ac.il,3;6;1,,Reject,0,5,0.0,yes,9/25/19,"University of Colorado, Boulder;International Business Machines;International Business Machines;Tufts University;Tel Aviv University",graph convolutional networks;graph learning;dynamic graphs;edge classification;tensors,59;-1;-1;194;30,123;-1;-1;139;188,m;m,europe,il,y,3;10
4148,ICLR,2020,Mint: Matrix-Interleaving for Multi-Task Learning,Tianhe Yu;Saurabh Kumar;Eric Mitchell;Abhishek Gupta;Karol Hausman;Sergey Levine;Chelsea Finn,tianheyu@cs.stanford.edu;szk@stanford.edu;eric.anthony.mitchell95@gmail.com;abhigupta@berkeley.edu;hausmankarol@gmail.com;svlevine@eecs.berkeley.edu;cbfinn@cs.stanford.edu,3;3;3;6,,Reject,0,5,0.0,yes,9/25/19,Stanford University;Stanford University;;University of California Berkeley;Google;University of California Berkeley;Stanford University,multi-task learning,5;5;-1;-1;-1;-1;5,4;4;-1;13;-1;13;4,m;f,usa,usa,y,1
4149,ICLR,2020,Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients,Chengcheng Ma;Baoyuan Wu;Shibiao Xu;Yanbo Fan;Yong Zhang;Xiaopeng Zhang;Zhifeng Li,machengcheng2016@gmail.com;wubaoyuan1987@gmail.com;shibiao.xu@ia.ac.cn;fanyanbo0124@gmail.com;zhangyong201303@gmail.com;xiaopeng.zhang@ia.ac.cn;michaelzfli@tencent.com,6;6;3,,Reject,0,3,0.0,yes,9/25/19,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;The Chinese University of Hong Kong, Shenzhen;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tencent AI Lab;;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tencent AI Lab",,-1;46;30;-1;-1;30;-1,-1;35;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,4
4150,ICLR,2020,Multi-objective Neural Architecture Search via Predictive Network Performance Optimization,Han Shi;Renjie Pi;Hang Xu;Zhenguo Li;James T. Kwok;Tong Zhang,hshiac@cse.ust.hk;pipilu@connect.hku.hk;xbjxh@live.com;li.zhenguo@huawei.com;jamesk@cse.ust.hk;tongzhang@tongzhang-ml.org,3;3;3,,Reject,1,8,0.0,yes,9/25/19,The Hong Kong University of Science and Technology;The University of Hong Kong;Huawei Technologies Ltd.;Huawei Technologies Ltd.;The Hong Kong University of Science and Technology;Google,,-1;92;-1;-1;-1;-1,47;35;-1;-1;47;-1,m;m,NAN,NAN,n,11;10
4151,ICLR,2020,CONFEDERATED MACHINE LEARNING ON HORIZONTALLY AND VERTICALLY SEPARATED MEDICAL DATA FOR LARGE-SCALE HEALTH SYSTEM INTELLIGENCE,Dianbo Liu;Tim Miller;Kenneth Mandl,dianbo.liu@childrens.harvard.edu;timothy.miller@childrens.harvard.edu;kenneth.mandl@childrens.harvard.edu,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Harvard University;Harvard University;Harvard University,Confederated learning;siloed medical data;representation joining,52;52;52,7;7;7,m;m,usa,usa,n,
4152,ICLR,2020,On Evaluating Explainability Algorithms,Gokula Krishnan Santhanam;Ali Alami-Idrissi;Nuno Mota;Anika Schumann;Ioana Giurgiu,gst@zurich.ibm.com;aai@zurich.ibm.com;nuno.motagoncalves@epfl.ch;ikh@zurich.ibm.com;igi@zurich.ibm.com,1;3;1,,Reject,0,6,0.0,yes,9/25/19,International Business Machines;International Business Machines;Swiss Federal Institute of Technology Lausanne;International Business Machines;International Business Machines,interpretability;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n,
4153,ICLR,2020,FRICATIVE PHONEME DETECTION WITH ZERO DELAY,Metehan Yurt;Alberto N. Escalante B.;Veniamin I. Morgenshtern,metehan.yurt@fau.de;alberto.escalante@sivantos.com;veniamin.morgenshtern@fau.de,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;Sivantos;Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg,fricative detection;phoneme detection;speech recognition;deep learning;hearing aids;zero delay;extrapolation;TIMIT,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4154,ICLR,2020,Deep Mining: Detecting Anomalous Patterns in Neural Network Activations with Subset Scanning,Skyler Speakman;Celia Cintas;Victor Akinwande;Srihari Sridharan;Edward McFowland III,skyler@ke.ibm.com;celia.cintas@ibm.com;victor.akinwande1@ibm.com;sriharis.sridharan@ke.ibm.com;mcfowland@umn.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,"International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Minnesota, Minneapolis",anomalous pattern detection;subset scanning;node activations;adversarial noise,-1;-1;-1;-1;73,-1;-1;-1;-1;79,m;m,NAN,NAN,n,4
4155,ICLR,2020,"GRAPHS, ENTITIES, AND STEP MIXTURE",Kyuyong Shin;Wonyoung Shin;Jung-Woo Ha;Sunyoung Kwon,p37329@gmail.com;wyshin@kaist.ac.kr;jungwoo.ha@navercorp.com;sunny.kwon@navercorp.com,3;6;3,,Reject,0,7,0.0,yes,9/25/19,NAVER;Korea Advanced Institute of Science and Technology;NAVER;NAVER,Graph Neural Network;Random Walk;Attention,-1;-1;-1;-1,-1;110;-1;-1,m;f,europe,gr,n,8;1;10
4156,ICLR,2020,Learning Human Postural Control with Hierarchical Acquisition Functions,Nils Rottmann;Tjasa Kunavar;Jan Babic;Jan Peters;Elmar Rueckert,rottmann@rob.uni-luebeck.de;tjasa.kunavar@ijs.si;jan.babic@ijs.si;mail@jan-peters.net;rueckert@ai-lab.science,1;1,,Reject,0,3,0.0,yes,9/25/19,Universit√§t zu L√ºbeck;Jozef Stefan institute;Jozef Stefan institute;TU Darmstadt;Universit√§t zu L√ºbeck,Human Postural Control Model;Hierarchical Bayesian Optimization;Acquisition Function,-1;-1;-1;59;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11
4157,ICLR,2020,Unknown-Aware Deep Neural Network,Lei Cao;Yizhou Yan;Samuel Madden;Elke Rundensteiner,lcao@csail.mit.edu;yyan2@wpi.edu;madden@csail.mit.edu;rundenst@cs.wpi.edu,8;3;3,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Worcester Polytechnic Institute;Massachusetts Institute of Technology;Worcester Polytechnic Institute,unknown;rejection;CNN;product relationship,5;143;5;143,5;628;5;628,m;f,usa,usa,n,1
4158,ICLR,2020,Low Bias Gradient Estimates for Very Deep Boolean Stochastic Networks,Adeel Pervez;Taco Cohen;Efstratios Gavves,a.a.pervez@uva.nl;tacos@qti.qualcomm.com;efstratios.gavves@gmail.com,3;6;6,,Reject,0,11,0.0,yes,9/25/19,"University of Amsterdam;Qualcomm Inc, QualComm;University of Amsterdam",,143;-1;143,62;-1;62,m;m,europe,nl,y,
4159,ICLR,2020,SoftLoc: Robust Temporal Localization under Label Misalignment,Julien Schroeter;Kirill Sidorov;Dave Marshall,schroeterj1@cardiff.ac.uk;sidorovk@cardiff.ac.uk;marshallad@cardiff.ac.uk,3;6;3,,Reject,0,6,0.0,yes,9/25/19,Cardiff University;Cardiff University;Cardiff University,deep learning;temporal localization;robustness;label misalignment;music;time series,168;168;168,196;196;196,m;m,europe,uk,n,
4160,ICLR,2020,Learning Video Representations using Contrastive Bidirectional Transformer,Chen Sun;Fabien Baradel;Kevin Murphy;Cordelia Schmid,chensun@google.com;fabien.baradel@insa-lyon.fr;kpmurphy@google.com;cordelias@google.com,6;6;6,,Reject,0,3,0.0,yes,9/25/19,Google;INSA de Lyon;Google;Google,self-supervised learning;video representations;cross-modal learning,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,2
4161,ICLR,2020,ShardNet: One Filter Set to Rule Them All,Saumya Jetley;Tommaso Cavallari;Philip Torr;Stuart Golodetz,sjetley@robots.ox.ac.uk;tommaso.cavallari@five.ai;phil@five.ai;stuart@five.ai,3;3;1,,Reject,0,7,0.0,yes,9/25/19,University of Oxford;FiveAI;FiveAI;FiveAI,neural network compression;filter sharing;network interpretability,46;-1;-1;-1,1;-1;-1;-1,f;m,NAN,NAN,n,2;1
4162,ICLR,2020,Explaining Time Series by Counterfactuals,Sana Tonekaboni;Shalmali Joshi;David Duvenaud;Anna Goldenberg,stonekaboni@cs.toronto.edu;shalmali@vectorinstitute.ai;duvenaud@cs.toronto.edu;anna.goldenberg@utoronto.ca,6;3;3,,Reject,0,4,0.0,yes,9/25/19,University of Toronto;Vector Institute;University of Toronto;Toronto University,explainability;counterfactual modeling;time series,18;-1;18;-1,18;-1;18;-1,f;f,NAN,NAN,n,
4163,ICLR,2020,On the Linguistic Capacity of Real-time Counter Automata,William Merrill,vikingarnir.will@gmail.com,6;1;6,,Reject,0,4,0.0,yes,9/25/19,Allen Institute for Artificial Intelligence,formal language theory;counter automata;natural language processing;deep learning,-1,-1,m,NAN,NAN,y,3;8;1
4164,ICLR,2020,The fairness-accuracy landscape of neural classifiers,Susan Wei;Marc Niethammer,susan.wei@unimelb.edu.au;mn@cs.unc.edu,1;6;3,,Reject,0,5,0.0,yes,9/25/19,"The University of Melbourne;University of North Carolina, Chapel Hill",,85;64,32;-1,f;m,NAN,NAN,n,8;7;4
4165,ICLR,2020,Corpus Based Amharic Sentiment Lexicon Generation,Girma Neshir;Andeas Rauber;and Solomon Atnafu,girma1978@gmail.com;rauber@ifs.tuwien.ac.at;solomon.atnafu@aau.edu.et,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Addis Ababa University;TU Wien Vienna University of Technology;Addis Ababa University,Amharic sentiment lexicon;Amharic sentiment classification;seed words,-1;102;-1,-1;360;-1,m;m,NAN,NAN,n,
4166,ICLR,2020,MaskConvNet: Training Efficient ConvNets from Scratch via Budget-constrained Filter Pruning,Raden Mu'az Mun'im;Jie Lin;Vijay Chandrasekhar;Koichi Shinoda,raden.m.muaz@gmail.com;lin-j@i2r.a-star.edu.sg;vijay@i2r.a-star.edu.sg;shinoda@ks.cs.titech.ac.jp,3;3;3,,Reject,0,8,0.0,yes,9/25/19,"Universiti Teknologi Malaysia;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Tokyo Institute of Technology",Structured Pruning;Sparsity Regularization;Budget-Aware,-1;-1;-1;168,674;-1;-1;299,m;m,asia,jp,n,
4167,ICLR,2020,Curvature-based Robustness Certificates against Adversarial Examples,Sahil Singla;Soheil Feizi,ssingla@cs.umd.edu;sfeizi@cs.umd.edu,6;6;6,,Reject,0,8,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park",Adversarial examples;Robustness certificates;Adversarial attacks;Machine Learning Security,12;12,91;91,m;m,usa,usa,y,1;9;4
4168,ICLR,2020,Pipelined Training with Stale Weights of Deep Convolutional Neural Networks,Lifu Zhang;Tarek S. Abdelrahman,lifu.zhang@mail.utoronto.ca;tsa@ece.utoronto.ca,3;6;3;3,,Reject,0,6,0.0,yes,9/25/19,Toronto University;Toronto University,Distributed CNN Training;Pipelined Backpropagation;Training with Stale Weights,-1;-1,-1;-1,m;m,NAN,NAN,n,
4169,ICLR,2020,Information Plane Analysis of Deep Neural Networks via Matrix--Based Renyi's Entropy and Tensor Kernels,Kristoffer Wickstr√∏m;Sigurd L√∏kse;Michael Kampffmeyer;Shujian Yu;Jose Principe;Robert Jenssen,kristoffer.k.wickstrom@uit.no;sigurd.lokse@uit.no;michael.c.kampffmeyer@uit.no;yusjlcy9011@cnel.ufl.edu;principe@cnel.ufl.edu;robert.jenssen@uit.no,3;6;6,,Reject,0,4,0.0,yes,9/25/19,UiT The Arctic University of Norway;UiT The Arctic University of Norway;UiT The Arctic University of Norway;University of Florida;University of Florida;UiT The Arctic University of Norway,information plane;information theory;deep neural networks;entropy;mutual information;tensor kernels,-1;-1;-1;168;168;-1,419;419;419;174;174;419,m;m,NAN,NAN,y,8;1
4170,ICLR,2020,Disentangled Representation Learning with Sequential Residual Variational Autoencoder,Nanxiang Li;Shabnam Ghaffarzadegan;Liu Ren,nanxiang.li@us.bosch.com;shabnam.ghaffarzadegan@us.bosch.com;liu.ren@us.bosch.com,3;8;3,,Reject,0,3,0.0,yes,9/25/19,Bosch;Bosch;Bosch,Disentangled Representation Learning;Variational Autoencoder;Residual Learning,-1;-1;-1,297;297;297,m;m,NAN,NAN,n,5
4171,ICLR,2020,MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics,Mohammadamin Barekatain;Ryo Yonetani;Masashi Hamaya,m.barekatain@tum.de;ryo.yonetani@sinicx.com;masashi.hamaya@sinicx.com,1;8;6,,Reject,0,7,0.0,yes,9/25/19,Technical University Munich;OMRON SINIC X;OMRON SINIC X,reinforcement learning;transfer learning;policy aggregation;residual policy learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4172,ICLR,2020,Simultaneous Classification and Out-of-Distribution Detection Using Deep Neural Networks,Aristotelis-Angelos Papadopoulos;Nazim Shaikh;Jiamian Wang;Mohammad Reza Rajati,aristotp@usc.edu;nshaikh@usc.edu;jiamianw@usc.edu;rajati@usc.edu,6;1;3,,Reject,0,11,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;University of Southern California,Out-of-Distribution Detection;OOD detection;Outlier Exposure;Classification;Open-World Classification;Anomaly Detection;Novelty Detection;Calibration;Neural Networks,36;36;36;36,62;62;62;62,m;m,usa,usa,n,
4173,ICLR,2020,"Learning vector representation of local content and matrix representation of local motion, with implications for V1",Ruiqi Gao;Jianwen Xie;Siyuan Huang;Yufan Ren;Song-Chun Zhu;Ying Nian Wu,ruiqigao@ucla.edu;jianwen@ucla.edu;huangsiyuan@ucla.edu;3160104704@zju.edu.cn;sczhu@stat.ucla.edu;ywu@stat.ucla.edu,3;1;6,,Reject,0,5,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;Zhejiang University;University of California, Los Angeles;University of California, Los Angeles",Representation learning;V1;neuroscience,-1;-1;-1;39;-1;-1,17;17;17;107;17;17,f;m,usa,usa,n,
4174,ICLR,2020,Data Valuation using Reinforcement Learning,Jinsung Yoon;Sercan O. Arik;Tomas Pfister,jsyoon0823@gmail.com;soarik@google.com;tpfister@google.com,6;6;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google,Data valuation;Domain adaptation;Robust learning;Corrupted sample discovery,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4175,ICLR,2020,Reject Illegal Inputs: Scaling Generative Classifiers with Supervised Deep Infomax,Xin WANG;SiuMing Yiu,xwang@cs.hku.hk;smyiu@cs.hku.hk,3;8;3,,Reject,0,3,1.0,yes,9/25/19,The University of Hong Kong;The University of Hong Kong,generative classifiers;selective classification;classification with rejection,92;92,35;35,u;m,NAN,NAN,n,5;4
4176,ICLR,2020,Surrogate-Based Constrained Langevin Sampling With Applications to Optimal Material Configuration Design,Thanh V Nguyen;Youssef Mroueh;Samuel C. Hoffman;Payel Das;Pierre Dognin;Giuseppe Romano;Chinmay Hegde,thanhng@iastate.edu;mroueh@us.ibm.com;shoffman@ibm.com;daspa@us.ibm.com;pdognin@us.ibm.com;romanog@mit.edu;chinmay@iastate.edu,3;6;6,,Reject,0,4,0.0,yes,9/25/19,Iowa State University;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Massachusetts Institute of Technology;Iowa State University,Black-box Constrained Langevin sampling;surrogate methods;projected and proximal methods;approximation theory of gradients;nano-porous material configuration design,194;-1;-1;-1;-1;5;194,399;-1;-1;-1;-1;5;399,m;m,usa,usa,y,1
4177,ICLR,2020,VILD: Variational Imitation Learning with Diverse-quality Demonstrations,Voot Tangkaratt;Bo Han;Mohammad Emtiyaz Khan;Masashi Sugiyama,voot.tangkaratt@riken.jp;bo.han@riken.jp;emtiyaz.khan@riken.jp;sugi@k.u-tokyo.ac.jp,6;3;6,,Reject,0,4,0.0,yes,9/25/19,RIKEN;RIKEN;RIKEN;The University of Tokyo,Imitation learning;inverse reinforcement learning;noisy demonstrations,-1;-1;-1;64,-1;-1;-1;36,m;m,NAN,NAN,n,10
4178,ICLR,2020,OPTIMAL BINARY QUANTIZATION FOR DEEP NEURAL NETWORKS,Hadi Pouransari;Oncel Tuzel,mpouransari@apple.com;onceltuzel@gmail.com,3;3;6;6,,Reject,0,5,1.0,yes,9/25/19,Apple;Apple,Binary Neural Networks;Quantization,-1;-1,-1;-1,m;m,NAN,NAN,n,1
4179,ICLR,2020,Learning Through Limited Self-Supervision: Improving Time-Series Classification Without Additional Data via Auxiliary Tasks,Ian Fox;Harry Rubin-Falcone;Jenna Wiens,ifox@umich.edu;hrf@umich.edu;wiensj@umich.edu,1;3;1,,Reject,0,4,0.0,yes,9/25/19,University of Michigan;University of Michigan;University of Michigan,Sequential Representation Learning;Self-Supervision;Function Approximation,7;7;7,21;21;21,m;f,usa,usa,n,
4180,ICLR,2020,Robust Natural Language Representation Learning for Natural Language Inference by Projecting Superficial Words out,Wanyun Cui;Guangyu Zheng;Wei Wang,cui.wanyun@sufe.edu.cn;simonzgy@outlook.com;weiwang1@fudan.edu.cn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,University of Science and Technology of China;;Fudan University,natural language inference;first order logic,-1;-1;73,80;-1;109,m;f,asia,cn,n,3
4181,ICLR,2020,DSReg: Using Distant Supervision as a Regularizer,Yuxian Meng;Muyu Li;Xiaoya Li;Wei Wu;Fei Wu;Jiwei Li,yuxian_meng@shannonai.com;muyu_li@shannonai.com;xiaoya_li@shannonai.com;wei_wu@shannonai.com;wufei@zju.edu.cn;jiwei_li@shannonai.com,6;3;3,,Reject,0,2,0.0,yes,9/25/19,Shannon.AI;Shannon.AI;Shannon.AI;Shannon.AI;Zhejiang University;Shannon.AI,,-1;-1;-1;-1;39;-1,-1;-1;-1;-1;107;-1,m;m,NAN,NAN,n,3
4182,ICLR,2020,MxPool: Multiplex Pooling for Hierarchical Graph Representation Learning,Yanyan Liang;Yanfeng Zhang;Fangjing Wang;Qian Xu,13354227340@163.com;zhangyf@mail.neu.edu.cn;inggraph@qq.com;xuqian1286@163.com,3;3;3,,Reject,0,0,0.0,yes,9/25/19,163;Northeastern University;;163,GNN;graph pooling;graph representation learning,-1;16;-1;-1,-1;906;-1;-1,f;f,asia,in,n,8;10
4183,ICLR,2020,Non-linear System Identification from Partial Observations via Iterative Smoothing and Learning,Kunal Menda;Jean de Becdeli√®vre;Jayesh K Gupta;Ilan Kroo;Mykel J. Kochenderfer;Zachary Manchester,kmenda@stanford.edu;jeandb@stanford.edu;jkg@cs.stanford.edu;kroo@stanford.edu;mykel@stanford.edu;zacmanchester@stanford.edu,6;6;6,,Reject,0,6,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,System Identification;Dynamical Systems;Partial Observations;Non-linear Programming;Expectation Maximization;Neural Networks,5;5;5;5;5;5,4;4;4;4;4;4,m;m,usa,usa,n,1
4184,ICLR,2020,Policy Message Passing: A New Algorithm for Probabilistic Graph Inference,Zhiwei Deng;Greg Mori,zhiweid@princeton.edu;mori@cs.sfu.ca,1;3;3,,Reject,0,0,0.0,yes,9/25/19,Princeton University;Simon Fraser University,graph inference algorithm;graph reasoning;variational inference,30;52,6;272,m;m,canada,ca,n,10
4185,ICLR,2020,Learning Mahalanobis Metric Spaces via Geometric Approximation Algorithms,Diego Ihara;Neshat Mohammadi;Anastasios Sidiropoulos,dihara@gmail.com;nmoham24@uic.edu;sidiropo@uic.edu,3;6;3,,Reject,0,3,0.0,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",Metric Learning;Geometric Algorithms;Approximation Algorithms,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y,1;4
4186,ICLR,2020,On Understanding Knowledge Graph Representation,Carl Allen*;Ivana Balazevic*;Timothy M Hospedales,carl.allen@ed.ac.uk;ivana.balazevic@ed.ac.uk;t.hospedales@ed.ac.uk,6;6;6,,Reject,1,6,1.0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh,knowledge graphs;word embedding;representation learning,36;36;36,30;30;30,m;m,europe,uk,n,3;10
4187,ICLR,2020,Learning to Prove Theorems by Learning to Generate Theorems,Mingzhe Wang;Jia Deng,mingzhew@cs.princeton.edu;jiadeng@princeton.edu,6;6;3,,Reject,0,6,0.0,yes,9/25/19,Princeton University;Princeton University,,30;30,6;6,m;m,usa,usa,n,1
4188,ICLR,2020,Augmenting Self-attention with Persistent Memory,Sainbayar Sukhbaatar;Edouard Grave;Guillaume Lample;Herve Jegou;Armand Joulin,sainbar@fb.com;egrave@fb.com;guismay@fb.com;rvj@fb.com;ajoulin@fb.com,3;6;6,,Reject,0,2,0.0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook;Facebook,transformer;language modeling;self-attention,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
4189,ICLR,2020,Realism Index: Interpolation in Generative Models With Arbitrary Prior,≈Åukasz Struski;Jacek Tabor;Igor Podolak;Aleksandra Nowak;Krzysztof Maziarz,lukasz.struski@uj.edu.pl;jacek.tabor@uj.edu.pl;igor.podolak@uj.edu.pl;aknoow@gmail.com;krzysztof.s.maziarz@gmail.com,3;3,,Reject,0,6,0.0,yes,9/25/19,Jagiellonian University;Jagiellonian University;Jagiellonian University;;Microsoft,,-1;-1;-1;-1;-1,610;610;610;-1;-1,m;m,NAN,NAN,y,5
4190,ICLR,2020,Fully Convolutional Graph Neural Networks using Bipartite Graph Convolutions,Marcel Nassar;Xin Wang;Evren Tumer,nassar.marcel@gmail.com;caseus.viridis@gmail.com;nervetumer@gmail.com,3;1;3,,Reject,1,3,0.0,yes,9/25/19,"Intel;Cerebras Systems, Inc;University of California, San Francisco",Graph Neural Networks;Graph Convolutional Networks,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,10
4191,ICLR,2020,Selective sampling for accelerating  training of deep neural networks,Berry Weinstein;Shai Fine;Yacov Hel-Or,berry.weinstein@post.idc.ac.il;shai.fine@idc.ac.il;toky@idc.ac.il,1;1;3,,Reject,0,2,0.0,yes,9/25/19,interdisciplinary center herzliya;interdisciplinary center herzliya;interdisciplinary center herzliya,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
4192,ICLR,2020,Hierarchical Graph-to-Graph Translation for Molecules,Wengong Jin;Regina Barzilay;Tommi Jaakkola,wengong@csail.mit.edu;regina@csail.mit.edu;tommi@csail.mit.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,graph generation;deep learning,5;5;5,5;5;5,m;m,usa,usa,n,10
4193,ICLR,2020,MelNet: A Generative Model for Audio in the Frequency Domain,Sean Vasquez;Mike Lewis,seanjv@mit.edu;mikelewis@fb.com,6;3;8,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Facebook,,5;-1,5;-1,m;m,NAN,NAN,n,5
4194,ICLR,2020,End-to-end learning of energy-based representations for irregularly-sampled signals and images,Ronan Fablet;Lucas Drumetz;Fran√ßois Rousseau,ronan.fablet@imt-atlantique.fr;lucas.drumetz@imt-atlantique.fr;francois.rousseau@imt-atlantique.fr,3;1;1,,Reject,0,0,0.0,yes,9/25/19,IMT Atlantique;IMT Atlantique;IMT Atlantique,end-to-end-learning;irregularly-sampled data;energy representations;optimal interpolation,-1;-1;-1,393;393;393,m;m,NAN,NAN,n,11
4195,ICLR,2020,Reparameterized Variational Divergence Minimization for Stable Imitation,Dilip Arumugam;Debadeepta Dey;Alekh Agarwal;Asli Celikyilmaz;Elnaz Nouri;Eric Horvitz;Bill Dolan,dilip@cs.stanford.edu;dedey@microsoft.com;alekha@microsoft.com;aslicel@microsoft.com;elnouri@microsoft.com;horvitz@microsoft.com;billdol@microsoft.com,1;1;1,,Reject,0,9,0.0,yes,9/25/19,Stanford University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Imitation Learning;Reinforcement Learning;Adversarial Learning;Learning from Demonstration,5;-1;-1;-1;-1;-1;-1,4;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
4196,ICLR,2020,TrojanNet: Exposing the Danger of Trojan Horse Attack on Neural Networks,Chuan Guo;Ruihan Wu;Kilian Q. Weinberger,cg563@cornell.edu;rw565@cornell.edu;kqw4@cornell.edu,3;3;3,,Reject,0,1,0.0,yes,9/25/19,Cornell University;Cornell University;Cornell University,machine learning security,7;7;7,19;19;19,m;m,usa,usa,y,1;4
4197,ICLR,2020,SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks,Jingwei GUAN;Cheng PAN;Songnan LI and Dahai YU,jwguan37@gmail.com;pancheng@tcl.com;lisn@tcl.com;dahai.yu@tcl.com,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Chinese University of Hong Kong;Tcl;Tcl;Tcl,Super Resolution GAN Denoise,-1;-1;-1;-1,-1;15;15;15,f;m,asia,in,n,5;4
4198,ICLR,2020,Detecting malicious PDF using CNN,Raphael Fettaya;Yishay Mansour,raphaelfettaya@gmail.com;mansour.yishay@gmail.com,1;1;3,,Reject,0,1,0.0,yes,9/25/19,Tel Aviv University;Tel Aviv University,Cybersecurity;Convolutional Neural Network;Malware,-1;-1,-1;-1,m;m,asia,in,n,
4199,ICLR,2020,Novelty Search in representational space for sample efficient exploration,Ruo Yu Tao;Vincent Fran√ßois-Lavet;Joelle Pineau,ruo.tao@mail.mcgill.ca;vincent.francois-lavet@mail.mcgill.ca;jpineau@cs.mcgill.ca,1;6;3,,Reject,0,3,0.0,yes,9/25/19,McGill University;McGill University;McGill University,Reinforcement Learning;Exploration,102;102;102,42;42;42,m;f,canada,ca,n,
4200,ICLR,2020,"Feature-Robustness, Flatness and Generalization Error for Deep Neural Networks",Henning Petzka;Linara Adilova;Michael Kamp;Cristian Sminchisescu,henning.petzka@gmail.com;adylova.linara.r@gmail.com;info@michaelkamp.org;cristian.sminchisescu@math.lth.se,1;3;3,,Reject,0,8,1.0,yes,9/25/19,Lund University;Ruhr-Universt√§t Bochum;CISPA Helmholtz-Zentrum f√ºr Informationssicherheit;Lund University,robustness;flatness;generalization error;loss surface;deep neural networks;feature space,445;-1;-1;445,98;-1;-1;98,m;m,asia,cn,y,1
4201,ICLR,2020,Robust Cross-lingual Embeddings from Parallel Sentences ,Ali Sabet;Prakhar Gupta;Jean-Baptiste Cordonnier;Robert West;Martin Jaggi,asabet@uwaterloo.ca;prakhar.gupta@epfl.ch;jean-baptiste.cordonnier@epfl.ch;robert.west@epfl.ch;martin.jaggi@epfl.ch,3;3;8,,Reject,0,4,0.0,yes,9/25/19,University of Waterloo;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Cross-lingual embeddings;sent2vec;word2vec;bilingual;word translation;sentence retrieval;text;NLP;word vectors;sentence vectors,30;-1;-1;-1;-1,235;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
4202,ICLR,2020,PowerSGD: Powered Stochastic Gradient Descent Methods for Accelerated Non-Convex Optimization,Jun Liu;Beitong Zhou;Weigao Sun;Ruijuan Chen;Claire J. Tomlin;Ye Yuan,j.liu@uwaterloo.ca;zhoubt@hust.edu.cn;sunweigao@outlook.com;ruijuanchen@hust.edu.cn;tomlin@eecs.berkeley.edu;yye@hust.edu.cn,3;3;8,,Reject,1,5,0.0,yes,9/25/19,University of Waterloo;Hong Kong University of Science and Technology;;Hong Kong University of Science and Technology;University of California Berkeley;Hong Kong University of Science and Technology,stochastic gradient descent;non-convex optimization;powerball function;acceleration,30;-1;-1;-1;-1;-1,235;47;-1;47;13;47,m;m,NAN,NAN,y,1;9
4203,ICLR,2020,Unaligned Image-to-Sequence Transformation with Loop Consistency,Siyang Wang;Justin Lazarow;Kwonjoon Lee;Zhuowen Tu,siw030@ucsd.edu;jlazarow@ucsd.edu;kwl042@ucsd.edu;ztu@ucsd.edu,1;3;3,,Reject,0,0,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",,-1;-1;-1;-1,31;31;31;31,f;m,usa,usa,n,
4204,ICLR,2020,Progressive Compressed Records: Taking a Byte Out of Deep Learning Data,Michael Kuchnik;George Amvrosiadis;Virginia Smith,mkuchnik@andrew.cmu.edu;gamvrosi@cmu.edu;smithv@cmu.edu,3;6;3;6,,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Deep Learning;Storage;Bandwidth;Compression,1;1;1,27;27;27,m;f,usa,usa,n,
4205,ICLR,2020,Training a Constrained Natural Media Painting Agent using Reinforcement Learning ,Biao Jia;Jonathan Brandt;Radomir Mech;Ning Xu;Byungmoon Kim;Dinesh Manocha,biao@cs.umd.edu;jbrandt@adobe.com;rmech@adobe.com;nxu@adobe.com;bmkim@adobe.com;dm@cs.umd.edu,3;1;1,,Reject,0,0,0.0,yes,9/25/19,"University of Maryland, College Park;Adobe Systems;Adobe Systems;Adobe Systems;Adobe Systems;University of Maryland, College Park",,12;-1;-1;-1;-1;12,91;-1;-1;-1;-1;91,m;m,usa,usa,n,
4206,ICLR,2020,Disentangling Improves VAEs' Robustness to Adversarial Attacks,Matthew Willetts;Alexander Camuto;Stephen Roberts;Chris Holmes,mwilletts@turing.ac.uk;acamuto@turing.ac.uk;sroberts@turing.ac.uk;cholmes@turing.ac.uk,3;6;3,,Reject,0,5,1.0,yes,9/25/19,Alan Turing Institute;Alan Turing Institute;Alan Turing Institute;Alan Turing Institute,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
4207,ICLR,2020,Exploring Cellular Protein Localization Through Semantic Image Synthesis,Daniel Li;Qiang Ma;Andrew Liu;Justin Cheung;Dana Pe‚Äôer;Itsik Pe‚Äôer,daniel.li@columbia.edu;ma.qiang@columbia.edu;andrew@ml.berkeley.edu;justin.cheung@stonybrookmedicine.edu;peerster@gmail.com;itsik@cs.columbia.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Columbia University;Columbia University;University of California Berkeley;Renaissance School of Medicine at Stony Brook University;;Columbia University,Computational biology;image synthesis;GANs;exploring multiplex images;attention;interpretability,24;24;-1;43;-1;24,16;16;13;304;-1;16,m;m,usa,usa,n,8;2;5
4208,ICLR,2020,Encoder-Agnostic Adaptation for Conditional Language Generation,Zachary M. Ziegler;Luke Melas-Kyriazi;Sebastian Gehrmann;Alexander M. Rush,zziegler@g.harvard.edu;lmelaskyriazi@college.harvard.edu;gehrmann@seas.harvard.edu;srush@seas.harvard.edu,8;8;3,,Reject,0,4,0.0,yes,9/25/19,Harvard University;Harvard University;Harvard University;Harvard University,NLP;generation;pretraining,52;52;52;52,7;7;7;7,m;m,usa,usa,n,8;3
4209,ICLR,2020,Better Knowledge Retention through Metric Learning,Ke Li*;Shichong Peng*;Kailas Vodrahalli*;Jitendra Malik,ke.li@eecs.berkeley.edu;shichong.peng@mail.utoronto.ca;kailasv@berkeley.edu;malik@eecs.berkeley.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,University of California Berkeley;Toronto University;University of California Berkeley;University of California Berkeley,metric learning;continual learning;catastrophic forgetting,-1;-1;-1;-1,13;-1;13;13,m;m,usa,usa,n,
4210,ICLR,2020,Robust Learning with Jacobian Regularization,Judy Hoffman;Daniel A. Roberts;Sho Yaida,judy@gatech.edu;dan@diffeo.com;shoyaida@fb.com,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Georgia Institute of Technology;Diffeo;Facebook,Supervised Representation Learning;Few-Shot Learning;Regularization;Adversarial Defense;Deep Learning,13;-1;-1,38;-1;-1,f;m,NAN,NAN,n,1;4
4211,ICLR,2020,CAN ALTQ LEARN FASTER: EXPERIMENTS AND THEORY,Bowen Weng;Huaqing Xiong;Yingbin Liang;Wei Zhang,weng.172@buckeyemail.osu.edu;xiong.309@buckeyemail.osu.edu;liang.889@osu.edu;zhangw3@sustech.edu.cn,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Ohio State University;Ohio State University;Ohio State University;Southern University of Science and Technology,Reinforcement Learning;Q-Learning;Adam;Restart;Convergence Analysis,59;59;59;-1,70;70;70;317,m;m,NAN,NAN,y,1;9
4212,ICLR,2020,A NEW POINTWISE CONVOLUTION IN DEEP NEURAL NETWORKS THROUGH EXTREMELY FAST AND NON PARAMETRIC TRANSFORMS,Joonhyun Jeong;Sung-Ho Bae,doublejtoh@khu.ac.kr;shbae@khu.ac.kr,3;8;3,,Reject,0,5,0.0,yes,9/25/19,Kyung Hee University;Kyung Hee University,Pointwise Convolution;Discrete Walsh-Hadamard Transform;Discrete Cosine-Transform,445;445,319;319,m;m,asia,kr,n,
4213,ICLR,2020,"Making the Shoe Fit: Architectures, Initializations, and Tuning for Learning with Privacy",Nicolas Papernot;Steve Chien;Shuang Song;Abhradeep Thakurta;Ulfar Erlingsson,papernot@google.com;schien@google.com;athakurta@google.com;shuangsong@google.com;ulfar@google.com,6;6;3,,Reject,0,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google,differential privacy;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4214,ICLR,2020,Toward Understanding Generalization of Over-parameterized Deep ReLU network trained with SGD in Student-teacher Setting,Yuandong Tian,yuandong.tian@gmail.com,3;3;3,,Reject,0,8,0.0,yes,9/25/19,Facebook,deep ReLU network;theoretical analysis;generalization;training dynamics;student teacher setting;interpolation region;over-parameterization,-1,-1,m,NAN,NAN,y,1
4215,ICLR,2020,Ordinary differential equations on graph networks,Juntang Zhuang;Nicha Dvornek;Xiaoxiao Li;James S. Duncan,j.zhuang@yale.edu;nicha.dvornek@yale.edu;xiaoxiao.li@yale.edu;james.duncan@yale.edu,1;6;3,,Reject,0,13,0.0,yes,9/25/19,Yale University;Yale University;Yale University;Yale University,Graph Networks;Ordinary differential equation,73;73;73;73,8;8;8;8,m;m,europe,fi,y,10
4216,ICLR,2020,Poincar√© Wasserstein Autoencoder,Ivan Ovinnikov,ivan.ovinnikov@inf.ethz.ch,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology,Variational inference;hyperbolic geometry;hierarchical latent space;representation learning,-1,-1,m,NAN,NAN,n,10
4217,ICLR,2020,Learning Neural Surrogate Model for Warm-Starting Bayesian Optimization,Haotian Zhang;Jian Sun;Zongben Xu,zht570795275@stu.xjtu.edu.cn;jiansun@xjtu.edu.cn;zbxu@xjtu.edu.cn,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,Bayesian optimization;meta learning;neural network;surrogate model;hyper-parameters tuning,-1;-1;-1,555;555;555,m;m,NAN,NAN,n,11
4218,ICLR,2020,Music Source Separation in the Waveform Domain,Alexandre Defossez;Nicolas Usunier;Leon Bottou;Francis Bach,defossez@fb.com;usunier@fb.com;leonb@fb.com;francis.bach@inria.fr,8;3;3,,Reject,0,8,0.0,yes,9/25/19,Facebook;Facebook;Facebook;INRIA,source separation;audio synthesis;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,gr,n,
4219,ICLR,2020,Self-Attentional Credit Assignment for Transfer in Reinforcement Learning,Johan Ferret;Rapha√´l Marinier;Matthieu Geist;Olivier Pietquin,jferret@google.com;raphaelm@google.com;mfgeist@google.com;pietquin@google.com,8;3;6,,Reject,1,5,0.0,yes,9/25/19,Google;Google;Google;Google,reinforcement learning;transfer learning;credit assignment,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
4220,ICLR,2020,Gradient Descent can Learn Less Over-parameterized Two-layer Neural Networks on Classification Problems,Atsushi Nitanda;Geoffrey Chinot;Taiji Suzuki,nitanda@mist.i.u-tokyo.ac.jp;geoffreychinot@gmail.com;taiji@mist.i.u-tokyo.ac.jp,8;3;3,,Reject,0,5,0.0,yes,9/25/19,The University of Tokyo;;The University of Tokyo,gradient descent;neural network;over-parameterization,64;-1;64,36;-1;36,f;f,NAN,NAN,y,1;9
4221,ICLR,2020,Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning,Yufei Wang*;Ziju Shen*;Zichao Long;Bin Dong,wang.yufei@pku.edu.cn;zjshen@pku.edu.cn;zlong@pku.edu.cn;dongbin@math.pku.edu.cn,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University,Numerical Methods;Conservation Laws;Reinforcement Learning,14;14;14;14,24;24;24;24,f;m,asia,cn,n,8;2;3;1;6
4222,ICLR,2020,Discovering the compositional structure of vector representations with Role Learning Networks,Paul Soulos;Tom McCoy;Tal Linzen;Paul Smolensky,psoulos1@jhu.edu;tom.mccoy@jhu.edu;tal.linzen@jhu.edu;paul.smolensky@gmail.com,6;3;6,,Reject,0,4,0.0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Microsoft,compositionality;generalization;neurosymbolic;symbolic structures;interpretability;tensor product representations,73;73;73;-1,12;12;12;-1,m;m,NAN,NAN,n,
4223,ICLR,2020,A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem,Zhihao Xing;Shikui Tu,xingzhihao@sjtu.edu.cn;tushikui@sjtu.edu.cn,6;6;1,,Reject,0,5,0.0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Traveling Salesman Problem;Graph Neural Network;Monte Carlo Tree Search,30;30,157;157,u;m,asia,cn,n,10
4224,ICLR,2020,A bi-diffusion based layer-wise sampling method for deep learning in large graphs,Yu He;Shiyang Wen;Wenjin Wu;Yan Zhang;Siran Yang;Yuan Wei;Di Zhang;Guojie  Song;Wei Lin;Liang Wang;Bo Zheng,herve.hy@alibaba-inc.com;shiyang.wsy@alibaba-inc.com;kevin.wwj@alibaba-inc.com;zy143424@alibaba-inc.com;siran.ysr@alibaba-inc.com;yuanxi.wy@alibaba-inc.com;di.zhangd@alibaba-inc.com;gjsong@pku.edu.cn;yangkun.lw@alibaba-inc.com;liangbo.wl@alibaba-inc.com;bozheng@alibaba-inc.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Peking University;Alibaba Group;Alibaba Group;Alibaba Group,Layerwise Sampling;Graph Neural Networks;Attention Mechanism,-1;-1;-1;-1;-1;-1;-1;14;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;24;-1;-1;-1,u;u,NAN,NAN,n,8;10
4225,ICLR,2020,Noise Regularization for Conditional Density Estimation,Jonas Rothfuss;Fabio Ferreira;Simon Boehm;Simon Walther;Maxim Ulrich;Tamim Asfour;Andreas Krause,jonas.rothfuss@gmail.com;fabioferreira@mailbox.org;simonboehm@gmx.de;simon.walther@kit.edu;maxim.ulrich@kit.edu;asfour@kit.edu;krausea@ethz.ch,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Universit√§t Freiburg;Swiss Federal Institute of Technology;Karlsruhe Institute of Technology;Karlsruhe Institute of Technology;Karlsruhe Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1;168;168;168;-1,-1;-1;-1;174;174;174;-1,m;m,NAN,NAN,y,1
4226,ICLR,2020,Learning with Protection: Rejection of Suspicious Samples under Adversarial Environment,Masahiro Kato;Yoshihiro Fukuhara;Hirokatsu Kataoka;Shigeo Morishima,mkato.csecon@gmail.com;gatheluck@gmail.com;hirokatsu.kataoka@aist.go.jp;shigeo@waseda.jp,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Cyberagent;;AIST;Waseda University,Learning with Rejection;Adversarial Examples,-1;-1;15;316,-1;-1;110;790,m;m,asia,jp,n,4
4227,ICLR,2020,Transition Based Dependency Parser for Amharic Language Using Deep Learning,Mizanu Zelalem;Million Meshesha (PhD),mizatmymail@gmail.com;meshe84@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Bahir Dar Institute of technology;Addis Ababa University,Amharic dependency parsing;arc-eager transition;LSTM;Transition action prediction;Relationship type prediction,-1;-1,-1;-1,m;u,asia,in,n,
4228,ICLR,2020,V1Net: A computational model of cortical horizontal connections,Vijay Veerabadran;Virginia R. de Sa,vveeraba@ucsd.edu;desa@ucsd.edu,1;1;3,,Reject,0,3,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego",Biologically plausible deep learning;Recurrent Neural Networks;Perceptual grouping;horizontal connections;visual neuroscience;perceptual robustness;Gestalt psychology,-1;-1,31;31,m;f,usa,usa,n,2
4229,ICLR,2020,HOW IMPORTANT ARE NETWORK WEIGHTS? TO WHAT EXTENT DO THEY NEED AN UPDATE?,Fawaz Sammani;Mahmoud Elsayed;Abdelsalam Hamdi,fawaz.sammani@aol.com;elsayedmahmoud@aol.com;abdelsalam.h.a.a@gmail.com,1;3;1,,Reject,0,3,0.0,yes,9/25/19,Multimedia University;;Multimedia University,weights update;weights importance;weight freezing,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,8
4230,ICLR,2020,INTERNAL-CONSISTENCY CONSTRAINTS FOR EMERGENT COMMUNICATION,Charles Lovering;Ellie Pavlick,charles_lovering@brown.edu;ellie_pavlick@brown.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Brown University;Brown University,Emergent Communication;Speaker-Listener Models,85;85,53;53,m;f,usa,usa,n,
4231,ICLR,2020,Not All Features Are Equal: Feature Leveling Deep Neural Networks for Better Interpretation,Yingjing Lu;Runde Yang,yingjinl@andrew.cmu.edu;ry82@cornell.edu,1;3;3;3,,Reject,0,0,0.0,yes,9/25/19,Carnegie Mellon University;Cornell University,,1;7,27;19,m;m,usa,usa,n,
4232,ICLR,2020,Neural Networks for Principal Component Analysis: A New Loss Function Provably Yields Ordered Exact Eigenvectors ,Reza Oftadeh;Jiayi Shen;Zhangyang Wang;Dylan Shell,oftadeh.reza@gmail.com;asjyjya-617@tamu.edu;atlaswang@tamu.edu;dshell@tamu.edu,6;6;3,,Reject,0,4,0.0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;Texas A&M,Principal Component Analysis;Autoencoder;Neural Network,46;46;46;46,177;177;177;177,m;m,NAN,NAN,y,1
4233,ICLR,2020,GENN: Predicting Correlated Drug-drug Interactions with Graph Energy Neural Networks,Tengfei Ma;Junyuan Shang;Cao Xiao;Jimeng Sun,tengfei.ma1@ibm.com;sjy1203@pku.edu.cn;cao.xiao@iqvia.com;sun@cc.gatech.edu,6;3;3,,Reject,0,4,0.0,yes,9/25/19,International Business Machines;Peking University;IQVIA;Georgia Institute of Technology,graph neural networks;energy model;structure prediction;drug-drug-interaction,-1;14;-1;13,-1;24;-1;38,m;m,usa,usa,n,10
4234,ICLR,2020,Efficient Systolic Array Based on Decomposable MAC for Quantized Deep Neural Networks,Ning-Chi Huang;Huan-Jan Chou;Kai-Chiang Wu,nchuang@cs.nctu.edu.tw;kulugu2.cs07g@nctu.edu.tw;kcw@cs.nctu.edu.tw,1;3;3,,Reject,0,0,0.0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University;National Chiao Tung University,,118;118;118,564;564;564,u;m,asia,tw,n,
4235,ICLR,2020,DeepEnFM: Deep neural networks with Encoder enhanced Factorization Machine,Qiang Sun;Zhinan Cheng;Yanwei Fu;Wenxuan Wang;Yu-Gang Jiang;Xiangyang Xue,sunqiang85@gmail.com;zhinancheng.bryan@gmail.com;yanweifu@fudan.edu.cn;wxwang.iris@gmail.com;ygj@fudan.edu.cn;xyxue@fudan.edu.cn,1;3;1,,Reject,0,3,0.0,yes,9/25/19,Fudan University;;Fudan University;Fudan University;Fudan University;Fudan University,CTR;Attention;Transformer;Encoder,73;-1;73;73;73;73,109;-1;109;109;109;109,m;m,asia,cn,n,8
4236,ICLR,2020,Statistically Consistent Saliency Estimation,Emre Barut;Shunyan Luo,barut@gwu.edu;shine_lsy@gwu.edu,8;8;3;6;6,,Reject,0,7,0.0,yes,9/25/19,George Washington University;George Washington University,Deep Learning Interpretation;Saliency Estimation;High Dimensional Statistics,194;194,198;198,m;m,usa,usa,y,2;1
4237,ICLR,2020,Towards Physics-informed Deep Learning for Turbulent Flow Prediction,Rui Wang;Karthik Kashinath;Mustafa Mustafa;Adrian Albert;Rose Yu,wang.rui4@husky.neu.edu;kkashinath@lbl.gov;mmustafa@lbl.gov;aalbert@lbl.gov;roseyu@northeastern.edu,6;3;6,,Reject,3,7,0.0,yes,9/25/19,Northeastern University;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;Northeastern University,,16;-1;-1;-1;16,906;-1;-1;-1;906,m;f,usa,usa,n,
4238,ICLR,2020,Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators,Yongseok Choi;Junyoung Park;Subin Yi;Dong-Yeon Cho,yschoi@sktbrain.com;jypark@sktbrain.com;yisubin@sktbrain.com;dycho24@sktbrain.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,SK Telecom;SK Telecom;SK Telecom;SK Telecom,Meta-learning;few-shot learning;multi-domain,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
4239,ICLR,2020,Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,Wei Zhou;Yiying Li;Yongxin Yang;Huaimin Wang;Timothy M. Hospedales,zhouwei14@nudt.edu.cn;liyiying10@nudt.edu.cn;yongxin.yang@ed.ac.uk;hmwang@nudt.edu.cn;t.hospedales@ed.ac.uk,3;3;6,,Reject,0,6,0.0,yes,9/25/19,National University of Defense Technology;National University of Defense Technology;University of Edinburgh;National University of Defense Technology;University of Edinburgh,off-policy actor-critic;reinforcement learning;meta-learning,-1;-1;36;-1;36,-1;-1;30;-1;30,u;m,europe,uk,n,6
4240,ICLR,2020,Using Explainabilty to Detect Adversarial Attacks,Ohad Amosy and Gal Chechik,amosy3@gmail.com;gal.chechik@gmail.com,3;3;1;3,,Reject,2,0,0.0,yes,9/25/19,Bar Ilan University;Bar Ilan University,adversarial;detection;explainability,102;102,513;513,m;m,europe,il,n,4
4241,ICLR,2020,Random Bias Initialization Improving Binary Neural Network Training,Xinlin Li;Vahid Partovi Nia,xinlin.li1@huawei.com;vahid.partovinia@huawei.com,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.,Binarized Neural Network;Activation function;Initialization;Neural Network Acceleration,-1;-1,-1;-1,m;m,NAN,NAN,n,8
4242,ICLR,2020,Bayesian Inference for Large Scale Image Classification,Jonathan Heek;Nal Kalchbrenner,jheek@google.com;nalk@google.com,6;3;6,,Reject,0,3,0.0,yes,9/25/19,Google;Google,image classification;bayesian inference;mcmc;imagenet,-1;-1,-1;-1,m;m,NAN,NAN,n,11;7
4243,ICLR,2020,Self-Supervised GAN Compression,Chong Yu;Jeff Pool,chongy@nvidia.com;jpool@nvidia.com,3;6;6,,Reject,0,4,0.0,yes,9/25/19,NVIDIA;NVIDIA,compression;pruning;generative adversarial networks;GAN,-1;-1,-1;-1,m;m,NAN,NAN,n,3;5;4
4244,ICLR,2020,"Generative Hierarchical Models for Parts, Objects, and Scenes",Fei Deng;Zhuo Zhi;Sungjin Ahn,fei.deng@rutgers.edu;zhizz001@stu.xjtu.edu.cn;sjn.ahn@gmail.com,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Rutgers University;Xi'an Jiaotong University;Rutgers University,,30;-1;30,-1;555;-1,f;m,usa,usa,n,5
4245,ICLR,2020,SDGM: Sparse Bayesian Classifier Based on a Discriminative Gaussian Mixture Model,Hideaki Hayashi;Seiichi Uchida,hayashi@ait.kyushu-u.ac.jp;uchida@ait.kyushu-u.ac.jp,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Kyushu University;Kyushu University,classification;sparse Bayesian learning;Gaussian mixture model,-1;-1,460;460,m;m,NAN,NAN,n,11;1
4246,ICLR,2020,Analytical Moment Regularizer for Training Robust Networks,Modar Alfadly;Adel Bibi;Muhammed Kocabas;Bernard Ghanem,modar.alfadly@kaust.edu.sa;adel.bibi@kaust.edu.sa;muhammed.kocabas@tue.mpg.de;bernard.ghanem@kaust.edu.sa,3;1;3,,Reject,1,3,0.0,yes,9/25/19,KAUST;KAUST;Max-Planck Institute;KAUST,robustness;analytic regularizer;first moment,102;102;-1;102,-1;-1;-1;-1,m;m,europe,gr,y,4
4247,ICLR,2020,ROBUST DISCRIMINATIVE REPRESENTATION LEARNING VIA GRADIENT RESCALING: AN EMPHASIS REGULARISATION PERSPECTIVE,Xinshao Wang;Yang Hua;Elyor Kodirov;Neil M. Robertson,xwang39@qub.ac.uk;y.hua@qub.ac.uk;elyor@anyvision.co;n.robertson@qub.ac.uk,6;3;3,,Reject,0,7,1.0,yes,9/25/19,Queen's University Belfast;Queen's University Belfast;Anyvision;Queen's University Belfast,examples weighting;emphasis regularisation;gradient scaling;abnormal training examples,248;248;-1;248,204;204;-1;204,m;m,europe,uk,n,
4248,ICLR,2020,Multi-step Greedy Policies in Model-Free Deep Reinforcement Learning,Yonathan Efroni;Manan Tomar;Mohammad Ghavamzadeh,jonathan.efroni@gmail.com;manan.tomar@gmail.com;mgh@fb.com,3;3;6,,Reject,0,8,0.0,yes,9/25/19,Microsoft;;Facebook,Reinforcement Learning;Multi-step greedy policies;Model free Reinforcement Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4249,ICLR,2020,Hidden incentives for self-induced distributional shift,David Scott Krueger;Tegan Maharaj;Shane Legg;Jan Leike,davidscottkrueger@gmail.com;tegan.jrm@gmail.com;legg@google.com;leike@google.com,6;1;1,,Reject,0,5,0.0,yes,9/25/19,University of Montreal;Polytechnique Montreal;Google;Google,distributional shift;safety;incentives;specification;content recommendation;reinforcement learning;online learning;ethics,-1;316;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
4250,ICLR,2020,Learning Temporal Abstraction with Information-theoretic Constraints for Hierarchical Reinforcement Learning,Wenshan Wang;Yaoyu Hu;Sebastian Scherer,wenshanw@andrew.cmu.edu;yaoyuh@andrew.cmu.edu;basti@andrew.cmu.edu,3;1;3,,Reject,0,12,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,hierarchical reinforcement learning;temporal abstraction,1;1;1,27;27;27,f;m,usa,usa,n,9
4251,ICLR,2020,Generalized Clustering by Learning to Optimize Expected Normalized Cuts,Azade Nazi;Will Hang;Anna Goldie;Sujith Ravi;Azalia Mirhoseini,azade@google.com;agoldie@google.com;sravi@google.com;azalia@google.com;willhang@stanford.edu,6;6;6,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Stanford University,Clustering;Normalized cuts;Generalizability,-1;-1;-1;-1;5,-1;-1;-1;-1;4,f;f,usa,usa,n,1
4252,ICLR,2020,Adversarially Robust Neural Networks via Optimal Control: Bridging Robustness with Lyapunov Stability,Zhiyang Chen;Hang Su,zy-chen17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn,1;6;1,,Reject,2,0,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",adversarial defense;optimal control;Lyapunov stability,4;4,23;23,m;m,NAN,NAN,y,4
4253,ICLR,2020,Temporal Difference Weighted Ensemble For Reinforcement Learning,Takuma Seno;Michita Imai,seno@ailab.ics.keio.ac.jp;michita@ailab.ics.keio.ac.jp,1;3;8,,Reject,0,6,0.0,yes,9/25/19,Keio University;Keio University,reinforcement learning;ensemble;deep q-network,248;248,692;692,m;m,asia,jp,n,
4254,ICLR,2020,Learning Generative Image Object Manipulations from Language Instructions,Martin L√§ngkvist;Andreas Persson;Amy Loutfi,martin.langkvist@oru.se;andreas.persson@oru.se;amy.loutfi@oru.se,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Centre for Applied Autonomous Sensor Systems;Centre for Applied Autonomous Sensor Systems;Centre for Applied Autonomous Sensor Systems,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,3;5;4
4255,ICLR,2020,A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks,Arushi Gupta;Sanjeev Arora,arushig@princeton.edu;arora@cs.princeton.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Princeton University;Princeton University,saliency;attribution;interpretability;sanity checks,30;30,6;6,f;m,usa,usa,y,
4256,ICLR,2020,Impact of the latent space on the ability of GANs to fit the distribution,Thomas Pinetz;Daniel Soukup;Thomas Pock,thomas.pinetz@ait.ac.at;daniel.soukup@ait.ac.at;pock@icg.tugraz.at,1;1;1,,Reject,0,0,0.0,yes,9/25/19,AIT Austrian Institute Of Technology;AIT Austrian Institute Of Technology;Graz University of Technology,Deep Learning;Generative Adversarial Networks;Compression;Perceptual Quality,-1;-1;118,-1;-1;542,m;m,europe,cz,y,1;5;4
4257,ICLR,2020,At Your Fingertips: Automatic Piano Fingering Detection,Amit Moryossef;Yanai Elazar;Yoav Goldberg,amitmoryossef@gmail.com;yanaiela@gmail.com;yoav.goldberg@gmail.com,1;3;1,,Reject,0,2,0.0,yes,9/25/19,Bar Ilan University;Bar Ilan University;Bar-Ilan University,piano;fingering;dataset,-1;102;102,-1;513;513,m;m,europe,il,n,5;4
4258,ICLR,2020,Latent Question Reformulation and Information Accumulation for Multi-Hop Machine Reading,Quentin Grail;Julien Perez;Eric Gaussier,quentin.grail@naverlabs.com;julien.perez@naverlabs.com;eric.gaussier@imag.fr,8;3;3,,Reject,0,4,0.0,yes,9/25/19,Naver Labs Europe;Naver Labs Europe;French National Center for Scientific Research,question-answering;machine comprehension;deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3
4259,ICLR,2020,Deep Variational Semi-Supervised Novelty Detection,Tal Daniel;Thanard Kurutach;Aviv Tamar,taldanielm@campus.technion.ac.il;thanard.kurutach@berkeley.edu;avivt@technion.ac.il,6;6;3,,Reject,0,4,0.0,yes,9/25/19,"Technion, Technion;University of California Berkeley;Technion, Technion",anomaly detection;semi-supervised anomaly detection;variational autoencoder,27;-1;27,-1;13;-1,m;m,NAN,NAN,n,5
4260,ICLR,2020,Occlusion  resistant  learning  of  intuitive physics from videos,Ronan Riochet;Josef Sivic;Ivan Laptev;Emmanuel Dupoux,ronan.riochet@inria.fr;josef.sivic@ens.fr;ivan.laptev@inria.fr;emmanuel.dupoux@gmail.com,3;6;3;3,,Reject,0,4,0.0,yes,9/25/19,INRIA;Ecole Normale Superieure;INRIA;INRIA,,-1;118;-1;-1,-1;-1;-1;-1,m;m,asia,in,n,8;2
4261,ICLR,2020,"Compressive Recovery Defense: A Defense Framework for $\ell_0, \ell_2$ and $\ell_\infty$ norm attacks.",Jasjeet Dhaliwal;Kyle Hambrook,jasjeet.dhaliwal@sjsu.edu;kyle.hambrook@sjsu.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,adversarial input;adversarial machine learning;neural networks;compressive sensing.,-1;-1,299;299,m;m,NAN,NAN,y,4
4262,ICLR,2020,Causally Correct Partial Models for Reinforcement Learning,Danilo J. Rezende;Ivo Danihelka;George Papamakarios;Nan Rosemary Ke;Ray Jiang;Theophane Weber;Karol Gregor;Hamza Merzic;Fabio Viola;Jane Wang;Jovana Mitrovic;Frederic Besse;Ioannis Antonoglou;Lars Buesing;Julian Schrittwieser;Thomas Hubert;David Silver,danilor@google.com;danihelka@google.com;gpapamak@google.com;rosemary.nan.ke@gmail.com;rayjiang@google.com;theophane@google.com;karolg@google.com;hamzamerzic@google.com;fviola@google.com;wangjane@google.com;mitrovic@google.com;fbesse@google.com;ioannisa@google.com;lbuesing@google.com;swj@google.com;tkhubert@google.com;davidsilver@google.com,8;1;3;6,,Reject,0,7,0.0,yes,9/25/19,Google;Google;Google;;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,causality;model-based reinforcement learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4263,ICLR,2020,Learning scalable and transferable multi-robot/machine sequential assignment planning via graph embedding,Hyunwook Kang;Aydar Mynbay;James R. Morrison;Jinkyoo Park,hwkang@tamu.edu;aydar.mynbay@bluehole.net;james.morrison@kaist.edu;jinkyoo.park@kaist.ac.kr,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Texas A&M;;KAIST;Korea Advanced Institute of Science and Technology,reinforcement learning;multi-robot/machine;scheduling;planning;scalability;transferability;mean-field inference;graph embedding,46;-1;15;-1,177;-1;110;110,m;m,NAN,NAN,y,10
4264,ICLR,2020,Improving Evolutionary Strategies with Generative Neural Networks,Louis Faury;Cl√©ment Calauz√®nes;Olivier Fercoq,l.faury@criteo.com;c.calauzenes@criteo.com;olivier.fercoq@telecom-paris.fr,8;6;6,,Reject,0,3,0.0,yes,9/25/19,Criteo;Criteo;T√©l√©com Paris,black-box optimization;evolutionary strategies;generative neural networks,-1;-1;-1,-1;-1;187,m;m,NAN,NAN,n,5
4265,ICLR,2020,Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning,Mitchell A Gordon;Kevin Duh;Nicholas Andrews,mgordo37@jhu.edu;kevinduh@cs.jhu.edu;noa@jhu.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,compression;pruning;pre-training;BERT;language modeling;transfer learning;ML;NLP,73;73;73,12;12;12,m;m,usa,usa,n,6;2;3
4266,ICLR,2020,REFINING MONTE CARLO TREE SEARCH AGENTS BY MONTE CARLO TREE SEARCH,Katsuki Ohto,katsuki.ohto@gmail.com,1;1;1,,Reject,0,3,0.0,yes,9/25/19,0,Reinforcement Learning;Monte Carlo Tree Search;Alpha Zero,,,m,NAN,NAN,n,
4267,ICLR,2020,Smooth Kernels Improve Adversarial Robustness and Perceptually-Aligned Gradients,Haohan Wang;Xindi Wu;Songwei Ge;Zachary C. Lipton;Eric P. Xing,haohanw@cs.cmu.edu;xindiw@andrew.cmu.edu;songweig@andrew.cmu.edu;zlipton@cmu.edu;epxing@cs.cmu.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,adversarial robustness;computer vision;smoothness regularization,1;1;1;1;1,27;27;27;27;27,m;m,usa,usa,y,4
4268,ICLR,2020,Modeling treatment events in disease progression,Guanyang Wang;Yumeng Zhang;Yong Deng;Xuxin Huang;Lukasz Kidzinski,guanyang@stanford.edu;zym3008@gmail.com;yongdeng@stanford.edu;xxhuang@stanford.edu;lukasz.kidzinski@stanford.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Stanford University;;Stanford University;Stanford University;Stanford University,disease progression;treatment events;matrix completion,5;-1;5;5;5,4;-1;4;4;4,m;m,usa,usa,y,
4269,ICLR,2020,Collaborative Generated Hashing for Market Analysis and Fast Cold-start Recommendation,Yan Zhang;Ivor W. Tsang;Lixin Duan;Guowu Yang,yixianqianzy@gmail.com;ivor.tsang@uts.edu.au;lxduan@gmail.com;guowu@uestc.edu.cn,1;1;1,,Reject,0,0,0.0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China,Recommender system;generated model;market analysis;hash;cold start,-1;73;-1;-1,-1;193;628;628,u;m,NAN,NAN,n,5
4270,ICLR,2020,Are Few-shot Learning Benchmarks Too Simple ?,Gabriel Huang;Hugo Larochelle;Simon Lacoste-Julien,gbxhuang@gmail.com;hugolarochelle@google.com;slacoste@iro.umontreal.ca,6;3;3,,Reject,0,7,0.0,yes,9/25/19,University of Montreal;Google;University of Montreal,few-shot;classification;meta-learning;benchmark;omniglot;miniimagenet;meta-dataset;learning to cluster;learning;cluster;unsupervised,-1;-1;118,-1;-1;85,m;m,canada,ca,n,6
4271,ICLR,2020,Towards trustworthy predictions from deep neural networks with fast adversarial calibration,Christian Tomani;Florian Buettner,christian.tomani@gmail.com;fbuettner.phys@gmail.com,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Technical University Munich;Siemens Corporate Research,deep learning;uncertainty;calibration;domain shift;robustness,-1;-1,-1;-1,m;m,asia,in,n,11;4
4272,ICLR,2020,Collaborative Training of Balanced Random Forests for Open Set Domain Adaptation,Jongbin Ryu;Jiun Bae;Jongwoo Lim,jongbin.ryu@gmail.com;maybe@hanyang.ac.kr;jlim@hanyang.ac.kr,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Ajou University;Hanyang University;Hanyang University,,-1;194;194,852;393;393,m;m,asia,kr,n,
4273,ICLR,2020,Accelerated Variance Reduced Stochastic Extragradient Method for Sparse Machine Learning Problems,Fanhua Shang;Lin Kong;Yuanyuan Liu;Hua Huang;Hongying Liu,fhshang@xidian.edu.cn;xdkonglin0511@163.com;yyliu@xidian.edu.cn;huanghua1115@outlook.com;hyliu@xidian.edu.cn,8;1;6,,Reject,0,5,0.0,yes,9/25/19,Xidian University;163;Xidian University;;Xidian University,non-smooth optimization;SVRG;proximal operator;extragradient descent;momentum acceleration,-1;-1;-1;-1;-1,919;-1;919;-1;919,m;f,asia,cn,y,2;9
4274,ICLR,2020,Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Nonconvex Optimization,Anas Barakat;Pascal Bianchi,anas.barakat@telecom-paristech.fr;pascal.bianchi@telecom-paristech.fr,3;3;3,,Reject,0,0,0.0,yes,9/25/19,T√©l√©com ParisTech;T√©l√©com ParisTech,nonconvex optimization;adaptive methods,-1;-1,187;187,m;m,NAN,NAN,y,1;9
4275,ICLR,2020,RTC-VAE: HARNESSING THE PECULIARITY OF TOTAL CORRELATION  IN LEARNING DISENTANGLED REPRESENTATIONS,Ze Cheng;Juncheng B Li;Chenxu Wang;Jixuan Gu;Hao Xu;Xinjian Li;Florian Metze,ze.cheng@cn.bosch.com;junchenl@cs.cmu.edu;chenxujwang@gmail.com;jixuan.gu@sjtu.edu.cn;hao.xu-1@colorado.edu;xinjianl@cs.cmu.edu;fmetze@cs.cmu.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,"Bosch;Carnegie Mellon University;;Shanghai Jiao Tong University;University of Colorado, Boulder;Carnegie Mellon University;Carnegie Mellon University",Total Correlation;VAEs;Disentanglement,-1;1;-1;30;59;1;1,297;27;-1;157;123;27;27,m;m,usa,usa,y,1;5
4276,ICLR,2020,Generalized Bayesian Posterior Expectation Distillation for Deep Neural Networks,Meet P. Vadera;Benjamin M. Marlin,mvadera@cs.umass.edu;marlin@cs.umass.edu,3;6;6,,Reject,0,7,0.0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst",Bayesian Neural Networks;Distillation,24;24,209;209,m;m,usa,usa,n,11
4277,ICLR,2020,Towards Simplicity in Deep Reinforcement Learning: Streamlined Off-Policy Learning,Che Wang;Yanqiu Wu;Quan Vuong;Keith Ross,cw1681@nyu.edu;yanqiu.wu@nyu.edu;quan.hovuong@gmail.com;keithwross@nyu.edu,6;3;3,,Reject,0,11,0.0,yes,9/25/19,New York University;New York University;;New York University,Deep Reinforcement Learning;Sample Efficiency;Off-Policy Algorithms,22;22;-1;22,29;29;-1;29,m;m,usa,usa,n,
4278,ICLR,2020,A shallow feature extraction network with a large receptive field for stereo matching tasks,Jianguo Liu;Yunjian Feng;Guo Ji;Fuwu Yan,ljg424@163.com;1029515027@whut.edu.cn;18754806756@163.com;yanfw@whut.edu.cn,3;1;6,,Reject,0,0,0.0,yes,9/25/19,163;South China University of Technology;163;South China University of Technology,stereo matching;feature extraction network;convolution neural network;receptive field,-1;-1;-1;-1,-1;501;-1;501,u;u,NAN,NAN,n,2
4279,ICLR,2020,Evaluating Semantic Representations of Source Code,Yaza Wainakh;Moiz Rauf;Michael Pradel,yaza.wainakh@gmail.com;moiz.rauf@iste.uni-stuttgart.de;michael@binaervarianz.de,6;3;1,,Reject,0,3,0.0,yes,9/25/19,Fraunhofer Institute for Computer Graphics Research IGD;University of Stuttgart;University of Stuttgart,embeddings;representation;source code;identifiers,-1;118;118,-1;292;292,m;m,europe,de,n,3
4280,ICLR,2020,UW-NET: AN INCEPTION-ATTENTION NETWORK FOR UNDERWATER IMAGE CLASSIFICATION,Miao Yang and Ke Hu;Chongyi Li;Zhiqiang Wei,lemonmiao@gmial.com;kexisibest@outlook.com;lichongyi@tju.edu.cn;weizhiqiang@ouc.edu.cn,3;1;3,,Reject,0,0,0.0,yes,9/25/19,"Gmial;;Zhejiang University;University of Illinois, Urbana-Champaign",Underwater image;Convolutional neural network;Image classification;Inception module;Attention module,-1;-1;39;-1,-1;-1;107;-1,u;u,usa,usa,n,8
4281,ICLR,2020,Deep Generative Classifier for Out-of-distribution Sample Detection,Dongha Lee;Sehun Yu;Hwanjo Yu,dongha0914@postech.ac.kr;hunu12@postech.ac.kr;hwanjoyu@postech.ac.kr,3;6;3,,Reject,1,3,0.0,yes,9/25/19,POSTECH;POSTECH;POSTECH,Out-of-distribution Detection;Generative Classifier;Deep Neural Networks;Multi-class Classification;Gaussian Discriminant Analysis,118;118;118,146;146;146,m;m,asia,kr,n,10;5
4282,ICLR,2020,Adaptive Loss Scaling for Mixed Precision Training,Ruizhe Zhao;Brian Vogel;Tanvir Ahmed,ruizhe.zhao15@imperial.ac.uk;vogel@preferred.jp;tanvira@preferred.jp,3;3;6,,Reject,0,3,0.0,yes,9/25/19,"Imperial College London;Preferred Networks, Inc.;Preferred Networks, Inc.",Deep Learning;Mixed Precision Training;Loss Scaling;Backpropagation,52;-1;-1,10;-1;-1,m;m,NAN,NAN,n,
4283,ICLR,2020,On importance-weighted autoencoders,Axel Finke;Alexandre H. Thiery,axelfinke42@gmail.com;a.h.thiery@nus.edu.sg,8;3;6,,Reject,0,5,0.0,yes,9/25/19,Loughborough University;National University of Singapore,variational inference;autoencoders;importance sampling,445;17,374;25,m;m,asia,sg,y,1;5
4284,ICLR,2020,Mixed Precision Training With 8-bit Floating Point,Naveen Mellempudi;Sudarshan Srinivasan;Dipankar Das;Bharat Kaul,naveen.k.mellempudi@intel.com;sudarshan.srinivasan@intel.com;dipankar.das@intel.com;bharat.kaul@intel.com,6;1;6,,Reject,0,7,0.0,yes,9/25/19,Intel;Intel;Intel;Intel,8-bit training;8-bit floating point;low precision training;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;1
4285,ICLR,2020,A Functional Characterization of Randomly Initialized Gradient Descent in Deep ReLU Networks,Justin Sahs;Aneel Damaraju;Ryan Pyle;Onur Tavaslioglu;Josue Ortega Caro;Hao Yang Lu;Ankit Patel,justin.sahs@bcm.edu;amd18@rice.edu;ryan.pyle@bcm.edu;onur.tavaslioglu@bcm.edu;josue.ortegacaro@bcm.edu;hl61@rice.edu;ankitp@bcm.edu,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Baylor College of Medicine;Rice University;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Rice University;Baylor College of Medicine,Inductive Bias;Generalization;Interpretability;Functional Characterization;Loss Surface;Initialization,-1;92;-1;-1;-1;92;-1,-1;105;-1;-1;-1;105;-1,m;m,NAN,NAN,y,1
4286,ICLR,2020,ASGen: Answer-containing Sentence Generation to Pre-Train Question Generator for Scale-up Data in Question Answering,Akhil Kedia;Sai Chetan Chinthakindi;Seohyun Back;Haejun Lee;Jaegul Choo,akhil.kedia@samsung.com;sai.chetan@samsung.com;scv.back@samsung.com;haejun82.lee@samsung.com;jchoo@korea.ac.kr,6;6,,Reject,0,9,0.0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Korea University,Question Answering;Machine Reading Comprehension;Data Augmentation;Question Generation;Answer Generation,-1;-1;-1;-1;168,-1;-1;-1;-1;179,m;m,asia,kr,n,3
4287,ICLR,2020,Invariance vs Robustness of Neural Networks,Sandesh Kamath;Amit Deshpande;K V Subrahmanyam,amitdesh@microsoft.com;ksandeshk@cmi.ac.in;kv@cmi.ac.in,3;1;3,,Reject,0,0,0.0,yes,9/25/19,Microsoft;Chennai Mathematical Institute;Chennai Mathematical Institute,Invariance;Adversarial;Robustness,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1;4
4288,ICLR,2020,Modelling the influence of data structure on learning in neural networks,S. Goldt;M. M√©zard;F. Krzakala;L. Zdeborov√°,goldt.sebastian@gmail.com;marc.mezard@gmail.com;florent.krzakala@gmail.com;lenka.zdeborova@gmail.com,1;1;3,,Reject,0,6,0.0,yes,9/25/19,SISSA;;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Neural Networks;Generative models;Synthetic data sets;Generalisation;Stochastic Gradient descent,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,5
4289,ICLR,2020,A Perturbation Analysis of Input Transformations for Adversarial Attacks,Adam Dziedzic;Sanjay Krishnan,ady@uchicago.edu;skr@uchicago.edu,3;3;6,,Reject,0,7,0.0,yes,9/25/19,University of Chicago;University of Chicago,adversarial examples;defenses;stochastic channels;deterministic channels;input transformations;compression;noise;convolutional neural networks,51;51,9;9,m;m,usa,usa,n,4
4290,ICLR,2020,Understanding Isomorphism Bias in Graph Data Sets ,Ivanov Sergey;Sviridov Sergey;Evgeny Burnaev,ivanovserg990@gmail.com;sergei.sviridov@gmail.com;e.burnaev@skoltech.ru,6;1;1;3,,Reject,0,5,0.0,yes,9/25/19,Criteo;;Skolkovo Institute of Science and Technology,graph classification;data sets;graph representation learning,-1;-1;-1,-1;-1;-1,m;m,europe,russia,y,1;10
4291,ICLR,2020,Data-Efficient Image Recognition with Contrastive Predictive Coding,Olivier J Henaff;Aravind Srinivas;Jeffrey De Fauw;Ali Razavi;Carl Doersch;S. M. Ali Eslami;Aaron van den Oord,henaff@google.com;aravind@cs.berkeley.edu;defauw@google.com;alirazavi@google.com;doersch@google.com;aeslami@google.com;avdnoord@google.com,3;3;6;3,,Reject,0,5,0.0,yes,9/25/19,Google;University of California Berkeley;Google;Google;Google;Google;Google,Deep learning;representation learning;contrastive methods;unsupervised learning;self-supervised learning;vision;data-efficiency,-1;-1;-1;-1;-1;-1;-1,-1;13;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2;1
4292,ICLR,2020,OBJECT-ORIENTED REPRESENTATION OF 3D SCENES,Chang Chen;Sungjin Ahn,chang.chen@rutgers.edu;sjn.ahn@gmail.com,3;6;3;3,,Reject,0,9,0.0,yes,9/25/19,Rutgers University;Rutgers University,unsupervised learning;representation learning;3D scene decomposition;3D detection,30;30,-1;-1,m;m,usa,usa,n,1;5
4293,ICLR,2020,Barcodes as summary of objective functions' topology,Serguei Barannikov;Alexander Korotin;Dmitry Oganesyan;Daniil Emtsev;Evgeny Burnaev,serguei.barannikov@imj-prg.fr;a.korotin@skoltech.ru;d.oganesyan@skoltech.ru;demtsev@student.ethz.ch;e.burnaev@skoltech.ru,1;1;1,,Reject,0,3,0.0,yes,9/25/19,"CNRS, Institut Mathematiques de Jussieu, Paris Diderot University;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Swiss Federal Institute of Technology;Skolkovo Institute of Science and Technology",Barcodes;canonical form invariants;loss surface;gradient complexes,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,europe,russia,n,
4294,ICLR,2020,Asynchronous Stochastic Subgradient Methods for General Nonsmooth Nonconvex Optimization,Vyacheslav Kungurtsev;Malcolm Egan;Bapi Chatterjee;Dan Alistarh,vyacheslav.kungurtsev@fel.cvut.cz;malcom.egan@insa-lyon.fr;bapi.chatterjee@ist.ac.at;dan.alistarh@ist.ac.at,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Czech Technical University in Prague;INSA de Lyon;Institute of Science and Technology Austria;Institute of Science and Technology Austria,optimziation;stochastic optimization;asynchronous parallel architecture;deep neural networks,168;-1;-1;-1,956;-1;-1;-1,m;m,NAN,NAN,y,
4295,ICLR,2020,Top-down training for neural networks,Shucong Zhang;Cong-Thanh Do;Rama Doddipatla;Erfan Loweimi;Peter Bell;Steve Renals,s1603602@sms.ed.ac.uk;cong-thanh.do@crl.toshiba.co.uk;rama.doddipatla@crl.toshiba.co.uk;e.loweimi@ed.ac.uk;peter.bell@ed.ac.uk;s.renals@ed.ac.uk,3;3;3,,Reject,1,5,0.0,yes,9/25/19,University of Edinburgh;Toshiba Research Europe Ltd.;Toshiba Research Europe Ltd.;University of Edinburgh;University of Edinburgh;University of Edinburgh,Neural network training;speech recognition,36;-1;-1;36;36;36,30;-1;-1;30;30;30,u;m,europe,uk,n,8
4296,ICLR,2020,A new perspective in understanding of Adam-Type algorithms and beyond,Zeyi Tao;Qi Xia;Qun Li,ztao@email.wm.edu;qxia01@email.wm.edu;liqun@cs.wm.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,College of William and Mary;College of William and Mary;College of William and Mary,Machine Learning;Algorithm;Adam;First-Order Method,194;194;194,-1;-1;-1,m;m,usa,usa,y,1;9
4297,ICLR,2020,Subjective Reinforcement Learning for Open Complex Environments,Zhile Yang*;Haichuan Gao*;Xin Su;Shangqi Guo;Feng Chen,yzl18@mails.tsinghua.edu.cn;ghc18@mails.tsinghua.edu.cn;suxin16@mails.tsinghua.edu.cn;gsq15@mails.tsinghua.edu.cn;chenfeng@mail.tsinghua.edu.cn,3;3;1,,Reject,0,5,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",reinforcement learning theory;subjective learning,4;4;4;4;4,23;23;23;23;23,u;m,NAN,NAN,n,
4298,ICLR,2020,Discriminative Variational Autoencoder for Continual Learning with Generative Replay,Woo-Young Kang;Cheol-Ho Han;Byoung-Tak Zhang,rkddndud50@gmail.com;chhan@bi.snu.ac.kr;btzhang@bi.snu.ac.kr,1;1;3,,Reject,0,7,0.0,yes,9/25/19,Kakao Brain;Seoul National University;Seoul National University,Continual learning;Generative replay;Variational Autoencoder,-1;39;39,-1;64;64,u;m,asia,kr,n,5
4299,ICLR,2020,BOSH: An Efficient Meta Algorithm for Decision-based Attacks,Zhenxin Xiao;Puyudi Yang;Yuchen Jiang;Kai-Wei Chang;Cho-Jui Hsieh,alanshawzju@gmail.com;pydyang@ucdavis.edu;jyc@zju.edu.cn;kw@kwchang.net;chohsieh@cs.ucla.edu,3;3,,Reject,0,3,0.0,yes,9/25/19,"Zhejiang University;University of California, Davis;Zhejiang University;University of California-Los Angeles;University of California, Los Angeles",,-1;-1;39;-1;-1,-1;55;107;17;17,m;m,usa,usa,y,11;4
4300,ICLR,2020,Behavior Regularized Offline Reinforcement Learning,Yifan Wu;George Tucker;Ofir Nachum,yw4@andrew.cmu.edu;gjt@google.com;ofirnachum@google.com,6;6;6,,Reject,0,3,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google,reinforcement learning;offline RL;batch RL,1;-1;-1,27;-1;-1,m;m,NAN,NAN,n,
4301,ICLR,2020,HyperEmbed:  Tradeoffs Between Resources and Performance in NLP Tasks with Hyperdimensional Computing enabled embedding of n-gram statistics ,Pedro Alonso;Kumar Shridhar;Denis Kleyko;Evgeny Osipov;Marcus Liwicki,pedro.alonso@ltu.se;kumar@neuralspace.ai;denis.kleyko@ltu.se;evgeny.osipov@ltu.se;marcus.liwicki@ltu.se,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Lule√• University of Technology;;Lule√• University of Technology;Lule√• University of Technology;Lule√• University of Technology,NLP;Hyperdimensional computing;n-gram statistics;word representation;semantic hashing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3
4302,ICLR,2020,Semi-Supervised Learning with Normalizing Flows,Pavel Izmailov;Polina Kirichenko;Marc Finzi;Andrew Wilson,izmailovpavel@gmail.com;pk1822@nyu.edu;maf820@nyu.edu;andrew@cornell.edu,6;1;1,,Reject,0,4,1.0,yes,9/25/19,New York University;New York University;New York University;Cornell University,Semi-Supervised Learning;Normalizing Flows,22;22;22;7,29;29;29;19,m;m,usa,usa,n,10
4303,ICLR,2020,Attacking Lifelong Learning Models with Gradient Reversion,Yunhui Guo;Mingrui Liu;Yandong Li;Liqiang Wang;Tianbao Yang;Tajana Rosing,yug185@eng.ucsd.edu;mingrui-liu@uiowa.edu;lyndon.leeseu@outlook.com;lwang@cs.ucf.edu;tianbao-yang@uiowa.edu;tajana@ucsd.edu,3;3;3,,Reject,0,0,0.0,yes,9/25/19,"University of California, San Diego;University of Iowa;;University of Central Florida;University of Iowa;University of California, San Diego",lifelong learning;adversarial learning,-1;168;-1;73;168;-1,31;227;-1;609;227;31,m;f,usa,usa,n,4
4304,ICLR,2020,Deep amortized clustering,Juho Lee;Yoonho Lee;Yee Whye Teh,juho@aitrics.com;einet89@gmail.com;y.w.teh@stats.ox.ac.uk,3;3;3,,Reject,0,5,0.0,yes,9/25/19,AITRICS;AITRICS;University of Oxford,clustering;amortized inference;meta learning;deep learning,-1;-1;46,-1;-1;1,m;m,europe,uk,n,
4305,ICLR,2020,Laconic Image Classification: Human vs. Machine Performance,Javier Carrasco;Aidan Hogan;Jorge P√©rez,jaco_1031@hotmail.com;aidhog@gmail.com;jorge.perez.rojas@gmail.com,1;6;6,,Reject,0,4,0.0,yes,9/25/19,Universidad de Chile;Universidad de Chile;Universidad de Chile,minimal images;entropy;human vs. machine performance,-1;316;316,-1;-1;-1,m;m,southamerica,cl,n,
4306,ICLR,2020,Understanding and Stabilizing GANs' Training Dynamics with Control Theory,Kun Xu;Chongxuan Li;Huanshu Wei;Jun Zhu;Bo Zhang,kunxu.thu@gmail.com;chongxuanli1991@gmail.com;weihuanshu94@hotmail.com;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,6;3;3,,Reject,0,7,0.0,yes,9/25/19,"Tsinghua University;;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Generative Adversarial Nets;Stability Analysis;Control Theory,-1;-1;-1;4;4,-1;-1;-1;23;23,m;m,NAN,NAN,n,1;5;4
4307,ICLR,2020,Benefits of Overparameterization in Single-Layer Latent Variable Generative Models,Rares-Darius Buhai;Andrej Risteski;Yoni Halpern;David Sontag,rbuhai@mit.edu;aristesk@andrew.cmu.edu;yhalpern@google.com;dsontag@csail.mit.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Carnegie Mellon University;Google;Massachusetts Institute of Technology,overparameterization;unsupervised;parameter recovery;rigorous experiments,5;1;-1;5,5;27;-1;5,m;m,usa,usa,n,1
4308,ICLR,2020,Detecting Noisy Training Data with Loss Curves,Geoff Pleiss;Tianyi Zhang;Ethan R. Elenberg;Kilian Q. Weinberger,geoff@cs.cornell.edu;tz58@cornell.edu;eelenberg@asapp.com;kqw4@cornell.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Cornell University;Cornell University;ASAPP Inc.;Cornell University,Deep learning;noisy data;robust training,7;7;-1;7,19;19;-1;19,m;m,usa,usa,n,1
4309,ICLR,2020,On Concept-Based Explanations in Deep Neural Networks,Chih-Kuan Yeh;Been Kim;Sercan Arik;Chun-Liang Li;Pradeep Ravikumar;Tomas Pfister,cjyeh@cs.cmu.edu;beenkim.mit@gmail.com;soarik@google.com;chunliang.tw@gmail.com;pradeep.ravikumar@gmail.com;tpfister@google.com,6;6;3;3,,Reject,0,9,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Carnegie Mellon University;Google,concept-based explanations;interpretability,1;-1;-1;-1;1;-1,27;-1;-1;-1;27;-1,m;m,NAN,NAN,y,
4310,ICLR,2020,Trajectory representation learning for Multi-Task NMRDPs planning,Firas JARBOUI;Vianney PERCHET;Roman EGGER,firasjarboui@gmail.com;vianney.perchet@gmail.com;roman.egger@fh-salzburg.ac.at,6;3;3,,Reject,0,4,0.0,yes,9/25/19,ENS Paris-Saclay;;University of Innsbruck,Representation Learning;State Estimation;Non Markovian Decision Process,-1;-1;-1,-1;-1;415,m;m,NAN,NAN,n,
4311,ICLR,2020,Distribution-Guided Local Explanation for Black-Box Classifiers,Weijie Fu;Meng Wang;Mengnan Du;Ninghao Liu;Shijie Hao;Xia Hu,fwj.edu@gmail.com;eric.mengwang@gmail.com;dumengnan@tamu.edu;nhliu43@tamu.edu;hfut.hsj@gmail.com;hu@cse.tamu.edu,6;3;3,,Reject,0,6,0.0,yes,9/25/19,Hefei University of Technology;;Texas A&M;Texas A&M;;Texas A&M,explanation;cnn;saliency map,-1;-1;46;46;-1;46,-1;-1;177;177;-1;177,m;m,NAN,NAN,n,
4312,ICLR,2020,Keyword Spotter Model for Crop Pest and Disease Monitoring from Community Radio Data,Benjamin Akera;Joyce Nakatumba-Nabende;Ali Hussein;Daniel Ssendiwala;Jonathan Mukiibi,akeraben@gmail.com;jnakatumba@cis.mak.ac.ug;ali.hussein@ronininstitute.org;ssendiwaladaniel@gmail.com;jonmuk7@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Makerere University;Makerere University;Ronin Institute;;Makerere University,keyword spotter;radio data;crop pest and disease;agriculture,-1;-1;-1;-1;-1,-1;605;-1;-1;-1,m;m,asia,in,n,
4313,ICLR,2020,Shallow VAEs with RealNVP Prior Can Perform as Well as Deep Hierarchical VAEs,Haowen Xu;Wenxiao Chen;Jinlin Lai;Zhihan Li;Youjian Zhao;Dan Pei,xhw15@mails.tsinghua.edu.cn;chen-wx17@mails.tsinghua.edu.cn;laijl16@mails.tsinghua.edu.cn;lizhihan17@mails.tsinghua.edu.cn;zhaoyoujian@tsinghua.edu.cn;peidan@tsinghua.edu.cn,6;3;3,,Reject,0,0,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Variational Auto-encoder;RealNVP;learnable prior,4;4;4;4;4;4,23;23;23;23;23;23,m;m,NAN,NAN,n,5
4314,ICLR,2020,Adaptive network sparsification with dependent variational beta-Bernoulli dropout,Juho Lee;Saehoon Kim;Jaehong Yoon;Hae Beom Lee;Eunho Yang;Sung Ju Hwang,juho@aitrics.com;shkim@aitrics.com;jaehong.yoon@kaist.ac.kr;haebeom.lee@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,6;3;6;3,,Reject,0,6,0.0,yes,9/25/19,AITRICS;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,network sparsification;variational inference;pruning,-1;-1;-1;-1;-1;-1,-1;-1;110;110;110;110,m;m,NAN,NAN,n,
4315,ICLR,2020,Scalable Generative Models for Graphs with Graph Attention Mechanism,Wataru Kawai;Yusuke Mukuta;Tatsuya Harada,w-kawai@mi.t.u-tokyo.ac.jp;mukuta@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,3;1;3,,Reject,0,9,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo,Graph Generative Model;Attention Mechanism,64;64;64,36;36;36,m;m,NAN,NAN,n,8;10;5
4316,ICLR,2020,On the Dynamics and Convergence of Weight Normalization for Training Neural Networks,Yonatan Dukler;Quanquan Gu;Guido Montufar,ydukler@math.ucla.edu;qgu@cs.ucla.edu;montufar@math.ucla.edu,3;6;3,,Reject,0,4,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Normalization methods;Weight Normalization;Convergence Theory,-1;-1;-1,17;17;17,m;m,usa,usa,y,1
4317,ICLR,2020,Semi-Supervised Few-Shot Learning with Prototypical Random Walks,Ahmed Ayyad;Nassir Navab;Mohamed Elhoseiny;Shadi Albarqouni,a.3ayad@gmail.com;nassir.navab@tum.de;mohamed.elhoseiny@gmail.com;shadi.albarqouni@tum.de,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Technical University Munich;Technical University Munich;KAUST;Technical University Munich,Few-Shot Learning;Semi-Supervised Learning;Random Walks,-1;-1;102;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6;10
4318,ICLR,2020,Agent as Scientist: Learning to Verify Hypotheses,Kenneth Marino;Rob Fergus;Arthur Szlam;Abhinav Gupta,kdmarino@cs.cmu.edu;fergus@cs.nyu.edu;aszlam@fb.com;abhinavg@cs.cmu.edu,3;3;1,,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;New York University;Facebook;Carnegie Mellon University,,1;22;-1;1,27;29;-1;27,m;m,usa,usa,n,
4319,ICLR,2020,Generating Robust Audio Adversarial Examples using Iterative Proportional Clipping,Hongting Zhang;Qiben Yan;Pan Zhou,htzhang@hust.edu.cn;qyan@msu.edu;panzhou@hust.edu.cn,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Hong Kong University of Science and Technology;Michigan State University;Hong Kong University of Science and Technology,audio adversarial examples;attack;machine learning,-1;102;-1,47;84;47,u;m,NAN,NAN,n,4
4320,ICLR,2020,Lean Images for Geo-Localization,Moti Kadosh;Yael Moses;Ariel Shamir,arik@idc.ac.il;yael@idc.ac.il,3;3;3,,Reject,0,0,0.0,yes,9/25/19,interdisciplinary center herzliya;interdisciplinary center herzliya,Geo Localization;Deep Learning;Computer Vision;Camera Localization,-1;-1,-1;-1,m;m,NAN,NAN,n,2
4321,ICLR,2020,Are Powerful Graph Neural Nets Necessary? A Dissection on Graph Classification,Ting Chen;Song Bian;Yizhou Sun,iamtingchen@gmail.com;biansonghz@gmail.com;yzsun@cs.ucla.edu,3;6;6,,Reject,0,5,0.0,yes,9/25/19,"Google;;University of California, Los Angeles",graph neural nets;graph classification;set function,-1;-1;-1,-1;-1;17,m;f,usa,usa,n,8;10
4322,ICLR,2020,DEEP GRAPH SPECTRAL EVOLUTION NETWORKS FOR GRAPH TOPOLOGICAL TRANSFORMATION,Liang Zhao;Qingzhe Li;Negar Etemadyrad;Xiaojie Guo,lzhao9@gmu.edu,6;3,,Reject,0,3,0.0,yes,9/25/19,George Mason University,deep graph learning;graph transformation;brain network,85,282,m;m,usa,usa,n,8;10
4323,ICLR,2020,Robust Federated Learning Through Representation Matching and Adaptive Hyper-parameters,Hesham Mostafa,hesham.mostafa@intel.com,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Intel,federated learning;hyper-parameter tuning;regularization,-1,-1,m,NAN,NAN,n,
4324,ICLR,2020,Enforcing Physical Constraints in Neural Neural Networks through Differentiable PDE Layer,"Chiyu Max"" Jiang;Karthik Kashinath;Prabhat;Philip Marcus""",chiyu.jiang@berkeley.edu;kkashinath@lbl.gov;prabhat@lbl.gov;pmarcus@me.berkeley.edu,3;6;3,,Reject,0,0,0.0,yes,9/25/19,University of California Berkeley;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;University of California Berkeley,PDE;Hard Constraints;Turbulence;Super-Resolution;Spectral Methods,-1;-1;-1;-1,13;-1;-1;13,m;m,usa,usa,n,5;4
4325,ICLR,2020,Evo-NAS: Evolutionary-Neural Hybrid Agent for Architecture Search,Krzysztof Maziarz;Mingxing Tan;Andrey Khorlin;Kuang-Yu Samuel Chang;Andrea Gesmundo,krzysztof.s.maziarz@gmail.com;tanmingxing@google.com;akhorlin@google.com;kysc@google.com;agesmundo@google.com,3;6;3,,Reject,1,11,0.0,yes,9/25/19,Microsoft;Google;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4326,ICLR,2020,HUBERT Untangles BERT to Improve Transfer across NLP Tasks,Mehrad Moradshahi;Hamid Palangi;Monica S. Lam;Paul Smolensky;Jianfeng Gao,mehrad@stanford.edu;hpalangi@microsoft.com;lam@cs.stanford.edu;paul.smolensky@gmail.com;jfgao@microsoft.com,1;3;3,,Reject,1,4,0.0,yes,9/25/19,Stanford University;Microsoft;Stanford University;Microsoft;Microsoft,Tensor Product Representation;BERT;Transfer Learning;Neuro-Symbolic Learning,5;-1;5;-1;-1,4;-1;4;-1;-1,m;m,NAN,NAN,n,8;3
4327,ICLR,2020,Learning De-biased Representations with Biased Representations,Hyojin Bahng;Sanghyuk Chun;Sangdoo Yun;Jaegul Choo;Seong Joon Oh,hjj552@korea.ac.kr;sanghyuk.c@navercorp.com;sangdoo.yun@navercorp.com;jchoo@korea.ac.kr;coallaoh@linecorp.com,6;6;6,,Reject,0,6,1.0,yes,9/25/19,Korea University;NAVER;NAVER;Korea University;LINE,Generalization;Bias;Dataset bias,168;-1;-1;168;-1,179;-1;-1;179;358,f;m,asia,ir,n,
4328,ICLR,2020,ICNN: INPUT-CONDITIONED FEATURE REPRESENTATION LEARNING FOR TRANSFORMATION-INVARIANT NEURAL NETWORK,Suraj Tripathi;Chirag Singh;Abhay Kumar,surajtripathi93@gmail.com;c.singh@samsung.com;abykumar12011@gmail.com,3;1;3,,Reject,0,1,0.0,yes,9/25/19,"Indian Institute of Technology Delhi;Samsung;University of Wisconsin, Madison",Transformation-invariance;Reconstruction;Run-time Convolution Filter generation,-1;-1;-1,-1;-1;-1,m;m,asia,in,y,1
4329,ICLR,2020,Learning Latent State Spaces for Planning through Reward Prediction,Aaron Havens;Yi Ouyang;Prabhat Nagarajan;Yasuhiro Fujita,ahavens2@illinois.edu;ouyangyi@preferred-america.com;prabhat@preferred.jp;fujita@preferred.jp,3;3;6,,Reject,0,4,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Deep Reinforcement Learning;Representation Learning;Model Based Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,
4330,ICLR,2020,Certified Robustness to Adversarial Label-Flipping Attacks via Randomized Smoothing,Elan Rosenfeld;Ezra Winston;Pradeep Ravikumar;J. Zico Kolter,ekr@andrew.cmu.edu;ewinston@andrew.cmu.edu;pradeepr@cs.cmu.edu;zkolter@cs.cmu.edu,3;3;3,,Reject,0,8,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Adversarial Robustness;Label Flipping Attack;Data Poisoning Attack,1;1;1;1,27;27;27;27,m;m,usa,usa,n,4
4331,ICLR,2020,Optimistic Adaptive Acceleration for Optimization,Jun-Kun Wang;Xiaoyun Li;Ping Li,jimwang@gatech.edu;xl374@scarletmail.rutgers.edu;liping11@baidu.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Georgia Institute of Technology;Rutgers University;Baidu,,13;30;-1,38;-1;-1,m;m,NAN,NAN,y,
4332,ICLR,2020,Hierarchical Bayes Autoencoders,Shuangfei Zhai;Carlos Guestrin;Joshua M. Susskind,szhai@apple.com;guestrin@apple.com;jsusskind@apple.com,1;1;3,,Reject,0,5,0.0,yes,9/25/19,Apple;Apple;Apple,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5;4
4333,ICLR,2020,Project and Forget: Solving Large Scale Metric Constrained Problems,Anna C. Gilbert;Rishi Sonthalia,annacg@umich.edu;rsonthal@umich.edu,6;3;6,,Reject,0,8,1.0,yes,9/25/19,University of Michigan;University of Michigan,metric constrained problems;metric learning;metric nearness;correlation clustering;Bregman projection;cutting planes;large scale optimization,7;7,21;21,f;m,usa,usa,y,1;10
4334,ICLR,2020,Deep Auto-Deferring Policy for Combinatorial Optimization,Sungsoo Ahn;Younggyo Seo;Jinwoo Shin,sungsoo.ahn@kaist.ac.kr;younggyo.seo@kaist.ac.kr;jinwoos@kaist.ac.kr,6;3;6,,Reject,0,6,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,deep reinforcement learning;combinatorial optimization,-1;-1;-1,110;110;110,m;m,NAN,NAN,n,8;10
4335,ICLR,2020,Under what circumstances do local codes emerge in feed-forward neural networks,Ella M. Gale;Nicolas Martin,ella.gale@bristol.ac.uk;nm13850@bristol.ac.uk,1;3;3;3,,Reject,0,0,0.0,yes,9/25/19,University of Bristol;University of Bristol,localist coding;emergence;contructionist science;neural networks;feed-forward;learning representation;distributed coding;generalisation;memorisation;biological plausibility;deep-NNs;training conditions,118;118,87;87,f;m,europe,uk,n,
4336,ICLR,2020,Reinforcement Learning with Structured Hierarchical Grammar Representations of Actions,Petros Christodoulou;Robert Lange;Ali Shafti;A. Aldo Faisal,petros.christodoulou18@imperial.ac.uk;rtl17@ic.ac.uk;a.shafti@imperial.ac.uk;a.faisal@imperial.ac.uk,3;8;1,,Reject,0,4,0.0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,Hierarchical Reinforcement Learning;Action Representations;Macro-Actions;Action Grammars,52;52;52;52,10;10;10;10,m;m,europe,uk,n,
4337,ICLR,2020,Global Adversarial Robustness Guarantees for Neural Networks,Luca Laurenti;Andrea Patane;Matthew Wicker;Luca Bortolussi;Luca Cardelli;Marta Kwiatkowska,luca.laurenti@cs.ox.ac.uk;andrea.patane@chch.ox.ac.uk;matthew.wicker@wolfson.ox.ac.uk;luca.bortolussi@gmail.com;luca.a.cardelli@gmail.com;marta.kwiatkowska@cs.ox.ac.uk,3;1;1,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;;;University of Oxford,Adversarial Robustness;Statistical Guarantees;Deep Neural Networks;Bayesian Neural Networks,46;46;46;-1;-1;46,1;1;1;-1;-1;1,m;f,europe,uk,y,11;1;4
4338,ICLR,2020,Learning Calibratable Policies using Programmatic Style-Consistency,Eric Zhan;Albert Tseng;Yisong Yue;Adith Swaminathan;Matthew Hausknecht,ezhan@caltech.edu;atseng@caltech.edu;yyue@caltech.edu;adswamin@microsoft.com;mahauskn@microsoft.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,California Institute of Technology;California Institute of Technology;California Institute of Technology;Microsoft;Microsoft,imitation learning;conditional generation;data programming,143;143;143;-1;-1,2;2;2;-1;-1,m;m,NAN,NAN,n,
4339,ICLR,2020,Alternating Recurrent Dialog Model with Large-Scale Pre-Trained Language Models,Qingyang Wu;Yichi Zhang;Yu Li;Zhou Yu,wilwu@ucdavis.edu;zhangyic17@mails.tsinghua.edu.cn;yooli@ucdavis.edu;joyu@ucdavis.edu,1;3;8,,Reject,0,4,0.0,yes,9/25/19,"University of California, Davis;Tsinghua University, Tsinghua University;University of California, Davis;University of California, Davis",NLP;Pre-training;GPT-2;Text Generation;Dialog Generation,-1;4;-1;-1,55;23;55;55,m;f,usa,usa,n,3
4340,ICLR,2020,Learning to Reason: Distilling Hierarchy via Self-Supervision and Reinforcement Learning,Jung-Su Ha;Young-Jin Park;Hyeok-Joo Chae;Soon-Seo Park;Han-Lim Choi,jung-su.ha@ipvs.uni-stuttgart.de;yjpark@lics.kaist.ac.kr;hjchae@lics.kaist.ac.kr;sspark@lics.kaist.ac.kr;hanlimc@kaist.ac.kr,6;1;3,,Reject,0,10,0.0,yes,9/25/19,University of Stuttgart;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement learning;Self-supervised learning;unsupervised learning;representation learning,118;-1;-1;-1;-1,292;110;110;110;110,m;m,NAN,NAN,n,
4341,ICLR,2020,The Geometry of Sign Gradient Descent,Lukas Balles;Fabian Pedregosa;Nicolas Le Roux,lukas.balles@tuebingen.mpg.de;f@bianp.net;nicolas@le-roux.name,3;1;3,,Reject,0,4,0.0,yes,9/25/19,Max-Planck Institute;Google;Google,Sign gradient descent;signSGD;steepest descent;Adam,-1;-1;-1,-1;-1;-1,m;m,asia,in,y,1
4342,ICLR,2020,Effective Use of Variational Embedding Capacity in Expressive End-to-End Speech Synthesis,Eric Battenberg;Soroosh Mariooryad;Daisy Stanton;RJ Skerry-Ryan;Matt Shannon;David Kao;Tom Bagby,ebattenberg@google.com;soroosh@google.com;daisy@google.com;rjryan@google.com;mattshannon@google.com;davidkao@google.com;tombagby@google.com,6;6;3,,Reject,0,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,Speech Synthesis;Deep Generative Models;Latent Variable Models;Unsupervised Representation Learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
4343,ICLR,2020,The problem with DDPG: understanding failures in deterministic environments with sparse rewards,Guillaume Matheron;Olivier Sigaud;Nicolas Perrin,matheron@isir.upmc.fr;olivier.sigaud@upmc.fr;perrin@isir.upmc.fr,6;3;3,,Reject,0,4,0.0,yes,9/25/19,"Universit√© Pierre et Marie Curie - Paris 6;Computer Science Lab  - Pierre and Marie Curie University, Paris, France;Universit√© Pierre et Marie Curie - Paris 6",ddpg;reinforcement learning;deep learning;policy gradient,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
4344,ICLR,2020,Enhanced Convolutional Neural Tangent Kernels,Dingli Yu;Ruosong Wang;Zhiyuan Li;Wei Hu;Ruslan Salakhutdinov;Sanjeev Arora;Simon S. Du,dingliy@cs.princeton.edu;ruosongw@andrew.cmu.edu;zhiyuanli@cs.princeton.edu;huwei@cs.princeton.edu;rsalakhu@cs.cmu.edu;arora@cs.princeton.edu;ssdu@ias.edu,3;6;6,,Reject,0,6,0.0,yes,9/25/19,"Princeton University;Carnegie Mellon University;Princeton University;Princeton University;Carnegie Mellon University;Princeton University;Institue for Advanced Study, Princeton",neural tangent kernel;data augmentation;global average pooling;kernel regression;deep learning theory;kernel design,30;1;30;30;1;30;-1,6;27;6;6;27;6;-1,m;m,NAN,NAN,y,
4345,ICLR,2020,COMBINED FLEXIBLE ACTIVATION FUNCTIONS FOR DEEP NEURAL NETWORKS,Renlong Jie;Junbin Gao;Andrey Vasnev;Minh-Ngoc Tran,renlong.jie@sydney.edu.au;junbin.gao@sydney.edu.au;andrey.vasnev@sydney.edu.au;minh-ngoc.tran@sydney.edu.au,1;3;3,,Reject,0,4,0.0,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney;University of Sydney,Flexible;Activation Functions;Deep Learning;Regularization,64;64;64;64,60;60;60;60,m;m,europe,uk,n,
4346,ICLR,2020,Meta-RCNN: Meta Learning for Few-Shot Object Detection,Xiongwei Wu;Doyen Sahoo;Steven C. H. Hoi,xwwu.2015@smu.edu.sg;dsahoo@salesforce.com;shoi@salesforce.com,6;3;8,,Reject,0,3,0.0,yes,9/25/19,Singapore Management University;SalesForce.com;SalesForce.com,Few-shot detection;Meta-Learning;Object Detection,79;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,6;2
4347,ICLR,2020,AutoSlim: Towards One-Shot Architecture Search for Channel Numbers,Jiahui Yu;Thomas Huang,jyu79@illinois.edu;t-huang1@illinois.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",AutoSlim;Neural Architecture Search;Efficient Networks;Network Pruning,-1;-1,-1;-1,m;m,usa,usa,n,
4348,ICLR,2020,Learning from Imperfect Annotations: An End-to-End Approach,Emmanouil Antonios Platanios;Maruan Al-Shedivat;Eric Xing;Tom Mitchell,e.a.platanios@cs.cmu.edu;alshedivat@cs.cmu.edu;epxing@cs.cmu.edu;tom.mitchell@cs.cmu.edu,6;6;6,,Reject,0,4,1.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1,27;27;27;27,m;m,usa,usa,n,
4349,ICLR,2020,Feature Map Transform Coding for Energy-Efficient CNN Inference,Brian Chmiel;Chaim Baskin;Ron Banner;Evgenii Zheltonozhskii;Yevgeny Yermolin;Alex Karbachevsky;Alex M. Bronstein;Avi Mendelson,brian.chmiel@intel.com;chaimbaskin@cs.technion.ac.il;ron.banner@intel.com;evgeniizh@campus.technion.ac.il;yevgeny_ye@campus.technion.ac.il;alex.k@cs.technion.ac.il;bron@cs.technion.ac.il;avi.mendelson@cs.technion.ac.il,3;3;8,,Reject,0,3,0.0,yes,9/25/19,"Intel;Technion, Technion;Intel;Technion, Technion;Technion, Technion;Technion, Technion;Technion, Technion;Technion, Technion",compression;efficient inference;quantization;memory bandwidth;entropy,-1;27;-1;27;27;27;27;27,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2
4350,ICLR,2020,Zero-Shot Out-of-Distribution Detection with Feature Correlations,Chandramouli S Sastry;Sageev Oore,chandramouli.sastry@gmail.com;osageev@gmail.com,3;8;3,,Reject,0,11,0.0,yes,9/25/19,Dalhousie University;Dalhousie University,out-of-distribution;gram matrices;classification;out-of-distribution detection,316;316,269;269,m;m,canada,ca,n,
4351,ICLR,2020,Neural Video Encoding,Abel Brown;Robert DiPietro,abelb@nvidia.com;rdipietro@nvidia.com,1;1;3,,Reject,0,0,0.0,yes,9/25/19,NVIDIA;NVIDIA,Kolmogorov complexity;differentiable programming;convolutional neural networks,-1;-1,-1;-1,m;m,NAN,NAN,n,3;2;1
4352,ICLR,2020,Continuous Adaptation in Multi-agent Competitive Environments,Kuei-Tso Lee;Sheng-Jyh Wang,fuj30089@gmail.com;shengjyh@faculty.nctu.edu.tw,1;1,,Reject,0,4,0.0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,multi-agent environment;continuous adaptation;Nash equilibrium;deep counterfactual regret minimization;reinforcement learning;stochastic game;baseball,-1;118,-1;564,u;m,asia,tw,n,
4353,ICLR,2020,Simple and Effective Stochastic Neural Networks,Tianyuan Yu;Yongxin Yang;Da Li;Timothy Hospedales;Tao Xiang,tianyuan.yu@surrey.ac.uk;yongxin.yang@surrey.ac.uk;dali.darren@hotmail.com;t.hospedales@ed.ac.uk;t.xiang@surrey.ac.uk,6;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Surrey;University of Surrey;;University of Edinburgh;University of Surrey,stochastic neural networks;pruning;adversarial defence;label noise,168;168;-1;36;168,260;260;-1;30;260,m;m,europe,uk,n,11;1;4
4354,ICLR,2020,On The Difficulty of Warm-Starting Neural Network Training,Jordan T. Ash;Ryan P. Adams,jordanta@cs.princeton.edu;rpa@princeton.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Princeton University;Princeton University,deep learning;neural networks,30;30,6;6,m;m,usa,usa,y,1
4355,ICLR,2020,Thwarting finite difference adversarial attacks with output randomization,Haidar Khan;Dan Park;Azer Khan;B√ºlent Yener,haidark@gmail.com;parkd5@gmail.com;azerkkhan@gmail.com;byener@gmail.com,3;6;3;3,,Reject,0,7,0.0,yes,9/25/19,Amazon;;;Rensselaer Polytechnic Institute,black box adversarial attacks;adversarial examples;defense;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n,1;4
4356,ICLR,2020,Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming,Claudio Michaelis;Benjamin Mitzkus;Robert Geirhos;Evgenia Rusak;Oliver Bringmann;Alexander S. Ecker;Matthias Bethge;Wieland Brendel,claudio.michaelis@uni-tuebingen.de;benjamin.mitzkus@uni-tuebingen.de;robert@geirhos.de;evgenia.rusak@bethgelab.org;oliver.bringmann@uni-tuebingen.de;alexander.ecker@uni-tuebingen.de;matthias@bethgelab.org;wieland.brendel@bethgelab.org,3;3;3,,Reject,0,6,0.0,yes,9/25/19,"University of Tuebingen;University of Tuebingen;;Centre for Integrative Neuroscience, AG Bethge;University of Tuebingen;University of Tuebingen;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge",deep learning;object detection;robustness;neural networks;data augmentation;autonomous driving,143;143;-1;-1;143;143;-1;-1,91;91;-1;-1;91;91;-1;-1,m;m,NAN,NAN,n,2
4357,ICLR,2020,Negative Sampling in Variational Autoencoders,Adri√°n Csisz√°rik;Beatrix Benk≈ë;D√°niel Varga,csadrian@renyi.hu;bbeatrix1010@gmail.com;daniel@renyi.hu,3;6;3,,Reject,0,5,0.0,yes,9/25/19,Alfr√©d R√©nyi Institute of Mathematics;;Alfr√©d R√©nyi Institute of Mathematics,Variational Autoencoder;generative modelling;out-of-distribution detection,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5;4
4358,ICLR,2020,An Empirical and Comparative Analysis of Data Valuation with Scalable Algorithms,Ruoxi Jia;Xuehui Sun;Jiacen Xu;Ce Zhang;Bo Li;Dawn Song,ruoxijia@berkeley.edu;zidaneandmessi@sjtu.edu.cn;coldstudy@sjtu.edu.cn;ce.zhang@inf.ethz.ch;lxbosky@gmail.com;dawnsong@gmail.com,1;1;3,,Reject,0,9,0.0,yes,9/25/19,University of California Berkeley;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Swiss Federal Institute of Technology;University of California Berkeley;University of California Berkeley,Data valuation;machine learning,-1;30;30;-1;-1;-1,13;157;157;-1;13;13,f;f,usa,usa,y,1
4359,ICLR,2020,Attraction-Repulsion Actor-Critic for Continuous Control Reinforcement Learning,Thang Doan;Bogdan Mazoure;Audrey Durand;Joelle Pineau;R Devon Hjelm,thang.doan@mail.mcgill.ca;bogdan.mazoure@mail.mcgill.ca;audrey.durand@ift.ulaval.ca;jpineau@cs.mcgill.ca;devon.hjelm@microsoft.com,3;3;8,,Reject,0,4,0.0,yes,9/25/19,McGill University;McGill University;Laval university;McGill University;Microsoft,reinforcement learning;continuous control;multi-agent;mujoco,102;102;-1;102;-1,42;42;272;42;-1,f;m,NAN,NAN,n,
4360,ICLR,2020,NormLime: A New Feature Importance Metric for Explaining Deep Neural Networks,Isaac Ahern;Adam Noack;Luis Guzman-Nateras;Dejing Dou;Boyang Li;Jun Huan,isaac@biofidelic.com;anoack2@uoregon.edu;lguzmann@uoregon.edu;dou@cs.uoregon.edu;boyangli@baidu.com;huanjun@baidu.com,3;6;6,,Reject,0,3,0.0,yes,9/25/19,University of Oregon;University of Oregon;University of Oregon;University of Oregon;Baidu;Baidu,Machine Learning;Deep Learning;Interpretability;Feature Importance;Salience,194;194;194;194;-1;-1,288;288;288;288;-1;-1,m;m,NAN,NAN,n,
4361,ICLR,2020,Unsupervised Learning of Node Embeddings by Detecting Communities,Chi Thang Duong;Dung Hoang;Truong Giang Le Ba;Thanh Le Cong;Hongzhi Yin;Matthias Weidlich;Quoc Viet Hung Nguyen;Karl Aberer,thang.duong@epfl.ch;dungmin97@gmail.com;giangpna98@gmail.com;thanhcls1316@gmail.com;h.yin1@uq.edu.au;matthias.weidlich@hu-berlin.de;quocviethung1@gmail.com;karl.aberer@epfl.ch,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;;;Hong Kong University of Science and Technology;University of Queensland;Humboldt Universit√§t Berlin;Griffith University;Swiss Federal Institute of Technology Lausanne,Unsupervised Learning;Graph Embedding;Community Detection;Mincut;Normalized cut;Deep Learning,-1;-1;-1;-1;248;-1;-1;-1,-1;-1;-1;47;66;-1;240;-1,m;m,NAN,NAN,y,10
4362,ICLR,2020,Global graph curvature,Liudmila Prokhorenkova;Egor Samosvat;Pim van der Hoorn,ostroumova-la@yandex-team.ru;sameg@yandex-team.ru;pimvdhoorn@gmail.com,6;6;3,,Reject,0,8,0.0,yes,9/25/19,Yandex;Yandex;Eindhoven University of Technology,graph curvature;graph embedding;hyperbolic space;distortion;Ollivier curvature;Forman curvature,-1;-1;-1,-1;-1;185,f;m,NAN,NAN,y,10
4363,ICLR,2020,Invertible generative models for  inverse problems: mitigating representation error and dataset bias,Muhammad Asim;Ali Ahmed;Paul Hand,msee16001@itu.edu.pk;ali.ahmed@itu.edu.pk;p.hand@northeastern.edu,6;1;3;6,,Reject,0,4,0.0,yes,9/25/19,"ITU of Punjab Lahore, Pakistan;ITU of Punjab Lahore, Pakistan;Northeastern University",Invertible generative models;inverse problems;generative prior;Glow;compressed sensing;denoising;inpainting.,-1;-1;16,-1;-1;906,m;m,usa,usa,n,5;4
4364,ICLR,2020,Decaying momentum helps neural network training,John Chen;Anastasios Kyrillidis,jc114@rice.edu;anastasios@rice.edu,6;3;3,,Reject,0,10,0.0,yes,9/25/19,Rice University;Rice University,sgd;momentum;adam;optimization;deep learning,92;92,105;105,m;m,australasia,au,n,
4365,ICLR,2020,GRAPH NEIGHBORHOOD ATTENTIVE POOLING,Zekarias Tilahun Kefato;Sarunas Girdzijauskas,zekarias@kth.se;sarunasg@kth.se,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",Network Representation Learning;Attentive Pooling Networks;Context-sensitive Embedding;Mutual Attention;Link Prediction;Node Clustering,194;194,222;222,m;m,NAN,NAN,n,10
4366,ICLR,2020,Quantum algorithm for finding the negative curvature direction,Kaining Zhang;Min-Hsiu Hsieh;Liu Liu;Dacheng Tao,kzha3670@uni.sydney.edu.au;min-hsiu.hsieh@uts.edu.au;liu.liu1@sydney.edu.au;dacheng.tao@sydney.edu.au,6;6;3,,Reject,0,4,0.0,yes,9/25/19,University of Sydney;University of Technology Sydney;University of Sydney;University of Sydney,quantum algorithm;negative curvature,64;73;64;64,60;193;60;60,u;m,europe,uk,y,1;9
4367,ICLR,2020,"Walking on the Edge: Fast, Low-Distortion Adversarial Examples",Hanwei Zhang;Teddy Furon;Yannis Avrithis;Laurent Amsaleg,hanwei.zhang@irisa.fr;teddy.furon@inria.fr;yannis@avrithis.net;laurent.amsaleg@irisa.fr,3;3;6,,Reject,0,5,0.0,yes,9/25/19,IRISA;INRIA;INRIA;IRISA,Deep learning;adversarial attack,-1;-1;-1;-1,-1;-1;-1;-1,f;m,europe,fr,n,8;4
4368,ICLR,2020,"Deep Reasoning Networks:  Thinking Fast and Slow, for Pattern De-mixing",Di Chen;Yiwei Bai;Wenting Zhao;Sebastian Ament;John M. Gregoire;Carla P. Gomes,di@cs.cornell.edu;bywbilly@cs.cornell.edu;wzhao@cs.cornell.edu;ament@cs.cornell.edu;gregoire@caltech.edu;gomes@cs.cornell.edu,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Cornell University;Cornell University;Cornell University;Cornell University;California Institute of Technology;Cornell University,Deep Reasoning Network;Pattern De-mixing,7;7;7;7;143;7,19;19;19;19;2;19,m;f,usa,usa,n,
4369,ICLR,2020,Measuring Calibration in Deep Learning,Jeremy Nixon;Mike Dusenberry;Ghassen Jerfel;Linchuan Zhang;Dustin Tran,jeremynixon@google.com;dusenberrymw@google.com;ghassen@google.com;linchzhang@google.com;trandustin@google.com,6;3;1,,Reject,0,0,0.0,yes,9/25/19,Google;Google;Google;Google;Google,Deep Learning;Multiclass Classification;Classification;Uncertainty Estimation;Calibration,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4370,ICLR,2020,Towards Understanding the Regularization of Adversarial Robustness on Neural Networks,Yuxin Wen;Shuai Li;Kui Jia,wen.yuxin@mail.scut.edu.cn;lishuai918@gmail.com;kuijia@scut.edu.cn,6;3;6,,Reject,0,7,0.0,yes,9/25/19,South China University of Technology;;South China University of Technology,Adversarial robustness;Statistical Learning;Regularization,-1;-1;-1,501;-1;501,f;m,NAN,NAN,y,1;4
4371,ICLR,2020,BRIDGING ADVERSARIAL SAMPLES AND ADVERSARIAL NETWORKS,Faqiang Liu;Mingkun Xu;Guoqi Li;Jing Pei;Luping Shi,lfq18@mails.tsinghua.edu.cn;xmk18@mails.tsinghua.edu.cn;liguoqi@mail.tsinghua.edu.cn;peij@mail.tsinghua.edu.cn;lpshi@mail.tsinghua.edu.cn,6;3;3,,Reject,0,6,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",ADVERSARIAL SAMPLES;ADVERSARIAL NETWORKS,4;4;4;4;4,23;23;23;23;23,m;m,NAN,NAN,n,5;4
4372,ICLR,2020,Kernel and Rich Regimes in Overparametrized Models,Blake Woodworth;Suriya Gunasekar;Pedro Savarese;Edward Moroshko;Itay Golan;Jason Lee;Daniel Soudry;Nathan Srebro,blake@ttic.edu;suriya@ttic.edu;savarese@ttic.edu;edward.moroshko@gmail.com;sitaygo@campus.technion.ac.il;jasondlee88@gmail.com;daniel.soudry@gmail.com;nati@ttic.edu,6;8;3,,Reject,0,3,0.0,yes,9/25/19,"Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;;Technion, Technion;Princeton University;Technion, Technion;Toyota Technological Institute at Chicago",Overparametrized;Implicit;Bias;Regularization;Kernel;Rich;Adaptive;Regime,-1;-1;-1;-1;27;30;27;-1,-1;-1;-1;-1;-1;6;-1;-1,m;m,NAN,NAN,y,1
4373,ICLR,2020,The Intriguing Effects of Focal Loss on the Calibration of Deep Neural Networks,Jishnu Mukhoti;Viveka Kulharia;Amartya Sanyal;Stuart Golodetz;Philip Torr;Puneet Dokania,jishnumukhoti7@gmail.com;viveka@robots.ox.ac.uk;amartya.sanyal@cs.ox.ac.uk;stuart@five.ai;philip.torr@eng.ox.ac.uk;puneet@robots.ox.ac.uk,6;3;6,,Reject,0,13,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;FiveAI;University of Oxford;University of Oxford,,-1;46;46;-1;46;46,-1;1;1;-1;1;1,m;m,europe,uk,y,2;3
4374,ICLR,2020,Domain-Invariant Representations: A Look on Compression and Weights,Victor Bouvier;C√©line Hudelot;Cl√©ment Chastagnol;Philippe Very;Myriam Tami,vbouvier@sidetrade.com;celine.hudelot@centralesupelec.fr;cchastagnol@sidetrade.com;pveryranchet@gmail.com;myriam.tami@centralesupelec.fr,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Sidetrade;CentraleSupelec;Sidetrade;;CentraleSupelec,Domain Adaptation;Invariant Representation;Compression;Machine Learning Theory,-1;-1;-1;-1;-1,-1;534;-1;-1;534,m;f,NAN,NAN,y,8;1
4375,ICLR,2020,Last-iterate convergence rates for min-max optimization,Jacob Abernethy;Kevin A. Lai;Andre Wibisono,prof@gatech.edu;nykal212@gmail.com;andrwbsn@gmail.com,6;6;6,,Reject,0,5,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Yale University,min-max optimization;zero-sum game;saddle point;last-iterate convergence;non-asymptotic convergence;global rates;Hamiltonian;sufficiently bilinear,13;13;73,38;38;8,m;m,europe,fi,y,1;5;4;9
4376,ICLR,2020,Implicit Generative Modeling for Efficient Exploration,Neale Ratzlaff;Qinxun Bai;Li Fuxin;Wei Xu,ratzlafn@oregonstate.edu;qinxun.bai@horizon.ai;lif@oregonstate.edu;wei.xu@horizon.ai,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Oregon State University;Horizon Robotics;Oregon State University;Horizon Robotics,Reinforcement Learning;Exploration;Intrinsic Reward;Implicit Generative Models,79;-1;79;-1,373;-1;373;-1,m;m,NAN,NAN,n,11;5
4377,ICLR,2020,Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration,Zhenyu Wu;Ye Yuan;Zhaowen Wang;Jianming Zhang;Zhangyang Wang;Hailin Jin,wuzhenyu_sjtu@tamu.edu;ye.yuan@tamu.edu;zhawang@adobe.com;jianmzha@adobe.com;atlaswang@tamu.edu;hljin@adobe.com,3;6;1,,Reject,0,4,0.0,yes,9/25/19,Texas A&M;Texas A&M;Adobe Systems;Adobe Systems;Texas A&M;Adobe Systems,Generative Adversarial Networks;Mode Collapse;Calibration,46;46;-1;-1;46;-1,177;177;-1;-1;177;-1,m;m,NAN,NAN,n,5;4
4378,ICLR,2020,Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning,Jianda Chen;Shangyu Chen;Sinno Jialin Pan,jianda001@e.ntu.edu.sg;schen025@e.ntu.edu.sg;sinnopan@ntu.edu.sg,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University,,43;43;43,49;49;49,m;m,asia,sg,n,
4379,ICLR,2020,Generalized Zero-shot ICD Coding,Congzheng Song;Shanghang Zhang;Najmeh Sadoughi;Pengtao Xie;Eric Xing,cs2296@cornell.edu;shanghang.zhang@petuum.com;najmeh.sadoughi@petuum.com;pengtao.xie@petuum.com;eric.xing@petuum.com,3;6;6,,Reject,0,4,0.0,yes,9/25/19,Cornell University;Petuum Inc.;Petuum Inc.;Petuum Inc.;Petuum Inc.,Generalized Zero-shot Learning;ICD Coding;NLP;Generative Model;Deep Learning,7;-1;-1;-1;-1,19;-1;-1;-1;-1,m;m,NAN,NAN,n,6;5;4
4380,ICLR,2020,"Unsupervised Disentanglement of Pose, Appearance and Background from Images and Videos",Aysegul Dundar;Kevin J Shih;Animesh Garg;Robert Pottorf;Andrew Tao;Bryan Catanzaro,aysegul.dundar89@gmail.com;kjshih2@illinois.edu;garg@cs.stanford.edu;rpottorff@gmail.com;atao@nvidia.com;bcatanzaro@nvidia.com,3;6;6,,Reject,0,4,0.0,yes,9/25/19,"NVIDIA;University of Illinois, Urbana Champaign;Stanford University;;NVIDIA;NVIDIA",unsupervised landmark discovery,-1;-1;5;-1;-1;-1,-1;-1;4;-1;-1;-1,f;m,NAN,NAN,n,
4381,ICLR,2020,A Bayes-Optimal View on Adversarial Examples,Eitan Richardson;Yair Weiss,eitan.richardson@gmail.com;yweiss@cs.huji.ac.il,1;6;3,,Reject,0,12,1.0,yes,9/25/19,Google;Hebrew University of Jerusalem,Adversarial Examples;Generative Models,-1;85,-1;216,m;m,europe,il,n,4
4382,ICLR,2020,"Carpe Diem, Seize the Samples Uncertain at the Moment"" for Adaptive Batch Selection""",Hwanjun Song;Minseok Kim;Sundong Kim;Jae-Gil Lee,songhwanjun@kaist.ac.kr;minseokkim@kaist.ac.kr;sundong@ibs.re.kr;jaegil@kaist.ac.kr,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Institute for Basic Science;Korea Advanced Institute of Science and Technology,batch selection;uncertain sample;acceleration;convergence,-1;-1;-1;-1,110;110;-1;110,m;m,NAN,NAN,n,
4383,ICLR,2020,EXACT ANALYSIS OF CURVATURE CORRECTED LEARNING DYNAMICS IN DEEP LINEAR NETWORKS,Dongsung Huh,dongsunghuh@gmail.com,6;6;1,,Reject,0,5,0.0,yes,9/25/19,International Business Machines,,-1,-1,m,NAN,NAN,n,
4384,ICLR,2020,TreeCaps: Tree-Structured Capsule Networks for Program Source Code Processing,Vinoj Jayasundara;Nghi Duy Quoc Bui;Lingxiao Jiang;David Lo,vinojjayasundara@gmail.com;dqnbui.2016@phdis.smu.edu.sg;lxjiang@smu.edu.sg;davidlo@smu.edu.sg,1;3;1,,Reject,0,4,0.0,yes,9/25/19,"University of Maryland, College Park;Singapore Management University;Singapore Management University;Singapore Management University",Program Classification;Capsule Networks;Deep Learning,12;79;79;79,91;-1;-1;-1,m;m,asia,sg,n,3;10
4385,ICLR,2020,Pre-trained Contextual Embedding of Source Code,Aditya Kanade;Petros Maniatis;Gogul Balakrishnan;Kensen Shi,akanade@google.com;maniatis@google.com;bgogul@google.com;kshi@google.com,6;3;6,,Reject,0,14,1.0,yes,9/25/19,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4386,ICLR,2020,AdaX: Adaptive Gradient Descent with Exponential Long Term Memory,Wenjie Li;Zhaoyang Zhang;Xinjiang Wang;Ping Luo,li3549@purdue.edu;zhaoyangzhang@link.cuhk.edu.hk;swanxinjiang@gmail.com;pluo.lhi@gmail.com,3;3;1;3,,Reject,0,4,0.0,yes,9/25/19,Purdue University;The Chinese University of Hong Kong;SenseTime Group Limited;The University of Hong Kong,Optimization Algorithm;Machine Learning;Deep Learning;Adam,24;316;-1;92,88;35;-1;35,m;m,NAN,NAN,y,3;2;1;9
4387,ICLR,2020,MIST: Multiple Instance Spatial Transformer Networks,Baptiste Angles;Simon Kornblith;Shahram Izadi;Andrea Tagliasacchi;Kwang Moo Yi,baptiste.angles@gmail.com;skornblith@google.com;shahrami@google.com;taglia@google.com;kyi@uvic.ca,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Apple;Google;Google;Google;University of Victoria,,-1;-1;-1;-1;194,-1;-1;-1;-1;449,m;m,europe,cy,n,
4388,ICLR,2020,Differentiable Bayesian Neural Network Inference for Data Streams,Namuk Park;Taekyu Lee;Songkuk Kim,namuk.park@yonsei.ac.kr;taekyu.lee@yonsei.ac.kr;songkuk@yonsei.ac.kr,3;3;8,,Reject,0,4,0.0,yes,9/25/19,Yonsei University;Yonsei University;Yonsei University,Bayesian neural network;approximate predictive inference;data stream;histogram,143;143;143,196;196;196,m;m,asia,cn,n,2;11
4389,ICLR,2020,CAT: Compression-Aware Training for bandwidth reduction,Chaim Baskin;Brian Chmiel;Evgenii Zheltonozhskii;Ron Banner;Alex M. Bronstein;Avi Mendelson,chaimbaskin@cs.technion.ac.il;brian.chmiel@intel.com;evgeniizh@campus.technion.ac.il;ron.banner@intel.com;bron@cs.technion.ac.il;avi.mendelson@cs.technion.ac.il,6;6;6,,Reject,0,5,0.0,yes,9/25/19,"Technion, Technion;Intel;Technion, Technion;Intel;Technion, Technion;Technion, Technion",compression;quantization;efficient inference;memory bandwidth;entropy;compression-aware training;Huffman;variable length coding,27;-1;27;-1;27;27,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4390,ICLR,2020,Using Logical Specifications of Objectives in Multi-Objective Reinforcement Learning,Kolby Nottingham;Anand Balakrishnan;Jyotirmoy Deshmukh;Connor Christopherson;David Wingate,kolbytn@byu.edu;anandbal@usc.edu;jdeshmukh@usc.edu;connormc@byu.edu;wingated@cs.byu.edu,3;6;3,,Reject,0,4,0.0,yes,9/25/19,The Hong Kong Polytechnic University;University of Southern California;University of Southern California;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,reinforcement learning;multi-objective;multi-task;propositional logic,118;36;36;118;118,171;62;62;171;171,m;m,asia,hk,n,
4391,ICLR,2020,High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection,VSR Veeravasarapu;Deepak Mittal;Abhishek Goel;Maneesh Singh,vsr.veera@gmail.com;deepak.mittal@verisk.com;abhishek.goel@verisk.com;maneesh.singh@verisk.com,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Verisk Analytics;Verisk Analytics;Verisk Analytics;Verisk Analytics,Computer Vision;Object Contour Detection;Curriculum Learning;Wavelets;Aerial Imagery,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4392,ICLR,2020,Learning General and Reusable Features via Racecar-Training,You Xie;Nils Thuerey,you.xie@tum.de;nils.thuerey@tum.de,1;3,,Reject,0,3,0.0,yes,9/25/19,Technical University Munich;Technical University Munich,transfer learning;neural networks;generalization;reusable features,-1;-1,-1;-1,m;m,NAN,NAN,n,
4393,ICLR,2020,Weakly-supervised Knowledge Graph Alignment with Adversarial Learning,Meng Qu;Jian Tang;Yoshua Bengio,meng.qu@umontreal.ca;jian.tang@hec.ca;yoshua.bengio@mila.quebec,6;6;3,,Reject,0,4,0.0,yes,9/25/19,University of Montreal;HEC Montreal;Mila,,118;-1;143,85;-1;336,m;m,NAN,NAN,y,1;10;4
4394,ICLR,2020,Differentially Private Mixed-Type Data Generation For Unsupervised Learning,Uthaipon Tantipongpipat;Chris Waites;Digvijay Boob;Amaresh Siva;Rachel Cummings,uthaipon@gmail.com;cwaites10@gmail.com;digvijaybb40@gmail.com;ankit.siva@gatech.edu;racheladcummings@gmail.com,1;3,,Reject,0,1,0.0,yes,9/25/19,Twitter;;;Georgia Institute of Technology;Columbia University,Differential privacy;synthetic data;private data generation;mixed-type;unsupervised learning;autoencoder;GAN;private deep learning,-1;-1;-1;13;24,-1;-1;-1;38;16,m;f,usa,usa,y,5
4395,ICLR,2020,Defense against Adversarial Examples by Encoder-Assisted Search in the Latent Coding Space,Wenjing Huang;Shikui Tu;Lei Xu,huangwenjing@sjtu.edu.cn;tushikui@sjtu.edu.cn,3;3;3;6,,Reject,1,7,0.0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Adversarial Defense;Auto-encoder;Adversarial Attack;GAN,30;30,157;157,m;m,asia,cn,n,5;4
4396,ICLR,2020,Matrix Multilayer Perceptron,Jalil Taghia;Maria B√•nkestad;Fredrik Lindsten;Thomas Sch√∂n,jalil.taghia@ericsson.com;maria.bankestad@ri.se;fredrik.lindsten@liu.se;thomas.schon@it.uu.se,6;6;3,,Reject,0,3,0.0,yes,9/25/19,Ericsson;RISE Research Institutes of Sweden;Link√∂ping University;Uppsala University,Multilayer Perceptron;symmetric positive definite;heteroscedastic regression;covariance estimation,-1;-1;-1;194,-1;-1;407;102,m;m,europe,se,n,
4397,ICLR,2020,A Simple Dynamic Learning Rate Tuning Algorithm For Automated Training of DNNs,Koyel Mukherjee;Alind Khare;Yogish Sabharwal;Ashish Verma,koyelmjee@gmail.com;kharealind@gmail.com;ysabharwal@in.ibm.com;ashish.verma1@ibm.com,1;1;1,,Reject,0,7,0.0,yes,9/25/19,"University of Maryland, College Park;;International Business Machines;International Business Machines",adaptive LR tuning algorithm;generalization,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,4
4398,ICLR,2020,Structural Language Models for Any-Code Generation,Uri Alon;Roy Sadaka;Omer Levy;Eran Yahav,urialon@cs.technion.ac.il;roysadaka@gmail.com;omerlevy@gmail.com;yahave@cs.technion.ac.il,6;6;1,,Reject,0,6,0.0,yes,9/25/19,"Technion, Technion;;Tel Aviv University;Technion, Technion",Program Generation;Structural Language Model;SLM;Generative Model;Code Generation,27;-1;30;27,-1;-1;188;-1,m;m,NAN,NAN,n,3
4399,ICLR,2020,Hierarchical Disentangle Network for Object Representation Learning,Shishi Qiao;Ruiping Wang;Shiguang Shan;Xilin Chen,qiaoshishi14@mails.ucas.ac.cn;wangruiping@ict.ac.cn;sgshan@ict.ac.cn;xlchen@ict.ac.cn,8;1;1;6,,Reject,0,5,0.0,yes,9/25/19,"Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",,30;30;30;30,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
4400,ICLR,2020,Improved Training Techniques for Online Neural Machine Translation,Maha Elbayad;Laurent Besacier;Jakob Verbeek,maha.elbayad@inria.fr;laurent.besacier@univ-grenoble-alpes.fr;jakob.verbeek@inria.fr,3;3;6,,Reject,0,3,0.0,yes,9/25/19,INRIA;University of Grenoble-Alpes;INRIA,Deep learning;natural language processing;Machine translation,-1;-1;-1,-1;-1;-1,f;m,europe,gr,n,8;3
4401,ICLR,2020,Removing the Representation Error of GAN Image Priors Using the Deep Decoder,Max Daniels;Reinhard Heckel;Paul Hand,daniels.g@husky.neu.edu;rh43@rice.edu;p.hand@northeastern.edu,1;3;3,,Reject,0,3,0.0,yes,9/25/19,Northeastern University;Rice University;Northeastern University,deep decoder;deep image prior;GAN;inverse problems,16;92;16,906;105;906,m;m,usa,usa,n,5
4402,ICLR,2020,Learning a Behavioral Repertoire from Demonstrations,Niels Justesen;Miguel Gonz√°lez Duque;Daniel Cabarcas Jaramillo;Jean-Baptiste Mouret;Sebastian Risi,noju@itu.edu;migonzalez@unal.edu.co;dcarbarc@unal.edu.co;jean-baptiste.mouret@inria.fr;sebr@itu.dk,1;3;3,,Reject,0,0,0.0,yes,9/25/19,"ITU of Punjab Lahore, Pakistan;Universidad Nacional de Colombia;Universidad Nacional de Colombia;INRIA;IT University of Copenhagen",Behavioral Repertoires;Imitation Learning;Deep Learning;Adaptation;StarCraft 2,-1;-1;-1;-1;168,-1;-1;-1;-1;101,m;m,europe,dk,n,
4403,ICLR,2020,One-Shot Neural Architecture Search via Compressive Sensing,Minsu Cho;Mohammadreza Soltani;Chinmay Hegde,chomd90@iastate.edu;mohammadreza.soltani@duke.edu;chinmay@iastate.edu,1;3;3,,Reject,0,4,0.0,yes,9/25/19,Iowa State University;Duke University;Iowa State University,deep learning;autoML;neural architecture search;image classification;language modeling,194;46;194,399;20;399,m;m,usa,usa,y,6
4404,ICLR,2020,Deep Audio Prior,Yapeng Tian;Chenliang Xu;Dingzeyu Li,yapengtian@rochester.edu;chenliang.xu@rochester.edu;dinli@adobe.com,3;6;6,,Reject,0,5,0.0,yes,9/25/19,University of Rochester;University of Rochester;Adobe Systems,deep audio prior;blind sound separation;deep learning;audio representation,102;102;-1,173;173;-1,m;m,NAN,NAN,n,
4405,ICLR,2020,XD: Cross-lingual Knowledge Distillation for Polyglot Sentence Embeddings,Maksym Del;Mark Fishel,max.del.edu@gmail.com;fishel@ut.ee,1;6;6;3,,Reject,1,4,0.0,yes,9/25/19,University of Tartu;University of Tartu,cross-lingual transfer;sentence embeddings;polyglot language models;knowledge distillation;natural language inference;embedding alignment;embedding mapping,-1;316,-1;319,m;m,europe,uk,n,3
4406,ICLR,2020,Graph Neural Networks for Soft Semi-Supervised Learning on Hypergraphs,Naganand Yadati;Tingran Gao;Shahab Asoodeh;Partha Talukdar;Anand Louis,y.naganand@gmail.com;trg17@uchicago.edu;shahab@seas.harvard.edu;ppt@iisc.ac.in;anandl@iisc.ac.in,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Indian Institute of Science;University of Chicago;Harvard University;Indian Institute of Science;Indian Institute of Science,Graph Neural Networks;Soft Semi-supervised Learning;Hypergraphs,-1;51;52;-1;-1,-1;9;7;301;301,m;m,NAN,NAN,y,1;10
4407,ICLR,2020,Self-Supervised State-Control through Intrinsic Mutual Information Rewards,Rui Zhao;Volker Tresp;Wei Xu,zhaorui.in.germany@gmail.com;volker.tresp@siemens.com;wei.xu@horizon.ai,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Siemens AG;Siemens Corporate Research;Horizon Robotics,Intrinsic Reward;Deep Reinforcement Learning;Skill Discovery;Mutual Information;Self-Supervised Learning;Unsupervised Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4408,ICLR,2020,A Generative Model for Molecular Distance Geometry,Gregor N. C. Simm;Jos√© Miguel Hern√°ndez-Lobato,gncsimm@gmail.com;jmh233@cam.ac.uk,6;3;6,,Reject,1,8,0.0,yes,9/25/19,University of Cambridge;University of Cambridge,graph neural networks;variational autoencoders;distance geometry;molecular conformation,-1;79,-1;3,m;m,europe,uk,n,10;5
4409,ICLR,2020,Multigrid Neural Memory,Tri Huynh;Michael Maire;Matthew R. Walter,trihuynh@uchicago.edu;mmaire@uchicago.edu;mwalter@ttic.edu,3;6;3,,Reject,0,5,1.0,yes,9/25/19,University of Chicago;University of Chicago;Toyota Technological Institute at Chicago,multigrid architecture;memory network;convolutional neural network,51;51;-1,9;9;-1,m;m,NAN,NAN,n,
4410,ICLR,2020,Neural Design of Contests and All-Pay Auctions using Multi-Agent Simulation,Thomas Anthony;Ian Gemp;Janos Kramar;Tom Eccles;Andrea Tacchetti;Yoram Bachrach,twa@google.com;imgemp@google.com;janosk@google.com;eccles@google.com;atacchet@google.com;yorambac@gmail.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Auctions;Mechanism Design;Multi-Agent;Fictitious Play,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4411,ICLR,2020,Geometry-aware Generation of Adversarial and Cooperative Point Clouds,Yuxin Wen;Jiehong Lin;Ke Chen;Kui Jia,wen.yuxin@mail.scut.edu.cn;lin.jiehong@mail.scut.edu.cn;chenk@scut.edu.cn;kuijia@scut.edu.cn,3;3;8,,Reject,0,3,0.0,yes,9/25/19,South China University of Technology;South China University of Technology;South China University of Technology;South China University of Technology,Adversarial attack;Point cloud classification,-1;-1;-1;-1,501;501;501;501,m;m,NAN,NAN,n,7;4
4412,ICLR,2020,Point Process Flows,Nazanin Mehrasa;Ruizhi Deng;Mohamed Osama Ahmed;Bo Chang;Jiawei He;Thibaut Durand;Marcus Brubaker;Greg Mori,nmehrasa@sfu.ca;ruizhid@sfu.ca;mohamed.o.ahmed@borealisai.com;bchang@stat.ubc.ca;jha203@sfu.ca;thibaut.p.durand@borealisai.com;marcus.brubaker@borealisai.com;mori@cs.sfu.ca,6;3;3,,Reject,0,7,0.0,yes,9/25/19,Simon Fraser University;Simon Fraser University;Borealis AI;University of British Columbia;Simon Fraser University;Borealis AI;Borealis AI;Simon Fraser University,Temporal Point Process;Intensity-free Point Process,52;52;-1;64;52;-1;-1;52,272;272;-1;34;272;-1;-1;272,f;m,canada,ca,y,
4413,ICLR,2020,Learning Effective Exploration Strategies For Contextual Bandits,Amr Sharaf;Hal Daum√© III,amr@cs.umd.edu;hal@umiacs.umd.edu,1;1;3,,Reject,0,5,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park",meta-learning;contextual bandits;imitation learning,12;12,91;91,m;m,usa,usa,y,6
4414,ICLR,2020,From English to Foreign Languages: Transferring Pre-trained Language Models,Ke Tran,ketranmanh@gmail.com,3;6;3,,Reject,0,2,1.0,yes,9/25/19,Amazon,pretrained language model;zero-shot transfer;parsing;natural language inference,-1,-1,m;m,NAN,NAN,n,6;3
4415,ICLR,2020,Leveraging Adversarial Examples to Obtain Robust Second-Order Representations,Mohit Prabhushankar;Gukyeong Kwon;Dogancan Temel;Ghassan AlRegib,mohit.p@gatech.edu;gukyeong.kwon@gatech.edu;cantemel@gatech.edu;alregib@gatech.edu,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Second-order representation;adversarial examples;robustness;gradients,13;13;13;13,38;38;38;38,m;m,usa,usa,n,4
4416,ICLR,2020,Multi-Agent Hierarchical Reinforcement Learning for Humanoid Navigation,Glen Berseth;Brandon haworth;Seonghyeon Moon;Mubbasir Kapadia;Petros Faloutsos,gberseth@gmail.com;m.brandon.haworth@gmail.com;sm2062@cs.rutgers.edu;mubbasir.kapadia@gmail.com;pfaloutsos@gmail.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;;Rutgers University;;York University,Multi-Agent Reinforcement Learning;Reinforcement Learning;Hierarchical Reinforcement Learning,-1;-1;30;-1;-1,13;-1;-1;-1;-1,m;m,asia,in,n,
4417,ICLR,2020,SemanticAdv: Generating Adversarial Examples via Attribute-Conditional Image Editing,Haonan Qiu;Chaowei Xiao;Lei Yang;Xinchen Yan;HongLak Lee;Bo Li,haonanqiu@link.cuhk.edu.cn;xiaocw@umich.edu;yl016@ie.cuhk.edu.hk;xcyan@umich.edu;honglak@eecs.umich.edu;lxbosky@gmail.com,3;6;6,,Reject,1,8,0.0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen;University of Michigan;The Chinese University of Hong Kong;University of Michigan;University of Michigan;University of California Berkeley",adversarial examples;semantic attack,46;7;316;7;7;-1,35;21;35;21;21;13,m;f,usa,usa,n,2;4
4418,ICLR,2020,Semantic Pruning for Single Class Interpretability,Kamila Abdiyeva;Martin Lukac;Kanat Alimanov,kabdiyeva@nu.edu.kz;martin.lukac@nu.edu.kz;kanat.alimanov@nu.edu.kz,3;3;1,,Reject,0,5,0.0,yes,9/25/19,Australian National University;Australian National University;Australian National University,deep learning;semantic pruning;filter correlation,102;102;102,50;50;50,f;m,australasia,au,n,2
4419,ICLR,2020,Dual Graph Representation Learning,Huiling Zhu;Xin Luo;Hankz Hankui Zhuo,zhuhling6@mail.sysu.edu.cn;luo35@mail2.sysu.edu.cn;zhuohank@mail.sysu.edu.cn,3;3;1,,Reject,0,0,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1,299;299;299,m;m,NAN,NAN,n,8;10
4420,ICLR,2020,Semi-Implicit Back Propagation,Ren Liu;Xiaoqun Zhang,liur0810@sjtu.edu.cn;xqzhang@sjtu.edu.cn,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Optimization;Neural Network;Proximal mapping;Back propagation;Implicit,30;30,157;157,u;f,asia,cn,n,8;9
4421,ICLR,2020,The Effect of Neural Net Architecture on Gradient Confusion & Training Performance,Karthik A. Sankararaman;Soham De;Zheng Xu;W. Ronny Huang;Tom Goldstein,karthikabinavs@gmail.com;sohamde@google.com;xuzh@cs.umd.edu;wrhuang@cs.umd.edu;tomg@cs.umd.edu,8;1;3,,Reject,0,6,0.0,yes,9/25/19,"Facebook;Google;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",neural network architecture;speed of training;layer width;network depth,-1;-1;12;12;12,-1;-1;91;91;91,m;m,usa,usa,y,
4422,ICLR,2020,Frequency Analysis for Graph Convolution Network,Hoang NT;Takanori Maehara,hoang.nguyen.rh@riken.jp;takanori.maehara@riken.jp,6;1;6,,Reject,0,7,0.0,yes,9/25/19,RIKEN;RIKEN,graph signal processing;frequency analysis;graph convolution neural network;simplified convolution network;semi-supervised vertex classification,-1;-1,-1;-1,m;m,NAN,NAN,y,1;10;4
4423,ICLR,2020,A SPIKING SEQUENTIAL MODEL: RECURRENT LEAKY INTEGRATE-AND-FIRE,Daiheng Gao;Hongwei Wang;Hehui Zhang;Meng Wang;Zhenzhi Wu,samuel.gao023@gmail.com;hongwei.wang@lynxi.com;zhh@bupt.edu.cn;wangmeng_wm@bupt.edu.cn;zhenzhi.wu@lynxi.com,3;1;1,,Reject,0,0,0.0,yes,9/25/19,"Alibaba Group;Lynxi technologies Co., Ltd.;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Lynxi technologies Co., Ltd.",spiking neural network;RNN;spiking mode;brain-inspired;text summarization;DVS,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4424,ICLR,2020,Expected Tight Bounds for Robust Deep Neural Network Training,Salman Alsubaihi;Adel Bibi;Modar Alfadly;Abdullah Hamdi;Bernard Ghanem,salman.subaihi@kaust.edu.sa;adel.bibi@kaust.edu.sa;modar.alfadly@kaust.edu.sa;abdullah.hamdi@kaust.edu.sa;bernard.ghanem@kaust.edu.sa,3;3;3,,Reject,1,6,0.0,yes,9/25/19,KAUST;KAUST;KAUST;KAUST;KAUST,network robustness;network verification;interval bound propagation,102;102;102;102;102,-1;-1;-1;-1;-1,m;m,europe,gr,y,1;4
4425,ICLR,2020,Neural Operator Search,Wei Li;Shaogang Gong;Xiatian Zhu,w.li@qmul.ac.uk;s.gong@qmul.ac.uk;eddy.zhuxt@gmail.com,6;3;3,,Reject,0,6,0.0,yes,9/25/19,Queen Mary University London;Queen Mary University London;University of Surrey,deep learning;autoML;neural architecture search;image classification;attention learning;dynamic convolution,-1;-1;168,-1;-1;260,m;m,europe,uk,n,8
4426,ICLR,2020,Behavior-Guided Reinforcement Learning,Aldo Pacchiano;Jack Parker-Holder;Yunhao Tang;Anna Choromanska;Krzysztof Choromanski;Michael I. Jordan,pacchiano@berkeley.edu;jh3764@columbia.edu;yt2541@columbia.edu;achoroma@gmail.com;kchoro@google.com;jordan@cs.berkeley.edu,1;3;6,,Reject,0,6,0.0,yes,9/25/19,University of California Berkeley;Columbia University;Columbia University;New York University;Google;University of California Berkeley,Reinforcement Learning;Optimal Transport;Evolution Strategies,-1;24;24;22;-1;-1,13;16;16;29;-1;13,m;m,usa,usa,y,
4427,ICLR,2020,"Semi-supervised semantic segmentation needs strong, high-dimensional perturbations",Geoff French;Timo Aila;Samuli Laine;Michal Mackiewicz;Graham Finlayson,g.french@uea.ac.uk;taila@nvidia.com;slaine@nvidia.com;m.mackiewicz@uea.ac.uk;g.finlayson@uea.ac.uk,3;3;3,,Reject,0,5,0.0,yes,9/25/19,University of East Anglia;NVIDIA;NVIDIA;University of East Anglia;University of East Anglia,computer vision;semantic segmentation;semi-supervised;consistency regularisation,-1;-1;-1;-1;-1,191;-1;-1;191;191,m;m,NAN,NAN,n,2
4428,ICLR,2020,Interpretations are useful: penalizing explanations to align neural networks with prior knowledge,Laura Rieger;Chandan Singh;W. James Murdoch;Bin Yu,lauri@dtu.dk;c_singh@berkeley.edu;jmurdoch@berkeley.edu;binyu@berkeley.edu,6;3;3,,Reject,2,5,0.0,yes,9/25/19,Technical University of Denmark;University of California Berkeley;University of California Berkeley;University of California Berkeley,explainability;deep learning;interpretability;computer vision,-1;-1;-1;-1,182;13;13;13,f;f,usa,usa,n,
4429,ICLR,2020,Axial Attention in Multidimensional Transformers,Jonathan Ho;Nal Kalchbrenner;Dirk Weissenborn;Tim Salimans,jonathanho@google.com;nalk@google.com;diwe@google.com;salimans@google.com,1;6;1;3,,Reject,0,6,0.0,yes,9/25/19,Google;Google;Google;Google,self-attention;transformer;images;videos,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;1
4430,ICLR,2020,Adversarial Robustness as a Prior for Learned Representations,Logan Engstrom;Andrew Ilyas;Shibani Santurkar;Dimitris Tsipras;Brandon Tran;Aleksander Madry,engstrom@mit.edu;ailyas@mit.edu;shibani@mit.edu;tsipras@mit.edu;btran115@mit.edu;madry@mit.edu,3;3;6,,Reject,0,12,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial robustness;adversarial examples;robust optimization;representation learning;feature visualization,5;5;5;5;5;5,5;5;5;5;5;5,m;m,usa,usa,n,4
4431,ICLR,2020,Equivariant neural networks and equivarification,Erkao Bao;Linqi Song,baoerkao@gmail.com;linqi.song@cityu.edu.hk,6;3;3;3,,Reject,0,6,0.0,yes,9/25/19,Simons Center for Geometry and Physics;The Hong Kong Polytechnic University,equivariant;invariant;neural network;equivarification,-1;118,-1;171,m;m,asia,hk,y,
4432,ICLR,2020,Do recent advancements in model-based deep reinforcement learning really improve data efficiency?,Kacper Piotr Kielak,k.kielak@bham.ac.uk,3;3;3,,Reject,1,4,0.0,yes,9/25/19,Birmingham University,deep learning;reinforcement learning;data efficiency;DQN;Rainbow;SimPLe,-1,-1,m,NAN,NAN,n,
4433,ICLR,2020,Efficient meta reinforcement learning via meta goal generation,Haotian Fu;Hongyao Tang;Jianye Hao,haotianfu@tju.edu.cn;bluecontra@tju.edu.cn;jianye.hao@tju.edu.cn,1;1;3,,Reject,0,3,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University,,39;39;39,107;107;107,u;u,asia,cn,n,6
4434,ICLR,2020,The Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions,Ahmed M. Alaa;Mihaela van der Schaar,a7med3laa@hotmail.com;mihaelaucla@gmail.com,3;6;3;6,,Reject,0,7,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",,-1;-1,-1;-1,m;f,asia,in,y,11;1
4435,ICLR,2020,Generative Adversarial Nets for Multiple Text Corpora,Diego Klabjan;Baiyang Wang,d-klabjan@northwestern.edu;baiyang@u.northwestern.edu,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Northwestern University;Northwestern University,GAN;NLP;embeddings,46;46,22;22,m;u,usa,usa,y,3;5;4
4436,ICLR,2020,Learning Similarity Metrics for Numerical Simulations,Georg Kohl;Kiwon Um;Nils Thuerey,georg.kohl@tum.de;kiwon.um@tum.de;nils.thuerey@tum.de,6;3;8,,Reject,0,4,0.0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,metric learning;CNNs;PDEs;numerical simulation;perceptual evaluation;physics simulation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
4437,ICLR,2020,Universal Adversarial Attack Using Very Few Test Examples,Amit Deshpande;Sandesh Kamath;K V Subrahmanyam,amitdesh@microsoft.com;ksandeshk@cmi.ac.in;kv@cmi.ac.in,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Microsoft;Chennai Mathematical Institute;Chennai Mathematical Institute,universal;adversarial;SVD,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;4
4438,ICLR,2020,Improved Generalization Bound of Permutation Invariant Deep Neural Networks,Akiyoshi Sannai;Masaaki Imaizumi,akiyoshi.sannai@riken.jp;imaizumi@ism.ac.jp,1;6;3,,Reject,0,8,0.0,yes,9/25/19,"RIKEN;The Institute of Statistical Mathematics, Japan",Deep Neural Network;Invariance;Symmetry;Group;Generalization,-1;-1,-1;-1,m;m,NAN,NAN,y,1;10
4439,ICLR,2020,Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates,Yang Liu;Hongyi Guo,yangliu@ucsc.edu;guohongyi@sjtu.edu.cn,3;3;8,,Reject,0,11,0.0,yes,9/25/19,University of Southern California;Shanghai Jiao Tong University,learning with noisy labels;empirical risk minimization;peer loss,36;30,62;157,m;m,asia,cn,y,
4440,ICLR,2020,Mode Connectivity and Sparse Neural Networks,Jonathan Frankle;Gintare Karolina Dziugaite;Daniel M. Roy;Michael Carbin,jfrankle@csail.mit.edu;karolina.dziugaite@gmail.com;droy@utstat.toronto.edu;mcarbin@csail.mit.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Massachusetts Institute of Technology;ServiceNow;University of Toronto;Massachusetts Institute of Technology,sparsity;mode connectivity;lottery ticket;optimization landscape,5;-1;18;5,5;-1;18;5,m;m,usa,usa,n,
4441,ICLR,2020,Generating valid Euclidean distance matrices,Moritz Hoffmann;Frank Noe,moritz.hoffmann@fu-berlin.de;frank.noe@fu-berlin.de,8;3;8,,Reject,0,3,0.0,yes,9/25/19,Freie Universit√§t Berlin;Freie Universit√§t Berlin,euclidean distance matrices;wgan;point clouds;molecular structures,316;316,-1;-1,m;m,europe,de,n,5
4442,ICLR,2020,GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended Animation,Jiawei Zhang;Lin Meng,jiawei@ifmlab.org;lin@ifmlab.org,6;3;3,,Reject,0,7,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Florida State University,Graph Neural Networks;Node Classification;Representation Learning,-1;-1,299;-1,m;m,asia,in,y,1;10
4443,ICLR,2020,Deep Spike Decoder (DSD),Emrah Adamey;Tarin Ziyaee;Nishanth Alapati;Jun Ye,emrah@ctrl-labs.com;tarin@ctrl-labs.com;nishanth@ctrl-labs.com;jun@ctrl-labs.com,1;1,,Reject,0,1,0.0,yes,9/25/19,Ctrl-labs;Ctrl-labs;Ctrl-labs;Ctrl-labs,self-supervised;deep learning;spike sorting;EMG;sEMG;autoencoder;inductive bias,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5
4444,ICLR,2020,Efficient High-Dimensional Data Representation Learning via Semi-Stochastic Block Coordinate Descent Methods,Bingkun Wei;Yangyang Li;Fanhua Shang;Yuanyuan Liu;Hongying Liu;Shengmei Shen,bkwei028@gmail.com;1615401247li@gmail.com;fhshang@xidian.edu.cn;yyliu@xidian.edu.cn;hyliu@xidian.edu.cn;jane.shen@pensees.ai,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Xidian University;;Xidian University;Xidian University;Xidian University;Xidian University,Sparse learning;Hard thresholding;High-dimensional regression,-1;-1;-1;-1;-1;-1,-1;-1;919;919;919;-1,m;f,asia,in,y,8;2
4445,ICLR,2020,Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs,Zeyuan Chen;Shaoliang Nie;Tianfu Wu;Christopher G. Healey,zchen23@ncsu.edu;snie@ncsu.edu;tianfu_wu@ncsu.edu;healey@ncsu.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Face Completion;GANs;Conditional Image Synthesis;Interpretability;Frequency-Oriented Attention,-1;-1;-1;-1,299;299;299;299,m;m,NAN,NAN,n,8;5;4
4446,ICLR,2020,Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?,Ofir Nachum;Haoran Tang;Xingyu Lu;Shixiang Gu;Honglak Lee;Sergey Levine,ofirnachum@google.com;hrtang.alex@berkeley.edu;xingyulu0701@berkeley.edu;shanegu@google.com;honglak@google.com;svlevine@eecs.berkeley.edu,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;University of California Berkeley;University of California Berkeley;Google;Google;University of California Berkeley,rl;hierarchy;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;13;13;-1;-1;13,m;m,usa,usa,n,
4447,ICLR,2020,Improving Exploration of Deep Reinforcement Learning using Planning for Policy Search,Jakob J. Hollenstein;Erwan Renaudo;Justus Piater,jakob.hollenstein@uibk.ac.at;erwan.renaudo@uibk.ac.at;justus.piater@uibk.ac.at,3;1;1,,Reject,0,3,0.0,yes,9/25/19,University of Innsbruck;University of Innsbruck;University of Innsbruck,reinforcement learning;kinodynamic planning;policy search,-1;-1;-1,415;415;415,m;m,NAN,NAN,n,
4448,ICLR,2020,"Improved Training Speed, Accuracy, and Data Utilization via Loss Function Optimization",Santiago Gonzalez;Risto Miikkulainen,slgonzalez@utexas.edu;risto@cs.utexas.edu,3;3;1,,Reject,0,0,0.0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin",metalearning;evolutionary computation;loss functions;optimization;genetic programming,-1;-1,-1;-1,m;m,usa,usa,n,
4449,ICLR,2020,Knowledge Hypergraphs: Prediction Beyond Binary Relations,Bahare Fatemi;Perouz Taslakian;David Vazquez;David Poole,bfatemi@cs.ubc.ca;perouz@elementai.com;dvazquez@elementai.com;poole@cs.ubc.ca,3;6;1,,Reject,0,5,0.0,yes,9/25/19,University of British Columbia;Element AI;Element AI;University of British Columbia,knowledge graphs;knowledge hypergraphs;knowledge hypergraph completion,64;-1;-1;64,34;-1;-1;34,f;m,canada,ca,y,10
4450,ICLR,2020,FR-GAN: Fair and Robust Training,Yuji Roh;Kangwook Lee;Gyeong Jo Hwang;Steven Euijong Whang;Changho Suh,rohyj113@gmail.com;kangwook.lee@wisc.edu;hkj4276@kaist.ac.kr;swhang@kaist.ac.kr;chsuh@kaist.ac.kr,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;University of Southern California;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,generative adversarial networks;model fairness;model robustness,-1;36;-1;-1;-1,110;62;110;110;110,f;m,NAN,NAN,y,7;5;4
4451,ICLR,2020,Unsupervised Intuitive Physics from Past Experiences,Sebastien Ehrhardt;Aron Monszpart;Niloy Mitra;Andrea Vedaldi,hyenal@robots.ox.ac.uk;aron@nianticlabs.com;n.mitra@cs.ucl.ac.uk;vedaldi@robots.ox.ac.uk,3;3;3,,Reject,0,7,0.0,yes,9/25/19,University of Oxford;Niantic Inc.;University College London;University of Oxford,Intuitive physics;Deep learning,46;-1;52;46,1;-1;-1;1,m;m,europe,uk,n,6
4452,ICLR,2020,Continual Learning with Delayed Feedback,THEIVENDIRAM PRANAVAN;TERENCE SIM,pranavan@u.nus.edu;tsim@comp.nus.edu.sg,1;1;1,,Reject,0,0,0.0,yes,9/25/19,National University of Singapore;National University of Singapore,,17;17,25;25,m;m,asia,sg,n,
4453,ICLR,2020,Adapting to Label Shift with Bias-Corrected Calibration,Avanti Shrikumar;Amr M. Alexandari;Anshul Kundaje,avanti.shrikumar@gmail.com;amr.alexandari@gmail.com;anshul@kundaje.net,6;1;3,,Reject,0,3,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University,calibration;label shift;domain adaptation;temperature scaling;em;bbse,-1;5;-1,-1;4;-1,f;m,asia,in,y,
4454,ICLR,2020,On the Unintended Social Bias of Training Language Generation Models with News Articles,Omar U. Florez,omar.florez@aggiemail.usu.edu,1;3;1,,Reject,0,0,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY,Fair AI;latent representations;sequence to sequence,-1,299,m,NAN,NAN,n,3;7
4455,ICLR,2020,Attacking Graph Convolutional Networks via Rewiring,Yao Ma;Suhang Wang;Tyler Derr;Lingfei Wu;Jiliang Tang,mayao4@msu.edu;szw494@psu.edu;derrtyle@msu.edu;wuli@us.ibm.com;tangjili@msu.edu,6;3;6;3,,Reject,0,5,0.0,yes,9/25/19,Michigan State University;Pennsylvania State University;Michigan State University;International Business Machines;Michigan State University,Graph Neural Networks;Rewiring;Adversarial Attacks,102;43;102;-1;102,84;-1;84;-1;84,m;m,usa,usa,n,10;4
4456,ICLR,2020,Modeling Fake News in Social Networks with Deep Multi-Agent Reinforcement Learning,Christoph Aymanns;Matthias Weber;Co-Pierre Georg;Jakob Foerster,christoph.aymanns@gmail.com;matthias.weber@unisg.ch;cogeorg@gmail.com;jakobfoerster@gmail.com,3;1;1,,Reject,0,9,0.0,yes,9/25/19,University of St Gallen;University of St. Gallen;;University of Toronto,deep multi-agent reinforcement learning;fake news;social networks;information aggregation,-1;-1;-1;-1,435;435;-1;-1,m;m,asia,in,n,4
4457,ICLR,2020,Group-Connected Multilayer Perceptron Networks,Mohammad Kachuee;Sajad Darabi;Shayan Fazeli;Majid Sarrafzadeh,mkachuee@ucla.edu;sajad.darabi@cs.ucla.edu;shayan@cs.ucla.edu;majid@cs.ucla.edu,3;3;3,,Reject,0,5,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",,-1;-1;-1;-1,17;17;17;17,m;m,usa,usa,n,10;7
4458,ICLR,2020,Neural ODEs for Image Segmentation with Level Sets,Rafael Valle;Fitsum Reda;Mohammad Shoeybi;Patrick Legresley;Andrew Tao;Bryan Catanzaro,rafaelvalle@nvidia.com;freda@nvidia.com;mshoeybi@nvidia.com;plegresley@nvidia.com;atao@nvidia.com;bcatanzaro@nvidia.com,3;1;3,,Reject,1,0,0.0,yes,9/25/19,NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA,neural odes;level sets;image segmentation,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2
4459,ICLR,2020,Knowledge Transfer via Student-Teacher Collaboration,Tianxiao Gao;Ruiqin Xiong;Zhenhua Liu;Siwei ma;Feng Wu;Tiejun Huang;Wen Gao,gtx@pku.edu.cn;rqxiong@pku.edu.cn;liu-zh@pku.edu.cn;swma@pku.edu.cn;fengwu@ustc.edu.cn;tjhuang@pku.edu.cn;wgao@pku.edu.cn,6;8;3,,Reject,1,4,0.0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;University of Science and Technology of China;Peking University;Peking University,Network Compression and Acceleration;Knowledge Transfer;Student-Teacher Collaboration;Deep Learning.,14;14;14;14;-1;14;14,24;24;24;24;80;24;24,m;m,asia,cn,n,
4460,ICLR,2020,VIMPNN: A physics informed neural network for estimating potential energies of out-of-equilibrium systems,Jay Morgan;Adeline Paiement;Christian Klinke,j.p.morgan@swansea.ac.uk;adeline.paiement@univ-tln.fr;christian.klinke@uni-rostock.de,6;6;6,,Reject,0,3,0.0,yes,9/25/19,Swansea University;CNRS university Toulon;Rostock University,neural network;chemical energy estimation;density functional theory,-1;-1;-1,266;-1;-1,m;m,usa,usa,n,1
4461,ICLR,2020,AutoLR: A Method for Automatic Tuning of Learning Rate,Nipun Kwatra;V Thejas;Nikhil Iyer;Ramachandran Ramjee;Muthian Sivathanu,nkwatra@microsoft.com;thejasvenkatesh97@gmail.com;t-niiyer@microsoft.com;ramjee@microsoft.com;muthian@microsoft.com,6;3,,Reject,0,12,0.0,yes,9/25/19,"Microsoft;BITS Pilani, BITS Pilani;Microsoft;Microsoft;Microsoft",Automatic Learning Rate;Deep Learning;Generalization;Stochastic Optimization,-1;445;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;1
4462,ICLR,2020,Continuous Convolutional Neural Network forNonuniform Time Series,Hui Shi;Yang Zhang;Hao Wu;Shiyu Chang;Kaizhi Qian;Mark Hasegawa-Johnson;Jishen Zhao,hshi@ucsd.edu;yang.zhang2@ibm.com;haowu11@illinois.edu;kqian3@illinois.edu;jhasegaw@illinois.edu;jzhao@ucsd.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"University of California, San Diego;International Business Machines;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of California, San Diego",,-1;-1;-1;-1;-1;-1,31;-1;-1;-1;-1;31,f;f,usa,usa,y,1
4463,ICLR,2020,Test-Time Training for Out-of-Distribution Generalization,Yu Sun;Xiaolong Wang;Zhuang Liu;John Miller;Alexei A. Efros;Moritz Hardt,yusun@berkeley.edu;dragonwxl123@gmail.com;zhuangl@berkeley.edu;miller_john@berkeley.edu;efros@eecs.berkeley.edu;hardt@berkeley.edu,6;6;6,,Reject,1,3,0.0,yes,9/25/19,"University of California Berkeley;University of California, San Diego;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley",out-of-distribution;distribution shifts,-1;-1;-1;-1;-1;-1,13;31;13;13;13;13,m;m,usa,usa,y,
4464,ICLR,2020,MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING,Prudencio Tossou;Basile Dura;Daniel Cohen;Mario Marchand;Fran√ßois Laviolette;Alexandre Lacoste,tossouprudencio@gmail.com;basile@invivoai.ca;daniel@invivoai.ca;mario.marchand@ift.ulaval.ca;francois.laviolette@ift.ulaval.ca;allac@elementai.com,6;3;8;3;6,,Reject,3,8,0.0,yes,9/25/19,InVivo AI;;;Laval university;Laval university;Element AI,few-shot learning;few-shot regression;deep kernel learning;biological assay modelling;drug discovery,-1;-1;-1;-1;-1;-1,-1;-1;-1;272;272;-1,m;m,NAN,NAN,n,6
4465,ICLR,2020,Hybrid Weight Representation: A Quantization Method Represented with Ternary and Sparse-Large Weights,Jinbae Park;Sung-Ho Bae,qkrwlsqo94@gmail.com;shbae@khu.ac.kr,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Kyung Hee University;Kyung Hee University,quantized neural networks;centralized quantization;hybrid weight representation;weighted ridge;ternary weight,-1;445,-1;319,m;m,asia,kr,n,
4466,ICLR,2020,Amharic Negation Handling,Girma Neshir,girma1978@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,0,Negation Handling Algorithm;Amharic Sentiment Analysis;Amharic Sentiment lexicon;char level;word level ngram;machine learning;hybrid,,,m,NAN,NAN,n,
4467,ICLR,2020,Stiffness: A New Perspective on Generalization in Neural Networks,Stanislav Fort;Pawe≈Ç Krzysztof Nowak;Stanis≈Çaw Jastrzebski;Srini Narayanan,stanislav.fort@gmail.com;powalnow@google.com;staszek.jastrzebski@gmail.com;srinin@google.com,3;3;6,,Reject,0,11,0.0,yes,9/25/19,Stanford University;Google;Jagiellonian University;Google,stiffness;gradient alignment;critical scale,5;-1;-1;-1,4;-1;610;-1,m;m,NAN,NAN,n,1
4468,ICLR,2020,POP-Norm: A Theoretically Justified and More Accelerated Normalization Approach,Hanyang Peng;Shiqi Yu,philoso_phy0922@163.com;shiqi.yu@gmai.com,3;3;1,,Reject,0,0,0.0,yes,9/25/19,163;Gmai,Batch Normalization;Optimization;Accelerate Training,-1;-1,-1;-1,u;m,NAN,NAN,y,9
4469,ICLR,2020,A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models,Elman Mansimov;Alex Wang;Kyunghyun Cho,elman.mansimov@gmail.com;wangalexc@gmail.com;kyunghyun.cho@nyu.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,New York University;;New York University,nlp;sequence modeling;natural language generation;machine translation;BERT;Sesame Street,-1;-1;22,-1;-1;29,m;m,usa,usa,n,8;3
4470,ICLR,2020,Pushing the bounds of dropout,G√°bor Melis;Charles Blundell;Tom√°≈° Koƒçisk√Ω;Karl Moritz Hermann;Chris Dyer;Phil Blunsom,melisgl@google.com;cblundell@google.com;tkocisky@google.com;kmh@google.com;cdyer@google.com;pblunsom@google.com,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google,dropout;language,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;1
4471,ICLR,2020,CRNet: Image Super-Resolution Using A Convolutional Sparse Coding  Inspired Network,Menglei Zhang;Zhou Liu;Jingwei He;Lei Yu,zmlhome@whu.edu.cn;liuzhou@whu.edu.cn;jingwei_he@whu.edu.cn;ly.wd@whu.edu.cn,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Wuhan University;Wuhan University;Wuhan University;Wuhan University,Convolutional sparse coding;LISTA;image super-resolution,194;194;194;194,354;354;354;354,m;m,europe,uk,n,8;2
4472,ICLR,2020,Hierarchical Graph Matching Networks for Deep Graph Similarity Learning,Xiang Ling;Lingfei Wu;Saizhuo Wang;Tengfei Ma;Fangli Xu;Chunming Wu;Shouling Ji,lingxiang@zju.edu.cn;lwu@email.wm.edu;szwang@zju.edu.cn;tengfei.ma1@ibm.com;lili@yixue.us;wuchunming@zju.edu.cn;sji@zju.edu.cn,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Zhejiang University;College of William and Mary;Zhejiang University;International Business Machines;Squirrel AI Learning;Zhejiang University;Zhejiang University,Graph Neural Network;Graph Matching Network;Graph Similarity Learning,39;194;39;-1;-1;39;39,107;-1;107;-1;-1;107;107,m;m,asia,cn,n,10
4473,ICLR,2020,RATE-DISTORTION OPTIMIZATION GUIDED AUTOENCODER FOR GENERATIVE APPROACH,Keizo Kato;Jing Zhou;Akira Nakagawa,kato.keizo@jp.fujitsu.com;zhoujing@cn.fujitsu.com;anaka@jp.fujitsu.com,1;3;3,,Reject,0,6,0.0,yes,9/25/19,Fujitsu Laboratories Ltd.;Fujitsu Laboratories Ltd.;Fujitsu Laboratories Ltd.,Autoencoder;Rate-distortion optimization;Generative model;Unsupervised learning;Jacobian,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5
4474,ICLR,2020,Learning to Recognize the Unseen Visual Predicates,Defa Zhu;Si Liu;Wentao Jiang;Guanbin Li;Tianyi Wu;Guodong Guo,zhudefa@iie.ac.cn;liusi@buaa.edu.cn;jiangwentao@buaa.edu.cn;liguanbin@mail.sysu.edu.cn;wutianyi01@baidu.com;guoguodong01@baidu.com,6;3;6,,Reject,0,5,0.0,yes,9/25/19,"Institute of information engineering, CAS;Beihang University;Beihang University;SUN YAT-SEN UNIVERSITY;Baidu;Baidu",Visual Relationship Detection;Scene Graph Generation;Knowledge;Zero-shot Learning,-1;102;102;-1;-1;-1,-1;594;594;299;-1;-1,m;m,NAN,NAN,n,6
4475,ICLR,2020,Self-supervised Training of Proposal-based Segmentation via Background Prediction,Isinsu Katircioglu;Helge Rhodin;Victor Constantin;J√∂rg Sp√∂rri;Mathieu Salzmann;Pascal Fua,isinsu.katircioglu@epfl.ch;rhodin@cs.ubc.ca;victor.constantin@epfl.ch;joerg.spoerri@balgrist.ch;mathieu.salzmann@epfl.ch;pascal.fua@epfl.ch,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;University of British Columbia;Swiss Federal Institute of Technology Lausanne;University of Zurich;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;64;-1;118;-1;-1,-1;34;-1;90;-1;-1,f;m,NAN,NAN,n,2
4476,ICLR,2020,Constrained Markov Decision Processes via Backward Value Functions,Harsh Satija;Philip Amortila;Joelle Pineau,harsh.satija@mail.mcgill.ca;philip.amortila@mail.mcgill.ca;jpineau@cs.mcgill.ca,3;8;3,,Reject,0,3,0.0,yes,9/25/19,McGill University;McGill University;McGill University,Reinforcement Learning;Constrained Markov Decision Processes;Deep Reinforcement Learning,102;102;102,42;42;42,m;f,canada,ca,y,
4477,ICLR,2020,Deep Interaction Processes for Time-Evolving Graphs,xiaofu chang;jianfeng wen;xuqin liu;yanming fang;le song;yuan qi,xiaofu.cxf@antfin.com;sylvain.wjf@antfin.com;xuqin.lxq@antfin.com;yanming.fym@mybank.cn;le.song@antfin.com;yuan.qi@antfin.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Antfin;Antfin;Antfin;;Antfin;Antfin,deep temporal point process;multiple time resolutions;dynamic continuous time-evolving graph;anti-fraud detection,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;u,NAN,NAN,n,8;10
4478,ICLR,2020,On summarized validation curves and generalization,Mohammad Hashir;Yoshua Bengio;Joseph Paul Cohen,mohammad.hashir.khan@umontreal.ca;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,3;3;1,,Reject,0,5,0.0,yes,9/25/19,University of Montreal;Mila;Stanford University,model selection;deep learning;early stopping;validation curves,118;143;5,85;336;4,m;m,usa,usa,n,1
4479,ICLR,2020,The Visual Task Adaptation Benchmark,Xiaohua Zhai;Joan Puigcerver;Alexander Kolesnikov;Pierre Ruyssen;Carlos Riquelme;Mario Lucic;Josip Djolonga;Andre Susano Pinto;Maxim Neumann;Alexey Dosovitskiy;Lucas Beyer;Olivier Bachem;Michael Tschannen;Marcin Michalski;Olivier Bousquet;Sylvain Gelly;Neil Houlsby,xzhai@google.com;jpuigcerver@google.com;alexander.kolesnikoff@gmail.com;pierrot@google.com;rikel@googel.com;lucic@google.com;josipd@google.com;andresp@google.com;maximneumann@google.com;adosovitskiy@gmail.com;lbeyer@google.com;bachem@google.com;tschannen@google.com;michalski@google.com;obousquet@google.com;sylvaingelly@google.com;neilhoulsby@google.com,8;3;6,,Reject,0,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google Inc;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,representation learning;self-supervised learning;benchmark;large-scale study,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
4480,ICLR,2020,SPREAD  DIVERGENCE,Mingtian Zhang;David Barber;Thomas Bird;Peter Hayes;Raza Habib,mingtian.zhang.17@ucl.ac.uk;david.barber@ucl.ac.uk;thomas.bird.17@ucl.ac.uk;peter.hayes.15@ucl.ac.uk;r.habib@cs.ucl.ac.uk,3;1;3,,Reject,0,3,0.0,yes,9/25/19,University College London;University College London;University College London;University College London;University College London,divergence minimization;generative model;variational inference,52;52;52;52;52,-1;-1;-1;-1;-1,m;m,europe,uk,n,5
4481,ICLR,2020,Adversarially learned anomaly detection for time series data,Alexander Geiger;Alfredo Cuesta-Infante;Kalyan Veeramachaneni,geigera@mit.edu;alfredo.cuesta@urjc.es;kalyanv@mit.edu,1;3;1,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Universidad Rey Juan Carlos;Massachusetts Institute of Technology,anomaly detection;gan,5;316;5,5;-1;5,m;m,usa,usa,n,5;4
4482,ICLR,2020,CEB Improves Model Robustness,Ian Fischer;Alex A. Alemi,iansf@google.com;alemi@google.com,6;3;3,,Reject,0,5,0.0,yes,9/25/19,Google;Google,Information Theory;Adversarial Robustness,-1;-1,-1;-1,m;m,NAN,NAN,n,4
4483,ICLR,2020,Mildly Overparametrized Neural Nets can Memorize Training Data Efficiently,Rong Ge;Runzhe Wang;Haoyu Zhao,rongge@cs.duke.edu;wrz16@mails.tsinghua.edu.cn;zhaohy16@mails.tsinghua.edu.cn,1;3;8,,Reject,0,3,0.0,yes,9/25/19,"Duke University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",nonconvex optimization;optimization landscape;overparametrization,46;4;4,20;23;23,m;m,NAN,NAN,y,
4484,ICLR,2020,Data-Driven Approach to Encoding and Decoding 3-D Crystal Structures,Jordan Hoffmann;Louis Maestrati;Yoshihide Sawada;Jian Tang;Jean Michel Sellier;Yoshua Bengio,jhoffmann@g.harvard.edu;maestratilouis@gmail.com;sawada.yoshihide@jp.panasonic.com;jian.tang@hec.ca;jeanmichel.sellier@mila.quebec;yoshua.bengio@mila.quebec,8;1;3,,Reject,0,6,0.0,yes,9/25/19,Harvard University;;Panasonic Corporation;HEC Montreal;Mila;Mila,,52;-1;-1;-1;143;143,7;-1;-1;-1;336;336,m;m,NAN,NAN,n,5
4485,ICLR,2020,Mean Field Models for Neural Networks in Teacher-student Setting,Lexing Ying;Yuandong Tian,lexing@stanford.edu;yuandong@fb.com,3;3;1,,Reject,0,5,0.0,yes,9/25/19,Stanford University;Facebook,mean field model;optimal transport;ResNet,5;-1,4;-1,m;m,NAN,NAN,y,
4486,ICLR,2020,A novel Bayesian estimation-based word embedding model for sentiment analysis,Jingyao Tang;Yun Xue;Ziwen Wang;Haoliang Zhao,manderous@foxmail.com;995438712@qq.com;773473833@qq.com;1044012786@qq.com,6;1;3,,Reject,0,3,0.0,yes,9/25/19,Foxmail;;;South China Normal University,sentiment analysis;sentiment word embeddings;maximum likelihood estimation;Bayesian estimation,-1;-1;-1;-1,-1;-1;-1;-1,u;u,asia,in,n,11;3
4487,ICLR,2020,Improving Gradient Estimation in Evolutionary Strategies With Past Descent Directions,Florian Meier;Asier Mujika;Marcelo Gauy;Angelika Steger,meierflo@inf.ethz.ch;asierm@inf.ethz.ch;marcelo.matheus@inf.ethz.ch;steger@inf.ethz.ch,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Evolutionary Strategies;Surrogate Gradients,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,y,1
4488,ICLR,2020,Few-Shot Few-Shot Learning and the role of Spatial Attention,Yann Lifchitz;Yannis Avrithis;Sylvaine Picard,yann.lifchitz@safrangroup.com;yannis@avrithis.net;sylvaine.picard@safrangroup.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Safran;INRIA;Safran,few-shot learning;spatial attention,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,6;8
4489,ICLR,2020,Generative Cleaning Networks with Quantized Nonlinear Transform  for  Deep Neural Network Defense,Jianhe Yuan;Zhihai He,yuanjia@missouri.edu;hezhi@missouri.edu,1;8;3,,Reject,0,10,0.0,yes,9/25/19,"University of Missouri, Columbia;University of Missouri, Columbia",Adversarial Defense;Adversarial Attack,316;316,424;424,u;m,NAN,NAN,n,5;4
4490,ICLR,2020,Clustered Reinforcement Learning,Xiao Ma;Shen-Yi Zhao;Zhao-Heng Yin;Wu-Jun Li,max@lamda.nju.edu.cn;zhaosy@lamda.nju.edu.cn;zhaohengyin@gmail.com;liwujun@nju.edu.cn,3;6;3,,Reject,0,0,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;;Zhejiang University,,39;39;-1;39,107;107;-1;107,u;u,asia,cn,n,
4491,ICLR,2020,Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders,Yang Li;Julien Amelot;Xin Zhou;Samy Bengio;Si Si,liyang@google.com;jamelot@google.com;zhouxin@google.com;bengio@google.com;sisidaisy@google.com,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google,Transformer;decoder;user interface;layout design,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;10
4492,ICLR,2020,Visual Imitation with Reinforcement Learning using Recurrent Siamese Networks,Glen Berseth;Christopher Pal,gberseth@gmail.com;christopher.pal@polymtl.ca,8;3;3,,Reject,0,6,0.0,yes,9/28/20,University of California Berkeley;Polytechnique Montreal,imitation learning;reinforcement learning;imitation from video,-1;316,13;-1,m;m,canada,ca,n,
4493,ICLR,2020,Deep Graph Translation,Xiaojie Guo;Lingfei Wu;Liang Zhao,xguo7@gmu.edu;wuli@us.ibm.com;lzhao9@gmu.edu,3;3;8,,Reject,0,5,0.0,yes,9/25/19,George Mason University;International Business Machines;George Mason University,Graph translation;graph generation;deep neural network,85;-1;85,282;-1;282,m;m,usa,usa,n,10;5;4
4494,ICLR,2020,GAN-based Gaussian Mixture Model Responsibility Learning,Wanming Huang;Shuai Jiang;Xuan Liang;Ian Oppermann;Richard Yi Da Xu,wanming.huang@student.uts.edu.au;shuai.jiang-1@student.uts.edu.au;xuan.liang@student.uts.edu.au;ianopper@outlook.com;yida.xu@uts.edu.au,1;3;1,,Reject,0,0,0.0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,Generative Adversarial Networks,73;73;73;73;73,193;193;193;193;193,u;m,australasia,au,n,5;4
4495,ICLR,2020,CROSS-DOMAIN CASCADED DEEP TRANSLATION,Oren Katzir;Dani Lischinski;Daniel Cohen-Or,orenkatzir@mail.tau.ac.il;cohenor@gmail.com;danix3d@gmail.com,6;6;3,,Reject,0,5,0.0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Hebrew University of Jerusalem,computer vision;image translation;generative adversarial networks,30;30;85,188;188;216,m;m,europe,il,n,4
4496,ICLR,2020,Mean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks,Soufiane Hayou;Arnaud Doucet;Judith Rousseau,soufiane.hayou@stats.ox.ac.uk;doucet@stats.ox.ac.uk;judith.rousseau@stats.ox.ac.uk,6;6;3,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,,46;46;46,1;1;1,m;f,europe,uk,y,
4497,ICLR,2020,NORML: Nodal Optimization for Recurrent Meta-Learning,David van Niekerk,davidpetrus94@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,0,meta-learning;learning to learn;few-shot classification;memory-based optimization,,,m,NAN,NAN,n,6
4498,ICLR,2020,Programmable Neural Network Trojan for Pre-trained Feature Extractor,Yu Ji;Zinxin Liu;Xing Hu;Peiqi Wang;Youhui Zhang,jiy15@mails.tsinghua.edu.cn;liuzixin18@mails.tsinghua.edu.cn;xinghu@ucsb.edu;wpq14@mails.tsinghua.edu.cn;zyh02@tsinghua.edu.cn,3;1;6,,Reject,0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;UC Santa Barbara;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Neural Network;Trojan;Security,4;4;-1;4;4,23;23;-1;23;23,m;m,NAN,NAN,n,4
4499,ICLR,2020,Contextual Inverse Reinforcement Learning,Philip Korsunsky;Stav Belogolovsky;Tom Zahavy;Chen Tessler;Shie Mannor,philip.korsunsky@gmail.com;stav.belo@gmail.com;tomzahavy@gmail.com;chen.tessler@gmail.com;shie@ee.technion.ac.il,6;3;6,,Reject,0,13,0.0,yes,9/25/19,"Technion, Technion;;DeepMind;Technion, Technion;Technion, Technion",Contextual MDP;Inverse Reinforcement Learning;Reinforcement Learning;Mirror Descent,-1;-1;-1;27;27,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
4500,ICLR,2020,Convolutional Bipartite Attractor Networks,Michael L. Iuzzolino;Yoram Singer;Michael C. Mozer,michael.iuzzolino@colorado.edu;yoram.singer@gmail.com;mcmozer@google.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"University of Colorado, Boulder;;Google",attractor network;recurrent network;energy function;convolutional network;image completion;super-resolution,59;-1;-1,123;-1;-1,m;m,NAN,NAN,n,5
4501,ICLR,2020,DeepSimplex: Reinforcement Learning of Pivot Rules Improves the Efficiency of Simplex Algorithm in Solving Linear Programming Problems,Varun Suriyanarayana;Onur Tavaslioglu;Ankit B. Patel;Andrew J. Schaefer,vs478@cornell.edu;onur.tavaslioglu@bcm.edu;ankit.patel@bcm.edu;andrew.schaefer@rice.edu,1;3;1,,Reject,0,4,0.0,yes,9/25/19,Cornell University;Baylor College of Medicine;Baylor College of Medicine;Rice University,Simplex Algorithm;Pivoting Rules;Reinforcement Learning;Combinatorial Optimization;Supervised Learning;Travelling Salesman Problem,7;-1;-1;92,19;-1;-1;105,m;m,australasia,au,n,
4502,ICLR,2020,Temporal-difference learning for nonlinear value function approximation in the lazy training regime,Andrea Agazzi;Jianfeng Lu,agazzi@math.duke.edu;jianfeng@math.duke.edu,6;6;3;3,,Reject,0,5,0.0,yes,9/25/19,Duke University;Duke University,deep reinforcement learning;function approximation;temporal-difference;lazy training,46;46,20;20,m;m,europe,se,y,1
4503,ICLR,2020,Off-policy Multi-step Q-learning,Gabriel Kalweit;Maria Huegle;Joschka Boedecker,kalweitg@cs.uni-freiburg.de;hueglem@informatik.uni-freiburg.de;jboedeck@informatik.uni-freiburg.de,1;3;3,,Reject,0,14,0.0,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Multi-step Learning;Off-policy Learning;Q-learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;10
4504,ICLR,2020,Towards Interpretable Molecular Graph Representation Learning,Emmanuel Noutahi;Dominique Beani;Julien Horwood;Prudencio Tossou,emmanuel@invivoai.com;dominique@invivoai.com;julien@invivoai.com;prudencio@invivoai.com,6;1;6,,Reject,0,5,0.0,yes,9/25/19,InVivo AI;InVivo AI;InVivo AI;InVivo AI,molecular graphs;graph pooling;hierarchical;GNN;Laplacian;drug discovery,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,10
4505,ICLR,2020,Effective Mechanism to Mitigate Injuries During NFL Plays ,Arraamuthan Arulanantham;Ahamed Arshad Ahamed Anzar;Gowshalini Rajalingam;Krusanth Ingran;Prasanna S. Haddela,anzanfas@gmail.com;arulanantham.arraamuthan@my.sliit.lk;it16113800@my.sliit.lk;krusanth7@gmail.com;prasanna@sliit.lk,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Srilanka Institute of information Technology;Srilanka Institute of information Technology;Srilanka Institute of information Technology;;Srilanka Institute of information Technology,Concussion;American football;Predictive modelling;Injuries;NFL Plays;Optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;u,NAN,NAN,n,1
4506,ICLR,2020,Ecological Reinforcement Learning,John D. Co-Reyes;Suvansh Sanjeev;Glen Berseth;Abhishek Gupta;Sergey Levine,jcoreyes@eecs.berkeley.edu;suvansh@berkeley.edu;gberseth@gmail.com;abhigupta@berkeley.edu;svlevine@eecs.berkeley.edu,1;3;3,,Reject,0,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,non-episodic;environment analysis;reward shaping;curriculum learning,-1;-1;-1;-1;-1,13;13;13;13;13,m;m,usa,usa,n,
4507,ICLR,2020,CP-GAN: Towards a Better Global Landscape of GANs,Ruoyu Sun;Tiantian Fang;Alex Schwing,ruoyus@illinois.edu;tf6@illinois.edu;aschwing@illinois.edu,8;3;3,,Reject,0,5,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",GAN;global landscape;non-convex optimization;min-max optimization;dynamics,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y,1;5;9
4508,ICLR,2020,Learning Semantically Meaningful Representations Through Embodiment,Viviane Clay;Peter K√∂nig;Kai-Uwe K√ºhnberger;Gordon Pipa,vkakerbeck@uos.de;pkoenig@uos.de;kkuehnbe@uos.de;gpipa@uos.de,3;1;3,,Reject,0,6,1.0,yes,9/25/19,University of Osnabr√ºck;University of Osnabr√ºck;University of Osnabr√ºck;University of Osnabr√ºck,reinforcement learning;deep learning;embodied;embodiment;embodied cognition;representation learning;representations;sparse coding,316;316;316;316,-1;-1;-1;-1,f;m,europe,de,n,
4509,ICLR,2020,Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks in Molecular Graph Analysis,Katsuhiko Ishiguro;Shin-ichi Maeda;Masanori Koyama,k.ishiguro.jp@ieee.org;ichi@preferred.jp;masomatics@preferred.jp,3;6;6,,Reject,0,4,0.0,yes,9/25/19,"Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Graph Neural Networks;molecular graph analysis;supernode;auxiliary module,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
4510,ICLR,2020,End-To-End Input Selection for Deep Neural Networks,Stefan Oehmcke;Fabian Gieseke,stefan.oehmcke@gmail.com;fabian.gieseke@di.ku.dk,3;3;3,,Reject,0,4,0.0,yes,9/25/19,University of Copenhagen;University of Copenhagen,Deep Learning;Input Selection;Gumbel Softmax Trick;Remote Sensing;Feature Selection,92;92,101;101,m;m,europe,dk,n,
4511,ICLR,2020,Learning Curves for Deep Neural Networks: A field theory perspective,Omry Cohen;Or Malka;Zohar Ringel,omrycohen.38.talpiot@gmail.com;or.malka@mail.huji.ac.il;zohar.ringel@mail.huji.ac.il,1;3;8,,Reject,0,4,0.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Gaussian Processes;Neural Tangent Kernel;Learning Curves;Field Theory;Statistical Mechanics;Generalization;Deep neural networks,-1;85;85,-1;216;216,m;m,europe,il,n,11;1
4512,ICLR,2020,Regional based query in graph active learning,Abel Roy;Louzoun Yoram,royabel10@gmail.com;louzouy@math.biu.ac.il,1;6,,Reject,0,2,0.0,yes,9/25/19,Bar Ilan University;Bar Ilan University,Active Learning;Graph Convolution Networks;Graph;Graph Topology,-1;102,-1;513,m;m,europe,il,n,10
4513,ICLR,2020,Analysis and Interpretation of Deep CNN Representations as Perceptual Quality Features,Taimoor Tariq;Munchurl Kim,taimoor.tariq@kaist.ac.kr;mkimee@kaist.ac.kr,3;6;3;3,,Reject,0,7,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,interpretation;perceptual quality;perceptual loss;image-restoration.,-1;-1,110;110,m;m,NAN,NAN,n,2;1
4514,ICLR,2020,Dynamical System Embedding for Efficient Intrinsically Motivated Artificial Agents,Ruihan Zhao;Stas Tiomkin;Pieter Abbeel,philipzhao@berkeley.edu;stas@berkeley.edu;pabbeel@cs.berkeley.edu,1;3;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,intrinsic motivation;empowerment;latent representation;encoder,-1;-1;-1,13;13;13,m;m,usa,usa,n,1
4515,ICLR,2020,Siamese Attention Networks,Hongyang Gao;Yaochen Xie;Shuiwang Ji,hongyang.gao@tamu.edu;ethanycx@tamu.edu;sji@tamu.edu,6;6;3,,Reject,0,2,0.0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M,,46;46;46,177;177;177,m;m,NAN,NAN,n,8
4516,ICLR,2020,Network Pruning for Low-Rank Binary Index,Dongsoo Lee;Se Jung Kwon;Byeongwook Kim;Parichay Kapoor;Gu-Yeon Wei,dslee3@gmail.com;mogndrewk@gmail.com;quddnr145@gmail.com;kparichay@gmail.com;gywei@g.harvard.edu,3;1;3,,Reject,0,0,0.0,yes,9/25/19,Samsung;Samsung;Samsung;;Harvard University,Pruning;Model compression;Index compression;low-rank;binary matrix decomposition,-1;-1;-1;-1;52,-1;-1;-1;-1;7,m;m,usa,usa,n,
4517,ICLR,2020,Attention Privileged Reinforcement Learning for Domain Transfer,Sasha Salter;Dushyant Rao;Markus Wulfmeier;Raia Hadsell;Ingmar Posner,sasha@robots.ox.ac.uk;dushyantr@google.com;mwulfmeier@google.com;raia@google.com;ingmar@robots.ox.ac.uk,3;1;3,,Reject,0,11,0.0,yes,9/25/19,University of Oxford;Google;Google;Google;University of Oxford,sim-to-real;domain randomisation;attention;transfer learning;reinforcement learning,46;-1;-1;-1;46,1;-1;-1;-1;1,m;m,europe,uk,n,8
4518,ICLR,2020,Wildly Unsupervised Domain Adaptation and Its Powerful and Efficient Solution,Feng Liu;Jie Lu;Bo Han;Gang Niu;Guangquan Zhang;Masashi Sugiyama,feng.liu-2@student.uts.edu.au;jie.lu@uts.edu.au;bo.han@riken.jp;gang.niu@riken.jp;guangquan.zhang@uts.edu.au;sugi@k.u-tokyo.ac.jp,1;8;3,,Reject,0,9,0.0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;RIKEN;RIKEN;University of Technology Sydney;The University of Tokyo,,73;73;-1;-1;73;64,193;193;-1;-1;193;36,m;m,NAN,NAN,y,
4519,ICLR,2020,"Deep RL for Blood Glucose Control: Lessons, Challenges, and Opportunities",Ian Fox;Joyce Lee;Rodica Busui;Jenna Wiens,ifox@umich.edu;joyclee@med.umich.edu;rpbusui@umich.edu;wiensj@umich.edu,3;3,,Reject,0,4,0.0,yes,9/25/19,University of Michigan;University of Michigan;University of Michigan;University of Michigan,Deep Reinforcement Learning;Diabetes;Artificial Pancreas;Control,7;7;7;7,21;21;21;21,m;f,usa,usa,n,
4520,ICLR,2020,Learning Likelihoods with Conditional Normalizing Flows ,Christina Winkler;Daniel Worrall;Emiel Hoogeboom;Max Welling,christina.winkler.94@gmail.com;d.e.worrall@uva.nl;e.hoogeboom@uva.nl;m.welling@uva.nl,3;6;6,,Reject,2,5,0.0,yes,9/25/19,Technical University Munich;University of Amsterdam;University of Amsterdam;University of Amsterdam,Likelihood learning;conditional normalizing flows;generative modelling;super-resolution;vessel segmentation,-1;143;143;143,-1;62;62;62,f;m,europe,nl,n,2;5
4521,ICLR,2020,Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality,Eric Nalisnick;Akihiro Matsukawa;Yee Whye Teh;Balaji Lakshminarayanan,e.nalisnick@eng.cam.ac.uk;matsukaw@deshaw.com;ywteh@google.com;balajiln@google.com,3;6;6,,Reject,0,6,0.0,yes,9/25/19,University of Cambridge;D. E. Shaw & Co.;Google;Google,Deep generative models;out-of-distribution detection;safety,79;-1;-1;-1,3;-1;-1;-1,m;m,NAN,NAN,y,5
4522,ICLR,2020,A Mechanism of Implicit Regularization in Deep Learning,Masayoshi Kubo;Genki Sugiura;Kenta Shinzato;Momose Oyama,kubo@i.kyoto-u.ac.jp;sugiura.genki.42n@st.kyoto-u.ac.jp;shinzato.kenta.82r@st.kyoto-u.ac.jp;oyama.momose.75c@st.kyoto-u.ac.jp,3;3;1,,Reject,0,10,0.0,yes,9/25/19,Kyoto University;Kyoto University;Kyoto University;Kyoto University,Implicit Regularization;Generalization;Deep Neural Network;Low Complexity,168;168;168;168,65;65;65;65,m;f,europe,fi,y,1
4523,ICLR,2020,Scaleable input gradient regularization for adversarial robustness,Chris Finlay;Adam M Oberman,christopher.finlay@mail.mcgill.ca;adam.oberman@mcgill.ca,3;6;3,,Reject,0,12,0.0,yes,9/25/19,McGill University;McGill University,adversarial robustness;gradient regularization;robust certification;robustness bounds,102;102,42;42,m;m,canada,ca,y,4
4524,ICLR,2020,Weakly-Supervised Trajectory Segmentation for Learning Reusable Skills,Parsa Mahmoudieh;Trevor Darrell;Deepak Pathak,parsa.m@berkeley.edu;trevor@eecs.berkeley.edu;pathak@berkeley.edu,3;3;1,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,skills;demonstration;agent;sub-task;primitives;robot learning;manipulation,-1;-1;-1,13;13;13,m;m,usa,usa,n,6;2;1
4525,ICLR,2020,Compositional Visual Generation with Energy Based Models,Yilun Du;Shuang Li;Igor Mordatch,yilundu@mit.edu;lishuang@mit.edu;mordatch@google.com,3;6;6,,Reject,0,10,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Google,Compositional Generation;Energy Based Model;Compositionality;Generative Models,5;5;-1,5;5;-1,m;m,NAN,NAN,n,1
4526,ICLR,2020,Fourier networks for uncertainty estimates and out-of-distribution detection,Hartmut Maennel;Alexandru »öifrea,hartmutm@google.com;tifreaa@student.ethz.ch,3;6;1,,Reject,2,3,0.0,yes,9/25/19,Google;Swiss Federal Institute of Technology,Fourier network;out-of-distribution detection;large initialization;uncertainty;ensembles,-1;-1,-1;-1,m;m,NAN,NAN,y,1
4527,ICLR,2020,Finding Winning Tickets with Limited (or No) Supervision,Mathilde Caron;Ari Morcos;Piotr Bojanowski;Julien Mairal;Armand Joulin,mathilde@fb.com;arimorcos@gmail.com;bojanowski@fb.com;julien.mairal@inria.fr;ajoulin@fb.com,1;3;6;3,,Reject,0,5,0.0,yes,9/25/19,Facebook;Facebook;Facebook;INRIA;Facebook,Lottery Tickets Hypothesis;Self-Supervised Learning;Deep Learning;Image Recognition,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
4528,ICLR,2020,DASGrad: Double Adaptive Stochastic Gradient,Kin Gutierrez;Cristian Challu;Jin Li;Artur Dubrawski,kdgutier@cs.cmu.edu;cchallu@cs.cmu.edu;jinl2@cs.cmu.edu;awd@cs.cmu.edu,6;3;3,,Reject,0,2,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,stochastic convex optimization;adaptivity;online learning;transfer learning,1;1;1;1,27;27;27;27,m;m,usa,usa,y,6;9
4529,ICLR,2020,Physics-Aware Flow Data Completion Using Neural Inpainting,Sebastien Foucher;Jingwei Tang;Vinicius da Costa de Azevedo;Byungsoo Kim;Markus Gross;Barbara Solenthaler,sfoucher@ethz.ch;jingwei.tang@inf.ethz.ch;vinicius.azevedo@inf.ethz.ch;kimby@inf.ethz.ch;grossm@inf.ethz.ch;solenthaler@inf.ethz.ch,1;3;3,,Reject,0,0,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,neural inpainting;fluid dynamics;flow data completion;physics-aware network,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,
4530,ICLR,2020,Towards Modular Algorithm Induction,Daniel A. Abolafia;Rishabh Singh;Manzil Zaheer;Charles Sutton,danabo@google.com;rising@google.com;manzilzaheer@google.com;charlessutton@google.com,1;1;1,,Reject,0,1,0.0,yes,9/25/19,Google;Google;Google;Google,algorithm induction;reinforcement learning;program synthesis;modular,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8
4531,ICLR,2020,PROVABLY BENEFITS OF DEEP HIERARCHICAL RL,Zeyu Jia;Simon S. Du;Ruosong Wang;Mengdi Wang;Lin F. Yang,jiazy@pku.edu.cn;ssdu@ias.edu;ruosongw@andrew.cmu.edu;mengdiw@princeton.edu;linyang@ee.ucla.edu,1;3;3,,Reject,0,3,0.0,yes,9/25/19,"Peking University;Institue for Advanced Study, Princeton;Carnegie Mellon University;Princeton University;University of California, Los Angeles",hierarchical model;reinforcement learning;low regret;online learning;tabular reinforcement learning,14;-1;1;30;-1,24;-1;27;6;17,m;m,usa,usa,y,1
4532,ICLR,2020,Effects of Linguistic Labels on Learned Visual Representations in Convolutional Neural Networks: Labels matter!,Seoyoung Ahn;Gregory Zelinsky;Gary Lupyan,seoyoung.ahn@stonybrook.edu;gregory.zelinsky@stonybrook.edu;lupyan@wisc.edu,6;6;6,,Reject,0,6,0.0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;University of Southern California",category learning;visual representation;linguistic labels;human behavior prediction,-1;-1;36,-1;-1;62,f;m,usa,usa,n,
4533,ICLR,2020,What Can Learned Intrinsic Rewards Capture?,Zeyu Zheng;Junhyuk Oh;Matteo Hessel;Zhongwen Xu;Manuel Kroiss;Hado van Hasselt;David Silver;Satinder Singh,zeyu@umich.edu;junhyuk@google.com;mtthss@google.com;zhongwen@google.com;makro@google.com;hado@google.com;davidsilver@google.com;baveja@google.com,6;6;6,,Reject,0,8,0.0,yes,9/25/19,University of Michigan;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;deep reinforcement learning;intrinsic movitation,7;-1;-1;-1;-1;-1;-1;-1,21;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;1
4534,ICLR,2020,QXplore: Q-Learning Exploration by Maximizing Temporal Difference Error,Riley Simmons-Edler;Ben Eisner;Daniel Yang;Anthony Bisulco;Eric Mitchell;Sebastian Seung;Daniel Lee,rileys@cs.princeton.edu;ben.a.eisner@gmail.com;daniel.yang17@gmail.com;arb426@cornell.edu;eric.anthony.mitchell95@gmail.com;sseung@princeton.edu;daniel.d.lee@samsung.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Princeton University;Samsung;;Cornell University;;Princeton University;Samsung,Deep Reinforcement Learning;Exploration,30;-1;-1;7;-1;30;-1,6;-1;-1;19;-1;6;-1,m;m,NAN,NAN,n,4
4535,ICLR,2020,Neural Clustering Processes,Ari Pakman;Yueqi Wang;Catalin Mitelut;JinHyung Lee;Liam Paninski,aripakman@gmail.com;yueqi.wang.pku@gmail.com;mitelutco@gmail.com;jl4303@columbia.edu;liam@stat.columbia.edu,3;6;6,,Reject,0,3,0.0,yes,9/25/19,Columbia University;Google;;Columbia University;Columbia University,amortized inference;probabilistic clustering;mixture models;exchangeability;spike sorting,24;-1;-1;24;24,16;-1;-1;16;16,m;m,usa,usa,n,11;5
4536,ICLR,2020,Pre-training as Batch Meta Reinforcement Learning with tiMe ,Quan Vuong;Shuang Liu;Minghua Liu;Kamil Ciosek;Hao Su;Henrik Iskov Christensen,quan.hovuong@gmail.com;s3liu@eng.ucsd.edu;minghua@ucsd.edu;kamil.ciosek@microsoft.com;haosu@eng.ucsd.edu;hichristensen@ucsd.edu,3;1;3,,Reject,0,10,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;Microsoft;University of California, San Diego;University of California, San Diego",Reinforcement Learning;Deep Reinforcement Learning;Meta Reinforcement Learning;Batch Reinforcement Learning;Transfer Learning,-1;-1;-1;-1;-1;-1,-1;31;31;-1;31;31,u;u,usa,usa,n,1
4537,ICLR,2020,Neural Architecture Search in Embedding Space,chun-ting liu,jimliu741523@gmail.com,1;3;3,,Reject,0,3,0.0,yes,9/25/19,0,neural architecture search;nas;automl,,,m;m,NAN,NAN,n,
4538,ICLR,2020,Multi-Task Learning via Scale Aware Feature Pyramid Networks and Effective Joint Head,Feng Ni,nifeng@pku.edu.cn,3;3,,Reject,0,1,0.0,yes,9/25/19,Peking University,Multi-Task Learning;Object Detection;Instance Segmentation,14,24,m,asia,cn,n,2
4539,ICLR,2020,BANANAS: Bayesian Optimization with Neural Networks for Neural Architecture Search,Colin White;Willie Neiswanger;Yash Savani,crwhite@cs.cmu.edu;willie@cs.cmu.edu;yash@realityengines.ai,3;3;3,,Reject,2,9,3.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,neural architecture search;Bayesian optimization,1;1;1,27;27;27,m;m,usa,usa,n,11
4540,ICLR,2020,Isolating Latent Structure with Cross-population Variational Autoencoders,Joe Davison;Kristen A. Severson;Soumya Ghosh,jddavison@g.harvard.edu;kristen.severson@ibm.com;ghoshso@us.ibm.com,6;3;3,,Reject,0,0,0.0,yes,9/25/19,Harvard University;International Business Machines;International Business Machines,variational autoencoder;latent variable model;probabilistic graphical model;machine learning;deep learning;continual learning,52;-1;-1,7;-1;-1,m;m,NAN,NAN,n,5
4541,ICLR,2020,Stabilizing Off-Policy Reinforcement Learning with Conservative Policy Gradients,Chen Tessler;Nadav Merlis;Shie Mannor,chen.tessler@gmail.com;merlis.nadav@gmail.com;shiemannor@gmail.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion",Deep Reinforcement Learning;Variance Reduction;Policy Gradient,27;27;27,-1;-1;-1,m;m,NAN,NAN,n,10
4542,ICLR,2020,When Covariate-shifted Data Augmentation Increases Test Error And How to Fix It,Sang Michael Xie*;Aditi Raghunathan*;Fanny Yang;John C. Duchi;Percy Liang,xie@cs.stanford.edu;aditir@stanford.edu;fannyang@stanford.edu;jduchi@stanford.edu;pliang@cs.stanford.edu,3;6;3,,Reject,0,5,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,data augmentation;adversarial training;interpolation;overparameterized,5;5;5;5;5,4;4;4;4;4,m;m,usa,usa,y,1;4
4543,ICLR,2020,Learning robust visual representations using data augmentation invariance,Alex Hernandez-Garcia;Peter K√∂nig;Tim C. Kietzmann,alexhg15@gmail.com;pkoenig@uos.de;t.kietzmann@donders.ru.nl,3;6;3,,Reject,0,3,0.0,yes,9/25/19,University of Montreal;University of Osnabr‚àö¬∫ck;Radboud University Nijmegen,deep neural networks;visual cortex;invariance;data augmentation,-1;316;248,-1;-1;128,m;m,NAN,NAN,n,
4544,ICLR,2020,Learning to Generate Grounded Visual Captions without Localization Supervision,Chih-Yao Ma;Yannis Kalantidis;Ghassan AlRegib;Peter Vajda;Marcus Rohrbach;Zsolt Kira,cyma@gatech.edu;ykalant@image.ntua.gr;vajdap@fb.com;alregib@gatech.edu;maroffm@gmail.com;zkira@gatech.edu,3;6;6,,Reject,0,8,0.0,yes,9/25/19,Georgia Institute of Technology;National Technical University of Athens;Facebook;Georgia Institute of Technology;Facebook;Georgia Institute of Technology,image captioning;video captioning;self-supervised learning;visual grounding,13;316;-1;13;-1;13,38;776;-1;38;-1;38,m;m,usa,usa,n,8;3
4545,ICLR,2020,On Empirical Comparisons of Optimizers for Deep Learning,Dami Choi;Christopher J. Shallue;Zachary Nado;Jaehoon Lee;Chris J. Maddison;George E. Dahl,choidami@cs.toronto.edu;shallue@google.com;znado@google.com;jaehlee@google.com;cmaddis@google.com;gdahl@google.com,1;6;6,,Reject,4,19,0.0,yes,9/25/19,University of Toronto;Google;Google;Google;Google;Google,Deep learning;optimization;adaptive gradient methods;Adam;hyperparameter tuning,18;-1;-1;-1;-1;-1,18;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
4546,ICLR,2020,LEARNING DIFFICULT PERCEPTUAL TASKS WITH HODGKIN-HUXLEY NETWORKS,Alan Lockett;Ankit Patel;Paul Pfaffinger,alan.lockett@gmail.com;ankitp@bcm.edu;paulp@bcm.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,IDSIA;Baylor College of Medicine;Baylor College of Medicine,conductance-weighted averaging;neural modeling;normalization methods,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2
4547,ICLR,2020,Adversarial Robustness Against the Union of Multiple Perturbation Models,Pratyush Maini;Eric Wong;Zico Kolter,pratyush.maini@gmail.com;ericwong@cs.cmu.edu;zkolter@cs.cmu.edu,3;6;1,,Reject,2,9,0.0,yes,9/25/19,Indian Institute of Technology Delhi;Carnegie Mellon University;Carnegie Mellon University,adversarial;robustness;multiple perturbation;MNIST;CIFAR10,-1;1;1,-1;27;27,m;m,usa,usa,n,1;4
4548,ICLR,2020,LightPAFF: A Two-Stage Distillation Framework for Pre-training and Fine-tuning,Kaitao Song;Hao Sun;Xu Tan;Tao Qin;Jianfeng Lu;Hongzhi Liu;Tie-Yan Liu,kt.song@njust.edu.cn;sigmeta@pku.edu.cn;xuta@microsoft.com;taoqin@microsoft.com;lujf@njust.edu.cn;liuhz@pku.edu.cn;tyliu@microsoft.com,3;6;6,,Reject,0,4,0.0,yes,9/25/19,Nanjing University of Science and Technology;Peking University;Microsoft;Microsoft;Nanjing University of Science and Technology;Peking University;Microsoft,Knowledge Distillation;Pre-training;Fine-tuning;BERT;GPT-2;MASS,52;14;-1;-1;52;14;-1,144;24;-1;-1;144;24;-1,m;m,NAN,NAN,n,3
4549,ICLR,2020,LocalGAN: Modeling Local Distributions for Adversarial Response Generation,Zhen Xu;Baoxun Wang;Huan Zhang;Kexin Qiu;Deyuan Zhang;Chengjie Sun,xuzhenhit@gmail.com;baoxun.wang@gmail.com;zhanghuan123@pku.edu.cn;kq2131@columbia.edu;dyzhang@sau.edu.cn;cjsun@insun.hit.edu.cn,3;3;1,,Reject,0,8,0.0,yes,9/25/19,Harbin Institute of Technology;Tencent AI Lab;Peking University;Columbia University;Shenyang Aerospace University;Harbin Institute of Technology,neural response generation;adversarial learning;local distribution;energy-based distribution modeling,-1;-1;14;24;-1;168,-1;-1;24;16;-1;424,m;m,asia,cn,y,5;4
4550,ICLR,2020,Partial Simulation for Imitation Learning,Nir Baram;Shie Mannor,nirb@campus.technion.ac.il;shie@ee.technion.ac.il,3;6;1,,Reject,0,3,0.0,yes,9/25/19,"Technion, Technion;Technion, Technion",Reinforcement Learning;Imitation Learning;Behavior Cloning;Partial Simulation,27;27,-1;-1,m;m,NAN,NAN,y,
4551,ICLR,2020,Progressive Upsampling Audio Synthesis via Effective Adversarial Training,Youngwoo Cho;Minwook Chang;Gerard Jounghyun Kim;Jaegul Choo,cyw314@gmail.com;fromme0528@gmail.com;gjkim@korea.ac.kr;jchoo@korea.ac.kr,1;6;3,,Reject,0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;;Korea University;Korea University,audio synthesis;sound effect generation;generative adversarial network;progressive training;raw-waveform,-1;-1;168;168,110;-1;179;179,m;m,asia,kr,n,5
4552,ICLR,2020,A Quality-Diversity Controllable GAN for Text Generation,Xingyu Lou;Kaihe Xu;Zhongliang Li;Tian Xia;Shaojun Wang;Jing Xiao,louxingyu83064256@163.com;xukaihenupt@gmail.com;zlli0520@gmail.com;summerrainet2008@gmail.com;swang.usa@gmail.com;jing.xiaoj@gmail.com,1;1;3,,Reject,0,3,0.0,yes,9/25/19,Pingan P&C insurance;;;;Pingan P&C insurance;Pingan P&C insurance,text generation;GAN;quality-diversity;generalized Jensen-Shannon divergence,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,asia,in,n,3;5;4
4553,ICLR,2020,Unsupervised-Learning of time-varying features,Henrik H√∏eg;Matthias Brix;Oswin Krause,lvt956@alumni.ku.dk;brixmatthias@gmail.com;oswin.krause@di.ku.dk,1;1;3,,Reject,0,4,0.0,yes,9/25/19,University of Copenhagen;;University of Copenhagen,Representation Learning;Variational Autoencoder;Unsupervised Learning;Deep-Learning;Registration,92;-1;92,101;-1;101,m;m,europe,dk,n,5
4554,ICLR,2020,Improving Visual Relation Detection using Depth Maps,Sahand Sharifzadeh;Sina Moayed Baharlou;Max Berrendorf;Rajat Koner;Volker Tresp,sharifzadeh@dbs.ifi.lmu.de;sina.baharlou@gmail.com;berrendorf@dbs.ifi.lmu.de;koner@dbs.ifi.lmu.de;volker.tresp@siemens.com,6;3;3,,Reject,0,8,1.0,yes,9/25/19,Institut f√ºr Informatik;;Institut f√ºr Informatik;Institut f√ºr Informatik;Siemens Corporate Research,Visual Relation Detection;Scene Graph Generation,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4555,ICLR,2020,DeepAGREL: Biologically plausible deep learning via direct reinforcement,Isabella Pozzi;Sander M. Bohte;Pieter R. Roelfsema,pozzi@cwi.nl;s.m.bohte@cwi.nl;p.roelfsema@nin.knaw.nl,6;6;1,,Reject,1,4,0.0,yes,9/25/19,Centrum voor Wiskunde en Informatica;Centrum voor Wiskunde en Informatica; Netherlands Institute for Neuroscience,biologically plausible deep learning;reinforcement learning;feedback gating;image claassification,-1;-1;-1,-1;-1;-1,f;m,asia,in,n,
4556,ICLR,2020,Learn Interpretable Word Embeddings Efficiently with von Mises-Fisher Distribution,Minghong Yao;Liansheng Zhuang;Houqiang Li;Jian Yang;Shafei Wang,mhyao1@mail.ustc.edu.cn;lszhuang@ustc.edu.cn;lihq@ustc.edu.cn;nanwuyaoshi@163.com;rockingsandstorm@163.com,8;1;1,,Reject,0,0,0.0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China;163;163,word embedding;natural language processing,-1;-1;-1;-1;-1,80;80;80;-1;-1,m;f,asia,in,n,3;1
4557,ICLR,2020,Mirror Descent View For Neural Network Quantization,Thalaiyasingam Ajanthan;Kartik Gupta;Philip H. S. Torr;Richard Hartley;Puneet K. Dokania,thalaiyasingam.ajanthan@anu.edu.au;kartik.gupta@anu.edu.au;phst@robots.ox.ac.uk;richard.hartley@anu.edu.au;puneet@robots.ox.ac.uk,3;6;3;8,,Reject,0,4,0.0,yes,9/25/19,Australian National University;Australian National University;University of Oxford;Australian National University;University of Oxford,mirror descent;network quantization;numerical stability,102;102;46;102;46,50;50;1;50;1,m;m,europe,uk,y,
4558,ICLR,2020,Topological Autoencoders,Michael Moor;Max Horn;Bastian Rieck;Karsten Borgwardt,michael.moor@bsse.ethz.ch;max.horn@bsse.ethz.ch;bastian.rieck@bsse.ethz.ch;karsten.borgwardt@bsse.ethz.ch,6;8;3,,Reject,0,4,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Topology;Deep Learning;Autoencoders;Persistent Homology;Representation Learning;Dimensionality Reduction;Topological Machine Learning;Topological Data Analysis,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,
4559,ICLR,2020,Utilizing Edge Features in Graph Neural Networks via Variational Information Maximization,Pengfei Chen;Weiwen Liu;Chang-Yu Hsieh;Guangyong Chen;Pheng Ann Heng,chenpf.cuhk@gmail.com;wwliu@cse.cuhk.edu.hk;kimhsieh@tencent.com;gycchen@tencent.com;pheng@cse.cuhk.edu.hk,3;6;8;3,,Reject,0,4,0.0,yes,9/25/19,"The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Tencent AI Lab;Tencent AI Lab;Department of Computer Science and Engineering, The Chinese University of Hong Kong",Graph Neural Network;Edge Feature;Mutual Information,316;46;-1;-1;46,35;35;-1;-1;35,m;m,NAN,NAN,y,10
4560,ICLR,2020,Redundancy-Free Computation Graphs for Graph Neural Networks,Zhihao Jia;Sina Lin;Rex Ying;Jiaxuan You;Jure Leskovec;Alex Aiken.,zhihao@cs.stanford.edu;silin@microsoft.com;rexying@stanford.edu;jiaxuan@stanford.edu;jure@cs.stanford.edu;aiken@cs.stanford.edu,3;6;6,,Reject,1,5,0.0,yes,9/25/19,Stanford University;Microsoft;Stanford University;Stanford University;Stanford University;Stanford University,Graph Neural Networks;Runtime Performance,5;-1;5;5;5;5,4;-1;4;4;4;4,m;m,usa,usa,y,10
4561,ICLR,2020,Long History Short-Term Memory for Long-Term Video Prediction,Wonmin Byeon;Jan Kautz,wonmin.byeon@gmail.com;jkautz@nvidia.com,3;3;3,,Reject,0,17,0.0,yes,9/25/19,NVIDIA;NVIDIA,LSTM;video;long-term prediction,-1;-1,-1;-1,f;m,NAN,NAN,n,4
4562,ICLR,2020,How the Softmax Activation Hinders the Detection of Adversarial and Out-of-Distribution Examples in Neural Networks,Jonathan Aigrain;Marcin Detyniecki,jonathan.aigrain@axa.com;marcin.detyniecki@axa.com,1;1;3,,Reject,0,3,0.0,yes,9/25/19,AXA;AXA,Adversarial examples;out-of-distribution;detection;softmax;logits,-1;-1,-1;-1,m;m,europe,gr,n,4
4563,ICLR,2020,Solving Packing Problems by Conditional Query Learning,Dongda Li;Changwei Ren;Zhaoquan Gu;Yuexuan Wang;Francis Lau,lidongda@gzhu.edu.cn;rcw@zju.edu.cn;zqgu@gzhu.edu.cn;amywang@zju.edu.cn;fcmlau@cs.hku.hk,1;3;6,,Reject,0,3,0.0,yes,9/25/19,"Guangzhou University, China, Tsinghua University;Zhejiang University;Guangzhou University, China, Tsinghua University;Zhejiang University;The University of Hong Kong",Neural Combinatorial Optimization;Reinforcement Learning;Packing Problem,4;39;4;39;92,23;107;23;107;35,m;m,NAN,NAN,n,8
4564,ICLR,2020,Context Based Machine Translation With Recurrent Neural Network For English-Amharic Translation ,Yeabsira Asefa Ashengo;Rosa Tsegaye Aga;Surafel Lemma Abebe,yeabsira.asefa@aait.edu.et;rosatsegaye@gmail.com;surafel.lemma@aait.edu.et,1;1;1,,Reject,0,4,0.0,yes,9/25/19,Addis Ababa Institute of Technology;;Addis Ababa Institute of Technology,Context based machine translation;machine translation;Neural network machine translation;English to Amharic machine translation,-1;-1;-1,-1;-1;-1,u;u,NAN,NAN,n,3
4565,ICLR,2020,"Long-term planning, short-term adjustments",Hamed Khorasgani;Chi Zhang;Chetan Gupta;Susumu Serita,hamed.khorasgani@hal.hitachi.com;chi.zhang@hal.hitachi.com;chetan.gupta@hal.hitachi.com;susumu.serita@hal.hitachi.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;Hitachi Ltd. R&D group,Deep Reinforcement Learning;Control,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4566,ICLR,2020,Boosting Network: Learn by Growing Filters and Layers via SplitLBI,Zuyuan Zhong;Chen Liu;Yanwei Fu;Yuan Yao,zyzhong19@fudan.edu.cn;corwinliu9669@gmail.com;yanweifu@fudan.edu.cn;yuany@ust.hk,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Fudan University;;Fudan University;The Hong Kong University of Science and Technology,,73;-1;73;-1,109;-1;109;47,m;f,NAN,NAN,n,2
4567,ICLR,2020,MULTI-STAGE INFLUENCE FUNCTION,Hongge Chen;Si Si;Yang Li;Ciprian Chelba;Sanjiv Kumar;Duane Boning;Cho-Jui Hsieh,chenhg@mit.edu;sisidaisy@google.com;liyang@google.com;ciprianchelba@google.com;sanjivk@google.com;boning@mtl.mit.edu;chohsieh@cs.ucla.edu,6;3;6,,Reject,0,4,0.0,yes,9/25/19,"Massachusetts Institute of Technology;Google;Google;Google;Google;Massachusetts Institute of Technology;University of California, Los Angeles",influence function;multistage training;pretrained model,5;-1;-1;-1;-1;5;-1,5;-1;-1;-1;-1;5;17,m;m,usa,usa,y,2;3
4568,ICLR,2020,$\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach,Jiaye Teng;Guang-He Lee;Yang Yuan,2016110299@live.sufe.edu.cn;guanghe@csail.mit.edu;yuanyang@tsinghua.edu.cn,6;3;3,,Reject,2,4,0.0,yes,9/25/19,"University of Science and Technology of China;Massachusetts Institute of Technology;Tsinghua University, Tsinghua University",,-1;5;4,80;5;23,m;m,NAN,NAN,y,4
4569,ICLR,2020,Scaling Up Neural Architecture Search with Big Single-Stage Models,Jiahui Yu;Pengchong Jin;Hanxiao Liu;Gabriel Bender;Pieter-Jan Kindermans;Mingxing Tan;Thomas Huang;Xiaodan Song;Quoc Le,jyu79@illinois.edu;pengchong@google.com;hanxiaol@google.com;gbender@google.com;pikinder@google.com;tanmingxing@google.com;t-huang1@illinois.edu;xiaodansong@google.com;qvl@google.com,3;3;6,,Reject,0,3,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;Google;Google;Google;Google;Google;University of Illinois, Urbana Champaign;Google;Google",Single-Stage Neural Architecture Search,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4570,ICLR,2020,CONTRIBUTION OF INTERNAL REFLECTION IN LANGUAGE EMERGENCE WITH AN UNDER-RESTRICTED SITUATION,Kense Todo;Masayuki Yamamura,k_todo@ali.c.titech.ac.jp;my@c.titech.ac.jp,3;3,,Reject,0,3,0.0,yes,9/25/19,Tokyo Institute of Technology;Tokyo Institute of Technology,Language emergence;Conceptual grounding;Reflection;Cognitive bias,168;168,299;299,m;m,asia,jp,n,
4571,ICLR,2020,MIM: Mutual Information Machine,Micha Livne;Kevin Swersky;David J. Fleet,mlivne@cs.toronto.edu;kswersky@google.com;leet@cs.toronto.edu,1;1;6,,Reject,2,5,0.0,yes,9/25/19,University of Toronto;Google;University of Toronto,Mutual Information;Representation Learning;Generative Models;Probability Density Estimator,18;-1;18,18;-1;18,m;m,canada,ca,n,5
4572,ICLR,2020,Variable Complexity in the Univariate and Multivariate Structural Causal Model,Tomer Galanti;Ofir Nabati;Lior Wolf,tomerga2@post.tau.ac.il;ofirnabati@mail.tau.ac.il;wolf@fb.com,6;6;3,,Reject,0,5,0.0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Facebook,,30;30;-1,188;188;-1,m;m,NAN,NAN,n,
4573,ICLR,2020,Copy That! Editing Sequences by Copying Spans,Sheena Panthaplackel;Miltiadis Allamanis;Marc Brockschmidt,spantha@cs.utexas.edu;miallama@microsoft.com;mabrocks@microsoft.com,6;3;6,,Reject,0,6,0.0,yes,9/25/19,"University of Texas, Austin;Microsoft;Microsoft",span copying;sequence generation;editing;code repair,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,3
4574,ICLR,2020,OmniNet: A unified architecture for multi-modal multi-task learning,Subhojeet Pramanik;Priyanka Agrawal;Aman Hussain,subhojeetpramanik@gmail.com;pagrawal.ml@gmail.com;email@amanhussain.com,6;1;3,,Reject,0,6,0.0,yes,9/25/19,International Business Machines;;University of Amsterdam,multimodal;multi-task;transformer;spatio-temporal;attention-networks;neural-network,-1;-1;143,-1;-1;62,m;m,europe,nl,n,3;8;1
4575,ICLR,2020,QGAN: Quantize Generative Adversarial Networks to Extreme low-bits,Peiqi Wang;Yu Ji;Xinfeng Xie;Yongqiang Lyu;Dongsheng Wang;Yuan Xie,wpq14@tsinghua.org.cn;jiy15@mails.tsinghua.edu.cn;xinfeng@ucsb.edu;luyq@tsinghua.edu.cn;wds@mail.tsinghua.edu.cn;yuanxie@ucsb.edu,3;6;3,,Reject,0,3,0.0,yes,9/25/19,"SenseTime Group Limited;Tsinghua University, Tsinghua University;UC Santa Barbara;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;UC Santa Barbara",generative adversarial networks;quantization;extreme low bits,-1;4;-1;4;4;-1,-1;23;-1;23;23;-1,f;m,NAN,NAN,n,5;4
4576,ICLR,2020,Imagine That! Leveraging Emergent Affordances for Tool Synthesis in Reaching Tasks,Yizhe Wu;Sudhanshu Kasewa;Oliver Groth;Sasha Salter;Li Sun;Oiwi Parker Jones;Ingmar Posner,ywu@robots.ox.ac.uk;su@robots.ox.ac.uk;ogroth@robots.ox.ac.uk;sasha@robots.ox.ac.uk;kevin@robots.ox.ac.uk;oiwi.parkerjones@jesus.ox.ac.uk;ingmar@robots.ox.ac.uk,3;1;3,,Reject,0,8,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Affordance Learning;Imagination;Generative Models;Activation Maximisation,46;46;46;46;46;46;46,1;1;1;1;1;1;1,m;m,europe,uk,n,5
4577,ICLR,2020,Enhancing Attention with Explicit Phrasal Alignments,Xuan-Phi Nguyen;Shafiq Joty;Thanh-Tung Nguyen,nxphi47@gmail.com;sjoty@salesforce.com;ng0155ng@e.ntu.edu.sg,6;3;8,,Reject,0,0,0.0,yes,9/25/19,Nanyang Technological University;SalesForce.com;Nanyang Technological University,NMT;Phrasal Attention;Machine Translation;Language Modeling,-1;-1;43,-1;-1;49,m;m,asia,sg,n,8;3
4578,ICLR,2020,A GOODNESS OF FIT MEASURE FOR GENERATIVE NETWORKS,Lorenzo Luzi;Randall Balestriero;Richard Baraniuk,lorenzo.luzi.28@gmail.com;randallbalestriero@gmail.com;richb@rice.edu,3;1;3,,Reject,0,4,0.0,yes,9/25/19,Rice University;Rice University;Rice University,generative adversarial networks;goodness of fit;inception score;empirical approximation error;validation metric;frechet inception score,-1;92;92,-1;105;105,m;m,australasia,au,n,5;4
4579,ICLR,2020,Learning Neural Causal Models from Unknown Interventions,Nan Rosemary Ke;Olexa Bilaniuk;Anirudh Goyal;Stephan Bauer;Hugol Larochelle;Chris Pal;Yoshua Bengio,rosemary.nan.ke@gmail.com;obilaniu@gmail.com;anirudhgoyal9119@gmail.com;stefan.a.bauer@gmail.com;hugolarochelle@google.com;chris.j.pal@gmail.com;yoshua.bengio@mila.quebec,6;8;3,,Reject,0,13,0.0,yes,9/25/19,University of Montreal;;;;Google;Polytechnique Montreal;Mila,deep learning;graphical models;meta learning,-1;-1;-1;-1;-1;316;143,-1;-1;-1;-1;-1;-1;336,f;m,NAN,NAN,n,6;10
4580,ICLR,2020,SLM Lab: A Comprehensive Benchmark and Modular Software Framework for Reproducible Deep Reinforcement Learning,Wah Loon Keng;Laura Graesser;Milan Cvitkovic,kengzwl@gmail.com;lhgraesser@gmail.com;mcvitkov@caltech.edu,3;8;3,,Reject,0,3,0.0,yes,9/25/19,AppLovin;Google;California Institute of Technology,reinforcement learning;machine learning;benchmark;reproducibility;software;framework;implementation issues;parallelization;software platforms,-1;-1;143,-1;-1;2,m;m,usa,usa,n,
4581,ICLR,2020,ADA+: A GENERIC FRAMEWORK WITH MORE ADAPTIVE EXPLICIT ADJUSTMENT FOR LEARNING RATE,Yue Zhao;Xiangsheng Huang;Ludan Kou,oasis.random.time@gmail.com;xiangsheng.huang@ia.ac.cn;2015019051@mail.buct.edu.cn,3;3;1,,Reject,0,0,0.0,yes,9/25/19,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;University of Science and Technology of China",Optimization;Adaptive Methods;Convergence;Convolutional Neural Network,-1;30;-1,-1;-1;80,m;m,NAN,NAN,y,1
4582,ICLR,2020,A‚ãÜMCTS: SEARCH WITH THEORETICAL GUARANTEE USING POLICY AND VALUE FUNCTIONS,Xian Wu;Yuandong Tian;Lexing Ying,xwu20@stanford.edu;yuandong@fb.com;lexing@stanford.edu,1;3;6,,Reject,0,4,0.0,yes,9/25/19,Stanford University;Facebook;Stanford University,tree search;reinforcement learning;value neural network;policy neural network,5;-1;5,4;-1;4,m;m,usa,usa,y,
4583,ICLR,2020,Faster Neural Network Training with Data Echoing,Dami Choi;Alexandre Passos;Christopher J. Shallue;George E. Dahl,choidami@cs.toronto.edu;apassos@google.com;shallue@google.com;gdahl@google.com,6;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Toronto;Google;Google;Google,systems;faster training;large scale,18;-1;-1;-1,18;-1;-1;-1,f;m,NAN,NAN,n,1
4584,ICLR,2020,Sparse Weight Activation Training,Md Aamir Raihan;Tor M. Aamodt,araihan@ece.ubc.ca;aamodt@ece.ubc.ca,3;6;3,,Reject,0,9,0.0,yes,9/25/19,University of British Columbia;University of British Columbia,Sparsity;Training;Acceleration;Pruning;Compression,64;64,34;34,m;m,canada,ca,n,10
4585,ICLR,2020,BOOSTING ENCODER-DECODER CNN FOR INVERSE PROBLEMS,Eunju Cha;Jaeduck Jang;Junho Lee;Eunha Lee;Jong Chul Ye,eunju.cha@kaist.ac.kr;jduck.jang@samsung.com;jh0325.lee@samsung.com;eunhayo.lee@samsung.com;jong.ye@kaist.ac.kr,6;1;3,,Reject,0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Samsung;Samsung;Samsung;Korea Advanced Institute of Science and Technology,Prediction error;Boosting;Encoder-decoder convolutional neural network;Inverse problem,-1;-1;-1;-1;-1,110;-1;-1;-1;110,f;m,NAN,NAN,y,
4586,ICLR,2020,Unsupervised Spatiotemporal Data Inpainting,Yuan Yin;Arthur Pajot;Emmanuel de B√©zenac;Patrick Gallinari,yuan.yin@lip6.fr;arthur.pajot@lip6.fr;emmanuel.de-bezenac@lip6.fr;patrick.gallinari@lip6.fr,3;3;6,,Reject,0,5,0.0,yes,9/25/19,LIP6;LIP6;LIP6;LIP6,Deep Learning;Adversarial;MAP;GAN;neural networks;video,445;445;445;445,-1;-1;-1;-1,m;m,asia,ir,n,5;4
4587,ICLR,2020,Deep geometric matrix completion:  Are we doing it right?,Amit Boyarski;Sanketh Vedula;Alex Bronstein,amitboy@cs.technion.ac.il;sanketh@cs.technion.ac.il;bron@cs.technion.ac.il,3;6;3,,Reject,1,6,0.0,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion",Geometric Matrix Completion;Spectral Graph Theory;Functional Maps;Deep Linear Networks,27;27;27,-1;-1;-1,m;m,NAN,NAN,n,10
4588,ICLR,2020,Predictive Coding for Boosting Deep Reinforcement Learning with Sparse Rewards,Xingyu Lu;Pieter Abbeel;Stas Tiomkin,xingyulu0701@berkeley.edu;pabbeel@cs.berkeley.edu;stas@berkeley.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;representation learning;reward shaping;predictive coding,-1;-1;-1,13;13;13,m;m,usa,usa,n,
4589,ICLR,2020,Improved Structural Discovery and Representation Learning of Multi-Agent Data,Jennifer Hobbs;Matthew Holbrook;Nathan Frank;Long Sha;Patrick Lucey,jennifer.hobbs@statsperform.com;matthewholbrook@statsperform.com;nathan.frank@statsperform.com;long.sha@statsperform.com;patrick.lucey@statsperform.com,1;6;3,,Reject,0,7,0.0,yes,9/25/19,Stats Perform;Stats Perform;Stats Perform;Stats Perform;Stats Perform,multi-agent;gaussian mixture;permutation learning;representation learning;group structure,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
4590,ICLR,2020,Laplacian Denoising Autoencoder,Jianbo Jiao;Linchao Bao;Yunchao Wei;Shengfeng He;Honghui Shi;Rynson Lau;Thomas Huang,jiaojianbo.i@gmail.com;linchaobao@gmail.com;wychao1987@gmail.com;shengfenghe7@gmail.com;shihonghui3@gmail.com;rynson.lau@cityu.edu.hk;t-huang1@illinois.edu,6;6;3,,Reject,0,4,0.0,yes,9/25/19,"University of Oxford;Tencent AI Lab;University of Technology Sydney;South China University of Technology;University of Oregon;The Hong Kong Polytechnic University;University of Illinois, Urbana Champaign",unsupervised;representation learning;Laplacian,46;-1;73;-1;194;118;-1,1;-1;193;501;288;171;-1,m;m,usa,usa,n,
4591,ICLR,2020,A Boolean Task Algebra for Reinforcement Learning,Geraud Nangue Tasse;Steven James;Benjamin Rosman,nanguetasse2000s@gmail.com;steven.james@wits.ac.za;brosman@csir.co.za,8;3;3,,Reject,0,10,0.0,yes,9/25/19,University of the Witwatersrand;University of the Witwatersrand;CSIR,Reinforcement Learning;Transfer;Composition;Lifelong;Multi-task;Deep Reinforcement learning,-1;-1;194,-1;193;-1,m;m,asia,in,y,1
4592,ICLR,2020,"On Iterative Neural Network Pruning, Reinitialization, and the Similarity of Masks",Michela Paganini;Jessica Forde,michela@fb.com;jzf2101@columbia.edu,1;3;3,,Reject,0,4,0.0,yes,9/25/19,Facebook;Columbia University,Pruning;Lottery Tickets;Science of Deep Learning;Experimental Deep Learning;Empirical Study,-1;24,-1;16,f;f,usa,usa,n,
4593,ICLR,2020,Semantics Preserving Adversarial Attacks,Ousmane Amadou Dia;Elnaz Barshan;Reza Babanezhad,ousmane@elementai.com;elnaz.barshan@elementai.com;babanezhad@gmail.com,1;6;6,,Reject,0,15,0.0,yes,9/25/19,Element AI;Element AI;Samsung,black-box adversarial attacks;stein variational inference;adversarial images and tex,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5;4
4594,ICLR,2020,Unified recurrent network for many feature types,Alexander Stec;Diego Klabjan;Jean Utke,stec@u.northwestern.edu;d-klabjan@northwestern.edu;jutke@allstate.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Northwestern University;Northwestern University;Allstate,sparse;recurrent;asynchronous;time;series,46;46;-1,22;22;-1,m;m,NAN,NAN,n,
4595,ICLR,2020,How noise affects the Hessian spectrum in overparameterized neural networks,Mingwei Wei;David Schwab,m.wei@u.northwestern.edu;dschwab@gc.cuny.edu,6;3;6,,Reject,0,6,0.0,yes,9/25/19,Northwestern University;The City University of New York,noise;optimization;loss landscape;Hessian,46;-1,22;-1,m;m,NAN,NAN,y,1
4596,ICLR,2020,Symmetric-APL Activations: Training Insights and Robustness to Adversarial Attacks,Mohammadamin Tavakoli;Forest Agostinelli;Pierre Baldi,mohamadt@uci.edu;fagostin@uci.edu;pfbaldi@ics.uci.edu,6;1;3,,Reject,0,4,0.0,yes,9/25/19,"University of California, Irvine;University of California, Irvine;University of California, Irvine",Activation function;Adaptive;Training;Robustness;Adversarial attack,-1;-1;-1,96;96;96,m;m,usa,usa,y,4
4597,ICLR,2020,Temporal Probabilistic Asymmetric Multi-task Learning,Nguyen Anh Tuan;Hyewon Jeong;Eunho Yang;Sungju Hwang,nanhtuan@kaist.ac.kr;jhw162@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,6;6;3,,Reject,0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Multi-task learning;Time-series analysis;Variational Inference,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n,10
4598,ICLR,2020,Learning Deep-Latent Hierarchies by Stacking Wasserstein Autoencoders,Benoit Gaujac;Ilya Feige;David Barber,benoit.gaujac.16@ucl.ac.uk;ilya@faculty.ai;david.barber@ucl.ac.uk,1;3;6,,Reject,0,3,0.0,yes,9/25/19,University College London;Faculty;University College London,Generative modelling;Optimal Transport,52;-1;52,-1;-1;-1,m;m,europe,uk,n,5
4599,ICLR,2020,Feature Selection using Stochastic Gates,Yutaro Yamada;Ofir Lindenbaum;Sahand Negahban;Yuval Kluger,yutaro.yamada@yale.edu;ofirlin@gmail.com;sahand.negahban@yale.edu;yuval.kluger@yale.edu,6;3;3,,Reject,1,3,0.0,yes,9/25/19,Yale University;Yale University;Yale University;Yale University,Feature selection;classification;regression;survival analysis,73;73;73;73,8;8;8;8,m;m,europe,fi,y,
4600,ICLR,2020,Stablizing Adversarial Invariance Induction by Discriminator Matching,Yusuke Iwasawa;Kei Akuzawa;Yutaka Matsuo,iwasawa@weblab.t.u-tokyo.ac.jp;akuzawa-kei@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,3;1;3,,Reject,0,4,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo,invariance induction;adversarial training;domain generalization,64;64;64,36;36;36,m;m,NAN,NAN,y,1;7;4
4601,ICLR,2020,Revisiting Gradient Episodic Memory for Continual Learning,Zhiyi Chen;Tong Lin*,chenzhiy16@mails.tsinghua.edu.cn;lintong@pku.edu.cn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Peking University",,4;14,23;24,m;f,asia,cn,n,
4602,ICLR,2020,"Unifying Question Answering, Text Classification, and Regression via Span Extraction",Nitish Shirish Keskar;Bryan McCann;Caiming Xiong;Richard Socher,nkeskar@salesforce.com;bmccann@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,NLP;span-extraction;BERT,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4603,ICLR,2020,Reinforcement Learning with Probabilistically Complete Exploration,Philippe Morere;Tom Blau;Gilad Francis;Fabio Ramos,philippe.morere@sydney.edu.au;tom.blau@sydney.edu.au;gilad.francis@sydney.edu.au;fabio.ramos@sydney.edu.au,3;6;3,,Reject,0,4,0.0,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney;University of Sydney,Reinforcement Learning;Exploration;sparse rewards;learning from demonstration,64;64;64;64,60;60;60;60,m;m,europe,uk,y,
4604,ICLR,2020,Global Momentum Compression for Sparse Communication in Distributed SGD,Shen-Yi Zhao;Yin-Peng Xie;Hao Gao;Wu-Jun Li,zhaosy@lamda.nju.edu.cn;xieyp@lamda.nju.edu.cn;gaoh@lamda.nju.edu.cn;liwujun@nju.edu.cn,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,Distributed momentum SGD;Communication compression,39;39;39;39,107;107;107;107,m;m,asia,cn,y,1;9
4605,ICLR,2020,Quantifying uncertainty with GAN-based priors,Dhruv V. Patel;Assad A. Oberai,dhruvvpa@usc.edu;aoberai@usc.edu,3;3;3,,Reject,0,9,0.0,yes,9/25/19,University of Southern California;University of Southern California,Bayesian inference;Uncertainty quantification;Generative adversarial networks,36;36,62;62,m;m,usa,usa,n,2;11;5;4
4606,ICLR,2020,Analyzing Privacy Loss in Updates of Natural Language Models,Shruti Tople;Marc Brockschmidt;Boris K√∂pf;Olga Ohrimenko;Santiago Zanella-B√©guelin,t-shtopl@microsoft.com;mabrocks@microsoft.com;boris.koepf@microsoft.com;oohrim@microsoft.com;santiago@microsoft.com,6;3;3,,Reject,0,7,0.0,yes,9/25/19,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Language Modelling;Privacy,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,3
4607,ICLR,2020,Layer Flexible Adaptive Computation Time for Recurrent Neural Networks,Lida Zhang;Diego Klabjan,lidazhang2018@u.northwestern.edu;d-klabjan@northwestern.edu,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Northwestern University;Northwestern University,,46;46,22;22,f;m,usa,usa,n,3
4608,ICLR,2020,Gumbel-Matrix Routing for Flexible Multi-task Learning,Krzysztof Maziarz;Efi Kokiopoulou;Andrea Gesmundo;Luciano Sbaiz;Gabor Bartok;Jesse Berent,krzysztof.s.maziarz@gmail.com;kokiopou@google.com;agesmundo@google.com;sbaiz@google.com;bartok@google.com;jberent@google.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Microsoft;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4609,ICLR,2020,"OPTIMAL TRANSPORT, CYCLEGAN, AND PENALIZED LS FOR UNSUPERVISED LEARNING IN INVERSE PROBLEMS",Byeongsu Sim;Gyutaek Oh;Sungjun Lim;and Jong Chul Ye,byeongsu.s@kaist.ac.kr;okt0711@kaist.ac.kr;sungjunlim@gmail.com;jong.ye@kaist.ac.kr,6;6;1,,Reject,0,9,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;;Korea Advanced Institute of Science and Technology,Optimal transport;CycleGAN;penalized LS;unsupervised learning;and inverse problems,-1;-1;-1;-1,110;110;-1;110,m;m,NAN,NAN,y,2;1;5;4
4610,ICLR,2020,Stabilizing DARTS with Amended Gradient Estimation on Architectural Parameters,Kaifeng Bi;Changping Hu;Lingxi Xie;Xin Chen;Longhui Wei;Qi Tian,bikaifeng@huawei.com;huchangping@huawei.com;198808xc@gmail.com;1410452@tongji.edu.cn;weilonghui1@huawei.com;tian.qi1@huawei.com,3;3;6;6,,Reject,0,12,0.0,yes,9/28/20,Huawei Technologies Ltd.;Huawei Technologies Ltd.;;Tongji University;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Neural Architecture Search;DARTS;Stability,-1;-1;-1;316;-1;-1,-1;-1;-1;441;-1;-1,m;m,NAN,NAN,n,
4611,ICLR,2020,Why ADAM Beats SGD for Attention Models	,Jingzhao Zhang;Sai Praneeth Karimireddy;Andreas Veit;Seungyeon Kim;Sashank J Reddi;Sanjiv Kumar;Suvrit Sra,jzhzhang@mit.edu;sai.karimrieddy@epfl.ch;aveit@google.com;seungyeonk@google.com;sashank@google.com;sanjivk@google.com;suvrit@mit.edu,3;6;6,,Reject,1,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Swiss Federal Institute of Technology Lausanne;Google;Google;Google;Google;Massachusetts Institute of Technology,Optimization;ADAM;Deep learning,5;-1;-1;-1;-1;-1;5,5;-1;-1;-1;-1;-1;5,u;u,usa,usa,y,8
4612,ICLR,2020,Multi-Sample Dropout for Accelerated Training and Better Generalization,Hiroshi Inoue,inouehrs@jp.ibm.com,1;3;1,,Reject,0,3,0.0,yes,9/25/19,International Business Machines,dropout;regularization;convolutional neural networks,-1,-1,m,NAN,NAN,n,1
4613,ICLR,2020,Prototype Recalls for Continual Learning,Mengmi Zhang;Tao Wang;Joo Hwee Lim;Jiashi Feng,mengmi@u.nus.edu;twangnh@gmail.com;joohwee@i2r.a-star.edu.sg;elefjia@nus.edu.sg,3;1;3,,Reject,0,0,0.0,yes,9/25/19,"National University of Singapore;;Institute for Infocomm Research, A*STAR;National University of Singapore",continual learning;catastrophic forgetting;prototypes;image classification;few-shot continual learning,17;-1;-1;17,25;-1;-1;25,f;m,asia,sg,n,6
4614,ICLR,2020,Learning Surrogate Losses,Josif Grabocka;Randolf Scholz;Lars Schmidt-Thieme,josif@ismll.uni-hildesheim.de;rscholz@ismll.uni-hildesheim.de;schmidt-thieme@ismll.uni-hildesheim.de,8;3;3,,Reject,0,10,0.0,yes,9/25/19,University of Hildesheim;University of Hildesheim;University of Hildesheim,Surrogate losses;Non-differentiable losses,445;445;445,-1;-1;-1,m;m,europe,de,n,
4615,ICLR,2020,Recurrent Independent Mechanisms,Anirudh Goyal;Alex Lamb;Shagun Sodhani;Jordan Hoffmann;Sergey Levine;Yoshua Bengio;Bernhard Scholkopf,anirudhgoyal9119@gmail.com;alex6200@gmail.com;sshagunsodhani@gmail.com;jhoffmann@g.harvard.edu;svlevine@eecs.berkeley.edu;yoshua.bengio@mila.quebec;bs@tuebingen.mpg.de,6;6;6,,Reject,0,13,0.0,yes,9/28/20,University of Montreal;;Facebook;Harvard University;University of California Berkeley;Mila;Max-Planck Institute,modular representations;better generalization;learning mechanisms,-1;-1;-1;52;-1;143;-1,-1;-1;-1;7;13;336;-1,m;m,NAN,NAN,n,8;1
4616,ICLR,2020,Anomaly Detection Based on Unsupervised Disentangled Representation Learning in Combination with Manifold Learning,Xiaoyan Li;Iluju Kiringa;Tet Yeap;Xiaodan Zhu;Yifeng Li,xli343@uottawa.ca;iluju.kiringa@uottawa.ca;tyeap@uottawa.ca;xiaodan.zhu@queensu.ca;yifeng.li@nrc-cnrc.gc.ca,3;3;6,,Reject,0,7,0.0,yes,9/25/19,University of Ottawa;University of Ottawa;University of Ottawa;Queens University;National Research Council Canada,anomaly detection;disentangled representation learning;manifold learning,248;248;248;248;-1,141;141;141;258;-1,m;m,NAN,NAN,n,5
4617,ICLR,2020,Stochastic Mirror Descent on Overparameterized Nonlinear Models,Navid Azizan;Sahin Lale;Babak Hassibi,azizan@caltech.edu;alale@caltech.edu;hassibi@caltech.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,California Institute of Technology;California Institute of Technology;California Institute of Technology,deep learning;optimization;overparameterized;stochastic gradient descent;mirror descent,143;143;143,2;2;2,m;m,usa,usa,y,1
4618,ICLR,2020,On the implicit minimization of alternative loss functions when training deep networks,Alexandre Lemire Paquin;Brahim Chaib-draa;Philippe Gigu√®re,alexandre.lemire-paquin.1@ulaval.ca;brahim.chaib-draa@ift.ulaval.ca;philippe.giguere@ift.ulaval.ca,1;3;3,,Reject,0,0,0.0,yes,9/25/19,Laval university;Laval university;Laval university,implicit minimization;optimization bias;margin based loss functions;flat minima,-1;-1;-1,272;272;272,m;m,NAN,NAN,n,1
4619,ICLR,2020,UWGAN: UNDERWATER GAN FOR REAL-WORLD UNDERWATER COLOR RESTORATION AND DEHAZING,Nan Wang;Yabin Zhou;Fenglei Han;Lichao Wan;Haitao Zhu;Yaojing Zheng,nanwangmail@hrbeu.edu.cn;zyb0977@163.com;fenglei_han@hrbeu.edu.cn;wanlch1203@hrbeu.edu.cn;zhuhaitao_heu@163.com;yaojingzheng_heu@163.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Science and Technology of China;163;University of Science and Technology of China;University of Science and Technology of China;163;163,underwater image;image restoration;image enhancement;GAN;CNNs,-1;-1;-1;-1;-1;-1,80;-1;80;80;-1;-1,f;f,asia,in,n,5;4
4620,ICLR,2020,LEARNING  TO LEARN  WITH  BETTER  CONVERGENCE,Patrick H. Chen;Sashank Reddi;Sanjiv Kumar;Cho-Jui Hsieh,patrickchen@g.ucla.edu;sashank@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,3;3;1,,Reject,0,0,0.0,yes,9/25/19,"University of California, Los Angeles;Google;Google;University of California, Los Angeles",,-1;-1;-1;-1,17;-1;-1;17,m;m,usa,usa,n,
4621,ICLR,2020,Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,Francesco Croce;Matthias Hein,francesco91.croce@gmail.com;matthias.hein@uni-tuebingen.de,6;6;6,,Reject,0,3,0.0,yes,9/25/19,University of Tuebingen;University of Tuebingen,adversarial attacks;adversarial robustness,143;143,91;91,m;m,europe,de,n,4
4622,ICLR,2020,Octave Graph Convolutional Network,Heng Chang;Yu Rong;Somayeh Sojoudi;Junzhou Huang;Wenwu Zhu,changh17@mails.tsinghua.edu.cn;yu.rong@hotmail.com;sojoudi@berkeley.edu;jzhuang@uta.edu;wwzhu@tsinghua.edu.cn,6;3;3,,Reject,0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tencent AI Lab;University of California Berkeley;University of Texas, Arlington;Tsinghua University, Tsinghua University",Graph Convolutional Networks;Octave Convolution;Graph Mining,4;-1;-1;-1;4,23;-1;13;-1;23,m;m,NAN,NAN,n,1;10
4623,ICLR,2020,"Lift-the-flap: what, where and when for context reasoning",Mengmi Zhang;Claire Tseng;Karla Montejo;Joseph Kwon;Gabriel Kreiman,mengmi.zhang@childrens.harvard.edu;ctseng@college.harvard.edu;kmont057@fiu.edu;joseph.kwon@yale.edu;gabriel.kreiman@tch.harvard.edu,3;3;6,,Reject,0,8,0.0,yes,9/25/19,"Harvard University;Harvard University;Indiana University, Bloomington;Yale University;Harvard University",contextual reasoning;visual recognition;human behavior;intelligent sampling,52;52;64;73;52,7;7;134;8;7,f;m,usa,usa,n,1
4624,ICLR,2020,The Dynamics of Signal Propagation in Gated Recurrent Neural Networks,Dar Gilboa;Bo Chang;Minmin Chen;Greg Yang;Samuel S. Schoenholz;Ed H. Chi;Jeffrey Pennington,dg2893@columbia.edu;bchang@stat.ubc.ca;minminc@google.com;gregyang@microsoft.com;schsam@google.com;edchi@google.com;jpennin@google.com,3;8;1,,Reject,0,0,0.0,yes,9/25/19,Columbia University;University of British Columbia;Google;Microsoft;Google;Google;Google,recurrent neural networks;theory of deep learning,24;64;-1;-1;-1;-1;-1,16;34;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
4625,ICLR,2020,Regulatory Focus: Promotion and Prevention Inclinations in Policy Search,Lanxin Lei;Zhizhong Li;Xiaoyang Li;Cong Qiu;Dahua Lin,leilansen@gmail.com;lizz@sensetime.com;lixiaoyang@nbu.edu.cn;qiucong@sensetime.com;dhlin@ie.cuhk.edu.hk,3;3;3,,Reject,0,0,0.0,yes,9/25/19,University of Electronic Science and Technology of China;SenseTime Group Limited;Boston University;SenseTime Group Limited;The Chinese University of Hong Kong,Reinforcement Learning;Regulatory Focus;Promotion and Prevention;Exploration,-1;-1;79;-1;316,-1;-1;61;-1;35,f;m,NAN,NAN,n,1
4626,ICLR,2020,WaveFlow: A Compact Flow-based Model for Raw Audio,Wei Ping;Kainan Peng;Kexin Zhao;Zhao Song,weiping.thu@gmail.com,8;6;3,,Reject,3,3,1.0,yes,9/25/19,NVIDIA,flow-based models;raw audio;waveforms;speech synthesis;generative models,-1,-1,m;m,NAN,NAN,n,5
4627,ICLR,2020,Identifying Weights and Architectures of Unknown ReLU Networks,David Rolnick;Konrad P. Kording,drolnick@seas.upenn.edu;koerding@gmail.com,3;1;6;6,,Reject,1,5,0.0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania,deep neural network;ReLU;piecewise linear function;linear region;activation region;weights;parameters;architecture,20;20,11;11,m;m,usa,usa,n,
4628,ICLR,2020,On PAC-Bayes Bounds for Deep Neural Networks using the Loss Curvature,Konstantinos Pitas,konstantinos.pitas@epfl.ch,1;3;1,,Reject,0,13,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne,PAC-Bayes;Hessian;curvature;lower bound;Variational Inference,-1,-1,m;m,NAN,NAN,n,1
4629,ICLR,2020,RoBERTa: A Robustly Optimized BERT Pretraining Approach,Yinhan Liu;Myle Ott;Naman Goyal;Jingfei Du;Mandar Joshi;Danqi Chen;Omer Levy;Mike Lewis;Luke Zettlemoyer;Veselin Stoyanov,yinhanliu@fb.com;myleott@fb.com;namangoyal@instagram.com;jingfeidu@fb.com;mandar90@cs.washington.edu;danqic@cs.princeton.edu;omerlevy@gmail.com;mikelewis@fb.com;lsz@fb.com;ves@fb.com,6;6;6,,Reject,0,4,0.0,yes,9/25/19,Facebook;Facebook;Instagram;Facebook;University of Washington;Princeton University;Tel Aviv University;Facebook;Facebook;Facebook,Deep learning;language representation learning;natural language understanding,-1;-1;-1;-1;11;30;30;-1;-1;-1,-1;-1;-1;-1;26;6;188;-1;-1;-1,f;m,NAN,NAN,n,3
4630,ICLR,2020,A Coordinate-Free Construction of Scalable Natural Gradient,Kevin Luk;Roger Grosse,kevin.kh.luk@gmail.com;rgrosse@cs.toronto.edu,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Facebook;University of Toronto,Natural gradient;second-order optimization;K-FAC;parameterization invariance;deep learning,-1;18,-1;18,m;m,canada,ca,y,
4631,ICLR,2020,Evaluating and Calibrating Uncertainty Prediction in Regression Tasks,Dan Levi;Liran Gispan;Niv Giladi;Ethan Fetaya,danmlevi@gmail.com;liran.gispan@gm.com;giladiniv@gmail.com;ethanf@cs.toronto.edu,1;3;1,,Reject,0,0,0.0,yes,9/25/19,"General Motors;General Motors;Technion, Technion;University of Toronto",Uncertainty Estimation;Regression;Deep learning,-1;-1;27;18,-1;-1;-1;18,m;m,canada,ca,n,2
4632,ICLR,2020,Why Does the VQA Model Answer No?: Improving Reasoning through Visual and Linguistic Inference,Seungjun Jung;Junyoung Byun;Kyujin Shim;Changick Kim,seungjun45@kaist.ac.kr;bjyoung@kaist.ac.kr;kjshim1028@kaist.ac.kr;changick@kaist.ac.kr,6;6;3,,Reject,0,3,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Image Captioning;Visual Question Answering;Explainable A.I;Beam Search;Constrained Beam Search,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n,
4633,ICLR,2020,Modeling Winner-Take-All Competition in Sparse Binary Projections,Wenye Li,wyli@cuhk.edu.cn,3;8;6,,Reject,0,4,0.0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen",Sparse Representation;Sparse Binary Projection;Winner-Take-All,46,35,m;m,NAN,NAN,n,8
4634,ICLR,2020,When Robustness Doesn‚Äôt Promote Robustness: Synthetic vs. Natural Distribution Shifts on ImageNet,Rohan Taori;Achal Dave;Vaishaal Shankar;Nicholas Carlini;Benjamin Recht;Ludwig Schmidt,rohantaori@berkeley.edu;achald@cs.cmu.edu;vaishaal@berkeley.edu;nicholas@carlini.com;brecht@berkeley.edu;ludwigschmidt2@gmail.com,3;6;3,,Reject,0,6,0.0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;University of California Berkeley;Google;University of California Berkeley;University of California Berkeley,robustness;distribution shift;image corruptions;adversarial robustness;reliable machine learning,-1;1;-1;-1;-1;-1,13;27;13;-1;13;-1,m;m,asia,in,n,4
4635,ICLR,2020,Perturbations are not Enough: Generating Adversarial Examples with Spatial Distortions,He Zhao;Trung Le;Paul Montague;Olivier De Vel;Tamas Abraham;Dinh Phung,ethanhezhao@gmail.com;trunglm@monash.edu;paul.montague@dst.defence.gov.au;olivier.devel@dst.defence.gov.au;tamas.abraham@dst.defence.gov.au;dinh.phung@monash.edu,3;1;3,,Reject,1,3,0.0,yes,9/25/19,Monash University;Monash University;Defence Science and Technology Group;Defence Science and Technology Group;Defence Science and Technology Group;Monash University,,92;92;-1;-1;-1;92,75;75;-1;-1;-1;75,m;m,australasia,au,y,4
4636,ICLR,2020,Adaptive Data Augmentation with Deep Parallel Generative Models,Boli Fang;Miao Jiang;Abhirag Nagpure;Jerry Shen,bfang@iu.edu;miajiang@iu.edu;anagpure@iu.edu;hashen@iu.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,"Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington",,64;64;64;64,134;134;134;134,m;m,NAN,NAN,n,2;5
4637,ICLR,2020,Visual Explanation for Deep Metric Learning,Sijie Zhu;Taojiannan Yang;Chen Chen,szhu3@uncc.edu;tyang30@uncc.edu;chen.chen@uncc.edu,6;3;8,,Reject,0,5,0.0,yes,9/25/19,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte",Metric Learning;Visual Explanation,64;64;64,-1;-1;-1,m;m,NAN,NAN,n,8
4638,ICLR,2020,Continual Learning via Neural Pruning,Siavash Golkar;Micheal Kagan;Kyunghyun Cho,siavash.golkar@gmail.com;makagan@slac.stanford.edu;kyunghyun.cho@nyu.edu,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Flatiron Institute;Stanford University;New York University,continual learning;lifelong learning;catastrophic forgetting;sparsification,-1;5;22,-1;4;29,m;m,usa,usa,n,
4639,ICLR,2020,Continual Learning using the SHDL Framework with Skewed Replay Distributions,Amarjot Singh;Jay McClelland,as2436@stanford.edu;jlmcc@stanford.edu,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Stanford University;Stanford University,Continual Learning;Catastrophic Forgetting;SHDL;CIFAR-100,5;5,4;4,m;m,usa,usa,n,
4640,ICLR,2020,Goten: GPU-Outsourcing Trusted Execution of Neural Network Training and Prediction,Lucien K.L. Ng;Sherman S.M. Chow;Anna P.Y. Woo;Donald P. H. Wong;Yongjun Zhao,nkl018@ie.cuhk.edu.hk;smchow@ie.cuhk.edu.hk;woopuiyung@gmail.com;foreverjun.zhao@gmail.com,1;6;1,,Reject,0,7,0.0,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong;;Nanyang Technological University,machine learning;security;privacy;TEE;trusted processors;Intel SGX;GPU;high-performance,316;316;-1;43,35;35;-1;49,m;m,asia,sg,n,
4641,ICLR,2020,One-way prototypical networks,Anna Kruspe,anna.kruspe@dlr.de,8;3;3,,Reject,0,0,0.0,yes,9/25/19,German Aerospace Center (DLR),few-shot learning;one-shot learning;prototypical networks;one-class classification;anomaly detection;outlier detection;matching networks,-1,-1,f,NAN,NAN,n,6
4642,ICLR,2020,FLUID FLOW MASS TRANSPORT FOR GENERATIVE NETWORKS,Jingrong Lin;Keegan Lensink;Eldad Haber,jlin@eoas.ubc.ca;klensink@eoas.ubc.ca;ehaber@eoas.ubc.ca,1;3;3,,Reject,0,0,0.0,yes,9/25/19,University of British Columbia;University of British Columbia;University of British Columbia,generative network;optimal mass transport;gaussian mixture;model matching,64;64;64,34;34;34,f;m,canada,ca,n,5;4
4643,ICLR,2020,Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration,Si-An Chen;Chun-Liang Li;Hsuan-Tien Lin,r05922089@csie.ntu.edu.tw;chunlial@cs.cmu.edu;htlin@csie.ntu.edu.tw,3;3;3,,Reject,0,2,0.0,yes,9/25/19,Nanyang Technological University;Carnegie Mellon University;Nanyang Technological University,generative adversarial network;GAN;model compatibility;machine learning efficacy,43;1;43,49;27;49,m;m,asia,sg,n,5;4
4644,ICLR,2020,Generative Imputation and Stochastic Prediction,Mohammad Kachuee;Kimmo K√§rkk√§inen;Orpaz Goldstein;Sajad Darabi;Majid Sarrafzadeh,mkachuee@ucla.edu;kimmo@cs.ucla.edu;orpgol@cs.ucla.edu;sajad.darabi@cs.ucla.edu;majid@cs.ucla.edu,6;6;6,,Reject,0,9,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",,-1;-1;-1;-1;-1,17;17;17;17;17,m;m,usa,usa,n,10
4645,ICLR,2020,Denoising Improves Latent Space Geometry in Text Autoencoders,Tianxiao Shen;Jonas Mueller;Regina Barzilay;Tommi Jaakkola,tianxiao@mit.edu;jonasmue@amazon.com;regina@csail.mit.edu;tommi@csail.mit.edu,6;3;6,,Reject,0,10,0.0,yes,9/25/19,Massachusetts Institute of Technology;Amazon;Massachusetts Institute of Technology;Massachusetts Institute of Technology,controllable text generation;autoencoders;denoising;latent space geometry,5;-1;5;5,5;-1;5;5,f;m,usa,usa,y,3;1;4
4646,ICLR,2020,Information-Theoretic Local Minima Characterization and Regularization,Zhiwei Jia;Hao Su,zjia@ucsd.edu;haosu@eng.ucsd.edu,1;8;3,,Reject,0,18,0.0,yes,9/25/19,"University of California, San Diego;University of California, San Diego",local minima;generalization;regularization;deep learning theory,-1;-1,31;31,m;m,usa,usa,y,1
4647,ICLR,2020,Wider Networks Learn Better Features,Dar Gilboa;Guy Gur-Ari,dg2893@columbia.edu;guyga@google.com,3;1;3,,Reject,0,0,0.0,yes,9/25/19,Columbia University;Google,Interpretability;transfer learning,24;-1,16;-1,m;m,NAN,NAN,n,
4648,ICLR,2020,GENERALIZATION GUARANTEES FOR NEURAL NETS VIA HARNESSING THE LOW-RANKNESS OF JACOBIAN,Samet Oymak;Zalan Fabian;Mingchen Li;Mahdi Soltanolkotabi,sametoymak@gmail.com;zfabian@usc.edu;mli176@ucr.edu;msoltoon@gmail.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"University of California, Riverside;University of Southern California;University of California, Riverside;University of Southern California",Theory of neural nets;low-rank structure of Jacobian;optimization and generalization theory,-1;36;-1;36,249;62;249;62,m;m,usa,usa,y,1
4649,ICLR,2020,Implicit competitive regularization in GANs,Florian Schaefer;Hongkai Zheng;Anima Anandkumar,florian.schaefer@caltech.edu;devzhk@sjtu.edu.cn;anima@caltech.edu,6;6;8;1,,Reject,0,7,0.0,yes,9/25/19,California Institute of Technology;Shanghai Jiao Tong University;California Institute of Technology,GAN;competitive optimization;game theory,143;30;143,2;157;2,m;f,usa,usa,n,5;4
4650,ICLR,2020,TWO-STEP UNCERTAINTY NETWORK FOR TASKDRIVEN SENSOR PLACEMENT,Yangyang Sun;Yang Zhang;Hassan Foroosh;Shuo Pang,yangyang@knights.ucf.edu;yangzhang@knights.ucf.edu;foroosh@cs.ucf.edu;pang@creol.ucf.edu,1;1,,Reject,0,0,0.0,yes,9/25/19,University of Central Florida;University of Central Florida;University of Central Florida;University of Central Florida,Uncertainty Estimation;Sensor Placement;Sequential Control;Adaptive Sensing,73;73;73;73,609;609;609;609,m;m,usa,usa,n,5
4651,ICLR,2020,Efficient Content-Based Sparse Attention with Routing Transformers,Aurko Roy*;Mohammad Taghi Saffar*;David Grangier;Ashish Vaswani,aurkor@google.com;msaffar@google.com;grangier@google.com;avaswani@google.com,3;3;6,,Reject,0,2,0.0,yes,9/25/19,Google;Google;Google;Google,Sparse attention;autoregressive;generative models,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
4652,ICLR,2020,Implicit Rugosity Regularization via Data Augmentation,Daniel LeJeune;Randall Balestriero;Hamid Javadi;Richard G. Baraniuk,dlejeune@rice.edu;randallbalestriero@gmail.com;hh35@rice.edu;richb@rice.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Rice University;Rice University;Rice University;Rice University,deep networks;implicit regularization;Hessian;rugosity;curviness;complexity,92;92;92;92,105;105;105;105,m;m,australasia,au,y,1
4653,ICLR,2020,Balancing Cost and Benefit with Tied-Multi Transformers,Raj Dabre;Raphael Rubino;Atsushi Fujita,raj.dabre@nict.go.jp;raphael.rubino@nict.go.jp;fujita@paraphrasing.org,1;6;1,,Reject,0,3,0.0,yes,9/25/19,"National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;Nara Institute of Science and Technology",tied models;encoder-decoder;multi-layer softmaxing;depth prediction;model compression,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,8;3
4654,ICLR,2020,Learning to Learn Kernels with Variational Random Features,Haoliang Sun;Yingjun Du;Jun Xu;Yilong Yin;Xiantong Zhen;Ling Shao,haolsun.cn@gmail.com;duyingjun@buaa.edu.cn;nankaimathxujun@gmail.com;ylyin@sdu.edu.cn;zhenxt@gmail.com;ling.shao@ieee.org,6;6;8,,Reject,0,7,0.0,yes,9/25/19,Shandong University;Beihang University;;Shandong University;University of Amsterdam;Inception Institute of Artificial Intelligence,Meta-learning;few-shot learning;Random Fourier Feature;Kernel learning,-1;102;-1;143;143;-1,-1;594;-1;658;62;-1,m;m,asia,in,n,6
4655,ICLR,2020,Learning Numeral Embedding,Chengyue Jiang;Zhonglin Nian;Kaihao Guo;Shanbo Chu;Yinggong Zhao;Libin Shen;Kewei Tu,jiangchy@shanghaitech.edu.cn;nianzhl@shanghaitech.edu.cn;guokh@shanghaitech.edu.cn;chushb@leyantech.com;ygzhao@leyantech.com;libin@leyantech.com;tukw@shanghaitech.edu.cn,3;6;6,,Reject,0,4,0.0,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;Leyantech;Leyantech;Leyantech;ShanghaiTech University,Natural Language Processing;Numeral Embedding;Word Embedding;Out-of-vocabulary Problem,316;316;316;-1;-1;-1;316,-1;-1;-1;-1;-1;-1;-1,f;m,asia,cn,n,3
4656,ICLR,2020,Label Cleaning with Likelihood Ratio Test,Songzhu Zheng;Pengxiang Wu;Aman Goswami;Mayank Goswami;Dimitris Metaxas;Chao Chen,zheng.songzhu@stonybrook.edu;pxiangwu@gmail.com;ag77in@gmail.com;mayank.isi@gmail.com;dnm@cs.rutgers.edu;chao.chen.1@stonybrook.edu,8;3;3,,Reject,0,4,0.0,yes,9/25/19,"State University of New York, Stony Brook;;;;Rutgers University;State University of New York, Stony Brook",Deep Learning,-1;-1;-1;-1;30;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,11;1
4657,ICLR,2020,Fast Task Adaptation for Few-Shot Learning,Yingying Zhang;Qiaoyong Zhong;Di Xie;Shiliang Pu,zhangyingying7@hikvision.com;zhongqiaoyong@hikvision.com;xiedi@hikvision.com;pushiliang@hikvision.com,8;1;3,,Reject,6,7,0.0,yes,9/25/19,Hikvision Research Institute;Hikvision Research Institute;Hikvision Research Institute;Hikvision Research Institute,Few-Shot Learning;Metric-Softmax Loss;Fast Task Adaptation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6;1
4658,ICLR,2020,Using Objective Bayesian Methods to Determine the Optimal Degree of Curvature within the Loss Landscape,Devon Jarvis;Richard Klein;Benjamin Rosman,devonjarvi@gmail.com;kleinric@gmail.com;benjros@gmail.com,1;6;1,,Reject,0,7,0.0,yes,9/25/19,University of the Witwatersrand;University of the Witwatersrand;University of the Witwatersrand,Objective Bayes;Information Geometry;Artificial Neural Networks,-1;-1;-1,193;193;193,m;m,NAN,NAN,n,11
4659,ICLR,2020,VIDEO AFFECTIVE IMPACT PREDICTION WITH MULTIMODAL FUSION AND LONG-SHORT TEMPORAL CONTEXT,Yin Zhao;Longjun Cai;Chaoping Tu;Jie Zhang;Wu Wei,yinzhao.zy@alibaba-inc.com;longjun.clj@alibaba-inc.com;chaoping.tcp@alibaba-inc.com;auzj_alex@mail.scut.edu.cn;weiwu@scut.edu.cn,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Alibaba Group;Alibaba Group;Alibaba Group;South China University of Technology;South China University of Technology,multi-modal fusion;affective computing;temporal context;residual-based training strategy,-1;-1;-1;-1;-1,-1;-1;-1;501;501,f;m,NAN,NAN,n,
4660,ICLR,2020,UNITER: Learning UNiversal Image-TExt Representations,Yen-Chun Chen;Linjie Li;Licheng Yu;Ahmed El Kholy;Faisal Ahmed;Zhe Gan;Yu Cheng;Jingjing Liu,yen-chun.chen@microsoft.com;lindsey.li@microsoft.com;licheng.yu@microsoft.com;ahmed.elkholy@microsoft.com;fiahmed@microsoft.com;zhe.gan@microsoft.com;yu.cheng@microsoft.com;jingjl@microsoft.com,6;6;6,,Reject,0,12,0.0,yes,9/25/19,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Self-supervised Representation Learning;Large-scale Pre-training;Vision and Language,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,3
4661,ICLR,2020,"Fast Linear Interpolation for Piecewise-Linear Functions, GAMs, and Deep Lattice Networks",Nathan Zhang;Kevin Canini;Sean Silva;and Maya R. Gupta,nzhang32@gmail.com;canini@google.com;silvasean@google.com;mayagupta@google.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Stanford University;Google;Google;Google,hardware;compiler;MLIR;runtime;CPU;interpolation,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,
4662,ICLR,2020,Knowledge Graph Embedding: A Probabilistic Perspective and Generalization Bounds,Ondrej Kuzelka;Yuyi Wang,kuzelo1@gmail.com;yuyiwang920@gmail.com,6;1;3,,Reject,0,11,0.0,yes,9/25/19,Czech Technical University in Prague;Swiss Federal Institute of Technology,knowledge graph embedding;generalization bounds,168;-1,956;-1,m;m,NAN,NAN,y,1;10
4663,ICLR,2020,BUZz: BUffer Zones for defending  adversarial examples in image classification,Phuong Ha Nguyen*;Kaleel Mahmood*;Lam M. Nguyen;Thanh Nguyen;Marten van Dijk,phuongha.ntu@gmail.com;kaleel.mahmood@uconn.edu;lamnguyen.mltd@gmail.com;thanhng@iastate.edu;marten.van_dijk@uconn.edu,1;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Connecticut;University of Connecticut;International Business Machines;Iowa State University;University of Connecticut,adversarial machine learning;machine learning security,168;168;-1;194;168,393;393;-1;399;393,m;m,usa,usa,n,4
4664,ICLR,2020,Domain Aggregation Networks for Multi-Source Domain Adaptation,Junfeng Wen;Russell Greiner;Dale Schuurmans,junfengwen@gmail.com;rgreiner@ualberta.ca;daes@ualberta.ca,6;3;6,,Reject,0,6,0.0,yes,9/25/19,Layer 6 AI;University of Alberta;University of Alberta,Domain Adaptation;Transfer Learning;Deep Learning,-1;102;102,-1;136;136,m;m,canada,ca,y,1
4665,ICLR,2020,Privacy-preserving Representation Learning by Disentanglement,Tassilo Klein;Moin Nabi,tassilo.klein@sap.com;m.nabi@sap.com,1;3;1,,Reject,1,0,0.0,yes,9/25/19,SAP;SAP,,316;316,258;258,m;m,asia,in,n,
4666,ICLR,2020,Angular Visual Hardness,Beidi Chen;Weiyang Liu;Animesh Garg;Zhiding Yu;Anshumali Shrivastava;Jan Kautz;Anima Anandkumar,beidi.chen@rice.edu;wyliu@gatech.edu;garg@cs.stanford.edu;zhidingy@nvidia.com;anshumali@rice.edu;jkautz@nvidia.com;anima@caltech.edu,1;8;8,,Reject,0,7,0.0,yes,9/25/19,Rice University;Georgia Institute of Technology;Stanford University;NVIDIA;Rice University;NVIDIA;California Institute of Technology,angular similarity;self-training;hard samples mining,92;13;5;-1;92;-1;143,105;38;4;-1;105;-1;2,f;f,usa,usa,n,
4667,ICLR,2020,Autoencoders and Generative Adversarial Networks for Imbalanced Sequence Classification,Stephanie Ger;Diego Klabjan,stephanieger@u.northwestern.edu;d-klabjan@northwestern.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Northwestern University;Northwestern University,imbalanced multivariate time series classification,46;46,22;22,f;m,usa,usa,n,5;4
4668,ICLR,2020,Multiagent Reinforcement Learning in Games with an Iterated Dominance Solution,Yoram Bachrach;Tor Lattimore;Marta Garnelo;Julien Perolat;David Balduzzi;Thomas Anthony;Satinder Singh;Thore Graepel,yorambac@gmail.com;lattimore@google.com;garnelo@google.com;perolat@google.com;dbalduzzi@google.com;twa@google.com;baveja@google.com;thore@google.com,1;6;3;6,,Reject,0,8,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,multiagent;reinforcement learning;iterated dominance;mechanism design;Nash equilibrium,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
4669,ICLR,2020,Blockwise Adaptivity:  Faster Training and Better Generalization in Deep Learning,Shuai Zheng;James T. Kwok,zs910504@gmail.com;jamesk@cse.ust.hk,3;6;1,,Reject,0,3,0.0,yes,9/25/19,Amazon;The Hong Kong University of Science and Technology,optimization;deep learning;blockwise adaptivity,-1;-1,-1;47,m;m,NAN,NAN,y,1;9
4670,ICLR,2020,Self-Educated Language Agent with Hindsight Experience Replay for Instruction Following,Geoffrey Cideron;Mathieu Seurin;Florian Strub;Olivier Pietquin,geoffrey.cideron@inria.fr;mathieu.seurin@inria.fr;fstrub@google.com;pietquin@google.com,6;6;3,,Reject,0,8,0.0,yes,9/25/19,INRIA;INRIA;Google;Google,Language;reinforcement learning;instruction following;Hindsight Experience Replay,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
4671,ICLR,2020,Extreme Triplet Learning: Effectively Optimizing Easy Positives and Hard Negatives,Hong Xuan;Robert Pless,xuanhong@gwu.edu;pless@gwu.edu,3;8;3,,Reject,0,2,0.0,yes,9/25/19,George Washington University;George Washington University,Triplet Learning;Easy Positive;Hard Negatives,194;194,198;198,m;m,usa,usa,n,
4672,ICLR,2020,MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit,John Palowitch;Bryan Perozzi,johnpalowitch@gmail.com;bperozzi@acm.org,6;6;3,,Reject,0,5,0.0,yes,9/25/19,"University of North Carolina, Chapel Hill;Google",Graph Embeddings;Representation Learning,-1;-1,-1;-1,m;m,NAN,NAN,y,10;7
4673,ICLR,2020,DYNAMIC SELF-TRAINING FRAMEWORK  FOR GRAPH CONVOLUTIONAL NETWORKS,Ziang Zhou;Shenzhong Zhang;Zengfeng Huang,15300180085@fudan.edu.cn;17210980007@fudan.edu.cn;huangzf@fudan.edu.cn,3;6;6,,Reject,0,3,0.0,yes,9/25/19,Fudan University;Fudan University;Fudan University,self-training;semi-supervised learning;graph convolutional networks,73;73;73,109;109;109,m;m,asia,cn,n,10
4674,ICLR,2020,TOWARDS FEATURE SPACE ADVERSARIAL ATTACK,Qiuling Xu;Guanhong Tao;Siyuan Cheng;Lin Tan;Xiangyu Zhang,xu1230@purdue.edu;taog@purdue.edu;516030910472@sjtu.edu.cn;lintan@purdue.edu;xyzhang@cs.purdue.edu,6;3;6,,Reject,0,3,0.0,yes,9/25/19,Purdue University;Purdue University;Shanghai Jiao Tong University;Purdue University;Purdue University,,24;24;30;24;24,88;88;157;88;88,m;m,usa,usa,n,4
4675,ICLR,2020,DIVA: Domain Invariant Variational Autoencoder,Maximilian Ilse;Jakub M. Tomczak;Christos Louizos;Max Welling,ilse.maximilian@gmail.com;jakubmkt@gmail.com;chr.louizos@gmail.com;welling.max@gmail.com,6;3;3,,Reject,0,7,0.0,yes,9/25/19,"University of Amsterdam;VU University Amsterdam;Qualcomm Inc, QualComm;University of California, Irvine",representation learning;generative models;domain generalization;invariance,143;-1;-1;-1,62;-1;-1;96,m;m,usa,usa,n,1;5
4676,ICLR,2020,Optimal Attacks on Reinforcement Learning Policies,Alessio Russo;Alexandre Proutiere,alessior@kth.se;alepro@kth.se,3;6;6,,Reject,0,6,0.0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",,194;194,222;222,m;m,NAN,NAN,y,4
4677,ICLR,2020,Recurrent Event Network : Global Structure Inference Over Temporal Knowledge Graph,Woojeong Jin;He Jiang;Meng Qu;Tong Chen;Changlin Zhang;Pedro¬†Szekely;Xiang Ren,woojeong.jin@usc.edu;jian567@usc.edu;meng.qu@umontreal.ca;tongc2@andrew.cmu.edu;changlin.zhang@usc.edu;pszekely@isi.edu;xiangren@usc.edu,6;3;3,,Reject,0,9,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Montreal;Carnegie Mellon University;University of Southern California;USC/ISI;University of Southern California,Temporal Knowledge Graphs;Representation Learning;Graph Sequence Inference;Knowledge Graph Completion,36;36;118;1;36;-1;36,62;62;85;27;62;-1;62,m;m,usa,usa,y,10
4678,ICLR,2020,Continual Learning with Gated Incremental Memories for Sequential Data Processing,Andrea Cossu;Antonio Carta;Davide Bacciu,cossu48@gmail.com;antonio.carta@di.unipi.it;bacciu@di.unipi.it,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Scuola Normale Superiore;University of Pisa;University of Pisa,continual learning;recurrent neural networks;progressive networks;gating autoencoders;sequential data processing,-1;248;248,152;366;366,m;m,europe,il,n,
4679,ICLR,2020,Context-Aware Object Detection With Convolutional Neural Networks,Yizhou Yan;Lei Cao;Samuel Madden;Elke Rundensteiner,yyan2@wpi.edu;lcao@csail.mit.edu;madden@csail.mit.edu;rundenst@cs.wpi.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Worcester Polytechnic Institute;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Worcester Polytechnic Institute,Object Detection;CNN;Context;CRF,143;5;5;143,628;5;5;628,f;f,usa,usa,n,2
4680,ICLR,2020,Resizable Neural Networks,Yichen Zhu;Xiangyu Zhang;Tong Yang;Jian Sun,k.zhu@mail.utoronto.ca;zhangxiangyu@megvii.com;yangtong@megvii.com;sunjian@megvii.com,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Toronto University;Megvii Technology Inc.;Megvii Technology Inc.;Megvii Technology Inc.,,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,
4681,ICLR,2020,SPROUT: Self-Progressing Robust Training,Minhao Cheng;Pin-Yu Chen;Sijia Liu;Shiyu Chang;Cho-Jui Hsieh;Payel Das,mhcheng@ucla.edu;pin-yu.chen@ibm.com;sijia.liu@ibm.com;shiyu.chang@ibm.com;chohsieh@cs.ucla.edu;daspa@us.ibm.com,3;6;3,,Reject,0,6,0.0,yes,9/25/19,"University of California, Los Angeles;International Business Machines;International Business Machines;International Business Machines;University of California, Los Angeles;International Business Machines",robustness;robust training;trustworthy machine learning,-1;-1;-1;-1;-1;-1,17;-1;-1;-1;17;-1,m;f,NAN,NAN,n,4
4682,ICLR,2020,FALCON: Fast and Lightweight Convolution for Compressing and Accelerating CNN,Chun Quan;Jun-Gi Jang;Hyun Dong Lee;U Kang,chunquan_cs@outlook.com;elnino4@snu.ac.kr;hyundonglee1015@gmail.com;ukang@snu.ac.kr,6;6;3,,Reject,0,5,0.0,yes,9/25/19,Seoul National University;Seoul National University;;Seoul National University,CNN compression;CNN acceleration;model compression,-1;39;-1;39,-1;64;-1;64,m;m,asia,kr,y,
4683,ICLR,2020,Conditional Invertible Neural Networks for Guided Image Generation,Lynton Ardizzone;Carsten L√ºth;Jakob Kruse;Carsten Rother;Ullrich K√∂the,lynton.ardizzone@iwr.uni-heidelberg.de;clueth@live.de;jakob.kruse@iwr.uni-heidelberg.de;carsten.rother@iwr.uni-heidelberg.de;ullrich.koethe@iwr.uni-heidelberg.de,6;6;3;8,,Reject,0,4,0.0,yes,9/25/19,Heidelberg University;;Heidelberg University;Heidelberg University;Heidelberg University,Invertible neural networks;generative models;conditional generation,194;-1;194;194;194,44;-1;44;44;44,m;m,europe,de,n,8;5
4684,ICLR,2020,Domain-Independent Dominance of Adaptive Methods,Pedro Savarese;David McAllester;Sudarshan Babu;Michael Maire,savarese@ttic.edu;mcallester@ttic.edu;sudarshan@ttic.edu;mmaire@uchicago.edu,3;6;3,,Reject,0,8,0.0,yes,9/25/19,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;University of Chicago,,-1;-1;-1;51,-1;-1;-1;9,m;m,usa,usa,y,3;1
4685,ICLR,2020,RISE and DISE: Two Frameworks for Learning from Time Series with Missing Data,Alberto Garcia-Duran;Robert West,alberto.duran@epfl.ch;robert.west@epfl.ch,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Time Series;Missing Data;RNN,-1;-1,-1;-1,m;m,NAN,NAN,n,
4686,ICLR,2020,Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models,Liu Yang;George Em Karniadakis,liu_yang@brown.edu;george_karniadakis@brown.edu,3;3;8,,Reject,0,7,0.0,yes,9/25/19,Brown University;Brown University,generative models;optimal transport;GANs;flow-based models,85;85,53;53,m;m,usa,usa,n,5
4687,ICLR,2020,Power up! Robust Graph Convolutional Network based on Graph Powering,Ming Jin;Heng Chang;Wenwu Zhu;Somayeh Sojoudi,jinming@berkeley.edu;changh@berkeley.edu;wwzhu@tsinghua.edu.cn;sojoudi@berkeley.edu,3;3;3,,Reject,0,7,0.0,yes,9/25/19,"University of California Berkeley;University of California Berkeley;Tsinghua University, Tsinghua University;University of California Berkeley",graph mining;graph neural network;adversarial robustness,-1;-1;4;-1,13;13;23;13,m;f,usa,usa,y,1;10;4
4688,ICLR,2020,DIME: AN INFORMATION-THEORETIC DIFFICULTY MEASURE FOR AI DATASETS,Peiliang Zhang;Huan Wang;Nikhil Naik;Caiming Xiong;Richard Socher,pez35@pitt.edu;huan.wang@salesforce.com;nnaik@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,3;3;1,,Reject,0,4,0.0,yes,9/25/19,University of Pittsburgh;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,Information Theory;Fano‚Äôs Inequality;Difficulty Measure;Donsker-Varadhan Representation;Theory,79;-1;-1;-1;-1,113;-1;-1;-1;-1,m;m,NAN,NAN,y,1
4689,ICLR,2020,Improved Detection of Adversarial Attacks via Penetration Distortion Maximization,Shai Rozenberg;Gal Elidan;Ran El-Yaniv,shairoz@cs.technion.ac.il;elidan@google.com;elyaniv@google.com,3;6;3,,Reject,0,3,0.0,yes,9/25/19,"Technion, Technion;Google;Google",Adversarial Examples;Adversarial Attacks;Adversarial Defense;White-Box threat models,27;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,4
4690,ICLR,2020,X-Forest: Approximate Random Projection Trees for Similarity Measurement,Yikai Zhao;Peiqing Chen;Zidong Zhao;Tong Yang;Jie Jiang;Bin Cui;Gong Zhang;Steve Uhlig,zyk@pku.edu.cn;chenpeiqing@pku.edu.cn;benkerd@pku.edu.cn;yangtongemail@gmail.com;jie.jiang@pku.edu.cn;bin.cui@pku.edu.cn;nicholas.zhang@huawei.com;steve.uhlig@qmul.ac.uk,1;3;3,,Reject,0,0,0.0,yes,9/25/19,Peking University;Peking University;Peking University;;Peking University;Peking University;Huawei Technologies Ltd.;Queen Mary University London,,14;14;14;-1;14;14;-1;-1,24;24;24;-1;24;24;-1;-1,m;m,europe,uk,y,
4691,ICLR,2020,Out-of-Distribution Image Detection Using the Normalized Compression Distance,Sehun Yu;Donga Lee;Hwanjo Yu,hunu12@postech.ac.kr;dongha0914@postech.ac.kr;hwanjoyu@postech.ac.kr,3;3;6,,Reject,0,5,0.0,yes,9/25/19,POSTECH;POSTECH;POSTECH,Out-of-Distribution Detection;Normalized Compression Distance;Convolutional Neural Networks,118;118;118,146;146;146,m;m,asia,kr,n,
4692,ICLR,2020,A Deep Recurrent Neural Network via Unfolding Reweighted l1-l1 Minimization,Huynh Van Luong;Duy Hung Le;Nikos Deligiannis,hvanluon@etrovub.be;dle@etrovub.be;ndeligia@etrovub.be,3;6;8,,Reject,0,3,0.0,yes,9/25/19,Vrije Universiteit Brussel;Vrije Universiteit Brussel;Vrije Universiteit Brussel,,-1;-1;-1,235;235;235,m;m,NAN,NAN,y,1
4693,ICLR,2020,Meta-Learning for Variational Inference,Ruqi Zhang;Yingzhen Li;Chris De Sa;Sam Devlin;Cheng Zhang,rz297@cornell.edu;yingzhen.li@microsoft.com;cdesa@cs.cornell.edu;sam.devlin@microsoft.com;cheng.zhang@microsoft.com,3;3;8,,Reject,0,7,0.0,yes,9/25/19,Cornell University;Microsoft;Cornell University;Microsoft;Microsoft,Variational inference;Meta-learning,7;-1;7;-1;-1,19;-1;19;-1;-1,f;f,NAN,NAN,y,6;11;5
4694,ICLR,2020,All Simulations Are Not Equal: Simulation Reweighing for Imperfect Information Games,Qucheng Gong;Yuandong Tian,qucheng@fb.com;yuandong@fb.com,1;3;3,,Reject,0,3,0.0,yes,9/25/19,Facebook;Facebook,Contract Bridge;Simulation;Imperfect Information Games;Reweigh;Belief Modeling,-1;-1,-1;-1,m;m,NAN,NAN,n,
4695,ICLR,2020,GRASPEL: GRAPH SPECTRAL LEARNING AT SCALE,Yongyu Wang;Zhiqiang Zhao;Zhuo Feng,yongyuw@mtu.edu;qzzhao@mtu.edu;zfeng12@stevens.edu,1;3;6,,Reject,0,4,0.0,yes,9/25/19,Michigan Technological University;Michigan Technological University;Stevens Institute of Technology,Spectral graph theory;graph learning;data clustering;t-SNE visualization,316;316;143,-1;-1;605,m;m,usa,usa,y,10
4696,ICLR,2020,Latent Variables on Spheres for Sampling and Inference,Deli Zhao;Jiapeng Zhu;Bo Zhang,zhaodeli@gmail.com;jengzhu0@gmail.com;zhangbo@xiaomi.com,6;1;6,,Reject,1,5,0.0,yes,9/25/19,Alibaba Group;Hong Kong University of Science and Technology;Xiaomi,variational autoencoder;generative adversarial network,-1;-1;-1,-1;47;-1,m;m,NAN,NAN,y,1;5
4697,ICLR,2020,Detecting Change in Seasonal Pattern via Autoencoder and Temporal Regularization,Raphael Fettaya;Dor Bank;Rachel Lemberg;Linoy Barel,raphaelfettaya@gmail.com;doban@microsoft.com;rlemberg@microsoft.com;t-libare@microsoft.com,1;3;1;3,,Reject,0,0,0.0,yes,9/25/19,Tel Aviv University;Microsoft;Microsoft;Microsoft,Autoencoder;Change Point Detection;Timeseries,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,
4698,ICLR,2020,Ladder Polynomial Neural Networks,Li-Ping Liu;Ruiyuan Gu;Xiaozhe Hu,liping.liu@tufts.edu;ruiyuan.gu@tufts.edu;xiaozhe.hu@tufts.edu,3;6;6,,Reject,0,3,0.0,yes,9/25/19,Tufts University;Tufts University;Tufts University,polynomial neural networks,194;194;194,139;139;139,m;m,usa,usa,n,
4699,ICLR,2020,Universal Safeguarded Learned Convex Optimization with Guaranteed Convergence,Howard Heaton;Xiaohan Chen;Zhangyang Wang;Wotao Yin,heaton@math.ucla.edu;chernxh@tamu.edu;atlaswang@tamu.edu;wotao.yin@alibaba-inc.com,3;3;3,,Reject,0,7,0.0,yes,9/25/19,"University of California, Los Angeles;Texas A&M;Texas A&M;Alibaba Group",L2O;learn to optimize;fixed point;machine learning;neural network;ADMM;LADMM;ALISTA;D-LADMM,-1;46;46;-1,17;177;177;-1,m;m,NAN,NAN,y,1;9
4700,ICLR,2020,Knockoff-Inspired Feature Selection via Generative Models,Marco F. Duarte;Siwei Feng,mduarte@ecs.umass.edu;siwei@umass.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst",feature selection;variable selection;knockoff variables;supervised learning,24;24,209;209,m;m,usa,usa,n,5
4701,ICLR,2020,Diagnosing the Environment Bias in Vision-and-Language Navigation,Yubo Zhang;Hao Tan;Mohit Bansal,zhangyb@cs.unc.edu;airsplay@cs.unc.edu;mbansal@cs.unc.edu,6;3;6,,Reject,0,8,2.0,yes,9/25/19,"University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",vision-and-language navigation;generalization;environment bias diagnosis,64;64;64,-1;-1;-1,m;m,NAN,NAN,n,10
4702,ICLR,2020,Entropy Minimization In Emergent Languages,Eugene Kharitonov;Rahma Chaabouni;Diane Bouchacourt;Marco Baroni,eugene.kharitonov@gmail.com;rchaabouni@fb.com;dianeb@fb.com;marco.baroni@unitn.it,1;6;6;6,,Reject,0,8,0.0,yes,9/25/19,Facebook;Facebook;Facebook;University of Trento,language emergence,-1;-1;-1;143,-1;-1;-1;307,m;m,europe,gr,n,4
4703,ICLR,2020,Improving SAT Solver Heuristics with Graph Networks and Reinforcement Learning,Vitaly Kurin;Saad Godil;Shimon Whiteson;Bryan Catanzaro,vitaliykurin@gmail.com;sgodil@nvidia.com;shimon.whiteson@gmail.com;bcatanzaro@nvidia.com,8;3;3,,Reject,1,5,0.0,yes,9/25/19,University of Oxford;NVIDIA;University of Oxford;NVIDIA,SAT;reinforcement learning;graph neural networks;heuristics;DQN;boolean satisfiability,-1;-1;46;-1,-1;-1;1;-1,m;m,NAN,NAN,n,1;10
4704,ICLR,2020,Toward Understanding The Effect of Loss Function on The Performance of Knowledge Graph Embedding,Mojtaba Nayyeri;Chengjin Xu;Yadollah Yaghoobzadeh;Hamed Shariat Yazdi;Jens Lehmann,nayyeri@cs.uni-bonn.de;xuc@cs.uni-bonn.de;yayaghoo@microsoft.com;shariat@cs.uni-bonn.de;jens.lehmann@cs.uni-bonn.de,6;3;1;3,,Reject,0,8,0.0,yes,9/25/19,University of Bonn;University of Bonn;Microsoft;University of Bonn;University of Bonn,Knowledge graph embedding;Translation based embedding;loss function;relation pattern,143;143;-1;143;143,106;106;-1;106;106,m;m,europe,uk,n,1;10
4705,ICLR,2020,Multi-Precision Policy Enforced Training (MuPPET) : A precision-switching strategy for quantised fixed-point training of CNNs,Aditya Rajagopal;Diederik A. Vink;Stylianos I. Venieris;Christos-Savvas Bouganis,aditya.rajagopal14@imperial.ac.uk;diederik.vink14@imperial.ac.uk;stelios.ven10@gmail.com;christos-savvas.bouganis@imperial.ac.uk,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Imperial College London;Imperial College London;Samsung;Imperial College London,,52;52;-1;52,10;10;-1;10,m;m,europe,uk,n,
4706,ICLR,2020,R2D2: Reuse & Reduce via Dynamic Weight Diffusion for Training Efficient NLP Models,Yi Tay;Aston Zhang;Shuai Zhang;Alvin Chan;Luu Anh Tuan;Siu Cheung Hui,ytay017@e.ntu.edu.sg;astonz@amazon.com;cheungshuai@outlook.com;guoweial001@e.ntu.edu.sg;tuanluu@csail.mit.edu;asschui@ntu.edu.sg,3;6;6,,Reject,0,3,0.0,yes,9/25/19,Nanyang Technological University;Amazon;Swiss Federal Institute of Technology;Nanyang Technological University;Massachusetts Institute of Technology;Nanyang Technological University,Deep Learning;Natural Language Processing,43;-1;-1;43;5;43,49;-1;-1;49;5;49,m;m,asia,sg,n,8;3
4707,ICLR,2020,Variational Autoencoders for Opponent Modeling in Multi-Agent Systems,Georgios Papoudakis;Stefano V. Albrecht,g.papoudakis@ed.ac.uk;s.albrecht@ed.ac.uk,3;1;6,,Reject,0,6,0.0,yes,9/25/19,University of Edinburgh;University of Edinburgh,reinforcement learning;multi-agent systems;representation learning,36;36,30;30,m;m,europe,uk,n,5
4708,ICLR,2020,SELF-KNOWLEDGE DISTILLATION ADVERSARIAL ATTACK,Ma Xiaoxiong[1];Wang Renzhi[1];Tian Cong;Dong Zeqian;Duan Zhenhua,maxrumi@163.com;shanicky4ever@gmail.com;tico_tools@163.com;zqdong@stu.xidian.edu.cn;zhenhua_duan@126.com,3;1;3,,Reject,1,6,0.0,yes,9/25/19,163;;163;Xidian University;126,Adversarial Examples;Transferability;black-box targeted attack;Distillation,-1;-1;-1;-1;-1,-1;-1;-1;919;-1,m;m,asia,in,n,1;4
4709,ICLR,2020,Continual Deep Learning by Functional Regularisation of Memorable Past,Pingbo Pan;Alexander Immer;Siddharth Swaroop;Runa Eschenhagen;Richard E Turner;Mohammad Emtiyaz Khan,pingbo.pan@student.uts.edu.au;alexander.immer@epfl.ch;ss2163@cam.ac.uk;reschenhagen@uni-osnabrueck.de;ret26@cam.ac.uk;emtiyaz.khan@riken.jp,1;1;6,,Reject,0,5,0.0,yes,9/25/19,University of Technology Sydney;Swiss Federal Institute of Technology Lausanne;University of Cambridge;Universit√§t Osnabr√ºck;University of Cambridge;RIKEN,Continual learning;deep learning;functional regularisation,73;-1;79;-1;79;-1,193;-1;3;-1;3;-1,m;m,NAN,NAN,y,
4710,ICLR,2020,Model Comparison of Beer data classification using an electronic nose,Mohammed Abdi;Aminat Adebiyi;Andrea Fasoli;Alberto Mannari;Ronald Labby;Luisa Bozano,mohammed.munir.abdi@ibm.com;aminat.adebiyi@ibm.com;andrea.fasoli@ibm.com;alberto.mannari@ibm.com;rlabby@us.ibm.com;lbozano@us.ibm.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,Electronic Nose;EVA;modular;olfaction;sensitivity;selectivity;analyte;temperature oscillated waveforms;features;fingerprint,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,
4711,ICLR,2020,Deep Multi-View Learning via Task-Optimal CCA,Heather D. Couture;Roland Kwitt;J.S. Marron;Melissa Troester;Charles M. Perou;Marc Niethammer,heather@pixelscientia.com;roland.kwitt@gmail.com;marron@unc.edu;troester@unc.edu;chuck_perou@med.unc.edu;mn@cs.unc.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,"Pixel Scientia Labs;University of Salzburg;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",multi-view;components analysis;CCA;representation learning;deep learning,-1;248;64;64;64;64,-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
4712,ICLR,2020,Unsupervised Representation Learning by Predicting Random Distances,Hu Wang;Guansong Pang;Chunhua Shen;Congbo Ma,hu.wang@adelaide.edu.au;pangguansong@gmail.com;chunhua.shen@adelaide.edu.au;201520121828@mail.scut.edu.cn,6;6;3,,Reject,0,4,0.0,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide;South China University of Technology,representation learning;unsupervised learning;anomaly detection;clustering,102;102;102;-1,120;120;120;501,m;m,NAN,NAN,n,
4713,ICLR,2020,Qgraph-bounded Q-learning: Stabilizing Model-Free Off-Policy Deep Reinforcement Learning,Sabrina Hoppe;Marc Toussaint,sabrina.hoppe@de.bosch.com;marc.toussaint@informatik.uni-stuttgart.de,6;3;1,,Reject,0,4,0.0,yes,9/25/19,Bosch;University of Stuttgart,deep learning;reinforcement learning;model-free reinforcement learning;Q-learning;DDPG,-1;118,297;292,f;m,europe,de,n,1;10
4714,ICLR,2020,Neural Maximum Common Subgraph Detection with Guided Subgraph Extraction,Yunsheng Bai;Derek Xu;Ken Gu;Xueqing Wu;Agustin Marinovic;Christopher Ro;Yizhou Sun;Wei Wang,yba@ucla.edu;derekqxu@ucla.edu;ken.qgu@gmail.com;shirley0@mail.ustc.edu.cn;amarinovic@ucla.edu;christopher.j.ro@gmail.com;yzsun@cs.ucla.edu;weiwang@cs.ucla.edu,3;3;6,,Reject,0,9,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;;University of Science and Technology of China;University of California, Los Angeles;;University of California, Los Angeles;University of California, Los Angeles",graph matching;maximum common subgraph;graph neural networks;subgraph extraction;graph alignment,-1;-1;-1;-1;-1;-1;-1;-1,17;17;-1;80;17;-1;17;17,m;f,usa,usa,n,10
4715,ICLR,2020,Blockwise Self-Attention for Long Document Understanding,Jiezhong Qiu;Hao Ma;Omer Levy;Scott Wen-tau Yih;Sinong Wang;Jie Tang,qiujz16@mails.tsinghua.edu.cn;gabe.hao.ma@gmail.com;omerlevy@gmail.com;scottyih@gmail.com;sinongwang@fb.com;jietang@tsinghua.edu.cn,3;6;6,,Reject,0,4,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Facebook;Tel Aviv University;Facebook AI Research;Facebook;Tsinghua University, Tsinghua University",BERT;Transformer,4;-1;30;-1;-1;4,23;-1;188;-1;-1;23,m;m,NAN,NAN,n,8
4716,ICLR,2020,GroSS Decomposition: Group-Size Series Decomposition for Whole Search-Space Training,Henry Howard-Jenkins;Yiwen Li;Victor Adrian Prisacariu,henryhj@robots.ox.ac.uk;kate@robots.ox.ac.uk;victor@robots.ox.ac.uk,3;6;3,,Reject,0,4,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,architecture search;block term decomposition;network decomposition;network acceleration;group convolution,46;46;46,1;1;1,m;m,europe,uk,n,1
4717,ICLR,2020,Emergence of Collective Policies Inside Simulations with Biased Representations,Jooyeon Kim;Alice Oh,jooyeon.kim@kaist.ac.kr;alice.oh@kaist.edu,3;1;3,,Reject,0,1,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;KAIST,collective policy;biased representation;model-based RL;simulation;imagination;virtual environment,-1;15,110;110,m;f,asia,in,n,
4718,ICLR,2020,On unsupervised-supervised risk and one-class neural networks,Christophe Cerisara,cerisara@loria.fr,3;3;6,,Reject,0,3,0.0,yes,9/25/19,University of Lorraine,unsupervised training;one-class models,-1,624,m,NAN,NAN,n,3;5
4719,ICLR,2020,Shifted Randomized Singular Value Decomposition,Ali Basirat,ali.basirat@lingfil.uu.se,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Uppsala University,SVD;PCA;Randomized Algorithms,194,102,m;m,europe,se,n,
4720,ICLR,2020,Encoding Musical Style with Transformer Autoencoders,Kristy Choi;Curtis Hawthorne;Ian Simon;Monica Dinculescu;Jesse Engel,kechoi@cs.stanford.edu;fjord@google.com;iansimon@google.com;noms@google.com;jesseengel@google.com,3;6,,Reject,0,4,0.0,yes,9/25/19,Stanford University;Google;Google;Google;Google,music generation;sequence-to-sequence model;controllable generation,5;-1;-1;-1;-1,4;-1;-1;-1;-1,f;m,NAN,NAN,n,8;3
4721,ICLR,2020,Adaptive Adversarial Imitation Learning,Yiren Lu;Jonathan Tompson;Sergey Levine,luyiren92@gmail.com;tompson@google.com;slevine@google.com,6;3;1,,Reject,0,7,0.0,yes,9/25/19,University of Pennsylvania;Google;Google,Imitation Learning;Reinforcement Learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y,4
4722,ICLR,2020,Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness,Haichao Zhang;Wei Xu,hczhang1@gmail.com;wei.xu@horizon.ai,6;3;3,,Reject,1,8,0.0,yes,9/25/19,Horizon Robotics;Horizon Robotics,adversarial training;adversarial robustness,-1;-1,-1;-1,m;f,NAN,NAN,n,4
4723,ICLR,2020,Do Image Classifiers Generalize Across Time?,Vaishaal Shankar;Achal Dave;Rebecca Roelofs;Deva Ramanan;Ben Recht;Ludwig Schmidt,vaishaal@berkeley.edu;achald@cs.cmu.edu;roelofs@cs.berkely.edu;deva@cs.cmu.edu;brecht@berkeley.edu;ludwigschmidt2@gmail.com,3;3;6,,Reject,0,5,0.0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;;Carnegie Mellon University;University of California Berkeley;University of California Berkeley,robustness;image classification;distribution shift,-1;1;-1;1;-1;-1,13;27;-1;27;13;-1,m;m,asia,in,n,
4724,ICLR,2020,Manifold Learning and Alignment with Generative Adversarial Networks,Jiseob Kim;Seungjae Jung;Hyundo Lee;Byoung-Tak Zhang,jkim@bi.snu.ac.kr;sjjung@bi.snu.ac.kr;hdlee@bi.snu.ac.kr;btzhang@bi.snu.ac.kr,6;6;6,,Reject,0,6,0.0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Generative Adversarial Networks;Manifold Learning;Manifold Alignment,39;39;39;39,64;64;64;64,m;m,asia,kr,y,5;4
4725,ICLR,2020,Count-guided Weakly Supervised Localization Based on Density Map,Ming Ma;Stephan Chalup;Fayeem Aziz;Yang Liu;Defu Cheng;Zhijian Zhou,mmingabc@outlook.com;stephan.chalup@newcastle.edu.au;mdfayeembin.aziz@uon.edu.au;liu15@mails.jlu.edu.cn;chengdefu@jlu.edu.cn;zhouzhijian@jlu.edu.cn,1;3;3,,Reject,0,0,0.0,yes,9/25/19,"Jilin University;University of Newcastle, Australia;University of Newcastle, Australia;Jilin University;Jilin University;Jilin University",Semi-supervised Learning;Weakly Supervised Localization;Variational Autoencoder;Density Map;Counting,-1;316;316;-1;-1;-1,-1;311;311;952;952;952,m;m,NAN,NAN,n,5
4726,ICLR,2020,Neural Phrase-to-Phrase Machine Translation,Jiangtao;Feng;Lingpeng Kong;Po-sen Huang;Chong;Wang;Da;Huang Jiayuan;Mao;Kan;Qiao;Dengyong;Zhou,lingpenk@google.com,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Google,,-1,-1,m;m,NAN,NAN,n,8;3
4727,ICLR,2020,Walking the Tightrope: An Investigation of the Convolutional Autoencoder Bottleneck,Ilja Manakov;Markus Rohm;Volker Tresp,ilja.manakov@med.uni-muenchen.de;markus.rohm@med.uni-muenchen.de;volker.tresp@siemens.com,6;3;3,,Reject,0,8,0.0,yes,9/25/19,Ludwig-Maximilians-Universit√§t M√ºnchen;Ludwig-Maximilians-Universit√§t M√ºnchen;Siemens Corporate Research,convolutional autoencoder;bottleneck;representation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,6;1
4728,ICLR,2020,LEX-GAN: Layered Explainable Rumor Detector Based on Generative Adversarial Networks,Mingxi Cheng;Yizhi Li;Shahin Nazarian;Paul Bogdan,mingxic@usc.edu;yizhi.li@bupt.edu.cn;shahin.nazarian@usc.edu;pbogdan@usc.edu,3;1;8;1,,Reject,0,8,0.0,yes,9/25/19,University of Southern California;Beijing University of Post and Telecommunication;University of Southern California;University of Southern California,explainable rumor detection;layered generative adversarial networks,36;-1;36;36,62;-1;62;62,f;m,usa,usa,n,5;4
4729,ICLR,2020,A New Multi-input Model with the Attention Mechanism for Text Classification,Junhao Qiu;Ronghua Shi;Fangfang Li (the corresponding author);Jinjing Shi;Wangmin Liao,qiujunhao@csu.edu.cn;shirh@csu.edu.cn;lifangfang@csu.edu.cn;shijinjing@csu.edu.cn;0909123117@csu.edu.cn,1;1;1,,Reject,0,0,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Natural Language Processing;Text Classification;Densent;Multi-input Model;Attention Mechanism,-1;-1;-1;-1;-1,299;299;299;299;299,m;m,NAN,NAN,n,8;2
4730,ICLR,2020,Stochastic Prototype Embeddings,Tyler R. Scott;Karl Ridgeway;Michael C. Mozer,tysc7237@colorado.edu;karl.ridgeway@colorado.edu;mcmozer@google.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,"University of Colorado, Boulder;University of Colorado, Boulder;Google",deep embeddings;stochastic embeddings;probabilistic embeddings;deep metric learning;few-shot learning,59;59;-1,123;123;-1,m;m,NAN,NAN,n,6
4731,ICLR,2020,GraphNVP: an Invertible Flow-based Model for Generating Molecular Graphs,Kaushalya Madhawa;Katsuhiko Ishiguro;Kosuke Nakago;Motoki Abe,kaushalya@net.c.titech.ac.jp;k.ishiguro.jp@ieee.org;nakago@preferred.jp;motoki@preferred.jp,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"Tokyo Institute of Technology;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Graph Neural Networks;graph generative model;invertible flow;graphNVP,168;-1;-1;-1,299;-1;-1;-1,m;m,NAN,NAN,n,10;5
4732,ICLR,2020,Contrastive Multiview Coding,Yonglong Tian;Dilip Krishnan;Phillip Isola,yonglong@mit.edu;dilipkay@google.com;phillipi@mit.edu,3;6;6,,Reject,0,3,0.0,yes,9/25/19,Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,Representation Learning;Unsupervised Learning;Self-supervsied Learning;Multiview Learning,5;-1;5,5;-1;5,m;m,usa,usa,n,
4733,ICLR,2020,RGTI:Response generation via templates integration for End to End dialog,Yuxin Zhang;Songyan Liu,zhangyuxin960625@gmail.com;anchor3l31@gmail.com,1;1;1;1,,Reject,0,0,0.0,yes,9/25/19,Beijing University of Post and Telecommunication;Chinese Academy of Sciences,End-to-end dialogue systems;transformer;pointer-generate network,-1;-1,-1;-1,m;m,asia,in,n,8
4734,ICLR,2020,Improving the Gating Mechanism of Recurrent Neural Networks,Albert Gua;Caglar Gulcehre;Tom le Paine;Razvan Pascanu;Matt Hoffman,gua@google.com;caglarg@google.com;mwhoffman@google.com;razp@google.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google,recurrent neural networks;LSTM;GRUs;gating mechanisms;deep learning;reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3
4735,ICLR,2020,Analyzing the Role of Model Uncertainty for Electronic Health Records,Michael W. Dusenberry;Dustin Tran;Edward Choi;Jonas Kemp;Jeremy Nixon;Ghassen Jerfel;Katherine Heller;Andrew M. Dai,dusenberrymw@google.com;trandustin@google.com;mp2893@gmail.com;jonasbkemp@google.com;jeremynixon@google.com;ghassen@google.com;kheller@google.com;adai@google.com,3;3,,Reject,2,3,0.0,yes,9/25/19,Google;Google;Korea Advanced Institute of Science and Technology;Google;Google;Google;Google;Google,medicine;uncertainty;neural networks;Bayesian;electronic health records,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;110;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11;7
4736,ICLR,2020,Leveraging Entanglement Entropy for Deep Understanding of  Attention Matrix in Text Matching,Peng Zhang;XiaoLiu Mao;XinDian Ma;BenYou Wang;Jing Zhang;Jun Wang;DaWei Song,pzhang@tju.edu.cn;xiaoliumao@tju.edu.cn;xindianma@tju.edu.cn;wang@dei.unipd.it;18738996120@163.com;jun.wang@cs.ucl.ac.uk;dwsong@bit.edu.cn,1;1;3,,Reject,0,3,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Universita' degli studi di Padova;163;University College London;Beijing Institute of Technology,Quantum entanglement entropy;Attention Matrix,39;39;39;-1;-1;52;-1,107;107;107;-1;-1;-1;661,m;m,NAN,NAN,n,8;1
4737,ICLR,2020,Superbloom: Bloom filter meets Transformer,John Anderson;Qingqing Huang;Walid Krichene;Steffen Rendle;Li Zhang,janders@google.com;qqhuang@google.com;walidk@google.com;srendle@google.com;liqzhang@google.com,6;3;3,,Reject,0,5,0.0,yes,9/25/19,Google;Google;Google;Google;Google,Bloom filter;Transformer;word pieces;contextual embeddings,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;3
4738,ICLR,2020,LEARNING TO IMPUTE: A GENERAL FRAMEWORK FOR SEMI-SUPERVISED LEARNING,Wei-Hong Li;Chuan-Sheng Foo;Hakan Bilen,w.h.li@ed.ac.uk;foo_chuan_sheng@i2r.a-star.edu.sg;hbilen@ed.ac.uk,3;3;3,,Reject,0,4,0.0,yes,9/25/19,"University of Edinburgh;Institute for Infocomm Research, A*STAR;University of Edinburgh",Semi-supervised Learning;Meta-Learning;Learning to label,36;-1;36,30;-1;30,m;m,europe,uk,n,1
4739,ICLR,2020,Reflection-based Word Attribute Transfer,Yoichi Ishibashi;Katsuhito Sudoh;Koichiro Yoshino;Satoshi Nakamura,ishibashi.yoichi.ir3@is.naist.jp;sudoh@is.naist.jp;koichiro@is.naist.jp;s-nakamura@is.naist.jp,6;6;6,,Reject,0,4,0.0,yes,9/25/19,"Nara Institute of Science and Technology, Japan;Nara Institute of Science and Technology, Japan;Nara Institute of Science and Technology, Japan;Nara Institute of Science and Technology, Japan",embedding;representation learning;analogy;geometry,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3;7
4740,ICLR,2020,ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks,Shuxuan Guo;Jose M. Alvarez;Mathieu Salzmann,shuxuan.guo@epfl.ch;josea@nvidia.com;mathieu.salzmann@epfl.ch,6;3,,Reject,0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;NVIDIA;Swiss Federal Institute of Technology Lausanne,Compact Network Training;Linear Expansion;Over-parameterization;Knowledge Transfer,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2;1
4741,ICLR,2020,PopSGD: Decentralized Stochastic Gradient Descent in the Population Model,Giorgi Nadiradze;Amirmojtaba Sabour;Aditya Sharma;Ilia Markov;Vitaly Aksenov;Dan Alistarh.,giorgi.nadiradze@ist.ac.at;amsabour79@gmail.com;adityasharma.2000.as@gmail.com;ilia.markov@ist.ac.at;aksenov.vitaly@gmail.com;dan.alistarh@ist.ac.at,3;1,,Reject,0,7,0.0,yes,9/25/19,Institute of Science and Technology Austria;;;Institute of Science and Technology Austria;ITMO University;Institute of Science and Technology Austria,Distributed machine learning;distributed optimization;decentralized parallel SGD;population protocols,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;480;-1,m;m,NAN,NAN,y,1
4742,ICLR,2020,Wide Neural Networks are Interpolating Kernel Methods: Impact of Initialization on Generalization,Manuel Nonnenmacher;David Reeb;Ingo Steinwart,manuel.nonnenmacher@de.bosch.com;david.reeb@de.bosch.com;ingo.steinwart@mathematik.uni-stuttgart.de,1;1;6;3,,Reject,0,5,0.0,yes,9/25/19,Bosch;Bosch;University of Stuttgart,overparametrization;generalization;initialization;gradient descent;kernel methods;deep learning theory,-1;-1;118,297;297;292,m;m,europe,de,y,1
4743,ICLR,2020,Improved Mutual Information Estimation,Youssef Mroueh*;Igor Melnyk*;Pierre Dognin*;Jerret Ross*;Tom Sercu*,mroueh@us.ibm.com;igor.melnyk@ibm.com;pdognin@us.ibm.com;rossja@us.ibm.com;tom.sercu@gmail.com,1;3;3;6,,Reject,0,7,0.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;Facebook,mutual information;variational bound;kernel methods;Neural estimators;mutual information maximization;self-supervised learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
4744,ICLR,2020,Confidence Scores Make Instance-dependent Label-noise Learning Possible,Antonin Berthon;Bo Han;Gang Niu;Tongliang Liu;Masashi Sugiyama,berthon.antonin@gmail.com;bo.han@riken.jp;gang.niu@riken.jp;tongliang.liu@sydney.edu.au;sugi@k.u-tokyo.ac.jp,8;1;8,,Reject,0,10,0.0,yes,9/25/19,RIKEN;RIKEN;RIKEN;University of Sydney;The University of Tokyo,Instance-dependent label noise;Deep learning,-1;-1;-1;64;64,-1;-1;-1;60;36,m;m,NAN,NAN,n,8
4745,ICLR,2020,Is Deep Reinforcement Learning Really Superhuman on Atari? Leveling the playing field,Marin Toromanoff;Emilie Wirbel;Fabien Moutarde,marin.toromanoff@mines-paristech.fr;emilie.wirbel@valeo.com;fabien.moutarde@mines-paristech.fr,6;3;3,,Reject,0,8,0.0,yes,9/25/19,Mines ParisTech;Valeo;Mines ParisTech,Reinforcement Learning;Deep Learning;Atari benchmark;Reproducibility,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4746,ICLR,2020,A Bilingual Generative Transformer for Semantic Sentence Embedding,John Wieting;Graham Neubig;Taylor Berg-Kirkpatrick,jwieting@cs.cmu.edu;gneubig@cs.cmu.edu;tberg@eng.ucsd.edu,3;6;3,,Reject,0,5,0.0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;University of California, San Diego",sentence embedding;semantic similarity;multilingual;latent variables;vae,1;1;-1,27;27;31,m;m,usa,usa,n,8;3
4747,ICLR,2020,TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph,Feiliang Ren,renfeiliang@cse.neu.edu.cn,1;1;3,,Reject,0,3,0.0,yes,9/25/19,Northeastern University,Chinese knowledge graph building,16,906,m;m,usa,usa,n,10
4748,ICLR,2020,Wasserstein Adversarial Regularization (WAR) on label noise,Bharath Damodaran;Kilian Fatras;Sylvain Lobry;R√©mi Flamary;Devis Tuia;Nicolas Courty,bharath-bhushan.damodaran@irisa.fr;kilian.fatras@irisa.fr;sylvain.lobry@wur.nl;remi.flamary@unice.fr;devis.tuia@wur.nl;ncourty@irisa.fr,8;3;6,,Reject,0,5,0.0,yes,9/25/19,IRISA;IRISA;Uni Wageningen;Universit√© C√¥te d'Azur;Uni Wageningen;IRISA,Label Noise;Adversarial regularization;Wasserstein,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,europe,fr,y,4
4749,ICLR,2020,Enhancing the Transformer with explicit relational encoding for math problem solving,Imanol Schlag;Paul Smolensky;Roland Fernandez;Nebojsa Jojic;J√ºrgen Schmidhuber;Jianfeng Gao,imanol@idsia.ch;paul.smolensky@gmail.com;rfernand@microsoft.com;jojic@microsoft.com;juergen@idsia.ch;jfgao@microsoft.com,3;6;6,,Reject,1,4,0.0,yes,9/25/19,IDSIA;Microsoft;Microsoft;Microsoft;IDSIA;Microsoft,Tensor Product Representation;Transformer;Mathematics Dataset;Attention,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
4750,ICLR,2020,Constant Curvature Graph Convolutional Networks,Gregor Bachmann;Gary B√©cigneul;Octavian-Eugen Ganea,gregorb@student.ethz.ch;garyb@mit.edu;oct@mit.edu,1;8;6,,Reject,0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,graph convolutional neural networks;hyperbolic spaces;gyrvector spaces;riemannian manifolds;graph embeddings,-1;5;5,-1;5;5,m;m,usa,usa,y,1;10
4751,ICLR,2020,Plan2Vec: Unsupervised Representation Learning by Latent Plans,Ge Yang;Amy Zhang;Ari Morcos;Joelle Pineau;Pieter Abbeel;Roberto Calandra,yangge1987@gmail.com;amyzhang2011@gmail.com;arimorcos@gmail.com;jpineau@cs.mcgill.ca;pabbeel@cs.berkeley.edu;rcalandra@fb.com,3;1;1,,Reject,0,5,0.0,yes,9/25/19,Massachusetts Institute of Technology;University of California Berkeley;Facebook;McGill University;University of California Berkeley;Facebook,Unsupervised Learning;Reinforcement Learning;Manifold Learning,-1;-1;-1;102;-1;-1,-1;13;-1;42;13;-1,m;m,NAN,NAN,n,10
4752,ICLR,2020,Generating Dialogue Responses From A Semantic Latent Space,Wei-Jen Ko;Avik Ray;Yilin Shen;Hongxia Jin,wjko@outlook.com;avik.r@samsung.com;yilin.shen@samsung.com;hongxia.jin@samsung.com,3;3;3,,Reject,0,3,1.0,yes,9/25/19,"University of Texas, Austin;Samsung;Samsung;Samsung",dialog;chatbot;open domain conversation;CCA,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,
4753,ICLR,2020,Learning Key Steps to Attack Deep Reinforcement Learning Agents,Chien-Min Yu;Hsuan-Tien Lin,r07922080@csie.ntu.edu.tw;htlin@csie.ntu.edu.tw,3;3;1,,Reject,0,4,0.0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University,deep reinforcement learning;adversarial attacks,43;43,49;49,m;m,asia,sg,n,4
4754,ICLR,2020,"If MaxEnt RL is the Answer, What is the Question?",Benjamin Eysenbach;Sergey Levine,beysenba@cs.cmu.edu;svlevine@eecs.berkeley.edu,8;3;3,,Reject,0,14,0.0,yes,9/25/19,Carnegie Mellon University;University of California Berkeley,reinforcement learning;maximum entropy;POMDP,1;-1,27;13,m;m,usa,usa,y,
4755,ICLR,2020,Learning to Control Latent Representations for Few-Shot Learning of Named Entities,Omar U. Florez;Erik Mueller,omar.florez@aggiemail.usu.edu;erikmueller@capitalone.com,3;1;1,,Reject,0,0,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Capital One Bank,Memory management;neuroscience;reinforcement learning;learning with small data,-1;-1,299;-1,m;m,NAN,NAN,n,6;3
4756,ICLR,2020,Variational Hyper RNN for Sequence Modeling,Ruizhi Deng;Yanshuai Cao;Bo Chang;Leonid Sigal;Greg Mori;Marcus Brubaker,ruizhid@sfu.ca;yanshuaicao@gmail.com;bchang@stat.ubc.ca;lsigal@cs.ubc.ca;mori@cs.sfu.ca;marcus.brubaker@borealisai.com,6;6;6,,Reject,0,9,0.0,yes,9/25/19,Simon Fraser University;;University of British Columbia;University of British Columbia;Simon Fraser University;Borealis AI,variational autoencoder;hypernetwork;recurrent neural network;time series,52;-1;64;64;52;-1,272;-1;34;34;272;-1,m;m,NAN,NAN,n,
4757,ICLR,2020,Weighted Empirical Risk Minimization: Transfer Learning based on Importance Sampling,Robin Vogel;Mastane Achab;Charles Tillier;St√©phan Cl√©men√ßon,robin.vogel@telecom-paris.fr;mastane.achab@telecom-paris.fr;charles.tillier@telecom-paris.fr;stephan.clemencon@telecom-paris.fr,3;3;3,,Reject,0,4,0.0,yes,9/25/19,T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris,statistical learning theory;importance sampling;positive unlabeled (PU) learning;selection bias,-1;-1;-1;-1,187;187;187;187,f;m,NAN,NAN,y,6;1
4758,ICLR,2020,Provenance detection through learning transformation-resilient watermarking,Jamie Hayes;Krishnamurthy Dvijotham;Yutian Chen;Sander Dieleman;Pushmeet Kohli;Norman Casagrande,j.hayes@cs.ucl.ac.uk;dvij@google.com;yutianc@google.com;sedielem@google.com;pushmeet@google.com;ncasagrande@google.com,1;6;8,,Reject,0,3,0.0,yes,9/25/19,University College London;Google;Google;Google;Google;Google,watermarking;provenance detection,52;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
4759,ICLR,2020,Underwhelming Generalization Improvements From Controlling Feature Attribution,Joseph D Viviano;Becks Simpson;Francis Dutil;Yoshua Bengio;Joseph Paul Cohen,joseph@viviano.ca;becks.simpson@imagia.com;francis.dutil@imagia.com;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Montreal;Imagia;Imagia;Mila;Stanford University,interpretability;medical;generalization;saliency,118;-1;-1;143;5,85;-1;-1;336;4,m;m,usa,usa,n,1
4760,ICLR,2020,Combining graph and sequence information to learn protein representations,Hassan Kan√©;Mohamed Coulibali;Pelkins Ajanoh;Ali Abdalla,hassanmohamed@alum.mit.edu;mohamed-konoufo.coulibali.1@ulaval.ca;pelkins@alum.mit.edu;aabdalla@alum.mit.edu,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Massachusetts Institute of Technology;Laval university;Massachusetts Institute of Technology;Massachusetts Institute of Technology,NLP;Protein;Representation Learning,5;-1;5;5,5;272;5;5,m;m,usa,usa,n,
4761,ICLR,2020,Sensible adversarial learning,Jungeum Kim;Xiao Wang,kim2712@purdue.edu;wangxiao@purdue.edu,3;6;8,,Reject,2,9,0.0,yes,9/25/19,Purdue University;Purdue University,adversarial learning;deep neural networks;trade-off;margins;sensible reversion;sensible robustness,24;24,88;88,m;m,usa,usa,y,4
4762,ICLR,2020,YaoGAN: Learning Worst-case Competitive Algorithms from Self-generated Inputs,Goran Zuzic;Di Wang;Aranyak Mehta;D. Sivakumar,zuza777@gmail.com;wadi@google.com;aranyak@google.com;siva@google.com,6;3;3,,Reject,0,8,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1;5;4
4763,ICLR,2020,Learning to Remember from a Multi-Task Teacher,Yuwen Xiong;Mengye Ren;Raquel Urtasun,yuwen@cs.toronto.edu;mren@cs.toronto.edu;urtasun@uber.com,1;3;8,,Reject,0,6,0.0,yes,9/25/19,University of Toronto;University of Toronto;Uber,Meta-learning;sequential learning;catastrophic forgetting,18;18;-1,18;18;-1,m;f,southamerica,br,n,6
4764,ICLR,2020,Pretraining boosts out-of-domain robustness for pose estimation,Alexander Mathis;Mert Y√ºksekg√∂n√ºl;Byron Rogers;Matthias Bethge;Mackenzie W. Mathis,amathis@fas.harvard.edu;mertyuksekgonul@gmail.com;byron@performancegenetics.com;matthias.bethge@uni-tuebingen.de;mathis@rowland.harvard.edu,1;1,,Reject,1,3,0.0,yes,9/25/19,Harvard University;Bogazici University;Performancegenetics;University of Tuebingen;Harvard University,pose estimation;robustness;out-of-domain;transfer learning,52;316;-1;143;52,7;672;-1;91;7,m;f,usa,usa,n,6;2;1
4765,ICLR,2020,Self-Induced Curriculum Learning in Neural Machine Translation,Dana Ruiter;Cristina Espa√±a-Bonet;Josef van Genabith,druiter@lsv.uni-saarland.de;cristinae@dfki.de;josef.van_genabith@dfki.de,6;3;1,,Reject,0,4,0.0,yes,9/25/19,Saarland University;German Research Center for AI;German Research Center for AI,curriculum learning;neural machine translation;self-supervised learning,92;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,3
4766,ICLR,2020,Adapt-to-Learn: Policy Transfer in Reinforcement Learning,Girish Joshi;Girish Chowdhary,girishj2@illinois.edu;girishc@illinois.edu,1;6;6,,Reject,0,1,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Transfer Learning;Reinforcement Learning;Adaptation,-1;-1,-1;-1,m;m,usa,usa,n,1
4767,ICLR,2020,The Surprising Behavior Of Graph Neural Networks,Vivek Kothari;Catherine Tong;Nicholas Lane,vivek.kothari@cs.ox.ac.uk;eu.tong@cs.ox.ac.uk;nicholas.lane@cs.ox.ac.uk,6;3;1,,Reject,0,4,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,Graph Neural Networks;Graph Toplogy;Noise;Attributed Networks,46;46;46,1;1;1,m;m,europe,uk,n,10
4768,ICLR,2020,On the Reflection of Sensitivity in the Generalization Error,Mahsa Forouzesh;Farnood Salehi;Patrick Thiran,mahsa.forouzesh@epfl.ch;farnood.salehi@epfl.ch;patrick.thiran@epfl.ch,3;3,,Reject,0,5,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Generalization Error;Sensitivity Analysis;Deep Neural Networks;Bias-variance Decomposition,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,1
4769,ICLR,2020,Bio-Inspired Hashing for Unsupervised Similarity Search,Chaitanya K. Ryali;John J. Hopfield;Dmitry Krotov,rckrishn@eng.ucsd.edu;hopfield@princeton.edu;krotov@ibm.com,6;6;3,,Reject,0,0,1.0,yes,9/25/19,"University of California, San Diego;Princeton University;International Business Machines",unsupervised learning;similarity search;neuroscience,-1;30;-1,31;6;-1,m;m,NAN,NAN,n,
4770,ICLR,2020,Neural Program Synthesis By Self-Learning,Yifan Xu;Lu Dai;Udaikaran Singh;Kening Zhang;Zhuowen Tu,yix081@ucsd.edu;dldaisy@mail.ustc.edu.cn;u1singh@ucsd.edu;kez040@ucsd.edu;ztu@ucsd.edu,3;1;3,,Reject,0,3,2.0,yes,9/25/19,"University of California, San Diego;University of Science and Technology of China;University of California, San Diego;University of California, San Diego;University of California, San Diego",Neural Program Synthesis;Reinforcement Learning;Deep learning;Self-Learning,-1;-1;-1;-1;-1,31;80;31;31;31,m;m,usa,usa,n,
4771,ICLR,2020,The Variational InfoMax AutoEncoder,Vinenzo Crescimanna;Bruce Graham,vincenzo.crescimanna1@stir.ac.uk;bruce.graham@stir.ac.uk,3;6;1,,Reject,0,3,0.0,yes,9/25/19,University of Stirling;University of Stirling,autoencoder;information theory;infomax;vae,-1;-1,350;350,m;m,NAN,NAN,n,5
4772,ICLR,2020,Neural Network Out-of-Distribution Detection for Regression Tasks,Geoff Pleiss;Amauri Souza;Joseph Kim;Boyi Li;Kilian Q. Weinberger,geoff@cs.cornell.edu;ahd64@cornell.edu;jk2569@cornell.edu;bl728@cornell.edu;kqw4@cornell.edu,3;3;1;1,,Reject,0,5,0.0,yes,9/25/19,Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,Out-of-distribution;deep learning;regression,7;7;7;7;7,19;19;19;19;19,m;m,usa,usa,n,5
4773,ICLR,2020,Stein Self-Repulsive Dynamics: Benefits from Past Samples,Mao Ye;Tongzheng Ren;Qiang Liu,lushleaf21@gmail.com;rtz19970824@gmail.com;lqiang@cs.utexas.edu,6;3;6,,Reject,0,8,0.0,yes,9/25/19,"University of Texas, Austin;;University of Texas, Austin",Approximate Inference;Markov Chain Monte Carlo;Stein Variational Gradient Descent,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y,
4774,ICLR,2020,Mesh-Free Unsupervised Learning-Based PDE Solver of Forward and Inverse problems,Leah Bar;Nir Sochen,barleah.libra@gmail.com;sochen@tauex.tau.ac.il,6;3;3,,Reject,0,5,0.0,yes,9/25/19,Tel Aviv University;Tel Aviv University,PDEs;forward problems;inverse problems;unsupervised learning;deep networks;EIT,30;30,188;188,f;m,europe,il,n,
4775,ICLR,2020,Gaussian Conditional Random Fields for Classification,Andrija Petrovic;Mladen Nikolic;Milos Jovanovic;Boris Delibasic,aapetrovic@mas.bg.ac.rs;nikolic@matf.bg.ac.rs;milos.jovanovic@fon.bg.ac.rs;boris.delibasic@fon.bg.ac.rs,1;6;6,,Reject,0,4,0.0,yes,9/25/19,University of Belgrade - Faculty of Organizational Sciences;University of Belgrade - Faculty of Organizational Sciences;University of Belgrade - Faculty of Organizational Sciences;University of Belgrade - Faculty of Organizational Sciences,Structured classification;Gaussian conditional random fields;Empirical Bayes;Local variational approximation;discriminative graph-based model,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,11;10
4776,ICLR,2020,Visual Hide and Seek,Boyuan Chen;Shuran Song;Hod Lipson;Carl Vondrick,bchen@cs.columbia.edu;shurans@cs.columbia.edu;hod.lipson@columbia.edu;vondrick@cs.columbia.edu,3;3;8,,Reject,0,6,0.0,yes,9/25/19,Columbia University;Columbia University;Columbia University;Columbia University,Embodied Learning;Self-supervised Learning;Reinforcement Learning,24;24;24;24,16;16;16;16,m;m,usa,usa,n,
4777,ICLR,2020,Supervised learning with incomplete data via sparse representations,Cesar F. Caiafa;Ziyao Wang;Jordi Sol√©-Casals;Qibin Zhao,ccaiafa@gmail.com;zy_wang@seu.edu.cn;jordi.sole@uvic.cat;qibin.zhao@riken.jp,6;6;1,,Reject,0,4,0.0,yes,9/25/19,CONICET;Southeast University;University of Victoria;RIKEN,Incomplete data;supervised learning;sparse representations,-1;-1;194;-1,-1;570;449;-1,m;m,NAN,NAN,y,
4778,ICLR,2020,Transfer Active Learning For Graph Neural Networks,Shengding Hu;Meng Qu;Zhiyuan Liu;Jian Tang,hsd16@mails.tsinghua.edu.cn;meng.qu@umontreal.ca;liuzy@tsinghua.edu.cn;jian.tang@hec.ca,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;University of Montreal;Tsinghua University, Tsinghua University;HEC Montreal",Active Learning;Graph Neural Networks;Transfer Learning;Reinforcement Learning,4;118;4;-1,23;85;23;-1,m;m,canada,ca,n,6;1;10
4779,ICLR,2020,Equivariant Entity-Relationship Networks,Devon Graham;Siamak Ravanbakhsh,drgraham@cs.ubc.ca;siamak@cs.mcgill.ca,3;3;3;8;3,,Reject,0,11,0.0,yes,9/25/19,University of British Columbia;McGill University,deep learning;relational model;knowledge graph;exchangeability;equivariance,64;102,34;42,m;m,canada,ca,y,1;10
4780,ICLR,2020,Assessing Generalization in TD methods for Deep Reinforcement Learning,Emmanuel Bengio;Doina Precup;Joelle Pineau,bengioe@gmail.com;dprecup@cs.mcgill.ca;jpineau@cs.mcgill.ca,3;6;6,,Reject,0,5,0.0,yes,9/25/19,McGill University;McGill University;McGill University,reinforcement learning;deep learning;generalization,102;102;102,42;42;42,m;f,canada,ca,n,1
4781,ICLR,2020,Chordal-GCN: Exploiting sparsity in training large-scale graph convolutional networks,Xin Jiang*;Kewei Cheng*;Song Jiang*;Yizhou Sun,jiangxjames@ucla.edu;viviancheng@cs.ucla.edu;songjiang@cs.ucla.edu;yzsun@cs.ucla.edu,6;1;3,,Reject,0,4,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",graph convolutional network;semi-supervised learning,-1;-1;-1;-1,17;17;17;17,m;f,usa,usa,n,10
4782,ICLR,2020,Certifying Distributional Robustness using Lipschitz Regularisation,Zac Cranko;Zhan Shi;Xinhua Zhang;Simon Kornblith;Richard Nock,zac.cranko@anu.edu.au;zshi22@uic.edu;zhangx@uic.edu;skornblith@google.com;richard.nock@data61.csiro.au,6;3;6,,Reject,0,6,0.0,yes,9/25/19,"Australian National University;University of Illinois, Chicago;University of Illinois, Chicago;Google;CSIRO",kernel method;adversarial learning;distributionally robust optimization,102;-1;-1;-1;-1,50;-1;-1;-1;-1,m;m,asia,in,y,4
4783,ICLR,2020,"Continuous Control with Contexts, Provably",Simon Du;Mengdi Wang;Ruosong Wang;Lin F. Yang,ssdu@ias.edu;mengdiw@princeton.edu;ruosongw@andrew.cmu.edu;linyang@ee.ucla.edu,3;1;6,,Reject,0,5,0.0,yes,9/25/19,"Institue for Advanced Study, Princeton;Princeton University;Carnegie Mellon University;University of California, Los Angeles",continuous control;learning;context,-1;30;1;-1,-1;6;27;17,m;m,usa,usa,y,1
4784,ICLR,2020,Using Hindsight to Anchor Past Knowledge in Continual Learning,Arslan Chaudhry;Albert Gordo;David Lopez-Paz;Puneet K. Dokania;Philip Torr,arslan.chaudhry@eng.ox.ac.uk;agordo@fb.com;david@lopezpaz.org;puneet@robots.ox.ac.uk;philip.torr@eng.ox.ac.uk,6;6;6,,Reject,2,5,1.0,yes,9/25/19,University of Oxford;Facebook;Facebook;University of Oxford;University of Oxford,Continual Learning;Lifelong Learning;Catastrophic Forgetting,46;-1;-1;46;46,1;-1;-1;1;1,m;m,europe,uk,n,6
4785,ICLR,2020,Solving single-objective tasks by preference multi-objective reinforcement learning,Jinsheng Ren;Shangqi Guo;Feng Chen,rjs17@mails.tsinghua.edu.cn;gsq15@mails.tsinghua.edu.cn;chenfeng@mail.tsinghua.edu.cn,3;1,,Reject,0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",reinforcement learning;single-objective tasks;multi-objectivization,4;4;4,23;23;23,m;m,NAN,NAN,y,1
4786,ICLR,2020,Transfer Alignment Network for Double Blind Unsupervised Domain Adaptation,Huiwen Xu;U Kang,xuhuiwen33@gmail.com;ukang@snu.ac.kr,1;1;1,,Reject,0,3,0.0,yes,9/25/19,Seoul National University;Seoul National University,unsupervised domain adaptation;double blind domain adaptation,39;39,64;64,m;m,asia,kr,n,6
4787,ICLR,2020,Policy Optimization by Local Improvement through Search,Jialin Song;Joe Wenjie Jiang;Amir Yazdanbakhsh;Ebrahim Songhori;Anna Goldie;Navdeep Jaitly;Azalia Mirhoseini,jssong@caltech.edu;wenjiej@google.com;ayazdan@google.com;esonghori@google.com;agoldie@google.com;ndjaitly@google.com;azalia@google.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,California Institute of Technology;Google;Google;Google;Google;Google;Google,policy learning;imitation learning,143;-1;-1;-1;-1;-1;-1,2;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,y,
4788,ICLR,2020,Regularly varying representation for sentence embedding,Hamid Jalalzai;Pierre Colombo;Chlo√© Clavel;Eric Gaussier;Giovanna Varni;Emmanuel Vignon;Anne Sabourin,hamid.jalalzai@telecom-paris.fr;pierre.colombo@telecom-paris.fr;chloe.clavel@telecom-paris.fr;giovanna.varni@telecom-paris.fr;emmanuel.vignon@fr.ibm.com;anne.sabourin@telecom-paris.fr,3;1;3,,Reject,0,3,0.0,yes,9/25/19,T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris;International Business Machines;T√©l√©com Paris,extreme value theory;classification;supvervised learning;data augmentation;representation learning,-1;-1;-1;-1;-1;-1,187;187;187;187;-1;187,m;f,NAN,NAN,y,3;1
4789,ICLR,2020,Statistical Verification of General Perturbations by Gaussian Smoothing,Marc Fischer;Maximilian Baader;Martin Vechev,marcfisc@student.ethz.ch;mbaader@inf.ethz.ch;martin.vechev@inf.ethz.ch,3;3;3,,Reject,0,4,1.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,adversarial robustness;certified network;randomised smoothing;geometric perturbations,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
4790,ICLR,2020,Learning to Anneal and Prune Proximity Graphs for Similarity Search,Minjia Zhang;Wenhan Wang;Yuxiong He,minjiaz@microsoft.com;wenhanw@microsoft.com;yuxhe@microsoft.com,6;6;8,,Reject,0,4,0.0,yes,9/25/19,Microsoft;Microsoft;Microsoft,Similarity search;Proximity graph;Learning to prune;Edge heterogeneity;Annealing;Efficiency,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,10
4791,ICLR,2020,Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport,Tengfei Ma;Jie Chen,tengfei.ma1@ibm.com;chenjie@us.ibm.com,3;6;6,,Reject,0,6,0.0,yes,9/25/19,International Business Machines;International Business Machines,Unsupervised learning;hierarchical representation learning;graph neural networks,-1;-1,-1;-1,m;f,NAN,NAN,y,10
4792,ICLR,2020,Bayesian Variational Autoencoders for Unsupervised Out-of-Distribution Detection,Erik Daxberger;Jos√© Miguel Hern√°ndez-Lobato,ead54@cam.ac.uk;jmh233@cam.ac.uk,3;3;3,,Reject,0,6,0.0,yes,9/25/19,University of Cambridge;University of Cambridge,variational autoencoders;out-of-distribution detection;stochastic gradient MCMC,79;79,3;3,m;m,europe,uk,n,11;5
4793,ICLR,2020,Robust Instruction-Following in a Situated Agent via Transfer-Learning from Text,Felix Hill;Sona Mokra;Nathaniel Wong;Tim Harley,felixhill@google.com;sonka@google.com;nathanielwong@google.com;tharley@google.com,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google,agent;language;3D;simulation;policy;instruction;transfer,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6;8;3
4794,ICLR,2020,Fully Polynomial-Time Randomized Approximation Schemes for Global Optimization of High-Dimensional Folded Concave Penalized Generalized Linear Models,Charles Hernandez;Hungyi Lee;Hongchen Liu,cdhernandez@ufl.edu;hungyilee@ufl.edu;hliu@ise.ufl.edu,3;3;8,,Reject,0,3,0.0,yes,9/25/19,University of Florida;University of Florida;University of Florida,statistical learning;FPRAS;global optimization;folded concave penalty;GLM;high dimensional learning,168;168;168,174;174;174,m;m,usa,usa,y,9
4795,ICLR,2020,MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS,Ronan Perry;Tyler M. Tomita;Jesse Patsolic;Benjamin Falk;Joshua Vogelstein,rperry27@jhu.edu;ttomita2@jhmi.edu;jpatsolic@jhu.edu;falk.ben@jhu.edu;jovo@jhu.edu,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Johns Hopkins University;;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,machine learning;structured learning;projections;structured data;images;classification,73;-1;73;73;73,12;-1;12;12;12,m;m,usa,usa,n,10
4796,ICLR,2020,Granger Causal Structure Reconstruction from Heterogeneous Multivariate Time Series,Yunfei Chu;Xiaowei Wang;Chunyan Feng;Jianxin Ma;Jingren Zhou;Hongxia Yang,yfchu@bupt.edu.cn;daemon.wxw@alibaba-inc.com;cyfeng@bupt.edu.cn;jason.mjx@alibaba-inc.com;jingren.zhou@alibaba-inc.com;yang.yhx@alibaba-inc.com,3;8;6,,Reject,0,4,0.0,yes,9/25/19,Beijing University of Post and Telecommunication;Alibaba Group;Beijing University of Post and Telecommunication;Alibaba Group;Alibaba Group;Alibaba Group,causal inference;Granger causality;time series;inductive;LSTM;attention,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8
4797,ICLR,2020,Towards Disentangling Non-Robust and Robust Components in Performance Metric,Yujun Shi;Benben Liao;Guangyong Chen;Yun Liu;Ming-ming Cheng;Jiashi Feng,shiyujun1016@gmail.com;bliao@tencent.com;gycchen@tencent.com;nk12csly@mail.nankai.edu.cn;cmm@nankai.edu.cn;elefjia@nus.edu.sg,1;1;3,,Reject,0,5,0.0,yes,9/25/19,National University of Singapore;Tencent AI Lab;Tencent AI Lab;Nankai University;Nankai University;National University of Singapore,adversarial examples;robust machine learning,17;-1;-1;-1;-1;17,25;-1;-1;366;366;25,m;m,asia,sg,y,1;4
4798,ICLR,2020,Distributed Training Across the World,Ligeng Zhu;Yao Lu;Yujun Lin;Song Han,ligeng@mit.edu;luyao11175@gmail.com;yujunlin@mit.edu;songhan@mit.edu,3;3;6,,Reject,0,7,0.0,yes,9/25/19,Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Distributed Training;Bandwidth,5;-1;5;5,5;-1;5;5,m;m,usa,usa,n,
4799,ICLR,2020,Risk Averse Value Expansion for Sample Efficient and Robust Policy Learning,Bo Zhou;Fan Wang;Hongsheng Zeng;Hao Tian,zhoubo01@baidu.com;wangfan04@baidu.com;zenghongsheng@baidu.com;tianhao@baidu.com,3;3;6;3,,Reject,0,4,0.0,yes,9/25/19,Baidu;Baidu;Baidu;Baidu,reinforcement learning;model-based RL;risk-sensitive;sample efficiency,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
4800,ICLR,2020,MANAS: Multi-Agent Neural Architecture Search,Fabio Maria Carlucci;Pedro M Esperan√ßa;Marco Singh;Victor Gabillon;Antoine Yang;Hang Xu;Zewei Chen;Jun Wang,fabiom.carlucci@gmail.com;pedro.esperanca@huawei.com;marco.singh@huawei.com;victor.gabillon@huawei.com;antoineyang3@gmail.com;xu.hang@huawei.com;chen.zewei@huawei.com;w.j@huawei.com,6;3;6,,Reject,0,4,0.0,yes,9/25/19,Facebook;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Neural Architecture Search;NAS;AutoML;Computer Vision,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,10
4801,ICLR,2020,Neural Architecture Search by Learning Action Space for Monte Carlo Tree Search,Linnan Wang;Saining Xie;Teng Li;Rodrigo Fonseca;Yuandong Tian,linnan_wang@brown.edu;s9xie@fb.com;yuandong@fb.com;tengli@fb.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Brown University;Facebook;Facebook;Facebook,MCTS;Neural Architecture Search;Search,85;-1;-1;-1,53;-1;-1;-1,m;m,NAN,NAN,y,11
4802,ICLR,2020,A multi-task U-net for segmentation with lazy labels,Rihuan Ke;Aur√©lie Bugeau;Nicolas Papadakis;Peter Schuetz;Carola-Bibiane Sch√∂nlieb,rk621@cam.ac.uk;aurelie.bugeau@labri.fr;nicolas.papadakis@math.u-bordeaux.fr;peter.schuetz@unilever.com;cbs31@cam.ac.uk,6;6;1,,Reject,0,7,0.0,yes,9/25/19,University of Cambridge;LaBRI;University of Bordeaux;Unilever;University of Cambridge,multi-task learning;weak labels;semisupervised learning;image segmentation,79;-1;-1;-1;79,3;646;430;-1;3,m;f,europe,uk,n,2
4803,ICLR,2020,Deep automodulators,Ari Heljakka;Yuxin Hou;Juho Kannala;Arno Solin,ari.heljakka@aalto.fi;yuxin.hou@aalto.fi;arno.solin@aalto.fi;juho.kannala@aalto.fi,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Aalto University;Aalto University;Aalto University;Aalto University,unsupervised learning;generative models;autoencoders;disentanglement;style transfer,118;118;118;118,182;182;182;182,m;m,europe,dk,n,5
4804,ICLR,2020,Towards Certified Defense for Unrestricted Adversarial Attacks,Shengjia Zhao;Yang Song;Stefano Ermon,sjzhao@stanford.edu;yangsong@cs.stanford.edu;ermon@cs.stanford.edu,1;3;3,,Reject,0,1,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University,Adversarial Defense;Certified Defense;Adversarial Examples,5;5;5,4;4;4,m;m,usa,usa,y,1;4
4805,ICLR,2020,Best feature performance in codeswitched hate speech texts,Edward Ombui;Lawrence Muchemi;Peter Wagacha,eombui@anu.ac.ke;lmuchemi@uonbi.ac.ke;waiganjo@uonbi.ac.ke,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Africa Nazarene University;University of Nairobi;University of Nairobi,Hate Speech;Code-switching;feature selection;representation learning,-1;-1;-1,-1;871;871,m;m,NAN,NAN,n,1
4806,ICLR,2020,Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination,Shauharda Khadka;Somdeb Majumdar;Santiago Miret;Stephen McAleer;Kagan Tumer,shauharda.khadka@intel.com;somdeb.majumdar@intel.com;santiago.miret@intel.com;smcaleer@uci.edu;kagan.tumer@oregonstate.edu,1;6;8,,Reject,0,5,0.0,yes,9/25/19,"Intel;Intel;Intel;University of California, Irvine;Oregon State University",reinforcement learning;multiagent;neuroevolution,-1;-1;-1;-1;79,-1;-1;-1;96;373,m;m,usa,usa,n,
4807,ICLR,2020,Gaussian Process Meta-Representations Of Neural Networks,Theofanis Karaletsos;Thang Bui,theofanis.karaletsos@gmail.com;thang.buivn@gmail.com,6;6;6,,Reject,0,12,1.0,yes,9/25/19,Facebook;University of Sydney,Bayesian Neural Networks;Representation Learning;Gaussian Processes;Variational Inference,-1;64,-1;60,m;m,europe,uk,n,11
4808,ICLR,2020,Training Deep Neural Networks with Partially Adaptive Momentum,Jinghui Chen;Dongruo Zhou;Yiqi Tang;Ziyan Yang;Yuan Cao;Quanquan Gu,jc4zg@virginia.edu;drzhou@cs.ucla.edu;yt6ze@virginia.edu;zy3cx@virginia.edu;yuanc@princeton.edu;qgu@cs.ucla.edu,1;6;3,,Reject,0,3,0.0,yes,9/25/19,"University of Virginia;University of California, Los Angeles;University of Virginia;University of Virginia;Princeton University;University of California, Los Angeles",,52;-1;52;52;30;-1,107;17;107;107;6;17,m;m,usa,usa,y,1;9
4809,ICLR,2020,Scalable Deep Neural Networks via Low-Rank Matrix Factorization,Atsushi Yaguchi;Taiji Suzuki;Shuhei Nitta;Yukinobu Sakata;Akiyuki Tanizawa,atsushi.yaguchi@toshiba.co.jp;taiji@mist.i.u-tokyo.ac.jp;shuhei.nitta@toshiba.co.jp;yuki.sakata@toshiba.co.jp;akiyuki.tanizawa@toshiba.co.jp,3;1;1,,Reject,1,4,0.0,yes,9/25/19,Toshiba Corporation;The University of Tokyo;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation,Deep Learning;Deep Neural Networks;Low-Rank Matrix Factorization;Model Compression,-1;64;-1;-1;-1,-1;36;-1;-1;-1,m;m,NAN,NAN,y,
4810,ICLR,2020,Antifragile and Robust Heteroscedastic Bayesian Optimisation,Ryan Rhys-Griffiths;Miguel Garcia-Ortegon;Alexander A. Aldrick;Alpha A. Lee,rrg27@cam.ac.uk;mg770@cam.ac.uk;av495@cam.ac.uk;aal44@cam.ac.uk,3;1;1,,Reject,0,1,0.0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge,Bayesian Optimisation;Gaussian Processeses;Heteroscedasticity,79;79;79;79,3;3;3;3,m;m,europe,uk,n,11
4811,ICLR,2020,Compressed Sensing with Deep Image Prior and Learned Regularization,Dave Van Veen;Ajil Jalal;Mahdi Soltanolkotabi;Eric Price;Sriram Vishwanath;Alexandros G. Dimakis,davemvanveen@gmail.com;ajiljalal@utexas.edu;soltanol@usc.edu;ecprice@cs.utexas.edu;sriram@austin.utexas.edu;dimakis@austin.utexas.edu,3;6;6;6,,Reject,0,0,0.0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin;University of Southern California;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",compressed sensing;sparsity;inverse problems,-1;-1;36;-1;-1;-1,-1;-1;62;-1;-1;-1,m;m,usa,usa,y,1;5
4812,ICLR,2020,Unsupervised Hierarchical Graph Representation Learning with Variational Bayes,Shashanka Ubaru;Jie Chen,shashanka.ubaru@ibm.com;chenjie@us.ibm.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,International Business Machines;International Business Machines,Hierarchical Graph Representation;Unsupervised Graph Learning;Variational Bayes;Graph classification,-1;-1,-1;-1,m;f,NAN,NAN,n,1;10
4813,ICLR,2020,Learning Algorithmic Solutions to Symbolic Planning Tasks with a Neural Computer,Daniel Tanneberg;Elmar Rueckert;Jan Peters,daniel@robot-learning.de;rueckert@rob.uni-luebeck.de;mail@jan-peters.net,6;6;3,,Reject,0,5,0.0,yes,9/25/19,TU Darmstadt;Universit‚àö¬ßt zu L‚àö¬∫beck;TU Darmstadt,,-1;-1;59,-1;-1;-1,m;m,europe,de,n,1
4814,ICLR,2020,Multi-Step Decentralized Domain Adaptation,Akhil Mathur;Shaoduo Gan;Anton Isopoussu;Fahim Kawsar;Nadia Berthouze;Nicholas D. Lane,akhilmathurs@gmail.com;sgan@inf.ethz.ch;anton.isopoussu@gmail.com;fahim.kawsar@gmail.com;nadia.berthouze@gmail.com;nicholasd.lane@gmail.com,6;3;3;6,,Reject,0,7,0.0,yes,9/25/19,University College London;Swiss Federal Institute of Technology;;;;University of Oxford,domain adaptation;decentralization,-1;-1;-1;-1;-1;46,-1;-1;-1;-1;-1;1,m;m,europe,uk,n,4
4815,ICLR,2020,Robust saliency maps with distribution-preserving decoys,Yang Young Lu;Wenbo Guo;Xinyu Xing;William Stafford Noble,ylu465@uw.edu;wzg13@ist.psu.edu;xxing@ist.psu.edu;william-noble@uw.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,"University of Washington, Seattle;Pennsylvania State University;Pennsylvania State University;University of Washington, Seattle",explainable machine learning;explainable AI;deep learning interpretability;saliency maps;perturbation;convolutional neural network,11;43;43;11,26;-1;-1;26,m;m,NAN,NAN,y,4
4816,ICLR,2020,Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors,Jiezhang Cao;Jincheng Li;Xiping Hu;Peilin Zhao;Mingkui Tan,secaojiezhang@mail.scut.edu.cn;sejinchengli@mail.scut.edu.cn;huxp@lzu.edu.cn;peilinzhao@hotmail.com;mingkuitan@scut.edu.cn,3;3;6,,Reject,1,4,0.0,yes,9/25/19,South China University of Technology;South China University of Technology;University of Science and Technology of China;;South China University of Technology,Interpretability of DNNs;Wasserstein distance;Layer behavior,-1;-1;-1;-1;-1,501;501;80;-1;501,m;m,NAN,NAN,y,1
4817,ICLR,2020,Robust Graph Representation Learning via Neural Sparsification,Cheng Zheng;Bo Zong;Wei Cheng;Dongjin Song;Jingchao Ni;Wenchao Yu;Haifeng Chen;Wei Wang,chengzheng@cs.ucla.edu;bzong@nec-labs.com;weicheng@nec-labs.com;dsong@nec-labs.com;jni@nec-labs.com;yuwenchao@ucla.edu;haifeng@nec-labs.com;weiwang@cs.ucla.edu,6;1;8,,Reject,0,6,0.0,yes,9/25/19,"University of California, Los Angeles;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;University of California, Los Angeles;NEC-Labs;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1;-1;-1,17;-1;-1;-1;-1;17;-1;17,m;f,usa,usa,n,10
4818,ICLR,2020,Good Semi-supervised VAE Requires Tighter Evidence Lower Bound,Haozhe Feng;Kezhi Kong;Tianye Zhang;Siyue Xue;Wei Chen,fenghz@zju.edu.cn;kong@cs.umd.edu;zhangtianye1026@zju.edu.cn;3160104527@zju.edu.cn;chenwei@cad.zju.edu.cn,3;3;3,,Reject,1,4,0.0,yes,9/25/19,"Zhejiang University;University of Maryland, College Park;Zhejiang University;Zhejiang University;Zhejiang University",VAE;Semi-supervised Learning;ELBO;Generative Model,39;12;39;39;39,107;91;107;107;107,m;m,asia,cn,n,5
4819,ICLR,2020,EDUCE: Explaining model Decision through Unsupervised Concepts Extraction,Diane Bouchacourt;Ludovic Denoyer,dianeb@fb.com;denoyer@fb.com,6;3;8,,Reject,0,9,0.0,yes,9/25/19,Facebook;Facebook,Interpretability;explainability;text processing,-1;-1,-1;-1,f;m,NAN,NAN,n,
4820,ICLR,2020,Projected Canonical Decomposition for Knowledge Base Completion,Timoth√©e Lacroix;Guillaume Obozinski;Joan Bruna;Nicolas Usunier,timothee.lax@gmail.com;guillaume.obozinski@epfl.ch;bruna@cims.nyu.edu;usunier@fb.com,3;8;3,,Reject,0,4,0.0,yes,9/25/19,Facebook;Swiss Federal Institute of Technology Lausanne;New York University;Facebook,knowledge base completion;adagrad,-1;-1;22;-1,-1;-1;29;-1,m;m,NAN,NAN,n,
4821,ICLR,2020,Lossless Data Compression with Transformer,Gautier Izacard;Armand Joulin;Edouard Grave,gizacard@gmail.com;ajoulin@fb.com;egrave@fb.com,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Ecole Normale Superieure;Facebook;Facebook,data compression;transformer,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;3
4822,ICLR,2020,Stochastically Controlled Compositional Gradient for the Composition problem,Liu Liu;Ji Liu;Cho-Jui Hsieh;Dacheng Tao,liu.liu1@sydney.edu.au;ji.liu.uwisc@gmail.com;chohsieh@cs.ucla.edu;dacheng.tao@sydney.edu.au,6;3;3,,Reject,0,3,0.0,yes,9/25/19,"University of Sydney;;University of California, Los Angeles;University of Sydney",Non-convex optimisation;Composition problem;Stochastically controlled compositional gradient,64;-1;-1;64,60;-1;17;60,f;m,europe,uk,y,
4823,ICLR,2020,Domain Adaptation via Low-Rank Basis Approximation,Christoph Raab;Frank-Michael Schleif,christoph.raab@fhws.de;frank-michael.schleif@fhws.de,1;3;1,,Reject,0,5,0.0,yes,9/25/19,University of Applied Sciences W√ºrzburg-Schweinfurt;University of Applied Sciences W√ºrzburg-Schweinfurt,Domain Adaptation;Basis Transfer;Transfer Learning;Low Rank Approximation;Nystr√∂m Approximation,-1;-1,-1;-1,m;m,NAN,NAN,n,
4824,ICLR,2020,SGD with Hardness Weighted Sampling for Distributionally Robust Deep Learning,Lucas Fidon;Sebastien Ourselin;Tom Vercauteren,lucas.fidon@kcl.ac.uk;sebastien.ourselin@kcl.ac.uk;tom.vercauteren@kcl.ac.uk,3;3;3,,Reject,0,7,0.0,yes,9/25/19,King's College London;King's College London;King's College London,distributionally robust optimization;distributionally robust deep learning;over-parameterized deep neural networks;deep neural networks;AI safety;hard example mining,168;168;168,36;36;36,m;m,europe,uk,y,1
4825,ICLR,2020,Fast Training of Sparse Graph Neural Networks on Dense Hardware,Matej Balog;Bart van Merri√´nboer;Subhodeep Moitra;Yujia Li;Daniel Tarlow,matej.balog@gmail.com;bartvm@google.com;smoitra@google.com;yujiali@google.com;dtarlow@google.com,3;6;6,,Reject,0,12,0.0,yes,9/25/19,University of Cambridge;Google;Google;Google;Google,,79;-1;-1;-1;-1,3;-1;-1;-1;-1,m;m,NAN,NAN,n,10
4826,ICLR,2020,CGT: Clustered Graph Transformer for Urban Spatio-temporal Prediction,Xu Geng;Lingyu Zhang;Shulin Li;Yuanbo Zhang;Lulu Zhang;Leye Wang;Qiang Yang;Hongtu Zhu;Jieping Ye,xgeng@connect.ust.hk;zhanglingyu@didiglobal.com;lishulin_i@didiglobal.com;bozhangyuanbo_i@didiglobal.com;zhanglulululu@didiglobal.com;leyewang@pku.edu.cn;qyang@cse.ust.hk;zhuhongtu@didiglobal.com;yejieping@didiglobal.com,3;3;1,,Reject,0,5,0.0,yes,9/25/19,The Hong Kong University of Science and Technology;Didi Chuxing;Didi Chuxing;Didi Chuxing;Didi Chuxing;Peking University;The Hong Kong University of Science and Technology;Didi Chuxing;Didi Chuxing,Unsmooth spatiotemporal forecasting;Clustered graph neural network;Graph-Transformer;Urban computing,-1;-1;-1;-1;-1;14;-1;-1;-1,47;-1;-1;-1;-1;24;47;-1;-1,m;m,NAN,NAN,n,8;10
4827,ICLR,2020,Regularizing Black-box Models for Improved Interpretability,Gregory Plumb;Maruan Al-Shedivat;Eric Xing;Ameet Talwalkar,gdplumb@andrew.cmu.edu;alshedivat@cs.cmu.edu;epxing@cs.cmu.edu;talwalkar@cmu.edu,6;3;1,,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Interpretable Machine Learning;Local Explanations;Regularization,1;1;1;1,27;27;27;27,m;m,usa,usa,y,
4828,ICLR,2020,AlgoNet: $C^\infty$ Smooth Algorithmic Neural Networks,Felix Petersen;Christian Borgelt;Oliver Deussen,felix.petersen@uni.kn;christian@borgelt.net;oliver.deussen@uni.kn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,University of Konstanz;University of Salzburg;University of Konstanz,Algorithms;Smoothness;Differentiable;Inverse Problems;Adversarial Training;Neural Networks;Deep Learning;Differentiable Renderer;3D Mesh;Turing-completeness;Library,-1;248;-1,-1;-1;-1,m;m,asia,in,n,
4829,ICLR,2020,CAPACITY-LIMITED REINFORCEMENT LEARNING: APPLICATIONS IN DEEP ACTOR-CRITIC METHODS FOR CONTINUOUS CONTROL,Tyler James Malloy;Matthew Riemer;Miao Liu;Tim Klinger;Gerald Tesauro;Chris R. Sims,mallot@rpi.edu;mdriemer@us.ibm.com;miao.liu1@ibm.com;tklinger@us.ibm.com;gtesauro@us.ibm.com;simsc3@rpi.edu,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Rensselaer Polytechnic Institute;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Rensselaer Polytechnic Institute,Reinforcement Learning;Generalization;Information Theory;Rate-Distortion Theory,248;-1;-1;-1;-1;248,438;-1;-1;-1;-1;438,m;m,usa,usa,n,1
4830,ICLR,2020,AdvCodec: Towards A Unified Framework for Adversarial Text Generation,Boxin Wang;Hengzhi Pei;Han Liu;Bo Li,boxinw2@illinois.edu;hzpei16@fudan.edu.cn;hanliu@northwestern.edu;lbo@illinois.edu,3;6;3,,Reject,0,7,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;Fudan University;Northwestern University;University of Illinois, Urbana Champaign",adversarial text generation;tree-autoencoder;human evaluation,-1;73;46;-1,-1;109;22;-1,m;f,usa,usa,n,3;4
4831,ICLR,2020,Function Feature Learning of Neural Networks,Guangcong Wang;Jianhuang Lai;Guangrun Wang;Wenqi Liang,wanggc3@mail2.sysu.edu.cn;stsljh@mail.sysu.edu.cn;wanggrun@mail2.sysu.edu.cn;liangwq8@mail2.sysu.edu.cn,3;3,,Reject,0,3,1.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1;-1,299;299;299;299,m;m,NAN,NAN,n,
4832,ICLR,2020,Unsupervised domain adaptation with imputation,Matthieu Kirchmeyer;Patrick Gallinari;Alain Rakotomamonjy;Amin Mantrach,m.kirchmeyer@criteo.com;patrick.gallinari@lip6.fr;a.rakotomamonjy@criteo.com;a.mantrach@criteo.com,8;3;3,,Reject,0,5,0.0,yes,9/25/19,Criteo;LIP6;Criteo;Criteo,domain adaptation;imputation;missing data;advertising,-1;445;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4833,ICLR,2020,Path Space for Recurrent Neural Networks with ReLU Activations,Yue Wang;Qi Meng;Wei Chen;Yuting Liu;Zhi-Ming Ma;Tie-Yan Liu,11271012@bjtu.edu.cn;meq@microsoft.com;wche@microsoft.com;ytliu@bjtu.edu.cn;mazm@amt.ac.cn;tie-yan.liu@microsoft.com,3;3;1,,Reject,0,4,0.0,yes,9/25/19,Beijing Jiaotong University;Microsoft;Microsoft;Beijing Jiaotong University;Chinese Academy of Sciences;Microsoft,optimization;neural network;positively scale-invariant;path space;deep learning;RNN,-1;-1;-1;-1;30;-1,952;-1;-1;952;-1;-1,m;m,NAN,NAN,y,1;10
4834,ICLR,2020,Fast Machine Learning with Byzantine Workers and Servers,El-Mahdi El-Mhamdi;Rachid Guerraoui;Arsany Guirguis,elmahdi.elmhamdi@epfl.ch;rachid.guerraoui@epfl.ch;arsany.guirguis@epfl.ch,3;6;3,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Distributed machine learning;Byzantine resilience;Fault tolerance,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
4835,ICLR,2020,Topology-Aware Pooling via Graph Attention,Hongyang Gao;Shuiwang Ji,hongyang.gao@tamu.edu;sji@tamu.edu,3;6;1,,Reject,0,0,0.0,yes,9/25/19,Texas A&M;Texas A&M,,46;46,177;177,m;m,NAN,NAN,n,8;2;3;10
4836,ICLR,2020,Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,Alex X. Lee;Anusha Nagabandi;Pieter Abbeel;Sergey Levine,alexlee_gk@cs.berkeley.edu;nagaban2@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,8;3;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n,5
4837,ICLR,2020,Localised Generative Flows,Rob Cornish;Anthony Caterini;George Deligiannidis;Arnaud Doucet,rcornish@robots.ox.ac.uk;anthony.caterini@stats.ox.ac.uk;deligian@stats.ox.ac.uk;doucet@stats.ox.ac.uk,3;3;1,,Reject,1,6,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Deep generative models;normalizing flows;variational inference,46;46;46;46,1;1;1;1,m;m,europe,uk,y,5
4838,ICLR,2020,Guided Adaptive Credit Assignment for Sample Efficient Policy Optimization,Hao Liu;Richard Socher;Caiming Xiong,lhao499@gmail.com;rsocher@salesforce.com;cxiong@salesforce.com,3;6;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;SalesForce.com;SalesForce.com,credit assignment;sparse reward;policy optimization;sample efficiency,-1;-1;-1,13;-1;-1,m;m,NAN,NAN,y,3
4839,ICLR,2020,Proactive Sequence Generator via Knowledge Acquisition,Qing Sun;James Cross;Dmitriy Genzel,qingsun@fb.com;jcross@fb.com;dgenzel@fb.com,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Facebook;Facebook;Facebook,neural machine translation;knowledge distillation;exposure bias;reinforcement learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,8;3
4840,ICLR,2020,Reinforcement Learning without Ground-Truth State,Xingyu Lin;Harjatin Singh Baweja;David Held,xlin3@cs.cmu.edu;dheld@andrew.cmu.edu;harjatis@andrew.cmu.edu,3;1;3,,Reject,0,4,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Self-supervised;goal-conditioned reinforcement learning,1;1;1,27;27;27,m;m,usa,usa,n,
4841,ICLR,2020,Generalized Inner Loop Meta-Learning,Edward Grefenstette;Brandon Amos;Denis Yarats;Phu Mon Htut;Artem Molchanov;Franziska Meier;Douwe Kiela;Kyunghyun Cho;Soumith Chintala,egrefen@gmail.com;brandon.amos.cs@gmail.com;denisyarats@cs.nyu.edu;pmh330@nyu.edu;a.molchanov86@gmail.com;fmeier@fb.com;dkiela@fb.com;kyunghyun.cho@nyu.edu;soumith@gmail.com,3;3;3,,Reject,0,10,0.0,yes,9/25/19,Facebook;Facebook;New York University;New York University;NVIDIA;Facebook;Facebook;New York University;Facebook,meta-learning,-1;-1;22;22;-1;-1;-1;22;-1,-1;-1;29;29;-1;-1;-1;29;-1,m;m,NAN,NAN,n,6;1
4842,ICLR,2020,Channel Equilibrium Networks,Wenqi Shao;Shitao Tang;Xingang Pan;Ping Tan;Xiaogang Wang;Ping Luo,weqish@link.cuhk.edu.hk;shitaot@sfu.ca;px117@ie.cuhk.edu.hk;pingtan@sfu.ca;xgwang@ee.cuhk.edu.hk;pluo.lhi@gmail.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,The Chinese University of Hong Kong;Simon Fraser University;The Chinese University of Hong Kong;Simon Fraser University;The Chinese University of Hong Kong;The University of Hong Kong,Deep learning;convolutional neural networks;building block design,316;52;316;52;316;92,35;272;35;272;35;35,m;m,NAN,NAN,y,1
4843,ICLR,2020,Zeroth Order Optimization by a Mixture of Evolution Strategies,Jun-Kun Wang;Xiaoyun Li;Ping Li,jimwang@gatech.edu;xl374@scarletmail.rutgers.edu;liping11@baidu.com,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Georgia Institute of Technology;Rutgers University;Baidu,,13;30;-1,38;-1;-1,m;m,NAN,NAN,n,
4844,ICLR,2020,Limitations for Learning from Point Clouds,Christian Bueno;Alan G. Hylton,christianbueno@ucsb.edu;alan.g.hylton@nasa.gov,8;3;3,,Reject,0,4,0.0,yes,9/25/19,UC Santa Barbara;NASA Ames,universal approximation;point clouds;deep learning;hausdorff metric;wasserstein metric,-1;-1,-1;-1,m;m,NAN,NAN,y,1
4845,ICLR,2020,WORD SEQUENCE PREDICTION FOR AMHARIC LANGUAGE,Nuniyat Kifle;Ermias Abebe,nunukifle2@gmail.com;ermiasabebe@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Addis Ababa University;Addis Ababa University,Word prediction;POS;Statistical approach,-1;-1,-1;-1,m;m,asia,in,n,3
4846,ICLR,2020,Learning Underlying Physical Properties From Observations For Trajectory Prediction,Ekaterina Nikonova;Jochen Renz,ekaterina.nikonova@anu.edu.au;jochen.renz@anu.edu.au,1;3;3,,Reject,0,4,0.0,yes,9/25/19,Australian National University;Australian National University,Physical Games;Deep Learning;Physical Reasoning;Transfer of Knowledge,102;102,50;50,f;m,australasia,au,n,
4847,ICLR,2020,Provable Representation Learning for Imitation Learning via Bi-level Optimization,Sanjeev Arora;Simon S. Du;Sham Kakade;Yuping Luo;Nikunj Saunshi,arora@cs.princeton.edu;ssdu@ias.edu;sham@cs.washington.edu;yupingl@cs.princeton.edu;nsaunshi@cs.princeton.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,"Princeton University;Institue for Advanced Study, Princeton;University of Washington;Princeton University;Princeton University",imitation learning;representation learning;multitask learning;theory;behavioral cloning;imitation from observations alone;reinforcement learning,30;-1;11;30;30,6;-1;26;6;6,m;m,usa,usa,y,1
4848,ICLR,2020,Anchor & Transform: Learning Sparse Representations of Discrete Objects,Paul Pu Liang;Manzil Zaheer;Yuan Wang;Amr Ahmed,pliang@cs.cmu.edu;manzilzaheer@google.com;yuanwang@google.com;amra@google.com,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google,sparse representation learning;discrete inputs;natural language processing,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n,3
4849,ICLR,2020,EgoMap: Projective mapping and structured egocentric memory for Deep RL,Edward Beeching;Christian Wolf;Jilles Dibangoye;Olivier Simonin,edward.beeching@inria.fr;christian.wolf@insa-lyon.fr;jilles.dibangoye@inria.fr;olivier.simonin@inria.fr,6;3;6,,Reject,0,5,0.0,yes,9/25/19,INRIA;INSA de Lyon;INRIA;INRIA,Reinforcement Learning;Deep Learning;Computer Vision;Robotics;Neural Memory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,gr,n,1
4850,ICLR,2020,Few-shot Learning by Focusing on Differences,Muhammad Rizki Maulana;Lee Wee Sun,maulana@comp.nus.edu.sg;leews@comp.nus.edu.sg,3;3;3,,Reject,0,3,0.0,yes,9/25/19,National University of Singapore;National University of Singapore,Deep learning;few-shot learning,17;17,25;25,m;m,asia,sg,n,6;8
4851,ICLR,2020,On the Parameterization of Gaussian Mean Field Posteriors in Bayesian Neural Networks,Jakub ≈öwiƒÖtkowski;Kevin Roth;Bastiaan S. Veeling;Linh Tran;Joshua V. Dillon;Jasper Snoek;Stephan Mandt;Tim Salimans;Rodolphe Jenatton;Sebastian Nowozin,kuba.swiatkowski@gmail.com;kevin.roth@inf.ethz.ch;basveeling@gmail.com;linh.tran@imperial.ac.uk;jvdillon@google.com;jaspersnoek@gmail.com;stephan.mandt@gmail.com;salimans@google.com;rjenatton@google.com;nowozin@google.com,3;1;3,,Reject,0,3,0.0,yes,9/25/19,"NoMagic;Swiss Federal Institute of Technology;Google;Imperial College London;Google;Google;University of California, Irvine;Google;Google;Google",variational Bayes;Bayesian neural networks;mean field,-1;-1;-1;52;-1;-1;-1;-1;-1;-1,-1;-1;-1;10;-1;-1;96;-1;-1;-1,m;m,NAN,NAN,n,11
4852,ICLR,2020,Deep unsupervised feature selection,Ian Covert;Uygar Sumbul;Su-In Lee,icovert@cs.washington.edu;uygars@alleninstitute.org;suinlee@cs.washington.edu,3;1;6,,Reject,0,0,0.0,yes,9/25/19,University of Washington;Allen Institute;University of Washington,Single cell rna;microarray;feature selection;feature ranking,11;-1;11,26;-1;26,m;f,usa,usa,y,1
4853,ICLR,2020,Efficient Bi-Directional Verification of ReLU Networks via Quadratic Programming,Aleksei Kuvshinov;Stephan Guennemann,kuvshino@in.tum.de;guennemann@in.tum.de,3;8;6,,Reject,0,5,0.0,yes,9/25/19,Technical University Munich;Technical University Munich,,-1;-1,-1;-1,m;m,NAN,NAN,y,1;4
4854,ICLR,2020,AdaScale SGD: A Scale-Invariant Algorithm for Distributed Training,Tyler B. Johnson;Pulkit Agrawal;Haijie Gu;Carlos Guestrin,tbjohns@apple.com;pulkit_agrawal@apple.com;jaygu@apple.com;guestrin@apple.com,3;3;3,,Reject,2,4,0.0,yes,9/25/19,Apple;Apple;Apple;Apple,Large-batch SGD;large-scale learning;distributed training,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,2;3
4855,ICLR,2020,Small-GAN: Speeding up GAN Training using Core-Sets,Samarth Sinha;Han Zhang;Anirudh Goyal;Yoshua Bengio;Hugo Larochelle;Augustus Odena,samarth.sinha@mail.utoronto.ca;zhanghan@google.com;anirudhgoyal9119@gmail.com;yoshua.bengio@mila.quebec;hugolarochelle@google.com;augustusodena@google.com,3;6;6,,Reject,0,9,1.0,yes,9/25/19,Toronto University;Google;;Mila;Google;Google,GANs;Coreset,-1;-1;-1;143;-1;-1,-1;-1;-1;336;-1;-1,m;m,NAN,NAN,n,5;4
4856,ICLR,2020,AUGMENTED POLICY GRADIENT METHODS FOR EFFICIENT REINFORCEMENT LEARNING,Kai Lagemann;Gregor Roering;Christoph Henke;Rene Vossen;Frank Hees,kai.lagemann@rwth-aachen.de;gregor.roering@rwth-aachen.de;christoph.henke@ifu.rwth-aachen.de;rene.vossen@ifu.rwth-aachen.de;hees.office@ima-ifu.rwth-aachen.de,1;1;1,,Reject,0,0,0.0,yes,9/25/19,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;RWTH Aachen University,model-free reinforcement learning;model-based reinforcement learning;Baysian neural network;deep learning;reinforcement learning,118;118;118;118;118,98;98;98;98;98,m;m,NAN,NAN,n,
4857,ICLR,2020,Neural Approximation of an Auto-Regressive Process through Confidence Guided Sampling,YoungJoon Yoo;Sanghyuk Chun;Jaejun Yoo;Sangdoo Yun;Jung Woo Ha,youngjoon.yoo@navercorp.com;sanghyuk.c@navercorp.com;jaejun.yoo@navercorp.com;sangdoo.yun@navercorp.com;jungwoo.ha@navercorp.com,6;3;6,,Reject,0,0,0.0,yes,9/25/19,NAVER;NAVER;NAVER;NAVER;NAVER,Neural approximation method;Auto-regressive model;Sequential sample generation,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,europe,gr,n,
4858,ICLR,2020,Certifiably Robust Interpretation in Deep Learning,Alexander Levine;Sahil Singla;Soheil Feizi,alevine0@cs.umd.edu;ssingla@cs.umd.edu;sfeizi@cs.umd.edu,3;1;3,,Reject,0,6,1.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",deep learning interpretation;robustness certificates;adversarial examples,12;12;12,91;91;91,m;m,usa,usa,y,1;4
4859,ICLR,2020,Towards More Realistic Neural Network Uncertainties,Joachim Sicking;Alexander Kister;Matthias Fahrland;Stefan Eickeler;Fabian Hueger;Stefan Rueping;Peter Schlicht;Tim Wirtz,joachim.sicking@iais.fraunhofer.de;alexander.kister@iais.fraunhofer.de;matthias.fahrland@iav.de;stefan.eickeler@iais.fraunhofer.de;fabian.hueger@volkswagen.de;stefan.rueping@iais.fraunhofer.de;peter.schlicht@volkswagen.de;tim.wirtz@iais.fraunhofer.de,1;3;1,,Reject,0,0,0.0,yes,9/25/19,"Fraunhofer IIS;Fraunhofer IIS;;Fraunhofer IIS;Machine Learning Research Lab, Volkswagen Group;Fraunhofer IIS;Machine Learning Research Lab, Volkswagen Group;Fraunhofer IIS",uncertainty;variational inference;MC dropout;variational autoencoder;evaluation,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
4860,ICLR,2020,Adversarial Training: embedding adversarial perturbations into the parameter space of a neural network to build a robust system,Shixian Wen;Laurent Itti,shixianw@usc.edu;itti@usc.edu,1;3;3,,Reject,0,0,0.0,yes,9/25/19,University of Southern California;University of Southern California,Adversarial Training;Adversarial Examples,36;36,62;62,m;m,usa,usa,n,4
4861,ICLR,2020,Neural Linear Bandits: Overcoming Catastrophic Forgetting through Likelihood Matching,Tom Zahavy;Shie Mannor,tomzahavy@gmail.com;shiemannor@gmail.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,"DeepMind;Technion, Technion",,-1;27,-1;-1,m;m,NAN,NAN,n,
4862,ICLR,2020,Neural Non-additive Utility Aggregation,Markus Zopf,mzopf@ke.tu-darmstadt.de,3;1;1,,Reject,0,5,0.0,yes,9/25/19,TU Darmstadt,,59,-1,m;m,europe,de,n,
4863,ICLR,2020,Understanding the functional and structural differences across excitatory and inhibitory neurons,Sun Minni;Li Ji-An;Theodore Moskovitz;Grace Lindsay;Kenneth Miller;Mario Dipoppa;Guangyu Robert Yang,sunminni1031@gmail.com;jian.li.acad@gmail.com;thmoskovitz@gmail.com;gracewlindsay@gmail.com;kendmiller@gmail.com;mario.dipoppa@gmail.com;gyyang.neuro@gmail.com,6;6;8,,Reject,0,11,0.0,yes,9/25/19,Columbia University;;University College London;University College London;Columbia University;;Columbia University,Neuroscience,24;-1;52;52;24;-1;24,16;-1;-1;-1;16;-1;16,f;m,usa,usa,n,
4864,ICLR,2020,Skew-Explore: Learn faster in continuous spaces with sparse rewards,Xi Chen;Yuan Gao;Ali Ghadirzadeh;Marten Bjorkman;Ginevra Castellano;Patric Jensfelt,xi8@kth.se;gaoyuankidult@gmail.com;algh@kth.se;celle@csc.kth.se;ginevra.castellano@it.uu.se;patric@kth.se,3;3;3,,Reject,0,5,0.0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;Uppsala University;KTH Royal Institute of Technology, Stockholm, Sweden",reinforcement learning;exploration;sparse reward,194;-1;194;194;194;194,222;-1;222;222;102;222,m;m,NAN,NAN,y,
4865,ICLR,2020,Self-Supervised Speech Recognition via Local Prior Matching,Wei-Ning Hsu;Ann Lee;Gabriel Synnaeve;Awni Hannun,wnhsu@mit.edu;annl@fb.com;gab@fb.com;awni@fb.com,6;3;3,,Reject,0,4,0.0,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook,speech recognition;self-supervised learning;language model;semi-supervised learning;pseudo labeling,5;-1;-1;-1,5;-1;-1;-1,m;m,NAN,NAN,n,3
4866,ICLR,2020,Learning Reusable Options for Multi-Task Reinforcement Learning,Francisco M. Garcia;Chris Nota;Philip S. Thomas,fmaxgarcia@gmail.com;cnota@cs.umass.edu;pthomas@cs.umass.edu,3;6;1,,Reject,0,6,0.0,yes,9/25/19,"Amazon;University of Massachusetts, Amherst;University of Massachusetts, Amherst",Reinforcement Learning;Temporal Abstraction;Options;Multi-Task RL,-1;24;24,-1;209;209,m;m,usa,usa,y,
4867,ICLR,2020,A Unified framework for randomized smoothing based certified defenses,Tianhang Zheng;Di Wang;Baochun Li;Jinhui Xu,th.zheng@mail.utoronto.ca;dwang45@buffalo.edu;bli@ece.toronto.edu;jinhui@buffalo.edu,3;1;3,,Reject,3,4,0.0,yes,9/25/19,"Toronto University;State University of New York, Buffalo;University of Toronto;State University of New York, Buffalo",Certificated Defense;Randomized Smoothing;A Unified and Self-Contained Framework,-1;-1;18;-1,-1;-1;18;-1,m;m,NAN,NAN,y,8;4
4868,ICLR,2020,Closed loop deep Bayesian inversion:  Uncertainty driven acquisition for fast MRI,Thomas Sanchez;Igor Krawczuk;Zhaodong Sun;Volkan Cevher,thomas.sanchez@epfl.ch;igor.krawczuk@epfl.ch;zhaodong.sun@epfl.ch;volkan.cevher@epfl.ch,3;3;3;3,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Deep Bayesian Inversion;accelerated MRI;uncertainty quantification;sampling mask design,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,11;5;4
4869,ICLR,2020,Scalable Differentially Private Data Generation via Private  Aggregation  of  Teacher Ensembles,Yunhui Long;Suxin Lin;Zhuolin Yang;Carl A. Gunter;Han Liu;Bo Li,ylong4@illinois.edu;linsuxin28@gmail.com;lucas110550@sjtu.edu.cn;cgunter@illinois.edu;hanliu@northwestern.edu;lbo@illinois.edu,3;1;8,,Reject,0,4,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;;Shanghai Jiao Tong University;University of Illinois, Urbana Champaign;Northwestern University;University of Illinois, Urbana Champaign",,-1;-1;30;-1;46;-1,-1;-1;157;-1;22;-1,f;f,usa,usa,y,1;5;4
4870,ICLR,2020,Adaptive Generation of Unrestricted Adversarial Inputs,Isaac Dunn;Hadrien Pouget;Tom Melham;Daniel Kroening,isaac.dunn@cs.ox.ac.uk;hadrien.pouget@cs.ox.ac.uk;tom.melham@cs.ox.ac.uk;kroening@cs.ox.ac.uk,3;6;6,,Reject,0,9,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Adversarial Examples;Adversarial Robustness;Generative Adversarial Networks;Image Classification,46;46;46;46,1;1;1;1,m;m,europe,uk,n,5;4
4871,ICLR,2020,GPNET: MONOCULAR 3D VEHICLE DETECTION BASED ON LIGHTWEIGHT WHEEL GROUNDING POINT DETECTION NETWORK,zizhang.wu,wuzizhang87@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,0,applications in vision;audio;speech;natural language processing;robotics,,,m,NAN,NAN,n,
4872,ICLR,2020,Training Neural Networks for and by Interpolation,Leonard Berrada;Andrew Zisserman;Pawan M. Kumar,lberrada@robots.ox.ac.uk;az@robots.ox.ac.uk;pawan@robots.ox.ac.uk,1;6;6;6,,Reject,0,5,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,optimization;adaptive learning-rate;Polyak step-size;Newton-Raphson,46;46;46,1;1;1,m;m,europe,uk,y,
4873,ICLR,2020,On the expected running time of nonconvex optimization with early stopping,Thomas Flynn;Kwang Min Yu;Abid Malik;Shinjae Yoo;Nicholas D'Imperio,thomasflynn918@gmail.com;kyu@bnl.gov;amalik@bnl.gov;sjyoo@bnl.gov;dimperio@bnl.gov,3;6;3,,Reject,0,0,0.0,yes,9/25/19,Brookhaven National Laboratory;Brookhaven National Laboratory;Brookhaven National Laboratory;Brookhaven National Laboratory;Brookhaven National Laboratory,non-convex;stopping times;statistics;gradient descent;early stopping,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1;9
4874,ICLR,2020,Interpreting video features: a comparison of 3D convolutional networks and convolutional LSTM networks,Joonatan M√§ntt√§ri*;Sofia Broom√©*;John Folkesson;Hedvig Kjellstr√∂m,sbroome@kth.se;manttari@kth.se;johnf@kth.se;hedvig@kth.se,6;1;3,,Reject,0,4,0.0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",interpretability;spatiotemporal;video;features;saliency;temporal,194;194;194;194,222;222;222;222,m;f,NAN,NAN,n,2
4875,ICLR,2020,Deep Multiple Instance Learning for Taxonomic Classification of Metagenomic read sets,Andreas Georgiou;Vincent Fortuin;Harun Mustafa;Gunnar R√§tsch,geandrea@ethz.ch;fortuin@inf.ethz.ch;harun.mustafa@inf.ethz.ch;raetsch@inf.ethz.ch,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8
4876,ICLR,2020,Learning with Long-term Remembering: Following the Lead of Mixed Stochastic Gradient,Yunhui Guo;Mingrui Liu;Tianbao Yang;Tajana Rosing,yug185@eng.ucsd.edu;mingrui-liu@uiowa.edu;tianbao-yang@uiowa.edu;tajana@ucsd.edu,3;3;3,,Reject,0,8,0.0,yes,9/25/19,"University of California, San Diego;University of Iowa;University of Iowa;University of California, San Diego",lifelong learning;continual learning,-1;168;168;-1,31;227;227;31,m;f,usa,usa,n,
4877,ICLR,2020,Skew-Fit: State-Covering Self-Supervised Reinforcement Learning,Vitchyr H. Pong;Murtaza Dalal;Steven Lin;Ashvin Nair;Shikhar Bahl;Sergey Levine,vitchyr@berkeley.edu;mdalal@berkeley.edu;stevenlin598@berkeley.edu;anair17@berkeley.edu;shikharbahl@berkeley.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,9,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,deep reinforcement learning;goal space;goal conditioned reinforcement learning;self-supervised reinforcement learning;goal sampling;reinforcement learning,-1;-1;-1;-1;-1;-1,13;13;13;13;13;13,m;m,usa,usa,y,
4878,ICLR,2020,Uncertainty - sensitive learning and planning with ensembles,Piotr Mi≈Ço≈õ;≈Åukasz Kuci≈Ñski;Konrad Czechowski;Piotr Kozakowski;Maciej Klimek,pmilos@mimuw.edu.pl;lukasz.kucinski@gmail.com;konrad.czechowski@gmail.com;p.kozakowski@mimuw.edu.pl;maciej.klimek@gmail.com,3;6;1,,Reject,1,3,0.0,yes,9/25/19,"University of Washington, Seattle;;University of Washington, Seattle;University of Washington, Seattle;Uppsala University",deep reinfocement learning;mcts;ensembles;uncertainty,11;-1;11;11;-1,26;-1;26;26;-1,m;m,asia,in,y,
4879,ICLR,2020,Gradient-based training of Gaussian Mixture Models in High-Dimensional Spaces,Alexander Gepperth;Benedikt Pf√ºlb,alexander.gepperth@cs.hs-fulda.de;benedikt.pfuelb@cs.hs-fulda.de,3;3;1,,Reject,0,4,0.0,yes,9/25/19,University of Applied Sciences Fulda;University of Applied Sciences Fulda,GMM;SGD,-1;-1,-1;-1,m;m,NAN,NAN,n,1
4880,ICLR,2020,Counterfactual Regularization for Model-Based Reinforcement Learning,Lawrence Neal;Li Fuxin;Xiaoli Fern,nealla@oregonstate.edu;fuxin.li@oregonstate.edu;xiaoli.fern@oregonstate.edu,3;3;3,,Reject,0,1,0.0,yes,9/25/19,Oregon State University;Oregon State University;Oregon State University,Counterfactual;Model-Based Reinforcement Learning,79;79;79,373;373;373,m;f,usa,usa,n,
4881,ICLR,2020,Three-Head Neural Network Architecture for AlphaZero Learning,Chao Gao;Martin Mueller;Ryan Hayward;Hengshuai Yao;Shangling Jui,cgao3@ualberta.ca;mmueller@ualberta.ca;hayward@ualberta.ca;hengshuai.yao@huawei.com;jui.shangling@huawei.com,6;3;6,,Reject,0,3,0.0,yes,9/25/19,University of Alberta;University of Alberta;University of Alberta;Huawei Technologies Ltd.;Huawei Technologies Ltd.,alphazero;reinforcement learning;two-player games;heuristic search;deep neural networks,102;102;102;-1;-1,136;136;136;-1;-1,m;m,NAN,NAN,n,1
4882,ICLR,2020,GATO: Gates Are Not the Only Option,Mark Goldstein*;Xintian Han*;Rajesh Ranganath,goldstein@nyu.edu;xh1007@nyu.edu;rajeshr@cims.nyu.edu,3;8;3,,Reject,0,5,0.0,yes,9/25/19,New York University;New York University;New York University,Sequence Models;Vanishing Gradients;Recurrent neural networks;Long-term dependence,22;22;22,29;29;29,m;m,usa,usa,n,1
4883,ICLR,2020,Collaborative Inter-agent Knowledge Distillation for Reinforcement Learning,Zhang-Wei Hong;Prabhat Nagarajan;Guilherme Maeda,williamd4112@gapp.nthu.edu.tw;prabhat@preferred.jp;gjmaeda@preferred.jp,3;8;6,,Reject,0,7,0.0,yes,9/25/19,"National Tsing Hua University;Preferred Networks, Inc.;Preferred Networks, Inc.",Reinforcement learning;distillation,194;-1;-1,365;-1;-1,m;m,NAN,NAN,n,
4884,ICLR,2020,THE EFFECT OF ADVERSARIAL TRAINING: A THEORETICAL CHARACTERIZATION,Mingyang Yi;Huishuai Zhang;Wei Chen;Zhi-Ming Ma;Tie-Yan Liu,yimingyang17@mails.ucas.edu.cn;huzhang@microsoft.com;wche@microsoft.com;mazm@amt.ac.cn;tie-yan.liu@microsoft.com,1;1;1,,Reject,0,4,0.0,yes,9/25/19,University of Chinese Academy of Sciences;Microsoft;Microsoft;Chinese Academy of Sciences;Microsoft,adversarial training;robustness;separable data,30;-1;-1;30;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1;4
4885,ICLR,2020,Flexible and Efficient Long-Range Planning Through Curious Exploration,Aidan Curtis;Minjian Xin;Kevin Feigelis;Dan Yamins,southpawac@gmail.com;xinminjian@sjtu.edu.cn;feigelis@stanford.edu;yamins@stanford.edu,3;1;6,,Reject,0,16,0.0,yes,9/25/19,Rice University;Shanghai Jiao Tong University;Stanford University;Stanford University,Curiosity;Planning;Reinforcement Learning;Robotics;Exploration,-1;30;5;5,-1;157;4;4,m;m,usa,usa,n,
4886,ICLR,2020,Learning Latent Dynamics for Partially-Observed Chaotic Systems,Said ouala;Duong Nguyen;Lucas Drumetz;Bertrand Chapron;Ananda Pascual;Fabrice Collard;Lucile Gaultier;Ronan Fablet,said.ouala@imt-atlantique.fr;van.nguyen1@imt-atlantique.fr;lucas.drumetz@imt-atlantique.fr;bertrand.chapron@ifremer.fr;ananda.pascual@imedea.uib-csic.es;dr.fab@oceandatalab.com;lucile.gaultier@oceandatalab.com;ronan.fablet@imt-atlantique.fr,3;3;6,,Reject,0,8,0.0,yes,9/25/19,IMT Atlantique;IMT Atlantique;IMT Atlantique;;Spanish National Research Council;Oceandatalab;Oceandatalab;IMT Atlantique,Dynamical systems;Neural networks;Embedding;Partially observed systems;Forecasting;chaos,-1;-1;-1;-1;-1;-1;-1;-1,393;393;393;-1;-1;-1;-1;393,m;m,NAN,NAN,n,1
4887,ICLR,2020,Make Lead Bias in Your Favor: A Simple and Effective Method for News Summarization,Chenguang Zhu;Ziyi Yang;Robert Gmyr;Michael Zeng;Xuedong Huang,chezhu@microsoft.com;zy99@stanford.edu;rogmyr@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com,6;1;6,,Reject,0,6,0.0,yes,9/25/19,Microsoft;Stanford University;Microsoft;Microsoft;Microsoft,Summarization;Pretraining,-1;5;-1;-1;-1,-1;4;-1;-1;-1,m;m,NAN,NAN,n,8
4888,ICLR,2020,High performance RNNs with spiking neurons,Manu V Nair;Giacomo Indiveri,mnair@ini.uzh.ch;giacomo@ini.uzh.ch,6;6;1,,Reject,0,5,1.0,yes,9/25/19,University of Zurich;University of Zurich,RNNs;Spiking neurons;Neuromorphics,118;118,90;90,m;m,europe,ch,n,8
4889,ICLR,2020,Universal Learning Approach for Adversarial Defense,Uriya Pesso;Koby Bibas;Meir Feder,uriyapes@gmail.com;kobybibas@gmail.com;meir@eng.tau.ac.il,3;1;3,,Reject,0,3,0.0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Tel Aviv University,Adversarial examples;Adversarial training;Universal learning;pNML for DNN,-1;30;30,-1;188;188,m;m,europe,il,n,4
4890,ICLR,2020,Re-Examining Linear Embeddings for High-dimensional Bayesian Optimization,Benjamin Letham;Roberto Calandra;Akshara Rai;Eytan Bakshy,bletham@fb.com;rcalandra@fb.com;akshararai@fb.com;ebakshy@fb.com,3;1;3,,Reject,0,4,0.0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook,Bayesian optimization;high-dimensional;Gaussian process,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,11
4891,ICLR,2020,Salient Explanation for Fine-grained Classification,Kanghan Oh;Sungchan Kim;Il-Seok Oh,blastps@gmail.com;s.k@jbnu.ac.kr;iosh@jbnu.ac.kr,1;1;3,,Reject,0,0,0.0,yes,9/25/19,Chonbuk National University;Chonbuk National University;Chonbuk National University,Visual explanation;XAI;Constitutional Neural Network,-1;-1;-1,965;965;965,f;m,NAN,NAN,n,8;1
4892,ICLR,2020,Deep Coordination Graphs,Wendelin Boehmer;Vitaly Kurin;Shimon Whiteson,wendelin.boehmer@cs.ox.ac.uk;vitaly.kurin@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk,6;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,multi-agent reinforcement learning;coordination graph;deep Q-learning;value factorization;relative overgeneralization,46;46;46,1;1;1,m;m,europe,uk,n,1;10
4893,ICLR,2020,Adversarial Training Generalizes Data-dependent Spectral Norm Regularization,Kevin Roth;Yannic Kilcher;Thomas Hofmann,kevin.roth@inf.ethz.ch;yannic.kilcher@inf.ethz.ch;thomas.hofmann@inf.ethz.ch,1;3;8,,Reject,0,11,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Adversarial Robustness;Adversarial Training;Spectral Norm Regularization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;4
4894,ICLR,2020,TriMap: Large-scale Dimensionality Reduction Using Triplets,Ehsan Amid;Manfred K. Warmuth,eamid@ucsc.edu;manfred@ucsc.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,University of Southern California;University of Southern California,Dimensionality Reduction;Triplets;Data Visualization;t-SNE;LargeVis;UMAP,36;36,62;62,m;m,usa,usa,n,
4895,ICLR,2020,Unsupervised Temperature Scaling: Robust Post-processing Calibration for Domain Shift,Azadeh Sadat Mozafari;Hugo Siqueira Gomes;Christian Gagne,azadeh-sadat.mozafari.1@ulaval.ca;hugo.siqueira-gomes.1@ulaval.ca;christian.gagne@gel.ulaval.ca,3;1;6,,Reject,0,10,0.0,yes,9/25/19,Laval university;Laval university;Laval university,calibration;domain shift;uncertainty prediction;deep neural networks;temperature scaling,-1;-1;-1,272;272;272,f;m,NAN,NAN,y,
4896,ICLR,2020,Uncertainty-Aware Prediction for Graph Neural Networks,Xujiang Zhao;Feng Chen;Shu Hu;jin-Hee Cho,xxz190020@utdallas.edu;feng.chen@utdallas.edu;shu2@albany.edu;jicho@vt.edu,3;3;3,,Reject,0,7,0.0,yes,9/25/19,"University of Texas, Dallas;University of Texas, Dallas;State University of New York, Albany;Virginia Tech",Uncertainty;Graph Neural Networks;Subjective Logic;Bayesian,-1;-1;-1;64,-1;-1;350;-1,m;f,usa,usa,n,11;1;10
4897,ICLR,2020,Hydra: Preserving Ensemble Diversity for Model Distillation,Linh Tran;Bastiaan S. Veeling;Kevin Roth;Jakub ≈öwiƒÖtkowski;Joshua V. Dillon;Jasper Snoek;Stephan Mandt;Tim Salimans;Sebastian Nowozin;Rodolphe Jenatton,linh.tran@imperial.ac.uk;basveeling@gmail.com;kevin.roth@inf.ethz.ch;kuba.swiatkowski@gmail.com;jvdillon@google.com;jaspersnoek@gmail.com;stephan.mandt@gmail.com;salimans@google.com;nowozin@google.com;rjenatton@google.com,6;3;1,,Reject,0,5,0.0,yes,9/25/19,"Imperial College London;Google;Swiss Federal Institute of Technology;NoMagic;Google;Google;University of California, Irvine;Google;Google;Google",model distillation;ensemble models,52;-1;-1;-1;-1;-1;-1;-1;-1;-1,10;-1;-1;-1;-1;-1;96;-1;-1;-1,f;m,NAN,NAN,n,
4898,ICLR,2020,Finding Deep Local Optima Using Network Pruning,Yangzi Guo;Yiyuan She;Ying Nian Wu;Adrian Barbu,yguo@math.fsu.edu;yshe@stat.fsu.edu;ywu@stat.ucla.edu;abarbu@stat.fsu.edu,3;6;3,,Reject,0,0,0.0,yes,9/25/19,"SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;University of California, Los Angeles;SUN YAT-SEN UNIVERSITY",network pruning;non-convex optimization,-1;-1;-1;-1,299;299;17;299,m;m,NAN,NAN,n,
4899,ICLR,2020,Advantage Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning,Xue Bin Peng;Aviral Kumar;Grace Zhang;Sergey Levine,xbpeng@berkeley.edu;aviralkumar2907@gmail.com;grace.zhang@berkeley.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,31,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;policy search;control,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,y,
4900,ICLR,2020,Generative Teaching Networks: Accelerating Neural Architecture Search by Learning  to Generate Synthetic Training Data,Felipe Petroski Such;Aditya Rawal;Joel Lehman;Kenneth Stanley;Jeff Clune,felipe.such@uber.com;aditya.rawal@uber.com;joel.lehman@uber.com;kstanley@uber.com;jeffclune@uber.com,3;6;6,,Reject,0,13,0.0,yes,9/25/19,Uber;Uber;Uber;Uber;Uber,Generative models;generating synthetic data;neural architecture search;learning to teach;meta-learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,southamerica,br,n,5
4901,ICLR,2020,Compression without Quantization,Gergely Flamich;Marton Havasi;Jos√© Miguel Hern√°ndez-Lobato,gf332@cam.ac.uk;mh740@cam.ac.uk;jmh233@cam.ac.uk,3;3;6;1,,Reject,0,5,0.0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge,Image Compression;Bits-back efficient;Quantization,79;79;79,3;3;3,m;m,europe,uk,y,
4902,ICLR,2020,CLAREL: classification via retrieval loss for zero-shot learning,Boris N. Oreshkin;Negar Rostamzadeh;Pedro O. Pinheiro;Christopher Pal,boris@elementai.com;negar@elementai.com;pedro@elementai.com;christopher.pal@elementai.com,1;6;3,,Reject,0,6,0.0,yes,9/25/19,Element AI;Element AI;Element AI;Element AI,zero-shot learning;representation learning;fine-grained classification,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
4903,ICLR,2020,Generating Semantic Adversarial Examples with Differentiable Rendering,Lakshya Jain;Steven Chen;Wilson Wu;Uyeong Jang;Varun Chandrasekaran;Sanjit Seshia;Somesh Jha,lakshya.jain@berkeley.edu;scchen@berkeley.edu;wilswu@berkeley.edu;wjang@cs.wisc.edu;vchandrasek4@wisc.edu;sseshia@eecs.berkeley.edu;jha@cs.wisc.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Southern California;University of Southern California;University of California Berkeley;University of Southern California,semantic adversarial examples;inverse graphics;differentiable rendering,-1;-1;-1;36;36;-1;36,13;13;13;62;62;13;62,m;m,usa,usa,n,10;4
4904,ICLR,2020,Constant Time Graph Neural Networks,Ryoma Sato;Makoto Yamada;Hisashi Kashima,r.sato@ml.ist.i.kyoto-u.ac.jp;myamada@i.kyoto-u.ac.jp;kashima@i.kyoto-u.ac.jp,6;3;6,,Reject,0,5,0.0,yes,9/25/19,Kyoto University;Kyoto University;Kyoto University,graph neural networks;constant time algorithm,168;168;168,65;65;65,m;m,europe,fi,y,8;10
4905,ICLR,2020,SSE-PT: Sequential Recommendation Via Personalized Transformer,Liwei Wu;Shuqing Li;Cho-Jui Hsieh;James Sharpnack,liwu@ucdavis.edu;qshli@ucdavis.edu;chohsieh@cs.ucla.edu;jsharpna@ucdavis.deu,1;6;6,,Reject,0,3,0.0,yes,9/25/19,"University of California, Davis;University of California, Davis;University of California, Los Angeles;University of California, Davis",sequential recommendation;personalized transformer;stochastic shared embeddings,-1;-1;-1;-1,55;55;17;-1,m;m,asia,in,n,8;3
4906,ICLR,2020,Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier,Zhenwei Dai;Anshumali Shrivastava,zd11@rice.edu;anshumali@rice.edu,3;6;6,,Reject,0,4,0.0,yes,9/25/19,Rice University;Rice University,Ada-BF;Bloom filter;machine learning;memory efficient,92;92,105;105,m;m,australasia,au,y,
4907,ICLR,2020,Classification Attention for Chinese NER,Yuchen Ge;FanYang;PeiYang,geyc2@lenovo.com;yangfan24@lenovo.com;yangpei4@lenovo.com,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Lenovo Research;Lenovo Research;Lenovo Research,Chinese NER;NER;tagging;deeplearning;nlp,-1;-1;-1,-1;-1;-1,m;u,NAN,NAN,n,8;3
4908,ICLR,2020,Global-Local Network for Learning Depth with Very Sparse Supervision,Antonio Loquercio;Alexey Dosovitskiy;Davide Scaramuzza,loquercio@ifi.uzh.ch;adosovitskiy@google.com;sdavide@ifi.uzh.ch,6;1;3,,Reject,0,4,0.0,yes,9/25/19,University of Zurich;Google;University of Zurich,Depth Perception;Learning from Sparse Supervision;Learning from Interaction.,118;-1;118,90;-1;90,m;m,europe,ch,n,
4909,ICLR,2020,Localized Generations with Deep Neural Networks for Multi-Scale Structured Datasets,Yoshihiro Nagano;Shiro Takagi;Yuki Yoshida;Masato Okada,nagano@mns.k.u-tokyo.ac.jp;takagi@mns.k.u-tokyo.ac.jp;yoshida@mns.k.u-tokyo.ac.jp;okada@edu.k.u-tokyo.ac.jp,3;3;8,,Reject,0,5,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,Variational autoencoder;Local learning;Model-agnostic meta-learning;Disentangled representation,64;64;64;64,36;36;36;36,m;m,NAN,NAN,n,6;5
4910,ICLR,2020,CrossNorm: On Normalization for Off-Policy Reinforcement Learning,Aditya Bhatt;Max Argus;Artemij Amiranashvili;Thomas Brox,aditya@bhatts.org;argus.max@gmail.com;amiranas@cs.uni-freiburg.de;brox@cs.uni-freiburg.de,3;6;3,,Reject,0,4,0.0,yes,9/25/19,TU Berlin;;Universit√§t Freiburg;Universit√§t Freiburg,RL;Normalization,118;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4911,ICLR,2020,Diagonal Graph Convolutional Networks with Adaptive Neighborhood Aggregation,Jie Zhang;Yuxiao Dong;Jie Tang,zhangjie.exe@gmail.com;yuxdong@microsoft.com;jietang@tsinghua.edu.cn,3;3;3,,Reject,0,0,0.0,yes,9/25/19,"WeBank Co., Ltd.;Microsoft;Tsinghua University, Tsinghua University",data mining;graph convolutional networks,-1;-1;4,-1;-1;23,m;m,NAN,NAN,n,8;10
4912,ICLR,2020,Variance Reduced Local SGD with Lower Communication Complexity,Xianfeng Liang;Shuheng Shen;Jingchang Liu;Zhen Pan;Yifei Cheng;Enhong Chen,zeroxf@mail.ustc.edu.cn;vaip@mail.ustc.edu.cn;jliude@cse.ust.hk;pzhen@mail.ustc.edu.cn;chengyif@mail.ustc.edu.cn;cheneh@ustc.edu.cn,3;1;6,,Reject,0,3,0.0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;The Hong Kong University of Science and Technology;University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China,variance reduction;local SGD;distributed optimization,-1;-1;-1;-1;-1;-1,80;80;47;80;80;80,m;m,NAN,NAN,y,8;1
4913,ICLR,2020,White Box Network: Obtaining a right composition ordering of functions,Eun saem Lee;Hyung Ju Hwang,dmstoa2502@postech.ac.kr;hjhwang@postech.ac.kr,1;1;1,,Reject,0,6,0.0,yes,9/25/19,POSTECH;POSTECH,white box;black box;function composition;neural network;ordering functions;reverse engineering;programmable logic controller;plc;white box network;WBN,118;118,146;146,f;f,asia,kr,n,
4914,ICLR,2020,Neural Embeddings for Nearest Neighbor Search Under Edit Distance,Xiyuan Zhang;Yang Yuan;Piotr Indyk,zhangxiyuan@zju.edu.cn;yuanyang@tsinghua.edu.cn;indyk@mit.edu,6;6;3,,Reject,0,7,0.0,yes,9/25/19,"Zhejiang University;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology",Embedding;Edit Distance;Nearest Neighbor Search;Learning-Augmented Algorithm,39;4;5,107;23;5,m;m,usa,usa,y,
4915,ICLR,2020,Accelerating First-Order Optimization Algorithms,Ange Tato;Roger Nkambou,angetato@gmail.com;nkambou@gmail.com,3;3;1,,Reject,0,0,0.0,yes,9/25/19,Universit√© du Qu√©bec √† Montr√©al;Universit√© du Qu√©bec √† Montr√©al,Neural Networks;Gradient Descent;First order optimization,-1;-1,-1;-1,f;m,asia,in,y,1
4916,ICLR,2020,A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING,Qi Qi;Yan Yan;Zixuan Wu;Xiaoyu Wang;Tianbao Yang,qi-qi@uiowa.edu;yanyan.tju@gmail.com;wuzu@bc.edu;fanghuaxue@gmail.com;tianbao-yang@uiowa.edu,6;6;3,,Reject,0,3,0.0,yes,9/25/19,University of Iowa;SUN YAT-SEN UNIVERSITY;Boston College;Snap Inc.;University of Iowa,Deep Metric Learning;Distributionally Robust Optimization,168;-1;248;-1;168,227;299;323;-1;227,f;m,europe,de,y,8;2
4917,ICLR,2020,Local Label Propagation for Large-Scale Semi-Supervised Learning,Chengxu Zhuang;Chaofei Fan;Xuehao Ding;Divyanshu Murli;Daniel Yamins,chengxuz@stanford.edu;stfan@stanford.edu;xhding@stanford.edu;divymurli@gmail.com;yamins@stanford.edu,3;6;6,,Reject,0,6,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Freelance;Stanford University,,5;5;5;-1;5,4;4;4;-1;4,m;m,usa,usa,n,
4918,ICLR,2020,Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes,Sophia Sanborn;Michael Chang;Sergey Levine;Thomas Griffiths,sanborn@berkeley.edu;mbchang@berkeley.edu;svlevine@eecs.berkeley.edu;tomg@princeton.edu,1;6;3,,Reject,0,1,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;Princeton University,hierarchical reinforcement learning;unsupervised learning;compression,-1;-1;-1;30,13;13;13;6,f;m,usa,usa,n,
4919,ICLR,2020,"JAX MD: End-to-End Differentiable, Hardware Accelerated, Molecular Dynamics in Pure Python",Samuel S. Schoenholz;Ekin D. Cubuk,schsam@google.com;cubuk@google.com,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Google;Google,Automatic Differentiation;Software Library;Physics Simulation;Differentiable Physics,-1;-1,-1;-1,m;m,NAN,NAN,n,
4920,ICLR,2020,ROS-HPL: Robotic Object Search with Hierarchical Policy Learning and Intrinsic-Extrinsic Modeling,Xin Ye;Shibin Zheng;Yezhou Yang,xinye1@asu.edu;szheng31@asu.edu;yz.yang@asu.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Robotic Object Search;Hierarchical Reinforcement Learning,-1;-1;-1,299;299;299,m;m,NAN,NAN,n,
4921,ICLR,2020,Fractional Graph Convolutional Networks (FGCN) for Semi-Supervised Learning,Yuzhou Chen;Yulia R. Gel;Konstantin Avrachenkov,yuzhouc@smu.edu;ygl@utdallas.edu;konstentin.avratchankov@inria.fr,6;3;8,,Reject,1,0,0.0,yes,9/25/19,"Singapore Management University;University of Texas, Dallas;INRIA",convolutional networks;node classification;Levy flight;graph-based semi-supervised learning;local graph topology,79;-1;-1,-1;-1;-1,m;m,europe,gr,y,10
4922,ICLR,2020,Graph Neural Networks For Multi-Image Matching,Stephen Phillips;Kostas Daniilidis,stephi@seas.upenn.edu;kostas@seas.upenn.edu,3;6;3,,Reject,0,8,0.0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania,Graph Neural Networks;Multi-image Matching,20;20,11;11,m;m,usa,usa,n,2;10
4923,ICLR,2020,Cost-Effective Testing of a Deep Learning Model through Input Reduction,Jianyi Zhou;Feng Li;Jinhao Dong;Hongyu Zhang;Dan Hao,zhoujianyi@pku.edu.cn;lifeng2014@pku.edu.cn;xdu_jhdong@163.com;hongyu.zhang@newcastle.edu.au;haod@sei.pku.edu.cn,8;6;3,,Reject,0,4,0.0,yes,9/25/19,"Peking University;Peking University;163;University of Newcastle, Australia;Peking University",Software Testing;Deep Learning;Input Data Reduction,14;14;-1;316;14,24;24;-1;311;24,u;f,asia,cn,n,
4924,ICLR,2020,Decoupling Weight Regularization from Batch Size for Model Compression,Dongsoo Lee;Se Jung Kwon;Byeongwook Kim;Yongkweon Jeon;Baeseong Park;Jeongin Yun;Gu-Yeon Wei,dslee3@gmail.com;mogndrewk@gmail.com;quddnr145@gmail.com;dragwon.jeon@gmail.com;qkrqotjd91@gmail.com;yji6373@naver.com;gywei@g.harvard.edu,8;3;3,,Reject,0,7,0.0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Samsung;Samsung;Harvard University,Model compression;Weight Regularization;Batch Size;Gradient Descent,-1;-1;-1;-1;-1;-1;52,-1;-1;-1;-1;-1;-1;7,m;m,usa,usa,n,
4925,ICLR,2020,Amharic Text Normalization with Sequence-to-Sequence Models,Seifedin Shifaw Mohamed;Solomon Teferra Abate (PhD),seifedin28@gmail.com;solomon_teferra_7@yahoo.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Addis Ababa University;Addis Ababa University,Text Normalization;Sequence-to-Sequence Model;Encoder-Decoder,-1;-1,-1;-1,m;m,asia,in,n,3
4926,ICLR,2020,Star-Convexity in Non-Negative Matrix Factorization,Johan Bjorck;Carla Gomes;Kilian Weinberger,njb225@cornell.edu;gomes@cs.cornell.edu;kilianweinberger@cornell.edu,3;6;3,,Reject,0,7,0.0,yes,9/25/19,Cornell University;Cornell University;Cornell University,nmf;convexity;nonconvex optimization;average-case-analysis,7;7;7,19;19;19,m;m,usa,usa,y,
4927,ICLR,2020,Learning Compact Reward for Image Captioning,Nannan Li;Zhenzhong Chen,live@whu.edu.cn;zzchen@whu.edu.cn,6;1;6,,Reject,0,5,0.0,yes,9/25/19,Wuhan University;Wuhan University,image captioning;adversarial learning;inverse reinforcement learning;vision;language,194;194,354;354,f;m,europe,uk,n,9;4
4928,ICLR,2020,Learning Entailment-Based Sentence Embeddings from Natural Language Inference,Rabeeh Karimi Mahabadi*;Florian Mai*;James Henderson,rkarimi@idiap.ch;florian.mai@idiap.ch;james.henderson@idiap.ch,6;6;6,,Reject,0,3,1.0,yes,9/25/19,Idiap Research Institute;Idiap Research Institute;Idiap Research Institute,sentence embeddings;textual entailment;natural language inference;interpretability,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,3
4929,ICLR,2020,Word embedding re-examined: is the symmetrical factorization optimal?,Zhichao Han;Jia Li;Xu Li;Hong Cheng,zchan@se.cuhk.edu.hk;lijia@se.cuhk.edu.hk;xuli@se.cuhk.edu.hk;hcheng@se.cuhk.edu.hk,6;3;3,,Reject,0,3,0.0,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,word embedding;matrix factorization;linear transformation;neighborhood structure,316;316;316;316,35;35;35;35,m;f,NAN,NAN,y,
4930,ICLR,2020,Structured consistency loss for semi-supervised semantic segmentation,JongMok Kim;Joo Young Jang;Hyunwoo Park,win98man1@gmail.com;jyjang1090@gmail.com;phw08132@gmail.com,1;1,,Reject,0,0,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;;Seoul National University,semi-supervised learning;semantic segmentation;structured prediction;structured consistency loss,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,2
4931,ICLR,2020,Attention on Abstract Visual Reasoning,Lukas Hahne;Timo L√ºddecke;Florentin W√∂rg√∂tter;David Kappel,l.hahne@stud.uni-goettingen.de;timo.lueddecke@phys.uni-goettingen.de;worgott@gwdg.de;david.kappel@phys.uni-goettingen.de,3;3;1,,Reject,0,2,0.0,yes,9/25/19,University of Goettingen;University of Goettingen;;University of Goettingen,Transformer Networks;Self-Attention;Wild Relation Networks;Procedurally Generated Matrices,316;316;-1;316,123;123;-1;123,m;m,europe,de,n,8
4932,ICLR,2020,Event extraction from unstructured Amharic text,Ephrem Tadesse;Rosa Tsegaye;Kuulaa Qaqqabaa,ephe11ta@gmail.com;rosatsegaye@gmail.com;kuulaa@gmail.com,3;1;1,,Reject,0,0,0.0,yes,9/25/19,Jimma University;;Addis Ababa Science and Technology University,Event extraction;machine learning classifiers;Nominal events,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
4933,ICLR,2020,Discovering Topics With Neural Topic Models Built From PLSA Loss,sileye ba,sileye.ba@outlook.com,1;1;3,,Reject,2,0,0.0,yes,9/25/19,0,neural network;topic model;neural topic model;bag-of-words;PLSA,,,m;m,NAN,NAN,n,
4934,ICLR,2020,Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness,J√∂rn-Henrik Jacobsen;Jens Behrmann;Nicholas Carlini;Florian Tram√®r;Nicolas Papernot,j.jacobsen@vectorinstitute.ai;jensb@uni-bremen.de;nicholas@carlini.com;tramer@cs.stanford.edu;nicolas.papernot@utoronto.ca,3;6;6,,Reject,0,5,0.0,yes,9/25/19,Vector Institute;Universit√§t Bremen;Google;Stanford University;Toronto University,Invariance;Robustness;Adversarial Examples,-1;-1;-1;5;-1,-1;-1;-1;4;-1,m;m,NAN,NAN,n,4
4935,ICLR,2020,WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia,Holger Schwenk;Vishrav Chaudhary;Shuo Sun;Hongyu Gong;Francisco Guzm√°n,schwenk@fb.com;vishrav@fb.com;ssun32@jhu.edu;hgong6@illinois.edu;fguzman@fb.com,3;6;8;3,,Reject,0,4,0.0,yes,9/25/19,"Facebook;Facebook;Johns Hopkins University;University of Illinois, Urbana Champaign;Facebook",multilinguality;bitext mining;neural MT;Wikipedia;low-resource languages;joint sentence representation,-1;-1;73;-1;-1,-1;-1;12;-1;-1,m;m,NAN,NAN,n,
4936,ICLR,2020,ProtoAttend: Attention-Based Prototypical Learning,Sercan O. Arik;Tomas Pfister,soarik@google.com;tpfister@google.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google,Interpretability;sample-based explanations;prototypes;confidence estimation,-1;-1,-1;-1,m;m,NAN,NAN,n,8
4937,ICLR,2020,Discourse-Based Evaluation of Language Understanding,Damien Sileo;Tim Van-De-Cruys;Camille Pradel;Philippe Muller,damien.sileo@irit.fr;tim.vandecruys@irit.fr;camille.pradel@synapse-fr.com;philippe.muller@irit.fr,6;6;6,,Reject,0,5,0.0,yes,9/25/19,"IRIT, CNRS;IRIT, CNRS;Synapse-fr;IRIT, CNRS",Natural Language Understanding;Pragmatics;Discourse;Semantics;Evaluation;BERT;Natural Language Processing,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3
4938,ICLR,2020,SINGLE PATH ONE-SHOT NEURAL ARCHITECTURE SEARCH WITH UNIFORM SAMPLING,Zichao Guo;Xiangyu Zhang;Haoyuan Mu;Wen Heng;Zechun Liu;Yichen Wei;Jian Sun,guozichao@megvii.com;zhangxiangyu@megvii.com;muhy17@mails.tsinghua.edu.cn;hengwen@megvii.com;zliubq@connect.ust.hk;weiyichen@megvii.com;sunjian@megvii.com,6;8;6,,Reject,1,6,1.0,yes,9/25/19,"Megvii Technology Inc.;Megvii Technology Inc.;Tsinghua University, Tsinghua University;Megvii Technology Inc.;The Hong Kong University of Science and Technology;Megvii Technology Inc.;Megvii Technology Inc.",Neural Architecture Search;Single Path,-1;-1;4;-1;-1;-1;-1,-1;-1;23;-1;47;-1;-1,m;m,NAN,NAN,n,
4939,ICLR,2020,Inducing Stronger Object Representations in Deep Visual Trackers,Ross Goroshin;Jonathan Tompson;Debidatta Dwibedi,goroshin@google.com;tompson@google.com;debidatta@google.com,3;3;1,,Reject,1,4,0.0,yes,9/25/19,Google;Google;Google,Object Tracking;Computer Vision;Deep Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4940,ICLR,2020,Automatically Learning Feature Crossing from Model Interpretation for Tabular Data,Zhaocheng Liu;Qiang Liu;Haoli Zhang,zhaocheng.liu@realai.ai;qiang.liu@realai.ai;haoli.zhang@realai.ai,3;3;3,,Reject,1,13,0.0,yes,9/25/19,RealAI;RealAI;RealAI,AutoML;feature crossing;interpretation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
4941,ICLR,2020,Semi-Supervised Boosting via Self Labelling,Akul Goyal;Yang Liu,akulg2@illinois.edu;yangliu@ucsc.edu,1;1;3,,Reject,0,5,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Southern California",semi-supervised learning;boosting;noise-resistant,-1;36,-1;62,m;m,usa,usa,y,8;1
4942,ICLR,2020,Depth creates no more spurious local minima in linear networks,Li Zhang,liqzhang@google.com,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Google,local minimum;deep linear network,-1,-1,m,NAN,NAN,y,1
4943,ICLR,2020,Learning by shaking: Computing policy gradients by physical forward-propagation,Arash Mehrjou;Ashkan Soleymani;Stefan Bauer;Bernhard Sch√∂lkopf,amehrjou@tuebingen.mpg.de;soli.ashkan98@gmail.com;stefan.bauer@tuebingen.mpg.de;bs@tuebingen.mpg.de,1;1;3;1,,Reject,0,5,0.0,yes,9/25/19,Max-Planck Institute;;Max-Planck Institute;Max-Planck Institute,Reinforcement Learning;Control Theory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
4944,ICLR,2020,Consistent Meta-Reinforcement Learning via Model Identification and Experience Relabeling,Russell Mendonca;Xinyang Geng;Chelsea Finn;Sergey Levine,russellm@berkeley.edu;young.geng@berkeley.edu;cbfinn@cs.stanford.edu;svlevine@eecs.berkeley.edu,3;6;3,,Reject,0,8,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,Meta-Reinforcement Learning;Reinforcement Learning;Off-Policy;Model Based,-1;-1;5;-1,13;13;4;13,m;m,usa,usa,n,
4945,ICLR,2020,Accelerating Monte Carlo Bayesian Inference via Approximating Predictive Uncertainty over the Simplex,Yufei Cui;Wuguannan Yao;Qiao Li;Antoni Chan;Chun Jason Xue,yufeicui92@gmail.com;satie.yao@my.cityu.edu.hk;qiaoli045@gmail.com;abchan@cityu.edu.hk;jasonxue@cityu.edu.hk,3;3;6,,Reject,0,6,0.0,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,,118;118;-1;118;118,171;171;-1;171;171,f;m,asia,hk,n,11;4
4946,ICLR,2020,Trajectory growth through random deep ReLU networks,Ilan Price;Jared Tanner,ilan.price@maths.ox.ac.uk;tanner@maths.ox.ac.uk,3;6;3,,Reject,0,7,0.0,yes,9/25/19,University of Oxford;University of Oxford,Deep networks;expressivity;trajectory growth;sparse neural networks,46;46,1;1,m;m,europe,uk,y,1
4947,ICLR,2020,Ellipsoidal Trust Region Methods for Neural Network Training,Leonard Adolphs;Jonas Kohler;Aurelien Lucchi,ladolphs@inf.ethz.ch;jonas.kohler@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,non-convex;optimization;neural networks;trust-region,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
4948,ICLR,2020,Defensive Tensorization: Randomized Tensor Parametrization for Robust Neural Networks,Adrian Bulat;Jean Kossaifi;Sourav Bhattacharya;Yannis Panagakis;Georgios Tzimiropoulos;Nicholas D.  Lane;Maja Pantic,adrian@adrianbulat.com;jean.kossaifi@gmail.com;bsourav@gmail.com;i.panagakis@imperial.ac.uk;georgios.t@samsung.com;nic.lane@samsung.com;maja.pantic@gmail.com,6;6;6,,Reject,1,5,0.0,yes,9/25/19,Samsung;NVIDIA;;Imperial College London;Samsung;Samsung;Imperial College London,tensor decomposition;tensor factorization;randomization;robustness,-1;-1;-1;52;-1;-1;52,-1;-1;-1;10;-1;-1;10,m;f,europe,uk,n,2;4
4949,ICLR,2020,The Dual Information Bottleneck,Zoe Piran;Naftali Tishby,zoe.piran@mail.huji.ac.il;tishby@cs.huji.ac.il,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,optimal prediction learning;exponential families;critical points;information theory,85;85,216;216,f;m,europe,il,y,
4950,ICLR,2020,ADAPTIVE GENERATION OF PROGRAMMING PUZZLES,Ashwin Kalyan;Oleksandr Polozov;Adam Tauman Kalai,ashwinkv@gatech.edu;alex.polozov@microsoft.com;adam.kalai@microsoft.com,3;8;3,,Reject,0,4,0.0,yes,9/25/19,Georgia Institute of Technology;Microsoft;Microsoft,program synthesis;reasoning;math problems,13;-1;-1,38;-1;-1,m;m,NAN,NAN,y,5
4951,ICLR,2020,Feature-map-level Online Adversarial Knowledge Distillation,Inseop Chung;SeongUk Park;Jangho Kim;Nojun Kwak,jis3613@snu.ac.kr;swpark0703@snu.ac.kr;kjh91@snu.ac.kr;nojunk@snu.ac.kr,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Computer vision;Image classification;Knowledge distillation;Deep Learning,39;39;39;39,64;64;64;64,m;m,asia,kr,n,4
4952,ICLR,2020,Graph convolutional networks for learning with few clean and many noisy labels,Ahmet Iscen;Giorgos Tolias;Yannis Avrithis;Ondrej Chum;Cordelia Schmid,iscen@google.com;giorgos.tolias@cmp.felk.cvut.cz;yannis@avrithis.net;chum@cmp.felk.cvut.cz;cordelias@google.com,6;6;6,,Reject,0,3,0.0,yes,9/25/19,Google;Czech Technical University in Prague;INRIA;Czech Technical University in Prague;Google,,-1;168;-1;168;-1,-1;956;-1;956;-1,m;f,NAN,NAN,n,6;10
4953,ICLR,2020,Visual Interpretability Alone Helps Adversarial Robustness,Akhilan Boopathy;Sijia Liu;Gaoyuan Zhang;Pin-Yu Chen;Shiyu Chang;Luca Daniel,akhilan@mit.edu;sijia.liu@ibm.com;gaoyuan.zhang@ibm.com;pin-yu.chen@ibm.com;shiyu.chang@ibm.com;dluca@mit.edu,3;6;3,,Reject,0,9,0.0,yes,9/25/19,Massachusetts Institute of Technology;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Massachusetts Institute of Technology,adversarial robustness;visual explanation;CNN;image classification,5;-1;-1;-1;-1;5,5;-1;-1;-1;-1;5,m;m,usa,usa,y,4
4954,ICLR,2020,Linguistic Embeddings as a Common-Sense Knowledge Repository: Challenges and Opportunities,Nancy Fulda,nfulda@byu.edu,1;1;3,,Reject,0,0,0.0,yes,9/25/19,The Hong Kong Polytechnic University,knowledge representation;word embeddings;sentence embeddings;common-sense knowledge,118,171,f,asia,hk,n,3;1
4955,ICLR,2020,Starfire: Regularization-Free Adversarially-Robust Structured Sparse Training,Noah Gamboa;Kais Kudrolli;Anand Dhoot;Ardavan Pedram,ngamboa@stanford.edu;kudrolli@stanford.edu;anandd@stanford.edu;perdavan@stanford.edu,1;1;1,,Reject,0,4,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,Structured Sparsity;Sparsity;Training;Compression;Adversarial;Regularization;Acceleration,5;5;5;5,4;4;4;4,m;m,usa,usa,n,4
4956,ICLR,2020,Pixel Co-Occurence Based Loss Metrics for Super Resolution Texture Recovery,Ying Da Wang;Pawel Swietojanski;Ryan T Armstrong;Peyman Mostaghimi,yingda.wang@unsw.edu.au;p.swietojanski@unsw.edu.au;ryan.armstrong@unsw.edu.au;peyman@unsw.edu.au,1;1;3,,Reject,0,1,0.0,yes,9/25/19,University of New South Wales;University of New South Wales;University of New South Wales;University of New South Wales,Super Resolution Generative Adversarial Networks;Perceptual Loss Functions,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
4957,ICLR,2020,Cross-Iteration Batch Normalization,Zhuliang Yao;Yue Cao;Shuxin Zheng;Gao Huang;Stephen Lin;Jifeng Dai,yaozhuliang13@gmail.com;yuecao@microsoft.com;shuxin.zheng@microsoft.com;gaohuang@tsinghua.edu.cn;stevelin@microsoft.com;jifdai@microsoft.com,6;3;6,,Reject,3,9,0.0,yes,9/25/19,"Tsinghua University;Microsoft;Microsoft;Tsinghua University, Tsinghua University;Microsoft;Microsoft",batch normalization;small batch size,-1;-1;-1;4;-1;-1,-1;-1;-1;23;-1;-1,m;m,NAN,NAN,n,2
4958,ICLR,2020,Exploration via Flow-Based Intrinsic Rewards,Hsuan-Kung Yang;Po-Han Chiang;Min-Fong Hong;Chun-Yi Lee,hellochick@gapp.nthu.edu.tw;ymmoy999@gapp.nthu.edu.tw;romulus@gapp.nthu.edu.tw;cylee@gapp.nthu.edu.tw,6;3;3,,Reject,0,10,0.0,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;National Tsing Hua University,reinforcement learning;exploration;curiosity;optical flow;intrinsic rewards,194;194;194;194,365;365;365;365,m;m,asia,tw,n,2
4959,ICLR,2020,Embodied Multimodal Multitask Learning,Devendra Singh Chaplot;Lisa Lee;Ruslan Salakhutdinov;Devi Parikh;Dhruv Batra,chaplot@cs.cmu.edu;lslee@cs.cmu.edu;rsalakhu@cs.cmu.edu;parikh@gatech.edu;dbatra@gatech.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Georgia Institute of Technology;Georgia Institute of Technology,Visual Grounding;Semantic Goal Navigation;Embodied Question Answering,1;1;1;13;13,27;27;27;38;38,m;m,usa,usa,n,
4960,ICLR,2020,Towards Principled Objectives for Contrastive Disentanglement,Anwesa Choudhuri;Ashok Vardhan Makkuva;Ranvir Rana;Sewoong Oh;Girish Chowdhary;Alexander Schwing,anwesac2@illinois.edu;makkuva2@illinois.edu;rbrana2@illinois.edu;sewoong@cs.washington.edu;girishc@illinois.edu;aschwing@illinois.edu,3;3;3,,Reject,0,4,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Washington;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Disentanglement;Contrastive,-1;-1;-1;11;-1;-1,-1;-1;-1;26;-1;-1,f;m,usa,usa,y,8
4961,ICLR,2020,Hebbian Graph Embeddings,Shalin Shah;Venkataramana Kini,shalin.shah@target.com;venkataramana.kini@target.com,1;1;1,,Reject,0,5,0.0,yes,9/25/19,Target;Target,graph embeddings;hebbian learning;simulated annealing,-1;-1,-1;-1,m;m,NAN,NAN,n,10
4962,ICLR,2020,Probabilistic modeling the hidden layers of deep neural networks,Xinjie Lan;Kenneth E. Barner,lxjbit@udel.edu;barner@udel.edu,6;6;8,,Reject,1,8,0.0,yes,9/25/19,University of Delaware;University of Delaware,Neural Networks;Gaussian Process;Probabilistic Representation for Deep Learning,194;194,295;295,m;m,usa,usa,y,11;1
4963,ICLR,2020,Empirical confidence estimates for classification by deep neural networks,Chris Finlay;Adam M. Oberman,christopher.finlay@gmail.com;adam.oberman@mcgill.ca,1;6;6,,Reject,0,4,0.0,yes,9/25/19,Deep Render;McGill University,confidence;classification;uncertainty;anomaly;robustness,-1;102,-1;42,m;m,canada,ca,n,1
4964,ICLR,2020,TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising,Ziyi Yang;Chenguang Zhu;Michael Zeng;Xuedong Huang;Eric Darve,ziyi.yang@stanford.edu;chezhu@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com;darve@stanford.edu,8;8;6,,Reject,0,4,0.0,yes,9/25/19,Stanford University;Microsoft;Microsoft;Microsoft;Stanford University,text summarization;unsupervised learning;natural language processing,5;-1;-1;-1;5,4;-1;-1;-1;4,m;m,usa,usa,n,8
4965,ICLR,2020,Biologically Plausible Neural Networks via Evolutionary Dynamics and Dopaminergic Plasticity,Sruthi Gorantla;Anand Louis;Christos H. Papadimitriou;Santosh Vempala;Naganand Yadati,sruthi@comp.nus.edu.sg;anandl@iisc.ac.in;christos@columbia.edu;vempala@gatech.edu;y.naganand@gmail.com,1;3;3,,Reject,0,3,0.0,yes,9/25/19,National University of Singapore;Indian Institute of Science;Columbia University;Georgia Institute of Technology;Indian Institute of Science,Biological plausibility;dopaminergic plasticity;allele frequency;neural net evolution,17;-1;24;13;-1,25;301;16;38;-1,f;m,asia,in,y,1
4966,ICLR,2020,Meta-Learning Initializations for Image Segmentation,Sean M. Hendryx;Andrew B. Leach;Paul D. Hein;Clayton T. Morrison,seanmhendryx@gmail.com;imaleach@gmail.com;pauldhein@email.arizona.edu;claytonm@email.arizona.edu,3;3;3,,Reject,0,8,0.0,yes,9/25/19,University of Arizona;Google;University of Arizona;University of Arizona,meta-learning;image segmentation,-1;-1;194;194,-1;-1;103;103,m;m,usa,usa,n,6;2;1
4967,ICLR,2020,Sequence-level Intrinsic Exploration Model for Partially Observable Domains,Haiyan Yin;Jianda Chen;Sinno Jialin Pan,yinhaiyan@outlook.com;jianda001@e.ntu.edu.sg;sinnopan@ntu.edu.sg,6;3;6,,Reject,0,4,0.0,yes,9/25/19,Baidu;Nanyang Technological University;Nanyang Technological University,deep learning;reinforcement learning,-1;43;43,-1;49;49,f;m,asia,sg,n,
4968,ICLR,2020,EINS: Long Short-Term Memory with Extrapolated Input Network Simplification,Nicholas I-Hsien Kuo;Mehrtash T. Harandi;Nicolas Fourrier;Gabriela Ferraro;Christian Walder;Hanna Suominen,u6424547@anu.edu.au;mehrtash.harandi@monash.edu;nicolas.fourrier@devinci.fr;gabriela.ferraro@csiro.au;gabriela.ferraro@data61.csiro.au;christian.walder@data61.csiro.au;hanna.suominen@anu.edu.au,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Australian National University;Monash University;Ecole Superieur d'Ingenieurs Leonard de Vinci;CSIRO;CSIRO;CSIRO;Australian National University,recurrent neural network;RNN;long short-term memory;LSTM;gated recurrent network;GRU;dynamical mathematics;interpretability,102;92;-1;-1;-1;-1;102,50;75;-1;-1;-1;-1;50,m;f,australasia,au,pdf miss,3;5
4969,ICLR,2020,Connectivity-constrained interactive annotations for panoptic segmentation,Ruobing Shen;Bo Tang;Ismail Ben Ayed;Andrea Lodi;Thomas Guthier,ruobing.shen@gmobis.com;lucastang1994@gmail.com;ismail.benayed@etsmtl.ca;andrea.lodi@polymtl.ca;thomas.guthier@gmobis.com,1;3;3;3,,Reject,0,5,0.0,yes,9/25/19,Hyundai Mobis;;√âcole de technologie sup√©rieure;Polytechnique Montreal;Hyundai Mobis,Panoptic Segmentation;Semantic Segmentation;Interactive Segmentation;Integer Programming,-1;-1;-1;316;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2;10
4970,ICLR,2020,Frustratingly easy quasi-multitask learning,G√°bor Berend;Norbert Kis-Szab√≥,berendg@inf.u-szeged.hu;kis-szabo.norbert@stud.u-szeged.hu,1;3,,Reject,0,2,0.0,yes,9/25/19,University of Szeged;University of Szeged,multitask learning;ensembling,445;445,874;874,m;m,europe,de,n,1
4971,ICLR,2020,Towards Effective 2-bit Quantization: Pareto-optimal Bit Allocation for Deep CNNs Compression,Zhe Wang;Jie Lin;Mohamed M. Sabry Aly;Sean I Young;Vijay Chandrasekhar;Bernd Girod,mark.wangzhe@gmail.com;lin-j@i2r.a-star.edu.sg;msabry@ntu.edu.sg;sean.i.young@stanford.edu;vijay@i2r.a-star.edu.sg;bgirod@stanford.edu,8;6;1,,Reject,1,9,0.0,yes,9/25/19,"Stanford University;Institute for Infocomm Research, A*STAR;Nanyang Technological University;Stanford University;Institute for Infocomm Research, A*STAR;Stanford University",,-1;-1;43;5;-1;5,-1;-1;49;4;-1;4,m;m,usa,usa,y,
4972,ICLR,2020,Representing Unordered Data Using Multiset Automata and Complex Numbers,Justin DeBenedetto;David Chiang,jdebened@nd.edu;dchiang@nd.edu,6;3;6,,Reject,0,4,0.0,yes,9/25/19,University of Notre Dame;University of Notre Dame,sets;multisets;automata;complex numbers;position encodings,118;118,157;157,m;m,usa,usa,y,8
4973,ICLR,2020,Domain-invariant Learning using Adaptive Filter Decomposition,Ze Wang;Xiuyuan Cheng;Guillermo Sapiro;Qiang Qiu,ze.w@duke.edu;xiuyuan.cheng@duke.edu;guillermo.sapiro@duke.edu;qiang.qiu@duke.edu,6;1;6,,Reject,0,3,0.0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,,46;46;46;46,20;20;20;20,m;m,europe,se,y,1
4974,ICLR,2020,Gradient-free Neural Network Training by Multi-convex Alternating Optimization,Junxiang Wang;Fuxun Yu;Xiang Chen;Liang Zhao,jwang40@gmu.edu;fyu2@gmu.edu;xchen26@gmu.edu;lzhao9@gmu.edu,1;6,,Reject,0,2,0.0,yes,9/25/19,George Mason University;George Mason University;George Mason University;George Mason University,neural network;alternating minimization;global convergence,85;85;85;85,282;282;282;282,m;m,usa,usa,y,8;1;9
4975,ICLR,2020,GDP: Generalized Device Placement for Dataflow Graphs,Yanqi Zhou;Sudip Roy;Amirali Abdolrashidi;Daniel Wong;Peter C. Ma;Qiumin Xu;Ming Zhong;Hanxiao Liu;Anna Goldie;Azalia Mirhoseini;James Laudon,yanqiz@google.com;sudipr@google.com;abdolrashidi@google.com;wonglkd@google.com;pcma@google.com;qiuminxu@google.com;mingzhong@google.com;hanxiaol@google.com;agoldie@google.com;azalia@google.com;jlaudon@google.com,6;3;6,,Reject,0,6,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,device placement;reinforcement learning;graph neural networks;transformer,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,8;10
4976,ICLR,2020,Policy Optimization In the Face of Uncertainty,Tung-Long Vuong;Han Nguyen;Hai Pham;Kenneth Tran,longvt94@vnu.edu.vn;hann1@andrew.cmu.edu;htpham@cs.cmu.edu;ktran@microsoft.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Australian National University;Carnegie Mellon University;Carnegie Mellon University;Microsoft,Reinforcement Learning;Model-based Reinforcement Learning,102;1;1;-1,50;27;27;-1,m;m,NAN,NAN,n,1;10
4977,ICLR,2020,Learning relevant features for statistical inference,C√©dric B√©ny,cedric.beny@gmail.com,3;3;1,,Reject,0,4,0.0,yes,9/25/19,0,unsupervised learning;non-parametric probabilistic model;singular value decomposition;fisher information metric;chi-squared distance,,,m;m,NAN,NAN,n,11
4978,ICLR,2020,Accelerating Reinforcement Learning Through GPU Atari Emulation,Steven Dalton;Michael Garland;Iuri Frosio,sdalton@nvidia.com;mgarland@nvidia.com;ifrosio@nvidia.com,1;8;8,,Reject,0,4,0.0,yes,9/25/19,NVIDIA;NVIDIA;NVIDIA,GPU;reinforcement learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
4979,ICLR,2020,Discrete InfoMax Codes for Meta-Learning,Yoonho Lee;Wonjae Kim;Seungjin Choi,einet89@gmail.com;dandelin.kim@kakaocorp.com;seungjin.choi.mlg@gmail.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,AITRICS;Kakao;BARO AI Academy,meta-learning;generalization;discrete representations,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,6;1
4980,ICLR,2020,Efficient Saliency Maps for Explainable AI,T. Nathan Mundhenk;Barry Chen;Gerald Friedland,mundhenk1@llnl.gov;chen52@llnl.gov;fractor@eecs.berkeley.edu,6;6;3,,Reject,0,22,0.0,yes,9/25/19,Lawrence Livermore National Labs;Lawrence Livermore National Labs;University of California Berkeley,Saliency;XAI;Efficent;Information,-1;-1;-1,-1;-1;13,m;m,usa,usa,n,
4981,ICLR,2020,Monte Carlo Deep Neural Network Arithmetic,Julian Faraone;Philip Leong,julian.faraone@sydney.edu.au;philip.leong@sydney.edu.au,3;3;6,,Reject,0,4,0.0,yes,9/25/19,University of Sydney;University of Sydney,deep learning;quantization;floating point;monte carlo methods,64;64,60;60,m;m,europe,uk,n,
4982,ICLR,2020,Language-independent Cross-lingual Contextual Representations,Xiao Zhang;Song Wang;Dejing Dou;Xien Liu;Thien Huu Nguyen;Ji Wu,xzhang19@mails.tsinghua.edu.cn;wangsong16@mails.tsinghua.edu.cn;dou@cs.uoregon.edu;xeliu@mail.tsinghua.edu.cn;thien@cs.uoregon.edu;wuji_ee@mail.tsinghua.edu.cn,3;3;3,,Reject,0,1,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Oregon;Tsinghua University, Tsinghua University;University of Oregon;Tsinghua University, Tsinghua University",contextual representation;cross-lingual;transfer learning,4;4;194;4;194;4,23;23;288;23;288;23,m;m,NAN,NAN,n,6;3
4983,ICLR,2020,Deep Nonlinear Stochastic Optimal Control for Systems with Multiplicative Uncertainties,Marcus Pereira;Ziyi Wang;Tianrong Chen;Evangelos Theodorou,mpereira30@gatech.edu;zwang450@gatech.edu;tianrong.chen@gatech.edu;evangelos.theodorou@gatech.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Deep Learning;Stochastic Optimal Control;Robotics;Biomechanics;LSTM,13;13;13;13,38;38;38;38,m;m,usa,usa,n,1
4984,ICLR,2020,Causal Induction from Visual Observations for Goal Directed Tasks,Suraj Nair;Yuke Zhu;Silvio Savarese;Li Fei-Fei,surajn@stanford.edu;yukez@cs.stanford.edu;ssilvio@stanford.edu;feifeili@cs.stanford.edu,6;3;6,,Reject,0,3,0.0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,meta-learning;causal reasoning;policy learning,5;5;5;5,4;4;4;4,m;f,usa,usa,n,6;8;10
4985,ICLR,2020,Towards Understanding the Spectral Bias of Deep Learning,Yuan Cao;Zhiying Fang;Yue Wu;Ding-Xuan Zhou;Quanquan Gu,yuancao@cs.ucla.edu;zyfang4-c@my.cityu.edu.hk;ywu@cs.ucla.edu;mazhou@cityu.edu.hk;qgu@cs.ucla.edu,3;6;6,,Reject,0,3,0.0,yes,9/25/19,"University of California, Los Angeles;The Hong Kong Polytechnic University;University of California, Los Angeles;The Hong Kong Polytechnic University;University of California, Los Angeles",,-1;118;-1;118;-1,17;171;17;171;17,m;m,usa,usa,y,1;9
4986,ICLR,2020,Reweighted Proximal Pruning for Large-Scale Language Representation,Fu-Ming Guo;Sijia Liu;Finlay S. Mungall;Xue Lin;Yanzhi Wang,elphinkuo@gmail.com;sijia.liu@ibm.com;fmungall@gmail.com;xue.lin@northeastern.edu;yanz.wang@northeastern.edu,6;6;6,,Reject,0,7,1.0,yes,9/25/19,Northeastern University;International Business Machines;;Northeastern University;Northeastern University,Language Representation;Machine Learning;Deep Learning;Optimizer;Statistical Learning;Model Compression,-1;-1;-1;16;16,-1;-1;-1;906;906,m;m,usa,usa,n,6;3
4987,ICLR,2020,Distilled embedding: non-linear embedding factorization using knowledge distillation,Vasileios Lioutas;Ahmad Rashid;Krtin Kumar;Md Akmal Haidar;Mehdi Rezagholizadeh,vasileios.lioutas@carleton.ca;ahmad.rashid@huawei.com;krtin.kumar@huawei.com;md.akmal.haidar@huawei.com;mehdi.rezagholizadeh@huawei.com,3;3;3,,Reject,0,6,0.0,yes,9/25/19,Carleton University;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Model Compression;Embedding Compression;Low Rank Approximation;Machine Translation;Natural Language Processing;Deep Learning,194;-1;-1;-1;-1,535;-1;-1;-1;-1,m;m,NAN,NAN,n,3
4988,ICLR,2020,Switched linear projections and inactive state sensitivity for deep neural network interpretability,Lech Szymanski;Brendan McCane;Craig Atkinson,lechszym@cs.otago.ac.nz;mccane@cs.otago.ac.nz;atkcr398@student.otago.ac.nz,1;3;6;6,,Reject,0,17,0.0,yes,9/25/19,University of Otago;University of Otago;University of Otago,deep learning;interpretability;artificial neural networks,445;445;445,218;218;218,m;m,australasia,nz,y,
4989,ICLR,2020,SpectroBank: A filter-bank convolutional layer for CNN-based audio applications,Helena Peic Tukuljac;Benjamin Ricaud;Nicolas Aspert;Pierre Vandergheynst,helena.peictukuljac@epfl.ch;benjamin.ricaud@epfl.ch;nicolas.aspert@epfl.ch;pierre.vandergheynst@epfl.ch,3;3;3,,Reject,0,8,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,audio;classification;convolutional neural network;deep learning;filter;filter-bank;raw waveform,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,
4990,ICLR,2020,Stochastic Latent Residual Video Prediction,Jean-Yves Franceschi;Edouard Delasalles;Mickael Chen;Sylvain Lamprier;Patrick Gallinari,jean-yves.franceschi@lip6.fr;edouard.delasalles@lip6.fr;mickael.chen@lip6.fr;sylvain.lamprier@lip6.fr;patrick.gallinari@lip6.fr,6;3;6,,Reject,0,4,1.0,yes,9/25/19,LIP6;LIP6;LIP6;LIP6;LIP6,stochastic video prediction;variational autoencoder;residual dynamics,445;445;445;445;445,-1;-1;-1;-1;-1,m;m,asia,ir,n,
4991,ICLR,2020,Large-scale Pretraining for Neural Machine Translation with Tens of Billions of Sentence Pairs,Yuxian Meng;Xiangyuan Ren;Zijun Sun;Xiaoya Li;Arianna Yuan;Fei Wu;Jiwei Li,yuxian_meng@shannonai.com;xiangyuan_re@shannonai.com;zijun_sun@shannonai.com;xiaoya_li@shannonai.com;xfyuan@stanford.edu;wufei@zju.edu.cn;jiwei_li@shannonai.com,3;6;3,,Reject,1,4,0.0,yes,9/25/19,Shannon.AI;Shannon.AI;Shannon.AI;Shannon.AI;Stanford University;Zhejiang University;Shannon.AI,,-1;-1;-1;-1;5;39;-1,-1;-1;-1;-1;4;107;-1,m;m,NAN,NAN,n,3
4992,ICLR,2020,Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures,Mohamed El Amine Seddik;Cosme Louart;Mohamed Tamaazousti;Romain Couillet,melaseddik@gmail.com;cosme.louart@gmail.com;mohamed.tamaazousti@cea.fr;romain.couillet@gmail.com,6;3;1,,Reject,0,5,0.0,yes,9/25/19,Ecole polytechnique;;CEA;Institut Polytechnique de Grenoble,Random Matrix Theory;Deep Learning Representations;GANs,-1;-1;194;-1,93;-1;1027;-1,m;m,asia,in,y,5;4
4993,ICLR,2020,The advantage of using Student's t-priors in variational autoencoders,Najmeh Abiri;Mattias Ohlsson,najmeh@thep.lu.se;mattias@thep.lu.se,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Lund University;Lund University,Variational Autoencoders;DLVMs;Posterior Collapse,445;445,98;98,f;m,asia,cn,n,5
4994,ICLR,2020,Neural Communication Systems with Bandwidth-limited Channel,Karen Ullrich;Fabio Viola;Danilo J. Rezende,mail.karen.ullrich@gmail.com;fviola@google.com;danilor@google.com,3;6;6,,Reject,0,3,0.0,yes,9/25/19,Facebook;Google;Google,variational inference;joint coding;bandwidth-limited channel;deep learning;representation learning;compression,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,1
4995,ICLR,2020,Unified Probabilistic Deep Continual Learning through Generative Replay and Open Set Recognition,Martin Mundt;Sagnik Majumder;Iuliia Pliushch;Visvanathan Ramesh,mmundt@em.uni-frankfurt.de;majumder@ccc.cs.uni-frankfurt.de;pliushch@em.uni-frankfurt.de;ramesh@fias.uni-frankfurt.de,6;3;3,,Reject,0,5,0.0,yes,9/25/19,Goethe University;Goethe University;Goethe University;Goethe University,Continual Learning;Open Set Recognition;Probabilistic Deep Learning;Variational Inference,316;316;316;316,305;305;305;305,m;m,NAN,NAN,n,11;5
4996,ICLR,2020,Optimizing Loss Landscape Connectivity via Neuron Alignment,N. Joseph Tatro;Pin-Yu Chen;Payel Das;Igor Melnyk;Prasanna Sattigeri;Rongjie Lai,tatron@rpi.edu;pin-yu.chen@ibm.com;daspa@us.ibm.com;igor.melnyk@ibm.com;psattig@us.ibm.com;lair@rpi.edu,1;6;3,,Reject,0,6,0.0,yes,9/25/19,Rensselaer Polytechnic Institute;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Rensselaer Polytechnic Institute,deep learning;optimization;non-convex optimization,248;-1;-1;-1;-1;248,438;-1;-1;-1;-1;438,m;m,usa,usa,y,
4997,ICLR,2020,Adaptive Online Planning for Continual Lifelong Learning,Kevin Lu;Igor Mordatch;Pieter Abbeel,kzl@berkeley.edu;imordatch@google.com;pabbeel@cs.berkeley.edu,1;6;3,,Reject,0,5,0.0,yes,9/25/19,University of California Berkeley;Google;University of California Berkeley,reinforcement learning;model predictive control;planning;model based;model free;uncertainty;computation,-1;-1;-1,13;-1;13,m;m,usa,usa,n,
4998,ICLR,2020,Adversarially Robust Generalization Just Requires More Unlabeled Data,Runtian Zhai;Tianle Cai;Di He;Chen Dan;Kun He;John E. Hopcroft;Liwei Wang,zhairuntian@pku.edu.cn;caitianle1998@pku.edu.cn;dihe@microsoft.com;cdan@cs.cmu.edu;brooklet60@hust.edu.cn;jeh17@cornell.edu;wanglw@cis.pku.edu.cn,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Peking University;Peking University;Microsoft;Carnegie Mellon University;Hong Kong University of Science and Technology;Cornell University;Peking University,Adversarial Robustness;Semi-supervised Learning,14;14;-1;1;-1;7;14,24;24;-1;27;47;19;24,m;m,asia,cn,y,1;4
4999,ICLR,2020,Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing,Dinghuai Zhang*;Mao Ye*;Chengyue Gong*;Zhanxing Zhu;Qiang Liu,zhangdinghuai@pku.edu.cn;lushleaf21@gmail.com;cygong@cs.utexas.edu;zhanxing.zhu@pku.edu.cn;lqiang@cs.utexas.edu,1;1;3,,Reject,2,5,0.0,yes,9/25/19,"Peking University;;University of Texas, Austin;Peking University;University of Texas, Austin",Adversarial Certification;Randomized Smoothing;Functional Optimization,14;-1;-1;14;-1,24;-1;-1;24;-1,m;m,usa,usa,y,4
5000,ICLR,2020,Zeno++: Robust Fully Asynchronous SGD,Cong Xie;Oluwasanmi Koyejo;Indranil Gupta,cx2@illinois.edu;sanmi@illinois.edu;indy@illinois.edu,3;3;6,,Reject,0,9,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",fault-tolerance;Byzantine-tolerance;security;SGD;asynchronous,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y,1
5001,ICLR,2020,LARGE SCALE REPRESENTATION LEARNING FROM TRIPLET COMPARISONS,Siavash Haghiri;Leena Chennuru Vankadara;Ulrike von Luxburg,siyavash.haghiri@gmail.com;leena.chennuru-vankadara@uni-tuebingen.de;luxburg@informatik.uni-tuebingen.de,3;1;3;6,,Reject,0,9,0.0,yes,9/25/19,University of Tuebingen;University of Tuebingen;University of Tuebingen,representation learning;triplet comparison;contrastive learning;ordinal embedding,-1;143;143,-1;91;91,m;f,europe,de,n,8
5002,ICLR,2020,A Mean-Field Theory for Kernel Alignment with Random Features in Generative Adverserial Networks,Masoud Badiei Khuzani;Liyue Shen;Shahin Shahrampour;Lei Xing,mbadieik@stanford.edu;liyues@stanford.edu;shahin@tamu.edu;lei@stanford.edu,1;6;6,,Reject,0,3,0.0,yes,9/25/19,Stanford University;Stanford University;Texas A&M;Stanford University,Kernel Learning;Generative Adversarial Networks;Mean Field Theory,5;5;46;5,4;4;177;4,m;m,usa,usa,y,1;5;4
5003,ICLR,2020,Homogeneous Linear Inequality Constraints for Neural Network Activations,Thomas Frerix;Matthias Nie√üner;Daniel Cremers,thomas.frerix@tum.de;niessner@tum.de;cremers@tum.de,1;3;3,,Reject,0,4,0.0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,deep learning;constrained optimization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5
5004,ICLR,2020,Distributed Online Optimization with Long-Term Constraints,Deming Yuan;Alexandre Proutiere;Guodong Shi,dmyuan1012@gmail.com;alepro@kth.se;guodong.shi@anu.edu.au,3;6;6,,Reject,0,5,0.0,yes,9/25/19,"Australian National University;KTH Royal Institute of Technology, Stockholm, Sweden;Australian National University",,-1;194;102,-1;222;50,m;m,australasia,au,y,10;9
5005,ICLR,2020,Semi-supervised Pose Estimation with Geometric Latent Representations,Luis A. Perez Rey;Dmitri Jarnikov;Mike Holenderski,l.a.perez.rey@tue.nl;d.s.jarnikov@tue.nl;m.holenderski@tue.nl,3;3;1,,Reject,0,3,0.0,yes,9/25/19,Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology,Semi-supervised learning;pose estimation;angle estimation;variational autoencoders,-1;-1;-1,185;185;185,m;m,NAN,NAN,n,2;5
5006,ICLR,2020,Parallel Scheduled Sampling,Daniel Duckworth;Arvind Neelakantan;Ben Goodrich;Lukasz Kaiser;Samy Bengio,duckworthd@google.com;aneelakantan@google.com;bgoodrich@google.com;lukaszkaiser@google.com;bengio@google.com,6;3;6,,Reject,0,7,0.0,yes,9/25/19,Google;Google;Google;Google;Google,deep learning;generative models;teacher forcing;scheduled sampling,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5007,ICLR,2020,ADAPTING PRETRAINED LANGUAGE MODELS FOR LONG DOCUMENT CLASSIFICATION,Matthew Lyle Olson;Lisa Zhang;Chun-Nam Yu,olsomatt@oregonstate.edu;lisa.zhang@nokia-bell-labs.com;cnyu@cs.cornell.edu,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Oregon State University;Bell Labs;Cornell University,NLP;Deep Learning;Language Models;Long Document,79;-1;7,373;-1;19,m;m,usa,usa,n,8;3
5008,ICLR,2020,Composable Semi-parametric Modelling for Long-range Motion Generation,Jingwei Xu;Huazhe Xu;Bingbing Ni;Xiaokang Yang;Trevor Darrell,xjwxjw@sjtu.edu.cn;huazhe_xu@eecs.berkeley.edu;nibingbing@sjtu.edu.cn;xkyang@sjtu.edu.cn;trevor@eecs.berkeley.edu,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Shanghai Jiao Tong University;University of California Berkeley;Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of California Berkeley,Semi-parametric;Long-range;Motion Generation,30;-1;30;30;-1,157;13;157;157;13,m;m,usa,usa,n,
5009,ICLR,2020,Finding Mixed Strategy Nash Equilibrium for Continuous Games through Deep Learning,Zehao Dou;Xiang Yan;Dongge Wang;Xiaotie Deng,zehaodou@pku.edu.cn;yxghost@sjtu.edu.cn;dgwang96@pku.edu.cn;xiaotie@pku.edu.cn,6;6;3,,Reject,0,9,0.0,yes,9/25/19,Peking University;Shanghai Jiao Tong University;Peking University;Peking University,Mixed strategy Nash Equilibrium;Continuous Game;Pushforward Measure;NI Function,14;30;14;14,24;157;24;24,m;m,asia,cn,y,5;4
5010,ICLR,2020,Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets,Zhilu Zhang;Adrian V. Dalca;Mert R. Sabuncu,zz452@cornell.edu;adalca@mit.edu;msabuncu@cornell.edu,3;1;1,,Reject,0,3,0.0,yes,9/25/19,Cornell University;Massachusetts Institute of Technology;Cornell University,Uncertainty Estimation;Calibration;Deep Learning,7;5;7,19;5;19,m;m,usa,usa,n,11
5011,ICLR,2020,Online Learned Continual Compression with Stacked Quantization Modules,Lucas Caccia;Eugene Belilovsky;Massimo Caccia;Joelle Pineau,lucas.page-caccia@mail.mcgill.ca;belilovsky.eugene@gmail.com;massimo.p.caccia@gmail.com;jpineau@cs.mcgill.ca,3;3;6;3;6,,Reject,1,4,0.0,yes,9/25/19,McGill University;University of Montreal;University of Montreal;McGill University,continual learning;lifelong learning,102;118;118;102,42;85;85;42,m;f,canada,ca,n,
5012,ICLR,2020,Yet another but more efficient black-box adversarial attack: tiling and evolution strategies,Laurent Meunier;Jamal Atif;Olivier Teytaud,laurent.meunier1995@gmail.com;jamal.atif@dauphine.fr;oteytaud@fb.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Univerist√© Paris-Dauphine;Univerist‚àö¬© Paris-Dauphine;Facebook,adversarial examples;black-box attacks;derivative free optimization;deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,4
5013,ICLR,2020,AlignNet: Self-supervised Alignment Module,Antonia Creswell;Luis Piloto;David Barrett;Kyriacos Nikiforou;David Raposo;Marta Garnelo;Peter Battaglia;Murray Shanahan,tonicreswell@google.com;piloto@google.com;peterbattaglia@google.com;knikiforou@google.com;barrettdavid@google.com;garnelo@google.com;mshanahan@google.com;draposo@google.com,6;3;1,,Reject,0,3,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,Graph networks;alignment;objects;relation networks,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,10
5014,ICLR,2020,A Simple Recurrent Unit with Reduced Tensor Product Representations,Shuai Tang;Paul Smolensky;Virginia R. de Sa,shuaitang93@ucsd.edu;paul.smolensky@gmail.com;desa@ucsd.edu,6;3;3,,Reject,0,1,0.0,yes,9/25/19,"University of California, San Diego;Microsoft;University of California, San Diego",RNNs;TPRs,-1;-1;-1,31;-1;31,m;f,usa,usa,n,3;1
5015,ICLR,2020,A Hierarchy of Graph Neural Networks Based on Learnable Local Features,Michael Lingzhi Li;Meng Dong;Jiawei Zhou;Alexander M. Rush,mlli@mit.edu;mengdong@g.harvard.edu;jzhou02@g.harvard.edu;srush@cornell.edu,3;8;3,,Reject,0,6,0.0,yes,9/25/19,Massachusetts Institute of Technology;Harvard University;Harvard University;Cornell University,Graph Neural Networks;Hierarchy;Weisfeiler-Lehman;Discriminative Power,5;52;52;7,5;7;7;19,m;m,usa,usa,y,1;10
5016,ICLR,2020,Discriminability Distillation in Group Representation Learning,Manyuan ZhangÔºåGuanglu SongÔºåYu LiuÔºåHang Zhou,zhangmanyuan@sensetime.com;songguanglu@sensetime.com;yuliu@ee.cuhk.edu.hk;zhouhang@link.cuhk.edu.hk,3;1;6;6,,Reject,0,4,0.0,yes,9/25/19,SenseTime Group Limited;SenseTime Group Limited;The Chinese University of Hong Kong;The Chinese University of Hong Kong,,-1;-1;316;316,-1;-1;35;35,f;m,NAN,NAN,n,8;2
5017,ICLR,2020,Blurring Structure and Learning to Optimize and Adapt Receptive Fields,Evan Shelhamer;Dequan Wang;Trevor Darrell,shelhamer@cs.berkeley.edu;dqwang@eecs.berkeley.edu;trevor@eecs.berkeley.edu,3;6;3,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,scale;deep learning;dynamic inference;fully convolutional,-1;-1;-1,13;13;13,m;m,usa,usa,n,2
5018,ICLR,2020,Conditional Flow Variational Autoencoders for Structured Sequence Prediction,Apratim Bhattacharyya;Michael Hanselmann;Mario Fritz;Bernt Schiele;Christoph-Nikolas Straehle,abhattac@mpi-inf.mpg.de;michael.hanselmann@de.bosch.com;fritz@cispa.saarland;schiele@mpi-inf.mpg.de;christoph-nikolas.straehle@de.bosch.com,6;6;1,,Reject,0,4,0.0,yes,9/25/19,Max-Planck Institute;Bosch;CISPA Helmholtz Center for Information Security;Max-Planck Institute;Bosch,Variational Inference;Normalizing Flows;Trajectories,-1;-1;92;-1;-1,-1;297;-1;-1;297,m;m,NAN,NAN,n,5
5019,ICLR,2020,LAVAE: Disentangling Location and Appearance,Andrea Dittadi;Ole Winther,adit@dtu.dk;olwi@dtu.dk,1;1;3,,Reject,0,2,0.0,yes,9/25/19,Technical University of Denmark;Technical University of Denmark,structured scene representations;compositional representations;generative models;unsupervised learning,-1;-1,182;182,m;m,NAN,NAN,n,5
5020,ICLR,2020,BETANAS: Balanced Training and selective drop for Neural Architecture Search,Muyuan Fang;Qiang Wang;Jian Zhang;Zhao Zhong,fangmuyuan@huawei.com;wangqiang168@huawei.com;zhangjian157@huawei.com;zorro.zhongzhao@huawei.com,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,neural architecture search;weight sharing;auto machine learning;deep learning;CNN,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,7
5021,ICLR,2020,Unifying Graph Convolutional Neural Networks and Label Propagation,Hongwei Wang;Jure Leskovec,wanghongwei55@gmail.com;jure@cs.stanford.edu,3;6;1,,Reject,0,3,0.0,yes,9/28/20,Stanford University;Stanford University,graph convolutional neural networks;label propagation;node classification,5;5,4;4,m;m,usa,usa,y,8;10
5022,ICLR,2020,Defective Convolutional Layers Learn Robust CNNs,Tiange Luo;Tianle Cai;Xiaomeng Zhang;Siyu Chen;Di He;Liwei Wang,luotg@pku.edu.cn;caitianle1998@pku.edu.cn;zhan147@usc.edu;siyuchen@pku.edu.cn;dihe@microsoft.com;wanglw@cis.pku.edu.cn,3;1;6,,Reject,0,4,0.0,yes,9/25/19,Peking University;Peking University;University of Southern California;Peking University;Microsoft;Peking University,adversarial examples;robust machine learning;cnn structure;deep feature representations,14;14;36;14;-1;14,24;24;62;24;-1;24,m;m,asia,cn,n,4
5023,ICLR,2020,Unsupervised Progressive Learning and the STAM Architecture,James Smith;Constantine Dovrolis,jamessealesmith@gatech.edu;constantine@gatech.edu,8;3;8,,Reject,0,5,2.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology,continual learning;unsupervised learning;online learning,13;13,38;38,m;m,usa,usa,n,
5024,ICLR,2020,Asymptotic learning curves of kernel methods: empirical data v.s. Teacher-Student paradigm,Stefano Spigler;Mario Geiger;Matthieu Wyart,stefano.spigler@epfl.ch;mario.geiger@epfl.ch;matthieu.wyart@epfl.ch,3;3;6,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
5025,ICLR,2020,Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation,Ran Tian;Shashi Narayan;Thibault Sellam;Ankur P. Parikh,tianran@google.com;shashinarayan@google.com;tsellam@google.com;aparikh@google.com,6;3;8;3,,Reject,0,9,0.0,yes,9/25/19,Google;Google;Google;Google,Natural Language Processing;Text Generation;Data-to-Text Generation;Hallucination;Calibration;Variational Bayes,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5026,ICLR,2020,Evidence-Aware Entropy Decomposition For  Active Deep Learning,Weishi Shi;Xujiang Zhao;Feng Chen;Qi Yu,ws7586@rit.edu;xujiang.zhao@utdallas.edu;feng.chen@utdallas.edu;qi.yu@rit.edu,6;3,,Reject,0,5,0.0,yes,9/25/19,"Rochester Institute of Technology;University of Texas, Dallas;University of Texas, Dallas;Rochester Institute of Technology",active learning;entropy decomposition;uncertainty,118;-1;-1;118,843;-1;-1;843,m;m,usa,usa,y,
5027,ICLR,2020,Meta-Learning by Hallucinating Useful Examples,Yu-Xiong Wang;Yuki Uchiyama;Martial Hebert;Karteek Alahari,yuxiongw@cs.cmu.edu;braverthan2@gmail.com;hebert@ri.cmu.edu;karteek.alahari@inria.fr,3;6;6,,Reject,0,5,0.0,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University;INRIA,few-shot learning;meta-learning,1;-1;1;-1,27;-1;27;-1,m;m,europe,gr,n,6
5028,ICLR,2020,PDP: A General Neural Framework for Learning SAT Solvers,Saeed Amizadeh;Sergiy Matusevych;Markus Weimer,saamizad@microsoft.com;sergiym@microsoft.com;markus.weimer@microsoft.com,1;6;3,,Reject,0,3,0.0,yes,9/25/19,Microsoft;Microsoft;Microsoft,Neural SAT solvers;Graph Neural Networks;Neural Message Passing;Unsupervised Learning;Neural Decimation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,10
5029,ICLR,2020,Consistency-Based Semi-Supervised Active Learning: Towards Minimizing Labeling Budget,Mingfei Gao;Zizhao Zhang;Guo Yu;Sercan O. Arik;Larry S. Davis;Tomas Pfister,mgao@cs.umd.edu;zizhaoz@google.com;gy63@uw.edu;soarik@google.com;lsd@umiacs.umd.edu;tpfister@google.com,6;6,,Reject,0,6,0.0,yes,9/25/19,"University of Maryland, College Park;Google;University of Washington, Seattle;Google;University of Maryland, College Park;Google",Active learning;semi-supervised learning,12;-1;11;-1;12;-1,91;-1;26;-1;91;-1,m;m,NAN,NAN,y,
5030,ICLR,2020,TabNet: Attentive Interpretable Tabular Learning,Sercan O. Arik;Tomas Pfister,soarik@google.com;tpfister@google.com,6;3;3,,Reject,1,8,0.0,yes,9/25/19,Google;Google,Tabular data;interpretable neural networks;attention models,-1;-1,-1;-1,m;m,NAN,NAN,n,8;10
5031,ICLR,2020,Adapting Behaviour for Learning Progress,Tom Schaul;Diana Borsa;David Ding;David Szepesvari;Georg Ostrovski;Will Dabney;Simon Osindero,schaul@google.com;borsa@google.com;fding@google.com;dsz@google.com;ostrovski@google.com;wdabney@google.com;osindero@google.com,6;3;3;3,,Reject,0,6,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,adaptation;behaviour;reinforcement learning;modulated behaviour;exploration;deep reinforcement learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5032,ICLR,2020,Improving Differentially Private Models with Active Learning,Zhengli Zhao;Nicolas Papernot;Sameer Singh;Neoklis Polyzotis;Augustus Odena,zhengliz@uci.edu;papernot@google.com;sameer@uci.edu;npolyzotis@google.com;augustusodena@google.com,3;3;1,,Reject,1,5,0.0,yes,9/25/19,"University of California, Irvine;Google;University of California, Irvine;Google;Google",Differential Privacy;Active Learning,-1;-1;-1;-1;-1,96;-1;96;-1;-1,m;m,NAN,NAN,n,1
5033,ICLR,2020,Style-based Encoder Pre-training for Multi-modal Image Synthesis,Moustafa Meshry;Yixuan Ren;Ricardo Martin-Brualla;Larry Davis;Abhinav Shrivastava,mmeshry@cs.umd.edu;yxren@cs.umd.edu;rmbrualla@google.com;lsd@umiacs.umd.edu;abhinav@cs.umd.edu,3;3;3,,Reject,0,4,0.0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;Google;University of Maryland, College Park;University of Maryland, College Park",image-to_image translation;representation learning;multi-modal image synthesis;GANs,12;12;-1;12;12,91;91;-1;91;91,m;m,usa,usa,n,5
5034,ICLR,2020,GRAPH ANALYSIS AND GRAPH POOLING IN THE SPATIAL DOMAIN,Mostafa Rahmani;Ping Li,mostafarahmani@baidu.com;liping11@baidu.com,6;6;3,,Reject,0,9,1.0,yes,9/25/19,Baidu;Baidu,Graph Neural Network;Graph Classification;Graph Pooling;Graph Embedding,-1;-1,-1;-1,m;m,NAN,NAN,n,10
5035,ICLR,2020,Cover Filtration and Stable Paths in the Mapper,Dustin L. Arendt;Matthew Broussard;Bala Krishnamoorthy;Nathaniel Saul,dustin.arendt@pnnl.gov;matthew.broussard@wsu.edu;kbala@wsu.edu;nat@riverasaul.com,1;6,,Reject,0,7,0.0,yes,9/25/19,Pacific Northwest National Laboratory;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Riverasaul,cover and nerve;Jaccard distance;stable paths in filtration;Mapper;recommender systems;explainable machine learning,-1;-1;-1;-1,-1;299;299;-1,m;m,NAN,NAN,y,1
5036,ICLR,2020,Rigging the Lottery: Making All Tickets Winners,Utku Evci;Erich Elsen;Pablo Castro;Trevor Gale,ue225@nyu.edu;eriche@google.com;tgale@google.com;psc@google.com,3;6;6,,Reject,0,13,4.0,yes,9/25/19,New York University;Google;Google;Google,sparse training;sparsity;pruning;lottery tickets;imagenet;resnet;mobilenet;efficiency;optimization;local minima,22;-1;-1;-1,29;-1;-1;-1,m;m,NAN,NAN,n,
5037,ICLR,2020,Disentangled GANs for Controllable Generation of High-Resolution Images,Weili Nie;Tero Karras;Animesh Garg;Shoubhik Debhath;Anjul Patney;Ankit B. Patel;Anima Anandkumar,wn8@rice.edu;tkarras@nvidia.com;garg@cs.toronto.edu;shoubhikdn@gmail.com;anjul.patney@gmail.com;abp4@rice.edu;animakumar@gmail.com,3;3;3,,Reject,0,5,0.0,yes,9/25/19,Rice University;NVIDIA;University of Toronto;NVIDIA;Facebook;Rice University;California Institute of Technology,Disentangled GANs;controllable generation;high-resolution image synthesis;semantic manipulation;fine-grained factors,92;-1;18;-1;-1;92;143,105;-1;18;-1;-1;105;2,m;f,usa,usa,n,1;5;4
5038,ICLR,2020,UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS,Israr Ul Haq;Yoshinobu Kawahara,israr.haq@riken.jp;kawahara@imi.kyushu-u.ac.jp,3;3;6,,Reject,0,0,0.0,yes,9/25/19,RIKEN;Kyushu University,Non-linear dynamics;Convolutional Autoencoder;Foreground modeling;Video classification;Dynamic mode decomposition,-1;-1,-1;460,m;m,NAN,NAN,n,8;2
5039,ICLR,2020,First-Order Preconditioning via Hypergradient Descent,Ted Moskovitz;Rui Wang;Janice Lan;Sanyam Kapoor;Thomas Miconi;Jason Yosinski;Aditya Rawal,thmoskovitz@gmail.com;ruiwang@uber.com;janlan@uber.com;sanyam@uber.com;tmiconi@uber.com;yosinski@uber.com;aditya.rawal@uber.com,3;3;3,,Reject,0,6,0.0,yes,9/25/19,University College London;Uber;Uber;Uber;Uber;Uber;Uber,optimization;deep learning;hypgergradient,52;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,southamerica,br,n,
5040,ICLR,2020,Zero-shot task adaptation by homoiconic meta-mapping,Andrew K. Lampinen;James L. McClelland,lampinen@stanford.edu;jlmcc@stanford.edu,3;3;3,,Reject,0,8,0.0,yes,9/25/19,Stanford University;Stanford University,Meta-mapping;zero-shot;task adaptation;task representation;meta-learning,5;5,4;4,m;m,usa,usa,n,6
5041,ICLR,2020,MLModelScope: A Distributed Platform for ML Model Evaluation and Benchmarking at Scale,Cheng Li;Abdul Dakkak;Jinjun Xiong;Wen-mei Hwu,cli99@illinois.edu;dakkak@illinois.edu;jinjun@us.ibm.com;w-hwu@illinois.edu,1;6;6,,Reject,0,13,0.0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;International Business Machines;University of Illinois, Urbana Champaign",Evaluation;Scalable;Repeatable;Fair;System,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,n,
5042,ICLR,2020,Efficient Multivariate Bandit Algorithm with Path Planning,Keyu Nie;Zezhong Zhang;Ted Tao Yuan;Rong Song;Pauline Berry Burke,keyunie@google.com;zezzhang@ebay.com;teyuan@ebay.com;rsong@ebay.com;pmburke10@gmail.com,3;1;6,,Reject,0,2,0.0,yes,9/25/19,Google;eBay;eBay;eBay;eBay,Multivariate Multi-armed Bandit;Monte Carlo Tree Search;Thompson Sampling;Path Planning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,asia,in,n,10
5043,ICLR,2020,Statistical Adaptive Stochastic Optimization,Pengchuan Zhang;Hunter Lang;Qiang Liu;Lin Xiao,penzhan@microsoft.com;hjl@mit.edu;lqiang@cs.utexas.edu;lin.xiao@microsoft.com,6;8;3,,Reject,0,6,0.0,yes,9/25/19,"Microsoft;Massachusetts Institute of Technology;University of Texas, Austin;Microsoft",,-1;5;-1;-1,-1;5;-1;-1,m;m,NAN,NAN,n,
5044,ICLR,2020,The Benefits of Over-parameterization at Initialization in Deep ReLU Networks,Devansh Arpit;Yoshua Bengio,devansharpit@gmail.com;yoshua.bengio@mila.quebec,1;3;3;3,,Reject,0,0,0.0,yes,9/25/19,SalesForce.com;Mila,deep relu networks;he initialization;norm preserving;gradient preserving,-1;143,-1;336,m;m,NAN,NAN,n,1
5045,ICLR,2020,Multichannel Generative Language Models,Harris Chan;Jamie Kiros;William Chan,hchan@cs.toronto.edu;kiros@google.com;williamchan@google.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,University of Toronto;Google;Google,text generation;generative language models;natural language processing,18;-1;-1,18;-1;-1,m;m,NAN,NAN,n,3;5
5046,ICLR,2020,Set Functions for Time Series,Max Horn;Michael Moor;Christian Bock;Bastian Rieck;Karsten Borgwardt,max.horn@bsse.ethz.ch;michael.moor@bsse.ethz.ch;christian.bock@bsse.ethz.ch;bastian.rieck@bsse.ethz.ch;karsten.borgwardt@bsse.ethz.ch,6;6;3,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Time Series;Set functions;Irregularly sampling;Medical Time series;Dynamical Systems;Time series classification,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5047,ICLR,2020,HIPPOCAMPAL NEURONAL REPRESENTATIONS IN CONTINUAL LEARNING,Samia Mohinta;Rui Ponte Costa;Stephane Ciocchi,dc18393@bristol.ac.uk;rui.costa@bristol.ac.uk,1;1;3;6,,Reject,0,4,0.0,yes,9/25/19,University of Bristol;University of Bristol,,118;118,87;87,f;m,europe,uk,n,
5048,ICLR,2020,Augmenting Transformers with KNN-Based Composite Memory,Angela Fan;Claire Gardent;Chloe Braud;Antoine Bordes,angelafan@fb.com;claire.gardent@loria.fr;chloe.braud@loria.fr;abordes@fb.com,6;6;3,,Reject,0,3,0.0,yes,9/25/19,Facebook;University of Lorraine;University of Lorraine;Facebook,knn;memory-augmented networks;language generation;dialogue,-1;-1;-1;-1,-1;624;624;-1,f;m,NAN,NAN,n,8;5
5049,ICLR,2020,Winning Privately: The Differentially Private Lottery Ticket Mechanism,Lovedeep Gondara;Ke Wang;Ricardo Silva Carvalho,lgondara@sfu.ca;wang@sfu.ca;ricardo_silva_carvalho@sfu.ca,3;3;3,,Reject,1,3,0.0,yes,9/25/19,Simon Fraser University;Simon Fraser University;Simon Fraser University,Differentially private neural networks;lottery ticket hypothesis;differential privacy,52;52;52,272;272;272,m;m,canada,ca,y,
5050,ICLR,2020,Localizing and Amortizing: Efficient Inference for Gaussian Processes,Linfeng Liu;Liping Liu,linfeng.liu@tufts.edu;liping.liu@tufts.edu,1;3;3,,Reject,1,5,0.0,yes,9/25/19,Tufts University;Tufts University,Gaussian Processes;Variational Inference;Amortized Inference;Nearest Neighbors,194;194,139;139,m;m,usa,usa,n,
5051,ICLR,2020,BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning,Xinyue Chen;Zijian Zhou;Zheng Wang;Che Wang;Yanqiu Wu;Qing Deng;Keith Ross,xc1305@nyu.edu;zz1435@nyu.edu;zw1454@nyu.edu;cw1681@nyu.edu;yanqiu.wu@nyu.edu;qd319@nyu.edu;keithwross@nyu.edu,3;1;3,,Reject,0,3,0.0,yes,9/25/19,New York University;New York University;New York University;New York University;New York University;New York University;New York University,Deep Reinforcement Learning;Batch Reinforcement Learning;Sample Efficiency,22;22;22;22;22;22;22,29;29;29;29;29;29;29,f;m,usa,usa,n,
5052,ICLR,2020,Entropy Penalty: Towards Generalization Beyond the IID Assumption,Devansh Arpit;Caiming Xiong;Richard Socher,devansharpit@gmail.com;cxiong@salesforce.com;rsocher@salesforce.com,1;3;3,,Reject,0,0,0.0,yes,9/25/19,SalesForce.com;SalesForce.com;SalesForce.com,domain shift;information bottleneck;entropy penalty;out of distribution generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
5053,ICLR,2020,A Causal View on Robustness  of Neural Networks,Cheng Zhang;Yingzhen Li,cheng.zhang@microsoft.com;yingzhen.li@microsoft.com,3;8;8,,Reject,0,2,1.0,yes,9/25/19,Microsoft;Microsoft,Neural Network Robustness;Variational autoencoder (VAE);Causality;Deep generative model,-1;-1,-1;-1,m;f,NAN,NAN,n,
5054,ICLR,2020,Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing,Philip May,eniak.info@gmail.com,1;1;1,,Reject,0,0,0.0,yes,9/25/19,T-Systems on site services GmbH,image augmentation;cnn;images;augmentation,-1,-1,m,NAN,NAN,n,
5055,ICLR,2020,Model-free Learning Control of Nonlinear Stochastic Systems with Stability Guarantee,Minghao Han;Yuan Tian;Lixian Zhang;Jun Wang;Wei Pan,mhhan@hit.edu.cn;yuantian013@163.com;lixianzhang@hit.edu.cn;jun.wang@cs.ucl.ac.uk;wei.pan@tudelft.nl,1;6;3,,Reject,0,7,0.0,yes,9/25/19,Harbin Institute of Technology;163;Harbin Institute of Technology;University College London;Delft University of Technology,Reinforcement learning;nonlinear stochastic system;Lyapunov,168;-1;168;52;-1,424;-1;424;-1;67,m;m,NAN,NAN,y,1
5056,ICLR,2020,A Theoretical Analysis of  Deep Q-Learning,Zhuoran Yang;Yuchen Xie;Zhaoran Wang,zy6@princeton.edu;yuchenxie2020@u.northwestern.edu;zhaoranwang@gmail.com,8;3;3,,Reject,0,6,0.0,yes,9/25/19,Princeton University;Northwestern University;Northwestern University,reinforcement learning;deep Q network;minimax-Q learning;zero-sum Markov Game,30;46;46,6;22;22,m;m,usa,usa,y,
5057,ICLR,2020,On the Pareto Efficiency of Quantized CNN,Ting-Wu Chin;Pierce I-Jen Chuang;Vikas Chandra;Diana Marculescu,tingwuc@cmu.edu;pichuang@fb.com;vchandra@fb.com;dianam@cmu.edu,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Carnegie Mellon University,convolutional neural networks quantization;model compression;efficient neural network,1;-1;-1;1,27;-1;-1;27,f;m,usa,usa,y,2
5058,ICLR,2020,Robust Reinforcement Learning via Adversarial Training with  Langevin Dynamics,Huang Yu-Ting;Parameswaran Kamalaruban;Paul Rolland;Ya-Ping Hsieh;Volkan Cevher,yu.huang@epfl.ch;kamalaruban.parameswaran@epfl.ch;paul.rolland@epfl.ch;ya-ping.hsieh@epfl.ch;volkan.cevher@epfl.ch,3;3;3;6,,Reject,0,6,0.0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,deep reinforcement learning;robust reinforcement learning;min-max problem,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,y,1
5059,ICLR,2020,Robust Reinforcement Learning with Wasserstein Constraint,Linfang Hou;Liang Pang;Xin Hong;Yanyan Lan;Zhiming Ma;Dawei Yin,houlinfang09@gmail.com;pangliang@ict.ac.cn;hongxin19b@ict.ac.cn;lanyanyan@ict.ac.cn;mazm@amt.ac.cn;yindawei@acm.org,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"JD AI Research;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Chinese Academy of Sciences;Baidu Inc.",,-1;30;30;30;30;-1,-1;-1;-1;-1;-1;-1,u;m,asia,in,y,
5060,ICLR,2020,Representation Learning for Remote Sensing: An Unsupervised Sensor Fusion Approach,Aidan M. Swope;Xander H. Rudelis;Kyle T. Story,aidanswope@gmail.com;xander@descarteslabs.com;kyle@descarteslabs.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"California Institute of Technology;Descartes Labs, Inc;Descartes Labs, Inc",unsupervised learning;representation learning;deep learning;remote sensing;sensor fusion,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5061,ICLR,2020,Learning to Combat Compounding-Error in Model-Based Reinforcement Learning,Chenjun Xiao;Yifan Wu;Chen Ma;Dale Schuurmans;Martin M√ºller,chenjun@ualberta.ca;yw4@andrew.cmu.edu;chenchloem@gmail.com;daes@ualberta.ca;mmueller@ualberta.ca,1;6;8,,Reject,0,3,0.0,yes,9/25/19,University of Alberta;Carnegie Mellon University;;University of Alberta;University of Alberta,reinforcement learning;model-based RL,102;1;-1;102;102,136;27;-1;136;136,u;m,canada,ca,y,
5062,ICLR,2020,Recurrent Neural Networks are Universal Filters,Wenjie Xu;Xiuqiong Chen;Stephen S.-T. Yau,1155118056@link.cuhk.edu.hk;cxq0828@tsinghua.edu.cn;yau@uic.edu,3;3;6,,Reject,0,4,0.0,yes,9/25/19,"The Chinese University of Hong Kong;Tsinghua University, Tsinghua University;University of Illinois, Chicago",Recurrent Neural Networks;Expressive Power;Deep Learning Theory,316;4;-1,35;23;-1,m;m,usa,usa,y,11;1
5063,ICLR,2020,Soft Token Matching for Interpretable Low-Resource Classification,Federico Errica;Fabrizio Silvestri;Bora Edizel;Sebastian Riedel;Ludovic Denoyer;Vassilis Plachouras,federico.errica@phd.unipi.it;fabrizio.silvestri@gmail.com;b.edizel@gmail.com;sebastian.riedel@gmail.com;denoyer@fb.com;vplachouras@fb.com,3;3;1,,Reject,0,6,0.0,yes,9/25/19,University of Pisa;Sapienza University of Rome;Facebook;Facebook;Facebook;Facebook,low-resource classification;semantic matching;error boosting;text classification;natural language processing,248;102;-1;-1;-1;-1,366;258;-1;-1;-1;-1,m;m,NAN,NAN,n,
5064,ICLR,2020,A Mention-Pair Model of Annotation with Nonparametric User Communities,Silviu Paun;Juntao Yu;Jon Chamberlain;Udo Kruschwitz;Massimo Poesio,s.paun@qmul.ac.uk;juntao.yu@qmul.ac.uk;jchamb@essex.ac.uk;udo@essex.ac.uk;m.poesio@qmul.ac.uk,3;8;6;6,,Reject,0,5,0.0,yes,9/25/19,Queen Mary University London;Queen Mary University London;University of Essex;University of Essex;Queen Mary University London,model of annotation;coreference resolution;anaphoric annotation;mention pair model;bayesian nonparametrics,-1;-1;248;248;-1,-1;-1;272;272;-1,m;m,europe,uk,n,3
5065,ICLR,2020,Towards Finding Longer Proofs,Zsolt Zombori;Adri√°n Csisz√°rik;Henryk Michalewski;Cezary Kaliszyk;Josef Urban,zombori@renyi.hu;csadrian@renyi.hu;henrykmichalewski@gmail.com;cezary.kaliszyk@uibk.ac.at;josef.urban@gmail.com,6;3;3,,Reject,0,4,0.0,yes,9/28/20,Alfr√©d R√©nyi Institute of Mathematics;Alfr√©d R√©nyi Institute of Mathematics;;University of Innsbruck;Czech Technical University in Prague,automated theorem proving;reinforcement learning;curriculum learning;internal guidance,-1;-1;-1;-1;168,-1;-1;-1;415;956,m;m,NAN,NAN,n,1
5066,ICLR,2020,iWGAN: an Autoencoder WGAN for Inference,Yao Chen;Qingyi Gao;Xiao Wang,chen2037@purdue.edu;gao424@purdue.edu;wangxiao@purdue.edu,8;3;3,,Reject,0,3,0.0,yes,9/25/19,Purdue University;Purdue University;Purdue University,Generative model;Autoencoder;Inference,24;24;24,88;88;88,m;m,usa,usa,y,1;5;4
5067,ICLR,2020,Teacher-Student Compression with Generative Adversarial Networks,Ruishan Liu;Nicolo Fusi;Lester Mackey,ruishan@stanford.edu;lmackey@stanford.edu;fusi@microsoft.com,3;3;3,,Reject,0,0,0.0,yes,9/25/19,Stanford University;Stanford University;Microsoft,,5;5;-1,4;4;-1,u;m,NAN,NAN,n,10;5;4
5068,ICLR,2020,Characterize and Transfer Attention in Graph Neural Networks,Mufei Li;Hao Zhang;Xingjian Shi;Minjie Wang;Yixing Guan;Zheng Zhang,limufe@amazon.com;sufeidechabei@gmail.com;xshiab@connect.ust.hk;wmjlyjemaine@gmail.com;guayixin@amazon.com;zz@nyu.edu,3;6;1,,Reject,0,7,0.0,yes,9/25/19,Amazon;;The Hong Kong University of Science and Technology;;Amazon;New York University,Graph Neural Networks;Graph Attention Networks;Attention;Transfer Learning;Empirical Study,-1;-1;-1;-1;-1;22,-1;-1;47;-1;-1;29,m;m,usa,usa,n,6;8;10
5069,ICLR,2020,Benchmarking Model-Based Reinforcement Learning,Tingwu Wang;Xuchan Bao;Ignasi Clavera;Jerrick Hoang;Yeming Wen;Eric Langlois;Shunshi Zhang;Guodong Zhang;Pieter Abbeel;Jimmy Ba,tingwuwang@cs.toronto.edu;xuchan.bao@mail.utoronto.ca;iclavera@berkeley.edu;jhoang@cs.toronto.edu;ywen@cs.toronto.edu;edl@cs.toronto.edu;matthew.zhang@mail.utoronto.ca;gdzhang@cs.toronto.edu;pabbeel@cs.berkeley.edu;jba@cs.toronto.edu,1;6;6,,Reject,0,5,0.0,yes,9/25/19,University of Toronto;Toronto University;University of California Berkeley;University of Toronto;University of Toronto;University of Toronto;Toronto University;University of Toronto;University of California Berkeley;University of Toronto,Reinforcement learning;model based Reinforcement learning;Benchmarking,18;-1;-1;18;18;18;-1;18;-1;18,18;-1;13;18;18;18;-1;18;13;18,m;m,canada,ca,n,
5070,ICLR,2020,Gradient Perturbation is Underrated for Differentially Private Convex Optimization,Da Yu;Huishuai Zhang;Wei Chen;Tie-yan Liu;Jian Yin,yuda3@mail2.sysu.edu.cn;huishuai.zhang@microsoft.com;wche@microsoft.com;tie-yan.liu@microsoft.com;issjyin@mail.sysu.edu.cn,6;3;6,,Reject,0,4,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft;Microsoft;SUN YAT-SEN UNIVERSITY,minimum curvature;gradient perturbation;DP-GD;DP-SGD,-1;-1;-1;-1;-1,299;-1;-1;-1;299,m;m,NAN,NAN,y,1;9
5071,ICLR,2020,BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation,Jin-Young  Kim;Sung-Bae Cho,seago0828@yonsei.ac.kr;sbcho@yonsei.ac.kr,1;1;1,,Reject,1,20,0.0,yes,9/25/19,Yonsei University;Yonsei University,variational autoencoder;latent space;basis;disentangled representation,143;143,196;196,m;m,asia,cn,y,5
5072,ICLR,2020,How many weights are enough : can tensor factorization learn efficient policies ?,Pierre H. Richemond;Arinbjorn Kolbeinsson;Yike Guo,phr17@ic.ac.uk;ak711@imperial.ac.uk;y.guo@imperial.ac.uk,3;1;3,,Reject,0,4,0.0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London,reinforcement learning;Q-learning;tensor factorization;low-rank approximation;data efficiency;second-order optimization;scattering,52;52;52,10;10;10,m;m,europe,uk,n,1
5073,ICLR,2020,Superseding Model Scaling by Penalizing Dead Units and Points with Separation Constraints,Carles Riera;Camilo Rey-Torres;Eloi Puertas;Oriol Pujol,blauigris@gmail.com;camilorey@gmail.com;epuertas@ub.edu;oriol_pujol@ub.edu,3;3;3,,Reject,0,13,1.0,yes,9/25/19,Universitat de Barcelona;Universidad Sergio Arboleda;Universitat de Barcelona;Universitat de Barcelona,Dead Point;Dead Unit;Model Scaling;Separation Constraints;Dying ReLU;Constant Width;Deep Neural Networks;Backpropagation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5074,ICLR,2020,AHash: A Load-Balanced One Permutation Hash,Chenxingyu Zhao;Jie Gui;Yixiao Guo;Jie Jiang;Tong Yang;Bin Cui;Gong Zhang,dkzcxy@pku.edu.cn;guisj2017@pku.edu.cn;1700016637@pku.edu.cn;jie.jiang@pku.edu.cn;yangtongemail@gmail.com;bin.cui@pku.edu.cn;nicholas.zhang@huawei.com,1;6;3;6,,Reject,0,0,0.0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;;Peking University;Huawei Technologies Ltd.,Data Representation;Probabilistic Algorithms,14;14;14;14;-1;14;-1,24;24;24;24;-1;24;-1,m;m,NAN,NAN,y,
5075,ICLR,2020,Representation Quality Explain Adversarial Attacks,Danilo Vasconcellos Vargas;Shashank Kotyan;Moe Matsuki,vargas@inf.kyushu-u.ac.jp;shashankkotyan@gmail.com;matsuki.sousisu@gmail.com,1;3;1,,Reject,0,3,0.0,yes,9/25/19,Kyushu University;Kyushu University;Kyushu University,Representation Metrics;Adversarial Machine Learning;One-Pixel Attack;DeepFool;CapsNet,-1;-1;-1,460;460;-1,m;m,asia,in,n,6;4
5076,ICLR,2020,Explaining A Black-box By Using A Deep Variational Information Bottleneck Approach,Seojin Bang;Pengtao Xie;Heewook Lee;Wei Wu;Eric Xing,seojinb@cs.cmu.edu,6;6;3,,Reject,0,12,0.0,yes,9/25/19,Carnegie Mellon University,interpretable machine learning;information bottleneck principle;black-box,1,27,f;m,usa,usa,n,8
5077,ICLR,2020,Neural networks are a priori biased towards Boolean functions with low entropy,Chris Mingard;Joar Skalse;Guillermo Valle-P√©rez;David Mart√≠nez-Rubio;Vladimir Mikulik;Ard A. Louis,christopher.mingard@hertford.ox.ac.uk;joar.skalse@hertford.ox.ac.uk;guillermo.valle@dtc.ox.ac.uk;david.martinez@cs.ox.ac.uk;vladimir.mikulik@hertford.ox.ac.uk;ard.louis@physics.ox.ac.uk,3;6;6,,Reject,0,4,0.0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,class imbalance;perceptron;inductive bias;simplicity bias;initialization,46;46;46;46;46;46,1;1;1;1;1;1,m;m,europe,uk,y,1
5078,ICLR,2020,Learning Structured Communication for Multi-agent Reinforcement Learning,Junjie Sheng;Xiangfeng Wang;Bo Jin;Junchi Yan;Wenhao Li;Tsung-Hui Chang;Jun Wang;Hongyuan Zha,52194501003@stu.ecnu.edu.cn;xfwang@sei.ecnu.edu.cn;bjin@cs.ecnu.edu.cn;yanjunchi@sjtu.edu.cn;52194501026@stu.ecnu.edu.cn;changtsunghui@cuhk.edu.cn;jwang@sei.ecnu.edu.cn;zha@sei.ecnu.edu.cn,6;3;3,,Reject,0,4,0.0,yes,9/25/19,"East China Normal University;East China Normal University;East China Normal University;Shanghai Jiao Tong University;East China Normal University;The Chinese University of Hong Kong, Shenzhen;East China Normal University;East China Normal University",Learning to communicate;Multi-agent reinforcement learning;Hierarchical communication network,-1;-1;-1;30;-1;46;-1;-1,544;544;544;157;544;35;544;544,m;m,NAN,NAN,n,10
5079,ICLR,2020,Lipschitz Lifelong Reinforcement Learning,Erwan Lecarpentier;David Abel;Kavosh Asadi;Yuu Jinnai;Emmanuel Rachelson;Michael L. Littman,erwan.lecarpentier@isae-supaero.fr;david_abel@brown.edu;k8@brown.edu;yuu_jinnai@brown.edu;emmanuel.rachelson@isae-supaero.fr;michael_littman@brown.edu,6;6;3,,Reject,0,5,0.0,yes,9/25/19,Institut Sup√©rieur de l'A√©ronautique et de l'Espace;Brown University;Brown University;Brown University;Institut Sup√©rieur de l'A√©ronautique et de l'Espace;Brown University,Reinforcement Learning;Lifelong Learning,-1;85;85;85;-1;85,-1;53;53;53;-1;53,m;m,usa,usa,y,
5080,ICLR,2020,Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas,Fei Wang;Zhanfu Yang;Ziliang Chen;Guannan Wei;Tiark Rompf,wang603@purdue.edu;yang1676@purdue.edu;c.ziliang@yahoo.com;wei220@purdue.edu;tiark@purdue.edu,6;8;3,,Reject,0,0,0.0,yes,9/25/19,Purdue University;Purdue University;;Purdue University;Purdue University,Graph Neural Networks;2-Quantified Boolean Formula;Symbolic Reasoning,24;24;-1;24;24,88;88;-1;88;88,m;m,usa,usa,n,10
5081,ICLR,2020,Semi-Supervised Few-Shot Learning with a Controlled Degree of Task-Adaptive Conditioning,Sung Whan Yoon;Jun Seo;Jaekyun Moon,shyoon8@kaist.ac.kr;tjwns0630@kaist.ac.kr;jmoon@kaist.edu,3;6;1,,Reject,0,4,0.0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,few-shot learning;meta-learning;semi-supervised learning;task-adaptive clustering;task-adaptive projection space,-1;-1;15,110;110;110,m;m,asia,in,n,6
5082,ICLR,2020,Deep Lifetime Clustering,S Chandra Mouli;Leonardo Teixeira;Jennifer Neville;Bruno Ribeiro,chandr@purdue.edu;lteixeir@purdue.edu;ribeiro@cs.purdue.edu;neville@cs.purdue.edu,6;6;3,,Reject,0,7,0.0,yes,9/25/19,Purdue University;Purdue University;Purdue University;Purdue University,Lifetime Clustering;Deep Learning;Survival Distributions;Kuiper two-sample test,24;24;24;24,88;88;88;88,m;m,usa,usa,n,1
5083,ICLR,2020,PassNet: Learning pass probability surfaces from single-location labels. An architecture for visually-interpretable soccer analytics,Javier Fern√°ndez;Luke Bornn,javier.fernandezr@fcbarcelona.cat;lbornn@kings.com,3;8;6,,Reject,0,5,0.0,yes,9/25/19,Universitat Polit√®cnica de Catalunya;Kings,fully convolutional neural networks;convolutional neural networks;sports analytics;interpretable machine learning;deep learning,-1;-1,-1;843,m;m,NAN,NAN,n,
5084,ICLR,2020,Few-Shot One-Class Classification via Meta-Learning,Ahmed Frikha;Denis Krompa√ü;Hans-Georg Koepken;Volker Tresp,ahmed.frikha@siemens.com;denis.krompass@siemens.com;hans-georg.koepken@siemens.com;volker.tresp@siemens.com,1;3;3,,Reject,0,13,0.0,yes,9/25/19,Siemens Corporate Research;Siemens Corporate Research;Siemens Corporate Research;Siemens Corporate Research,meta-learning;few-shot learning;one-class classification;class-imbalance learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
5085,ICLR,2020,Simple is Better: Training an End-to-end Contract Bridge Bidding Agent without Human Knowledge,Qucheng Gong;Yu Jiang;Yuandong Tian,qucheng@fb.com;tinayujiang@fb.com;yuandong@fb.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Facebook;Facebook;Facebook,Contract Bridge;Bidding;Selfplay;AlphaZero,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5086,ICLR,2020,Rethinking deep active learning: Using unlabeled data at model training,Oriane Sim√©oni;Mateusz Budnik;Yannis Avrithis;Guillaume Gravier,oriane.simeoni@inria.fr;mateusz.budnik@inria.fr;yannis@avrithis.net;guig@irisa.fr,3;3;3,,Reject,0,7,0.0,yes,9/25/19,INRIA;INRIA;INRIA;IRISA,active learning;deep learning;semi-supervised learning;unsupervised feature learning,-1;-1;-1;-1,-1;-1;-1;-1,f;m,europe,fr,n,
5087,ICLR,2020,Why Convolutional Networks Learn Oriented Bandpass Filters: A Hypothesis,Richard P. Wildes,wildes@cse.yorku.ca,3;3;1;3,,Reject,0,0,0.0,yes,9/25/19,York University,convolutional networks;computer vision;oriented bandpass filters;linear systems theory,194,416,m,asia,kr,n,
5088,ICLR,2020,Deep Expectation-Maximization in Hidden Markov Models via Simultaneous Perturbation Stochastic Approximation,Chong Li;Dan Shen;C.J. Richard Shi;Hongxia Yang,chongli@uw.edu;dshen@alibaba-inc.com;cjshi@uw.edu;yang.yhx@alibaba-inc.com,3;3,,Reject,0,2,0.0,yes,9/25/19,"University of Washington, Seattle;Alibaba Group;University of Washington, Seattle;Alibaba Group",recommender system;gradient approximation;Hidden Markov Model,11;-1;11;-1,26;-1;26;-1,m;f,NAN,NAN,y,1
5089,ICLR,2020,Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling,Ouyu Lan*;Xiao Huang*;Bill Yuchen Lin;He Jiang;Xiang Ren,olan@usc.edu;huan183@usc.edu;yuchen.lin@usc.edu;jian567@usc.edu;xiangren@usc.edu,6;6;3,,Reject,0,6,0.0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;University of Southern California;University of Southern California,crowdsourcing;domain adaptation;sequence labeling;named entity recognition;weak supervision,36;36;36;36;36,62;62;62;62;62,f;m,usa,usa,n,6;8;3
5090,ICLR,2020,Disentangled Cumulants Help Successor Representations Transfer to New Tasks,Chris Grimm;Irina Higgins;Andre Barreto;Denis Teplyashin;Markus Wulfmeier;Tim Hertweck;Raia Hadsell;Satinder Singh,crgrimm@umich.edu;irinah@google.com;andrebarreto@google.com;teplyashin@google.com;mwulfmeier@google.com;thertweck@google.com;raia@google.com;baveja@google.com,6;6;3,,Reject,0,0,0.0,yes,9/25/19,University of Michigan;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;representation learning;intrinsic reward;intrinsic control;endogenous;generalized policy improvement;successor features;variational;monet;disentangled,7;-1;-1;-1;-1;-1;-1;-1,21;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
5091,ICLR,2020,Adversarial training with perturbation generator networks,Hyeungill Lee;Sungyeob Han;Jungwoo Lee,hyungil0113@snu.ac.kr;yubise7en@snu.ac.kr;junglee@snu.ac.kr,3;3;3,,Reject,0,9,0.0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University,Adversarial training;Generative model;Adaptive perturbation generator;Robust optimization,39;39;39,64;64;64,u;m,asia,kr,n,4
5092,ICLR,2020,Batch Normalization has Multiple Benefits: An Empirical Study on Residual Networks,Soham De;Samuel L Smith,sohamde@google.com;slsmith@google.com,3;1;3,,Reject,1,4,0.0,yes,9/25/19,Google;Google,batch normalization;residual networks;initialization;batch size;learning rate;ImageNet,-1;-1,-1;-1,m;m,NAN,NAN,n,
5093,ICLR,2020,A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION,Jin Zhang;Weipeng Ming;Pengfei Liu,zhangjin9@100tal.com;mingweipeng@100tal.com;liupengfei1@100tal.com,1;3;6,,Reject,0,0,0.0,yes,9/25/19,TAL Education Group;TAL Education Group;TAL Education Group,mathematical expressions recognition;seq2seq model,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;2;1
5094,ICLR,2020,The Sooner The Better: Investigating Structure of Early Winning Lottery Tickets,Shihui Yin;Kyu-Hyoun Kim;Jinwook Oh;Naigang Wang;Mauricio Serrano;Jae-Sun Seo;Jungwook Choi,shihui.yin@ibm.com;kimk@us.ibm.com;ohj@us.ibm.com;nwang@us.ibm.com;mserrano@us.ibm.com;jaesun.seo@asu.edu;choij@hanyang.ac.kr,6;3;3,,Reject,0,6,0.0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;SUN YAT-SEN UNIVERSITY;Hanyang University,pruning;lottery ticket hypothesis;deep neural network;compression;image classification,-1;-1;-1;-1;-1;-1;194,-1;-1;-1;-1;-1;299;393,m;m,asia,kr,n,
5095,ICLR,2020,How Well Do WGANs Estimate the Wasserstein Metric?,Anton Mallasto;Guido Mont√∫far;Augusto Gerolin,anton.mallasto@gmail.com;montufar@math.ucla.edu;augustogerolin@gmail.com,1;3;3,,Reject,0,3,0.0,yes,9/25/19,"Aalto University;University of California, Los Angeles;VU University Amsterdam",Optimal Transport;Wasserstein Metric;Generative Adversial Networks,118;-1;-1,182;17;-1,m;m,asia,in,n,5;4
5096,ICLR,2020,A Group-Theoretic Framework for Knowledge Graph Embedding,Tong Yang;Long Sha;Pengyu Hong,yangto@bc.edu;longsha@brandeis.edu;hongpeng@brandeis.edu,3;3;3,,Reject,4,4,0.0,yes,9/25/19,Boston College;Brandeis University;Brandeis University,group theory;knowledge graph embedding;representation learning,248;248;248,323;244;244,m;m,usa,usa,n,1;10
5097,ICLR,2020,Accelerated Information Gradient flow,Yifei Wang;Wuchen Li,zackwang24@pku.edu.cn;wcli@math.ucla.edu,3;3,,Reject,0,3,0.0,yes,9/25/19,"Peking University;University of California, Los Angeles",Optimal transport;Information geometry;Nesterov accelerated gradient method,14;-1,24;17,m;m,usa,usa,y,11;1
5098,ICLR,2020,Time2Vec: Learning a Vector Representation of Time,Seyed Mehran Kazemi;Rishab Goel;Sepehr Eghbali;Janahan Ramanan;Jaspreet Sahota;Sanjay Thakur;Stella Wu;Cathal Smyth;Pascal Poupart;Marcus Brubaker,mehran.kazemi@borealisai.com;rishab.goel@borealisai.com;sepehr.eghbali@rbc.com;janahan.ramanan@borealisai.com;jaspreet.sahota@borealisai.com;sttsanjay@gmail.com;stella.wu@borealisai.com;cathal.smyth@rbc.com;pascal.poupart@borealisai.com;marcus.brubaker@borealisai.com,6;1;3;8,,Reject,0,5,0.0,yes,9/25/19,Borealis AI;Borealis AI;Borealis AI;Borealis AI;Borealis AI;;Borealis AI;Borealis AI;Borealis AI;Borealis AI,,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
5099,ICLR,2020,MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction of Sepsis,Margherita Rosnati;Vincent Fortuin,mrosnati@ethz.ch;fortuin@inf.ethz.ch,3;1;8,,Reject,0,3,0.0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,time series analysis;interpretability;Gaussian Processes;attention neural networks,-1;-1,-1;-1,f;m,NAN,NAN,n,8
5100,ICLR,2020,NESTED LEARNING FOR MULTI-GRANULAR TASKS,Rapha√´l Achddou;J. Matias Di Martino;Guillermo Sapiro,raphael.achddou@telecom-paristech.fr;matiasdm@fing.edu.uy;guillermo.sapiro@duke.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,T√©l√©com ParisTech;Facultad de Ingenier√≠a;Duke University,Nested learning,-1;-1;46,187;-1;20,m;m,europe,se,n,1
5101,ICLR,2020,Attack-Resistant Federated Learning with Residual-based Reweighting,Shuhao Fu;Chulin Xie;Bo Li;Qifeng Chen,sfuab@connect.ust.hk;chulinxie@zju.edu.cn;lbo@illinois.edu;chenqifeng22@gmail.com,3;6;3,,Reject,0,1,0.0,yes,9/25/19,"The Hong Kong University of Science and Technology;Zhejiang University;University of Illinois, Urbana Champaign;Hong Kong University of Science and Technology",robust federated learning;backdoor attacks,-1;39;-1;-1,47;107;-1;47,m;m,NAN,NAN,y,4
5102,ICLR,2020,Self-Supervised Policy Adaptation,Christopher Mutschler;Sebastian Pokutta,christopher.mutschler@iis.fraunhofer.de;pokutta@zib.de,1;1;1,,Reject,0,1,0.0,yes,9/25/19,Fraunhofer IIS;ZIB,reinforcement learning;environment representation;representation learning;model mismatch,-1;-1,-1;-1,m;m,europe,gr,n,
5103,ICLR,2020,Efficient generation of structured objects with Constrained Adversarial Networks,Jacopo Gobbi;Luca Di Liello;Pierfrancesco Ardino;Paolo Morettin;Stefano Teso;Andrea Passerini,jacopo.gobbi@studenti.unitn.it;luca.diliello@studenti.unitn.it;pierfrancesco.ardino@unitn.it;paolo.morettin@unitn.it;stefano.teso@gmail.com;andrea.passerini@unitn.it,3;3;3,,Reject,0,3,0.0,yes,9/25/19,University of Trento;University of Trento;University of Trento;University of Trento;University of Trento;University of Trento,deep generative models;generative adversarial networks;constraints,143;143;143;143;143;143,307;307;307;307;307;307,m;f,europe,gr,y,10;5;4
5104,ICLR,2020,Subgraph Attention for Node Classification and Hierarchical Graph Pooling,Sambaran Bandyopadhyay;Manasvi Aggarwal;M. N. Murty,sambaran.ban89@gmail.com;manasvia@iisc.ac.in;mnm@iisc.ac.in,3;6;1,,Reject,0,5,0.0,yes,9/25/19,International Business Machines;Indian Institute of Science;Indian Institute of Science,Graph Neural Network;Graph Attention;Graph Pooling;Node Classification;Graph Classification;Network Representation Learning,-1;-1;-1,-1;301;301,m;m,NAN,NAN,n,8;10
5105,ICLR,2020,Learning from Partially-Observed Multimodal Data with Variational Autoencoders,Yu Gong;Hossein Hajimirsadeghi;Jiawei He;Megha Nawhal;Thibaut Durand;Greg Mori,yu_gong@sfu.ca;hossein.hajimirsadeghi@gmail.com;jha203@sfu.ca;mnawhal@sfu.ca;thibaut.p.durand@borealisai.com;mori@cs.sfu.ca,3;3;3;6,,Reject,0,7,0.0,yes,9/25/19,Simon Fraser University;Borealis AI;Simon Fraser University;Simon Fraser University;Borealis AI;Simon Fraser University,data imputation;variational autoencoders;generative models,52;-1;52;52;-1;52,272;-1;272;272;-1;272,m;m,canada,ca,n,5
5106,ICLR,2020,A Simple Approach to the Noisy Label Problem Through the Gambler's Loss,Liu Ziyin;Ru Wang;Paul Pu Liang;Ruslan Salakhutdinov;Louis-Philippe Morency;Masahito Ueda,zliu@cat.phys.s.u-tokyo.ac.jp;wangru1994305@gmail.com;pliang@cs.cmu.edu;rsalakhu@cs.cmu.edu;morency@cs.cmu.edu;ueda@phys.s.u-tokyo.ac.jp,6;3;3,,Reject,0,7,0.0,yes,9/25/19,The University of Tokyo;;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;The University of Tokyo,noisy labels;robust learning;early stopping;generalization,64;-1;1;1;1;64,36;-1;27;27;27;36,u;m,NAN,NAN,y,1
5107,ICLR,2020,Contextual Temperature for Language Modeling,Pei-Hsin Wang;Sheng-Iou Hsieh;Shieh-Chieh Chang;Jia-Yu Pan;Yu-Ting Chen;Wei Wei;Da-Cheng Juan,peihsin@gapp.nthu.edu.tw;steins1111@gapp.nthu.edu.tw;scchang@cs.nthu.edu.tw;jypan@google.com;yutingchen@google.com;wewei@google.com;dacheng@google.com,3;6;3,,Reject,0,5,0.0,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Google;Google;Google;Google,natural language processing;language modeling;sequence modeling;temperature scaling,194;194;194;-1;-1;-1;-1,365;365;365;-1;-1;-1;-1,u;m,NAN,NAN,n,3
5108,ICLR,2020,MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS,Tao Zheng;Ivor Tsang;Xin Yao,tao.zheng@student.uts.edu.au;ivor.tsang@uts.edu.au;xiny@sustech.edu.cn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;Southern University of Science and Technology,metric learning;representation learning;multi-label classification;multi-output,73;73;-1,193;193;317,m;u,NAN,NAN,n,
5109,ICLR,2020,Unsupervised Data Augmentation for Consistency Training,Qizhe Xie;Zihang Dai;Eduard Hovy;Minh-Thang Luong;Quoc V. Le,qizhex@cs.cmu.edu;dzihang@cs.cmu.edu;hovy@cs.cmu.edu;thangluong@google.com;qvl@google.com,8;3;3,,Reject,0,11,1.0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Google;Google,Semi-supervised learning;computer vision;natural language processing,1;1;1;-1;-1,27;27;27;-1;-1,m;m,NAN,NAN,n,6
5110,ICLR,2020,Representation Learning Through Latent Canonicalizations,Or Litany;Ari Morcos;Srinath Sridhar;Leonidas Guibas;Judy Hoffman,orlitany@gmail.com;arimorcos@gmail.com;ssrinath@cs.stanford.edu;guibas@cs.stanford.edu;judy@gatech.edu,3;8;3,,Reject,0,5,0.0,yes,9/25/19,NVIDIA;Facebook;Stanford University;Stanford University;Georgia Institute of Technology,representation learning;latent canonicalization;sim2real;few shot;disentanglement,-1;-1;5;5;13,-1;-1;4;4;38,m;f,usa,usa,n,1
5111,ICLR,2020,Molecular Graph Enhanced Transformer for Retrosynthesis Prediction,Kelong Mao;Peilin Zhao;Tingyang Xu;Yu Rong;Xi Xiao;Junzhou Huang,mkl18@mails.tsinghua.edu.cn;masonzhao@tencent.com;tingyangxu@tencent.com;yu.rong@hotmail.com;xiaox@sz.tsinghua.edu.cn;joehhuang@tencent.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tsinghua University, Tsinghua University;Tencent AI Lab",,4;-1;-1;-1;4;-1,23;-1;-1;-1;23;-1,m;m,NAN,NAN,n,8;3;10
5112,ICLR,2020,Frequency Pooling: Shift-Equivalent and Anti-Aliasing Down Sampling,Zhendong Zhang;Cheolkon Jung,zhd.zhang.ai@gmail.com;zhengzk@xidian.edu.cn,1;6;3,,Reject,0,7,0.0,yes,9/25/19,Xidian University;Xidian University,pooling;anti-aliasing;shift-equivalent;frequency,-1;-1,-1;919,m;m,asia,cn,n,1
5113,ICLR,2020,Where is the Information in a Deep Network?,Alessandro Achille;Stefano Soatto,achille@cs.ucla.edu;soatto@cs.ucla.edu,6;8;6,,Reject,0,8,1.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",Information;Learning Dynamics;PAC-Bayes;Deep Learning,-1;-1,17;17,m;m,usa,usa,y,1
5114,ICLR,2020,FleXOR: Trainable Fractional Quantization,Dongsoo Lee;Se Jung Kwon;Byeongwook Kim;Yongkweon Jeon;Baeseong Park;Jeongin Yun;Gu-Yeon Wei,dslee3@gmail.com;mogndrewk@gmail.com;quddnr145@gmail.com;dragwon.jeon@gmail.com;qkrqotjd91@gmail.com;yji6373@naver.com;gywei@g.harvard.edu,3;6;3,,Reject,0,4,0.0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Samsung;Samsung;Harvard University,Quantization;Model Compression;Trainable Compression;XOR;Encryption,-1;-1;-1;-1;-1;-1;52,-1;-1;-1;-1;-1;-1;7,m;m,usa,usa,n,8
5115,ICLR,2020,Mixture Distributions for Scalable Bayesian Inference,Pranav Poduval;Hrushikesh Loya;Rajat Patel;Sumit Jain,pranav97.poduval@gmail.com;loyahrushikesh@gmail.com;prajat5232@iitb.ac.in;sumitjain3033@gmail.com,1;3;3,,Reject,0,13,0.0,yes,9/25/19,Indian Institute of Technology Bombay;;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay,uncertainty estimation;Deep Ensembles;Adverserial Robustness,-1;-1;-1;-1,-1;-1;480;-1,m;m,asia,in,n,11;4
5116,ICLR,2020,On the Invertibility of Invertible Neural Networks,Jens Behrmann;Paul Vicol;Kuan-Chieh Wang;Roger B. Grosse;J√∂rn-Henrik Jacobsen,jensb@uni-bremen.de;pvicol@cs.toronto.edu;wangkua1@cs.toronto.edu;rgrosse@cs.toronto.edu;j.jacobsen@vectorinstitute.ai,6;3;3,,Reject,0,6,0.0,yes,9/25/19,Universit√§t Bremen;University of Toronto;University of Toronto;University of Toronto;Vector Institute,Invertible Neural Networks;Stability;Normalizing Flows;Generative Models;Evaluation of Generative Models,-1;18;18;18;-1,-1;18;18;18;-1,m;m,NAN,NAN,y,5
5117,ICLR,2020,Meta Learning via Learned Loss,Sarah Bechtle;Artem Molchanov;Yevgen Chebotar;Edward Grefenstette;Ludovic Righetti;Gaurav Sukhatme;Franziska Meier,sbechtle@tuebingen.mpg.de;molchano@usc.edu;ychebota@usc.edu;egrefen@gmail.com;ludovic.righetti@nyu.edu;gaurav@usc.edu;fmeier@fb.com,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Max-Planck Institute;University of Southern California;University of Southern California;Facebook;New York University;University of Southern California;Facebook,Meta Learning;Reinforcement Learning;Loss Learning,-1;36;36;-1;22;36;-1,-1;62;62;-1;29;62;-1,f;f,NAN,NAN,n,6
5118,ICLR,2020,Demonstration Actor Critic,Guoqing Liu;Li Zhao;Pushi Zhang;Jiang Bian;Tao Qin;Nenghai Yu;Tie-Yan Liu,lgq1001@mail.ustc.edu.cn;lizo@microsoft.com;zpschang@gmail.com;jiang.bian@microsoft.com;taoqin@microsoft.com;ynh@ustc.edu.cn;tyliu@microsoft.com,6;6;1,,Reject,0,9,0.0,yes,9/25/19,University of Science and Technology of China;Microsoft;;Microsoft;Microsoft;University of Science and Technology of China;Microsoft,Deep Reinforcement Learning;Reinforcement Learning from Demonstration,-1;-1;-1;-1;-1;-1;-1,80;-1;-1;-1;-1;80;-1,m;m,NAN,NAN,y,1;10
5119,ICLR,2020,Moniqua: Modulo Quantized Communication in Decentralized SGD,Yucheng Lu;Christopher De Sa,yl2967@cornell.edu;cdesa@cs.cornell.edu,3;3;3;8,,Reject,0,10,0.0,yes,9/25/19,Cornell University;Cornell University,decentralized training;quantization;communicaiton;stochastic gradient descent,7;7,19;19,m;m,usa,usa,y,1;10
5120,ICLR,2020,Testing For Typicality with Respect to an Ensemble of Learned Distributions,Forrest Laine;Claire Tomlin,forrest.laine@berkeley.edu;tomlin@eecs.berkeley.edu,3;1;6,,Reject,0,5,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley,anomaly detection;density estimation;generative models,-1;-1,13;13,m;f,usa,usa,y,
5121,ICLR,2020,Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML,Sijia Liu;Songtao Lu;Xiangyi Chen;Yao Feng;Kaidi Xu;Abdullah Al-Dujaili;Minyi Hong;Una-May Obelilly,sijia.liu@ibm.com;songtao@ibm.com;chen5719@umn.edu;feng-y16@mails.tsinghua.edu.cn;xu.kaid@husky.neu.edu;aldujail@mit.edu;mhong@umn.edu;unamay@csail.mit.edu,3;6;6,,Reject,0,7,0.0,yes,9/25/19,"International Business Machines;International Business Machines;University of Minnesota, Minneapolis;Tsinghua University, Tsinghua University;Northeastern University;Massachusetts Institute of Technology;University of Minnesota, Minneapolis;Massachusetts Institute of Technology",nonconvex optimization;min-max optimization;robust optimization;adversarial attack,-1;-1;73;4;16;5;73;5,-1;-1;79;23;906;5;79;5,m;f,usa,usa,y,9;4
5122,ICLR,2020,Wyner VAE: A Variational Autoencoder with Succinct Common Representation Learning,J. Jon Ryu;Yoojin Choi;Young-Han Kim;Mostafa El-Khamy;Jungwon Lee,jongha.ryu@gmail.com;yoojin.c@samsung.com;yhk@ucsd.edu;mostafa.e@samsung.com;jungwon2.lee@samsung.com,6;6;3;6,,Reject,0,15,0.0,yes,9/25/19,"University of California, San Diego;Samsung;University of California, San Diego;Samsung;Samsung",Wyner's common information;information theoretic regularization;information bottleneck;representation learning;generative models;conditional generation;joint generation;style transfer;variational autoencoders,-1;-1;-1;-1;-1,31;-1;31;-1;-1,m;m,NAN,NAN,n,5
5123,ICLR,2020,Improving Confident-Classifiers For Out-of-distribution Detection,Sachin Vernekar;Ashish Gaurav;Vahdat Abdelzad;Taylor Denouden;Rick Salay;Krzysztof Czarnecki,sverneka@uwaterloo.ca;a5gaurav@uwaterloo.ca;vabdelza@gsd.uwaterloo.ca;tadenoud@uwaterloo.ca;rsalay@gsd.uwaterloo.ca;kczarnec@gsd.uwaterloo.ca,3;3;6,,Reject,0,3,0.0,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo,Out-of-distribution detection;Manifold;Nullspace;Variational Auto-encoder;GAN;Confident-classifier,30;30;30;30;30;30,235;235;235;235;235;235,m;m,canada,ca,n,
5124,ICLR,2020,FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS,Dogu Araci;Zulkuf Genc,dogu.araci@naspers.com;zulkuf.genc@naspers.com,3;3;1;3,,Reject,0,0,0.0,yes,9/25/19,Naspers;Prosus,Financial sentiment analysis;financial text classification;transfer learning;pre-trained language models;BERT;NLP,-1;-1,-1;-1,m;m,NAN,NAN,n,6;3
5125,ICLR,2020,Rethinking Neural Network Quantization,Qing Jin;Linjie Yang;Zhenyu Liao,jinqingking@gmail.com;yljatthu@gmail.com;liaozhenyu2004@gmail.com,3;3;1,,Reject,0,7,0.0,yes,9/25/19,Northeastern University;ByteDance;Kuaishou Technology,Deep Learning;Convolutional Network;Network Quantization;Efficient Learning,16;-1;-1,906;-1;-1,u;m,NAN,NAN,n,
5126,ICLR,2020,A Simple and Scalable Shape Representation for 3D Reconstruction,Mateusz Michalkiewicz;Eugene Belilovsky;Mahsa Baktashmotagh;Anders Eriksson,78lhar@gmail.com;belilovsky.eugene@gmail.com;m.baktashmotlagh@uq.edu.au;a.eriksson@uq.edu.au,6;3;3,,Reject,0,4,0.0,yes,9/25/19,University of Queensland;University of Montreal;University of Queensland;University of Queensland,Computer Vision;3D Reconstruction,-1;118;248;248,-1;85;66;66,m;m,australasia,au,n,
5127,ICLR,2020,Learning Cross-Context Entity Representations from Text,Jeffrey Ling;Nicholas FitzGerald;Zifei Shan;Livio Baldini Soares;Thibault F√©vry;David Weiss;Tom Kwiatkowski,jeffreyling@google.com;nfitz@google.com;zifeis@google.com;liviobs@google.com;tfevry@google.com;djweiss@google.com;tomkwiat@google.com,3;3;6,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,entities;entity representations;knowledge representation;entity linking;entity typing,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
5128,ICLR,2020,Unsupervised Few Shot Learning via Self-supervised Training,Zilong Ji;Xiaolong Zou;Tiejun Huang;Si Wu,jizilong@mail.bnu.edu.cn;xiaolz@pku.edu.cn;tjhuang@pku.edu.cn;siwu@pku.edu.cn,1;6;3,,Reject,0,4,0.0,yes,9/25/19,Australian National University;Peking University;Peking University;Peking University,few shot learning;self-supervised learning;meta-learning,102;14;14;14,50;24;24;24,m;f,asia,cn,n,6
5129,ICLR,2020,Confidence-Calibrated Adversarial Training: Towards Robust Models Generalizing Beyond the Attack Used During Training,David Stutz;Matthias Hein;Bernt Schiele,david.stutz@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de;matthias.hein@uni-tuebingen.de,3;3;6,,Reject,0,9,0.0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;University of Tuebingen,Adversarial Training;Adversarial Examples;Adversarial Robustness;Confidence Calibration,-1;-1;143,-1;-1;91,m;m,europe,de,y,4
5130,ICLR,2020,Optimal Unsupervised Domain Translation,Emmanuel de B√©zenac;Ibrahim Ayed;Patrick Gallinari,emmanuel.de-bezenac@lip6.fr;ayedibrahim@gmail.com;patrick.gallinari@lip6.fr,3;6;6,,Reject,0,4,0.0,yes,9/25/19,LIP6;LIP6;LIP6,Unsupervised Domain Translation;CycleGAN;Optimal Transport,445;445;445,-1;-1;-1,m;m,asia,ir,y,1
5131,ICLR,2020,A Uniform Generalization Error Bound for Generative Adversarial Networks,Hao Chen;Zhanfeng Mo;Qingyi Gao;Zhouwang Yang;Xiao Wang,ch330822@mail.ustc.edu.cn;oscarmzf@mail.ustc.edu.cn;gao424@purdue.edu;yangzw@ustc.edu.cn;wangxiao@purdue.edu,1;3;3,,Reject,0,5,0.0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;Purdue University;University of Science and Technology of China;Purdue University,GANs;Uniform Generalization Bound;Deep Learning;Weight normalization,-1;-1;24;-1;24,80;80;88;80;88,m;m,usa,usa,y,1;5;4
5132,ICLR,2020,Efficient Wrapper Feature Selection using Autoencoder and Model Based Elimination,Sharan Ramjee;Aly El Gamal,sramjee@purdue.edu;elgamala@purdue.edu,1;3;3,,Reject,1,5,0.0,yes,9/25/19,Purdue University;Purdue University,Wrapper Feature Selection;AMBER;Ranker Model;Generative Training;Wireless Subsampling,24;24,88;88,m;m,usa,usa,n,
5133,ICLR,2020,Training Data Distribution Search with Ensemble Active Learning,Kashyap Chitta;Jose M. Alvarez;Elmar Haussmann;Clement Farabet,kashyap.chitta@tue.mpg.de;josea@nvidia.com;ehaussmann@nvidia.com;cfarabet@nvidia.com,6;6;1,,Reject,0,3,0.0,yes,9/25/19,Max-Planck Institute;NVIDIA;NVIDIA;NVIDIA,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5134,ICLR,2020,Coresets for Accelerating Incremental Gradient Methods,Baharan Mirzasoleiman;Jeff Bilmes;Jure Leskovec,baharanm@cs.stanford.edu;bilmes@uw.edu;jure@cs.stanford.edu,8;3;3,,Reject,0,3,0.0,yes,9/25/19,"Stanford University;University of Washington, Seattle;Stanford University",,5;11;5,4;26;4,f;m,usa,usa,y,1
5135,ICLR,2020,Gaussian MRF Covariance Modeling for Efficient Black-Box Adversarial Attacks,Anit Kumar Sahu;J. Zico Kolter;Satya Narayan Shukla,anit.sahu@gmail.com;zkolter@cs.cmu.edu;snshukla@cs.umass.edu,8;3;3,,Reject,0,5,0.0,yes,9/25/19,"Amazon;Carnegie Mellon University;University of Massachusetts, Amherst",Black-Box Adversarial Attacks;Gaussian Markov Random Fields,-1;1;24,-1;27;209,m;m,usa,usa,n,11;4
5136,ICLR,2020,How can we generalise learning distributed representations of graphs?,Paul M Scherer;Pietro Lio,pms69@cam.ac.uk;pl219@cam.ac.uk,3;6;1,,Reject,0,8,0.0,yes,9/25/19,University of Cambridge;University of Cambridge,graphs;distributed representations;similarity learning,79;79,3;3,m;m,europe,uk,n,10
5137,ICLR,2020,Graph Residual Flow for Molecular Graph Generation,Shion Honda;Hirotaka Akita;Katsuhiko Ishiguro;Toshiki Nakanishi;Kenta Oono,26x.orc.ed5.1hs@gmail.com;akita714@preferred.jp;k.ishiguro.jp@ieee.org;nakanishi@preferred.jp;oono@preferred.jp,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"The University of Tokyo;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",deep generative model;normalizing flow;graph generation;cheminformatics,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;10;5
5138,ICLR,2020,Regularizing Deep Multi-Task Networks using Orthogonal Gradients,Mihai Suteu;Yi-ke Guo,m.suteu16@imperial.ac.uk;y.guo@imperial.ac.uk,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Imperial College London;Imperial College London,multi-task learning;gradient regularization;orthogonal gradients,52;52,10;10,m;m,europe,uk,n,
5139,ICLR,2020,Blending Diverse Physical Priors with Neural Networks,Yunhao Ba;Guangyuan Zhao;Achuta Kadambi,yhba@ucla.edu;zhaoguangyuan@ucla.edu;achuta@ee.ucla.edu,6;3;6,,Reject,0,6,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Physics-based learning;Physics-aware learning,-1;-1;-1,17;17;17,m;m,usa,usa,n,1
5140,ICLR,2020,The Detection of Distributional Discrepancy for Text Generation,Xingyuan Chen;Ping Cai;Peng Jin;Haokun Du;Hongjun Wang;Xinyu Dai;Jiajun Chen,1045258214@qq.com;1061185275@qq.com;jandp@pku.edu.cn;626913553@qq.com;wanghongjun@swjtu.edu.cn;daixinyu@nju.edu.cn;chenjj@nju.edu.cn,1;3;1,,Reject,0,0,0.0,yes,9/25/19,Nanjing University;;Peking University;;Southwest Jiaotong University;Zhejiang University;Zhejiang University,,-1;-1;14;-1;-1;39;39,-1;-1;24;-1;1072;107;107,m;f,asia,cn,n,3;5;4
5141,ICLR,2020,DG-GAN: the GAN with the duality gap,Cheng Peng;Hao Wang;Xiao Wang;Zhouwang Yang,pch0051@mail.ustc.edu.cn;wh001@mail.ustc.edu.cn;wangxiao@purdue.edu;yangzw@ustc.edu.cn,1;1;1,,Reject,0,3,0.0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;Purdue University;University of Science and Technology of China,GAN;duality gap;metric;saddle point;game,-1;-1;24;-1,80;80;88;80,m;m,NAN,NAN,n,1;5;4
5142,ICLR,2020,Samples Are Useful? Not Always: denoising policy gradient updates using variance explained,Yannis Flet-Berliac;Philippe Preux,yannis.flet-berliac@inria.fr;philippe.preux@inria.fr,3;6;6,,Reject,0,4,0.0,yes,9/25/19,INRIA;INRIA,reinforcement learning;policy gradient;sampling,-1;-1,-1;-1,m;m,europe,gr,n,
5143,ICLR,2020,Continual Learning via Principal Components Projection,Gyuhak Kim;Bing Liu,gkim87@uic.edu;liub@uic.edu,3;3;3,,Reject,0,0,0.0,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago",Neural network;continual learning;catastrophic forgetting;lifelong learning,-1;-1,-1;-1,u;m,usa,usa,n,
5144,ICLR,2020,Iterative Deep Graph Learning for Graph Neural Networks,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,3;6;3,,Reject,0,5,0.0,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,deep learning;graph neural networks;graph learning,248;194;248,438;-1;438,f;m,usa,usa,n,10
5145,ICLR,2020,Training Deep Neural Networks by optimizing over nonlocal paths in hyperparameter space,Vlad Pushkarov;Yonathan Efroni;Mykola Maksymenko;Maciej Koch-Janusz,vladpush@icloud.com;jonathan.efroni@gmail.com;mmaks@softserveinc.com;maciejk@ethz.ch,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Icloud;;SoftServe Inc.;Swiss Federal Institute of Technology,deep learning;Hyperparameter optimization;dropout,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5146,ICLR,2020,An Optimization Principle Of Deep Learning?,Cheng Chen;Junjie Yang;Yi Zhou,u0952128@utah.edu;yang.4972@buckeyemail.osu.edu;yi.zhou@utah.edu,3;1;1,,Reject,0,4,0.0,yes,9/25/19,University of Utah;Ohio State University;University of Utah,,64;59;64,219;70;219,f;m,europe,uk,y,9
5147,ICLR,2020,Amata: An Annealing Mechanism for Adversarial Training Acceleration,Nanyang Ye;Qianxiao Li;Zhanxing Zhu,yn272@cam.ac.uk;qianxiao@nus.edu.sg;zhanxing.zhu@pku.edu.cn,6;6;3,,Reject,0,4,0.0,yes,9/25/19,University of Cambridge;National University of Singapore;Peking University,,79;17;14,3;25;24,m;m,asia,cn,y,1;4
5148,ICLR,2020,Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets,Thu Dinh*;Bao Wang*;Andrea L. Bertozzi;Stanley J. Osher;Jack Xin,thud2@uci.edu;wangbaonj@gmail.com;bertozzi@math.ucla.edu;sjo@math.ucla.edu;jxin@math.uci.edu,3;3;1,,Reject,0,4,0.0,yes,9/25/19,"University of California, Irvine;University of Utah;University of California, Los Angeles;University of California, Los Angeles;University of California, Irvine",Sparse Network;Model Compression;Adversarial Training,-1;64;-1;-1;-1,96;219;17;17;96,m;m,usa,usa,y,4
5149,ICLR,2020,Perceptual Generative Autoencoders,Zijun Zhang;Ruixiang Zhang;Zongpeng Li;Yoshua Bengio;Liam Paull,zijun.zhang@ucalgary.ca;sodabeta7@gmail.com;zongpeng@whu.edu.cn;yoshua.bengio@mila.quebec;paulll@iro.umontreal.ca,3;3;3,,Reject,0,5,0.0,yes,9/25/19,"University of Calgary;Mila, UdeM;Wuhan University;Mila;University of Montreal",,248;-1;194;143;118,210;-1;354;336;85,m;m,canada,ca,y,5
5150,ICLR,2020,Deep symbolic regression,Brenden K. Petersen,petersen33@llnl.gov,3;6;1,,Reject,0,4,0.0,yes,9/25/19,Lawrence Livermore National Labs,symbolic regression;reinforcement learning;automated machine learning,-1,-1,m,NAN,NAN,n,
5151,ICLR,2020,Task-Relevant Adversarial Imitation Learning,Konrad Zolna;Scott Reed;Alexander Novikov;Ziyu Wang;Sergio G√≥mez;David Budden;Serkan Cabi;Misha Denil;Nando de Freitas,konrad.zolna@gmail.com;reedscot@google.com;anovikov@google.com;ziyu@google.com;sergomez@google.com;budden@google.com;cabi@google.com;mdenil@google.com;nandodefreitas@google.com,8;6;3,,Reject,1,5,0.0,yes,9/25/19,Jagiellonian University;Google;Google;Google;Google;Google;Google;Google;Google,adversarial;imitation;robot;manipulation,-1;-1;-1;-1;-1;-1;-1;-1;-1,610;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
5152,ICLR,2020,"Imitation Learning of Robot Policies using Language, Vision and Motion",Simon Stepputtis;Joseph Campbell;Mariano Phielipp;Chitta Baral;Heni Ben Amor,sstepput@asu.edu;jacampb1@asu.edu;mariano.j.phielipp@intel.com;chitta@asu.edu;hbenamor@asu.edu,6;3;1,,Reject,0,6,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Intel;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,robot learning;imitation learning;natural language processing,-1;-1;-1;-1;-1,299;299;-1;299;299,m;m,NAN,NAN,n,3;1
5153,ICLR,2020,Why Learning of Large-Scale Neural Networks Behaves Like Convex Optimization,Hui Jiang,hj@cse.yorku.ca,1;1;1;1,,Reject,0,0,0.0,yes,9/25/19,York University,function space;canonical space;neural networks;stochastic gradient descent;disparity matrix,194,416,m,asia,kr,y,9
5154,ICLR,2020,Information Theoretic Model Predictive Q-Learning,Mohak Bhardwaj;Ankur Handa;Dieter Fox;Byron Boots,mohakb@cs.washington.edu;ahanda@nvidia.com;fox@cs.washington.edu;bboots@cs.washington.edu,3;6;3,,Reject,0,9,0.0,yes,9/25/19,University of Washington;NVIDIA;University of Washington;University of Washington,entropy regularized reinforcement learning;information theoretic MPC;robotics,11;-1;11;11,26;-1;26;26,m;m,usa,usa,n,
5155,ICLR,2020,Learning to Optimize via Dual space Preconditioning,S√©lim Chraibi;Adil Salim;Samuel Horv√°th;Filip Hanzely;Peter Richt√°rik,selimsepthuit@gmail.com;adil.salim@kaust.edu.sa;samuel.horvath@kaust.edu.sa;filip.hanzely@kaust.edu.sa;richtarik@gmail.com,3;3;1,,Reject,0,3,0.0,yes,9/25/19,CNRS;KAUST;KAUST;KAUST;KAUST,Optimization;meta-learning,-1;102;102;102;102,-1;-1;-1;-1;-1,m;m,europe,gr,y,
5156,ICLR,2020,HaarPooling: Graph Pooling with Compressive Haar Basis,Yu Guang Wang;Ming Li;Zheng Ma;Guido Montufar;Xiaosheng Zhuang;Yanan Fan,yuguang.wang@unsw.edu.au;ming.li.ltu@gmail.com;mzheng@princeton.edu;montufar@math.ucla.edu;xzhuang7@cityu.edu.hk;y.fan@unsw.edu.au,3;3;3;6,,Reject,0,9,0.0,yes,9/25/19,"University of New South Wales;Australian National University;Princeton University;University of California, Los Angeles;The Hong Kong Polytechnic University;University of New South Wales",graph pooling;graph neural networks;tree;graph classification;graph regression;deep learning;Haar wavelet basis;fast Haar transforms,-1;102;30;-1;118;-1,-1;50;6;17;171;-1,m;f,NAN,NAN,y,10
5157,ICLR,2020,Neural-Guided Symbolic Regression with Asymptotic Constraints,Li Li;Minjie Fan;Rishabh Singh;Patrick Riley,leeley@google.com;mjfan@google.com;rising@google.com;pfr@google.com,3;3;8,,Reject,0,12,0.0,yes,9/25/19,Google;Google;Google;Google,symbolic regression;program synthesis;monte carlo tree search,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5158,ICLR,2020,Handwritten Amharic Character Recognition System Using Convolutional Neural Networks,Fetulhak Abdurahman,afetulhak@yahoo.com,1;1;1,,Reject,1,1,0.0,yes,9/25/19,0,Amharic;Handwritten;Character;Convolutional neural network;Recognition,,,m,NAN,NAN,n,
5159,ICLR,2020,Deep Relational Factorization Machines,Hongchang Gao;Gang Wu;Ryan Rossi;Viswanathan Swaminathan;Heng Huang,hongchanggao@gmail.com;gawu@adobe.com;ryrossi@adobe.com;vishy@adobe.com;henghuanghh@gmail.com,1;1;3,,Reject,0,1,0.0,yes,9/25/19,University of Pittsburgh;Adobe Systems;Adobe Systems;Adobe Systems;University of Pittsburgh,,79;-1;-1;-1;79,113;-1;-1;-1;113,m;m,usa,usa,n,10
5160,ICLR,2020,Dirichlet Wrapper to Quantify Classification Uncertainty in Black-Box Systems,Jos√© Mena Rold√°n;Oriol Pujol Vila;Jordi Vitri√† Marca,jmenarol7@alumnes.ub.edu;oriol_pujol@ub.edu;jordi.vitria@ub.edu,6;1;1;1,,Reject,0,0,0.0,yes,9/25/19,Universitat de Barcelona;Universitat de Barcelona;Universitat de Barcelona,uncertainty;black-box classifiers;rejection;deep learning;NLP;CV,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2;3
5161,ICLR,2020,DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images,Tianshuo Cong;Dan Peng;Furui Liu;Zhitang Chen,cts17@mails.tsinghua.edu.cn;lepangdan@outlook.com;liufurui2@huawei.com;chenzhitang2@huawei.com,1;1;6,,Reject,0,3,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;;Huawei Technologies Ltd.;Huawei Technologies Ltd.",Causality discovery;AutoEncoder;Deep representation learning;Do-calculus,4;-1;-1;-1,23;-1;-1;-1,u;m,NAN,NAN,n,10;4
5162,ICLR,2020,Forecasting Deep Learning Dynamics with Applications to Hyperparameter Tuning,Piotr Kozakowski;≈Åukasz Kaiser;Afroz Mohiuddin,p.kozakowski@mimuw.edu.pl;lukaszkaiser@google.com;afrozm@google.com,3;6;1,,Reject,0,5,0.0,yes,9/25/19,"University of Washington, Seattle;Google;Google",,11;-1;-1,26;-1;-1,m;m,NAN,NAN,n,8
5163,ICLR,2020,Disentangling Trainability and Generalization in Deep Learning,Lechao Xiao;Jeffrey Pennington;Sam Schoenholz,xlc@google.com;jpennin@google.com;schsam@google.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;Google,NTK;NNGP;mean field theory;CNN;trainability and generalization;Gaussian process,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
5164,ICLR,2020,Versatile Anomaly Detection with Outlier Preserving Distribution Mapping Autoencoders,Walter Gerych;Elke Rundensteiner;Emmanuel Agu,wgerych@wpi.edu;rundenst@wpi.edu;emmanuel@wpi.edu,6;6;3,,Reject,0,3,0.0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute,Anomaly detection;outliers;deep learning;distribution mapping;wasserstein autoencoders,143;143;143,628;628;628,m;m,usa,usa,y,
5165,ICLR,2020,DeepPCM: Predicting Protein-Ligand Binding using Unsupervised Learned Representations,Paul Kim;Robin Winter;Djork-Arn√© Clevert,paul.kim@bayer.com;robin.winter@bayer.com;djork-arne.clevert@bayer.com,3;1;3,,Reject,2,0,0.0,yes,9/25/19,Bayer Ag;Bayer Ag;Bayer Ag,Unsupervised Representation Learning;Computational biology;computational chemistry;protein-ligand binding,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5166,ICLR,2020,Learning transitional skills with intrinsic motivation,Qiangxing Tian;Jinxin Liu;Donglin Wang,11821087@zju.edu.cn;liujinxin@westlake.edu.cn;wangdonglin@westlake.edu.cn,3;3;6,,Reject,0,3,0.0,yes,9/25/19,Zhejiang University;University of Science and Technology of China;University of Science and Technology of China,,39;-1;-1,107;80;80,m;m,NAN,NAN,n,
5167,ICLR,2020,Preventing Imitation Learning with Adversarial Policy Ensembles,Albert Zhan;Pieter Abbeel;Stas Tiomkin,albertzhan@berkeley.edu;pabbeel@cs.berkeley.edu;stasti@gmail.com,3;1;3,,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Imitation Learning;Reinforcement Learning;Representation Learning,-1;-1;-1,13;13;13,m;m,usa,usa,n,4
5168,ICLR,2020,Noisy Machines: Understanding noisy neural networks and enhancing robustness to analog hardware errors using distillation,Chuteng Zhou;Prad Kadambi;Matthew Mattina;Paul N. Whatmough,chu.zhou@arm.com;pkadambi@asu.edu;matthew.mattina@arm.com;paul.whatmough@arm.com,3;6;6;3,,Reject,0,5,0.0,yes,9/25/19,arm;SUN YAT-SEN UNIVERSITY;arm;arm,network noise robustness;analog accelerator;noise injection;distillation;error rate,59;-1;59;59,289;299;289;289,m;m,asia,in,n,
5169,ICLR,2020,Mutual Information Maximization for Robust Plannable Representations,Yiming Ding;Ignasi Clavera;Pieter Abbeel,dingyiming0427@berkeley.edu;iclavera@berkeley.edu;pabbeel@cs.berkeley.edu,3;1;6,,Reject,0,3,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;robust learning;model based;planning;representation learning,-1;-1;-1,13;13;13,f;m,usa,usa,n,
5170,ICLR,2020,Removing input features via a generative model to explain their attributions to classifier's decisions,Chirag Agarwal;Dan Schonfeld;Anh Nguyen,chiragagarwall12@gmail.com;dans@uic.edu;anh.ng8@gmail.com,1;3;6,,Reject,0,8,0.0,yes,9/25/19,"Harvard University;University of Illinois, Chicago;Auburn University",attribution maps;generative models;inpainting;counterfactual;explanations;interpretability;explainability,52;-1;445,7;-1;651,m;m,usa,usa,n,5
5171,ICLR,2020,Gauge Equivariant Spherical CNNs,Berkay Kicanaoglu;Pim de Haan;Taco Cohen,b.kicanaoglu@uva.nl;pimdehaan@gmail.com;taco.cohen@gmail.com,8;8;3,,Reject,0,4,0.0,yes,9/25/19,University of Amsterdam;University of Amsterdam;University of Amsterdam,deep learning;convolutional networks;equivariance;gauge equivariance;symmetry;geometric deep learning;manifold convolution,143;143;-1,62;62;-1,m;m,asia,in,n,2;1;10
5172,ICLR,2020,Relation-based Generalized Zero-shot Classification with the Domain Discriminator on the shared representation,Masahiro Suzuki;Yutaka Matsuo,masa@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,6;3;6,,Reject,0,6,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo,,64;64,36;36,m;m,NAN,NAN,n,6;5
5173,ICLR,2020,Machine Truth Serum,Tianyi Luo;Yang Liu,tluo6@ucsc.edu;yangliu@ucsc.edu,6;1;3,,Reject,0,4,0.0,yes,9/25/19,University of Southern California;University of Southern California,Ensemble method;Classification;Machine Truth Serum;Minority;Machine Learning,36;36,62;62,m;m,usa,usa,y,11
5174,ICLR,2020,A Gradient-Based Approach to Neural Networks Structure Learning,Amir Ali Moinfar;Amirkeivan Mohtashami;Mahdieh Soleymani;Ali Sharifi-Zarchi,moinfar@ce.sharif.edu;mohtashami@ce.sharif.edu;soleymani@sharif.edu;sharifi@sharif.edu,6;3;3,,Reject,0,3,0.0,yes,9/25/19,Sharif University of Technology;Sharif University of Technology;Sharif University of Technology;Sharif University of Technology,,316;316;316;316,564;564;564;564,m;m,asia,ir,y,
5175,ICLR,2020,Learning Generative Models using Denoising Density Estimators,Siavash Bigdeli;Geng Lin;Tiziano Portenier;Andrea Dunbar;Matthias Zwicker,siavash.bigdeli@csem.ch;geng@cs.umd.edu;tiziano.portenier@vision.ee.ethz.ch;andrea.dunbar@csem.ch;zwicker@cs.umd.edu,1;3;6,,Reject,0,7,0.0,yes,9/25/19,"Swiss Center for Electronics and Micro Electronics;University of Maryland, College Park;Swiss Federal Institute of Technology;Swiss Center for Electronics and Micro Electronics;University of Maryland, College Park",generative probabilistic models;denoising autoencoders;neural density estimation,-1;12;-1;-1;12,-1;91;-1;-1;91,m;m,usa,usa,y,1;5;4
5176,ICLR,2020,NPTC-net: Narrow-Band Parallel Transport Convolutional Neural Network on Point Clouds,Pengfei Jin;Tianhao Lai;Rongjie Lai;Bin Dong,jinpf@pku.edu.cn;howeverlth@pku.edu.cn;lair@rpi.edu;dongbin@math.pku.edu.cn,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Peking University;Peking University;Rensselaer Polytechnic Institute;Peking University,geometric convolution;point cloud;parallel transport,14;14;248;14,24;24;438;24,u;m,asia,cn,n,2;1
5177,ICLR,2020,Attributed Graph Learning with 2-D Graph Convolution,Qimai Li;Xiaotong Zhang;Han Liu;Xiao-Ming Wu,csqmli@comp.polyu.edu.hk;zxt.dut@hotmail.com;liu.han.dut@gmail.com;xiao-ming.wu@polyu.edu.hk,3;6;6,,Reject,0,4,0.0,yes,9/25/19,The Hong Kong Polytechnic University;;;The Hong Kong Polytechnic University,2-D Graph Convolution;Attributed Graph;Representation learning,118;-1;-1;118,171;-1;-1;171,m;f,asia,hk,y,10
5178,ICLR,2020,Pareto Optimality in No-Harm Fairness,Natalia Martinez;Martin Bertran;Guillermo Sapiro,natalia.martinez@duke.edu;martin.bertran@duke.edu;guillermo.sapiro@duke.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Duke University;Duke University;Duke University,Fairness;Fairness in Machine Learning;No-Harm Fairness,46;46;46,20;20;20,f;m,europe,se,y,1;7
5179,ICLR,2020,Conditional generation of molecules from disentangled representations,Amina Mollaysa;Brooks Paige;Alexandros  Kalousis,amina.mollaysa@gmail.com;tbpaige@gmail.com;alexandros.kalousis@hesge.ch,3;1;6,,Reject,0,5,0.0,yes,9/25/19,"University of Geneva, Switzerland;University College London;University of Applied Sciences Western Switzerland",molecule generation;disentangling,-1;52;-1,144;-1;-1,f;m,NAN,NAN,y,
5180,ICLR,2020,Overparameterized Neural Networks Can Implement Associative Memory,Adityanarayanan Radhakrishnan;Mikhail Belkin;Caroline Uhler,aradha@mit.edu;mbelkin@cse.ohio-state.edu;cuhler@mit.edu,3;3;3,,Reject,0,9,0.0,yes,9/25/19,"Massachusetts Institute of Technology;University of California, San Diego;Massachusetts Institute of Technology",Associative Memory;Memorization and Recall;Attractors;Deep Autoencoders,5;-1;5,5;31;5,m;f,usa,usa,y,
5181,ICLR,2020,TinyBERT: Distilling BERT for Natural Language Understanding,Xiaoqi Jiao;Yichun Yin;Lifeng Shang;Xin Jiang;Xiao Chen;Linlin Li;Fang Wang;Qun Liu,jiaoxiaoqi@hust.edu.cn;yinyichun@huawei.com;shang.lifeng@huawei.com;jiang.xin@huawei.com;chen.xiao2@huawei.com;lynn.lilinlin@huawei.com;wangfang@hust.edu.cn;qun.liu@huawei.com,8;3;6,,Reject,1,9,1.0,yes,9/25/19,Hong Kong University of Science and Technology;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Hong Kong University of Science and Technology;Huawei Technologies Ltd.,BERT Compression;Transformer Distillation;TinyBERT,-1;-1;-1;-1;-1;-1;-1;-1,47;-1;-1;-1;-1;-1;47;-1,u;m,NAN,NAN,n,8;3
5182,ICLR,2020,Cross Domain Imitation Learning,Kun Ho Kim;Yihong Gu;Jiaming Song;Shengjia Zhao;Stefano Ermon,khkim@cs.stanford.edu;gyh15@mails.tsinghua.edu.cn;jiaming.tsong@gmail.com;sjzhao@stanford.edu;ermon@cs.stanford.edu,3;6;8,,Reject,1,5,0.0,yes,9/25/19,"Stanford University;Tsinghua University, Tsinghua University;Stanford University;Stanford University;Stanford University",Imitation Learning;Domain Adaptation;Reinforcement Learning;Zeroshot Learning;Machine Learning;Artificial Intelligence,5;4;5;5;5,4;23;4;4;4,m;m,usa,usa,y,6;1;5;4
5183,ICLR,2020,Multi-source Multi-view Transfer Learning in Neural Topic Modeling with Pretrained Topic and Word Embeddings,Pankaj Gupta;Yatin Chaudhary;Hinrich Sch√ºtze,pankaj_gupta96@yahoo.com;yatinchaudhary91@gmail.com;hinrich@hotmail.com,6;3;6,,Reject,0,6,0.0,yes,9/25/19,DRIMCo GmbH;;Centrum fuer Informations- und Sprachverarbeitung,Neural Topic Modeling;Transfer Learning;Unsupervised learning;Natural Language Processing,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,3;1;6
5184,ICLR,2020,Natural Image Manipulation for Autoregressive Models Using Fisher Scores,Wilson Yan;Jonathan Ho;Pieter Abbeel,wilson1.yan@berkeley.edu;jonathanho@berkeley.edu;pabbeel@cs.berkeley.edu,3;8;1,,Reject,0,4,0.0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,fisher score;generative models;image interpolation,-1;-1;-1,13;13;13,m;m,usa,usa,n,5
5185,ICLR,2020,SPECTRA: Sparse Entity-centric Transitions,Rim Assouel;Yoshua Bengio,rim.assouel@hotmail.fr;yoshua.bengio@mila.quebec,3;3;3,,Reject,0,1,0.0,yes,9/25/19,University of Montreal;Mila,representation learning;slot-structured representations;sparse slot-structured transitions;entity-centric representation;unsupervised learning;object-centric,-1;143,-1;336,f;m,NAN,NAN,n,
5186,ICLR,2020,Attentive Sequential Neural Processes,Jaesik Yoon;Gautam Singh;Sungjin Ahn,jaesik817@gmail.com;singh.gautam.iitg@gmail.com;sjn.ahn@gmail.com,6;1;3,,Reject,0,6,0.0,yes,9/25/19,Rutgers University;;Rutgers University,meta-learning;neural processes;attention;sequential modeling,30;-1;30,-1;-1;-1,m;m,usa,usa,n,8
5187,ICLR,2020,Generative Latent Flow,Zhisheng Xiao;Qing Yan;Yali Amit,zxiao@uchicago.edu;yanq@uchicago.edu;amit@marx.uchicago.edu,3;3;6,,Reject,0,6,0.0,yes,9/25/19,University of Chicago;University of Chicago;University of Chicago,Generative Model;Auto-encoder;Normalizing Flow,51;51;51,9;9;9,m;m,usa,usa,n,5
5188,ICLR,2020,"Farkas layers: don't shift the data, fix the geometry",Aram-Alexandre Pooladian;Chris Finlay;Adam M Oberman,aram-alexandre.pooladian@mail.mcgill.ca;christopher.finlay@gmail.com;adam.oberman@mcgill.ca,1;3;3,,Reject,0,3,0.0,yes,9/25/19,McGill University;Deep Render;McGill University,initialization;deep networks;residual networks;batch normalization;training;optimization,102;-1;102,42;-1;42,m;m,canada,ca,y,
5189,ICLR,2020,STABILITY AND CONVERGENCE THEORY FOR LEARNING RESNET: A FULL CHARACTERIZATION,Huishuai Zhang;Da Yu;Mingyang Yi;Wei Chen;Tie-yan Liu,huishuai.zhang@microsoft.com;yuda3@mail2.sysu.edu.cn;v-minyi@microsoft.com;wche@microsoft.com;tie-yan.liu@microsoft.com,3;1;6,,Reject,1,4,0.0,yes,9/25/19,Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft;Microsoft,ResNet;stability;convergence theory;over-parameterization,-1;-1;-1;-1;-1,-1;299;-1;-1;-1,m;m,NAN,NAN,y,9
5190,ICLR,2020,Universal approximations of permutation invariant/equivariant functions by deep neural networks,Akiyoshi Sannai;Yuuki Takai;Matthieu Cordonnier,akiyoshi.sannai@riken.jp;yuuki.takai@riken.jp;matthieu.cordonnier@ens-paris-saclay.fr,3;3;3,,Reject,0,3,0.0,yes,9/25/19,RIKEN;RIKEN;Ecole Normale Superieure,finite group;invariant;equivariant;neural networks,-1;-1;118,-1;-1;-1,m;m,europe,fr,y,1
5191,ICLR,2020,Context-aware Attention Model for Coreference Resolution,Yufei Li;Xiangyu Zhou;Jie Ma;Yu Long;Xuan Wang;Chen Li,vermouthtarot@gmail.com;zxy951005@stu.xjtu.edu.cn;majack@stu.xjtu.edu.cn;longyu95@stu.xjtu.edu.cn;wangxuan8888@stu.xjtu.edu.cn;cli@xjtu.edu.cn,1;1;1,,Reject,0,0,0.0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,Coreference resolution;Feature Attention,-1;-1;-1;-1;-1;-1,-1;555;555;555;555;555,u;m,NAN,NAN,n,8
5192,ICLR,2020,A Random Matrix Perspective on Mixtures of Nonlinearities in High Dimensions,Ben Adlam;Jake Levinson;Jeffrey Pennington,adlam@google.com;jpennin@google.com;jlev@google.com,8;3;6,,Reject,0,5,0.0,yes,9/25/19,Google;Google;Google,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
5193,ICLR,2020,CaptainGAN: Navigate Through Embedding Space For Better Text Generation,Chun-Hsing Lin;Alvin Chiang;Chi-Liang Liu;Chien-Fu Lin;Po-Hsien Chu;Siang-Ruei Wu;Yi-En Tsai;Chung-Yang (Ric) Huang,jsaon92@gmail.com;alvin.chiang.180@gmail.com;liangtaiwan1230@gmail.com;gblin75468@gmail.com;cph@yoctol.com;raywu0@gmail.com;ypiheyn.imm02g@g2.nctu.edu.tw;cyhuang@ntu.edu.tw,6;6;3,,Reject,0,12,0.0,yes,9/25/19,National Taiwan University;;;;Yoctol;;National Chiao Tung University;Nanyang Technological University,Generative Adversarial Network;Text Generation;Straight-Through Estimator,-1;-1;-1;-1;-1;-1;118;43,-1;-1;-1;-1;-1;-1;564;49,m;m,asia,sg,n,3;5
5194,ICLR,2020,Policy Optimization with Stochastic Mirror Descent,Long Yang;Gang Zheng;Zavier Zhang;Yu Zhang;Qian Zheng;Jun Wen;Gang Pana sample efficient policy gradient method with stochastic mirror descent.,yanglong@zju.edu.cn;gang_zheng@zju.edu.cn;21721269@zju.edu.cn;hzzhangyu@zju.edu.cn;csqianzheng@gmail.com;junwen@zju.edu.cn;gpan@zju.edu.cn,3;3;6,,Reject,0,5,0.0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;;Zhejiang University;Zhejiang University,reinforcement learning;policy gradient;stochastic variance reduce gradient;sample efficiency;stochastic mirror descent,39;39;39;39;-1;39;39,107;107;107;107;-1;107;107,m;u,asia,cn,y,9
5195,ICLR,2020,A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization,Guangzeng Xie;Luo Luo;Zhihua Zhang,smsxgz@pku.edu.cn;rickyluoluo@gmail.com;zhzhang@math.pku.edu.cn,3;8;6,,Reject,1,4,0.0,yes,9/25/19,Peking University;;Peking University,convex optimization;lower bound complexity;proximal incremental first-order oracle,14;-1;14,24;-1;24,m;m,asia,cn,y,1
5196,ICLR,2020,Reducing Computation in Recurrent Networks by Selectively Updating State Neurons,Thomas Hartvigsen;Cansu Sen;Xiangnan Kong;Elke Rundensteiner,twhartvigsen@wpi.edu;csen@wpi.edu;xkong@wpi.edu;rundenst@wpi.edu,6;6;6,,Reject,0,4,0.0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute,recurrent neural networks;conditional computation;representation learning,143;143;143;143,628;628;628;628,m;f,usa,usa,n,
5197,ICLR,2020,Selective Brain Damage: Measuring the Disparate Impact of Model Pruning,Sara Hooker;Yann Dauphin;Aaron Courville;Andrea Frome,shooker@google.com;ynd@google.com;aaron.courville@gmail.com;onepinkfairyarmadillo@gmail.com,3;3;3,,Reject,0,4,0.0,yes,9/25/19,Google;Google;University of Montreal;Google,machine learning,-1;-1;118;-1,-1;-1;85;-1,f;f,asia,in,n,
5198,ICLR,2020,Deep exploration by novelty-pursuit with maximum state entropy,Zi-Niu Li;Xiong-Hui Chen;Yang Yu,liziniu1997@gmail.com;chenxh@lamda.nju.edu.cn;yuy@lamda.nju.edu.cn,1;3;3,,Reject,0,4,0.0,yes,9/25/19,The Chinese University of Hong Kong;Zhejiang University;Zhejiang University,Exploration;Reinforcement Learning,-1;39;39,-1;107;107,m;m,asia,cn,y,
5199,ICLR,2020,Smart Ternary Quantization,Gregoire Morin;Ryan Razani;Vahid Partovi Nia;Eyyub Sari,gregoire.morin@huawei.com;ryan.razani@huawei.com;vahid.partovinia@huawei.com;eyyub.sari@huawei.com,3;6;1;3,,Reject,0,3,0.0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5200,ICLR,2020,Alleviating Privacy Attacks via Causal Learning,Shruti Tople;Amit Sharma;Aditya Nori,t-shtopl@microsoft.com;amshar@microsoft.com;adityan@microsoft.com,3;6;3,,Reject,0,14,0.0,yes,9/25/19,Microsoft;Microsoft;Microsoft,Causal learning;Membership Inference Attacks;Differential Privacy,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y,11;1;4
5201,ICLR,2020,Generalized Domain Adaptation with Covariate and Label Shift CO-ALignment,Shuhan Tan;Xingchao Peng;Kate Saenko,tanshh@mail2.sysu.edu.cn;xpeng@bu.edu;saenko@bu.edu,6;1;1,,Reject,1,5,0.0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Boston University;Boston University,Domain Adaptation;Label Shift;Covariate Shift,-1;79;79,299;61;61,m;f,europe,it,y,
5202,ICLR,2020,Deeper Insights into Weight Sharing in Neural Architecture Search,Yuge Zhang;Quanlu Zhang;Junyang Jiang;Zejun Lin;Yujing Wang,scottyugochang@gmail.com;quanlu.zhang@microsoft.com;jyjiang97@gmail.com;gdzejlin@gmail.com;yujing.wang@microsoft.com,3;3;3,,Reject,0,3,0.0,yes,9/25/19,Microsoft;Microsoft;;;Microsoft,Neural Architecture Search;NAS;AutoML;AutoDL;Deep Learning;Machine Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;u,NAN,NAN,n,8
5203,ICLR,2020,Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels,Shuang Song;David Berthelot;Afshin Rostamizadeh,shuangsong@google.com;dberth@google.com;rostami@google.com,3;6;3,,Reject,0,3,0.0,yes,9/25/19,Google;Google;Google,active learning;semi-supervised learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,
5204,ICLR,2020,Perceptual Regularization: Visualizing and Learning Generalizable Representations,Hongzhou Lin;Joshua Robinson;Stefanie Jegelka,hongzhou@mit.edu;joshrob@mit.edu;stefje@csail.mit.edu,6;1;3,,Reject,0,6,0.0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,regularization;representation learning;visualization,5;5;5,5;5;5,m;f,usa,usa,n,8;4
5205,ICLR,2020,Attention Forcing for Sequence-to-sequence Model Training,Qingyun Dou;Yiting Lu;Joshua Efiong;Mark J.F. Gales,qd212@cam.ac.uk;ytl28@cam.ac.uk;je369@cam.ac.uk;mjfg@cam.ac.uk,1;3;3,,Reject,2,4,0.0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge,deep learning;sequence-to-sequence model;attention mechanism;speech synthesis;machine translation,79;79;79;79,3;3;3;3,m;m,europe,uk,n,8;3
5206,ICLR,2020,Transferable Recognition-Aware Image Processing,Zhuang Liu;Tinghui Zhou;Zhiqiang Shen;Bingyi Kang;Trevor Darrell,zhuangl@berkeley.edu;tinghuiz@eecs.berkeley.edu;zhiqians@andrew.cmu.edu;kang@u.nus.edu;trevor@eecs.berkeley.edu,8;1;3,,Reject,0,8,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;Carnegie Mellon University;National University of Singapore;University of California Berkeley,Image Recognition;Image Processing,-1;-1;1;17;-1,13;13;27;25;13,m;m,usa,usa,n,
5207,ICLR,2020,NeuralUCB: Contextual Bandits with Neural Network-Based Exploration,Dongruo Zhou;Lihong Li;Quanquan Gu,drzhou@cs.ucla.edu;lihongli.cs@gmail.com;qgu@cs.ucla.edu,3;6;6,,Reject,0,10,0.0,yes,9/25/19,"University of California, Los Angeles;Amazon;University of California, Los Angeles",contextual bandits;neural network;upper confidence bound,-1;-1;-1,17;-1;17,m;m,usa,usa,y,1
5208,ICLR,2020,Quantized Reinforcement Learning (QuaRL),Srivatsan Krishnan;Sharad Chitlangia;Maximilian Lam;Zishen Wan;Aleksandra Faust;Vijay Janapa Reddi,srivatsan@seas.harvard.edu;f20170472@goa.bits-pilani.ac.in;maxlam@g.harvard.edu;zishenwan@g.harvard.edu;sandrafaust@google.com;vj@eecs.harvard.edu,3;3;3,,Reject,0,3,0.0,yes,9/25/19,"Harvard University;BITS Pilani, BITS Pilani;Harvard University;Harvard University;Google;Harvard University",Deep Reinforcement Learning;Quantization,52;445;52;52;-1;52,7;-1;7;7;-1;7,m;m,usa,usa,n,
5209,ICLR,2020,CNAS: Channel-Level Neural Architecture Search,Heechul Lim;Min-Soo Kim;Jinjun Xiong,skyde1021@dgist.ac.kr;mskim@dgist.ac.kr;jinjun@us.ibm.com,3;1;3;3,,Reject,0,0,0.0,yes,9/25/19,DGIST;DGIST;International Business Machines,Neural architecture search,15;15;-1,-1;-1;-1,m;m,NAN,NAN,n,
5210,ICLR,2020,Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?,Hiroaki Yamane;Chin-Yew Lin;Tatsuya Harada,hiroaki.yamane@riken.jp;cyl@microsoft.com;harada@mi.t.u-tokyo.ac.jp,1;3;1,,Reject,0,0,0.0,yes,9/25/19,RIKEN;Microsoft;The University of Tokyo,numerical common sense;word embedding;semantic representation,-1;-1;64,-1;-1;36,m;m,NAN,NAN,n,3
5211,ICLR,2020,Semi-supervised Semantic Segmentation using Auxiliary Network,Wei-Hsu Chen;Hsueh-Ming Hang,qoososola520.ee06g@nctu.edu.tw;hmhang@nctu.edu.tw,3;3;3,,Reject,0,0,0.0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,deep learning;semi-supervised segmentation;semantic segmentation;CNN,118;118,564;564,m;m,asia,tw,n,2;4
5212,ICLR,2020,DeepSFM: Structure From Motion Via Deep Bundle Adjustment,Xingkui Wei;Yinda Zhang;Zhuwen Li;Yanwei Fu;Xiangyang Xue,xkwei19@fudan.edu.cn;yindaz@cs.princeton.edu;lzhuwen@gmail.com;yanweifu@fudan.edu.cn;xyxue@fudan.edu.cn,6;6;3,,Reject,0,4,0.0,yes,9/25/19,"Fudan University;Princeton University;Nuro, Inc;Fudan University;Fudan University",Computer Vision;Bundle Ajustment;Structure from Motion,73;30;-1;73;73,109;6;-1;109;109,m;m,asia,cn,n,2
5213,ICLR,2020,A Base Model Selection Methodology for Efficient Fine-Tuning,Yosuke Ueno;Masaaki Kondo,ueno@hal.ipc.i.u-tokyo.ac.jp;kondo@hal.ipc.i.u-tokyo.ac.jp,3;3;3,,Reject,0,4,0.0,yes,9/25/19,The University of Tokyo;The University of Tokyo,transfer learning;fine-tuning;parameter transfer,64;64,36;36,m;m,NAN,NAN,n,6
5214,ICLR,2020,Localized Meta-Learning: A PAC-Bayes Analysis for Meta-Leanring Beyond Global Prior,Chenghao Liu;Tao Lu;Doyen Sahoo;Yuan Fang;Steven C.H. Hoi.,chliu@smu.edu.sg;lutaott@zju.edu.cn;doyensahoo@gmail.com;yfang@smu.edu.sg;shoi@salesforce.com,3;3;8;6,,Reject,0,9,0.0,yes,9/25/19,Singapore Management University;Zhejiang University;;Singapore Management University;SalesForce.com,localized meta-learning;PAC-Bayes;meta-learning,79;39;-1;79;-1,-1;107;-1;-1;-1,m;m,NAN,NAN,y,6;1
5215,ICLR,2020,Searching to Exploit Memorization Effect in Learning from Corrupted Labels,Hansi Yang;Quanming Yao;Bo Han;Gang Niu,yhs17@mails.tsinghua.edu.cn;qyaoaa@connect.ust.hk;bo.han@riken.jp;gang.niu@riken.jp,3;3;3,,Reject,0,5,0.0,yes,9/25/19,"Tsinghua University, Tsinghua University;The Hong Kong University of Science and Technology;RIKEN;RIKEN",Noisy Label;Deep Learning;Automated Machine Learning,4;-1;-1;-1,23;47;-1;-1,u;m,NAN,NAN,n,
5216,ICLR,2020,Attention over Phrases,Wanyun Cui,cui.wanyun@sufe.edu.cn,3;1;1,,Reject,1,2,0.0,yes,9/25/19,University of Science and Technology of China,representation learning;natural language processing;attention,-1,80,m,NAN,NAN,n,8;3
5217,ICLR,2020,Retrospection: Leveraging the Past for Efficient Training of Deep Neural Networks,Ayush Chopra;Surgan Jandial;Mausoom Sarkar;Balaji Krishnamurthy;Vineeth Balasubramanian,ayuchopr@adobe.com;cs17btech11038@iith.ac.in;msarkar@adobe.com;kbalaji@adobe.com;vineethnb@iith.ac.in,8;3,,Reject,0,6,0.0,yes,9/25/19,Adobe Systems;Indian Institute of Technology Hyderabad;Adobe Systems;Adobe Systems;Indian Institute of Technology Hyderabad,Deep Neural Networks;Supervised Learning;Classification;Training Strategy;Generative Adversarial Networks;Convolutional Neural Networks,-1;-1;-1;-1;-1,-1;713;-1;-1;713,m;m,NAN,NAN,n,
5218,ICLR,2020,Improving Dirichlet Prior Network for Out-of-Distribution Example Detection,Jay Nandy,a0123886@u.nus.edu,3;3;6,,Reject,0,5,0.0,yes,9/25/19,National University of Singapore,predictive uncertainty;distributional uncertainty;Dirichlet distribution;out-of-distribution detection;deep learning,17,25,m,asia,sg,n,
5219,ICLR,2020,Continual Density Ratio Estimation (CDRE): A new method for evaluating generative models in continual learning,Yu Chen;Song Liu;Tom Diethe;Peter Flach,yc14600@bristol.ac.uk;song.liu@bristol.ac.uk;tdiethe@amazon.com;peter.flach@bristol.ac.uk,1;1;6,,Reject,0,5,0.0,yes,9/25/19,University of Bristol;University of Bristol;Amazon;University of Bristol,density ratio estimation;continual learning;evaluation;generative model;f divergence,118;118;-1;118,87;87;-1;87,m;m,europe,uk,n,5
5220,ICLR,2020,Prune or quantize? Strategy for Pareto-optimally low-cost and accurate CNN,Kengo Nakata;Daisuke Miyashita;Asuka Maki;Fumihiko Tachibana;Shinichi Sasaki;Jun Deguchi,kengo1.nakata@toshiba.co.jp;daisuke1.miyashita@toshiba.co.jp;asuka.maki@toshiba.co.jp;fumihiko.tachibana@toshiba.co.jp;shinichi8.sasaki@toshiba.co.jp;jun.deguchi@toshiba.co.jp,3;3;3,,Reject,0,11,0.0,yes,9/25/19,Toshiba Corporation;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation,CNN;Quantization;Pruning;Accelerator;Computational cost,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5221,ICLR,2020,Concise Multi-head Attention Models,Srinadh Bhojanapalli;Chulhee Yun;Ankit Singh Rawat;Sashank Reddi;Sanjiv Kumar,bsrinadh@google.com;chulheey@mit.edu;ankitsrawat@google.com;sashank@google.com;sanjivk@google.com,1;3;3,,Reject,0,3,0.0,yes,9/25/19,Google;Massachusetts Institute of Technology;Google;Google;Google,Transformers;Attention;Multihead;expressive power;embedding size,-1;5;-1;-1;-1,-1;5;-1;-1;-1,m;m,NAN,NAN,y,8;3
5222,ICLR,2020,A Finite-Time Analysis of  Q-Learning with Neural Network Function Approximation,Pan Xu;Quanquan Gu,panxu@cs.ucla.edu;qgu@cs.ucla.edu,3;6;6,,Reject,4,6,0.0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",Reinforcement Learning;Neural Networks,-1;-1,17;17,m;m,usa,usa,y,1;9
5223,ICLR,2020,SCELMo: Source Code Embeddings from Language Models,Rafael - Michael Karampatsis;Charles Sutton,mpatsis13@gmail.com;charlessutton@google.com,3;3;8,,Reject,0,4,0.0,yes,9/25/19,University of Edinburgh;Google,Transfer Learning;Pretraining;Program Repair,-1;-1,-1;-1,m;m,NAN,NAN,n,3
5224,ICLR,2020,GraphMix: Regularized Training of Graph Neural Networks for Semi-Supervised Learning,Vikas Verma;Meng Qu;Alex Lamb;Yoshua Bengio;Juho Kannala;Jian Tang,vikasverma.iitm@gmail.com;meng.qu@umontreal.ca;lambalex@iro.umontreal.ca;yoshua.bengio@mila.quebec;juho.kannala@aalto.fi;jian.tang@hec.ca,3;3;6,,Reject,1,5,0.0,yes,9/25/19,Aalto University;University of Montreal;University of Montreal;Mila;Aalto University;HEC Montreal,Regularization;Graph Neural Networks;Mixup;Manifold Mixup;Semi-supervised Object Classification over graph Data,118;118;118;143;118;-1,182;85;85;336;182;-1,m;m,canada,ca,n,10
5225,ICLR,2020,Neural networks with motivation,Sergey A. Shuvaev;Ngoc B. Tran;Marcus Stephenson-Jones;Bo Li;Alexei A. Koulakov,sshuvaev@cshl.edu;ntran@cshl.edu;mstephen@cshl.edu;bli@cshl.edu;akula@cshl.edu,1;3;3,,Reject,0,11,0.0,yes,9/25/19,Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory,neuroscience;brain;motivation;learning;reinforcement learning;recurrent neural network;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
5226,ICLR,2020,Measuring causal influence with back-to-back regression: the linear case,Jean-Remi King;Francois Charton;Maxime Oquab;David Lopez-Paz,jeanremi@fb.com;fcharton@fb.com;qas@fb.com;dlp@fb.com,6;3;3,,Reject,0,6,0.0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5227,ICLR,2020,Longitudinal Enrichment of Imaging Biomarker Representations for Improved Alzheimer's Disease Diagnosis,Saad Elbeleidy;Lyujian Lu;L. Zoe Baker;Hua Wang;Feiping Nie,selbeleidy@mymail.mines.edu;lyujianlu@mines.edu;laurenzoebaker@mymail.mines.edu;huawangcs@gmail.com;feipingnie@gmail.com,1;3;1,,Reject,0,0,0.0,yes,9/25/19,Colorado School of Mines;Colorado School of Mines;Colorado School of Mines;Colorado School of Mines;Tsinghua University,,248;248;248;248;-1,343;343;343;343;-1,m;m,asia,in,y,
5228,ICLR,2020,RefNet: Automatic Essay Scoring by Pairwise Comparison,Jiaxin Li;Jinan Zhou,jiaxin.li@link.cuhk.edu.hk;jinan.zhou@link.cuhk.edu.hk,1;3;1,,Withdrawn,0,0,,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong,Natural Language Processing;Automatic Essay Scoring;Few-shot Learning;Neural Network;,316;316,35;35,m;m,NAN,NAN,n,
5229,ICLR,2020,Topology of deep neural networks,Gregory Naitzat;Andrey Zhitnikov;Lek-Heng Lim,gregn@uchicago.edu;andreyz@technion.ac.il;lekheng@galton.uchicago.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,"University of Chicago;Technion, Technion;University of Chicago",theoretical issues in deep learning;topology;Betti numbers;,51;27;51,9;-1;9,m;m,usa,usa,pdf miss,1
5230,ICLR,2020,Provable Convergence and Global Optimality  of Generative Adversarial Network,Qi Cai;Zhuoran Yang;Jason D. Lee;Shaolei S. Du;Zhaoran Wang,qicai2022@u.northwestern.edu;zy6@princeton.edu;jasonlee@princeton.edu;ssdu@ias.edu;zhaoranwang@gmail.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"Northwestern University;Princeton University;Princeton University;Institue for Advanced Study, Princeton;Northwestern University",generative adversarial network;IPM-based GANs;overparametrized neural network;,46;30;30;-1;46,22;6;6;-1;22,f;m,usa,usa,n,1;5;4;9
5231,ICLR,2020,Improving Irregularly Sampled Time Series Learning with Dense Descriptors of Time,Rafael Teixeira Sousa;Lucas Ara√∫jo Pereira;Anderson da Silva Soares,rafaelts777@gmail.com;apereiral@outlook.com;engsoares@gmail.com,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Universidade Federal de Mato Grosso;;Federal University of Goias,irregularly sampled;time series;embeddings;,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
5232,ICLR,2020,Understanding and Training Deep Diagonal Circulant Neural Networks,Alexandre Araujo;Benjamin Negrevergne;Yann Chevaleyre;Jamal Atif,alexandre.araujo@dauphine.eu;benjamin.negrevergne@dauphine.psl.eu;yann.chevaleyre@lamsade.dauphine.fr;jamal.atif@lamsade.dauphine.fr,1;3,,Withdrawn,0,2,,yes,9/25/19,Univerist√© Paris-Dauphine;Universit‚àö¬© Paris Dauphine;Univerist‚àö¬© Paris-Dauphine;Univerist‚àö¬© Paris-Dauphine,Deep Learning;Structured Matrices;Compression;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,
5233,ICLR,2020,DP-LSSGD: An Optimization Method to Lift the Utility in Privacy-Preserving ERM,Bao Wang;Quanquan Gu;March Boedihardjo;Farzin Barekat;Stanley J. Osher,wangbaonj@gmail.com;qgu@cs.ucla.edu;march@math.ucla.edu;fbarekat@math.ucla.edu;sjo@math.ucla.edu,3;6;3,,Withdrawn,0,3,,yes,9/25/19,"University of Utah;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Privacy-preserving ERM;Laplacian Smoothing;Improve Utility;,64;-1;-1;-1;-1,219;17;17;17;17,m;m,usa,usa,y,
5234,ICLR,2020,On Global Feature Pooling for Fine-grained Visual Categorization,Pei Guo;Connor Anderson;Ryan Farrell,peiguo@cs.byu.edu;thecatalystak@gmail.com;farrell@cs.byu.edu,6;3;1,,Withdrawn,2,0,,yes,9/25/19,The Hong Kong Polytechnic University;;The Hong Kong Polytechnic University,global pooling;fine-grained recognition;benchmark;,118;-1;118,171;-1;171,m;m,asia,hk,n,1
5235,ICLR,2020,Quantifying Exposure Bias for Neural Language Generation,Tianxing He;Jingzhao Zhang;Zhiming Zhou;James Glass,cloudygoose@csail.mit.edu;jzhzhang@mit.edu;heyohai@apex.sjtu.edu.cn;glass@mit.edu,3;3;3,,Withdrawn,0,6,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Shanghai Jiao Tong University;Massachusetts Institute of Technology,language model;exposure bias;language generation;,5;5;30;5,5;5;157;5,m;m,usa,usa,n,3
5236,ICLR,2020,Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for Neural Language Generation Models,Tianxing He;Jun Liu;Kyunghyun Cho;Myle Ott;Bing Liu;James Glass;Fuchun Peng,tianxing@mit.edu;junliu@fb.com;kyunghyuncho@fb.com;myleott@fb.com;bingl@fb.com;glass@mit.edu;fuchunpeng@fb.com,3;3;6,,Withdrawn,0,3,,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook;Facebook;Massachusetts Institute of Technology;Facebook,language generation;forgetting;pretraining;open-domain dialogue;,5;-1;-1;-1;-1;5;-1,5;-1;-1;-1;-1;5;-1,m;m,NAN,NAN,n,8
5237,ICLR,2020,INVOCMAP: MAPPING METHOD NAMES TO METHOD INVOCATIONS VIA MACHINE LEARNING,Hung Phan;Ali Jannesari,hungphd@iastate.edu;jannesar@iastate.edu,1;1;1,,Withdrawn,0,4,,yes,9/25/19,Iowa State University;Iowa State University,Statistical Machine Translation;Method Invocation;Auto Code Completion;Software Engineering;,194;194,399;399,m;m,usa,usa,n,3;1
5238,ICLR,2020,Fix-Net: pure fixed-point representation of deep neural networks,Lukas Enderich;Fabian Timm;Lars Rosenbaum;Wolfram Burgard,lukas.enderich@de.bosch.com;fabian.timm@de.bosch.com;lars.rosenbaum@de.bosch.com;burgard@informatik.uni-freiburg.de,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Bosch;Bosch;Bosch;Universit√§t Freiburg,Deep neural networks;fixed-point quantization;bit-shift;soft quantization;,-1;-1;-1;-1,297;297;297;-1,m;m,NAN,NAN,n,
5239,ICLR,2020,Random Partition Relaxation for Training Binary and Ternary Weight Neural Network,Lukas Cavigelli;Luca Benini,cavigelli@iis.ee.ethz.ch;benini@iis.ee.ethz.ch,1;3;1;3,,Withdrawn,0,1,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,binary weight neural networks;ternary weight neural networks;quantization;quantized neural networks;,-1;-1,-1;-1,m;m,NAN,NAN,n,
5240,ICLR,2020,Emergent Communication in Networked Multi-Agent Reinforcement Learning,Shubham Gupta;Rishi Hazra;Amebdkar Dukkipati,shubhamg@iisc.ac.in;rishihazra@iisc.ac.in;ambedkar@iisc.ac.in,3;1;3,,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;Indian Institute of Science,emergent communication;multi-agent reinforcement learning;,-1;-1;-1,301;301;301,m;m,NAN,NAN,n,
5241,ICLR,2020,Recognizing Plans by Learning Embeddings from Observed Action Distributions,Yantian Zha;Yikang Li;Sriram Gopalakrishnan;Hankz Hankui Zhuo;Baoxin Li;Subbarao Kambhampati,yantian.zha@asu.edu;yikangli@asu.edu;sgopal28@asu.edu;zhuohank@mail.sysu.edu.cn;baoxin.li@asu.edu;rao@asu.edu,1;3;1;3,,Withdrawn,0,5,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,action representation learning;plan recognition;shallow model planning;,-1;-1;-1;-1;-1;-1,299;299;299;299;299;299,m;m,NAN,NAN,n,
5242,ICLR,2020,Cancer homogeneity in single cell revealed by Bi-state model and Binary matrix factorization,Changlin Wan;Wennan Chang;Sha Cao;Xiao Wang;Chi Zhang,wan82@purdue.edu;chang534@purdue.edu;shacao@iu.edu;wangxiao@purdue.edu;czhang87@iu.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,"Purdue University;Purdue University;Indiana University, Bloomington;Purdue University;Indiana University, Bloomington",Boolean Matrix factorization;single cell analysis;computational biology;cancer research;,24;24;64;24;64,88;88;134;88;134,m;m,NAN,NAN,n,
5243,ICLR,2020,Residual EBMs: Does Real vs. Fake Text Discrimination Generalize?,Anton Bakhtin;Sam Gross;Myle Ott;Yuntian Deng;Marc'Aurelio Ranzato;Arthur Szlam,yolo@fb.com;sgross@fb.com;myleott@fb.com;dengyuntian@g.harvard.edu;ranzato@fb.com;aszlam@fb.com,1;3;3;1,,Withdrawn,0,0,,yes,9/25/19,Facebook;Facebook;Facebook;Harvard University;Facebook;Facebook,energy-based models;real fake discrimination;text modeling;,-1;-1;-1;52;-1;-1,-1;-1;-1;7;-1;-1,m;m,NAN,NAN,n,3;1
5244,ICLR,2020,EnsembleNet: A novel architecture for Incremental Learning,Suri Bhasker Sri Harsha;Y Kalidas,cs18s506@iittp.ac.in;ykalidas@iittp.ac.in,1;1;1,,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Technology Tirupati;Indian Institute of Technology Tirupati,,-1;-1,-1;-1,f;m,NAN,NAN,n,
5245,ICLR,2020,Dual Sequential Monte Carlo: Tunneling Filtering and Planning in Continuous POMDPs,Yunbo Wang;Bo Liu;Jiajun Wu;Yuke Zhu;Simon Shaolei Du;Li Fei-Fei;Joshua B. Tenenbaum,yunbo.thu@gmail.com;bliu@cs.utexas.edu;jiajunw@stanford.edu;yukez@cs.stanford.edu;ssdu@ias.edu;feifeili@cs.stanford.edu;jbt@mit.edu,1;3;3,,Withdrawn,0,4,,yes,9/25/19,"Shanghai Jiao Tong University;University of Texas, Austin;Stanford University;Stanford University;Institue for Advanced Study, Princeton;Stanford University;Massachusetts Institute of Technology",,30;-1;5;5;-1;5;5,157;-1;4;4;-1;4;5,m;m,usa,usa,y,4
5246,ICLR,2020,Fast Bilinear Matrix Normalization via  Rank-1 Update,Tan Yu;Yunfeng Cai;Ping Li,tanyu01@baidu.com;caiyunfeng@baidu.com;liping11@baidu.com,6;3;1,,Withdrawn,0,7,,yes,9/25/19,Baidu;Baidu;Baidu,Computer Vision;Bilinear Pooling;Efficient Network;Fine-grained Classification;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,2
5247,ICLR,2020,Task-Mediated Representation Learning,Sergei Bugrov;Ron Sun,bugros@rpi.edu;rsun@rpi.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute,,248;248,438;438,m;m,usa,usa,n,5
5248,ICLR,2020,Universality Theorems for Generative Models,Valentin Khrulkov;Ivan Oseledets,khrulkov.v@gmail.com;i.oseledets@skoltech.ru,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Yandex;Skolkovo Institute of Science and Technology,generative models;theory;universality;manifolds;differential geometry;,-1;-1,-1;-1,m;m,europe,russia,y,1;5
5249,ICLR,2020,Embodied Language Grounding with Implicit 3D Visual Feature Representations,Mihir Prabhudesai;Hsiao-Yu Fish Tung;Syed Ashar Javed;Maximilian Sieb;Adam W. Harley;Katerina Fragkiadaki,mprabhud@cs.cmu.edu;htung@cs.cmu.edu;sajaved@andrew.cmu.edu;aharley@cs.cmu.edu;katef@cs.cmu.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1;1,27;27;27;27;27,m;f,usa,usa,n,2;3
5250,ICLR,2020,Geometry-Aware Visual Predictive Models of Intuitive Physics,Hsiao-Yu Fish Tung;Zhou Xian;Mihir Prabhudesai;Katerina Fragkiadaki,htung@cs.cmu.edu;zhouxian@cmu.edu;mprabhud@cs.cmu.edu;katef@cs.cmu.edu,3;6;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1,27;27;27;27,f;f,usa,usa,n,2
5251,ICLR,2020,PNEN: Pyramid Non-Local Enhanced Networks,Feida Zhu;Chaowei Fang;Kai-Kuang Ma,feida.zhu@ntu.edu.sg;chwfang@connect.hku.hk;ekkma@ntu.edu.sg,1;1;6,,Withdrawn,0,0,,yes,9/25/19,Nanyang Technological University;The University of Hong Kong;Nanyang Technological University,,43;92;43,49;35;49,m;m,asia,sg,n,
5252,ICLR,2020,"Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks",Agustinus Kristiadi;Matthias Hein;Philipp Hennig,agustinus.kristiadi@uni-tuebingen.de;matthias.hein@uni-tuebingen.de;philipp.hennig@uni-tuebingen.de,1;1;3,,Withdrawn,0,1,,yes,9/25/19,University of Tuebingen;University of Tuebingen;University of Tuebingen,uncertainty quantification;overconfidence;Bayesian inference;,143;143;143,91;91;91,m;m,europe,de,y,11
5253,ICLR,2020,Auto Network Compression with Cross-Validation Gradient,Nannan Tian;Yong Liu,tiannannan@iie.ac.cn;liuyong@iie.ac.cn,1;3;1,,Withdrawn,0,1,,yes,9/25/19,"Institute of information engineering, CAS;Institute of information engineering, CAS",,-1;-1,-1;-1,f;m,NAN,NAN,n,1
5254,ICLR,2020,Feature-based Augmentation for Semi-Supervised Learning,Min-Hye Oh;Byung-Gook Park,listogato3@gmail.com;bgpark@snu.ac.kr,3;1;6,,Withdrawn,0,0,,yes,9/25/19,Seoul National University;Seoul National University,semi-supervised learning;,-1;39,-1;64,m;m,asia,kr,n,1
5255,ICLR,2020,Capsule Networks without Routing Procedures,Zhenhua Chen;Xiwen Li;Chuhua Wang;David Crandall,chen478@iu.edu;xiwenli@wustl.edu;cw234@iu.edu;djcran@indiana.edu,1;3;3,,Withdrawn,6,3,,yes,9/25/19,"Indiana University, Bloomington;Washington University, St. Louis;Indiana University, Bloomington;Indiana University",CapsNets;routing procedures;,64;-1;64;64,134;-1;134;134,m;m,usa,usa,n,4
5256,ICLR,2020,Noisy $\ell^{0}$-Sparse Subspace Clustering on Dimensionality Reduced Data,Yingzhen Yang,superyyzg@gmail.com,3;6;3,,Withdrawn,0,0,,yes,9/25/19,0,Sparse Subspace Clustering (SSC);Noisy L0-SSC;Subspace Detection Property;,,,m,NAN,NAN,y,
5257,ICLR,2020,Side-Tuning: Network Adaptation via Additive Side Networks,Alexander Sax;Jeffrey Zhang;Amir Zamir;Silvio Savarese;Jitendra Malik,sax@berkeley.edu;jozhang@berkeley.edu;zamir@cs.stanford.edu;ssilvio@cs.stanford.edu;malik@eecs.berkeley.edu,3;3;3,,Withdrawn,0,6,,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;Stanford University;University of California Berkeley,sidetuning;finetuning;transfer learning;representation learning;lifelong learning;incremental learning;continual learning;meta-learning;,-1;-1;5;5;-1,13;13;4;4;13,m;m,usa,usa,n,6;3
5258,ICLR,2020,Deep Multivariate Mixture of Gaussians for Object Detection under Occlusion,Yihui He;Jianren Wang,he2@andrew.cmu.edu;jianrenw@andrew.cmu.edu,1;1;6,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,object detection;multivariate mixture of Gaussian;,1;1,27;27,m;m,usa,usa,n,
5259,ICLR,2020,Dynamic Graph Message Passing Networks,Li Zhang;Dan Xu;Anurag Arnab;Philip H.S. Torr,lz@robots.ox.ac.uk;danxu@robots.ox.ac.uk;anurag.arnab@gmail.com;phst@robots.ox.ac.uk,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of Oxford;University of Oxford;Google;University of Oxford,,46;46;-1;46,1;1;-1;1,m;m,europe,uk,n,2;10
5260,ICLR,2020,POLYNOMIAL ACTIVATION FUNCTIONS,Vikas Gottemukkula,vikas11187@gmail.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Zoloz,Activation functions;Deep Learning;,-1,-1,m,NAN,NAN,n,
5261,ICLR,2020,CopyCAT: Taking Control of Neural Policies with Constant Attacks,L√©onard Hussenot;Matthieu Geist;Olivier Pietquin,hussenot@google.com;mfgeist@google.com;pietquin@google.com,1;3;3,,Withdrawn,0,4,,yes,9/25/19,Google;Google;Google,reinforcement learning;adversarial examples;attack;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,4
5262,ICLR,2020,Influence-aware Memory for Deep Reinforcement Learning,Miguel Suau;Elena Congeduti;Rolf A.N. Starre;Aleksander Czechowski;Frans A. Oliehoek,m.suaudecastro@tudelft.nl;e.congeduti@tudelft.nl;a.t.czechowski@tudelft.nl;r.a.n.starre@tudelft.nl;f.a.oliehoek@tudelft.nl,1;3;1,,Withdrawn,1,4,,yes,9/25/19,Delft University of Technology;Delft University of Technology;Delft University of Technology;Delft University of Technology;Delft University of Technology,Deep Reinforcement Learning;POMDP;Influence;Memory;Recurrent Neural Networks;,-1;-1;-1;-1;-1,67;67;67;67;67,m;m,NAN,NAN,n,
5263,ICLR,2020,CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition,Yuge Huang;Yuhan Wang;Ying Tai;Xiaoming Liu;Pengcheng Shen;Shaoxin Li;Jilin Li;Feiyue Huang,huangyg@zju.edu.cn;wang_yuhan@zju.edu.cn;yingtai@tencent.com;liuxm@cse.msu.edu;quantshen@tencent.com;darwinli@tencent.com;jerolinli@tencent.com;garyhuang@tencent.com,3;6;3,,Withdrawn,0,3,,yes,9/25/19,Zhejiang University;Zhejiang University;Tencent AI Lab;Michigan State University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab,CurricularFace;Adaptive Curriculum Learning;Face Recognition;,39;39;-1;102;-1;-1;-1;-1,107;107;-1;84;-1;-1;-1;-1,f;m,NAN,NAN,n,2
5264,ICLR,2020,Compressive Hyperspherical Energy Minimization,Rongmei Lin;Weiyang Liu;Zhen Liu;Chen Feng;Zhiding Yu;James M. Rehg;Li Xiong;Le Song,rongmei.lin@emory.edu;wyliu@gatech.edu;zhen.liu.2@umontreal.ca;cfeng@nyu.edu;zhidingy@nvidia.com;rehg@gatech.edu;lxiong@emory.edu;lsong@cc.gatech.edu,6;3;3;3,,Withdrawn,0,9,,yes,9/25/19,Emory University;Georgia Institute of Technology;University of Montreal;New York University;NVIDIA;Georgia Institute of Technology;Emory University;Georgia Institute of Technology,,194;13;118;22;-1;13;194;13,80;38;85;29;-1;38;80;38,f;m,usa,usa,y,1;4
5265,ICLR,2020,Testing Robustness Against Unforeseen Adversaries,Daniel Kang*;Yi Sun*;Dan Hendrycks;Tom Brown;Jacob Steinhardt,ddkang@stanford.edu;yisun@math.columbia.edu;hendrycks@berkeley.edu;tom@openai.com;jsteinhardt@berkeley.edu,3;3;3,,Withdrawn,1,4,,yes,9/28/20,Stanford University;Columbia University;University of California Berkeley;OpenAI;University of California Berkeley,adversarial examples;adversarial training;adversarial attacks;,5;24;-1;-1;-1,4;16;13;-1;13,m;m,usa,usa,n,4
5266,ICLR,2020,Reasoning-Aware Graph Convolutional Network for Visual Question Answering,Yangyang Cheng;Chun Yuan,chengyang317@gmail.com;yuanc@sz.tsinghua.edu.cn,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",graph convolutional networks;visual reasoning;visual question answering;,4;4,23;23,f;m,NAN,NAN,n,10
5267,ICLR,2020,Text Embedding Bank Module for Detailed Image Paragraph Caption,Zengming Shen;Arjun Gupta;Thomas S. Huang,zshen5@illinois.edu;arjung2@illinois.edu;t-huang1@illinois.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",caption;text embedding;,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,3
5268,ICLR,2020,FNNP: Fast Neural Network Pruning Using Adaptive Batch Normalization,Bailin Li;Bowen Wu;Jiang Su;Guangrun Wang,bl-zorro@163.com;wubw6@mail2.sysu.edu.cn;sujiang@dm-ai.cn;wangguangrun@dm-ai.cn,3;3;1,,Withdrawn,1,5,,yes,9/25/19,163;SUN YAT-SEN UNIVERSITY;DMAI Inc.;DMAI Inc.,,-1;-1;-1;-1,-1;299;-1;-1,m;m,NAN,NAN,n,
5269,ICLR,2020,Boosting Ticket: Towards Practical Pruning for Adversarial Training with Lottery Ticket Hypothesis,Bai Li;Shiqi Wang;Yunhan Jia;Yantao Lu;Zhenyu Zhong;Lawrence Carin;Suman Jana,bai.li@duke.edu;tcwangshiqi@cs.columbia.edu;jack0082010@gmail.com;ylu25@syr.edu;edwardzhong@baidu.com;lcarin@duke.edu;suman@cs.columbia.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Duke University;Columbia University;University of Michigan;Syracuse University;Baidu;Duke University;Columbia University,neural networks;adversarial training;prune;,46;24;7;194;-1;46;24,20;16;21;292;-1;20;16,m;m,usa,usa,n,9;4
5270,ICLR,2020,Stabilizing Neural ODE Networks with Stochasticity,Xuanqing Liu;Tesi Xiao;Si Si;Qin Cao;Sanjiv Kumar;Cho-Jui Hsieh,xqliu@cs.ucla.edu;texiao@ucdavis.edu;sisidaisy@google.com;qincao@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Los Angeles;University of California, Davis;Google;Google;Google;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1,17;55;-1;-1;-1;17,m;m,usa,usa,n,1;4
5271,ICLR,2020,Robustness and/or Redundancy Emerge in Overparametrized Deep Neural Networks,Stephen Casper;Xavier Boix;Vanessa D'Amario;Christopher Rodriguez;Ling Guo;Kasper Vinken;Gabriel Kreiman,scasper@college.harvard.edu;xboix@mit.edu;vanedamario@gmail.com;chrizrodz@gmail.com;kasper.vinken@kuleuven.be;gabriel.kreiman@childrens.harvard.edu,8;1;3,,Withdrawn,0,0,,yes,9/25/19,Harvard University;Massachusetts Institute of Technology;;;KU Leuven;Harvard University,overparametrized dnns;robustness;redundancy;compressibility;generalization;,52;5;-1;-1;143;52,7;5;-1;-1;45;7,m;m,usa,usa,n,
5272,ICLR,2020,Interpretable Deep Neural Network Models: Hybrid of Image Kernels and Neural Networks,Mr. Jay Hoon Jung;and Prof. YoungMin Kwon,jay.jung@stonybrook.edu;youngmin.kwon@sunykorea.ac.kr,1;1;3,,Withdrawn,0,0,,yes,9/25/19,"State University of New York, Stony Brook;Korea University",Interpretability;DNN;Hybrid Networks;,-1;168,-1;179,m;m,asia,kr,y,
5273,ICLR,2020,EnsembleNet: End-to-End Optimization of Multi-headed Models,Hanhan Li;Joe Ng;Apostol (Paul) Natsev,mirror.haha@gmail.com;yhng@google.com;natsev@google.com,3;3;1,,Withdrawn,0,6,,yes,9/25/19,Google;Google;Google,Computer Vision;Deep Learning;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5274,ICLR,2020,PatchVAE: Learning Local Latent Codes for Recognition,Kamal Gupta;Saurabh Singh;Abhinav Shrivastava,kamalgupta308@gmail.com;saurabhsingh@google.com;abhinav@cs.umd.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"University of Maryland, College Park;Google;University of Maryland, College Park",unsupervised learning;deep learning;representation learning;recognition;computer vision;,12;-1;12,91;-1;91,m;m,usa,usa,n,5
5275,ICLR,2020,Improving One-Shot NAS By Suppressing The Posterior Fading,Xiang Li*;Chen Lin*;Chuming Li;Ming Sun;Wei Wu;Junjie Yan;Wanli Ouyang,xiang_li_1@brown.edu;linchen@sensetime.com;lichuming@sensetime.com;sunming1@sensetime.com;wuwei@sensetime.com;yanjunjie@sensetime.com;wanli.ouyang@sydney.edu.au,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Brown University;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;University of Sydney,Computer vision;Image classification;Neural Architecture Search;,85;-1;-1;-1;-1;-1;64,53;-1;-1;-1;-1;-1;60,m;m,europe,uk,n,2;11
5276,ICLR,2020,Min-max Entropy for Weakly Supervised Pointwise Localization,Belharbi Soufiane;Rony J√©r√¥me;Dolz Jose;Ben Ayed Ismail;McCaffrey Luke;Granger Eric,soufiane.belharbi.1@etsmtl.net;jerome.rony.1@etsmtl.net;jose.dolz@etsmtl.ca;ismail.benayed@etsmtl.ca;luke.mccaffrey@mcgill.ca;eric.granger@etsmtl.ca,3;3;1,,Withdrawn,0,0,,yes,9/25/19,√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;McGill University;√âcole de technologie sup√©rieure,weakly supervised pointwise localization;deep learning;interpretability;computer vision;,-1;-1;-1;-1;102;-1,-1;-1;-1;-1;42;-1,m;m,NAN,NAN,n,8
5277,ICLR,2020,Context-Gated Convolution,Xudong Lin;Lin Ma;Wei Liu;Shih-Fu Chang,xudong.lin@columbia.edu;forest.linma@gmail.com;wl2223@columbia.edu;shih.fu.chang@columbia.edu,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Columbia University;;Columbia University;Columbia University,Convolutional Neural Network;Context-Gated Convolution;Global Context Information;,24;-1;24;24,16;-1;16;16,m;m,usa,usa,n,3
5278,ICLR,2020,FAKE CAN BE REAL IN GANS,Song Tao;Jia Wang,taosong@sjtu.edu.cn;jiawang@sjtu.edu.cn,1;3;8,,Withdrawn,0,4,,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,GANs;Mode collapse;Gradient exploding;Stability;,30;30,157;157,m;f,asia,cn,y,1;5;4
5279,ICLR,2020,WHAT ILLNESS OF LANDSCAPE CAN OVER-PARAMETERIZATION ALONE CURE?,Dawei Li;Tian Ding;Ruoyu Sun,dawei2@illinois.edu;dt016@ie.cuhk.edu.hk;ruoyus@illinois.edu,3;3;1,,Withdrawn,0,9,,yes,9/25/19,"University of Illinois, Urbana Champaign;The Chinese University of Hong Kong;University of Illinois, Urbana Champaign",,-1;316;-1,-1;35;-1,m;m,usa,usa,y,1
5280,ICLR,2020,Representational Disentanglement for Multi-Domain Image Completion,Liyue Shen;Wentao Zhu;Xiaosong Wang;Lei Xing;John Pauly;Baris Turkbey;Stephanie Harmon;Thomas Sanford;Sherif Mehralivand;Peter L. Choyke;Bradford J. Wood;Daguang Xu,liyues@stanford.edu;wentaoz@nvidia.com;xiaosongw@nvidia.com;lei@stanford.edu;pauly@stanford.edu;ismail.turkbey@nih.gov;stephanie.harmon@nih.gov;thomas.sanford@nih.gov;sherif.mehralivand@nih.gov;pchoyke@mail.nih.gov;bwood@nih.gov;daguangx@nvidia.com,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Stanford University;NVIDIA;NVIDIA;Stanford University;Stanford University;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;NVIDIA,,5;-1;-1;5;5;-1;-1;-1;-1;-1;-1;-1,4;-1;-1;4;4;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,2;5;4
5281,ICLR,2020,SCL: Towards Accurate Domain Adaptive Object Detection via Gradient Detach Based Stacked Complementary Losses,Zhiqiang Shen;Harsh Maheshwari;Weichen Yao;Marios Savvides,zhiqians@andrew.cmu.edu;harshmaheshwari135@gmail.com;wyao2@andrew.cmu.edu;marioss@andrew.cmu.edu,3;3;3,,Withdrawn,1,5,,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University;Carnegie Mellon University,Domain Adaptation;Object Detection;Gradient Detach;Stacked Complementary Losses;,1;-1;1;1,27;-1;27;27,m;m,usa,usa,n,2
5282,ICLR,2020,Relevant-features based Auxiliary Cells for Robust and Energy Efficient Deep Learning,Aparna Aketi;Priyadarshini Panda;Kaushik Roy,saketi@purdue.edu;priya.panda@yale.edu;kaushik@purdue.edu,1;3;6,,Withdrawn,0,5,,yes,9/25/19,Purdue University;Yale University;Purdue University,Machine learning;deep neural networks;error detection;robust deep learning;energy efficiency;adversarial robustness;out-of-distribution detection;abnormal inputs detection;misclassified samples detection;,24;73;24,88;8;88,f;m,usa,usa,n,
5283,ICLR,2020,Learning to Transfer Learn,Linchao Zhu;Sercan O. Arik;Yi Yang;Tomas Pfister,zhulinchao7@gmail.com;soarik@google.com;yi.yang@uts.edu.au;tpfister@google.com,3;3,,Withdrawn,0,4,,yes,9/25/19,University of Technology Sydney;Google;University of Technology Sydney;Google,transfer learning;adaptive training;,73;-1;73;-1,193;-1;193;-1,u;m,NAN,NAN,n,6
5284,ICLR,2020,Variational lower bounds on mutual information based on nonextensive statistical mechanics,Valeriu Balaban;Yang Zikun;Paul Bogdan,vbalaban@usc.edu;yangzikun@buaa.edu.cn;pbogdan@usc.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Southern California;Beihang University;University of Southern California,mutual information;variational bounds;nonextensive statistical mechanics;,36;102;36,62;594;62,m;m,usa,usa,n,1
5285,ICLR,2020,Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets,Yogesh Balaji;Tom Goldstein;Judy Hoffman,yogesh@cs.umd.edu;tomg@cs.umd.edu;judy@gatech.edu,3;6;3,,Withdrawn,0,5,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;Georgia Institute of Technology",Adversarial training;Improving generalization;robustness-accuracy tradeoff;,12;12;13,91;91;38,m;f,usa,usa,n,1;4
5286,ICLR,2020,Robust Few-Shot Learning with Adversarially Queried Meta-Learners,Micah Goldblum;Liam Fowl;Tom Goldstein,goldblumcello@gmail.com;lhfowl@gmail.com;tomg@cs.umd.edu,3;6;3,,Withdrawn,0,4,,yes,9/25/19,"University of Maryland, College Park;;University of Maryland, College Park",meta-learning;adversarial;robust;few-shot;,-1;-1;12,-1;-1;91,m;m,usa,usa,n,6;4
5287,ICLR,2020,Mixture Density Networks Find Viewpoint the Dominant Factor for Accurate Spatial Offset Regression,Ali Varamesh;Tinne Tuytelaars,ali.varamesh@kuleuven.be;tinne.tuytelaars@esat.kuleuven.be,3;1;3,,Withdrawn,0,3,,yes,9/25/19,KU Leuven;KU Leuven,Mixture Density Estimation;Spatial Offset Regression;Dense Prediction;Human Pose Estimation;,143;143,45;45,m;f,europe,be,n,2
5288,ICLR,2020,Learning Adversarial Grammars for Future Prediction,AJ Piergiovanni;Alexander Toshev;Anelia Angelova;Michael Ryoo,ajpiergi@indiana.edu;toshev@google.com;anelia@google.com;mryoo@google.com,1;1,,Withdrawn,0,2,,yes,9/25/19,Indiana University;Google;Google;Google,future prediction;grammar;,64;-1;-1;-1,134;-1;-1;-1,m;m,NAN,NAN,n,4
5289,ICLR,2020,Dual-Component Deep Domain Adaptation: A New Approach for Cross Project Software Vulnerability Detection,Van Nguyen;Trung Le;Olivier de Vel;Paul Montague;John C Grundy;Dinh Phung,van.nk@monash.edu;trunglm@monash.edu;olivier.devel@dst.defence.gov.au;paul.montague@dst.defence.gov.au;john.grundy@monash.edu;dinh.phung@monash.edu,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Monash University;Monash University;Defence Science and Technology Group;Defence Science and Technology Group;Monash University;Monash University,Domain adaptation;Cyber security;Software vulnerability detection;Machine learning;Deep learning;,92;92;-1;-1;92;92,75;75;-1;-1;75;75,f;m,australasia,au,n,6;5;4
5290,ICLR,2020,FAN: Focused Attention Networks,Chu Wang;Babak Samari;Vladimir Kim;Siddhartha Chaudhuri;Kaleem Siddiqi,chuwang@cim.mcgill.ca;babak@cim.mcgill.ca;vokim@adobe.com;sidch@adobe.com;siddiqi@cim.mcgill.ca,3;3;3,,Withdrawn,0,8,,yes,9/25/19,McGill University;McGill University;Adobe Systems;Adobe Systems;McGill University,Deep Learning;Attention Mechanism;Loss Functions;Computer Vision;Natural Language Processing;,102;102;-1;-1;102,42;42;-1;-1;42,m;m,canada,ca,n,8
5291,ICLR,2020,State2vec: Off-Policy Successor Feature Approximators,Sephora Madjiheurem;Laura Toni,sephora.madjiheurem.17@ucl.ac.uk;l.toni@ucl.ac.uk,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University College London;University College London,reinforcement learning;meta learning;transfer learning;value function approximation;,52;52,-1;-1,f;f,europe,uk,n,10
5292,ICLR,2020,Semi-supervised Autoencoding Projective Dependency Parsing,Xiao Zhang;Dan Goldwasser,zhang923@purdue.edu;dgoldwas@purdue.edu,1;3;6,,Withdrawn,0,0,,yes,9/25/19,Purdue University;Purdue University,Dependency Parsing;Semi-supervised Learning;Tractable Inference;Evidence Lowerbound;,24;24,88;88,m;m,usa,usa,n,10;5
5293,ICLR,2020,Progressive Knowledge Distillation For Generative Modeling,Yu-Xiong Wang;Adrien Bardes;Ruslan Salakhutdinov;Martial Hebert,yuxiongw@cs.cmu.edu;adrien.bardes@dbmail.com;rsalakhu@cs.cmu.edu;hebert@ri.cmu.edu,3;3;6,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Dbmail;Carnegie Mellon University;Carnegie Mellon University,knowledge distillation;generative modeling;deep learning;,1;-1;1;1,27;-1;27;27,m;m,usa,usa,n,6;5
5294,ICLR,2020,Lyceum: An efficient and scalable ecosystem for robot learning,Colin X. Summers;Kendall Lowrey;Aravind Rajeswaran;Emanuel Todorov;Siddhartha Srinivasa,colinxs@cs.washington.edu;klowrey@cs.washington.edu;todorov@cs.washington.edu;siddh@cs.washington.edu;aravraj@cs.washington.edu,1;6;3,,Withdrawn,0,1,,yes,9/25/19,University of Washington;University of Washington;University of Washington;University of Washington;University of Washington,Robotics;RL;Julia;,11;11;11;11;11,26;26;26;26;26,m;m,usa,usa,n,
5295,ICLR,2020,Adversarial Attribute Learning by  Exploiting negative correlated attributes,Satoshi Tsutsui;Yanwei Fu;David Crandall,stsutsui@indiana.edu;yanweifu@fudan.edu.cn;djcran@indiana.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Indiana University;Fudan University;Indiana University,,64;73;64,134;109;134,m;m,usa,usa,n,4
5296,ICLR,2020,VISUALIZING POINT CLOUD CLASSIFIERS BY MORPHING POINT CLOUDS INTO POTATOES,Ziwen Chen;Wenxuan Wu;Zhongang Qi;Fuxin Li,chenziwe@grinnell.edu;wuwen@oregonstate.edu;qiz@oregonstate.edu;lif@oregonstate.edu,3;3;3;6,,Withdrawn,0,4,,yes,9/25/19,Grinnell College;Oregon State University;Oregon State University;Oregon State University,point cloud;3D computer vision;visualization;,-1;79;79;79,-1;373;373;373,f;m,usa,usa,n,
5297,ICLR,2020,Learning Multi-Agent Communication Through Structured Attentive Reasoning,Murtaza Rangwala;Ryan Williams,murtazar@vt.edu;rywilli1@vt.edu,3;1;1,,Withdrawn,0,3,,yes,9/25/19,Virginia Tech;Virginia Tech,Multi-Agent;Deep Reinforcement Learning;Communication;,64;64,-1;-1,m;m,usa,usa,n,8
5298,ICLR,2020,The Power of  Semantic Similarity based Soft-Labeling for Generalized Zero-Shot Learning,Shabnam Daghaghi;Tharun Medini;Anshumali Shrivastava,shabnam.daghaghi@rice.edu;tharun.medini@rice.edu;anshumali@rice.edu,6;1;3;3;3,,Withdrawn,0,5,,yes,9/25/19,Rice University;Rice University;Rice University,Zero Shot Learning;,92;92;92,105;105;105,f;m,australasia,au,n,6
5299,ICLR,2020,Spline Templated Based Handwriting Generation,Daniel Clothiaux;Ravi Starzl,dclothia@andrew.cmu.edu;rstarzl@cs.cmu.edu,6;3;1,,Withdrawn,0,3,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,,1;1,27;27,m;m,usa,usa,n,
5300,ICLR,2020,Improving the robustness of ImageNet classifiers using elements of human visual cognition,Emin Orhan;Brenden Lake,aeminorhan@gmail.com;brenden@nyu.edu,3;1;3,,Withdrawn,0,3,,yes,9/25/19,New York University;New York University,human vision;robustness;large-scale image recognition;,22;22,29;29,m;m,usa,usa,n,4
5301,ICLR,2020,Going Deeper with Lean Point Networks,Eric-Tuan Le;Iasonas Kokkinos;Niloy J. Mitra,eric-tuan.le.18@ucl.ac.uk;i.kokkinos@cs.ucl.ac.uk;n.mitra@cs.ucl.ac.uk,1;6;3,,Withdrawn,0,3,,yes,9/25/19,University College London;University College London;University College London,point cloud processing;point convolutions;memory-efficient training;deep neural network design;,52;52;52,-1;-1;-1,m;m,europe,uk,n,2
5302,ICLR,2020,Newton Residual Learning,Grigorios Chrysos;Jiankang Deng;Yannis Panagakis;Stefanos Zafeiriou,g.chrysos@imperial.ac.uk;j.deng16@imperial.ac.uk;i.panagakis@imperial.ac.uk;s.zafeiriou@imperial.ac.uk,8;1;3,,Withdrawn,1,1,,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,Residual learning;Resnet;Newton;,52;52;52;52,10;10;10;10,m;m,europe,uk,n,2
5303,ICLR,2020,Training-Free Uncertainty Estimation for Neural Networks,Lu Mi;Hao Wang;Yonglong Tian;Nir Shavit,lumi@mit.edu;hoguewang@gmail.com;yonglong@mit.edu;shanir@csail.mit.edu,1;6;6;1,,Withdrawn,0,5,,yes,9/25/19,Massachusetts Institute of Technology;Rutgers University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,uncertainty estimation;training-free;neural network;,5;30;5;5,5;-1;5;5,m;m,usa,usa,n,2;11
5304,ICLR,2020,AMUSED: A Multi-Stream Vector Representation Method for Use In Natural Dialogue,Gaurav Kumar;Rishabh Joshi;Jaspreet Singh;Promod Yenigalla,gaurav.k1@samsung.com;rjoshi2@andrew.cmu.edu;jaspreet.ahluwalia@stonybrook.edu;promod.y@samsung.com,6;1;3,,Withdrawn,0,3,,yes,9/25/19,"Samsung;Carnegie Mellon University;State University of New York, Stony Brook;Samsung",Natural Language Processing;Dialogue Systems;Learning Embeddings;Knowledge Graphs;Memory Networks;Graph Convolution Networks;,-1;1;-1;-1,-1;27;-1;-1,m;m,NAN,NAN,n,6;8;10
5305,ICLR,2020,PAD-Nets: Learning Dynamic Receptive Fields via Pixel-Wise Adaptive Dilation,Dongdong Wang;Hao Hu;Jie Yao;Zihang Zou;Liqiang Wang,daniel.wang@knights.ucf.edu;hhu@fxpal.com;17112098@bjtu.edu.cn;zzz@knights.ucf.edu;lwang@cs.ucf.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Central Florida;FX Palo Alto Laboratory;Beijing Jiaotong University;University of Central Florida;University of Central Florida,receptive field;dilated CNN;representation learning;,73;-1;-1;73;73,609;-1;952;609;609,m;m,usa,usa,n,
5306,ICLR,2020,Posterior Sampling: Make Reinforcement Learning Sample Efficient Again,Calvin Seward;Urs Bergmann;Roland Vollgraf;Sepp Hochreiter,seward@bioinf.jku.at;urs.bergmann@zalando.de;roland.vollgraf@zalando.de;hochreit@bioinf.jku.at,3;3;6;1,,Withdrawn,0,4,,yes,9/25/19,Johannes Kepler University Linz;Zalando SE;Zalando SE;Johannes Kepler University Linz,Model Based Reinforcement Learning;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,11
5307,ICLR,2020,Unifying Part Detection And Association For Multi-person Pose Estimation,Rania Briq;Andreas Doering;Juergen Gall,briq@iai.uni-bonn.de;doering@iai.uni-bonn.de;gall@iai.uni-bonn.de,3;6;3,,Withdrawn,0,0,,yes,9/25/19,University of Bonn;University of Bonn;University of Bonn,,143;143;143,106;106;106,f;m,europe,uk,n,2
5308,ICLR,2020,Slow Thinking Enables Task-Uncertain Lifelong and Sequential Few-Shot Learning,Rosalie Dolor;Hsin-Chi Chu;Shan-Hung Wu,rosalie@ghtinc.com;hcchu@datalab.cs.nthu.edu.tw;shwu@cs.nthu.edu.tw,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Ghtinc;National Tsing Hua University;National Tsing Hua University,lifelong learning;few-shot learning;memory-augmented models;runtime adaptation;,-1;194;194,-1;365;365,u;m,asia,tw,n,6
5309,ICLR,2020,How Aggressive Can Adversarial Attacks Be: Learning Ordered Top-k Attacks,Zekun Zhang;Tianfu Wu,zzhang56@ncsu.edu;tianfu_wu@ncsu.edu,3;3;1,,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Adversarial Attack;Adversarial Distillation;Ordered Top-k Attack;,-1;-1,299;299,m;m,NAN,NAN,n,4
5310,ICLR,2020,PolyGAN: High-Order Polynomial Generators,Grigorios Chrysos;Stylianos Moschoglou;Yannis Panagakis;Stefanos Zafeiriou,g.chrysos@imperial.ac.uk;s.moschoglou@imperial.ac.uk;i.panagakis@imperial.ac.uk;s.zafeiriou@imperial.ac.uk,1;3;1;1,,Withdrawn,0,1,,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,tensor decomposition;Generative Adversarial Networks;polynomial expansion;function approximation;,52;52;52;52,10;10;10;10,m;m,europe,uk,y,8;5;4
5311,ICLR,2020,Generative Multi Source Domain Adaptation,Subhankar Roy;Aliaksandr Siarohin;Enver Sangineto;Moin Nabi;Tassilo Klein;Nicu Sebe;Elisa Ricci,subhankar.roy@unitn.it;aliaksandr.siarohin@unitn.it;enver.sangineto@unitn.it;m.nabi@sap.com;tassilo.klein@sap.com;niculae.sebe@unitn.it;eliricci@fbk.eu,3;3;1,,Withdrawn,0,5,,yes,9/25/19,University of Trento;University of Trento;University of Trento;SAP;SAP;University of Trento;Fondazione Bruno Kessler,Domain Adaptation;Generative Adversarial Networks;,143;143;143;316;316;143;-1,307;307;307;258;258;307;-1,m;f,NAN,NAN,n,5;4
5312,ICLR,2020,Semi-Supervised Named Entity Recognition with CRF-VAEs,Thomas Effland;Michael Collins,teffland@cs.columbia.edu;mcollins@cs.columbia.edu;mc3354@columbia.edu,3;3;1,,Withdrawn,1,3,,yes,9/25/19,Columbia University;Columbia University;Columbia University,vae;ner;tagging;crf;nlp;semi-supervised learning;,24;24;24,16;16;16,m;m,usa,usa,n,5
5313,ICLR,2020,Understanding the (Un)interpretability of Natural Image Distributions Using Generative Models,Ryen Krusinga;Sohil Shah;Matthias Zwicker;Tom Goldstein;David Jacobs,krusinga@cs.umd.edu;sohilas@umd.edu;zwicker@inf.unibe.ch;tom@cs.umd.edu;djacobs@umiacs.umd.edu,1;3;3,,Withdrawn,1,0,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Bern;University of Maryland, College Park;University of Maryland, College Park",GANs;Generative Models;Density Estimation;,12;12;316;12;12,91;91;113;91;91,m;m,usa,usa,n,5
5314,ICLR,2020,Depth-Recurrent Residual Connections for Super-Resolution of Real-Time Renderings,Erik Franz;Mengyu Chu;R√ºdiger Westermann;Nils Thuerey,franzer@in.tum.de;mengyu.chu@tum.de;westermann@tum.de;nils.thuerey@tum.de,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich,temporal coherence;anti-aliasing;super-resolution;GAN;RNN;real-time rendering;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
5315,ICLR,2020,The Blessing of Dimensionality: An Empirical Study of Generalization,W. Ronny Huang;Zeyad Emam;Micah Goldblum;Liam Fowl;Justin K. Terry;Furong Huang;Tom Goldstein,wrhuang@umd.edu;zeyad@math.umd.edu;goldblum@math.umd.edu;lfowl@math.umd.edu;jkterry@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",deep neural networks;convolutional neural networks;generalization;visualization;loss landscape;optimization;,12;12;12;12;12;12;12,91;91;91;91;91;91;91,m;m,usa,usa,n,1
5316,ICLR,2020,Strong Baseline Defenses Against Clean-Label Poisoning Attacks,Neal Gupta;W. Ronny Huang;Liam Fowl;Chen Zhu;Soheil Feizi;Tom Goldstein;John Dickerson,ngupta@cs.umd.edu;wronnyhuang@gmail.com;lhfowl@gmail.com;chenzhu@cs.umd.edu;sfeizi@cs.umd.edu;tomg@cs.umd.edu;john@cs.umd.edu,3;3;1,,Withdrawn,0,3,,yes,9/25/19,"University of Maryland, College Park;Google;;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",poisoning;defenses;robustness;adversarial;ML security;ML safety;,12;-1;-1;12;12;12;12,91;-1;-1;91;91;91;91,m;m,usa,usa,n,4
5317,ICLR,2020,MetaPoison:   Learning to craft adversarial poisoning examples via meta-learning,W. Ronny Huang;Jonas Geiping;Liam Fowl;Gavin Taylor;Tom Goldstein,wronnyhuang@gmail.com;jonas.geiping@uni-siegen.de;lfowl@math.umd.edu;taylor@usna.edu;tomg@cs.umd.edu,3;3;1,,Withdrawn,0,3,,yes,9/25/19,"Google;University of Siegen;University of Maryland, College Park;University of Arizona;University of Maryland, College Park",Adversarial Examples;Poisoning;Backdoor Attacks;Deep Learning;,-1;316;12;194;12,-1;570;91;103;91,m;m,usa,usa,n,6;4
5318,ICLR,2020,Domain-Relevant Embeddings for Question Similarity,Clara McCreery;Namit Katariya;Anitha Kannan;Manish Chablani;Xavier Amatriain,mccreery@stanford.edu;namit@curai.com;anitha@curai.com;manish@curai.com;xavier@curai.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Stanford University;Curai;Curai;Curai;Curai,Question Similarity;Medical Domain;Transfer Learning;Question Entailment;,5;-1;-1;-1;-1,4;-1;-1;-1;-1,f;m,NAN,NAN,n,
5319,ICLR,2020,Divide-and-Conquer Adversarial Learning for High-Resolution Image Enhancement,Zhiwu Huang;Danda Pani Paudel;Guanju Li;Jiqing Wu;Radu Timofte;Luc Van Gool,zhiwu.huang@vision.ee.ethz.ch;paudel@vision.ee.ethz.ch;ligua@student.ethz.ch;jwu@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,divide-and-conquer;adversarial learning;image enhancement;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
5320,ICLR,2020,Learning Out-of-distribution Detection without Out-of-distribution Data,Yen-Chang Hsu;Yilin Shen;Hongxia Jin;Zsolt Kira,yenchang.hsu@gatech.edu;yilin.shen@samsung.com;hongxia.jin@samsung.com;zkira@gatech.edu,3;3;1,,Withdrawn,3,1,,yes,9/25/19,Georgia Institute of Technology;Samsung;Samsung;Georgia Institute of Technology,out-of-distribution;deep learning;neural networks;,13;-1;-1;13,38;-1;-1;38,m;m,usa,usa,n,
5321,ICLR,2020,Domain Adaptation Through Label Propagation: Learning Clustered and Aligned Features,Changhwa Park;Jaeyoon Yoo;Youngjun Hong;Sungroh Yoon,omega6464@snu.ac.kr;yjy765@snu.ac.kr;youngjun.hong@enerzai.com;sryoon@snu.ac.kr,3;3;3,,Withdrawn,1,10,,yes,9/25/19,Seoul National University;Seoul National University;Enerzai;Seoul National University,domain adaptation;label propagation;manifold regularization;computer vision;,39;39;-1;39,64;64;-1;64,m;m,asia,kr,y,1
5322,ICLR,2020,ManiGAN: Text-Guided Image Manipulation,Bowen Li;Xiaojuan Qi;Thomas Lukasiewicz;Philip H. S. Torr,bowen.li@cs.ox.ac.uk;xiaojuan.qi@eng.ox.ac.uk;thomas.lukasiewicz@cs.ox.ac.uk;philip.torr@eng.ox.ac.uk,1;6;6,,Withdrawn,0,3,,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Image Manipulation;Natural Language;Generative Adversarial Networks;,46;46;46;46,1;1;1;1,m;m,europe,uk,n,8;3;5;4
5323,ICLR,2020,Empirical observations pertaining to learned priors for deep latent variable models,Rogan Morrow;Wei-Chen Chiu,rogan.o.morrow@gmail.com;walon@cs.nctu.edu.tw,3;1;3,,Withdrawn,0,4,,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,,118;118,564;564,m;m,asia,tw,n,2;5;4
5324,ICLR,2020,Variational inference of latent hierarchical dynamical systems in neuroscience: an application to calcium imaging data,Luke Y. Prince;Blake A. Richards,luke.prince@utoronto.ca;blake.richards@mcgill.ca,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Toronto University;McGill University,variational autoencoders;neuroscience;dynamic systems;hierarchical;generative model;calcium imaging;,-1;102,-1;42,m;m,canada,ca,n,5
5325,ICLR,2020,Characterizing convolutional neural networks with one-pixel signature,Shanjiaoyang Huang;Weiqi Peng;Zhuowen Tu,shh236@ucsd.edu;wep012@ucsd.edu;ztu@ucsd.edu,3;3;3,,Withdrawn,0,3,,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego",Neural Network characterization;backdoor detection;one-pixel signature;,-1;-1;-1,31;31;31,m;m,usa,usa,n,4
5326,ICLR,2020,Increasing batch size through instance repetition improves generalization,Elad Hoffer;Tal Ben-Nun;Itay Hubara;Niv Giladi;Torsten Hoefler;Daniel Soudry,elad.hoffer@gmail.com;talbn@inf.ethz.ch;itayhubara@gmail.com;giladiniv@campus.technion.ac.il;htor@inf.ethz.ch;daniel.soudry@gmail.com,3;3;6,,Withdrawn,2,3,,yes,9/25/19,"Habana Labs (Intel);Swiss Federal Institute of Technology;;Technion, Technion;Swiss Federal Institute of Technology;Technion, Technion",,-1;-1;-1;27;-1;27,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
5327,ICLR,2020,"Mix & Match: training convnets with mixed image sizes for improved accuracy, speed and scale resiliency",Elad Hoffer;Berry Weinstein;Itay Hubara;Tal Ben-Nun;Torsten Hoefler;Daniel Soudry,elad.hoffer@gmail.com;bweinstein@habana.ai;itayhubara@gmail.com;talbn@inf.ethz.ch;htor@inf.ethz.ch;daniel.soudry@gmail.com,6;3;3,,Withdrawn,0,3,,yes,9/25/19,"Habana Labs (Intel);Habana Labs (Intel);;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Technion, Technion",convolutional networks;deep learning;,-1;-1;-1;-1;-1;27,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5328,ICLR,2020,Revisit Knowledge Distillation: a Teacher-free Framework,Li Yuan;Francis EH Tay;Guilin Li;Tao Wang;Jiashi Feng,ylustcnus@gmail.com;mpetayeh@nus.edu.sg;liguilin2@huawei.com;twangnh@gmail.com;elefjia@nus.edu.sg,6;3;3,,Withdrawn,0,5,,yes,9/25/19,National University of Singapore;National University of Singapore;Huawei Technologies Ltd.;;National University of Singapore,Knowledge Distillation;Label Smoothing Regularization;,17;17;-1;-1;17,25;25;-1;-1;25,m;m,asia,sg,n,1
5329,ICLR,2020,On learning visual odometry errors,Andrea De Maio;Simon Lacroix,andrea.de-maio@laas.fr;simon.lacroix@laas.fr,1;3;3,,Withdrawn,0,4,,yes,9/25/19,LAAS / CNRS;LAAS / CNRS,visual odometry;deep learning in robotics;uncertainty estimation in computer vision;,-1;-1,-1;-1,f;m,NAN,NAN,n,
5330,ICLR,2020,Mitigating Posterior Collapse in Strongly Conditioned Variational Autoencoders,Mohammad Sadegh Aliakbarian;Fatemeh Sadat Saleh;Mathieu Salzmann;Lars Petersson;Stephen Gould,sadegh.aliakbarian@anu.edu.au;fatemehsadat.saleh@anu.edu.au;mathieu.salzmann@epfl.ch;lars.petersson@data61.csiro.au;stephen.gould@anu.edu.au,3;1;1,,Withdrawn,0,4,,yes,9/25/19,Australian National University;Australian National University;Swiss Federal Institute of Technology Lausanne;CSIRO;Australian National University,conditional variational autoencoder;posterior collapse;generative models;,102;102;-1;-1;102,50;50;-1;-1;50,m;m,australasia,au,n,5
5331,ICLR,2020,Unsupervised  Video-to-Video Translation via Self-Supervised Learning,Kangning Liu;Shuhang Gu;Radu Timofte,kl3141@nyu.edu;shuhang.gu@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch,3;3;3,,Withdrawn,0,4,,yes,9/25/19,New York University;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Self-supervised learning;Unsupervised video-to-video translation;,22;-1;-1,29;-1;-1,m;m,NAN,NAN,n,
5332,ICLR,2020,ROBUST SINGLE-STEP ADVERSARIAL TRAINING,B.S. Vivek;R. Venkatesh Babu,svivek@iisc.ac.in;venky@iisc.ac.in,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science,Adversarial Defense;robust deep neural networks;,-1;-1,301;301,m;m,NAN,NAN,n,2;4
5333,ICLR,2020,Attentive Weights Generation for Few Shot Learning via Information Maximization,Yiluan Guo;Ngai-Man Cheung,guoyl1990@outlook.com;ngaiman_cheung@sutd.edu.sg,1;6;6,,Withdrawn,0,5,,yes,9/25/19,Singapore University of Technology and Design;Singapore University of Technology and Design,few shot learning;meta learning;information maximization;image classification;,-1;-1,-1;-1,m;m,NAN,NAN,n,6;1
5334,ICLR,2020,DropGrad: Gradient Dropout Regularization for Meta-Learning,Hung-Yu Tseng;Yi-Wen Chen;Yi-Hsuan Tsai;Sifei Liu;Yen-Yu Lin;Ming-Hsuan Yang,htseng6@ucmerced.edu;ychen319@ucmerced.edu;wasidennis@gmail.com;sifeil@nvidia.com;lin@cs.nctu.edu.tw;mhyang@ucmerced.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,University of California at Merced;University of California at Merced;NEC-Labs;NVIDIA;National Chiao Tung University;University of California at Merced,,-1;-1;-1;-1;118;-1,-1;-1;-1;-1;564;-1,m;m,usa,usa,n,6;8;1
5335,ICLR,2020,Hierarchical Image-to-image Translation with Nested Distributions Modeling,Shishi Qiao;Ruiping Wang;Shiguang Shan;Xilin Chen,qiaoshishi14@mails.ucas.ac.cn;wangruiping@ict.ac.cn;sgshan@ict.ac.cn;xlchen@ict.ac.cn,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",,30;30;30;30,-1;-1;-1;-1,m;m,NAN,NAN,n,
5336,ICLR,2020,Deep Neural Forests: An Architecture for Tabular Data,Ami Abutbul;Gal Elidan;Liran Katzir;Ran El-Yaniv,amramabutbul@cs.technion.ac.il;elidan@google.com;lirank@google.com;elyaniv@google.com,3;3;3;3,,Withdrawn,0,4,,yes,9/25/19,"Technion, Technion;Google;Google;Google",neural architectures;tabular data;multi-modal data;decision trees;gradient boosting;,27;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,10
5337,ICLR,2020,Is my Deep Learning Model Learning more than I want it to?,Naveen Panwar;Tarun Tater;Anush Sankaran;Senthil Mani,naveen.panwar@in.ibm.com;anussank@in.ibm.com;taruntater3@gmail.com;sentmani@in.ibm.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,International Business Machines;International Business Machines;;International Business Machines,model trust;disentangled representation;colored mnist;face attribute preservation;new dataset;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
5338,ICLR,2020,Mixing Up Real Samples and Adversarial Samples for Semi-Supervised Learning,Yun Ma;Xudong Mao;Yangbin Chen;Qing Li,mayun371@gmail.com;xudong.xdmao@gmail.com;robinchen2-c@my.cityu.edu.hk;qing-prof.li@polyu.edu.hk,1;3;1,,Withdrawn,0,1,,yes,9/25/19,The Hong Kong Polytechnic University;Xiamen University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,,-1;-1;118;118,-1;579;171;171,m;m,asia,hk,n,4
5339,ICLR,2020,ADASAMPLE: ADAPTIVE SAMPLING OF HARD POSITIVES FOR DESCRIPTOR LEARNING,Xin-Yu Zhang;Jia-Wang Bian;Le Zhang;Zao-Yi Zheng;Yun Liu;Ming-Ming Cheng;Ian Reid,xinyuzhang@mail.nankai.edu.cn;jiawang.bian@gmail.com;zhangleuestc@gmail.com;roymarssss@gmail.com;nk12csly@mail.nankai.edu.cn;cmm@nankai.edu.cn;ian.reid@adelaide.edu.au,3;6;3,,Withdrawn,0,5,,yes,9/25/19,Nankai University;;;;Nankai University;Nankai University;The University of Adelaide,Descriptor;Correspondence;,-1;-1;-1;-1;-1;-1;102,366;-1;-1;-1;366;366;120,m;m,NAN,NAN,y,8
5340,ICLR,2020,Better Optimization for Neural Architecture Search with Mixed-Level Reformulation,Chaoyang He;Haishan Ye;Tong Zhang,chaoyang.he@usc.edu;yhs12354123@163.com;tongzhang@tongzhang-ml.org,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Southern California;163;Google,,36;-1;-1,62;-1;-1,m;m,NAN,NAN,n,
5341,ICLR,2020,Amharic Light Stemmer,Girma Neshir;Andeas Rauber;and Solomon Atnafu,girma1978@gmail.com;rauber@ifs.tuwien.ac.at;solomon.atnafu@aau.edu.et,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Addis Ababa University;TU Wien Vienna University of Technology;Addis Ababa University,Amharic light Stemmer;Affixes;Amharic Sentiment Classification;,-1;102;-1,-1;360;-1,m;m,NAN,NAN,n,
5342,ICLR,2020,Neural Reverse Engineering of Stripped Binaries,Yaniv David;Uri Alon;Eran Yahav,yanivd@cs.technion.ac.il;urialon@cs.technion.ac.il;yahave@cs.technion.ac.il,6;3;3,,Withdrawn,0,7,,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion",,27;27;27,-1;-1;-1,m;m,NAN,NAN,n,10
5343,ICLR,2020,Cost-Effective Interactive Neural Attention Learning,Jay Heo;Junhyeon Park;Hyewon Jeong;Wuhyun Shin;Kwang Joon Kim;juho Lee;Eunho Yang;Sung Ju Hwang,jayheo@kaist.ac.kr;pjh2941@kaist.ac.kr;jhw162@kaist.ac.kr;wuhyun.shin@kaist.ac.kr;preppie@yuhs.ac.kr;juho@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,3;3;3;1,,Withdrawn,0,4,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Kyung Hee;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,interactive learning;neural process;attention mechanism;interpretable machine learning;influence functions;uncertainty.;,-1;-1;-1;-1;445;-1;-1;-1,110;110;110;110;319;-1;110;110,m;m,NAN,NAN,n,8
5344,ICLR,2020,Gated Channel Transformation for Visual Recognition,Zongxin Yang;Linchao Zhu;Yu Wu;Yi Yang,zongxin.yang@student.uts.edu.au;zhulinchao7@gmail.com;yu.wu-3@student.uts.edu.au;yi.yang@uts.edu.au,3;1;6,,Withdrawn,0,3,,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,,73;73;73;73,193;193;193;193,m;m,australasia,au,n,2
5345,ICLR,2020,Masked Translation Model,Arne Nix;Yunsu Kim;Jan Rosendahl;Shahram Khadivi;Hermann Ney,nix@i6.informatik.rwth-aachen.de;kim@i6.informatik.rwth-aachen.de;rosendahl@i6.informatik.rwth-aachen.de;skhadivi@ebay.com;ney@i6.informatik.rwth-aachen.de,3;3;3,,Withdrawn,1,1,,yes,9/25/19,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;eBay;RWTH Aachen University,Neural Machine Translation;Non-Autoregressive Decoding;Deep Learning;Transformer;,118;118;118;-1;118,98;98;98;-1;98,m;m,NAN,NAN,n,8;3
5346,ICLR,2020,Target-directed Atomic Importance Estimation via Reverse Self-attention,Gyoung S. Na;Hyun Woo Kim,ngs0726@gmail.com;ahwk@krict.re.kr,1;1;3,,Withdrawn,0,3,,yes,9/25/19,POSTECH;POSTECH,Scientific Application;Knowledge Discovery;Graph Neural Network;Attention Mechanism;,-1;-1,-1;-1,m;m,asia,in,n,8;1;10
5347,ICLR,2020,ProxNet: End-to-End Learning of  Structured Representation by Proximal Mapping,Mao Li;Yingyi Ma;Xinhua Zhang,mli206@uic.edu;yma36@uic.edu;zhangx@uic.edu,3;1;3,,Withdrawn,0,2,,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",representation learning;multiview learning;,-1;-1;-1,-1;-1;-1,f;m,usa,usa,n,4
5348,ICLR,2020,Measure by Measure: Automatic Music Composition with Traditional Western Music Notation,Yujia Yan;Zhiyao Duan,yujia.yan.w@gmail.com;zhiyao.duan@rochester.edu,1;1;1,,Withdrawn,0,1,,yes,9/25/19,University of Rochester;University of Rochester,,102;102,173;173,u;m,europe,uk,pdf miss,
5349,ICLR,2020,When Do Variational Autoencoders Know  What They Don't Know?,Bin Dai;David Wipf,daib13@mails.tsinghua.edu.cn;davidwipf@gmail.com,8;6;8,,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University, Tsinghua University;Amazon",variational autoencoder;generative model;,4;-1,23;-1,m;m,NAN,NAN,y,5
5350,ICLR,2020,Irrationality can help reward inference,Lawrence Chan;Andrew Critch;Anca Dragan,chanlaw@berkeley.edu;critch@berkeley.edu;anca@berkeley.edu,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,preference inference;inverse reinforcement learning;reward inference;irrationality;,-1;-1;-1,13;13;13,m;f,usa,usa,n,
5351,ICLR,2020,Teaching GAN to generate per-pixel annotation,Danil Galeev;Konstantin Sofiyuk;Danila Rukhovich;Anton Konushin;Mikhail Romanov,denemmy@gmail.com;ksofiyuk@gmail.com;danrukh@gmail.com;a.konushin@samsung.com;m.romanov@samsung.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Samsung,GAN;unsupervised representation learning;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2;5
5352,ICLR,2020,One Generation Knowledge Distillation by Utilizing Peer Samples,Xingjian Li;Haozhe An;Haoyi Xiong;Jun Huan;Dejing Dou;Chengzhong Xu,1762778193@qq.com;haozhe.an@yahoo.com,1;3;3,,Withdrawn,0,3,,yes,9/25/19,"Baidu;University of Maryland, College Park",,-1;12,-1;91,m;m,usa,usa,n,
5353,ICLR,2020,Guided variational autoencoder for disentanglement learning,Zheng Ding;Yifan Xu;Weijian Xu;Yang Yang;Max Welling;Zhuowen Tu,dingz16@mails.tsinghua.edu.cn;yix081@ucsd.edu;wex041@eng.ucsd.edu;yyangy@qti.qualcomm.com;welling.max@gmail.com;ztu@ucsd.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University, Tsinghua University;University of California, San Diego;University of California, San Diego;Qualcomm Inc, QualComm;University of California, Irvine;University of California, San Diego",variational autoencoder;representation learning;disentanglement learning;,4;-1;-1;-1;-1;-1,23;31;31;-1;96;31,m;m,usa,usa,n,5;4
5354,ICLR,2020,Learning Sparsity and Quantization Jointly and Automatically for Neural Network Compression via Constrained Optimization,Haichuan Yang;Shupeng Gui;Yuhao Zhu;Ji Liu,h.yang@rochester.edu;sgui2@ur.rochester.edu;yzhu@rochester.edu;ji.liu.uwisc@gmail.com,3;6;3,,Withdrawn,0,0,,yes,9/25/19,University of Rochester;University of Rochester;University of Rochester;Kwai Inc.,model compression;pruning;quantization;autoML;,102;102;102;-1,173;173;173;-1,m;m,asia,in,pdf miss,
5355,ICLR,2020,FairFace: A Novel Face Attribute Dataset for Bias Measurement and Mitigation,Kimmo K√§rkk√§inen;Jungseock Joo,kimmo@cs.ucla.edu;jjoo@comm.ucla.edu,3;1;1,,Withdrawn,0,3,,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",dataset bias;face attribute recognition;bias measurement;,-1;-1,17;17,m;m,usa,usa,n,2;1;7
5356,ICLR,2020,Pruning Depthwise Separable Convolutions for Extra Efficiency Gain of Lightweight Models,Cheng-Hao Tu;Jia-Hong Lee;Yi-Ming Chan;Chu-Song Chen,andytu28@iis.sinica.edu.tw;honghenry.lee@iis.sinica.edu.tw;yiming@iis.sinica.edu.tw;song@iis.sinica.edu.tw,3;3;3,,Withdrawn,1,0,,yes,9/25/19,Academia Sinica;Academia Sinica;Academia Sinica;Academia Sinica,Deep Learning;Network Pruning;Lightweight CNN;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5357,ICLR,2020,Benchmarking Adversarial Robustness,Yinpeng Dong;Qi-An Fu;Xiao Yang;Tianyu Pang;Hang Su;Jun Zhu,dyp17@mails.tsinghua.edu.cn;fqa19@mails.tsinghua.edu.cn;yangxiao19@mails.tsinghua.edu.cn;pty17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,1;3;1,,Withdrawn,0,0,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Adversarial Example;Robustness;Benchmark;,4;4;4;4;4;4,23;23;23;23;23;23,m;m,NAN,NAN,n,1;4
5358,ICLR,2020,Unsupervised Learning from Video with Deep Neural Embeddings,Chengxu Zhuang;Tianwei She;Alex Andonian;Daniel Yamins,chengxuz@stanford.edu;shetw@stanford.edu;aandonia@mit.edu;yamins@stanford.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Stanford University;Stanford University;Massachusetts Institute of Technology;Stanford University,Unsupervised learning;action recognition;video learning;deep neural networks;,5;5;5;5,4;4;5;4,m;m,usa,usa,n,
5359,ICLR,2020,Towards Unifying Neural Architecture Space Exploration and Generalization,Kartikeya Bhardwaj;Radu Marculescu,bhardwajkartikeya@gmail.com;radum@cmu.edu,3;1,,Withdrawn,0,0,,yes,9/25/19,arm;Carnegie Mellon University,Neural Architecture Space Exploration;Generalization;Model Compression;Network Science;Convolutional Neural Networks;,59;1,289;27,m;m,usa,usa,y,1
5360,ICLR,2020,IEG: Robust neural net training with severe label noises,Zizhao Zhang;Han Zhang;Sercan Arik;Honglak Lee;Tomas Pfister,zizhaoz@google.com;zhanghan@google.com;soarik@google.com;honglak@google.com;tpfister@google.com,1;3;3,,Withdrawn,0,6,,yes,9/25/19,Google;Google;Google;Google;Google,Robust deep learning;label noise;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5361,ICLR,2020,Stochastic Geodesic Optimization for Neural Networks,Zana Rashidi;Aijun An;Xiaogang Wang,zrashidi@eecs.yorku.ca;aan@cse.yorku.ca;stevenw@mathstat.yorku.ca,1;3;3,,Withdrawn,0,1,,yes,9/25/19,York University;York University;York University,Neural Network Optimization;Geodesic Optimization;Momentum;,194;194;194,416;416;416,m;m,asia,kr,n,
5362,ICLR,2020,WEEGNET: an wavelet based Convnet for Brain-computer interfaces,Mouad Riyad;Mohammed Khalil;Abdellah Adib,riyadmouad1@gmail.com;medkhalil87@gmail.com;adib@fstm.ma,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Faculty of Sciences and Technologies -Mohammedia;;Faculty of Sciences and Technologies -Mohammedia,BCI;EEG;Convnet;DWT;WEEGNET;,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
5363,ICLR,2020,Classification as Decoder: Trading Flexibility for Control in Multi Domain Dialogue,Sam Shleifer;Manish Chablani;Namit Katariya;Anitha Kannan;Xavier Amatriain,sshleifer@gmail.com;manish@curai.com;namit@curai.com;anitha@curai.com;xavier@curai.com,1;3;1,,Withdrawn,0,3,,yes,9/25/19,Stanford University;Curai;Curai;Curai;Curai,NLP;dialogue;chatbot;weak supervision;language model;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
5364,ICLR,2020,Anomaly Detection and Localization in Images using Guided Attention,Shashanka Venkataramanan;Rajat Vikram Singh;Kuan-Chuan Peng,shashankv@knights.ucf.edu;singh.rajat@siemens.com;kp388@cornell.edu,6;3;3,,Withdrawn,0,5,,yes,9/25/19,University of Central Florida;Siemens Corporate Research;Cornell University,,73;-1;7,609;-1;19,m;m,usa,usa,n,8;2;5;4
5365,ICLR,2020,In-training Matrix Factorization for Parameter-frugal Neural Machine Translation,Zachary Kaden;Teven Le Scao;Raphael Olivier,kadenzack@gmail.com;tlescao@andrew.cmu.edu;rolivier@cs.cmu.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,natural language processing;neural machine translation;matrix factorization;model compression;,-1;1;1,-1;27;27,m;m,usa,usa,n,3
5366,ICLR,2020,Dataset Distillation,Tongzhou Wang;Jun-Yan Zhu;Antonio Torralba;Alexei A. Efros,tongzhou.wang.1994@gmail.com;junyanz@mit.edu;torralba@mit.edu;efros@eecs.berkeley.edu,6;3;3,,Withdrawn,2,11,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley,knowledge distillation;deep learning;few-shot learning;continual learning;,5;5;5;-1,5;5;5;13,m;m,usa,usa,n,
5367,ICLR,2020,Spatial Information is Overrated for Image Classification,Yue Fan;Yongqin Xian;Max Maria Losch;Bernt Schiele,yfan@mpi-inf.mpg.de;yxian@mpi-inf.mpg.de;mlosch@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de,6;1;1,,Withdrawn,0,1,,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5368,ICLR,2020,GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modelling,Yahui Liu;Marco De Nadai;Jian Yao;Nicu Sebe;Bruno Lepri;Xavier Alameda-Pineda,yahui.liu@unitn.it;denadai@fbk.eu;jian.yao@whu.edu.cn;niculae.sebe@unitn.it;lepri@fbk.eu;xavier.alameda-pineda@inria.fr,6;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Trento;Fondazione Bruno Kessler;Wuhan University;University of Trento;Fondazione Bruno Kessler;INRIA,GANs;image-to-image translation;multi-domain image translation;multi-modal image translation;Gaussian Mixture Model;,143;-1;194;143;-1;-1,307;-1;354;307;-1;-1,m;m,europe,gr,n,
5369,ICLR,2020,Information lies in the eye of the beholder: The effect of representations on observed mutual information,Julian Zilly;Lorenz Hetzel;Andrea Censi;Emilio Frazzoli,jzilly@ethz.ch;hetzell@ethz.ch;acensi@ethz.ch;emilio.frazzoli@idsc.mavt.ethz.ch,3;1;1,,Withdrawn,0,2,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep learning;Information theory;representation;coding;mutual information estimation;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,
5370,ICLR,2020,Quantitatively Disentangling and Understanding Part Information in CNNs,Quanshi Zhang;Yu Yang;Haotian Ma;Ying Nian Wu,zqs1022@sjtu.edu.cn;yy19970901@ucla.edu;11612807@mail.sustc.edu.cn;ywu@stat.ucla.edu,6;3;3,,Withdrawn,0,0,,yes,9/25/19,"Shanghai Jiao Tong University;University of California, Los Angeles;University of Science and Technology of China;University of California, Los Angeles",Convolutional Neural Networks;Interpretability;Deep Learning;,30;-1;-1;-1,157;17;80;17,m;m,usa,usa,n,
5371,ICLR,2020,Graph-based motion planning networks,Tai Hoang;Ngo Anh Vien,thobotics@gmail.com;v.ngo@qub.ac.uk,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Queen's University Belfast,motion planning;reinforcement learning;graph-based planning;transfer-planning;zero-shot planning;,-1;248,-1;204,m;m,europe,uk,n,1;10
5372,ICLR,2020,Bridging ELBO objective and MMD,Talip Ucar,pilatracu@gmail.com,1;1;1,,Withdrawn,0,3,,yes,9/25/19,University College London,ELBO;MMD;VAE;Posterior collapse;,52,-1,m,europe,uk,n,5
5373,ICLR,2020,Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom,Juan Luis Gonzalez Bello;Munchurl Kim,juanluisgb@kaist.ac.kr;mkimee@kaist.ac.kr,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Deep learning;novel view synthesis;Deep 3D Zoom;,-1;-1,110;110,m;m,NAN,NAN,n,6
5374,ICLR,2020,Through the Lens of Neural Network: Analyzing Neural QA Models via Quantized Latent Representation,Tsung-Han Wu;Chun-Cheng Hsieh;Yen-Hao Chen;Hung-yi Lee,ynnekuw@gmail.com;syasyunjyo@gmail.com;r07921112@ntu.edu.tw;hungyilee@ntu.edu.tw,3;3;1,,Withdrawn,0,0,,yes,9/25/19,National Taiwan University;;Nanyang Technological University;Nanyang Technological University,Question Answering;Discrete Representation;Vector Quantization;,-1;-1;43;43,-1;-1;49;49,m;m,asia,sg,n,
5375,ICLR,2020,Hierarchical Complement Objective Training,Hao-Yun Chen;Li-Huang Tsai;Shih-Chieh Chang;Jia-Yu Pan;Yu-Ting Chen;Wei Wei;Da-Cheng Juan,haoyunchen@gapp.nthu.edu.tw;lihuangtsai@gapp.nthu.edu.tw;scchang@cs.nthu.edu.tw;jypan@google.com;yutingchen@google.com;wewei@google.com;dacheng@google.com,3;3;3,,Withdrawn,0,3,,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Google;Google;Google;Google,category hierarchy;optimization;entropy;image recognition;semantic segmentation;deep learning;,194;194;194;-1;-1;-1;-1,365;365;365;-1;-1;-1;-1,m;m,NAN,NAN,n,2
5376,ICLR,2020,Anomalous Pattern Detection in Activations and Reconstruction Error of Autoencoders,Celia Cintas;Skyler Speakman;Victor Akinwande;Srihari Sridharan;William Ogallo;Edward McFowland III,celia.cintas@ibm.com;skyler@ke.ibm.com;victor.akinwande1@ibm.com;sriharis.sridharan@ke.ibm.com;william.ogallo@ibm.com;mcfowland@umn.edu,3;1;1,,Withdrawn,0,3,,yes,9/25/19,"International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Minnesota, Minneapolis",unsupervised anomaly detection;adversarial attacks;autoencoders;subset scanning;,-1;-1;-1;-1;-1;73,-1;-1;-1;-1;-1;79,f;m,NAN,NAN,n,4
5377,ICLR,2020,Dynamically Balanced Value Estimates for Actor-Critic Methods,Nicolai Dorka;Joschka Boedecker;Wolfram Burgard,dorka@cs.uni-freiburg.de;jboedeck@cs.uni-freiburg.de;burgard@cs.uni-freiburg.de,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Reinforcement Learning;Actor-Critic;Continuous Control;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5378,ICLR,2020,Incorporating Perceptual Prior to Improve Model's Adversarial Robustness,B.S. Vivek;Arya Baburaj;Ashutosh B Sathe;R. Venkatesh Babu,svivek@iisc.ac.in;aryababuraj@iisc.ac.in;satheab16.mech@coep.ac.in;venky@iisc.ac.in,1;1;1,,Withdrawn,0,5,,yes,9/25/19,"Indian Institute of Science;Indian Institute of Science;College of Engineering, Pune;Indian Institute of Science",Representation learining;adversarial defense;robust neural networks;,-1;-1;-1;-1,301;301;-1;301,m;m,NAN,NAN,n,2;4
5379,ICLR,2020,MultiGrain: a unified image embedding for classes and instances,Maxim Berman;Herv√© J√©gou;Andrea Vedaldi;Iasonas Kokkinos;Matthijs Douze,maxim.berman@esat.kuleuven.be;rvj@fb.com;vedaldi@fb.com;iasonas.kokkinos@gmail.com;matthijs@fb.com,3;3;3,,Withdrawn,0,4,,yes,9/25/19,KU Leuven;Facebook;Facebook;Ariel AI;Facebook,classification;image retrieval;deep learning;data augmentation;,143;-1;-1;-1;-1,45;-1;-1;-1;-1,m;m,NAN,NAN,n,
5380,ICLR,2020,A Simple Geometric Proof for the Benefit of Depth in ReLU Networks,Asaf Amrami;Yoav Goldberg,asaf.amrami@gmail.com;yoav.goldberg@gmail.com,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Bar Ilan University;Bar-Ilan University,,-1;102,-1;513,m;m,europe,il,y,1
5381,ICLR,2020,How does Lipschitz Regularization Influence GAN Training?,Yipeng Qin;Niloy Mitra;Peter Wonka,qinyipeng1991@gmail.com;niloym@gmail.com;pwonka@gmail.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Cardiff University;University College London;KAUST,,168;52;102,196;-1;-1,m;m,europe,gr,y,5
5382,ICLR,2020,SIMULTANEOUS ATTRIBUTED NETWORK EMBEDDING AND CLUSTERING,Lazhar labiod;Mohamed Nadif,lazhar.labiod@parisdescartes.fr;mohamed.nadif@parisdescartes.fr,1;1;1,,Withdrawn,0,0,,yes,9/25/19,University Paris Descartes;University Paris Descartes,Attributed network;Embedding;clustering;matrix decomposition;spectral rotation;,-1;-1,-1;-1,m;m,NAN,NAN,n,
5383,ICLR,2020,Tree-structured Attention Module for Image Classification,Gyungin Shin;Sung-Ho Bae;and Yong-Jae Moon,gishin@khu.ac.kr;shbae@khu.ac.kr;moonyj@khu.ac.kr,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,inter-channel relationship;attention module;point-wise group convolution;,445;445;445,319;319;319,m;m,asia,kr,n,8;2
5384,ICLR,2020,Task Level Data Augmentation for Meta-Learning,Jialin Liu;Fei Chao;Chih-Min Lin,31520171153232@stu.xmu.edu.cn;fchao@xmu.edu.cn;cml@saturn.yzu.edu.tw,3;3;6,,Withdrawn,0,1,,yes,9/25/19,Xiamen University;Xiamen University;National Tsing Hua University,Meta-learning;few-shot learning;data augmentation;,-1;-1;194,579;579;365,f;m,asia,tw,n,6;1
5385,ICLR,2020,Learning Semantic Correspondences from Noisy Data-text Pairs by Local-to-Global Alignments,Feng Nie;Jinpeng Wang;Rong Pan;Chin-Yew Lin,fengniesysu@gmail.com;jinpwa@microsoft.com;panr@sysu.edu.cn;cyl@microsoft.com,3;8,,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft,textual grounding;data-to-text generation;multi-instance learning;conditional random fields;,-1;-1;-1;-1,-1;-1;299;-1,u;m,NAN,NAN,n,3
5386,ICLR,2020,VideoEpitoma: Efficient Recognition of Long-range Actions,Noureldien Hussein;Babak Ehteshami Bejnordi;Mihir Jain,nhussein@uva.nl;behtesha@qti.qualcomm.com;mijain@qti.qualcomm.com,1;3;1,,Withdrawn,0,3,,yes,9/25/19,"University of Amsterdam;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",Computer Vision;Action Recognition;Video Understanding;Efficient CNNs;,143;-1;-1,62;-1;-1,m;m,NAN,NAN,n,
5387,ICLR,2020,StacNAS: Towards Stable and Consistent  Optimization for Differentiable  Neural Architecture Search,Li Guilin;Zhang Xing;Wang Zitong;Li Zhenguo;Zhang Tong,hiliguilin@gmail.com;zhang.xing1@huawei.com;ztwang@math.cuhk.edu.hk;li.zhenguo@huawei.com;tongzhang@tongzhang-ml.org,6;3;3,,Withdrawn,1,3,,yes,9/25/19,National University of Singapore;Huawei Technologies Ltd.;The Chinese University of Hong Kong;Huawei Technologies Ltd.;Google,Differentiable  Neural Architecture Search;,-1;-1;316;-1;-1,-1;-1;35;-1;-1,f;m,NAN,NAN,n,
5388,ICLR,2020,Construction of Macro Actions for Deep Reinforcement Learning,Yi-Hsiang Chang;Kuan-Yu	Chang;Henry Kuo;Chun-Yi Lee,shawn420@gapp.nthu.edu.tw;kychang@elsa.cs.nthu.edu.tw;hkuo@college.harvard.edu;cylee@gapp.nthu.edu.tw,1;1;3,,Withdrawn,0,1,,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;Harvard University;National Tsing Hua University,macro action;genetic algorithm;deep reinforcement learning;,194;194;52;194,365;365;7;365,u;m,asia,tw,n,
5389,ICLR,2020,Towards Understanding Generalization in Gradient-Based Meta-Learning,Simon Guiroy;Vikas Verma;Christopher J. Pal,simon.guiroy@umontreal.ca;vikasverma.iitm@gmail.com;christopher.pal@polymtl.ca,3;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Montreal;Aalto University;Polytechnique Montreal,meta-learning;objective landscapes;,118;118;316,85;182;-1,m;m,canada,ca,n,6;1
5390,ICLR,2020,Structural Multi-agent Learning,Kaiqian Han;Liangliang Ren;Jiwen Lu;Jie Zhou,hkg16@mails.tsinghua.edu.cn;renll16@mails.tsinghua.edu.cn;lujiwen@tsinghua.edu.cn;jzhou@tsinghua.edu.cn,1;3;6,,Withdrawn,0,4,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Multi-agent Learning;Communication;Graph Network;,4;4;4;4,23;23;23;23,m;m,NAN,NAN,n,10
5391,ICLR,2020,AdamT: A Stochastic Optimization with Trend Correction Scheme,Bingxin Zhou;Xuebin Zheng;Junbin Gao,bzho3923@uni.sydney.edu.au;xzhe2914@uni.sydney.edu.au;junbin.gao@sydney.edu.au,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney,Optimization;ADAM;Stochastic Gradient Descent;Deep Learning;,64;64;64,60;60;60,m;m,europe,uk,y,
5392,ICLR,2020,Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Imbalanced Data,Utkarsh Ojha;Krishna Kumar Singh;Cho-Jui Hsieh;Yong Jae Lee,uojha@ucdavis.edu;krsingh@ucdavis.edu;chohsieh@cs.ucla.edu;yongjaelee@ucdavis.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Davis;University of California, Davis;University of California, Los Angeles;University of California, Davis",Generative Adversarial Networks;Imbalanced data;Data Augmentation;,-1;-1;-1;-1,55;55;17;55,m;m,usa,usa,n,5
5393,ICLR,2020,Generalizing Deep Multi-task Learning with Heterogeneous Structured Networks,Ming Hou;Xinqi Chen;Shifeng Huang;Shengli Xie;Guoxu Zhou;Qibin Zhao,ming.hou@riken.jp;xinqicham@gmail.com;sfengmmin@163.com;shlxie@gdut.edu.cn;gx.zhou@gdut.edu.cn;qibin.zhao@riken.jp,3;1;3,,Withdrawn,0,0,,yes,9/25/19,RIKEN;;163;South China University of Technology;South China University of Technology;RIKEN,deep multi-task learning;heterogenous network architectures;tensor representation;,-1;-1;-1;-1;-1;-1,-1;-1;-1;501;501;-1,m;m,NAN,NAN,n,
5394,ICLR,2020,Rethinking Data Augmentation: Self-Supervision and Self-Distillation,Hankook Lee;Sung Ju Hwang;Jinwoo Shin,hankook.lee@kaist.ac.kr;sjhwang82@kaist.ac.kr;jinwoos@kaist.ac.kr,1;3;3,,Withdrawn,0,2,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,self-supervision;data augmentation;,-1;-1;-1,110;110;110,m;m,NAN,NAN,n,6;1
5395,ICLR,2020,Dynamical Clustering of Time Series Data Using Multi-Decoder RNN Autoencoder,Daisuke Kaji;Kazuho Watanabe;Masahiro Kobayashi,daisuke.kaji.j3a@jp.denso.com;wkazuho@cs.tut.ac.jp;kobayashi@lisl.cs.tut.ac.jp,3;3;1,,Withdrawn,0,3,,yes,9/25/19,Denso Corporation;Meiji University;Meiji University,Dynamical system;Recurrent neural network;Autoencoder;Variational Bayes;Clustering;Time series data;Driving data;,-1;-1;-1,-1;1323;1323,u;u,asia,jp,n,
5396,ICLR,2020,Regularizing Predictions via Class-wise Self-knowledge Distillation,Sukmin Yun;Jongjin Park;Kimin Lee;Jinwoo Shin,sukmin.yun@kaist.ac.kr;jongjin.park@kaist.ac.kr;kiminlee@kaist.ac.kr;jinwoos@kaist.ac.kr,3;1;6,,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,regularization;knowledge distillation;,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n,1
5397,ICLR,2020,Imbalanced Classification via Adversarial Minority Over-sampling,Jaehyung Kim;Jongheon Jeong;Jinwoo Shin,jaehyungkim@kaist.ac.kr;jongheonj@kaist.ac.kr;jinwoos@kaist.ac.kr,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,imbalanced classification;adversarial examples;,-1;-1;-1,110;110;110,m;m,NAN,NAN,n,3;1;4
5398,ICLR,2020,Neuron ranking - an informed way to compress convolutional neural networks,Kamil Adamczewski;Mijung Park,kamil.m.adamczewski@gmail.com;mijung.park@tuebingen.mpg.de,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Max-Planck Institute;Max-Planck Institute,convolutional neural network;compression;shapley value;importance switch;variational inference;interpretability;,-1;-1,-1;-1,m;f,NAN,NAN,n,1
5399,ICLR,2020,Compressing Deep Neural Networks With Learnable Regularization,Yoojin Choi;Mostafa El-Khamy;Jungwon Lee,yoojin.c@samsung.com;mostafa.e@samsung.com;jungwon2.lee@samsung.com,3;6;3;3,,Withdrawn,0,1,,yes,9/25/19,Samsung;Samsung;Samsung,,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,
5400,ICLR,2020,Image Classification Through Top-Down Image Pyramid Traversal,Athanasios Papadopoulos;Pawel Korus;Nasir Memon,ap4094@nyu.edu;pkorus@nyu.edu;memon@nyu.edu,3;1;3,,Withdrawn,0,4,,yes,9/25/19,New York University;New York University;New York University,image classification;multi-scale processing;attention;,22;22;22,29;29;29,m;m,usa,usa,n,8
5401,ICLR,2020,PAC-Bayes Few-shot Meta-learning with Implicit Learning of Model Prior Distribution,Cuong Nguyen;Thanh-Toan Do;Gustavo Carneiro,cuong.nguyen@adelaide.edu.au;thanh-toan.do@liverpool.ac.uk;gustavo.carneiro@adelaide.edu.au,6;1;1,,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;University of Liverpool;The University of Adelaide,meta-learning;few-shot learning;,102;118;102,120;165;120,m;m,NAN,NAN,y,6;11;1;5
5402,ICLR,2020,CRAP: Semi-supervised Learning via Conditional Rotation Angle Prediction,Hai-Ming Xu;Lingqiao Liu,hai-ming.xu@adelaide.edu.au;lingqiao.liu@adelaide.edu.au,3;3;3,,Withdrawn,0,2,,yes,9/25/19,The University of Adelaide;The University of Adelaide,Semi-supervised Learning;Self-supervised Learning;,102;102,120;120,m;m,NAN,NAN,n,
5403,ICLR,2020,A novel text representation which enables image classifiers to perform text classification,Stephen M. Petrie;T'Mir D. Julius,spetrie@swin.edu.au;tdjempire@gmail.com,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Swinburne University of Technology;University of Melbourne,supervised representation learning;natural language processing;image pattern recognition;named entity disambiguation;,-1;-1,389;-1,m;f,asia,in,n,3
5404,ICLR,2020,FACE SUPER-RESOLUTION GUIDED BY 3D FACIAL PRIORS,xiaobin hu;wenqi ren;jiaolong yang;xiaochun cao;Xiaoming Li;John LaMaster;Bjoern Menze;wei liu,xiaobin.hu@tum.de;rwq.renwenqi@gmail.com;jiaoyan@microsoft.com;caoxiaochun@iie.ac.cn;hit.xmshr@gmail.com;jlamaste@gmail.com;bjoern.menze@tum.de;wl2223@columbia.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Technical University Munich;Institute of information engineering, CAS;Microsoft;Institute of information engineering, CAS;;Technical University Munich;Technical University Munich;Columbia University",Super-resolution;3D Facial priors;Spatial Attention Mechanism;,-1;-1;-1;-1;-1;-1;-1;24,-1;-1;-1;-1;-1;-1;-1;16,m;m,usa,usa,n,8
5405,ICLR,2020,Doubly Normalized Attention,Nan Ding;Xinjie Fan;Zhenzhong Lan;Dale Schuurmans;Radu Soricut,dingnan@google.com;fan.xinjiebuaa@gmail.com;lanzhzh@google.com;schuurmans@google.com;rsoricut@google.com,3;1;1,,Withdrawn,0,3,,yes,9/25/19,Google;;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,8
5406,ICLR,2020,Correctness Verification of Neural Network,Yichen Yang;Martin Rinard,yicheny@csail.mit.edu;rinard@csail.mit.edu,1;3;1,,Withdrawn,0,3,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neural network verification;safety;reliability;,5;5,5;5,m;m,usa,usa,y,1
5407,ICLR,2020,Diversely Stale Parameters for Efficient Training of Deep Convolutional Networks,An Xu;Zhouyuan Huo;Heng Huang,an.xu@pitt.edu;zhouyuan.huo@pitt.edu;heng.huang@pitt.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Pittsburgh;University of Pittsburgh;University of Pittsburgh,Layer-wise Staleness;Parallel Training;Convolutional Neural Networks;,79;79;79,113;113;113,m;m,usa,usa,pdf miss,1
5408,ICLR,2020,WHAT DATA IS USEFUL FOR MY DATA: TRANSFER LEARNING WITH A MIXTURE OF SELF-SUPERVISED EXPERTS,Xi Yan;David Acuna;Sanja Fidler,xi.yan@mail.utoronto.ca;davidj@cs.toronto.edu;fidler@cs.toronto.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Toronto University;University of Toronto;University of Toronto,,-1;18;18,-1;18;18,f;f,canada,ca,n,6;2
5409,ICLR,2020,Classification Logit Two-sample Testing by Neural Networks,Xiuyuan Cheng;Alexander Cloninger,xiuyuan.cheng@duke.edu;acloninger@ucsd.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"Duke University;University of California, San Diego",,46;-1,20;31,m;m,usa,usa,y,1;5;4
5410,ICLR,2020,Frontal low-rank random tensors for high-order feature representation,Yan Zhang;Krikamol Muandet;Qianli Ma;Heiko Neumann;Siyu Tang,yan.zhang@tuebingen.mpg.de;krikamol@tuebingen.mpg.de;qianli.ma@tue.mpg.de;heiko.neumann@uni-ulm.de;stang@tuebingen.mpg.de,6;3;3;3,,Withdrawn,0,1,,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Ulm University;Max-Planck Institute,,-1;-1;-1;-1;-1,-1;-1;-1;141;-1,f;f,NAN,NAN,y,2;1
5411,ICLR,2020,Interpretability Evaluation Framework for Deep Neural Networks,Junxiang Wang;Liang Zhao;Yanfang Ye and Houman Homayoun,jwang40@gmu.edu;lzhao9@gmu.edu;yanfang.ye@mail.wvu.edu;hhomayou@gmu.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,George Mason University;George Mason University;West Virginia University;George Mason University,Interpretability Evaluation;Deep Neural Networks;Alternating Direction Method of Multipliers;,85;85;316;85,282;282;601;282,m;m,usa,usa,pdf miss,1
5412,ICLR,2020,CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement Learning problem,Arpan Kusari,arpan.kusari@gmail.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,0,inverse reinforcement learning;conditional variational auto-encoder;wasserstein;,,,m,NAN,NAN,n,5
5413,ICLR,2020,"Study of a Simple, Expressive and Consistent Graph Feature Representation",Pineau Edouard,pineau.edouard@gmail.com,1;3;3,,Withdrawn,0,1,,yes,9/25/19,0,Graph representation;Spectral;Graph perturbation;,,,m,NAN,NAN,y,10
5414,ICLR,2020,Input Alignment along Chaotic directions increases Stability in Recurrent Neural Networks,Priyadarshini Panda;Kaushik Roy,priya.panda@yale.edu;kaushik@purdue.edu,6;1;1,,Withdrawn,0,0,,yes,9/25/19,Yale University;Purdue University,Reservoir Models;Stability;Chaos;Input Alignment;Mean Field Analysis;,73;24,8;88,f;m,usa,usa,n,
5415,ICLR,2020,All Neural Networks are Created Equal,Guy Hacohen;Leshem Choshen;Daphna Weinshall,guy.hacohen@mail.huji.ac.il;leshem.choshen@mail.huji.ac.il;daphna@cs.huji.ac.il,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,deep learning;empirical machine learning;learning dynamics;curriculum;consistency score;consensus score;network comparison;,85;85;85,216;216;216,m;f,europe,il,n,1;10
5416,ICLR,2020,Hyperbolic Image Embeddings,Valentin Khrulkov;Leyla Mirvakhabova;Evgeniya Ustinova;Ivan Oseledets;Victor Lempitsky,khrulkov.v@gmail.com;leyla.mirvakhabova@skoltech.ru;evgeniya.ustinova@skoltech.ru;i.oseledets@skoltech.ru;v.lempitsky@samsung.com,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Yandex;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Samsung,hyperbolic;poincare;image embeddings;few show learning;reidentification;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;2
5417,ICLR,2020,Instant Quantization of Neural Networks using Monte Carlo Methods,Gon√ßalo Mordido;Matthijs Van Keirsbilck;Alexander Keller,goncalo.mordido@hpi.de;matthijsv@nvidia.com;akeller@nvidia.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Hasso Plattner Institute;NVIDIA;NVIDIA,monte carlo;importance sampling;network quantization;,143;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5418,ICLR,2020,Gating Revisited: Deep Multi-layer RNNs That Can Be Trained,Mehmet Ozgur Turkoglu;Stefano D'Aronco;Jan Dirk Wegner;Konrad Schindler,ozgur.turkoglu@geod.baug.ethz.ch;stefano.daronco@geod.baug.ethz.ch;jan.wegner@geod.baug.ethz.ch;schindler@geod.baug.ethz.ch,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep RNN;Multi-layer RNN;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5419,ICLR,2020,ILS-SUMM: Iterated Local Search for Unsupervised Video Summarization,Yair Shemer;Daniel Rotman;Nahum Shimkin,sy@campus.technion.ac.il;danieln@il.ibm.com;shimkin@ee.technion.ac.il,1;3;6,,Withdrawn,0,1,,yes,9/25/19,"Technion, Technion;International Business Machines;Technion, Technion",,27;-1;27,-1;-1;-1,m;m,NAN,NAN,n,
5420,ICLR,2020,Quadratic GCN for graph classification,Omer Nagar;Yoram Louzoun,ovednagar@hotmail.com;louzouy@math.biu.ac.il,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Bar Ilan University;Bar Ilan University,GCN;Quadratic activation;graph classification;,-1;102,-1;513,m;m,europe,il,n,10
5421,ICLR,2020,Topological based classification using graph convolutional networks,Roy Abel;Idan Benami;Yoram Louzoun,royabel10@gmail.com;louzouy@math.biu.ac.il,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Bar Ilan University;Bar Ilan University,Graph Neural Networks;Graph Convolutional Networks;Graph;Topology;,-1;102,-1;513,m;m,europe,il,n,10
5422,ICLR,2020,Quantifying Layerwise Information Discarding of Neural Networks and Beyond,Haotian Ma;Yinqing Zhang;Fan Zhou;Quanshi Zhang,11612807@mail.sustc.edu.cn;zhangyinqing@sjtu.edu.cn;zhoufan98@sjtu.edu.cn;zqs1022@sjtu.edu.cn,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Deep Learning;Information Theory;Interpretability;Convolutional Neural Networks;,-1;30;30;30,80;157;157;157,m;m,asia,cn,n,7
5423,ICLR,2020,Real or Fake: An Empirical Study and Improved Model for Fake Face Detection,Zhengzhe Liu;Xiaojuan Qi;Jiaya Jia;Philip H. S. Torr,liuzhengzhelzz@gmail.com;xiaojuan.qi@eng.ox.ac.uk;leojia@cse.cuhk.edu.hk;philip.torr@eng.ox.ac.uk,3;3;3,,Withdrawn,0,3,,yes,9/25/19,"The Chinese University of Hong Kong;University of Oxford;Department of Computer Science and Engineering, The Chinese University of Hong Kong;University of Oxford",global image texture;generative adversarial networks;Gram matrix;,-1;46;46;46,-1;1;35;1,m;m,europe,uk,pdf miss,5
5424,ICLR,2020,Minimizing Change in Classifier Likelihood to Mitigate Catastrophic Forgetting,Ashish Gaurav;Sachin Vernekar;Sean Sedwards;Jaeyoung Lee;Vahdat Abdelzad;Krzysztof Czarnecki,ashish.gaurav@uwaterloo.ca;sachin.vernekar@uwaterloo.ca;sean.sedwards@uwaterloo.ca;jaeyoung.lee@uwaterloo.ca;vabdelza@gsd.uwaterloo.ca;kczarnec@gsd.uwaterloo.ca,3;3;3,,Withdrawn,1,1,,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo,catastrophic forgetting;continual learning;classification;regularization;,30;30;30;30;30;30,235;235;235;235;235;235,m;m,canada,ca,n,
5425,ICLR,2020,A Memory-augmented Neural Network by Resembling Human Cognitive Process of Memorization,Dongjing Shan;Xiongwei Zhang;Chao Zhang;Limin Wang,shandongjing@pku.edu.cn;xwzhang9898@163.com;chzhang@cis.pku.edu.cn;07wanglimin@gmail.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Peking University;163;Peking University;Zhejiang University,,14;-1;14;39,24;-1;24;107,u;m,asia,cn,n,
5426,ICLR,2020,Molecule Property Prediction and Classification with Graph Hypernetworks,Eliya Nachmani;Lior Wolf,enk100@gmail.com;wolf@fb.com,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Facebook;Facebook,,-1;-1,-1;-1,m;m,NAN,NAN,n,10
5427,ICLR,2020, Sparsity Learning in Deep Neural Networks,Amirsina Torfi;Rouzbeh A. Shirvani;Sobhan Soleymani;Nasser M. Nasrabadi,atorfi@vt.edu;rouzbeh.asghari@gmail.com;ssoleyma@mix.wvu.edu;nasser.nasrabadi@mail.wvu.edu,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Virginia Tech;;West Virginia University;West Virginia University,Neural Networks;Deep Learning;Sparsity;Guided Attention;,64;-1;316;316,-1;-1;601;601,m;m,usa,usa,n,8
5428,ICLR,2020,A Harmonic Structure-Based Neural Network Model for Musical Pitch Detection,Xian Wang;Lingqiao Liu;Qinfeng Shi,xian.wang01@adelaide.edu.au;lingqiao.liu@adelaide.edu.au;javen.shi@adelaide.edu.au,3;3;3,,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,musical pitch detection;automatic music transcription;,102;102;102,120;120;120,m;m,NAN,NAN,n,
5429,ICLR,2020,SEERL : Sample Efficient Ensemble Reinforcement Learning,Rohan Saphal;Balaraman Ravindran;Dheevatsa Mudigere;Sasikanth Avancha;Bharat Kaul,rohansaphal@gmail.com;ravi@cse.iitm.ac.in;dheevatsa@fb.com;sasikanth.avancha@intel.com;bharat.kaul@intel.com,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Oxford;Indian Institute of Technology Madras;Facebook;Intel;Intel,Reinforcement learning;,-1;-1;-1;-1;-1,-1;641;-1;-1;-1,m;m,NAN,NAN,n,1
5430,ICLR,2020,Exploring by Exploiting Bad Models in Model-Based Reinforcement Learning,Yixin Lin;Sarah Bechtle;Ludovic Righetti;Akshara Rai;Franziska Meier,yixinlin@fb.com;sbechtle@tuebingen.mpg.de;ludovic.righetti@nyu.edu;akshararai@fb.com;fmeier@fb.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Facebook;Max-Planck Institute;New York University;Facebook;Facebook,,-1;-1;22;-1;-1,-1;-1;29;-1;-1,m;f,NAN,NAN,n,
5431,ICLR,2020,Defensive Quantization Layer For Convolutional Network Against Adversarial Attack,Sirui Song;Qinglong Wang;Derek Yang;Yan Song;Xue Liu;Tong Zhang,siruisong97@gmail.com;qinglong.wang@mail.mcgill.ca;dyang1206@gmail.com;songyan@chuangxin.com;xueliu@cs.mcgill.ca;tongzhang0@gmail.com,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Tsinghua University;McGill University;;Sinovation Ventures;McGill University;Google,quantization;adversarial example;robustness;convolutional neural network;concept;,-1;102;-1;-1;102;-1,-1;42;-1;-1;42;-1,m;m,NAN,NAN,n,4
5432,ICLR,2020,Learnable Higher-order Representation for Action Recognition,Kai Hu;Bhiksha Raj,kaihu@cmu.edu;bhiksha@cs.cmu.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,action recognition;context learning;,1;1,27;27,u;u,usa,usa,n,1
5433,ICLR,2020,Meta Module Network for Compositional Visual Reasoning,Wenhu Chen;Zhe Gan;Linjie Li;Yu Cheng;William Wang;Jingjing Liu,wenhuchen@ucsb.edu;zhe.gan@microsoft.com;lindsey.li@microsoft.com;yu.cheng@microsoft.com;william@cs.ucsb.edu;jingjl@microsoft.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,UC Santa Barbara;Microsoft;Microsoft;Microsoft;UC Santa Barbara;Microsoft,Module Network;Visual Reasoning;Question Answering;Program Synthesis;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,1;10
5434,ICLR,2020,Multi-Task Adapters for On-Device Audio Inference,M. Tagliasacchi;F. de Chaumont Quitry;D. Roblek,mtagliasacchi@google.com;fcq@google.com;droblek@google.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Google;Google;Google,Audio;multi-task learning;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5435,ICLR,2020,Learning audio representations with self-supervision,M. Tagliasacchi;B. Gfeller;F. de Chaumont Quitry;D. Roblek,mtagliasacchi@google.com;beatg@google.com;fcq@google.com;droblek@google.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Google;Google;Google;Google,Audio representations;self-supervised learning;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3
5436,ICLR,2020,Scholastic-Actor-Critic For Multi Agent Reinforcement Learning,Weiying ChenÔºåRuize Hou,dissolution@126.com;fsszns@163.com,1;1;1;1,,Withdrawn,0,4,,yes,9/25/19,126;163,multi-agent reinforcement learning;Actor-Critic;,-1;-1,-1;-1,m;m,asia,in,n,8
5437,ICLR,2020,Non-Gaussian processes and neural networks at finite widths,Sho Yaida,shoyaida@fb.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Facebook,Gaussian process;perturbation theory;renormalization group;Bayesian inference;,-1,-1,m,NAN,NAN,n,11
5438,ICLR,2020,Uncertainty-aware Variational-Recurrent Imputation Network for Clinical Time Series,Ahmad Wisnu Mulyadi;Eunji Jun;Heung-Il Suk,wisnumulyadi@korea.ac.kr;ejjun92@korea.ac.kr;hisuk@korea.ac.kr,1;3;6;1,,Withdrawn,0,0,,yes,9/25/19,Korea University;Korea University;Korea University,Missing data imputation;electronic health Records;deep generative models;deep learning;,168;168;168,179;179;179,m;m,asia,kr,n,8;5
5439,ICLR,2020,An Information Theoretic Perspective on Disentangled Representation Learning,Xiaojiang Yang;Wendong Bi;Yu Cheng;Junchi Yan,yangxiaojiang@sjtu.edu.cn;biwendong1997@gmail.com;yu.cheng@microsoft.com;yanjunchi@sjtu.edu.cn,1;1;3,,Withdrawn,0,4,,yes,9/25/19,Shanghai Jiao Tong University;;Microsoft;Shanghai Jiao Tong University,,30;-1;-1;30,157;-1;-1;157,m;m,asia,cn,n,1;5
5440,ICLR,2020,Towards a Unified Evaluation of Explanation Methods without Ground Truth,Hao Zhang;Jiayi Chen;Haotian Xue;Quanshi Zhang,1603023-zh@sjtu.edu.cn;miracle3310@sjtu.edu.cn;xavihart@sjtu.edu.cn;zqs1022@sjtu.edu.cn,3;1;6,,Withdrawn,0,3,,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Deep Learning;Interpretability;Evaluation;Convolutional Neural Networks;,30;30;30;30,157;157;157;157,m;m,asia,cn,n,
5441,ICLR,2020,Fast Sparse ConvNets,Erich Elsen;Marat Dukhan;Trevor Gale;Karen Simonyan,eriche@google.com;maratek@google.com;tgale@google.com;simonyan@google.com,3;6;3,,Withdrawn,0,3,,yes,9/25/19,Google;Google;Google;Google,Sparsity;Vision;CNNs;ConvNets;Inference;Mobile;Kernels;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
5442,ICLR,2020,Locally adaptive activation functions with slope recovery term for deep and physics-informed neural networks,Ameya D. Jagtap;Kenji Kawaguchi;George Em Karniadakis,ameya_jagtap@brown.edu;kawaguch@mit.edu;george_karniadakis@brown.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Brown University;Massachusetts Institute of Technology;Brown University,PINN;machine learning;stochastic gradients;accelerated training;,85;5;85,53;5;53,m;m,usa,usa,y,1
5443,ICLR,2020,GumbelClip: Off-Policy Actor-Critic Using Experience Replay,Norman Tasfi;Miriam Capretz,ntasfi@gmail.com,1;3;3,,Withdrawn,0,1,,yes,9/25/19,University of Western Ontario,reinforcement learning;off-policy;actor-critic;experience replay;,-1,-1,m;f,NAN,NAN,n,
5444,ICLR,2020,Adversarial Neural Pruning,Divyam Madaan;Jinwoo Shin;Sung Ju Hwang,dmadaan@kaist.ac.kr;jinwoos@kaist.ac.kr;sjhwang82@kaist.ac.kr,1;3;3,,Withdrawn,0,3,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,adversarial examples;robust machine learning;robust optimization;network pruning;,-1;-1;-1,110;110;110,m;m,NAN,NAN,n,11;4
5445,ICLR,2020,Auto-Encoding Explanatory Examples,C√©sar Ojeda;David Biesner;Ramses Sanchez;Kostadin Cvejoski;Jannis Schuecker;Christian Bauckhage;Bodgan Georgiev,cesarali07@gmail.com;david.biesner@iais.fraunhofer.de;sanchez@bit.uni-bonn.de;kostadin.cvejoski@iais.fraunhofer.de;jannis.schuecker@iais.fraunhofer.de;christian.bauckhage@iais.fraunhofer.de;bogdan.georgiev@iais.fraunhofer.de,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Fraunhofer IAIS;Fraunhofer IIS;University of Bonn;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS,Variational Auto Encoders;Interpolations;Explanations;Stochastic Processes;,-1;-1;143;-1;-1;-1;-1,-1;-1;106;-1;-1;-1;-1,m;m,NAN,NAN,y,
5446,ICLR,2020,Affine Self Convolution,Nichita Diaconu;Daniel E. Worrall,diacon995@gmail.com;d.e.worrall@uva.nl,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Amsterdam;University of Amsterdam,Self-attention;convolution;equivariant;,-1;143,-1;62,m;m,europe,nl,n,8
5447,ICLR,2020,Universal Source-Free Domain Adaptation,Jogendra Nath Kundu;Naveen Venkat;Rahul M V;R. Venkatesh Babu,jogendrak@iisc.ac.in;nav.naveenvenkat@gmail.com;rmvenkat@andrew.cmu.edu;venky@iisc.ac.in,3;3;3,,Withdrawn,0,4,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;Carnegie Mellon University;Indian Institute of Science,unsupervised domain adaptation;knowledge transfer;source-free adaptation;,-1;-1;1;-1,301;301;27;301,m;m,NAN,NAN,n,5;4
5448,ICLR,2020,Learning an off-policy predictive state representation for deep reinforcement learning for vision-based steering in autonomous driving,Daniel Graves,dgraves@ualberta.ca,1;3;3,,Withdrawn,0,4,,yes,9/25/19,University of Alberta,Predictive representations;general value functions;reinforcement learning;off-policy learning;behavior estimation;,102,136,m,canada,ca,n,1
5449,ICLR,2020,$\textrm{D}^2$GAN: A Few-Shot Learning Approach with Diverse and Discriminative Feature Synthesis,Kai Li;Yulun Zhang;Kunpeng Li;Yun Fu,li.kai.gml@gmail.com;yulun100@gmail.com;kunpengli@ece.neu.edu;yunfu@ece.neu.edu,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Northeastern University;Northeastern University;Northeastern University;Northeastern University,few-shot learning;generative adversarial networks;,-1;16;16;16,-1;906;906;906,m;m,usa,usa,n,6;5;4
5450,ICLR,2020,Hardware-aware One-Shot Neural Architecture Search in Coordinate Ascent Framework,Li Lyna Zhang;Yuqing Yang;Yuhang Jiang;Wenwu Zhu;Yunxin Liu,lzhani@microsoft.com;yuqing.yang@microsoft.com;jyh17@mails.tsinghua.edu.cn;wwzhu@tsinghua.edu.cn;yunxin.liu@microsoft.com,3;1;6,,Withdrawn,0,0,,yes,9/25/19,"Microsoft;Microsoft;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Microsoft",Neural Architecture Search;Hardware Diversity;Search Space;,-1;-1;4;4;-1,-1;-1;23;23;-1,f;m,NAN,NAN,n,
5451,ICLR,2020,Multi-task Network Embedding with Adaptive Loss Weighting,Fatemeh Salehi Rizi;Michael Granitzer,fatemeh.salehirizi@uni-passau.de;michael.granitzer@uni-passau.de,3;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Passau;University of Passau,,316;316,252;252,f;m,europe,de,n,
5452,ICLR,2020,Perception-Driven Curiosity with Bayesian Surprise,Bernadette Bucher;Anton Arapin;Ramanan Sekar;Marc Badger;Feifei Duan;Oleh Rybkin;Kostas Daniilidis,bucherb@seas.upenn.edu;aarapin@fandm.edu;ramanans@seas.upenn.edu;mbadger@seas.upenn.edu;feifeid@seas.upenn.edu;oleh@seas.upenn.edu;kostas@seas.upenn.edu,1;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Pennsylvania;Franklin & Marshall College;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,deep reinforcement learning;exploration;curiosity;variational methods;deep autoencoders;,20;-1;20;20;20;20;20,11;-1;11;11;11;11;11,f;m,usa,usa,n,
5453,ICLR,2020,Global reasoning network for image super-resolution,Jiahui Zhang;Bin Zhou;Qingchang Tao;Deqiang Wang,jhzhang988@gmail.com;binzhou@sdu.edu.cn;taoqingchang@mail.tsinghua.edu.cn;wdq_sdu@sdu.edu.cn,1;3;3,,Withdrawn,1,2,,yes,9/25/19,"Shandong University;Shandong University;Tsinghua University, Tsinghua University;Shandong University",Global reasoning network;upsampling module;graph model;image super-resolution;,-1;143;4;143,-1;658;23;658,u;u,asia,cn,n,10
5454,ICLR,2020,MUSE: Multi-Scale Attention Model for Sequence to Sequence Learning,Guangxiang Zhao;Xu Sun;Jingjing Xu;Zhiyuan Zhang;Liangchen Luo,1701214310@pku.edu.cn;xusun@pku.edu.cn;jingjingxu@pku.edu.cn;zzy1210@pku.edu.cn;luolc@pku.edu.cn,3;3;3,,Withdrawn,0,6,,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;Peking University,Attention;Sequence to sequence learning;Deep neural networks;Machine Translation;Natural Language Processing;,14;14;14;14;14,24;24;24;24;24,m;m,asia,cn,n,8;3
5455,ICLR,2020,Utility Analysis of Network Architectures for 3D Point Cloud Processing,Shikun Huang;Binbin Zhang;Wen Shen;Zhihua Wei;Quanshi Zhang,hsk@tongji.edu.cn;0206zbb@tongji.edu.cn;1810068@tongji.edu.cn;zhihua_wei@tongji.edu.cn;zqs1022@sjtu.edu.cn,6;3;1,,Withdrawn,0,3,,yes,9/25/19,Tongji University;Tongji University;Tongji University;Tongji University;Shanghai Jiao Tong University,3D Point Cloud Processing;Interpretability;Deep Learning;,316;316;316;316;30,441;441;441;441;157,m;m,asia,cn,n,1;4
5456,ICLR,2020,Reducing Sentiment Bias in Language Models via Counterfactual Evaluation,Po-Sen Huang;Huan Zhang;Ray Jiang;Robert Stanforth;Johannes Welbl;Jack Rae;Vishal Maini;Dani Yogatama;Pushmeet Kohli,posenhuang@google.com;huan@huan-zhang.com;rayjiang@google.com;stanforth@google.com;j.welbl@cs.ucl.ac.uk;jwrae@google.com;vmaini@google.com;dyogatama@google.com;pushmeet@google.com,3;3;3,,Withdrawn,0,6,,yes,9/25/19,Google;Carnegie Mellon University;Google;Google;University College London;Google;Google;Google;Google,language model;fairness;counterfactual analysis;sentiment analysis;,-1;1;-1;-1;52;-1;-1;-1;-1,-1;27;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3;7
5457,ICLR,2020,BERT for Sequence-to-Sequence Multi-Label Text Classification,Ramil Yarullin;Pavel Serdyukov,ramly@ya.ru;pavel.serdyukov@gmail.com,3;3;1,,Withdrawn,0,4,,yes,9/25/19,Yandex;Yandex,Multi-Label Text Classification;Sequence-to-Sequence Learning;BERT;Sequence Generation;Hierarchical Text Classification;,-1;-1,-1;-1,m;m,asia,in,n,
5458,ICLR,2020,Boosting Generative Models by Leveraging Cascaded Meta-Models,Fan Bao;Hang Su;Jun Zhu,bf19@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,1;6;1,,Withdrawn,0,0,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Probabilistic Machine Learning;Learning Generative Models;Unsupervised Learning;,4;4;4,23;23;23,m;m,NAN,NAN,y,1;5
5459,ICLR,2020,RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers,Bailin Wang*;Richard Shin*;Xiaodong Liu;Oleksandr Polozov;Matthew Richardson,bailin.wang@ed.ac.uk;ricshin@cs.berkeley.edu;xiaodl@microsoft.com;polozov@microsoft.com;mattri@microsoft.com,6;1;3,,Withdrawn,0,4,,yes,9/25/19,University of Edinburgh;University of California Berkeley;Microsoft;Microsoft;Microsoft,semantic parsing;text-to-sql;self-attention;program synthesis;transformer;representation learning;natural language processing;,36;-1;-1;-1;-1,30;13;-1;-1;-1,m;m,NAN,NAN,n,3;8;1
5460,ICLR,2020,Shape Features Improve General Model Robustness,Chaowei Xiao;Mingjie Sun;Haonan Qiu;Han Liu;Mingyan Liu;Bo Li,xiaocw@umich.edu;mingjies@andrew.cmu.edu;haonanqiu@link.cuhk.edu.cn;hanliu@northwestern.edu;mingyan@umich.ed;lxbosky@gmail.com,1;1;6,,Withdrawn,0,0,,yes,9/25/19,"University of Michigan;Carnegie Mellon University;The Chinese University of Hong Kong, Shenzhen;Northwestern University;;University of California Berkeley",adversarial machine learning;robustness;backdoor attacks;,7;1;46;46;-1;-1,21;27;35;22;-1;13,m;f,usa,usa,n,8;5;4
5461,ICLR,2020,The Secret Revealer: Generative Model Inversion Attacks Against Deep Neural Networks,Yuheng Zhang;Ruoxi Jia;Hengzhi Pei;Wenxiao Wang;Bo Li;Dawn Song,16307130075@fudan.edu.cn;ruoxijia@berkeley.edu;hzpei16@fudan.edu.cn;wangwx16@mails.tsinghua.edu.cn;lxbosky@gmail.com,6;1;3,,Withdrawn,0,0,,yes,9/25/19,"Fudan University;University of California Berkeley;Fudan University;Tsinghua University, Tsinghua University;University of California Berkeley",Model inversion attack;privacy;deep learning;,73;-1;73;4;-1,109;13;109;23;13,m;f,usa,usa,y,2;1;5;4
5462,ICLR,2020,Common sense and Semantic-Guided Navigation via Language in Embodied Environments,Dian Yu;Chandra Khatri;Alexandros Papangelis;Mahdi Namazifar;Andrea Madotto;Huaixiu Zheng;Gokhan Tur,dian.yu@uber.com;chandrak@uber.com;apapangelis@uber.com;mahdin@uber.com;amadotto@connect.ust.hk;huaixiu.zheng@uber.com;gokhan@uber.com,1;1;3,,Withdrawn,0,0,,yes,9/25/19,Uber;Uber;Uber;Uber;The Hong Kong University of Science and Technology;Uber;Uber,,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;47;-1;-1,f;m,southamerica,br,n,
5463,ICLR,2020,TransINT: Embedding Implication Rules in Knowledge Graphs with Isomorphic Intersections of Linear Subspaces,So Yeon Min;Preethi Raghavan;Peter Szolovits,symin95@mit.edu;praghav@us.ibm.com;psz@mit.edu,3;3;1,,Withdrawn,2,3,,yes,9/25/19,Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology,Knowledge Graph Embedding;Knowledge Graph;Common Sense;Rules;Isomorphic Embedding;Isomorphism;Semantics Mining;Rule Mining;,5;-1;5,5;-1;5,u;m,usa,usa,y,10
5464,ICLR,2020,Meta Label Correction for Learning with Weak Supervision,Guoqing Zheng;Ahmed Hassan Awadallah;Susan Dumais,zheng@microsoft.com;hassanam@microsoft.com;sdumais@microsoft.com,3;3;8;1,,Withdrawn,0,1,,yes,9/25/19,Microsoft;Microsoft;Microsoft,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,6
5465,ICLR,2020,Towards Effective and Efficient Zero-shot Learning by Fine-tuning with  Task Descriptions,Tian Jin*;Zhun Liu*;Shengjia Yan;Alexandre Eichenberger;Louis-Philippe Morency,tian.jin1@ibm.com;zhunl@andrew.cmu.edu;sjyan@nyu.edu;alexe@us.ibm.com;morency@cs.cmu.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,International Business Machines;Carnegie Mellon University;New York University;International Business Machines;Carnegie Mellon University,zero-shot learning;meta-learning;convolutional neural;dynamic parameter generation;,-1;1;22;-1;1,-1;27;29;-1;27,u;m,usa,usa,n,6;3
5466,ICLR,2020,Multi-hop Question Answering via Reasoning Chains,Jifan Chen;Shih-ting Lin;Greg Durrett,jfchen@cs.utexas.edu;j0717lin@gmail.com;gdurrett@cs.utexas.edu,6;3;3,,Withdrawn,0,4,,yes,9/25/19,"University of Texas, Austin;;University of Texas, Austin",natural language processing;question answering;multi-hop reasoning;reasoning chain extraction;,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,
5467,ICLR,2020,Factorized Multimodal Transformer for Multimodal Sequential Learning,Amir Zadeh;Chengfeng Mao;Jiaxin Shi;Yiwei Zhang;Paul Pu Liang;Soujanya Poria;Louis-Philippe Morency,abagherz@andrew.cmu.edu;chengfem@andrew.cmu.edu;jiaxins1@andrew.cmu.edu;yiweizh2@andrew.cmu.edu;pliang@cs.cmu.edu;sporia@ntu.edu.sg;morency@cs.cmu.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Nanyang Technological University;Carnegie Mellon University,Multimodal Machine Learning;Multimodal Transformer;Multimodal Language;Sentiment Analysis;Emotion Recognition;,1;1;1;1;1;43;1,27;27;27;27;27;49;27,m;m,usa,usa,n,8;1
5468,ICLR,2020,Faster and Just As Accurate: A Simple Decomposition for Transformer Models,Qingqing Cao;Harsh Trivedi;Aruna Balasubramanian;Niranjan Balasubramanian,qicao@cs.stonybrook.edu;hjtrivedi@cs.stonybrook.edu;arunab@cs.stonybrook.edu;niranjan@cs.stonybrook.edu,6;3;3,,Withdrawn,1,4,,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook",Faster Inference;Transformers;Pre-trained Representations;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
5469,ICLR,2020,Learning Function-Specific Word Representations,Daniela Gerz;Ivan Vuliƒá;Marek Rei;Roi Reichart;Anna Korhonen,dsg40@cam.ac.uk;iv250@cam.ac.uk;marek.rei@cl.cam.ac.uk;roiri@technion.ac.il;alk23@cam.ac.uk,3;6;3,,Withdrawn,0,0,,yes,9/25/19,"University of Cambridge;University of Cambridge;University of Cambridge;Technion, Technion;University of Cambridge",representation learning;associations;word embeddings;SVO;thematic fit;selectional preference;,79;79;79;27;79,3;3;3;-1;3,f;f,europe,uk,n,
5470,ICLR,2020,Attention over Parameters for Dialogue Systems,Andrea Madotto;Zhaojiang Lin;Chien-Sheng Wu;Jamin Shin;Pascale Fung,amadotto@connect.ust.hk;zlinao@connect.ust.hk;wu.jason@salesforce.com;jay.shin@connect.ust.hk;pascale@ece.ust.hk,1;3;1,,Withdrawn,0,3,,yes,9/25/19,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;SalesForce.com;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,end-to-end dialogue systems;natural language processing;,-1;-1;-1;-1;-1,47;47;-1;47;47,f;f,NAN,NAN,n,8
5471,ICLR,2020,"RL-ST: Reinforcing Style, Fluency and Content Preservation for Unsupervised Text Style Transfer",Bhargav Upadhyay;Akhilesh Sudhakar;Arjun Maheswaran,bhargav@agaralabs.com;akhilesh@agaralabs.com;arjun@agaralabs.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Agara;Agara;Agara,style transfer;text generation;reinforcement learning;sentiment transfer;RL;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;3
5472,ICLR,2020,Extreme Language Model Compression with Optimal Subwords and Shared Projections,Sanqiang Zhao;Raghav Gupta;Yang Song;Denny Zhou,sanqiang.zhao@pitt.edu;raghavgupta@google.com;yangso@google.com;dennyzhou@google.com,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of Pittsburgh;Google;Google;Google,NLP;BERT;Knowledge Distillation;Model Compression;Language Modeling;,79;-1;-1;-1,113;-1;-1;-1,m;m,NAN,NAN,n,3
5473,ICLR,2020,Distilling the Knowledge of BERT for Text Generation,Yen-Chun Chen;Zhe Gan;Yu Cheng;Jingzhou Liu;Jingjing Liu,yen-chun.chen@microsoft.com;zhe.gan@microsoft.com;yu.cheng@microsoft.com;jingzhol@andrew.cmu.edu;jingjl@microsoft.com,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Microsoft;Carnegie Mellon University;Microsoft,text generation;neural machine translation;abstractive summarization;,-1;-1;-1;1;-1,-1;-1;-1;27;-1,m;f,NAN,NAN,n,8;3
5474,ICLR,2020,DCTD: Deep Conditional Target Densities for Accurate Regression,Fredrik K. Gustafsson;Martin Danelljan;Goutam Bhat;Thomas B. Sch√∂n,fredrik.gustafsson@it.uu.se;martin.danelljan@vision.ee.ethz.ch;goutam.bhat@vision.ee.ethz.ch;thomas.schon@it.uu.se,3;6;1,,Withdrawn,0,0,,yes,9/25/19,Uppsala University;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Uppsala University,Computer vision;deep learning;regression;object detection;visual tracking;,194;-1;-1;194,102;-1;-1;102,m;m,europe,se,n,2
5475,ICLR,2020,A Gradient-based Architecture HyperParameter Optimization Approach,Zechun Liu;Xiangyu Zhang;Zhe Li;Yichen Wei;Kwang-Ting Cheng;Jian Sun,zliubq@connect.ust.hk;zhangxiangyu@megvii.com;lizhe@megvii.com;weiyichen@megvii.com;timcheng@ust.hk;sunjian@megvii.com,3;1;3,,Withdrawn,0,0,,yes,9/25/19,The Hong Kong University of Science and Technology;Megvii Technology Inc.;Megvii Technology Inc.;Megvii Technology Inc.;The Hong Kong University of Science and Technology;Megvii Technology Inc.,gradient-based;neural architecture search;architecture hyperparameter optimization;,-1;-1;-1;-1;-1;-1,47;-1;-1;-1;47;-1,f;m,NAN,NAN,n,
5476,ICLR,2020,Generalizing Natural Language Analysis through Span-relation Representations,Zhengbao Jiang;Wei Xu;Jun Araki;Graham Neubig,zhengbaj@cs.cmu.edu;weixu@cse.ohio-state.edu;jun.araki@us.bosch.com;gneubig@cs.cmu.edu,3;3;6,,Withdrawn,0,1,,yes,9/25/19,Carnegie Mellon University;;Bosch;Carnegie Mellon University,Span-Relation Representation;Task-Independent Framework;Natural Language Analysis;Benchmark;,1;-1;-1;1,27;-1;297;27,m;m,usa,usa,n,3
5477,ICLR,2020,On the Distribution of Penultimate Activations of Classification Networks,Minkyo Seo;Yoonho Lee;Suha Kwak,mkseo@postech.ac.kr;einet89@gmail.com;suha.kwak@postech.ac.kr,1;3;3,,Withdrawn,0,0,,yes,9/25/19,POSTECH;AITRICS;POSTECH,,118;-1;118,146;-1;146,m;m,asia,kr,n,5
5478,ICLR,2020,Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control,Yu-Wei Chao;Jimei Yang;Weifeng Chen;Jia Deng,ychao@nvidia.com;jimyang@adobe.com;wfchen@umich.edu;jiadeng@princeton.edu,3;3;1,,Withdrawn,0,0,,yes,9/25/19,NVIDIA;Adobe Systems;University of Michigan;Princeton University,physics-based motion synthesis;hierarchical reinforcement learning;motion capture data;,-1;-1;7;30,-1;-1;21;6,m;m,usa,usa,n,
5479,ICLR,2020,"Unsupervised Few-shot Object Recognition by Integrating Adversarial, Self-supervision, and Deep Metric Learning of Latent Parts",Khoi Nguyen;Sinisa Todorovic,nguyenkh@oregonstate.edu;sinisa@oregonstate.edu,1;1;3,,Withdrawn,0,0,,yes,9/25/19,Oregon State University;Oregon State University,Unsupervised Few-shot Learning;Deep Metric Learning;Self-supervised Learning;,79;79,373;373,m;m,usa,usa,n,6;5;4
5480,ICLR,2020,BERT Wears GloVes: Distilling Static Embeddings from Pretrained Contextual Representations,Rishi Bommasani;Kelly Davis;Claire Cardie,rb724@cornell.edu;kdavis@mozilla.com;cardie@cs.cornell.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Cornell University;Mozilla;Cornell University,Pretrained Word Representations;Lightweight Representations;NLP;Social Bias;Word Embeddings;,7;-1;7,19;-1;19,m;f,usa,usa,n,3
5481,ICLR,2020,Mixed Setting Training Methods for Incremental Slot-Filling Tasks,Daniel C. Michelin;Jonathan K. Kummerfeld;Kevin Leach;Stefan Larson;Yunqi Zhang;Joeseph J. Peper,daniel@clinc.com;jkk@clinc.com;kevin.leach@clinc.com;slars@clinc.com;yunqi@clinc.com;joe@clinc.com,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Clinc;Clinc;Clinc;Clinc;Clinc;Clinc,incremental learning;slot-filling;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5482,ICLR,2020,PLEX: PLanner and EXecutor for Embodied Learning in Navigation,Gil Avraham;Yan Zuo;Tom Drummond,gil.avraham@monash.edu;yan.zuo@monash.edu;tom.drummond@monash.edu,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Monash University;Monash University;Monash University,Hierarchical Reinforcement Learning;Embodied Learning;Navigation;,92;92;92,75;75;75,m;m,australasia,au,y,
5483,ICLR,2020,UniLoss: Unified Surrogate Loss by Adaptive Interpolation,Lanlan Liu;Mingzhe Wang;Jia Deng,llanlan@umich.edu;mingzhew@cs.princeton.edu;jiadeng@princeton.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,University of Michigan;Princeton University;Princeton University,,7;30;30,21;6;6,f;m,usa,usa,n,
5484,ICLR,2020,MobileBERT: Task-Agnostic Compression of BERT by Progressive Knowledge Transfer,Zhiqing Sun;Hongkun Yu;Xiaodan Song;Renjie Liu;Yiming Yang;Denny Zhou,zhiqings@andrew.cmu.edu;hongkuny@google.com;xiaodansong@google.com;renjieliu@google.com;yiming@cs.cmu.edu;dennyzhou@google.com,6;3;3;3,,Withdrawn,0,8,,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Carnegie Mellon University;Google,BERT;knowledge transfer;model compression;,1;-1;-1;-1;1;-1,27;-1;-1;-1;27;-1,m;m,NAN,NAN,n,8;3
5485,ICLR,2020,Interactive Classification by Asking Informative Questions,Lili Yu;Howard Chen;Sida I. Wang;Yoav Artzi and Tao Lei,liliyu@asapp.com;hchen@asapp.com;sidaw@cs.princeton.edu;yoav@cs.cornell.edu;tao@asapp.com,6;1;3,,Withdrawn,0,0,,yes,9/25/19,ASAPP Inc.;ASAPP Inc.;Princeton University;Cornell University;ASAPP Inc.,NLP;interactive classification;interactive system;text classification;data collection;,-1;-1;30;7;-1,-1;-1;6;19;-1,f;m,NAN,NAN,n,3
5486,ICLR,2020,Cross-Lingual Vision-Language Navigation,An Yan;Xin Wang;Jiangtao Feng;Lei Li;William Wang,ayan@ucsd.edu;xwang@cs.ucsb.edu;fengjiangtao@bytedance.com;lileilab@bytedance.com;william@cs.ucsb.edu,6;3;1,,Withdrawn,0,0,,yes,9/25/19,"University of California, San Diego;UC Santa Barbara;ByteDance;ByteDance;UC Santa Barbara",Vision-Language Navigation;Cross-lingual Representation Learning;Cross-lingual Adaptation;,-1;-1;-1;-1;-1,31;-1;-1;-1;-1,f;m,NAN,NAN,n,6;3;4
5487,ICLR,2020,Single Deep Counterfactual Regret Minimization,Eric Steinberger,ericsteinberger.est@gmail.com,3;6;1,,Withdrawn,0,1,,yes,9/25/19,0,Game Theory;Deep Reinforcement Learning;Counterfactual Regret Minimization;Imperfect Information Games;Games;Poker;Nash Equilibrium;,,,m,NAN,NAN,y,
5488,ICLR,2020,I love your chain mail! Making knights smile in a fantasy game world,Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Emily Dinan;Douwe Kiela;Jason Weston;Arthur Szlam,sprabhum@cs.cmu.edu;margaretli@fb.com;jju@fb.com;edinan@fb.com;dkiela@fb.com;jase@fb.com;aszlam@fb.com,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,reinforcement learning;dialogue systems;goal-oriented chit-chat;,1;-1;-1;-1;-1;-1;-1,27;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
5489,ICLR,2020,DOUBLE-HARD DEBIASING: TAILORING WORD EMBEDDINGS FOR GENDER BIAS MITIGATION,Tianlu Wang;Xi Victoria Lin;Nazneen Fatema Rajani;Vicente Ordonez;Caimng Xiong,tianlu@virginia.edu;xilin@salesforce.com;nazneen.rajani@salesforce.com;vicente@virginia.edu;cxiong@salesforce.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Virginia;SalesForce.com;SalesForce.com;University of Virginia;SalesForce.com,Gender bias;Word embeddings;,52;-1;-1;52;-1,107;-1;-1;107;-1,f;m,NAN,NAN,n,3;7
5490,ICLR,2020,Joint text classification on multiple levels with multiple labels,Miruna P√Æslar;Marek Rei,miruna.pislar@gmail.com;marek.rei@cl.cam.ac.uk,1;3;1,,Withdrawn,0,3,,yes,9/25/19,DeepMind;University of Cambridge,multi-head attention;zero-shot learning;multi-task learning;text classification;sequence labeling;,-1;79,-1;3,f;m,europe,uk,n,6;8;3
5491,ICLR,2020,Discrete Transformer,Jambay Kinley;Yuntian Deng;Alexander M. Rush,j_kinley@college.harvard.edu;dengyuntian@seas.harvard.edu;arush@cornell.edu,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Harvard University;Harvard University;Cornell University,transformer;natural language processing;attention;,52;52;7,7;7;19,m;m,usa,usa,n,3;8;1
5492,ICLR,2020,Pragmatic Evaluation of Adversarial Examples in Natural Language,John Morris;Eli Lifland;Ji Gao;Jack Lanchantin;Yangfeng Ji;Yanjun Qi,jm8wx@virginia.edu;edl9cy@virginia.edu;jg6yd@virginia.edu;jjl5sw@virginia.edu;yj3fs@virginia.edu;yq2h@virginia.edu,6;3;3,,Withdrawn,1,3,,yes,9/25/19,University of Virginia;University of Virginia;University of Virginia;University of Virginia;University of Virginia;University of Virginia,adversarial examples;natural language processing;analysis;,52;52;52;52;52;52,107;107;107;107;107;107,m;f,usa,usa,n,3;4
5493,ICLR,2020,Question Generation from Paragraphs: A Tale of Two Hierarchical Models,Vishwajeet Kumar;Raktim Chaki;Sai Teja Talluri;Ganesh Ramakrishnan;Yuan-Fang Li;Gholamreza Haffari,vishwajeet@cse.iitb.ac.in;raktimchaki@cse.iitb.ac.in;saiteja.talluri@gmail.com;ganesh@cse.iitb.ac.in;yuanfang.li@monash.edu;gholamreza.haffari@monash.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;;Indian Institute of Technology Bombay;Monash University;Monash University,Question Generation;Hierarchical models;Transformer;BiLSTM;LSTM;,-1;-1;-1;-1;92;92,480;480;-1;480;75;75,m;m,australasia,au,n,8
5494,ICLR,2020,Should All Cross-Lingual Embeddings Speak English?,Antonios Anastasopoulos;Graham Neubig,aanastas@andrew.cmu.edu;gneubig@cs.cmu.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,multilingual embeddings;cross-lingual embeddings;under-represented languages;,1;1,27;27,m;m,usa,usa,n,3
5495,ICLR,2020,Couple-VAE: Mitigating the Encoder-Decoder Incompatibility in Variational Text Modeling with Coupled Deterministic Networks,Chen Wu;Prince Zizhuang Wang;William Yang Wang,wu-c16@mails.tsinghua.edu.cn;zizhuang_wang@ucsb.edu;william@cs.ucsb.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University, Tsinghua University;UC Santa Barbara;UC Santa Barbara",variational autoencoders;posterior collapse;text modeling;amortized variational inference;,4;-1;-1,23;-1;-1,m;m,NAN,NAN,n,5
5496,ICLR,2020,Task-agnostic Continual Learning via Growing Long-Term Memory Networks,Germ√°n Kruszewski;Ionut Teodor Sorodoc;Tomas Mikolov,germank@gmail.com;ionutteodor.sorodoc@upf.edu;tmikolov@fb.com,6;6;3,,Withdrawn,0,0,,yes,9/25/19,Naver Labs Europe;Universitat Pompeu Fabra;Facebook,growing;long term memory;continual learning;catastrophic forgetting;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2;3
5497,ICLR,2020,Exploring the Pareto-Optimality between Quality and Diversity in Text Generation,Jianing Li;Yanyan Lan;Jiafeng Guo;Xueqi Cheng,lijianing@ict.ac.cn;lanyanyan@ict.ac.cn;guojiafeng@ict.ac.cn;cxq@ict.ac.cn,1;3;3,,Withdrawn,0,3,,yes,9/25/19,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",text generation;quality;diversity;,30;30;30;30,-1;-1;-1;-1,u;m,NAN,NAN,y,1
5498,ICLR,2020,An Empirical Study of Encoders and Decoders in Graph-Based Dependency Parsing,Ge Wang;Ziyuan Hu;Zechuan Hu;Kewei Tu,wangge@shanghaitech.edu.cn;huzy@shanghaitech.edu.cn;huzch@shanghaitech.edu.cn;tukw@shanghaitech.edu.cn,3;3,,Withdrawn,0,0,,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;ShanghaiTech University,dependency parsing;high order decoding;empirical study;,316;316;316;316,-1;-1;-1;-1,m;m,asia,cn,n,
5499,ICLR,2020,Hierarchical Summary-to-Article Generation,Wangchunshu Zhou;Tao Ge;Ke Xu;Furu Wei;Ming Zhou,v-waz@microsoft.com;tage@microsoft.com;kexu@nlsde.buaa.edu.cn;fuwei@microsoft.com;mingzhou@microsoft.com,3;3;3,,Withdrawn,0,4,,yes,9/25/19,Microsoft;Microsoft;Beihang University;Microsoft;Microsoft,text generation;reinforcement learning;hierarchical generation;,-1;-1;102;-1;-1,-1;-1;594;-1;-1,m;m,NAN,NAN,n,3
5500,ICLR,2020,Anomaly Detection by Deep Direct Density Ratio Estimation,Masahiro Abe;Masashi Sugiyama,masahiro.abe@d2c.co.jp;sugi@k.u-tokyo.ac.jp,3;3;3,,Withdrawn,0,0,,yes,9/25/19,The University of Tsukuba;The University of Tokyo,anomaly detection;density ratio estimation;neural networks;,-1;64,-1;36,m;m,NAN,NAN,n,
5501,ICLR,2020,Generating Biased Datasets for Neural Natural Language Processing,Alvin Chan;Yi Tay;Yew Soon Ong;Aston Zhang,guoweial001@e.ntu.edu.sg;ytay017@e.ntu.edu.sg;asysong@ntu.edu.sg;astonz@amazon.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Amazon,bias;natural language processing;text classification;natural language inference;,43;43;43;-1,49;49;49;-1,m;m,NAN,NAN,n,3;5;7
5502,ICLR,2020,3D-SIC: 3D Semantic Instance Completion for RGB-D Scans,Ji Hou;Angela Dai;Matthias Niessner,ji.hou@tum.de;angela.dai@tum.de;niessner@tum.de,6;3;3,,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,3d reconstruction;rgb-d scanning;3d learning;3d scene understanding;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5503,ICLR,2020,Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation,Bo Pang;Erik Nijkamp;Wenjuan Han;Alex Zhou,bopang@g.ucla.edu;erik.nijkamp@gmail.com;hanwj0309@gmail.com;alexzhou907@gmail.com,1;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Los Angeles;;;ShanghaiTech University",open-dialogue system;generation evaluation;natural language processing;,-1;-1;-1;-1,17;-1;-1;-1,m;m,asia,in,n,8;3
5504,ICLR,2020,Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders,Zixia Jia;Youmi Ma;Jiong Cai;Kewei Tu,jiazx@shanghaitech.edu.cn;maym@shanghaitech.edu.cn;caijiong@shanghaitech.edu.cn;tukw@shanghaitech.edu.cn,3;6;3,,Withdrawn,0,0,,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;ShanghaiTech University,Semi-Supervised Learning;Semantic Dependency Parsing;CRF Autoencoder;Natural Language Processing;,316;316;316;316,-1;-1;-1;-1,m;m,asia,cn,n,10;5
5505,ICLR,2020,A Syntax-Aware Approach for Unsupervised Text Style Transfer,Yun Ma;Yangbin Chen;Xudong Mao;Qing Li,mayun371@gmail.com;robinchen2-c@my.cityu.edu.hk;xudong.xdmao@gmail.com;qing-prof.li@polyu.edu.hk,3;3;3,,Withdrawn,0,1,,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Xiamen University;The Hong Kong Polytechnic University,,-1;118;-1;118,-1;171;579;171,m;m,asia,hk,n,
5506,ICLR,2020,Contextualized Sparse Representation with Rectified N-Gram Attention for Open-Domain Question Answering,Jinhyuk Lee;Minjoon Seo;Hannaneh Hajishirzi;Jaewoo Kang,jinhyuk_lee@korea.ac.kr;minjoon@cs.washington.edu;hannaneh@washington.edu;kangj@korea.ac.kr,6;3;3,,Withdrawn,0,4,,yes,9/25/19,Korea University;University of Washington;University of Washington;Korea University,Open-Domain Question Answering;Sparse Representation;Phrase Representation;Information Retrieval;,168;11;11;168,179;26;26;179,m;m,asia,kr,n,8
5507,ICLR,2020,Recurrent Layer Attention Network,Eunseok Kim;Inwook Shim,eunseok1117@gmail.com;inugi00@gmail.com,1;3;1,,Withdrawn,2,1,,yes,9/25/19,Agency for Defense Development;Korea Advanced Institute of Science and Technology,attention mechanism;recurrent neural network;image recognition;deep learning;,-1;-1,-1;-1,u;m,asia,in,n,8;2
5508,ICLR,2020,Super-AND: A Holistic Approach to Unsupervised Embedding Learning,Sungwon Han;Yizhan Xu;Sungwon Park;Meeyoung Cha;Cheng-Te Li,lion4151@kaist.ac.kr;re6071020@gs.ncku.edu.tw;psw0416@kaist.ac.kr;mcha@ibs.re.kr;chengte@mail.ncku.edu.tw,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Peking University;Korea Advanced Institute of Science and Technology;Institute for Basic Science;Peking University,Unsupervised embedding learning;computer vision;anchor neighborhood discovery;image clustering;,-1;14;-1;-1;14,110;24;110;-1;24,m;m,asia,cn,n,
5509,ICLR,2020,Natural Language State Representation for Reinforcement Learning,Erez Schwartz;Guy Tennenholtz;Chen Tessler;Shie Mannor,erezschwartz@campus.technion.ac.il;sguyt@campus.technion.ac.il;chen.tessler@gmail.com;shiemannor@gmail.com,1;1;6,,Withdrawn,0,1,,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion;Technion, Technion",Reinforcement Learning;Natural Language;Representation Learning;Deep Learning;,27;27;27;27,-1;-1;-1;-1,m;m,NAN,NAN,n,3
5510,ICLR,2020,BEAN: Interpretable Representation Learning with Biologically-Enhanced Artificial Neuronal Assembly Regularization,Yuyang Gao;Giorgio Ascoli;Liang Zhao,ygao13@gmu.edu;ascoli@gmu.edu;lzhao9@gmu.edu,3;1;3,,Withdrawn,0,1,,yes,9/25/19,George Mason University;George Mason University;George Mason University,regularization;interpretability;bio-inspired deep learning;neuroscience;computational biology;,85;85;85,282;282;282,m;m,usa,usa,n,
5511,ICLR,2020,Revisiting Fine-tuning for Few-shot Learning,Akihiro Nakamura;Tatsuya Harada,nakamura@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,1;3;1,,Withdrawn,0,0,,yes,9/25/19,The University of Tokyo;The University of Tokyo,few-shot learning;fine-tuning;,64;64,36;36,m;m,NAN,NAN,n,6
5512,ICLR,2020,Unrestricted Adversarial Attacks For Semantic Segmentation,Guangyu Shen;Chengzhi Mao;Junfeng Yang;Baishakhi Ray,shen447@purdue.edu;cm3797@columbia.edu;junfeng@cs.columbia.edu;rayb@cs.columbia.edu,6;6;1,,Withdrawn,0,0,,yes,9/25/19,Purdue University;Columbia University;Columbia University;Columbia University,Adversarial Attacks;Semantic Segmentation;Computer Vision;,24;24;24;24,88;16;16;16,m;f,usa,usa,n,2;5;4
5513,ICLR,2020,End-to-End Multi-Domain Task-Oriented Dialogue Systems with Multi-level Neural Belief Tracker,Hung Le;Doyen Sahoo;Chenghao Liu;Nancy F. Chen;Steven C.H. Hoi,l.hung1610@gmail.com;dsahoo@salesforce.com;chliu@smu.edu.sg;nfychen@i2r.a-star.edu.sg;shoi@salesforce.com,3;3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Singapore Management University;SalesForce.com;Singapore Management University;Institute for Infocomm Research, A*STAR;SalesForce.com",task-oriented;dialogues;dialogue state tracking;end-to-end;,79;-1;79;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5514,ICLR,2020,Accelerate DNN Inference  By Inter-Operator Parallelization,Yaoyao Ding;Ligeng Zhu;Zhihao Jia;Song Han,yyding@mit.edu;ligeng@mit.edu;zhihao@cs.stanford.edu;songhan@mit.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Stanford University;Massachusetts Institute of Technology,,5;5;5;5,5;5;4;5,m;m,usa,usa,n,
5515,ICLR,2020,Posterior Control of Blackbox Generation ,Xiang Lisa Li;Alexander M. Rush,xli150@jhu.edu;srush@seas.harvard.edu,3;3;6,,Withdrawn,0,0,,yes,9/25/19,Johns Hopkins University;Harvard University,nlp;text generation;deep latent variable models;variational autoencoders;,73;52,12;7,f;m,usa,usa,n,3
5516,ICLR,2020,Learning to Generate 3D Training Data through Hybrid Gradient,Dawei Yang;Jia Deng,ydawei@umich.edu;jiadeng@princeton.edu,8;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Michigan;Princeton University,,7;30,21;6,m;m,usa,usa,n,10
5517,ICLR,2020,Learning to Learn via Gradient Component Corrections,Christian Simon;Piotr Koniusz;Richard Nock;Mehrtash Harandi,christian.simon@anu.edu.au;peter.koniusz@data61.csiro.au;richard.nock@data61.csiro.au;mehrtash.harandi@monash.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Australian National University;CSIRO;CSIRO;Monash University,meta-learning;classification;regression;,102;-1;-1;92,50;-1;-1;75,m;m,australasia,au,pdf miss,6;8
5518,ICLR,2020,Counting the Paths in Deep Neural Networks as a Performance Predictor,Michele Sasdelli;Ian Reid;Gustavo Carneiro,michele.sasdelli@adelaide.edu.au;ian.reid@adelaide.edu.au;gustavo.carneiro@adelaide.edu.au,3;1;3,,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,learning theory;deep learning;convolutional neural networks;,102;102;102,120;120;120,m;m,NAN,NAN,n,10
5519,ICLR,2020,VUSFA:Variational Universal Successor Features Approximator ,Shamane Siriwardhana;Rivindu Weerasakera;Denys J.C. Matthies;Suranga Nanayakkara,shamane@ahlab.org;rivindu@ahlab.org;denys@ahlab.org;suranga@ahlab.org,1;1;1,,Withdrawn,0,3,,yes,9/25/19,University of Auckland;;;University of Auckland,Universal Successor Features;Successor Features;Model Free Deep Reinforcement Learning;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n,6
5520,ICLR,2020,Data Annealing Transfer learning Procedure for Informal Language Understanding Tasks,Jing Gu;Yu Zhou,jkgu@ucdavis.edu;joyu@ucdavis.edu,3;3;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Davis;University of California, Davis",,-1;-1,55;55,f;f,usa,usa,n,6;3
5521,ICLR,2020,Building Hierarchical Interpretations in Natural Language via Feature Interaction Detection,Hanjie Chen;Guangtao Zheng;Yangfeng Ji,hc9mx@virginia.edu;gz5hp@virginia.edu;yangfeng@virginia.edu,3;1;1,,Withdrawn,0,1,,yes,9/25/19,University of Virginia;University of Virginia;University of Virginia,Hierarchical Interpretations;Natural Language Processing;Feature Interaction;,52;52;52,107;107;107,f;m,usa,usa,n,3
5522,ICLR,2020,Mem2Mem: Learning to Summarize Long Texts with Memory-to-Memory Transfer,Jaehong Park;Jonathan Pilault;Christopher Pal,jaehong.park@elementai.com;jonathan.pilault@elementai.com;christopher.pal@elementai.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Element AI;Element AI;Element AI,Abstractive summarization;Memory augmented networks;Memory Augmented Encoder Decoder;Memory transfer;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5523,ICLR,2020,Improving Neural Abstractive Summarization Using Transfer Learning and Factuality-Based Evaluation: Towards Automating Science Journalism,Rumen Dangovski*;Michelle Shen*;Dawson Byrd*;Li Jing*;Preslav Nakov;Marin Soljacic,rumenrd@mit.edu;mcshen99@mit.edu;dbyrd@exeter.edu;ljing@mit.edu;pnakov@qf.org.qa;soljacic@mit.edu,1;1;1,,Withdrawn,0,1,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Phillips Exeter Academy;Massachusetts Institute of Technology;IDKT-RDI QF;Massachusetts Institute of Technology,neural abstractive summarization;transfer learning;multitask learning;natural language processing;,5;5;-1;5;-1;5,5;5;-1;5;-1;5,m;m,usa,usa,n,6
5524,ICLR,2020,Higher-order Weighted Graph Convolutional Networks,Songtao Liu;Lingwei Chen;Hanze Dong;Zihao Wang;Dinghao Wu;Zengfeng Huang,stliu15@fudan.edu.cn;lvc5613@psu.edu;hdongaj@ust.hk;zzw166@psu.edu;duw12@psu.edu;huangzf@fudan.edu.cn,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Fudan University;Pennsylvania State University;The Hong Kong University of Science and Technology;Pennsylvania State University;Pennsylvania State University;Fudan University,Graph Convolutional Networks;Lasso;Classification;Higher-order neighbors;,73;43;-1;43;43;73,109;-1;47;-1;-1;109,m;m,asia,cn,y,10
5525,ICLR,2020,Distilling Neural Networks for Faster and Greener Dependency Parsing,Mark Anderson;Carlos G√≥mez-Rodr√≠guez,mark.anderson.nlp@gmail.com;carlos.gomez@udc.es,3;6;1,,Withdrawn,0,5,,yes,9/25/19,Universidade da Coru√±a;Universidade da Coru√±a,dependency parsing;efficiency;green AI;compression;distillation;syntax;NLP;,-1;-1,-1;-1,m;m,NAN,NAN,n,3
5526,ICLR,2020,From Here to There: Video Inbetweening Using Direct 3D Convolutions,Yunpeng Li;Dominik Roblek;Marco Tagliasacchi,yunpeng@google.com;droblek@google.com;mtagliasacchi@google.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Google;Google;Google,Computer vision;video generation;generative models;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,4
5527,ICLR,2020,ON SOLVING COOPERATIVE DECENTRALIZED MARL PROBLEMS WITH SPARSE REINFORCEMENTS,Rajiv Ranjan Kumar;Pradeep Varakantham,rajivrk.2017@phdis.smu.edu.sg;pradeepv@smu.edu.sg,1;6;1,,Withdrawn,0,0,,yes,9/25/19,Singapore Management University;Singapore Management University,Deep Reinforcement Learning;Cooperative Multi Agent Systems;Sparse Reward;Decentralized Decision Making;,79;79,-1;-1,m;m,asia,sg,n,
5528,ICLR,2020,On the Anomalous Generalization of GANs,Jinchen Xuan;Yunchang Yang;Ze Yang;Di He;Liwei Wang,1600012865@pku.edu.cn;1500010650@pku.edu.cn;yangze@pku.edu.cn;dihe@microsoft.com;wanglw@cis.pku.edu.cn,1;3;6,,Withdrawn,0,0,,yes,9/25/19,Peking University;Peking University;Peking University;Microsoft;Peking University,GANs;Generalization;,14;14;14;-1;14,24;24;24;-1;24,m;m,asia,cn,y,8;1;5;4
5529,ICLR,2020,Bridging the domain gap in cross-lingual document classification,Guokun Lai;Barlas Oguz;Yiming Yang;Veselin Stoyanov,guokun@cs.cmu.edu;barlaso@fb.com;yiming@cs.cmu.edu;ves@fb.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Facebook;Carnegie Mellon University;Facebook,cross-lingual;document classification;semi-supervised learning;,1;-1;1;-1,27;-1;27;-1,m;m,NAN,NAN,n,3
5530,ICLR,2020,NAMSG: An Efficient Method for Training Neural Networks,Yushu Chen;Hao Jing;Wenlai Zhao;Zhiqiang Liu;Ouyi Li;Liang Qiao;Haohuan Fu;Wei Xue;Guangwen Yang,yschen11@126.com;jinghao0320@gmail.com;cryinlaugh@gmail.com;gt_liuzq@163.com;18801087946@163.com;qiaoliang6363@163.com;haohuan@tsinghua.edu.cn;xuewei@mail.tsinghua.edu.cn;ygw@mail.tsinghua.edu.cn,3;3;1,,Withdrawn,2,4,,yes,9/25/19,"126;;;163;163;163;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",neural networks;training;adaptive methods;,-1;-1;-1;-1;-1;-1;4;4;4,-1;-1;-1;-1;-1;-1;23;23;23,f;m,NAN,NAN,y,1
5531,ICLR,2020,INTERPRETING CNN  PREDICTION THROUGH  LAYER - WISE SELECTED DISCERNIBLE NEURONS,Md Tauhid Bin Iqbal;Abdul Muqeet;Sung-Ho Bae,tauhidiq@khu.ac.kr;amuqeet@khu.ac.kr;shbae@khu.ac.kr,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,,445;445;445,319;319;319,m;m,asia,kr,n,
5532,ICLR,2020,Toward Controllable Text Content Manipulation,Shuai Lin;Wentao Wang;Zhiting Hu;Zichao Yang;Xiaodan Liang;Haoran Shi;Frank Xu;Eric Xing,shuailin97@gmail.com;wwt.cpp@gmail.com;zhitinghu@gmail.com;yangtze2301@gmail.com;xdliang328@gmail.com;haoranshi97@gmail.com;eric.xing@petuum.com,3;1;6,,Withdrawn,0,0,,yes,9/25/19,"Sun Yat-sen University;Peking University;University of California, San Diego;;;;Petuum Inc.",,-1;14;-1;-1;-1;-1;-1,-1;24;31;-1;-1;-1;-1,m;m,NAN,NAN,n,
5533,ICLR,2020,Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality Regularization and Singular Value Sparsification,Huanrui Yang;Minxue Tang;Wei Wen;Feng Yan;Daniel Hu;Ang Li;Hai Li,huanrui.yang@duke.edu;tangmx16@mails.tsinghua.edu.cn;wei.wen@duke.edu;fyan@unr.edu;danielhu2003@gmail.com;ang.li630@duke.edu;hai.li@duke.edu,3;1,,Withdrawn,0,0,,yes,9/25/19,"Duke University;Tsinghua University, Tsinghua University;Duke University;University of Nevada, Reno;;Duke University;Duke University",Deep neural network;low-rank factorization;singular value decomposition;,46;4;46;248;-1;46;46,20;23;20;-1;-1;20;20,m;f,europe,se,n,
5534,ICLR,2020,FAST LEARNING VIA EPISODIC MEMORY: A PERSPECTIVE FROM ANIMAL DECISION-MAKING,Xiaohan Zhang;Lu Liu;Guodong Long;jing jiang;Shenquan Liu,xh1315255662@gmail.com;lu.liu.cs@icloud.com;guodong.long@uts.edu.au;jing.jiang@uts.edu.au;mashqliu@scut.edu.cn,1;1,,Withdrawn,0,0,,yes,9/25/19,South China University of Technology;Icloud;University of Technology Sydney;University of Technology Sydney;South China University of Technology,neuroscience;cognitive science;memory;perception;,-1;-1;73;73;-1,-1;-1;193;193;501,f;u,NAN,NAN,pdf miss,5
5535,ICLR,2020,Improving and Stabilizing Deep Energy-Based Learning,Lifu Tu;Richard Yuanzhe Pang;Kevin Gimpel,lifu@ttic.edu;yzpang@nyu.edu;kgimpel@ttic.edu,6;1;1,,Withdrawn,0,0,,yes,9/25/19,Toyota Technological Institute at Chicago;New York University;Toyota Technological Institute at Chicago,deep structured prediction;energy-based learning;inference networks;sequence labeling;training objectives;,-1;22;-1,-1;29;-1,m;m,NAN,NAN,n,
5536,ICLR,2020,INTERPRETING CNN COMPRESSION USING INFORMATION BOTTLENECK,Hui Xiang;Feifei Shi;Peng Wang;Qigang Wang;Zhongchao Shi,xianghui1@lenovo.com;shiff3@lenovo.com;wangpeng31@lenovo.com;wangqg1@lenovo.com;shizc2@lenovo.com,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Lenovo Research;Lenovo Research;Lenovo Research;Lenovo Research;Lenovo Research,Learning Representation;Information Bottleneck;Model Compression;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,pdf miss,1
5537,ICLR,2020,Conversation Generation with Concept Flow,Houyu Zhang;Zhenghao Liu;Chenyan Xiong;Zhiyuan Liu,houyu_zhang@brown.edu;liu-zh16@mails.tsinghua.edu.cn;chenyan.xiong@microsoft.com;liuzy@tsinghua.edu.cn,6;3;3,,Withdrawn,0,0,,yes,9/25/19,"Brown University;Tsinghua University, Tsinghua University;Microsoft;Tsinghua University, Tsinghua University",Grounded Natural Language Generation;Conversation Response Generation;ConceptNet;ConceptFlow;Conversation Flow;,85;4;-1;4,53;23;-1;23,m;m,NAN,NAN,n,8;10
5538,ICLR,2020,iSOM-GSN: An Integrative Approach for Transforming Multi-omic Data into Gene Similarity Networks via Self-organizing Maps,Nazia Fatima;Johan Fernandes;Luis Rueda,fatiman@uwindsor.ca;ferna11i@uwindsor.ca;lrueda@uwindsor.ca,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Windsor;University of Windsor;University of Windsor,Gene similarity networks;self-organizing maps;convolutional neural networks;multi-omics data integration;graph representation learning;dimensionality reduction;,445;445;445,605;605;605,f;m,canada,ca,n,10
5539,ICLR,2020,Task-Agnostic Robust Encodings for Combating Adversarial Typos,Erik Jones;Robin Jia;Aditi Raghunathan;Percy Liang,erik.jones313@gmail.com;robinjia@stanford.edu;aditir@stanford.edu;pliang@cs.stanford.edu,3;3;3,,Withdrawn,0,4,,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,Natural language processing;adversarial examples;robustness;,-1;5;5;5,-1;4;4;4,m;m,usa,usa,n,3;4
5540,ICLR,2020,Natural Language Adversarial Attack and Defense in Word Level,Xiaosen Wang;Hao Jin;Kun He,xiaosen@hust.edu.cn;mailtojinhao@hust.edu.cn;brooklet60@hust.edu.cn,6;3;3,,Withdrawn,0,2,,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,adversarial examples;text adversarial defense;text adversarial attack;synonym encoding;natural language processing;,-1;-1;-1,47;47;47,m;f,NAN,NAN,n,2;3;4
5541,ICLR,2020,Randomness in Deconvolutional Networks for Visual Representation,Kun He;Jingbo Wang;Haochuan Li;Yao Shu;Liwei Wang;John E. Hopcroft,brooklet60@hust.edu.cn;jingbow@usc.edu;lhchuan@pku.edu.cn;shuyao95@gmail.com;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Hong Kong University of Science and Technology;University of Southern California;Peking University;;Peking University;Cornell University,Deep representation;random representation;untrained deconvolutional network;image reconstruction;,-1;36;14;-1;14;7,47;62;24;-1;24;19,f;m,usa,usa,y,
5542,ICLR,2020,An Inter-Layer Weight Prediction and Quantization for Deep Neural Networks based on Smoothly Varying Weight Hypothesis,Kang-Ho Lee;JoonHyun Jung;Sung-Ho Bae,ho7719@khu.ac.kr;doublejtoh@khu.ac.kr;shbae@khu.ac.kr,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,Network Compression;Quantization;Weight Prediction;,445;445;445,319;319;319,m;m,asia,kr,n,
5543,ICLR,2020,Generalized Transformation-based Gradient,Anbang Wu,wab@zju.edu.cn,3;1;6,,Withdrawn,0,3,,yes,9/25/19,Zhejiang University,variational inference;stochastic optimization;stochastic gradient;,39,107,u,asia,cn,n,1
5544,ICLR,2020,Learning Multi-facet Embeddings of Phrases and Sentences using Sparse Coding for Unsupervised Semantic Applications,Haw-Shiuan Chang;Amol Agrawal;Andrew McCallum,hschang@cs.umass.edu;amolagrawal@cs.umass.edu;mccallum@cs.umass.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",lexical semantics;sparse coding;multi-mode embeddings;unsupervised sentence embedding;clustering;set decoder;semantic similarity;,24;24;24,209;209;209,m;m,usa,usa,n,3
5545,ICLR,2020,Making DenseNet Interpretable: A Case Study in Clinical Radiology,Kwun Ho Ngan;Artur d'Avila Garcez;Karen M. Knapp;Andy Appelboam;Constantino Carlos Reyes-Aldasoro,kwun-ho.ngan@city.ac.uk;a.garcez@city.ac.uk;k.m.knapp@exeter.ac.uk;andy.appelboam@nhs.net;reyes@city.ac.uk,1;1;3,,Withdrawn,0,1,,yes,9/25/19,"City, University of London;City, University of London;University of Exeter;;City, University of London",Model Interpretation;Medical Image Analysis;Deep Learning;,248;248;316;-1;248,422;422;146;-1;422,m;m,europe,uk,n,2
5546,ICLR,2020,Learning Classifier Synthesis for Generalized Few-Shot Learning,Han-Jia Ye;Hexiang Hu;De-Chuan Zhan;Fei Sha,yehj@lamda.nju.edu.cn;hexiang.frank.hu@gmail.com;zhandc@nju.edu.cn;feisha@usc.edu,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Zhejiang University;;Zhejiang University;University of Southern California,Generalized Few-Shot Learning (GFSL);Few-Shot Learning;Meta-Learning;,39;-1;39;36,107;-1;107;62,m;m,usa,usa,n,6
5547,ICLR,2020,Restoration of Video Frames from a Single Blurred Image with Motion Understanding,Dawit Mureja Argaw;Junsik Kim;Francois Rameau;Chaoning Zhang;In so Kweon,dawitmureja@kaist.ac.kr;mibastro@gmail.com;rameau.fr@gmail.com;chaoningzhang1990@gmail.com;iskweon77@kaist.ac.kr,3;6;3,,Withdrawn,0,0,,yes,9/25/19,Korea Advanced Institute of Science and Technology;;;;Korea Advanced Institute of Science and Technology,Blur-to-Video;Motion deblurring;Encoder-Decoder;,-1;-1;-1;-1;-1,110;-1;-1;-1;110,m;m,NAN,NAN,n,8
5548,ICLR,2020,Open-Set Domain Adaptation with Category-Agnostic Clusters,Yingwei Pan;Ting Yao;Yehao Li;Chong-Wah Ngo;Tao Mei,panyw.ustc@gmail.com;tingyao.ustc@gmail.com;yehaoli.sysu@gmail.com;cscwngo@cityu.edu.hk;tmei@live.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,JD AI Research;JD AI Research;;The Hong Kong Polytechnic University;JD AI Research,Unsupervised Domain Adaptation;Open-set Domain Adaptation;Category-agnostic Clusters;,-1;-1;-1;118;-1,-1;-1;-1;171;-1,m;m,NAN,NAN,n,8;1
5549,ICLR,2020,Understanding Distributional Ambiguity via Non-robust Chance Constraint,Shumin MA;LEUNG Cheuk Hang;Qi WU;Wei Liu,shuminma@cityu.edu.hk;chleung87@cityu.edu.hk;qiwu55@cityu.edu.hk;wl2223@columbia.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Columbia University,Heavy tail distribution;Chance constraint;Distributionally robust optimization;,118;118;118;24,171;171;171;16,m;m,usa,usa,y,
5550,ICLR,2020,Simple but effective techniques to reduce dataset biases,Rabeeh Karimi Mahabadi;James Henderson,rkarimi@idiap.ch;james.henderson@idiap.ch,3;6;1,,Withdrawn,0,1,,yes,9/25/19,Idiap Research Institute;Idiap Research Institute,bias reduction;natural language inference;robust models;out-of-domain performance;,-1;-1,-1;-1,f;m,NAN,NAN,n,3
5551,ICLR,2020,EfferenceNets for latent space planning,Hlynur Dav√≠√∞ Hlynsson;Merlin Sch√ºler;Robin Schiewer;Laurenz Wiskott,hlynurd@gmail.com;merlin.schueler@ini.rub.de;robin.schiewer@ini.rub.de;laurenz.wiskott@ini.rub.de,1;1;1,,Withdrawn,0,0,,yes,9/25/19,KTH Royal Institute of Technology;Ruhr-Universt‚àö¬ßt Bochum;Ruhr-Universt‚àö¬ßt Bochum;Ruhr-Universt‚àö¬ßt Bochum,Informed Search;Deep Learning;Heuristics;Transfer Learning;Efference Theory;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1;10
5552,ICLR,2020,Mining GANs for knowledge transfer to small domains,Yaxing Wang;Abel Gonzalez-Garcia;David Berga;Luis Herranz;Fahad Shahbaz Khan;Joost van de Weijer,yaxing@cvc.uab.es;agonzalez@cvc.uab.es;dberga@cvc.uab.es;lherranz@cvc.uab.es;fahad.khan@liu.se;joost@cvc.uab.es,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Link√∂ping University;Computer Vision Center, Universitat Aut√≤noma de Barcelona",Generative adversarial networks;transferring learning;small domains;deep Learning;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;407;-1,m;m,NAN,NAN,n,8;5
5553,ICLR,2020,"EMS: End-to-End Model Search for Network Architecture, Pruning and Quantization",Tianzhe Wang;Kuan Wang;Han Cai;Ji Lin;Yujun Lin;Zhijian Liu;Song Han,usedtobe@mit.edu;wangkuan15@mails.tsinghua.edu.cn;hancai@mit.edu;jilin@mit.edu;yujunlin@mit.edu;zhijian@mit.edu;songhan@mit.edu,3;1;1,,Withdrawn,1,0,,yes,9/25/19,"Massachusetts Institute of Technology;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology",End-to-end Design;Joint Optimization;Architecture Search;Network Pruning;Network Quanzation;,5;4;5;5;5;5;5,5;23;5;5;5;5;5,m;m,usa,usa,n,
5554,ICLR,2020,Deflecting Adversarial Attacks,Yao Qin;Nicholas Frosst;Colin Raffel;Garrison Cottrell;Geoffrey Hinton,yaq007@eng.ucsd.edu;frosst@google.com;craffel@google.com;gary@eng.ucsd.edu;geoffhinton@google.com,3;3;3,,Withdrawn,0,2,,yes,9/25/19,"University of California, San Diego;Google;Google;University of California, San Diego;Google",Adversarial Examples;,-1;-1;-1;-1;-1,31;-1;-1;31;-1,f;m,NAN,NAN,n,4
5555,ICLR,2020,One Demonstration Imitation Learning,Bradly C. Stadie;Siyan Zhao;Qiqi Xu;Bonnie Li;Lunjun Zhang,bstadie@berkeley.edu;siyan.zhao@mail.utoronto.ca;frances.xu@mail.utoronto.ca;bonnieli20010901@gmail.com;lunjun.zhang@mail.utoronto.ca,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University of California Berkeley;Toronto University;Toronto University;;Toronto University,imitation learning;one shot imitation learning;reinforcement learning;exploration;representation learning;,-1;-1;-1;-1;-1,13;-1;-1;-1;-1,m;u,NAN,NAN,pdf miss,
5556,ICLR,2020,SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering,Chenguang Zhu;Michael Zeng;Xuedong Huang,chezhu@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Microsoft,Machine Reading Comprehension;Conversational Question Answering;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8
5557,ICLR,2020,Differentially Private Survival Function Estimation,Lovedeep Gondara;Ke Wang,lgondara@sfu.ca;wang@sfu.ca,1;1;3,,Withdrawn,0,1,,yes,9/25/19,Simon Fraser University;Simon Fraser University,Survival function;differential privacy;healthcare;,52;52,272;272,m;m,canada,ca,n,
5558,ICLR,2020,GPU Memory Management for Deep Neural Networks Using Deep Q-Network,Shicheng Chen,coder.chen.shi.cheng@gmail.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,0,GPU memory management;deep reinforcement learning;neural networks;,,,u,NAN,NAN,n,
5559,ICLR,2020,Meta Decision Trees for Explainable Recommendation Systems,Eyal Shulman;Lior Wolf,shulmaneyal@gmail.com;wolf@fb.com,3;8;3,,Withdrawn,0,1,,yes,9/25/19,Tel Aviv University;Facebook,,30;-1,188;-1,m;m,NAN,NAN,n,
5560,ICLR,2020,Parameterized Action Reinforcement Learning for Inverted Index Match Plan Generation,Linfeng Zhao;Lifei Zhu;Qi Chen;Hui Xue;Haidong Wang;Chuanjie Liu;Yuan Liu;Lawson Wong;Lintao Zhang,zhao.linf@husky.neu.edu;v-lifzh@microsoft.com;cheqi@microsoft.com;xuehui@microsoft.com;haidwa@microsoft.com;chuanli@microsoft.com;yuanliu@neu.edu.cn;lawsonlsw@northeastern.edu;lintaoz@microsoft.com,3;3;1,,Withdrawn,0,5,,yes,9/25/19,Northeastern University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Northeastern University;Northeastern University;Microsoft,,16;-1;-1;-1;-1;-1;16;16;-1,906;-1;-1;-1;-1;-1;906;906;-1,m;m,NAN,NAN,n,
5561,ICLR,2020,Fault Tolerant Reinforcement Learning via A Markov Game of Control and Stopping,David Mguni,davidmguni@hotmail.com,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Prowler.io,Fault-Tolerance;Robust Control;Reinforcement Learning;Stochastic Games;Markov Games;Optimal Stopping;,-1,-1,m,NAN,NAN,y,1;4
5562,ICLR,2020,Fuzzing-Based Hard-Label Black-Box Attacks Against Machine Learning Models,Yi Qin;Chuan Yue,yiqin@mines.edu;chuanyue@mines.edu,3;1;1,,Withdrawn,0,5,,yes,9/25/19,Colorado School of Mines;Colorado School of Mines,,248;248,343;343,u;m,usa,usa,n,4
5563,ICLR,2020,"Read, Highlight and Summarize: A Hierarchical Neural Semantic Encoder-based Approach",Rajeev Bhatt Ambati;Saptarashmi Bandyopadhyay;Prasenjit Mitra,rajeev24811@gmail.com;sbandyo20@gmail.com;pum10@psu.edu,3;1,,Withdrawn,0,0,,yes,9/25/19,"Pennsylvania State University;University of Maryland, College Park;Pennsylvania State University",Abstractive summarization;text summarization;memory augmented neural network;extractive summarization;self critical reinforcement learning;policy gradient;,-1;12;43,-1;91;-1,m;m,usa,usa,n,3;8;1
5564,ICLR,2020,Generalization Puzzles in Deep Networks,Qianli Liao;Brando Miranda;Lorenzo Rosasco;Andrzej Banburski;Robert Liang;Jack Hidary;Tomaso Poggio,lql@mit.edu;miranda9@illinois.edu;lrosasco@mit.edu;kappa666@mit.edu;bobliang345@gmail.com;hidary@google.com;tp@csail.mit.edu,1;1;6,,Withdrawn,0,3,,yes,9/25/19,"Massachusetts Institute of Technology;University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Google;Massachusetts Institute of Technology",deep learning;theory;generalization;cross-entropy loss;overfitting;,5;-1;5;5;-1;-1;5,5;-1;5;5;-1;-1;5,m;m,usa,usa,n,1
5565,ICLR,2020,Recurrent Chunking Mechanisms for Conversational Machine Reading Comprehension,Hongyu Gong;Yelong Shen;Dian Yu;Jianshu Chen;Dong Yu,hgong6@illinois.edu;yelongshen@tencent.com;yudian@tencent.com;jianshuchen@tencent.com;dyu@tencent.com,6;3;1,,Withdrawn,0,8,,yes,9/25/19,"University of Illinois, Urbana Champaign;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab",Recurrent Chunking Policy;Machine Reading Comprehension;Reinforcement Learning;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
5566,ICLR,2020,Rethinking Generalized Matrix Factorization for Recommendation: The Importance of Multi-hot Encoding,Lei Feng;Hongxin Wei;Qingyu Guo;Zhuoyi Lin;Bo An,feng0093@e.ntu.edu.sg;owenwei@ntu.edu.sg;qguo005@e.ntu.edu.sg;zhuoyi001@e.ntu.edu.sg;boan@ntu.edu.sg,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University,supervised representation learning;recommender systems;,43;43;43;43;43,49;49;49;49;49,m;m,asia,sg,n,
5567,ICLR,2020,Extractor-Attention Network: A New Attention Network with Hybrid Encoders for Chinese Text Classification,Junhao Qiu;Ronghua Shi;Fangfang Li (the corresponding author);Jinjing Shi;Wangmin Liao,qiujunhao@csu.edu.cn;shirh@csu.edu.cn;lifangfang@csu.edu.cn;shijinjing@csu.edu.cn;0909123117@csu.edu.cn,1;6;1,,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1;-1;-1,299;299;299;299;299,m;u,NAN,NAN,n,8
5568,ICLR,2020,Fooling Pre-trained Language Models: An Evolutionary Approach to Generate Wrong Sentences with High Acceptability Score,Marco Di Giovanni;Marco Brambilla,marco.digiovanni@polimi.it;marco.brambilla@polimi.it,3;3;1,,Withdrawn,0,6,,yes,9/25/19,Politecnico di Milano;Politecnico di Milano,Pre-trained Language Models;Adversarial Attack;Evolutionary Algorithm;BERT;RoBERTa;CoLA;,143;143,-1;-1,m;m,europe,it,n,3;1;4
5569,ICLR,2020,The Convex Information Bottleneck Lagrangian,Borja Rodr√≠guez G√°lvez;Ragnar Thobaben;Mikael Skoglund,borjarg@kth.se;ragnart@kth.se;skoglund@kth.se,3;3;1,,Withdrawn,0,5,,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",information bottleneck;representation learning;,194;194;194,222;222;222,m;m,NAN,NAN,y,1
5570,ICLR,2020,Deep Learning-Based Average Consensus,Masako Kishida;Masaki Ogura;Yuichi Yoshida;Tadashi Wadayama,kishida@nii.ac.jp;oguram@is.naist.jp;yyoshida@nii.ac.jp;wadayama@nitech.ac.jp,1;1;3,,Withdrawn,0,4,,yes,9/25/19,"National Institute of Informatics;Nara Institute of Science and Technology, Japan;National Institute of Informatics;Nagoya Institute of Technology",complex network;optimization;deep-learning;,-1;-1;-1;-1,-1;-1;-1;1157,u;m,NAN,NAN,y,10
5571,ICLR,2020,STYLE EXAMPLE-GUIDED TEXT GENERATION USING GENERATIVE ADVERSARIAL TRANSFORMERS,Kuo-Hao Zeng;Mohammad Shoeybi;Ming-Yu Liu,khzeng@cs.washington.edu;mshoeybi@nvidia.com;sean.mingyu.liu@gmail.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Washington;NVIDIA;NVIDIA,Language generation;Transformer;GANs;,11;-1;-1,26;-1;-1,m;m,asia,in,n,5
5572,ICLR,2020,GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,1;1,,Withdrawn,0,0,,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,deep learning;graph neural networks;natural language processing;reading comprehension;,248;194;248,438;-1;438,f;m,usa,usa,n,10
5573,ICLR,2020,Revisiting the Information Plane,Martin Schiemer;Juan Ye,martin.schiemer@web.de;juan.ye@st-andrews.ac.uk,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of St Andrews;University of St Andrews,Deep Learning;Information Theory;Information Bottleneck;Neural Network Design;,-1;316,-1;201,m;f,europe,uk,n,1
5574,ICLR,2020,Fully Quantized Transformer for Improved Translation,Gabriele Prato;Ella Charlaix;Mehdi Rezagholizadeh,prato.gab@gmail.com;ella.charlaix@huawei.com;mehdi.rezagholizadeh@huawei.com,3;1;3,,Withdrawn,0,3,,yes,9/25/19,University of Montreal;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Transformer;quantization;machine translation;compression;pruning;,118;-1;-1,85;-1;-1,f;m,NAN,NAN,n,8;3
5575,ICLR,2021,Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks,Yikai Wu;Xingyu Zhu;Chenwei Wu;Annie N. Wang;Rong Ge,~Yikai_Wu1;~Xingyu_Zhu1;~Chenwei_Wu1;~Annie_N._Wang1;~Rong_Ge1,4;7;4;4,4;4;5;2,Reject,0,8,0.0,yes,9/28/20,Yale University;Duke University;Duke University;Duke University;Duke University,Hessian;neural network;Kronecker factorization;PAC-Bayes bound;eigenspace;eigenvalue,71;46;46;46;46,8;20;20;20;20,m;m,europe,se,y,1
5576,ICLR,2021,Identifying Physical Law of Hamiltonian Systems via Meta-Learning,Seungjun Lee;Haesang Yang;Woojae Seong,~Seungjun_Lee1;~Haesang_Yang1;~Woojae_Seong1,7;6;7,4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Seoul National University;Seoul National University;;Seoul National University,Learning physical laws;meta-learning;Hamiltonian systems,37;37;-1;37,60;60;-1;60,m;m,asia,kr,n,6
5577,ICLR,2021,Retrieval-Augmented Generation for Code Summarization via Hybrid GNN,Shangqing Liu;Yu Chen;Xiaofei Xie;Jing Kai Siow;Yang Liu,~Shangqing_Liu1;~Yu_Chen5;~Xiaofei_Xie1;jingkai001@e.ntu.edu.sg;~Yang_Liu36,7;7;7,3;3;3,Accept (Spotlight),0,6,0.0,yes,9/28/20,Nanyang Technological University;Facebook AI;Kyushu University;;;Nanyang Technological University,Code Summarization;Graph Neural Network;Retrieval;Generation,44;-1;-1;-1;-1;44,47;-1;452;-1;-1;47,m;m,asia,sg,n,3;8;1;10
5578,ICLR,2021,Accurate Learning of Graph Representations with Graph Multiset Pooling,Jinheon Baek;Minki Kang;Sung Ju Hwang,~Jinheon_Baek1;~Minki_Kang1;~Sung_Ju_Hwang1,7;6;7;4,5;5;4;4,Accept (Poster),0,29,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Graph representation learning;Graph pooling,-1;-1;-1,96;96;96,m;m,NAN,NAN,y,8;10
5579,ICLR,2021,Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets,Hayeon Lee;Eunyoung Hyung;Sung Ju Hwang,~Hayeon_Lee1;~Eunyoung_Hyung2;~Sung_Ju_Hwang1,5;4;6,4;4;2,Accept (Poster),0,19,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Machine Learning;Neural Architecture Search;Meta-learning,-1;-1;-1,96;96;96,f;m,NAN,NAN,n,6;10
5580,ICLR,2021,Learning to Recombine and Resample Data For Compositional Generalization,Ekin Aky√ºrek;Afra Feyza Aky√ºrek;Jacob Andreas,~Ekin_Aky√ºrek1;~Afra_Feyza_Aky√ºrek1;~Jacob_Andreas1,6;7;7;8,3;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Massachusetts Institute of Technology;Boston University;Massachusetts Institute of Technology,compositional generalization;data augmentation;language processing;sequence models;generative modeling,5;79;5,4;54;4,m;m,usa,usa,n,1;5
5581,ICLR,2021,Refining Deep Generative Models via Discriminator Gradient Flow,Abdul Fatir Ansari;Ming Liang Ang;Harold Soh,~Abdul_Fatir_Ansari2;~Ming_Liang_Ang4;~Harold_Soh1,7;6;7;7;7,4;3;2;3;4,Accept (Poster),0,9,0.0,yes,9/28/20,National University of Singapore;National University of Singapore;National University of Singapore,gradient flows;generative models;GAN;VAE;Normalizing Flow,17;17;17,25;25;25,m;m,asia,sg,y,5
5582,ICLR,2021,RMSprop converges with proper hyper-parameter,Naichen Shi;Dawei Li;Mingyi Hong;Ruoyu Sun,~Naichen_Shi1;~Dawei_Li3;~Mingyi_Hong1;~Ruoyu_Sun1,6;8;8,3;3;3,Accept (Spotlight),0,3,0.0,yes,9/28/20,"University of Michigan;University of Illinois, Urbana Champaign;Iowa State University;University of Illinois, Urbana-Champaign",RMSprop;convergence;hyperparameter,7;-1;209;-1,22;-1;427;-1,u;m,usa,usa,y,1
5583,ICLR,2021,CopulaGNN: Towards Integrating Representational and Correlational Roles of Graphs in Graph Neural Networks,Jiaqi Ma;Bo Chang;Xuefei Zhang;Qiaozhu Mei,~Jiaqi_Ma1;~Bo_Chang1;~Xuefei_Zhang1;~Qiaozhu_Mei1,7;7;5;7,3;4;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,University of Michigan;Google;University of Michigan;University of Michigan Ann Arbor,Graph Neural Network;Gaussian Copula;Gaussian Graphical Model,7;-1;7;7,22;-1;22;22,m;m,NAN,NAN,n,10
5584,ICLR,2021,On Statistical Bias In Active Learning: How and When to Fix It,Sebastian Farquhar;Yarin Gal;Tom Rainforth,~Sebastian_Farquhar1;~Yarin_Gal1;~Tom_Rainforth1,7;4;7;8,4;4;3;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,Active Learning;Monte Carlo;Risk Estimation,46;46;46,1;1;1,m;m,europe,uk,y,
5585,ICLR,2021,Unsupervised Discovery of 3D Physical Objects from Video,Yilun Du;Kevin A. Smith;Tomer Ullman;Joshua B. Tenenbaum;Jiajun Wu,~Yilun_Du1;~Kevin_A._Smith1;~Tomer_Ullman1;~Joshua_B._Tenenbaum1;~Jiajun_Wu1,6;5;6;6,4;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Stanford University,unsupervised object discovery;surprisal;scene decomposition;physical scene understanding,5;5;-1;5;5;5,4;4;-1;4;4;2,m;m,usa,usa,n,
5586,ICLR,2021,CPT: Efficient Deep Neural Network Training via Cyclic Precision,Yonggan Fu;Han Guo;Meng Li;Xin Yang;Yining Ding;Vikas Chandra;Yingyan Lin,~Yonggan_Fu1;hg31@rice.edu;meng.li@fb.com;xy33@rice.edu;yd31@rice.edu;~Vikas_Chandra2;~Yingyan_Lin1,7;7;7;7,3;3;5;5,Accept (Spotlight),0,6,0.0,yes,9/28/20,"Rice University;, Rice University;Facebook;Rice University;;;Facebook;Rice University",Efficient training;low precision training,92;92;-1;92;-1;-1;-1;92,124;124;-1;124;-1;-1;-1;124,m;f,australasia,au,n,3;8;1
5587,ICLR,2021,Learning from Protein Structure with Geometric Vector Perceptrons,Bowen Jing;Stephan Eismann;Patricia Suriana;Raphael John Lamarre Townshend;Ron Dror,~Bowen_Jing1;~Stephan_Eismann1;psuriana@stanford.edu;~Raphael_John_Lamarre_Townshend1;~Ron_Dror1,7;10;6;6,3;4;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,structural biology;graph neural networks;proteins;geometric deep learning,5;5;5;5;5,2;2;2;2;2,m;m,usa,usa,n,10
5588,ICLR,2021,Learning Neural Generative Dynamics for Molecular Conformation Generation,Minkai Xu;Shitong Luo;Yoshua Bengio;Jian Peng;Jian Tang,~Minkai_Xu1;~Shitong_Luo1;~Yoshua_Bengio1;~Jian_Peng1;~Jian_Tang1,7;6;6,4;3;3,Accept (Poster),0,7,0.0,yes,9/28/20,University of Montreal;Peking University;University of Montreal;Univ. of Illinois at Urbana-Champaign;HEC Montreal,Molecular conformation generation;deep generative models;continuous normalizing flow;energy-based models,128;14;128;2;-1,73;23;73;-1;-1,m;m,canada,ca,n,10;5
5589,ICLR,2021,Long-tailed Recognition by Routing Diverse Distribution-Aware Experts,Xudong Wang;Long Lian;Zhongqi Miao;Ziwei Liu;Stella Yu,~Xudong_Wang4;~Long_Lian1;~Zhongqi_Miao1;~Ziwei_Liu1;~Stella_Yu2,7;7;8;7,4;4;5;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,"Electrical Engineering & Computer Science Department, University of California Berkeley;University of California Berkeley;University of California Berkeley;Nanyang Technological University;University of California Berkeley",Long-tailed Recognition;Bias-variance Decomposition,-1;-1;-1;44;-1,-1;7;7;47;7,m;f,usa,usa,n,
5590,ICLR,2021,Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning,Tsung-Wei Ke;Jyh-Jing Hwang;Stella Yu,~Tsung-Wei_Ke2;~Jyh-Jing_Hwang1;~Stella_Yu2,6;7;5;6;7,5;3;4;4;5,Accept (Poster),0,6,0.0,yes,9/28/20,University of California Berkeley;University of Pennsylvania;University of California Berkeley,weakly supervised representation learning;representation learning for computer vision;metric learning;semantic segmentation,-1;20;-1,7;13;7,m;f,usa,usa,n,2
5591,ICLR,2021,Boost then Convolve: Gradient Boosting Meets Graph Neural Networks,Sergei Ivanov;Liudmila Prokhorenkova,~Sergei_Ivanov2;~Liudmila_Prokhorenkova1,7;6;9;5,4;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Criteo;Higher School of Economics,GNN;GBDT;graphs;tabular data;heterogeneous data,-1;-1,-1;-1,m;f,NAN,NAN,n,10
5592,ICLR,2021,DC3: A learning method for optimization with hard constraints,Priya L. Donti;David Rolnick;J Zico Kolter,~Priya_L._Donti1;~David_Rolnick1;~J_Zico_Kolter1,4;7;8;6,5;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Carnegie Mellon University;School of Computer Science, McGill University;Carnegie Mellon University",approximate constrained optimization;implicit differentiation;optimal power flow;surrogate models,1;99;1,28;40;28,f;m,usa,usa,n,
5593,ICLR,2021,A Universal Representation Transformer Layer for Few-Shot Image Classification,Lu Liu;William L. Hamilton;Guodong Long;Jing Jiang;Hugo Larochelle,~Lu_Liu7;~William_L._Hamilton1;~Guodong_Long2;~Jing_Jiang6;~Hugo_Larochelle1,7;6;6;8;7,5;4;5;5;5,Accept (Poster),0,5,0.0,yes,9/28/20,University of Technology Sydney;McGill University;University of Technology Sydney;University of Technology Sydney;Google,,71;99;71;71;-1,160;40;160;160;-1,f;m,NAN,NAN,n,6;8;1
5594,ICLR,2021,Generalized Multimodal ELBO,Thomas M. Sutter;Imant Daunhawer;Julia E Vogt,~Thomas_Marco_Sutter1;~Imant_Daunhawer2;~Julia_E_Vogt1,6;6;7;6,4;4;4;3,Accept (Poster),0,0,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Memorial Sloan Kettering Cancer Center,Multimodal;VAE;ELBO;self-supervised;generative learning,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,y,5
5595,ICLR,2021,Debiasing Concept-based Explanations with Causal Analysis,Mohammad Taha Bahadori;David Heckerman,~Mohammad_Taha_Bahadori1;~David_Heckerman1,6;7;5;4,4;3;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,Amazon;University of California - Los Angeles,Interpretability;Concept-based Explanation,-1;-1,-1;15,m;m,usa,usa,n,10
5596,ICLR,2021,Tilted Empirical Risk Minimization,Tian Li;Ahmad Beirami;Maziar Sanjabi;Virginia Smith,~Tian_Li1;~Ahmad_Beirami1;~Maziar_Sanjabi1;~Virginia_Smith1,6;8;6;6,3;4;3;3,Accept (Poster),0,7,0.0,yes,9/28/20,Carnegie Mellon University;Facebook AI;Facebook;Carnegie Mellon University,exponential tilting;models of learning and generalization;label noise robustness;fairness,1;-1;-1;1,28;-1;-1;28,f;f,usa,usa,y,1;7
5597,ICLR,2021,Wandering within a world: Online contextualized few-shot learning,Mengye Ren;Michael Louis Iuzzolino;Michael Curtis Mozer;Richard Zemel,~Mengye_Ren1;~Michael_Louis_Iuzzolino1;~Michael_Curtis_Mozer1;~Richard_Zemel1,7;7;7;6,3;4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,"University of Toronto;University of Colorado, Boulder;University of Colorado at Boulder;University of Toronto",Few-shot learning;continual learning;lifelong learning,18;64;-1;18,18;131;-1;18,m;m,canada,ca,n,6
5598,ICLR,2021,Multi-resolution modeling of a discrete stochastic process identifies causes of cancer,Adam Uri Yaari;Maxwell Sherman;Oliver Clarke Priebe;Po-Ru Loh;Boris Katz;Andrei Barbu;Bonnie Berger,~Adam_Uri_Yaari1;~Maxwell_Sherman1;~Oliver_Clarke_Priebe1;~Po-Ru_Loh1;~Boris_Katz1;~Andrei_Barbu3;~Bonnie_Berger1,6;6;7,3;1;3,Accept (Poster),0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Pennsylvania;Harvard University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Computational Biology;non-stationary stochastic processes;cancer research;deep learning;probabelistic models;graphical models,5;5;20;53;5;5;5,4;4;13;3;4;4;4,m;f,usa,usa,n,
5599,ICLR,2021,Discrete Graph Structure Learning for Forecasting Multiple Time Series,Chao Shang;Jie Chen;Jinbo Bi,~Chao_Shang1;~Jie_Chen1;~Jinbo_Bi1,6;7;4,3;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,JD AI Research;International Business Machines;University of Connecticut,Time series forecasting;graph neural network;graph structure learning,-1;-1;174,-1;-1;440,m;f,usa,usa,n,10
5600,ICLR,2021,A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima,Zeke Xie;Issei Sato;Masashi Sugiyama,~Zeke_Xie1;~Issei_Sato1;~Masashi_Sugiyama1,6;6;7;7,3;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,The University of Tokyo;the University of Tokyo;RIKEN Center for Advanced Intelligence Project,deep learning dynamics;SGD;diffusion;flat minima;stochastic optimization,71;71;-1,36;36;-1,m;m,NAN,NAN,y,1
5601,ICLR,2021,Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with $1/n$ Parameters,Aston Zhang;Yi Tay;SHUAI Zhang;Alvin Chan;Anh Tuan Luu;Siu Hui;Jie Fu,~Aston_Zhang2;~Yi_Tay1;~SHUAI_Zhang5;~Alvin_Chan1;~Anh_Tuan_Luu2;~Siu_Hui1;~Jie_Fu2,8;8;8,4;3;5,Accept (Spotlight),0,9,0.0,yes,9/28/20,AWS;Google;Swiss Federal Institute of Technology;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;University of Montreal,hypercomplex representation learning,209;-1;-1;44;44;44;128,-1;-1;-1;47;47;47;73,m;m,canada,ca,n,8;3
5602,ICLR,2021,Trusted Multi-View Classification,Zongbo Han;Changqing Zhang;Huazhu Fu;Joey Tianyi Zhou,~Zongbo_Han1;~Changqing_Zhang1;~Huazhu_Fu4;~Joey_Tianyi_Zhou1,4;8;7,5;5;3,Accept (Poster),0,7,0.0,yes,9/28/20,"Tianjin University;Tianjin University;Inception Institute of Artificial Intelligence;IHPC, A*STAR",Multi-Modal Learning;Multi-View Learning;Uncertainty Machine Learning,-1;-1;-1;-1,496;496;-1;-1,m;m,NAN,NAN,n,1
5603,ICLR,2021,Knowledge Distillation as Semiparametric Inference,Tri Dao;Govinda M Kamath;Vasilis Syrgkanis;Lester Mackey,~Tri_Dao1;govinda.kamath@microsoft.com;~Vasilis_Syrgkanis1;~Lester_Mackey1,6;8;6;6,4;4;4;2,Accept (Poster),0,6,0.0,yes,9/28/20,Stanford University;Microsoft;Microsoft;Microsoft Research New England,knowledge distillation;semiparametric inference;generalization bounds;model compression;cross-fitting;orthogonal machine learning;loss correction,5;-1;-1;-1,2;-1;-1;-1,m;m,NAN,NAN,y,10
5604,ICLR,2021,Initialization and Regularization of Factorized Neural Layers,Mikhail Khodak;Neil A. Tenenholtz;Lester Mackey;Nicolo Fusi,~Mikhail_Khodak1;~Neil_A._Tenenholtz1;~Lester_Mackey1;~Nicolo_Fusi1,6;6;6;6,3;3;3;3,Accept (Poster),0,13,0.0,yes,9/28/20,Carnegie Mellon University;Microsoft Research;Microsoft Research New England;Microsoft,model compression;knowledge distillation;multi-head attention;matrix factorization,1;-1;-1;-1,28;-1;-1;-1,m;m,NAN,NAN,y,8
5605,ICLR,2021,Learning N:M  Fine-grained Structured Sparse Neural Networks From Scratch,Aojun Zhou;Yukun Ma;Junnan Zhu;Jianbo Liu;Zhijie Zhang;Kun Yuan;Wenxiu Sun;Hongsheng Li,~Aojun_Zhou2;~Yukun_Ma2;junnan.zhu@nlpr.ia.ac.cn;~Jianbo_Liu3;~Zhijie_Zhang1;~Kun_Yuan1;~Wenxiu_Sun1;~Hongsheng_Li3,6;5;6;6,3;5;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,"SenseTime Research;Northwestern University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;The Chinese University of Hong Kong;university  of tianjin of china, Tsinghua University;SenseTime Research;SenseTime Group Limited;The Chinese University of Hong Kong",sparsity;efficient training and inference.,-1;46;34;327;4;-1;-1;327,-1;24;-1;39;20;-1;-1;39,u;m,NAN,NAN,n,
5606,ICLR,2021,Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering,Calypso Herrera;Florian Krach;Josef Teichmann,~Calypso_Herrera1;~Florian_Krach1;jteichma@math.ethz.ch,6;7;7;4,4;5;2;3,Accept (Poster),0,9,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Neural ODE;conditional expectation;irregular-observed data modelling,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y,1
5607,ICLR,2021,Go with the flow: Adaptive control for Neural ODEs,Mathieu Chalvidal;Matthew Ricci;Rufin VanRullen;Thomas Serre,~Mathieu_Chalvidal1;~Matthew_Ricci1;rufin.vanrullen@cnrs.fr;~Thomas_Serre1,7;7;8;7,5;4;4;2,Accept (Poster),0,8,0.0,yes,9/28/20,Brown University;Brown University;CNRS;Brown University,Neural ODEs;Optimal Control Theory;Hypernetworks;Normalizing flows,85;85;-1;85,61;61;-1;61,m;m,usa,usa,n,
5608,ICLR,2021,Orthogonalizing Convolutional Layers with the Cayley Transform,Asher Trockman;J Zico Kolter,~Asher_Trockman1;~J_Zico_Kolter1,7;7;7;8,3;4;4;4,Accept (Spotlight),0,0,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University,orthogonal layers;Lipschitz constrained networks;adversarial robustness,1;1,28;28,m;m,usa,usa,n,4
5609,ICLR,2021,A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks,Nikunj Saunshi;Sadhika Malladi;Sanjeev Arora,~Nikunj_Saunshi1;~Sadhika_Malladi2;~Sanjeev_Arora1,7;6;7;8;6,3;2;4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Princeton University;Princeton University;Princeton University,language models;theory;representation learning;self-supervised learning;unsupervised learning;transfer learning;natural language processing,29;29;29,9;9;9,m;m,usa,usa,y,6;3
5610,ICLR,2021,Layer-adaptive Sparsity for the Magnitude-based Pruning,Jaeho Lee;Sejun Park;Sangwoo Mo;Sungsoo Ahn;Jinwoo Shin,~Jaeho_Lee3;~Sejun_Park1;~Sangwoo_Mo1;~Sungsoo_Ahn1;~Jinwoo_Shin1,6;7;5;8,4;5;4;3,Accept (Poster),0,12,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology (KAIST);Mohamed Bin Zayed University of Artificial Intelligence;Korea Advanced Institute of Science and Technology,network pruning;layerwise sparsity;magnitude-based pruning,-1;-1;15;-1;-1,96;96;96;874;96,m;m,NAN,NAN,n,
5611,ICLR,2021,PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences,Hehe Fan;Xin Yu;Yuhang Ding;Yi Yang;Mohan Kankanhalli,~Hehe_Fan1;~Xin_Yu1;~Yuhang_Ding1;~Yi_Yang4;~Mohan_Kankanhalli1,7;7;5,4;3;5,Accept (Poster),0,5,0.0,yes,9/28/20,National University of Singapore;University of Technology Sydney;Baidu;Zhejiang University;National University of Singapore,Point cloud;spatio-temporal modeling;video analysis;action recognition;semantic segmentation;convolutional neural network,17;71;-1;42;17,25;160;-1;94;25,m;m,asia,sg,n,2
5612,ICLR,2021,Self-supervised Representation Learning with Relative Predictive Coding,Yao-Hung Hubert Tsai;Martin Q. Ma;Muqiao Yang;Han Zhao;Louis-Philippe Morency;Ruslan Salakhutdinov,~Yao-Hung_Hubert_Tsai1;~Martin_Q._Ma1;~Muqiao_Yang1;~Han_Zhao1;~Louis-Philippe_Morency1;~Ruslan_Salakhutdinov1,6;7;8;6,4;3;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,"Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;CMU, Carnegie Mellon University;University of Illinois, Urbana Champaign;Carnegie Mellon University;Carnegie-Mellon University",self-supervised learning;contrastive learning;dependency based method,1;1;1;-1;1;1,28;28;28;-1;28;28,m;m,usa,usa,y,
5613,ICLR,2021,Generalization bounds via distillation,Daniel Hsu;Ziwei Ji;Matus Telgarsky;Lan Wang,~Daniel_Hsu1;~Ziwei_Ji1;~Matus_Telgarsky1;~Lan_Wang4,8;7;6;6,5;2;2;2,Accept (Spotlight),0,8,0.0,yes,9/28/20,"Columbia University;University of Illinois, Urbana Champaign;Department of Computer Science, University of Illinois, Urbana Champaign;University of Illinois at Urbana-Champaign",Generalization;statistical learning theory;theory;distillation,23;-1;-1;-1,17;-1;-1;48,m;f,NAN,NAN,y,1;10
5614,ICLR,2021,Deep Networks and the Multiple Manifold Problem,Sam Buchanan;Dar Gilboa;John Wright,~Sam_Buchanan1;~Dar_Gilboa1;~John_Wright1,6;7;5;8,2;4;1;2,Accept (Poster),0,6,0.0,yes,9/28/20,Columbia University;Harvard University;Columbia University,deep learning;overparameterized neural networks;low-dimensional structure,23;53;23,17;3;17,m;m,usa,usa,y,1
5615,ICLR,2021,Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients,Brenden K Petersen;Mikel Landajuela Larma;Terrell N. Mundhenk;Claudio Prata Santiago;Soo Kyung Kim;Joanne Taery Kim,~Brenden_K_Petersen1;landajuelala1@llnl.gov;~Terrell_N._Mundhenk1;santiago10@llnl.gov;~Soo_Kyung_Kim1;kim102@llnl.gov,7;9;8;8,4;3;4;3,Accept (Oral),0,10,0.0,yes,9/28/20,Lawrence Livermore National Labs;Lawrence Livermore National Labs;Lawrence Livermore National Labs;Lawrence Livermore National Labs;Lawrence Livermore National Labs;Lawrence Livermore National Labs,symbolic regression;reinforcement learning;automated machine learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,y,
5616,ICLR,2021,Evaluations and Methods for Explanation through Robustness Analysis,Cheng-Yu Hsieh;Chih-Kuan Yeh;Xuanqing Liu;Pradeep Kumar Ravikumar;Seungyeon Kim;Sanjiv Kumar;Cho-Jui Hsieh,~Cheng-Yu_Hsieh1;~Chih-Kuan_Yeh1;~Xuanqing_Liu1;~Pradeep_Kumar_Ravikumar1;~Seungyeon_Kim1;~Sanjiv_Kumar1;~Cho-Jui_Hsieh1,7;7;7;6,4;3;4;3,Accept (Poster),0,13,0.0,yes,9/28/20,"University of Washington;School of Computer Science, Carnegie Mellon University;University of California, Los Angeles;Carnegie Mellon University;Google;Google;Amazon",Interpretability;Explanations;Adversarial Robustness,11;1;-1;1;-1;-1;-1,29;28;15;28;-1;-1;-1,m;m,NAN,NAN,n,4
5617,ICLR,2021,FedBN: Federated Learning on Non-IID Features via Local Batch Normalization,Xiaoxiao Li;Meirui JIANG;Xiaofei Zhang;Michael Kamp;Qi Dou,~Xiaoxiao_Li1;~Meirui_JIANG1;~Xiaofei_Zhang1;~Michael_Kamp1;~Qi_Dou2,8;7;4;5,4;5;4;5,Accept (Poster),0,12,0.0,yes,9/28/20,Princeton University;The Chinese University of Hong Kong;Iowa State University;CISPA Helmholtz-Zentrum f√ºr Informationssicherheit;The Chinese University of Hong Kong,Federated Learning;Non-IID;Batch Normalization,29;327;209;-1;327,9;39;427;-1;39,f;f,NAN,NAN,y,9
5618,ICLR,2021,Tomographic Auto-Encoder: Unsupervised Bayesian Recovery of Corrupted Data,Francesco Tonolini;Pablo Garcia Moreno;Andreas Damianou;Roderick Murray-Smith,~Francesco_Tonolini1;~Pablo_Garcia_Moreno1;~Andreas_Damianou1;~Roderick_Murray-Smith1,7;7;7;7,4;3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Glasgow;Amazon;Amazon;University of Glasgow,Missing value imputation;variational inference;variational auto-encoders,209;-1;-1;209,92;-1;-1;92,m;m,europe,uk,y,
5619,ICLR,2021,X2T: Training an X-to-Text Typing Interface with Online Learning from User Feedback,Jensen Gao;Siddharth Reddy;Glen Berseth;Nicholas Hardy;Nikhilesh Natraj;Karunesh Ganguly;Anca Dragan;Sergey Levine,jenseng@berkeley.edu;~Siddharth_Reddy1;~Glen_Berseth1;nhardy01@gmail.com;nikhilesh.natraj@ucsf.edu;karunesh.ganguly@ucsf.edu;~Anca_Dragan1;~Sergey_Levine1,8;7;4,4;4;4,Accept (Poster),0,14,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley;;;;;;;University of California-Berkeley;University of Washington,reinforcement learning;human-computer interaction,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;11,7;7;7;-1;-1;-1;-1;-1;-1;7;29,m;m,usa,usa,n,
5620,ICLR,2021,Attentional Constellation Nets for Few-Shot Learning,Weijian Xu;yifan xu;Huaijin Wang;Zhuowen Tu,~Weijian_Xu1;~yifan_xu1;~Huaijin_Wang1;~Zhuowen_Tu1,5;6;6;6,5;4;5;5,Accept (Poster),0,11,0.0,yes,9/28/20,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",few-shot learning;constellation models,-1;-1;-1;-1,33;33;33;33,m;m,usa,usa,n,6;8
5621,ICLR,2021,Rethinking Architecture Selection in Differentiable NAS,Ruochen Wang;Minhao Cheng;Xiangning Chen;Xiaocheng Tang;Cho-Jui Hsieh,~Ruochen_Wang2;~Minhao_Cheng1;~Xiangning_Chen1;~Xiaocheng_Tang1;~Cho-Jui_Hsieh1,7;7;10;7,4;5;5;4,Accept (Oral),0,11,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;Google;Lehigh University;Amazon",,-1;-1;-1;263;-1,15;15;-1;613;-1,m;m,NAN,NAN,y,8;1
5622,ICLR,2021,Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning,Zhenfang Chen;Jiayuan Mao;Jiajun Wu;Kwan-Yee Kenneth Wong;Joshua B. Tenenbaum;Chuang Gan,~Zhenfang_Chen1;~Jiayuan_Mao1;~Jiajun_Wu1;~Kwan-Yee_Kenneth_Wong2;~Joshua_B._Tenenbaum1;~Chuang_Gan1,6;7;6;7,4;4;2;3,Accept (Poster),0,12,0.0,yes,9/28/20,The University of Hong Kong;Massachusetts Institute of Technology;Stanford University;The University of Hong Kong;Massachusetts Institute of Technology;MIT-IBM Watson AI Lab,Concept Learning;Neuro-Symbolic Learning;Video Reasoning;Visual Reasoning,99;5;5;99;5;-1,39;4;2;39;4;-1,m;m,NAN,NAN,n,1;10
5623,ICLR,2021,Byzantine-Resilient Non-Convex Stochastic Gradient Descent,Zeyuan Allen-Zhu;Faeze Ebrahimianghazani;Jerry Li;Dan Alistarh,~Zeyuan_Allen-Zhu1;faezeeb75@gmail.com;~Jerry_Li1;~Dan_Alistarh7,7;6;5;8,3;2;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Microsoft;;;Massachusetts Institute of Technology;Institute of Science and Technology Austria,distributed machine learning;distributed deep learning;robust deep learning;non-convex optimization;Byzantine resilience,-1;-1;-1;5;-1,-1;-1;-1;4;-1,m;m,NAN,NAN,y,4
5624,ICLR,2021,ECONOMIC HYPERPARAMETER OPTIMIZATION WITH BLENDED SEARCH STRATEGY,Chi Wang;Qingyun Wu;Silu Huang;Amin Saied,~Chi_Wang3;qingyun.wu@microsoft.com;silu.huang@microsoft.com;amin.saied@microsoft.com,7;6;6,4;5;3,Accept (Poster),0,4,0.0,yes,9/28/20,Microsoft Research;Microsoft;University of Illinois  Urbana-Champaign;Microsoft,HYPERPARAMETER OPTIMIZATION;COST,-1;-1;-1;-1,-1;-1;48;-1,m;m,NAN,NAN,n,8;3
5625,ICLR,2021,When Do Curricula Work?,Xiaoxia Wu;Ethan Dyer;Behnam Neyshabur,~Xiaoxia_Wu1;~Ethan_Dyer1;~Behnam_Neyshabur1,8;8;7,3;4;3,Accept (Oral),0,3,0.0,yes,9/28/20,University of Chicago;Google;Google,Curriculum Learning;Understanding Deep Learning;Empirical Investigation,46;-1;-1,10;-1;-1,f;m,NAN,NAN,n,
5626,ICLR,2021,Learning Long-term Visual Dynamics with Region Proposal Interaction Networks,Haozhi Qi;Xiaolong Wang;Deepak Pathak;Yi Ma;Jitendra Malik,~Haozhi_Qi1;~Xiaolong_Wang3;~Deepak_Pathak1;~Yi_Ma4;~Jitendra_Malik2,6;7;7;6,3;4;4;2,Accept (Poster),0,5,0.0,yes,9/28/20,"University of California Berkeley;University of California, San Diego;Carnegie Mellon University;University of California Berkeley;UC Berkeley",dynamics prediction;interaction networks;physical reasoning,-1;-1;1;-1;-1,7;33;28;7;-1,m;m,NAN,NAN,n,
5627,ICLR,2021,Modeling the Second Player in Distributionally Robust Optimization,Paul Michel;Tatsunori Hashimoto;Graham Neubig,~Paul_Michel1;~Tatsunori_Hashimoto1;~Graham_Neubig1,7;7;6;7,4;3;4;3,Accept (Poster),0,13,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Stanford University;Carnegie Mellon University",distributionally robust optimization;deep learning;robustness;adversarial learning,1;5;1,28;2;28,m;m,usa,usa,n,3;5
5628,ICLR,2021,Explainable Subgraph Reasoning for Forecasting on Temporal Knowledge Graphs,Zhen Han;Peng Chen;Yunpu Ma;Volker Tresp,~Zhen_Han3;peng.chen@tum.de;~Yunpu_Ma1;~Volker_Tresp1,6;7;6;1;6,4;4;3;3;4,Accept (Poster),0,13,0.0,yes,9/28/20,Institut f√ºr Informatik;;;Institut f√ºr Informatik;Ludwig Maximilian University of Munich,Temporal knowledge graph;future link prediction;graph neural network;subgraph reasoning.,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;10
5629,ICLR,2021,Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows,Kashif Rasul;Abdul-Saboor Sheikh;Ingmar Schuster;Urs M Bergmann;Roland Vollgraf,kashif.rasul@zalando.de;~Abdul-Saboor_Sheikh1;ingmar.schuster@zalando.de;~Urs_M_Bergmann1;~Roland_Vollgraf1,7;6;7;9,4;3;5;5,Accept (Spotlight),0,0,0.0,yes,9/28/20,Free University Berlin;TU Berlin;Freie Universit√§t Berlin;Google Research;Zalando,time series;normalizing flows;attention;probabilistic multivariate forecasting,-1;128;327;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5630,ICLR,2021,Estimating Treatment Effects via Orthogonal Regularization,Tobias Hatt;Stefan Feuerriegel,~Tobias_Hatt1;sfeuerriegel@ethz.ch,7;5;3;5,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Treatment Effects;Regularization;Neural Networks,-1;-1,-1;-1,m;m,NAN,NAN,y,
5631,ICLR,2021,"Few-Shot Learning via Learning the Representation, Provably",Simon Shaolei Du;Wei Hu;Sham M. Kakade;Jason D. Lee;Qi Lei,~Simon_Shaolei_Du1;~Wei_Hu1;~Sham_M._Kakade1;~Jason_D._Lee1;~Qi_Lei1,6;7;8;6,4;4;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,Facebook;Princeton University;University of Washington;Princeton University;Princeton University,representation learning;statistical learning theory,-1;29;11;29;29,-1;9;29;9;9,m;f,usa,usa,y,6;1
5632,ICLR,2021,One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks,Atish Agarwala;Abhimanyu Das;Brendan Juba;Rina Panigrahy;Vatsal Sharan;Xin Wang;Qiuyi Zhang,thetish@google.com;abhidas@google.com;~Brendan_Juba1;~Rina_Panigrahy1;~Vatsal_Sharan1;wanxin@google.com;~Qiuyi_Zhang1,6;7;3;5,3;3;4;2,Accept (Poster),0,4,0.0,yes,9/28/20,Google;University of Southern California;Washington University in St. Louis;Google;Massachusetts Institute of Technology;Google;Google,deep learning theory;multi-task learning,-1;37;110;-1;5;-1;-1,-1;53;50;-1;4;-1;-1,m;m,NAN,NAN,y,
5633,ICLR,2021,What are the Statistical Limits of Offline RL with Linear Function Approximation?,Ruosong Wang;Dean Foster;Sham M. Kakade,~Ruosong_Wang1;~Dean_Foster1;~Sham_M._Kakade1,7;8;7;8,4;3;3;3,Accept (Spotlight),0,7,0.0,yes,9/28/20,"Carnegie Mellon University;The Wharton School, University of Pennsylvania;University of Washington",batch reinforcement learning;function approximation;lower bound;representation,1;20;11,28;13;29,m;m,usa,usa,y,
5634,ICLR,2021,Contemplating Real-World Object Classification,ali borji,~ali_borji1,6;5;6;6,4;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,HCL America,object recognition;deep learning;ObjectNet;Robustness,-1,-1,m,NAN,NAN,n,2;1;4
5635,ICLR,2021,Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling,Yang Zhao;Jianwen Xie;Ping Li,~Yang_Zhao5;~Jianwen_Xie1;~Ping_Li3,4;6;7;5,5;4;4;4,Accept (Poster),0,17,0.0,yes,9/28/20,"State University of New York, Buffalo;Baidu Research;Baidu",Energy-based model;generative model;image translation;Langevin dynamics,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5
5636,ICLR,2021,Simple Spectral Graph Convolution,Hao Zhu;Piotr Koniusz,~Hao_Zhu2;~Piotr_Koniusz1,5;6;7;6,4;4;4;4,Accept (Poster),0,0,0.0,yes,9/28/20,Australian National University;Australian National University,Graph Convolutional Network;Oversmoothing,99;99,59;59,m;m,australasia,au,y,10
5637,ICLR,2021,Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation,Mrigank Raman;Aaron Chan;Siddhant Agarwal;PeiFeng Wang;Hansen Wang;Sungchul Kim;Ryan Rossi;Handong Zhao;Nedim Lipka;Xiang Ren,mrigankraman1611@gmail.com;~Aaron_Chan1;~Siddhant_Agarwal1;~PeiFeng_Wang1;~Hansen_Wang1;sukim@adobe.com;~Ryan_Rossi1;~Handong_Zhao3;lipka@adobe.com;~Xiang_Ren1,6;6;4;7,3;4;4;3,Accept (Poster),0,8,0.0,yes,9/28/20,"Indian Institute of Technology Delhi, Dhirubhai Ambani Institute Of Information and Communication Technology;University of Southern California;Indian Institute of Technology Kharagpur;University of Southern California;Tsinghua University, Tsinghua University;;;Adobe Research;Adobe Systems;;;University of Southern California",neural symbolic reasoning;interpretability;model explanation;faithfulness;knowledge graph;commonsense question answering;recommender system,-1;37;-1;37;4;-1;-1;-1;-1;-1;-1;37,-1;53;-1;53;20;-1;-1;-1;-1;-1;-1;53,m;m,usa,usa,n,8;10
5638,ICLR,2021,Seq2Tens: An Efficient Representation of Sequences by Low-Rank Tensor Projections,Csaba Toth;Patric Bonnier;Harald Oberhauser,~Csaba_Toth2;~Patric_Bonnier1;~Harald_Oberhauser1,5;4;8;7,4;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,time series;sequential data;representation learning;low-rank tensors;classification;generative modelling,46;46;46,1;1;1,m;m,europe,uk,y,5
5639,ICLR,2021,Expressive Power of Invariant and Equivariant Graph Neural Networks,Waiss Azizian;marc lelarge,waiss.azizian@ens.fr;~marc_lelarge1,8;6;8;9,4;4;3;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,Ecole Normale Sup√©rieure de Paris;inria,Graph Neural Network;Universality;Approximation,-1;-1,-1;-1,m;m,NAN,NAN,y,1;10
5640,ICLR,2021,FOCAL: Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization,Lanqing Li;Rui Yang;Dijun Luo,~Lanqing_Li1;yangrui19@mails.tsinghua.edu.cn;~Dijun_Luo1,5;7;5,3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Tencent AI Lab;Tsinghua University, Tsinghua University;Tencent AI Lab",offline/batch reinforcement learning;meta-reinforcement learning;multi-task reinforcement learning;distance metric learning;contrastive learning,-1;4;-1,-1;20;-1,m;m,NAN,NAN,n,
5641,ICLR,2021,Efficient Empowerment Estimation for Unsupervised Stabilization,Ruihan Zhao;Kevin Lu;Pieter Abbeel;Stas Tiomkin,~Ruihan_Zhao1;~Kevin_Lu2;~Pieter_Abbeel2;~Stas_Tiomkin1,7;7;5;6,3;5;4;2,Accept (Poster),0,10,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;Covariant;University of California Berkeley,unsupervised stabilization;representation of dynamical systems;neural networks;empowerment;intrinsic motivation,-1;-1;-1;-1,7;7;-1;7,m;m,usa,usa,n,9
5642,ICLR,2021,Learning with Feature-Dependent Label Noise: A Progressive Approach,Yikai Zhang;Songzhu Zheng;Pengxiang Wu;Mayank Goswami;Chao Chen,~Yikai_Zhang1;~Songzhu_Zheng1;~Pengxiang_Wu1;~Mayank_Goswami1;~Chao_Chen1,8;7;8;7,4;3;3;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,"Rutgers University;State University of New York, Stony Brook;Rutgers University;CUNY Queens College;State University of New York, Stony Brook",Noisy Label;Deep Learning;Classification,29;-1;29;263;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
5643,ICLR,2021,Theoretical bounds on estimation error for meta-learning,James Lucas;Mengye Ren;Irene Raissa KAMENI KAMENI;Toniann Pitassi;Richard Zemel,~James_Lucas1;~Mengye_Ren1;~Irene_Raissa_KAMENI_KAMENI1;~Toniann_Pitassi1;~Richard_Zemel1,5;7;7;6,4;4;4;3,Accept (Poster),0,27,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of Toronto;African Institute for mathematical Sciences;University of Toronto;University of Toronto",meta learning;few-shot;minimax risk;lower bounds;learning theory,18;18;-1;18;18,18;18;-1;18;18,m;m,canada,ca,y,6;11
5644,ICLR,2021,Direction Matters: On the Implicit Bias of Stochastic Gradient Descent with Moderate Learning Rate,Jingfeng Wu;Difan Zou;Vladimir Braverman;Quanquan Gu,~Jingfeng_Wu1;~Difan_Zou1;~Vladimir_Braverman1;~Quanquan_Gu1,6;7;6,3;3;3,Accept (Poster),0,11,0.0,yes,9/28/20,"Johns Hopkins University;University of California, Los Angeles;Department of Computer Science, Whiting School of Engineering;University of California, Los Angeles",SGD;regularization;implicit bias,71;-1;-1;-1,12;15;-1;15,m;m,usa,usa,y,1
5645,ICLR,2021,Local Convergence Analysis of Gradient Descent Ascent with Finite Timescale Separation,Tanner Fiez;Lillian J Ratliff,~Tanner_Fiez1;~Lillian_J_Ratliff1,6;6;6;7,4;4;3;4,Accept (Poster),0,52,0.0,yes,9/28/20,University of Washington;University of Washington,game theory;continuous games;generative adversarial networks;theory;gradient descent-ascent;equilibrium;convergence,11;11,29;29,m;f,usa,usa,y,5;4;9
5646,ICLR,2021,Discovering Non-monotonic Autoregressive Orderings with Variational Inference,Xuanlin Li;Brandon Trabucco;Dong Huk Park;Michael Luo;Sheng Shen;Trevor Darrell;Yang Gao,~Xuanlin_Li1;~Brandon_Trabucco1;~Dong_Huk_Park2;~Michael_Luo2;~Sheng_Shen2;~Trevor_Darrell2;~Yang_Gao1,6;7;7;6,4;2;5;3,Accept (Poster),0,6,0.0,yes,9/28/20,"University of California, San Diego;Machine Learning Department, School of Computer Science;University of California Berkeley;University of California Berkeley;University of California Berkeley;Electrical Engineering & Computer Science Department;Tsinghua University, Tsinghua University",variational inference;unsupervised learning;computer vision;natural language processing;optimization;reinforcement learning,-1;-1;-1;-1;-1;-1;4,33;-1;7;7;7;-1;20,m;m,NAN,NAN,y,3;1
5647,ICLR,2021,Neural Pruning via Growing Regularization,Huan Wang;Can Qin;Yulun Zhang;Yun Fu,~Huan_Wang3;~Can_Qin1;~Yulun_Zhang1;~Yun_Fu1,8;7;6;7,5;4;5;5,Accept (Poster),0,5,0.0,yes,9/28/20,Northeastern University;Northeastern University;Northeastern University;Northeastern University,model compression;deep neural network pruning;Hessian matrix;regularization,16;16;16;16,895;895;895;895,m;m,usa,usa,n,8
5648,ICLR,2021,Neurally Augmented ALISTA,Freya Behrens;Jonathan Sauder;Peter Jung,~Freya_Behrens1;~Jonathan_Sauder2;~Peter_Jung2,8;8;7;5,4;3;5;4,Accept (Poster),0,8,0.0,yes,9/28/20,TU Berlin;TU Berlin;TU Berlin,compressed sensing;sparse reconstruction;unrolled algorithms;learned ISTA,128;128;128,-1;-1;-1,f;m,europe,de,n,
5649,ICLR,2021,Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data,Colin Wei;Kendrick Shen;Yining Chen;Tengyu Ma,~Colin_Wei1;kshen6@stanford.edu;~Yining_Chen1;~Tengyu_Ma1,7;7;9;9,4;3;4;4,Accept (Oral),0,8,0.0,yes,9/28/20,"Computer Science Department, Stanford University;Stanford University;Stanford University;Stanford University",deep learning theory;domain adaptation theory;unsupervised learning theory;semi-supervised learning theory,5;5;5;5,2;2;2;2,m;m,usa,usa,y,1
5650,ICLR,2021,Simple Augmentation Goes a Long Way: ADRL for DNN Quantization,Lin Ning;Guoyang Chen;Weifeng Zhang;Xipeng Shen,~Lin_Ning1;~Guoyang_Chen1;weifeng.z@alibaba-inc.com;~Xipeng_Shen1,7;6;6,3;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,Google;North Carolina State University;;;North Carolina State University,Reinforcement Learning;Quantization;mixed precision;augmented deep reinforcement learning;DNN,-1;92;-1;-1;92,-1;340;-1;-1;340,f;m,usa,usa,n,
5651,ICLR,2021,Better Fine-Tuning by Reducing Representational Collapse,Armen Aghajanyan;Akshat Shrivastava;Anchit Gupta;Naman Goyal;Luke Zettlemoyer;Sonal Gupta,~Armen_Aghajanyan1;akshats@fb.com;anchit@fb.com;~Naman_Goyal1;~Luke_Zettlemoyer1;sonalgupta@fb.com,7;6;6;6,3;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Facebook;;;;;Georgia Institute of Technology;Facebook;Facebook,finetuning;nlp;representational learning;glue,-1;-1;-1;-1;-1;12;-1;-1,-1;-1;-1;-1;-1;38;-1;-1,m;f,NAN,NAN,n,3;1;4
5652,ICLR,2021,On the Critical Role of Conventions in Adaptive Human-AI Collaboration,Andy Shih;Arjun Sawhney;Jovana Kondic;Stefano Ermon;Dorsa Sadigh,~Andy_Shih1;~Arjun_Sawhney1;~Jovana_Kondic1;~Stefano_Ermon1;~Dorsa_Sadigh1,7;7;7;6,4;3;4;2,Accept (Poster),0,11,0.0,yes,9/28/20,"Computer Science Department, Stanford University;Stanford University;Princeton University;Stanford University;Stanford University",Multi-agent games;emergent behavior;transfer learning;human-AI collaboration,5;5;29;5;5,2;2;9;2;2,m;f,usa,usa,y,6
5653,ICLR,2021,Meta-learning with negative learning rates,Alberto Bernacchia,~Alberto_Bernacchia1,6;6;6;8,4;4;3;4,Accept (Poster),0,9,0.0,yes,9/28/20,MedaiTek Research,Meta-learning,-1,-1,m,NAN,NAN,y,6;1
5654,ICLR,2021,Capturing Label Characteristics in VAEs,Tom Joy;Sebastian Schmon;Philip Torr;Siddharth N;Tom Rainforth,~Tom_Joy1;sebastian.schmon@gmail.com;~Philip_Torr1;~Siddharth_N1;~Tom_Rainforth1,6;6;5;7,4;4;4;5,Accept (Poster),0,13,0.0,yes,9/28/20,"University of Oxford, University of Oxford;Durham University;University of Oxford;University of Edinburgh;University of Oxford",variational autoencoder;representation learning;deep generative models,46;263;46;29;46,1;149;1;30;1,m;m,europe,uk,n,5
5655,ICLR,2021,Federated Learning Based on Dynamic Regularization,Durmus Alp Emre Acar;Yue Zhao;Ramon Matas;Matthew Mattina;Paul Whatmough;Venkatesh Saligrama,~Durmus_Alp_Emre_Acar1;~Yue_Zhao12;~Ramon_Matas1;~Matthew_Mattina1;~Paul_Whatmough1;~Venkatesh_Saligrama1,7;8;7;7,3;4;5;3,Accept (Oral),0,10,0.0,yes,9/28/20,"Boston University;Washington University, St. Louis;Universitat Polit√®cnica de Catalunya;arm;Arm Inc;Trustees of Boston University",Federated Learning;Deep Neural Networks;Distributed Optimization,79;-1;-1;64;-1;79,54;-1;700;302;-1;54,m;m,NAN,NAN,y,
5656,ICLR,2021,Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding,Sana Tonekaboni;Danny Eytan;Anna Goldenberg,~Sana_Tonekaboni1;biliary.colic@gmail.com;~Anna_Goldenberg1,6;6;8;6,4;4;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Technion, Technion;University of Toronto",,18;29;18,18;-1;18,f;f,canada,ca,n,5
5657,ICLR,2021,Random Feature Attention,Hao Peng;Nikolaos Pappas;Dani Yogatama;Roy Schwartz;Noah Smith;Lingpeng Kong,~Hao_Peng4;~Nikolaos_Pappas1;~Dani_Yogatama2;~Roy_Schwartz1;~Noah_Smith1;~Lingpeng_Kong1,8;8;8;4,3;4;3;5,Accept (Spotlight),0,10,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;Department of Computer Science, University of Washington;Google DeepMind;Hebrew University, Hebrew University of Jerusalem;University of Washington;Department of Computer Science, The University of Hong Kong",Attention;transformers;machine translation;language modeling,11;11;-1;85;11;99,29;29;-1;235;29;39,m;m,NAN,NAN,y,8;3
5658,ICLR,2021,Contrastive  Learning  with Adversarial Perturbations for Conditional Text Generation,Seanie Lee;Dong Bok Lee;Sung Ju Hwang,~Seanie_Lee1;~Dong_Bok_Lee1;~Sung_Ju_Hwang1,6;6;5;4,3;3;4;3,Accept (Poster),0,18,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,conditional text generation;contrastive learning,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,3;8;1
5659,ICLR,2021,SOLAR: Sparse Orthogonal Learned and Random Embeddings,Tharun Medini;Beidi Chen;Anshumali Shrivastava,~Tharun_Medini1;~Beidi_Chen1;~Anshumali_Shrivastava1,7;7;7;3,4;5;3;5,Accept (Poster),0,7,0.0,yes,9/28/20,Rice University;Stanford University;Rice University,Sparse Embedding;Inverted Index;Learning to Hash;Embedding Models,92;5;92,124;2;124,m;m,australasia,au,y,1
5660,ICLR,2021,Information Laundering for Model Privacy,Xinran Wang;Yu Xiang;Jun Gao;Jie Ding,wang8740@umn.edu;yu.xiang@utah.edu;0618johnny@gmail.com;~Jie_Ding2,6;7;7,4;2;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,"University of Minnesota, Minneapolis;;;Stanford University;University of Minnesota, Minneapolis",Adversarial Attack;Machine Learning;Model privacy;Privacy-utility tradeoff;Security,71;-1;-1;5;71,85;-1;-1;2;85,f;m,NAN,NAN,y,4
5661,ICLR,2021,"Kanerva++: Extending the Kanerva Machine With Differentiable, Locally Block Allocated Latent Memory",Jason Ramapuram;Yan Wu;Alexandros Kalousis,~Jason_Ramapuram1;~Yan_Wu1;~Alexandros_Kalousis1,6;6;7;6,4;4;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Geneva, Switzerland;DeepMind;University Of Geneva, Switzerland",memory;generative model;latent variable;heap allocation,-1;-1;-1,149;-1;149,m;m,NAN,NAN,n,11;1
5662,ICLR,2021,Bag of Tricks for Adversarial Training,Tianyu Pang;Xiao Yang;Yinpeng Dong;Hang Su;Jun Zhu,~Tianyu_Pang1;~Xiao_Yang4;~Yinpeng_Dong2;~Hang_Su3;~Jun_Zhu2,5;7;6;7,3;4;5;4,Accept (Poster),0,9,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University",Adversarial Training;Robustness;Adversarial Examples,4;4;4;4;4,20;20;20;20;20,m;m,asia,cn,n,4
5663,ICLR,2021,Uncertainty Estimation and Calibration with Finite-State Probabilistic RNNs,Cheng Wang;Carolin Lawrence;Mathias Niepert,~Cheng_Wang9;~Carolin_Lawrence1;~Mathias_Niepert1,7;7;6;7,2;2;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Amazon Alexa AI;NEC Laboratories Europe;NEC,uncertainty estimation;calibration;RNN,-1;-1;-1,-1;-1;440,m;m,europe,gr,n,
5664,ICLR,2021,Learning a Latent Simplex in Input Sparsity Time,Ainesh Bakshi;Chiranjib Bhattacharyya;Ravi Kannan;David Woodruff;Samson Zhou,~Ainesh_Bakshi1;~Chiranjib_Bhattacharyya1;~Ravi_Kannan1;~David_Woodruff1;~Samson_Zhou1,8;9;7,3;4;4,Accept (Spotlight),0,3,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Indian Institute of Science;;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University",Latent Simplex;numerical linear algebra;low-rank approximation,1;-1;-1;1;1,28;323;-1;28;28,m;m,NAN,NAN,y,4
5665,ICLR,2021,Explaining the Efficacy of Counterfactually Augmented Data,Divyansh Kaushik;Amrith Setlur;Eduard H Hovy;Zachary Chase Lipton,~Divyansh_Kaushik1;~Amrith_Setlur1;~Eduard_H_Hovy1;~Zachary_Chase_Lipton1,6;7;8;7,3;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,humans in the loop;annotation artifacts;text classification;sentiment analysis;natural language inference,1;1;1;1,28;28;28;28,m;m,usa,usa,n,3;8;1
5666,ICLR,2021,A unifying view on implicit bias in training linear neural networks,Chulhee Yun;Shankar Krishnan;Hossein Mobahi,~Chulhee_Yun1;~Shankar_Krishnan1;~Hossein_Mobahi2,7;7;6,2;4;4,Accept (Poster),0,3,0.0,yes,9/28/20,Massachusetts Institute of Technology;Google;Google,implicit bias;implicit regularization;convergence;gradient flow;gradient descent,5;-1;-1,4;-1;-1,m;m,NAN,NAN,y,1;9
5667,ICLR,2021,Net-DNF: Effective Deep Modeling of Tabular Data,Liran Katzir;Gal Elidan;Ran El-Yaniv,~Liran_Katzir1;~Gal_Elidan1;~Ran_El-Yaniv1,6;6;7,4;3;2,Accept (Poster),0,3,0.0,yes,10/1/20,"Technion, Technion;Google;Technion",Neural Networks;Architectures;Tabular Data;Predictive Modeling,29;-1;29,-1;-1;408,m;m,europe,il,y,3;10
5668,ICLR,2021,Uncertainty in Gradient Boosting via Ensembles,Andrey Malinin;Liudmila Prokhorenkova;Aleksei Ustimenko,~Andrey_Malinin1;~Liudmila_Prokhorenkova1;austimenko@yandex-team.ru,6;6;7;7,3;4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,Yandex;Higher School of Economics;Lomonosov Moscow State University,uncertainty;ensembles;gradient boosting;decision trees;knowledge uncertainty,-1;-1;-1,-1;-1;173,m;m,NAN,NAN,n,10
5669,ICLR,2021,Learning to Reach Goals via Iterated Supervised Learning,Dibya Ghosh;Abhishek Gupta;Ashwin Reddy;Justin Fu;Coline Manon Devin;Benjamin Eysenbach;Sergey Levine,~Dibya_Ghosh1;~Abhishek_Gupta1;~Ashwin_Reddy1;~Justin_Fu1;~Coline_Manon_Devin1;~Benjamin_Eysenbach1;~Sergey_Levine1,7;8;8;7,4;4;4;3,Accept (Oral),0,6,0.0,yes,9/28/20,University of California Berkeley;Google;University of California Berkeley;University of California Berkeley;DeepMind;Carnegie Mellon University;University of Washington,goal reaching;reinforcement learning;behavior cloning;goal-conditioned RL,-1;-1;-1;-1;-1;1;11,7;-1;7;7;-1;28;29,m;m,usa,usa,y,1
5670,ICLR,2021,WaveGrad: Estimating Gradients for Waveform Generation,Nanxin Chen;Yu Zhang;Heiga Zen;Ron J Weiss;Mohammad Norouzi;William Chan,~Nanxin_Chen1;~Yu_Zhang2;~Heiga_Zen1;~Ron_J_Weiss1;~Mohammad_Norouzi1;~William_Chan1,5;6;7;8,4;5;3;4,Accept (Poster),0,9,0.0,yes,9/28/20,Johns Hopkins University;Google;Google;Google;Google Brain;Google,vocoder;diffusion;score matching;text-to-speech;gradient estimation;waveform generation,71;-1;-1;-1;-1;-1,12;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,4
5671,ICLR,2021,SALD: Sign Agnostic Learning with Derivatives,Matan Atzmon;Yaron Lipman,~Matan_Atzmon1;~Yaron_Lipman1,6;7;8;8,5;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,Weizmann Institute;Facebook,implicit neural representations;3D shapes learning;sign agnostic learning,110;-1,-1;-1,m;m,NAN,NAN,y,2;10
5672,ICLR,2021,MetaNorm: Learning to Normalize Few-Shot Batches Across Domains,Yingjun Du;Xiantong Zhen;Ling Shao;Cees G. M. Snoek,~Yingjun_Du1;~Xiantong_Zhen1;~Ling_Shao1;~Cees_G._M._Snoek1,4;7;6;6,5;3;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam;Inception Institute of Artificial Intelligence;University of Amsterdam,Meta-learning;batch normalization;few-shot domain generalization,128;128;-1;128,66;66;-1;66,m;m,europe,nl,n,6;1
5673,ICLR,2021,Probing BERT in Hyperbolic Spaces,Boli Chen;Yao Fu;Guangwei Xu;Pengjun Xie;Chuanqi Tan;Mosha Chen;Liping Jing,~Boli_Chen1;~Yao_Fu3;kunka.xgw@taobao.com;chengchen.xpj@taobao.com;chuanqi.tcq@alibaba-inc.com;chenmosha.cms@alibaba-inc.com;~Liping_Jing3,6;5;7;6,3;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,Alibaba DAMO Academy;University of Edinburgh;University of Electronic Science and Technology of China;;;Alibaba Group;Alibaba Group;Beijing Jiaotong University,Hyperbolic;BERT;Probe;Syntax;Sentiment,-1;29;-1;-1;-1;-1;-1;-1,-1;30;553;-1;-1;-1;-1;978,m;f,NAN,NAN,n,3
5674,ICLR,2021,Coping with Label Shift via Distributionally Robust Optimisation,Jingzhao Zhang;Aditya Krishna Menon;Andreas Veit;Srinadh Bhojanapalli;Sanjiv Kumar;Suvrit Sra,~Jingzhao_Zhang2;~Aditya_Krishna_Menon1;~Andreas_Veit1;~Srinadh_Bhojanapalli1;~Sanjiv_Kumar1;~Suvrit_Sra1,6;7;4,4;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,Massachusetts Institute of Technology;Google;Google;Google;Google;Massachusetts Institute of Technology,Label shift;distributional robust optimization,5;-1;-1;-1;-1;5,4;-1;-1;-1;-1;4,m;m,usa,usa,y,
5675,ICLR,2021,Self-Supervised Policy Adaptation during Deployment,Nicklas Hansen;Rishabh Jangir;Yu Sun;Guillem Aleny√†;Pieter Abbeel;Alexei A Efros;Lerrel Pinto;Xiaolong Wang,~Nicklas_Hansen1;jangirrishabh@gmail.com;~Yu_Sun1;~Guillem_Aleny√†1;~Pieter_Abbeel2;~Alexei_A_Efros1;~Lerrel_Pinto1;~Xiaolong_Wang3,7;7;7;7,4;4;4;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,"University of California, San Diego;University of California, San Diego;University of California Berkeley;Spanish National Research Council;Covariant;University of California Berkeley;New York University;University of California, San Diego",reinforcement learning;robotics;self-supervised learning;generalization;sim2real,-1;-1;-1;-1;-1;-1;23;-1,33;33;7;-1;-1;7;26;33,m;m,usa,usa,n,1
5676,ICLR,2021,DrNAS: Dirichlet Neural Architecture Search,Xiangning Chen;Ruochen Wang;Minhao Cheng;Xiaocheng Tang;Cho-Jui Hsieh,~Xiangning_Chen1;~Ruochen_Wang2;~Minhao_Cheng1;~Xiaocheng_Tang1;~Cho-Jui_Hsieh1,7;5;6;6,4;3;3;2,Accept (Poster),0,10,0.0,yes,9/28/20,"Google;University of California, Los Angeles;University of California, Los Angeles;Lehigh University;Amazon",,-1;-1;-1;263;-1,-1;15;15;613;-1,m;m,NAN,NAN,y,1
5677,ICLR,2021,Mathematical Reasoning via Self-supervised Skip-tree Training,Markus Norman Rabe;Dennis Lee;Kshitij Bansal;Christian Szegedy,~Markus_Norman_Rabe1;~Dennis_Lee1;~Kshitij_Bansal1;~Christian_Szegedy1,7;7;7;7,4;4;3;4,Accept (Spotlight),0,10,0.0,yes,9/28/20,Google;University of California Berkeley;Google;Google,self-supervised learning;mathematics;reasoning;theorem proving;language modeling,-1;-1;-1;-1,-1;7;-1;-1,m;m,NAN,NAN,n,3;1
5678,ICLR,2021,The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings,Elliot Meyerson;Risto Miikkulainen,~Elliot_Meyerson1;~Risto_Miikkulainen1,6;6;9;9,4;3;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,"Cognizant;The University of Texas, Austin",Multi-task;Many-task;Multi-domain;Cross-domain;Variable Embeddings;Task Embeddings;Tabular;Analogies,-1;-1,-1;-1,m;m,NAN,NAN,n,
5679,ICLR,2021,Overparameterisation and worst-case generalisation: friend or foe?,Aditya Krishna Menon;Ankit Singh Rawat;Sanjiv Kumar,~Aditya_Krishna_Menon1;~Ankit_Singh_Rawat1;~Sanjiv_Kumar1,7;5;6,3;3;3,Accept (Poster),0,3,0.0,yes,9/28/20,Google;Google;Google,overparameterisation;worst-case generalisation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5680,ICLR,2021,Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?,Zhen Qin;Le Yan;Honglei Zhuang;Yi Tay;Rama Kumar Pasumarthi;Xuanhui Wang;Michael Bendersky;Marc Najork,~Zhen_Qin5;lyyanle@google.com;~Honglei_Zhuang1;~Yi_Tay1;~Rama_Kumar_Pasumarthi1;~Xuanhui_Wang1;bemike@google.com;najork@google.com,8;2;8;6,4;5;4;3,Accept (Spotlight),0,4,0.0,yes,9/28/20,Google;Google;Google Research;Google;Carnegie Mellon University;Google;Google;Google,Learning to Rank;benchmark;neural network;gradient boosted decision trees,-1;-1;-1;-1;1;-1;-1;-1,-1;-1;-1;-1;28;-1;-1;-1,m;m,NAN,NAN,n,
5681,ICLR,2021,Gradient Origin Networks,Sam Bond-Taylor;Chris G. Willcocks,~Sam_Bond-Taylor1;christopher.g.willcocks@durham.ac.uk,7;5;7,4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Durham University;Durham University,Deep Learning;Generative Models;Implicit Representation,263;263,149;149,m;m,europe,uk,n,5
5682,ICLR,2021,Improving Transformation Invariance in Contrastive Representation Learning,Adam Foster;Rattana Pukdee;Tom Rainforth,~Adam_Foster1;~Rattana_Pukdee1;~Tom_Rainforth1,6;7;7,4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,contrastive learning;representation learning;transformation invariance,46;46;46,1;1;1,m;m,europe,uk,y,5
5683,ICLR,2021,Representation Learning via Invariant Causal Mechanisms,Jovana Mitrovic;Brian McWilliams;Jacob C Walker;Lars Holger Buesing;Charles Blundell,~Jovana_Mitrovic1;~Brian_McWilliams2;~Jacob_C_Walker1;~Lars_Holger_Buesing1;~Charles_Blundell1,5;6;6;7,3;4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,DeepMind;Deepmind;Carnegie Mellon University;Deepmind;DeepMind,Representation Learning;Self-supervised Learning;Contrastive Methods;Causality,-1;-1;1;-1;-1,-1;-1;28;-1;-1,f;m,NAN,NAN,y,1
5684,ICLR,2021,WaNet - Imperceptible Warping-based Backdoor Attack,Tuan Anh Nguyen;Anh Tuan Tran,~Tuan_Anh_Nguyen4;~Anh_Tuan_Tran2,6;7;6,4;4;2,Accept (Poster),0,10,0.0,yes,9/28/20,VinAI Research;VinAI Research,backdoor attack;image warping;wanet,-1;-1,-1;-1,m;m,NAN,NAN,n,4
5685,ICLR,2021,Bowtie Networks: Generative Modeling for Joint Few-Shot Recognition and Novel-View Synthesis,Zhipeng Bao;Yu-Xiong Wang;Martial Hebert,~Zhipeng_Bao1;~Yu-Xiong_Wang1;~Martial_Hebert1,6;7;6;5,5;4;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,"Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University",computer vision;object recognition;few-shot learning;generative models;adversarial training,1;1;1,28;28;28,m;m,usa,usa,n,6;5
5686,ICLR,2021,Enforcing robust control guarantees within neural network policies,Priya L. Donti;Melrose Roderick;Mahyar Fazlyab;J Zico Kolter,~Priya_L._Donti1;mroderick@cmu.edu;mahyarfa@seas.upenn.edu;~J_Zico_Kolter1,6;6;6;6,4;4;4;3,Accept (Poster),0,10,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;;;Carnegie Mellon University,robust control;reinforcement learning;differentiable optimization,1;1;-1;-1;1,28;28;-1;-1;28,f;m,usa,usa,y,1
5687,ICLR,2021,Stabilized Medical Image Attacks,Gege Qi;Lijun GONG;Yibing Song;Kai Ma;Yefeng Zheng,~Gege_Qi1;~Lijun_GONG2;~Yibing_Song1;~Kai_Ma2;~Yefeng_Zheng2,7;8;7,3;5;4,Accept (Spotlight),0,0,0.0,yes,9/28/20,Peking University;Tencent Jarvis Lab;Tencent AI Lab;Tencent Jarvis Lab;Tencent,Healthcare;Biometrics,14;-1;-1;-1;-1,23;-1;-1;-1;-1,f;m,NAN,NAN,n,4
5688,ICLR,2021,Hopper: Multi-hop Transformer for Spatiotemporal Reasoning,Honglu Zhou;Asim Kadav;Farley Lai;Alexandru Niculescu-Mizil;Martin Renqiang Min;Mubbasir Kapadia;Hans Peter Graf,~Honglu_Zhou1;~Asim_Kadav1;~Farley_Lai1;~Alexandru_Niculescu-Mizil1;~Martin_Renqiang_Min1;~Mubbasir_Kapadia2;~Hans_Peter_Graf1,7;6;8;6,4;4;4;3,Accept (Poster),0,11,0.0,yes,9/28/20,Rutgers University;NEC Labs;NEC Laboratories America  Inc.;NEC-Labs;NEC Laboratories America;Rutgers University;NEC Laboratories America,Multi-hop Reasoning;Object Permanence;Spatiotemporal Understanding;Video Recognition;Transformer,29;-1;-1;-1;-1;29;-1,-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,8
5689,ICLR,2021,Viewmaker Networks: Learning Views for Unsupervised Representation Learning,Alex Tamkin;Mike Wu;Noah Goodman,~Alex_Tamkin1;~Mike_Wu1;~Noah_Goodman1,7;6;7;6,3;3;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,unsupervised learning;self-supervised;representation learning;contrastive learning;views;data augmentation,5;5;5,2;2;2,m;m,usa,usa,n,5;4
5690,ICLR,2021,Pruning Neural Networks at Initialization: Why Are We Missing the Mark?,Jonathan Frankle;Gintare Karolina Dziugaite;Daniel Roy;Michael Carbin,~Jonathan_Frankle1;~Gintare_Karolina_Dziugaite1;~Daniel_Roy1;~Michael_Carbin1,7;6;9;4,3;5;5;4,Accept (Poster),0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;ServiceNow;Vector Institute;Massachusetts Institute of Technology,Pruning;Sparsity;Lottery Ticket;Science,5;-1;-1;5,4;-1;-1;4,m;m,usa,usa,n,
5691,ICLR,2021,MixKD: Towards Efficient Distillation of Large-scale Language Models,Kevin J Liang;Weituo Hao;Dinghan Shen;Yufan Zhou;Weizhu Chen;Changyou Chen;Lawrence Carin,~Kevin_J_Liang1;~Weituo_Hao1;~Dinghan_Shen1;~Yufan_Zhou1;~Weizhu_Chen1;~Changyou_Chen1;~Lawrence_Carin2,6;5;7;6,3;4;3;4,Accept (Poster),0,12,0.0,yes,9/28/20,"Facebook;Duke University;Microsoft;State University of New York, Buffalo;Microsoft;State University of New York, Buffalo;Duke University",Natural Language Processing;Representation Learning,-1;46;-1;-1;-1;-1;46,-1;20;-1;-1;-1;-1;20,m;m,europe,se,y,3;1
5692,ICLR,2021,Self-supervised Learning from a Multi-view Perspective,Yao-Hung Hubert Tsai;Yue Wu;Ruslan Salakhutdinov;Louis-Philippe Morency,~Yao-Hung_Hubert_Tsai1;~Yue_Wu17;~Ruslan_Salakhutdinov1;~Louis-Philippe_Morency1,6;7;6;6,3;5;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie-Mellon University;Carnegie Mellon University,Self-supervised Learning;Unsupervised Learning;Multi-view Representation Learning,1;1;1;1,28;28;28;28,m;m,usa,usa,y,2;1
5693,ICLR,2021,FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning,Hong-You Chen;Wei-Lun Chao,~Hong-You_Chen1;~Wei-Lun_Chao1,6;5;7;6,4;2;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,Ohio State University;Ohio State University,,58;58,78;78,m;m,usa,usa,n,11
5694,ICLR,2021,QPLEX: Duplex Dueling Multi-Agent Q-Learning,Jianhao Wang;Zhizhou Ren;Terry Liu;Yang Yu;Chongjie Zhang,~Jianhao_Wang1;~Zhizhou_Ren1;~Terry_Liu2;~Yang_Yu5;~Chongjie_Zhang1,6;6;4;7,4;5;4;2,Accept (Poster),0,12,0.0,yes,9/28/20,"Tsinghua University;University of Illinois, Urbana Champaign;Tsinghua University, Tsinghua University;Nanjing University;Tsinghua University",Multi-agent reinforcement learning;Value factorization;Dueling structure,4;-1;4;52;4,20;-1;20;111;20,m;m,asia,cn,y,
5695,ICLR,2021,CPR: Classifier-Projection Regularization for Continual Learning,Sungmin Cha;Hsiang Hsu;Taebaek Hwang;Flavio Calmon;Taesup Moon,~Sungmin_Cha1;~Hsiang_Hsu1;gxq9106@gmail.com;~Flavio_Calmon1;~Taesup_Moon1,4;7;6;6,4;4;4;5,Accept (Poster),0,0,0.0,yes,9/28/20,Sungkyunkwan University;Harvard University;;;Harvard University;Seoul National University,continual learning;regularization;wide local minima,-1;53;-1;-1;53;37,100;3;-1;-1;3;60,m;m,asia,kr,n,1
5696,ICLR,2021,Improved Autoregressive Modeling with Distribution Smoothing,Chenlin Meng;Jiaming Song;Yang Song;Shengjia Zhao;Stefano Ermon,~Chenlin_Meng1;~Jiaming_Song1;~Yang_Song1;~Shengjia_Zhao1;~Stefano_Ermon1,7;7;8;7,3;4;3;3,Accept (Oral),0,4,0.0,yes,9/28/20,"Stanford University;Computer Science Department, Stanford University;Stanford University;Stanford University;Stanford University",generative models;autoregressive models,5;5;5;5;5,2;2;2;2;2,f;m,usa,usa,y,5;4
5697,ICLR,2021,GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images,Sungmin Cha;Taeeon Park;Byeongjoon Kim;Jongduk Baek;Taesup Moon,~Sungmin_Cha1;pte1236@skku.edu;bjkim2006@naver.com;jongdukbaek@yonsei.ac.kr;~Taesup_Moon1,7;4;7;7,4;3;3;5,Accept (Poster),0,0,0.0,yes,9/28/20,Sungkyunkwan University;Department of Electronic and Electrical Engineering;Yonsei University;Yonsei unicersity;Seoul National University,blind denoising;unsupervised learning;iterative training;generative learning,-1;-1;150;150;37,100;-1;186;-1;60,m;m,asia,kr,y,5
5698,ICLR,2021,Knowledge distillation via softmax regression representation learning,Jing Yang;Brais Martinez;Adrian Bulat;Georgios Tzimiropoulos,~Jing_Yang7;~Brais_Martinez3;~Adrian_Bulat1;~Georgios_Tzimiropoulos1,6;7;6;7,4;4;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,University of Nottingham;Samsung;Samsung AI Center Cambridge;Queen Mary University London,,209;-1;-1;-1,158;-1;-1;-1,f;m,europe,uk,n,
5699,ICLR,2021,Improving VAEs' Robustness to Adversarial Attack,Matthew JF Willetts;Alexander Camuto;Tom Rainforth;S Roberts;Christopher C Holmes,~Matthew_JF_Willetts1;acamuto@turing.ac.uk;~Tom_Rainforth1;~S_Roberts1;cholmes@stats.ox.ac.uk,7;6;7;6,3;5;2;3,Accept (Poster),0,11,0.0,yes,9/28/20,University College London;University of Oxford;University of Oxford;University of Oxford;University of Oxford,deep generative models;variational autoencoders;robustness;adversarial attack,53;46;46;46;46,-1;1;1;1;1,m;m,europe,uk,y,5;4
5700,ICLR,2021,A teacher-student framework to distill future trajectories,Alexander Neitz;Giambattista Parascandolo;Bernhard Sch√∂lkopf,~Alexander_Neitz1;~Giambattista_Parascandolo1;~Bernhard_Sch√∂lkopf1,6;6;6;6,3;3;4;2,Accept (Poster),0,7,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Swiss Federal Institute of Technology;Max Planck Institute for Intelligent Systems, Max-Planck Institute",meta-learning;privileged information,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5701,ICLR,2021,Policy-Driven Attack: Learning to Query for Hard-label Black-box Adversarial Examples,Ziang Yan;Yiwen Guo;Jian Liang;Changshui Zhang,~Ziang_Yan1;~Yiwen_Guo1;~Jian_Liang3;~Changshui_Zhang1,6;7;7;7,4;3;3;5,Accept (Poster),0,7,0.0,yes,9/28/20,Tsinghua University;ByteDance;Alibaba Group;Tsinghua University,hard-label attack;black-box attack;adversarial attack;reinforcement learning,4;-1;-1;4,20;-1;-1;20,m;m,asia,cn,n,4
5702,ICLR,2021,"SAFENet: A Secure, Accurate and Fast Neural Network Inference",Qian Lou;Yilin Shen;Hongxia Jin;Lei Jiang,~Qian_Lou1;~Yilin_Shen1;~Hongxia_Jin1;~Lei_Jiang1,6;5;7;7,3;3;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Indiana University, Bloomington;Samsung Research America;Samsung Research America AI center;Indiana University",Cryptographic inference;Channel-Wise Approximated Activation;Hyper-Parameter Optimization;Garbled Circuits,64;-1;-1;64,140;-1;-1;140,m;m,usa,usa,n,
5703,ICLR,2021,CaPC Learning: Confidential and Private Collaborative Learning,Christopher A. Choquette-Choo;Natalie Dullerud;Adam Dziedzic;Yunxiang Zhang;Somesh Jha;Nicolas Papernot;Xiao Wang,~Christopher_A._Choquette-Choo1;~Natalie_Dullerud1;~Adam_Dziedzic1;~Yunxiang_Zhang1;~Somesh_Jha1;~Nicolas_Papernot1;~Xiao_Wang11,7;7;7,4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,"Google;Toronto University;Toronto University;The Chinese University of Hong Kong;Department of Computer Science, University of Wisconsin, Madison;University of Toronto;Northwestern University",machine learning;deep learning;privacy;confidentiality;security;homomorphic encryption;mpc;differential privacy,-1;-1;-1;327;-1;18;46,-1;-1;-1;39;-1;18;24,m;m,usa,usa,n,7
5704,ICLR,2021,High-Capacity Expert Binary Networks,Adrian Bulat;Brais Martinez;Georgios Tzimiropoulos,~Adrian_Bulat1;~Brais_Martinez3;~Georgios_Tzimiropoulos1,5;4;6;7,2;5;4;3,Accept (Poster),0,18,0.0,yes,9/28/20,Samsung AI Center Cambridge;Samsung;Queen Mary University London,,-1;-1;-1,-1;-1;-1,m;m,europe,uk,n,
5705,ICLR,2021,Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs,Pim De Haan;Maurice Weiler;Taco Cohen;Max Welling,~Pim_De_Haan1;~Maurice_Weiler1;~Taco_Cohen1;~Max_Welling1,7;7;7;9,4;4;3;4,Accept (Spotlight),0,11,0.0,yes,9/28/20,"University of Amsterdam;University of Amsterdam;University of Amsterdam;Donald Bren School of Information and Computer Sciences, University of California, Irvine",symmetry;equivariance;mesh;geometric;convolution,128;128;128;-1,66;66;66;98,m;m,NAN,NAN,n,10
5706,ICLR,2021,InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective,Boxin Wang;Shuohang Wang;Yu Cheng;Zhe Gan;Ruoxi Jia;Bo Li;Jingjing Liu,~Boxin_Wang1;~Shuohang_Wang1;~Yu_Cheng1;~Zhe_Gan1;ruoxijia@vt.edu;~Bo_Li19;~Jingjing_Liu2,6;8;4,3;2;4,Accept (Poster),0,8,0.0,yes,9/28/20,"Department of Computer Science, University of Illinois, Urbana Champaign;Microsoft;Microsoft Research;Microsoft;Virginia Tech;University of Illinois, Urbana Champaign;Microsoft",adversarial robustness;information theory;BERT;adversarial training;NLI;QA,-1;-1;-1;-1;64;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,y,3;4
5707,ICLR,2021,In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness,Sang Michael Xie;Ananya Kumar;Robbie Jones;Fereshte Khani;Tengyu Ma;Percy Liang,~Sang_Michael_Xie1;~Ananya_Kumar1;rmjones@stanford.edu;~Fereshte_Khani1;~Tengyu_Ma1;~Percy_Liang1,7;7;7,3;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,pre-training;self-training theory;robustness;out-of-distribution;unlabeled data;auxiliary information;multi-task learning theory;distribution shift,5;5;5;5;5;5,2;2;2;2;2;2,m;m,usa,usa,y,
5708,ICLR,2021,Interpreting and Boosting Dropout from a Game-Theoretic View,Hao Zhang;Sen Li;YinChao Ma;Mingjie Li;Yichen Xie;Quanshi Zhang,~Hao_Zhang22;~Sen_Li2;~YinChao_Ma1;~Mingjie_Li3;~Yichen_Xie1;~Quanshi_Zhang1,7;7;7;5,5;4;5;1,Accept (Poster),0,8,0.0,yes,9/28/20,Shanghai Jiao Tong University;SUN YAT-SEN UNIVERSITY;Huazhong University of Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Dropout;Interpretability;Interactions,29;-1;-1;29;29;29,100;293;312;100;100;100,m;m,asia,cn,n,1
5709,ICLR,2021,Selective Classification Can Magnify Disparities Across Groups,Erik Jones;Shiori Sagawa;Pang Wei Koh;Ananya Kumar;Percy Liang,~Erik_Jones3;~Shiori_Sagawa1;~Pang_Wei_Koh1;~Ananya_Kumar1;~Percy_Liang1,8;7;5;7,4;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,selective classification;group disparities;log-concavity;robustness,5;5;5;5;5,2;2;2;2;2,m;m,usa,usa,y,3;1
5710,ICLR,2021,A Hypergradient Approach to Robust Regression without Correspondence,Yujia Xie;Yixiu Mao;Simiao Zuo;Hongteng Xu;Xiaojing Ye;Tuo Zhao;Hongyuan Zha,~Yujia_Xie1;956986044myx@gmail.com;~Simiao_Zuo1;~Hongteng_Xu1;~Xiaojing_Ye1;~Tuo_Zhao1;~Hongyuan_Zha1,6;8;5;7,3;5;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Georgia Institute of Technology;Shanghai Jiao Tong University;Georgia Institute of Technology;Renmin University of China;Georgia State University;Georgia Institute of Technology;The Chinese University of Hong Kong, Shenzhen",Regression without correspondence;differentiable programming;first-order optimization;Sinkhorn algorithm,12;29;12;85;327;12;46,38;100;38;517;494;38;39,f;m,NAN,NAN,y,
5711,ICLR,2021,Neural Topic Model via Optimal Transport,He Zhao;Dinh Phung;Viet Huynh;Trung Le;Wray Buntine,~He_Zhao1;~Dinh_Phung2;~Viet_Huynh1;~Trung_Le2;~Wray_Buntine1,7;6;7;8,3;4;3;4,Accept (Spotlight),0,0,0.0,yes,9/28/20,Monash University;Monash University;Monash University;Monash University;Monash University,topic modelling;optimal transport;document analysis,92;92;92;92;92,64;64;64;64;64,m;m,australasia,au,y,1;5
5712,ICLR,2021,Solving Compositional Reinforcement Learning Problems via Task Reduction,Yunfei Li;Yilin Wu;Huazhe Xu;Xiaolong Wang;Yi Wu,~Yunfei_Li1;wuyilin98@gmail.com;~Huazhe_Xu1;~Xiaolong_Wang3;~Yi_Wu1,3;5;6;7,3;4;4;3,Accept (Poster),0,8,0.0,yes,9/28/20,"Institute for Interdisciplinary Information Sciences, Tsinghua University;Stanford University;University of California Berkeley;University of California, San Diego;Tsinghua University",compositional task;sparse reward;reinforcement learning;task reduction;imitation learning,4;5;-1;-1;4,20;2;7;33;20,m;m,asia,cn,n,
5713,ICLR,2021,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,Lee Xiong;Chenyan Xiong;Ye Li;Kwok-Fung Tang;Jialin Liu;Paul N. Bennett;Junaid Ahmed;Arnold Overwijk,~Lee_Xiong1;~Chenyan_Xiong1;yeli1@microsoft.com;kwokfung.tang@microsoft.com;jialliu@microsoft.com;~Paul_N._Bennett1;jahmed@microsoft.com;arnold.overwijk@microsoft.com,6;7;9;6,3;3;5;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Microsoft;Microsoft Research;;;;;;;Microsoft;University of Washington, Seattle;Microsoft",Dense Retrieval;Text Retrieval;Text Representation;Neural IR,-1;-1;-1;-1;-1;-1;-1;-1;-1;11;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;29;-1,m;m,NAN,NAN,n,1
5714,ICLR,2021,Parameter-Based Value Functions,Francesco Faccio;Louis Kirsch;J√ºrgen Schmidhuber,~Francesco_Faccio1;~Louis_Kirsch1;~J√ºrgen_Schmidhuber1,7;7;7;6,4;5;4;4,Accept (Poster),0,18,0.0,yes,9/28/20,The Swiss AI Lab IDSIA;DeepMind;IDSIA,Reinforcement Learning;Off-Policy Reinforcement Learning,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,6;1
5715,ICLR,2021,Towards Robust Neural Networks via Close-loop Control,Zhuotong Chen;Qianxiao Li;Zheng Zhang,~Zhuotong_Chen1;~Qianxiao_Li1;~Zheng_Zhang2,7;6;7;7,4;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,UC Santa Barbara;National University of Singapore;UC Santa Barbara,neural network robustness;optimal control;dynamical system,-1;17;-1,-1;25;-1,m;m,NAN,NAN,y,
5716,ICLR,2021,Transient Non-stationarity and Generalisation in Deep Reinforcement Learning,Maximilian Igl;Gregory Farquhar;Jelena Luketina;Wendelin Boehmer;Shimon Whiteson,~Maximilian_Igl1;~Gregory_Farquhar1;~Jelena_Luketina1;~Wendelin_Boehmer1;~Shimon_Whiteson1,7;5;5;8,4;3;5;4,Accept (Poster),0,8,0.0,yes,9/28/20,University of Oxford;DeepMind;University of Oxford;Delft University of Technology;University of Oxford,Reinforcement Learning;Generalization,46;-1;46;-1;46,1;-1;1;78;1,m;m,europe,uk,n,
5717,ICLR,2021,What Should Not Be Contrastive in Contrastive Learning,Tete Xiao;Xiaolong Wang;Alexei A Efros;Trevor Darrell,~Tete_Xiao1;~Xiaolong_Wang3;~Alexei_A_Efros1;~Trevor_Darrell2,5;7;6;8,4;3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"University of California Berkeley;University of California, San Diego;University of California Berkeley;Electrical Engineering & Computer Science Department",Self-supervised learning;Contrastive learning;Representation learning,-1;-1;-1;-1,7;33;7;-1,m;m,NAN,NAN,n,6
5718,ICLR,2021,Extreme Memorization via Scale of Initialization,Harsh Mehta;Ashok Cutkosky;Behnam Neyshabur,~Harsh_Mehta1;~Ashok_Cutkosky1;~Behnam_Neyshabur1,7;7;9,4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Indian Institute of Technology Guwahati;Boston University;Google,Scale of initialization;Memorization;Overfitting;Generalization;Generalization Measure;Understanding Deep Learning,-1;79;-1,-1;54;-1,m;m,NAN,NAN,y,1
5719,ICLR,2021,Convex Potential Flows: Universal Probability Distributions with Optimal Transport and Convex Optimization,Chin-Wei Huang;Ricky T. Q. Chen;Christos Tsirigotis;Aaron Courville,~Chin-Wei_Huang1;~Ricky_T._Q._Chen1;~Christos_Tsirigotis1;~Aaron_Courville3,7;6;5;8,4;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,University of Montreal;University of Toronto;University of Montreal;University of Montreal,Normalizing flows;generative models;variational inference;invertible neural networks;universal approximation;optimal transport;convex optimization,128;18;128;128,73;18;73;73,m;m,canada,ca,y,1;9
5720,ICLR,2021,Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds,Efthymios Tzinis;Scott Wisdom;Aren Jansen;Shawn Hershey;Tal Remez;Dan Ellis;John R. Hershey,~Efthymios_Tzinis1;~Scott_Wisdom1;arenjansen@google.com;shershey@google.com;talremez@google.com;~Dan_Ellis1;~John_R._Hershey1,6;6;6;7,4;4;4;4,Accept (Poster),0,14,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Google Research;Google;;;;;;Google",Audio-visual sound separation;in-the-wild data;unsupervised learning;self-supervised learning;universal sound separation,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;2
5721,ICLR,2021,Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability,Jeremy Cohen;Simran Kaur;Yuanzhi Li;J Zico Kolter;Ameet Talwalkar,~Jeremy_Cohen1;skaur@andrew.cmu.edu;~Yuanzhi_Li1;~J_Zico_Kolter1;~Ameet_Talwalkar1,8;8;5;6,4;5;4;4,Accept (Poster),0,28,0.0,yes,9/28/20,"Carnegie Mellon University;;;CMU, Carnegie Mellon University;Carnegie Mellon University;University of California-Los Angeles",optimization;trajectory;stability;sharpness;implicit bias;implicit regularization;L-smoothness;deep learning theory;science of deep learning,1;-1;-1;1;1;-1,28;-1;-1;28;28;15,m;m,usa,usa,y,1
5722,ICLR,2021,Multiplicative Filter Networks,Rizal Fathony;Anit Kumar Sahu;Devin Willmott;J Zico Kolter,~Rizal_Fathony1;~Anit_Kumar_Sahu1;~Devin_Willmott1;~J_Zico_Kolter1,8;6;6;9,3;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,Bosch Center for AI;Amazon Alexa AI;Bosch Center for AI;Carnegie Mellon University,Deep Architectures;Implicit Neural Representations;Fourier Features,-1;-1;-1;1,-1;-1;-1;28,m;m,usa,usa,n,
5723,ICLR,2021,Learning to Make Decisions via Submodular Regularization,Ayya Alieva;Aiden Aceves;Jialin Song;Stephen Mayo;Yisong Yue;Yuxin Chen,alievaayya@gmail.com;aaceves@caltech.edu;~Jialin_Song1;~Stephen_Mayo1;~Yisong_Yue1;~Yuxin_Chen1,6;7;7,4;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,Stanford University;California Institute of Technology;California Institute of Technology;;California Institute of Technology;University of Chicago,,5;150;150;-1;150;46,2;4;4;-1;4;10,f;m,usa,usa,y,11;1
5724,ICLR,2021,The Importance of Pessimism in Fixed-Dataset Policy Optimization,Jacob Buckman;Carles Gelada;Marc G Bellemare,~Jacob_Buckman2;cgel@openai.com;~Marc_G_Bellemare1,6;6;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;;;McGill University",deep learning;reinforcement learning;offline reinforcement learning,128;-1;-1;99,73;-1;-1;40,m;m,canada,ca,y,10
5725,ICLR,2021,Using latent space regression to analyze and leverage compositionality in GANs,Lucy Chai;Jonas Wulff;Phillip Isola,~Lucy_Chai1;~Jonas_Wulff1;~Phillip_Isola1,7;5;8;5,4;4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Computer Science and Artificial Intelligence Laboratory, Electrical Engineering & Computer Science;Massachusetts Institute of Technology",Image Synthesis;Composition;Generative Adversarial Networks;Image Editing;Interpretability,5;-1;5,4;-1;4,f;m,usa,usa,n,5;4
5726,ICLR,2021,Large Scale Image Completion via Co-Modulated Generative Adversarial Networks,Shengyu Zhao;Jonathan Cui;Yilun Sheng;Yue Dong;Xiao Liang;Eric I-Chao Chang;Yan Xu,~Shengyu_Zhao1;~Jonathan_Cui1;simon1727@qq.com;dongyue8@gmail.com;liangx@rdfz.cn;echang@microsoft.com;~Yan_Xu2,6;8;4;7;8,4;3;3;3;5,Accept (Spotlight),0,6,0.0,yes,9/28/20,Institute for Interdisciplinary Information Sciences  Tsinghua University;Vacaville Christian Schools;;;;;Beihang University,image completion;generative adversarial networks;co-modulation,4;-1;-1;-1;-1;-1;99,20;-1;-1;-1;-1;-1;567,m;f,asia,cn,n,1;5;4
5727,ICLR,2021,Generative Scene Graph Networks,Fei Deng;Zhuo Zhi;Donghun Lee;Sungjin Ahn,~Fei_Deng1;~Zhuo_Zhi1;donghun@etri.re.kr;~Sungjin_Ahn1,4;6;6;6,3;4;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Rutgers University;University of California, San Diego;;;Rutgers University",object-centric representations;generative modeling;scene generation;variational autoencoders,29;-1;-1;-1;29,-1;33;-1;-1;-1,u;m,usa,usa,n,10;1;5
5728,ICLR,2021,Learning explanations that are hard to vary,Giambattista Parascandolo;Alexander Neitz;ANTONIO ORVIETO;Luigi Gresele;Bernhard Sch√∂lkopf,~Giambattista_Parascandolo1;~Alexander_Neitz1;~ANTONIO_ORVIETO2;~Luigi_Gresele1;~Bernhard_Sch√∂lkopf1,5;7;2;9,4;3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Swiss Federal Institute of Technology;Max-Planck-Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute",invariances;consistency;gradient alignment,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
5729,ICLR,2021,Sharper Generalization Bounds for Learning with Gradient-dominated Objective Functions,Yunwen Lei;Yiming Ying,~Yunwen_Lei1;~Yiming_Ying1,6;7;5;6,3;3;3;2,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Birmingham;State University of New York, Albany",generalization bounds;non-convex learning,128;-1,107;-1,m;m,NAN,NAN,y,1;9
5730,ICLR,2021,Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time,Tolga Ergen;Mert Pilanci,~Tolga_Ergen1;~Mert_Pilanci3,7;6;7,3;4;2,Accept (Spotlight),0,9,0.0,yes,9/28/20,Stanford University;Stanford University,Convex optimization;non-convex optimization;group sparsity;$\ell_1$ norm;convex duality;polynomial time;deep learning,5;5,2;2,m;m,usa,usa,y,1;9
5731,ICLR,2021,Exemplary Natural Images Explain CNN Activations Better than State-of-the-Art Feature Visualization,Judy Borowski;Roland Simon Zimmermann;Judith Schepers;Robert Geirhos;Thomas S. A. Wallis;Matthias Bethge;Wieland Brendel,~Judy_Borowski1;~Roland_Simon_Zimmermann1;judith-schepers@web.de;~Robert_Geirhos1;~Thomas_S._A._Wallis1;~Matthias_Bethge1;~Wieland_Brendel1,8;5;6;7,5;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Tuebingen;Centre for Integrative Neuroscience, AG Bethge;;;University of T√ºbingen & International Max Planck Research School for Intelligent Systems;TU Darmstadt;University of Tuebingen;T√ºbingen AI Center, University of T√ºbingen",evaluation of interpretability;feature visualization;activation maximization;human psychophysics;understanding CNNs;explanation method,128;-1;-1;-1;128;64;128;128,78;-1;-1;-1;78;-1;78;78,f;m,NAN,NAN,n,
5732,ICLR,2021,Group Equivariant Stand-Alone Self-Attention For Vision,David W. Romero;Jean-Baptiste Cordonnier,~David_W._Romero1;~Jean-Baptiste_Cordonnier2,6;8;6;7,3;5;5;4,Accept (Poster),0,9,0.0,yes,9/28/20,Vrije Universiteit Amsterdam;Swiss Federal Institute of Technology Lausanne,group equivariant transformers;group equivariant self-attention;group equivariance;self-attention;transformers,-1;-1,116;-1,m;m,NAN,NAN,y,8
5733,ICLR,2021,Pre-training Text-to-Text Transformers for Concept-centric Common Sense,Wangchunshu Zhou;Dong-Ho Lee;Ravi Kiran Selvam;Seyeon Lee;Xiang Ren,~Wangchunshu_Zhou1;~Dong-Ho_Lee1;~Ravi_Kiran_Selvam1;~Seyeon_Lee1;~Xiang_Ren1,8;7;8;4,4;4;4;4,Accept (Poster),0,16,0.0,yes,9/28/20,Beihang University;University of Southern California;University of Southern California;University of Southern California;University of Southern California,Language Model Pre-training;Commonsense Reasoning;Self-supervised Learning,99;37;37;37;37,567;53;53;53;53,m;m,usa,usa,n,6;8;3;5
5734,ICLR,2021,SSD: A Unified Framework for Self-Supervised Outlier Detection,Vikash Sehwag;Mung Chiang;Prateek Mittal,~Vikash_Sehwag1;~Mung_Chiang2;~Prateek_Mittal1,6;6;7;6,5;5;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Princeton University;Purdue University;Princeton University,Outlier detection;Out-of-distribution detection in deep learning;Anomaly detection with deep neural networks;Self-supervised learning,29;23;29,9;94;9,m;m,usa,usa,n,6
5735,ICLR,2021,Symmetry-Aware Actor-Critic for 3D Molecular Design,Gregor N. C. Simm;Robert Pinsler;G√°bor Cs√°nyi;Jos√© Miguel Hern√°ndez-Lobato,~Gregor_N._C._Simm1;~Robert_Pinsler1;gc121@cam.ac.uk;~Jos√©_Miguel_Hern√°ndez-Lobato1,8;6;6,4;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;;;University of Cambridge,deep reinforcement learning;molecular design;covariant neural networks,79;79;-1;-1;79,6;6;-1;-1;6,m;m,europe,uk,n,1;10
5736,ICLR,2021,Tent: Fully Test-Time Adaptation by Entropy Minimization,Dequan Wang;Evan Shelhamer;Shaoteng Liu;Bruno Olshausen;Trevor Darrell,~Dequan_Wang1;~Evan_Shelhamer2;~Shaoteng_Liu1;~Bruno_Olshausen1;~Trevor_Darrell2,7;8;7,4;3;5,Accept (Spotlight),0,7,0.0,yes,9/28/20,University of California Berkeley;DeepMind;Xi'an Jiaotong University;University of California Berkeley;Electrical Engineering & Computer Science Department,deep learning;unsupervised learning;domain adaptation;self-supervision;robustness,-1;-1;-1;-1;-1,7;-1;445;7;-1,m;m,NAN,NAN,n,2;1
5737,ICLR,2021,The role of Disentanglement in Generalisation,Milton Llera Montero;Casimir JH Ludwig;Rui Ponte Costa;Gaurav Malhotra;Jeffrey Bowers,~Milton_Llera_Montero1;c.ludwig@bristol.ac.uk;~Rui_Ponte_Costa3;~Gaurav_Malhotra1;~Jeffrey_Bowers1,5;6;7;8,4;4;4;5,Accept (Poster),0,7,0.0,yes,9/28/20,University of Bristol;;;University of Bristol;University of Bristol;University of Bristol,disentanglement;compositionality;compositional generalization;generalisation;generative models;variational autoencoders,110;-1;-1;110;110;110,91;-1;-1;91;91;91,m;m,europe,uk,n,5
5738,ICLR,2021,Learning Deep Features in Instrumental Variable Regression,Liyuan Xu;Yutian Chen;Siddarth Srinivasan;Nando de Freitas;Arnaud Doucet;Arthur Gretton,~Liyuan_Xu1;~Yutian_Chen1;sidsrini@cs.washington.edu;~Nando_de_Freitas1;~Arnaud_Doucet2;~Arthur_Gretton1,6;5;7;8,2;3;4;5,Accept (Poster),0,8,0.0,yes,9/28/20,"University College London;DeepMind;Department of Computer Science, University of Washington;DeepMind;Google DeepMind;University College London",Causal Inference;Instrumental Variable Regression;Deep Learning;Reinforcement Learning,53;-1;11;-1;-1;53,-1;-1;29;-1;-1;-1,m;m,europe,uk,y,
5739,ICLR,2021,Group Equivariant Conditional Neural Processes,Makoto Kawano;Wataru Kumagai;Akiyoshi Sannai;Yusuke Iwasawa;Yutaka Matsuo,~Makoto_Kawano1;~Wataru_Kumagai2;~Akiyoshi_Sannai1;~Yusuke_Iwasawa1;~Yutaka_Matsuo1,6;5;7;4,3;4;2;2,Accept (Poster),0,5,0.0,yes,9/28/20,"The University of Tokyo, Tokyo Institute of Technology;The University of Tokyo;RIKEN;The University of Tokyo;The University of Tokyo",Neural Processes;Conditional Neural Processes;Stochastic Processes;Regression;Group Equivariance;Symmetry,71;71;-1;71;71,36;36;-1;36;36,m;m,NAN,NAN,y,6;1
5740,ICLR,2021,Latent Skill Planning for Exploration and Transfer,Kevin Xie;Homanga Bharadhwaj;Danijar Hafner;Animesh Garg;Florian Shkurti,~Kevin_Xie1;~Homanga_Bharadhwaj1;~Danijar_Hafner1;~Animesh_Garg1;~Florian_Shkurti1,5;6;7;6,4;3;4;3,Accept (Poster),0,12,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;School of Computer Science, Carnegie Mellon University;Department of Computer Science, University of Toronto;University of Toronto;Department of Computer Science, University of Toronto",Model-Based Reinforcement Learning;World Models;Skill Discovery;Mutual Information;Planning;Model Predictive Control;Partial Amortization,18;1;18;18;18,18;28;18;18;18,m;m,NAN,NAN,n,
5741,ICLR,2021,ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity,Kangkang Lu;Cuong Manh Nguyen;Xun Xu;Kiran Chari;Yu Jing Goh;Chuan-Sheng Foo,~Kangkang_Lu1;~Cuong_Manh_Nguyen1;~Xun_Xu1;~Kiran_Chari1;~Yu_Jing_Goh1;~Chuan-Sheng_Foo1,7;7;7;7,4;5;5;3,Accept (Poster),0,6,0.0,yes,9/28/20,"A*STAR;A*STAR;A*STAR;National University of Singapore;National University of Singapore;Institute for Infocomm Research, A*STAR",Adversarial Robustness;Semi-supervised Learning;Multi-view Learning;Diversity Regularization;Entropy Maximization,-1;-1;-1;17;17;-1,-1;-1;-1;25;25;-1,u;m,NAN,NAN,y,1;4
5742,ICLR,2021,Dataset Inference: Ownership Resolution in Machine Learning,Pratyush Maini;Mohammad Yaghini;Nicolas Papernot,~Pratyush_Maini1;~Mohammad_Yaghini1;~Nicolas_Papernot1,7;7;7,4;4;4,Accept (Spotlight),0,11,0.0,yes,9/28/20,Indian Institute of Technology Delhi;Toronto University;University of Toronto,model ownership;model extraction;MLaaS,-1;-1;18,-1;-1;18,m;m,canada,ca,y,4
5743,ICLR,2021,not-MIWAE: Deep Generative Modelling with Missing not at Random Data,Niels Bruun Ipsen;Pierre-Alexandre Mattei;Jes Frellsen,~Niels_Bruun_Ipsen1;~Pierre-Alexandre_Mattei3;~Jes_Frellsen1,4;6;7;6,3;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Technical University of Denmark;INRIA;Technical University of Denmark,,-1;-1;-1,186;-1;186,m;m,NAN,NAN,y,1
5744,ICLR,2021,Batch Reinforcement Learning Through Continuation Method,Yijie Guo;Shengyu Feng;Nicolas Le Roux;Ed Chi;Honglak Lee;Minmin Chen,~Yijie_Guo1;~Shengyu_Feng1;~Nicolas_Le_Roux2;~Ed_Chi1;~Honglak_Lee2;~Minmin_Chen1,7;9;6;4,4;4;4;5,Accept (Poster),0,7,0.0,yes,9/28/20,University of Michigan;Intel;Google;;LG AI Research;Machine Learning Science Team at Amazon,batch reinforcement learning;continuation method;relaxed regularization,7;-1;-1;-1;-1;-1,22;-1;-1;-1;-1;-1,f;f,NAN,NAN,y,
5745,ICLR,2021,A Learning Theoretic Perspective on Local Explainability,Jeffrey Li;Vaishnavh Nagarajan;Gregory Plumb;Ameet Talwalkar,~Jeffrey_Li1;~Vaishnavh_Nagarajan3;~Gregory_Plumb2;~Ameet_Talwalkar1,7;7;5,3;4;3,Accept (Poster),0,4,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;University of California-Los Angeles",Interpretability;Learning Theory;Local Explanations;Generalization,11;1;1;-1,29;28;28;15,m;m,usa,usa,y,1
5746,ICLR,2021,Bayesian Few-Shot Classification with One-vs-Each P√≥lya-Gamma Augmented Gaussian Processes,Jake Snell;Richard Zemel,~Jake_Snell1;~Richard_Zemel1,7;7;6;8,4;3;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of Toronto",few-shot learning;gaussian processes;bayesian deep learning;uncertainty estimation,18;18,18;18,m;m,canada,ca,n,6;11
5747,ICLR,2021,Group Equivariant Generative Adversarial Networks,Neel Dey;Antong Chen;Soheil Ghafurian,~Neel_Dey1;~Antong_Chen2;~Soheil_Ghafurian1,6;6;5;6,4;4;2;4,Accept (Poster),0,9,0.0,yes,9/28/20,"New York University;MERCK & CO., INC.;Merck & C",Group Equivariance;Geometric Deep Learning;Generative Adversarial Networks,23;-1;-1,26;-1;-1,m;m,NAN,NAN,n,5;4
5748,ICLR,2021,Zero-Cost Proxies for Lightweight NAS,Mohamed S Abdelfattah;Abhinav Mehrotra;≈Åukasz Dudziak;Nicholas Donald Lane,~Mohamed_S_Abdelfattah1;a.mehrotra1@samsung.com;~≈Åukasz_Dudziak1;~Nicholas_Donald_Lane1,7;6;5;6,4;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Samsung AI Center;University College London;Samsung;Department of Computer Science, University of Oxford",NAS;AutoML;proxy;pruning;efficient,-1;53;-1;46,-1;-1;-1;1,m;m,NAN,NAN,n,
5749,ICLR,2021,Revisiting Hierarchical Approach for Persistent Long-Term Video Prediction,Wonkwang Lee;Whie Jung;Han Zhang;Ting Chen;Jing Yu Koh;Thomas Huang;Hyungsuk Yoon;Honglak Lee;Seunghoon Hong,~Wonkwang_Lee2;~Whie_Jung1;~Han_Zhang1;~Ting_Chen1;~Jing_Yu_Koh2;thomaseh@umich.edu;~Hyungsuk_Yoon2;~Honglak_Lee2;~Seunghoon_Hong2,7;6;6;5,5;4;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Rutgers University;Google;Google;University of Michigan;MOLOCO;LG AI Research;Korea Advanced Institute of Science and Technology,Video prediction;generative model;long-term prediction,-1;-1;29;-1;-1;7;-1;-1;-1,96;96;-1;-1;-1;22;-1;-1;96,m;m,NAN,NAN,n,
5750,ICLR,2021,Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks,Jan Schuchardt;Aleksandar Bojchevski;Johannes Klicpera;Stephan G√ºnnemann,~Jan_Schuchardt1;~Aleksandar_Bojchevski1;~Johannes_Klicpera1;~Stephan_G√ºnnemann1,8;7;5;6,2;3;1;1,Accept (Poster),0,5,0.0,yes,9/28/20,"Department of Informatics, Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich",Robustness certificates;Adversarial robustness;Graph neural networks,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,2;3;10;4
5751,ICLR,2021,NAS-Bench-ASR: Reproducible Neural Architecture Search for Speech Recognition,Abhinav Mehrotra;Alberto Gil C. P. Ramos;Sourav Bhattacharya;≈Åukasz Dudziak;Ravichander Vipperla;Thomas Chau;Mohamed S Abdelfattah;Samin Ishtiaq;Nicholas Donald Lane,~Abhinav_Mehrotra1;a.gilramos@samsung.com;~Sourav_Bhattacharya1;~≈Åukasz_Dudziak1;~Ravichander_Vipperla1;thomas.chau@samsung.com;~Mohamed_S_Abdelfattah1;s.ishtiaq@samsung.com;~Nicholas_Donald_Lane1,4;6;6;7;5,5;4;4;3;5,Accept (Poster),0,8,0.0,yes,9/28/20,"University College London;Samsung;Samsung;Samsung;Samsung;Samsung;Samsung AI Center;;;Department of Computer Science, University of Oxford",NAS;ASR;Benchmark,53;-1;-1;-1;-1;-1;-1;-1;-1;46,-1;-1;-1;-1;-1;-1;-1;-1;-1;1,m;m,NAN,NAN,n,8;2;3
5752,ICLR,2021,Practical Massively Parallel Monte-Carlo Tree Search Applied to Molecular Design,Xiufeng Yang;Tanuj Aasawat;Kazuki Yoshizoe,~Xiufeng_Yang1;~Tanuj_Aasawat1;~Kazuki_Yoshizoe2,8;3;7;5;7,3;3;3;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,RIKEN;University of British Columbia;RIKEN,parallel Monte Carlo Tree Search (MCTS);Upper Confidence bound applied to Trees (UCT);molecular design,-1;58;-1,-1;34;-1,m;m,NAN,NAN,n,
5753,ICLR,2021,CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning,Ossama Ahmed;Frederik Tr√§uble;Anirudh Goyal;Alexander Neitz;Manuel Wuthrich;Yoshua Bengio;Bernhard Sch√∂lkopf;Stefan Bauer,~Ossama_Ahmed1;~Frederik_Tr√§uble1;~Anirudh_Goyal1;~Alexander_Neitz1;~Manuel_Wuthrich1;~Yoshua_Bengio1;~Bernhard_Sch√∂lkopf1;~Stefan_Bauer1,6;4;8;7,3;4;4;3,Accept (Poster),0,10,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;, Max Planck Institute for Intelligent Systems;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Swiss Federal Institute of Technology",reinforcement learning;transfer learning;sim2real transfer;domain adaptation;causality;generalization;robotics,-1;-1;128;-1;-1;128;-1;-1,-1;-1;73;-1;-1;73;-1;-1,m;m,NAN,NAN,n,6;1
5754,ICLR,2021,Ringing ReLUs: Harmonic Distortion Analysis of Nonlinear Feedforward Networks,Christian H.X. Ali Mehmeti-G√∂pel;David Hartmann;Michael Wand,~Christian_H.X._Ali_Mehmeti-G√∂pel1;~David_Hartmann1;michael.wand@uni-mainz.de,5;8;8;4,4;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Mainz;University of Mainz, Institute of Computer Science;University of Mainz",deep learning theory;loss landscape;harmonic distortion analysis;network trainability,327;327;327,310;-1;310,m;m,europe,il,n,
5755,ICLR,2021,Understanding Over-parameterization in Generative Adversarial Networks,Yogesh Balaji;Mohammadmahdi Sajedi;Neha Mukund Kalibhat;Mucong Ding;Dominik St√∂ger;Mahdi Soltanolkotabi;Soheil Feizi,~Yogesh_Balaji1;sajedi@usc.edu;~Neha_Mukund_Kalibhat1;~Mucong_Ding1;~Dominik_St√∂ger1;~Mahdi_Soltanolkotabi1;~Soheil_Feizi2,6;6;4;7,3;2;5;3,Accept (Poster),0,9,0.0,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;University of Southern California;University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park;University of Southern California;University of Southern California;University of Maryland, College Park",GAN;Over-parameterization;min-max optimization,-1;37;12;-1;37;37;12,90;53;90;90;53;53;90,m;m,usa,usa,y,1;5;4;9
5756,ICLR,2021,On the Curse of Memory in Recurrent Neural Networks: Approximation and Optimization Analysis,Zhong Li;Jiequn Han;Weinan E;Qianxiao Li,~Zhong_Li2;~Jiequn_Han1;~Weinan_E1;~Qianxiao_Li1,6;8;3;8,3;4;2;4,Accept (Poster),0,14,0.0,yes,9/28/20,Peking University;Princeton University;;National University of Singapore,recurrent neural network;dynamical system;universal approximation;optimization;curse of memory,14;29;-1;17,23;9;-1;25,u;m,asia,sg,y,1
5757,ICLR,2021,Global optimality of softmax policy gradient with single hidden layer neural networks in the mean-field regime,Andrea Agazzi;Jianfeng Lu,~Andrea_Agazzi2;~Jianfeng_Lu1,7;7;7;7,3;4;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,Duke University;Duke University,policy gradient;entropy regularization;mean-field dynamics;neural networks,46;46,20;20,m;m,europe,se,y,1
5758,ICLR,2021,Scalable Transfer Learning with Expert Models,Joan Puigcerver;Carlos Riquelme Ruiz;Basil Mustafa;Cedric Renggli;Andr√© Susano Pinto;Sylvain Gelly;Daniel Keysers;Neil Houlsby,~Joan_Puigcerver1;~Carlos_Riquelme_Ruiz1;basilm@google.com;~Cedric_Renggli1;~Andr√©_Susano_Pinto1;~Sylvain_Gelly1;~Daniel_Keysers2;~Neil_Houlsby1,5;7;7;6,4;4;2;3,Accept (Poster),0,9,0.0,yes,9/28/20,"Google;Google;Google;Swiss Federal Institute of Technology;Research, Google;Google Brain;Google;Google",Transfer Learning;Expert Models;Few Shot,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5759,ICLR,2021,Learning Subgoal Representations with Slow Dynamics,Siyuan Li;Lulu Zheng;Jianhao Wang;Chongjie Zhang,~Siyuan_Li1;zll19@mails.tsinghua.edu.cn;wjh19@mails.tsinghua.edu.cn;~Chongjie_Zhang1,7;6;7;4,3;3;2;5,Accept (Poster),0,15,0.0,yes,9/28/20,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University",Hierarchical Reinforcement Learning;Representation Learning;Exploration,4;4;4;4,20;20;20;20,f;m,asia,cn,y,
5760,ICLR,2021,Representation Balancing Offline Model-based Reinforcement Learning,Byung-Jun Lee;Jongmin Lee;Kee-Eung Kim,~Byung-Jun_Lee1;~Jongmin_Lee1;~Kee-Eung_Kim4,7;7;6;7,4;4;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Model-based Reinforcement Learning;Offline Reinforcement Learning;Batch Reinforcement Learning;Off-policy policy evaluation,-1;-1;-1,96;96;96,m;m,NAN,NAN,y,
5761,ICLR,2021,Generating Adversarial Computer Programs using Optimized Obfuscations,Shashank Srikant;Sijia Liu;Tamara Mitrovska;Shiyu Chang;Quanfu Fan;Gaoyuan Zhang;Una-May O'Reilly,~Shashank_Srikant1;~Sijia_Liu1;tamaram@mit.edu;~Shiyu_Chang2;~Quanfu_Fan1;~Gaoyuan_Zhang1;~Una-May_O'Reilly1,6;6;7,3;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Michigan State University;;;UC Santa Barbara;MIT-IBM Watson AI Lab;International Business Machines;Massachusetts Institute of Technology,Machine Learning (ML) for Programming Languages (PL)/Software Engineering (SE);Adversarial computer programs;Program obfuscation;Combinatorial optimization;Differentiable program generator;Models for code,5;110;-1;-1;-1;-1;-1;5,4;105;-1;-1;-1;-1;-1;4,m;f,usa,usa,n,4
5762,ICLR,2021,TropEx: An Algorithm for Extracting Linear Terms in Deep Neural Networks,Martin Trimmel;Henning Petzka;Cristian Sminchisescu,~Martin_Trimmel1;~Henning_Petzka1;~Cristian_Sminchisescu1,6;6;8;6,3;3;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,Lund University / Lund Institute of Technology;Lund University;Lund University,linear regions;linear terms;deep learning theory;deep neural networks;rectified linear unit;relu network;piecewise linear function;tropical function,453;453;453,103;103;103,m;m,asia,cn,y,1
5763,ICLR,2021,Scalable Bayesian Inverse Reinforcement Learning,Alex James Chan;Mihaela van der Schaar,~Alex_James_Chan1;~Mihaela_van_der_Schaar2,7;6;7;6,4;3;4;3,Accept (Poster),0,12,0.0,yes,9/28/20,University of Cambridge;University of Cambridge,Bayesian;Inverse reinforcement learning;Imitation Learning,79;79,6;6,m;f,europe,uk,n,11;10
5764,ICLR,2021,Rethinking Embedding Coupling in Pre-trained Language Models,Hyung Won Chung;Thibault Fevry;Henry Tsai;Melvin Johnson;Sebastian Ruder,~Hyung_Won_Chung1;~Thibault_Fevry1;henrytsai@google.com;~Melvin_Johnson1;~Sebastian_Ruder2,4;7;6;7,5;3;3;5,Accept (Poster),0,6,0.0,yes,9/28/20,Google;Point72;Columbia University;Google;Google,natural language processing;transfer learning;efficiency;pre-training,-1;-1;23;-1;-1,-1;-1;17;-1;-1,m;m,NAN,NAN,n,8;3
5765,ICLR,2021,Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time,Yu Cheng;Honghao Lin,~Yu_Cheng2;~Honghao_Lin1,4;5;7;7,4;4;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,University of Illinois at Chicago;Carnegie Mellon University,Bayesian networks;robust statistics;learning theory,53;1,276;28,m;m,usa,usa,y,11;10;4
5766,ICLR,2021,The Intrinsic Dimension of Images and Its Impact on Learning,Phil Pope;Chen Zhu;Ahmed Abdelkader;Micah Goldblum;Tom Goldstein,~Phil_Pope1;~Chen_Zhu2;~Ahmed_Abdelkader1;~Micah_Goldblum1;~Tom_Goldstein1,7;7;8;6,4;4;4;3,Accept (Spotlight),0,4,0.0,yes,9/28/20,"University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park;University of Texas, Austin;University of Maryland, College Park;University of Maryland, College Park",generalization;dimension;manifold;ImageNet;CIFAR,12;-1;-1;12;12,90;90;-1;90;90,m;m,usa,usa,n,2;5
5767,ICLR,2021,Neural Learning of One-of-Many Solutions for Combinatorial Problems in Structured Output Spaces,Yatin Nandwani;Deepanshu Jindal;Mausam .;Parag Singla,~Yatin_Nandwani1;deepanshujindal.99@gmail.com;~Mausam_.1;~Parag_Singla1,5;6;5;8,3;3;3;4,Accept (Poster),0,10,0.0,yes,9/28/20,"Indian Institute of Technology Delhi;Indian Institute of Technology Delhi, Dhirubhai Ambani Institute Of Information and Communication Technology;Indian Institute of Technology Delhi;IIT Delhi",Neuro symbolic;constraint satisfaction;reasoning,-1;-1;-1;150,-1;-1;-1;-1,m;m,asia,in,n,
5768,ICLR,2021,Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning,Wonyong Jeong;Jaehong Yoon;Eunho Yang;Sung Ju Hwang,~Wonyong_Jeong1;~Jaehong_Yoon1;~Eunho_Yang1;~Sung_Ju_Hwang1,6;6;4;6,3;3;3;3,Accept (Poster),0,12,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology,Federated Learning,-1;-1;-1;-1,96;96;-1;96,m;m,NAN,NAN,n,
5769,ICLR,2021,Personalized Federated Learning with First Order Model Optimization,Michael Zhang;Karan Sapra;Sanja Fidler;Serena Yeung;Jose M. Alvarez,~Michael_Zhang4;~Karan_Sapra2;~Sanja_Fidler1;~Serena_Yeung1;~Jose_M._Alvarez2,6;7;6;6,3;3;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,"Stanford University;Clemson University;Department of Computer Science, University of Toronto;Stanford University;NVIDIA",Federated learning;personalized learning,5;174;18;5;-1,2;799;18;2;-1,m;m,NAN,NAN,n,
5770,ICLR,2021,MARS: Markov Molecular Sampling for Multi-objective Drug Discovery,Yutong Xie;Chence Shi;Hao Zhou;Yuwei Yang;Weinan Zhang;Yong Yu;Lei Li,~Yutong_Xie3;~Chence_Shi1;zhouhao.nlp@bytedance.com;yuwei.yang@bytedance.com;~Weinan_Zhang1;~Yong_Yu1;~Lei_Li11,4;7;6;8,5;4;4;5,Accept (Spotlight),0,14,0.0,yes,9/28/20,University of Michigan;University of Montreal;Bytedance;New York University;Shanghai Jiao Tong University;;ByteDance AI Lab,drug discovery;molecular graph generation;MCMC sampling,7;128;-1;23;29;-1;-1,22;73;-1;26;100;-1;-1,f;m,NAN,NAN,n,10
5771,ICLR,2021,Fantastic Four: Differentiable and Efficient Bounds on Singular Values of Convolution Layers,Sahil Singla;Soheil Feizi,~Sahil_Singla1;~Soheil_Feizi2,8;5;3;4,5;4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park",spectral regularization;spectral normalization,12;12,90;90,m;m,usa,usa,y,1
5772,ICLR,2021,No Cost Likelihood Manipulation at Test Time for Making Better Mistakes in Deep Networks,Shyamgopal Karthik;Ameya Prabhu;Puneet K. Dokania;Vineet Gandhi,~Shyamgopal_Karthik1;~Ameya_Prabhu1;~Puneet_K._Dokania1;~Vineet_Gandhi2,6;6;7;8,4;3;2;4,Accept (Poster),0,9,0.0,yes,9/28/20,IIIT Hyderabad;University of Oxford;University of Oxford;International Institute of Information Technology Hyderabad,Hierarchy-Aware Classification;Conditional Risk Minimization;Post-Hoc Correction,174;46;46;-1,-1;1;1;-1,m;m,NAN,NAN,y,10
5773,ICLR,2021,A Discriminative Gaussian Mixture Model with Sparsity,Hideaki Hayashi;Seiichi Uchida,~Hideaki_Hayashi1;~Seiichi_Uchida1,6;8;5;7,4;5;3;4,Accept (Poster),0,14,0.0,yes,9/28/20,Kyushu University;Kyushu University,classification;sparse Bayesian learning;Gaussian mixture model,-1;-1,452;452,m;m,NAN,NAN,n,11;1
5774,ICLR,2021,Combining Label Propagation and Simple Models out-performs Graph Neural Networks,Qian Huang;Horace He;Abhay Singh;Ser-Nam Lim;Austin Benson,qh53@cornell.edu;~Horace_He1;as2626@cornell.edu;~Ser-Nam_Lim3;~Austin_Benson1,6;7;7;6,3;4;4;4,Accept (Poster),0,12,0.0,yes,9/28/20,Allen Institute for Artificial Intelligence;Cornell University;Cornell University;Facebook;Cornell University,graphs;graph neural networks;label propagation;simple;residual,-1;7;7;-1;7,-1;19;19;-1;19,f;m,usa,usa,n,10
5775,ICLR,2021,PolarNet: Learning to Optimize Polar Keypoints for Keypoint Based Object Detection,Wu Xiongwei;Doyen Sahoo;Steven HOI,~Wu_Xiongwei1;~Doyen_Sahoo1;~Steven_HOI1,6;3;8;6,4;5;5;4,Accept (Poster),0,4,0.0,yes,9/28/20,Singapore Management University;Singapore Management University;Singapore Management University,Object Detection;Deep Learning,79;79;79,-1;-1;-1,m;m,asia,sg,n,
5776,ICLR,2021,Combining Physics and Machine Learning for Network Flow Estimation,Arlei Lopes da Silva;Furkan Kocayusufoglu;Saber Jafarpour;Francesco Bullo;Ananthram Swami;Ambuj Singh,~Arlei_Lopes_da_Silva1;furkan@cs.ucsb.edu;saber@ucsb.edu;bullo@engineering.ucsb.edu;~Ananthram_Swami1;~Ambuj_Singh1,7;4;6;7,3;5;5;3,Accept (Poster),0,4,0.0,yes,9/28/20,UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;Army Research Labortory;UC Santa Barbara,graphs;networks;bilevel optimization;metalearning;flow graphs,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5777,ICLR,2021,Reset-Free Lifelong Learning with Skill-Space Planning,Kevin Lu;Aditya Grover;Pieter Abbeel;Igor Mordatch,~Kevin_Lu2;~Aditya_Grover1;~Pieter_Abbeel2;~Igor_Mordatch4,6;7;6;5,3;3;3;3,Accept (Poster),0,9,0.0,yes,9/28/20,"University of California Berkeley;Computer Science Department, Stanford University;Covariant;University of Washington",reset-free;lifelong;reinforcement learning,-1;5;-1;11,7;2;-1;29,m;m,usa,usa,n,
5778,ICLR,2021,Self-supervised Visual Reinforcement Learning with Object-centric Representations,Andrii Zadaianchuk;Maximilian Seitzer;Georg Martius,~Andrii_Zadaianchuk1;~Maximilian_Seitzer1;~Georg_Martius1,8;7;5;9,3;5;5;5,Accept (Spotlight),0,10,0.0,yes,9/28/20,"Max-Planck-Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems",self-supervision;autonomous learning;object-centric representations;visual reinforcement learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;5
5779,ICLR,2021,Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning,Zhiyuan Li;Yuping Luo;Kaifeng Lyu,~Zhiyuan_Li2;~Yuping_Luo1;~Kaifeng_Lyu2,6;8;7;6,4;3;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,"Department of Computer Science, Princeton University;Princeton University;Princeton University",matrix factorization;gradient descent;implicit regularization;implicit bias,29;29;29,9;9;9,m;m,usa,usa,y,
5780,ICLR,2021,Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods,Taiji Suzuki;Shunta Akiyama,~Taiji_Suzuki1;shunta_akiyama@mist.i.u-tokyo.ac.jp,7;8;6;8,4;3;2;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,The University of Tokyo;The University of Tokyo,Excess risk;minimax optimal rate;local Rademacher complexity;fast learning rate;kernel method;linear estimator,71;71,36;36,m;u,NAN,NAN,y,1
5781,ICLR,2021,Provable Rich Observation Reinforcement Learning with Combinatorial Latent States,Dipendra Misra;Qinghua Liu;Chi Jin;John Langford,~Dipendra_Misra1;~Qinghua_Liu1;~Chi_Jin1;jcl@microsoft.com,6;7;5;7,2;4;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,Microsoft Research;Princeton University;Princeton University;Microsoft,Reinforcement learning theory;Rich observation;Noise-contrastive learning;State abstraction;Factored MDP,-1;29;29;-1,-1;9;9;-1,m;m,NAN,NAN,y,
5782,ICLR,2021,IDF++: Analyzing and Improving Integer Discrete Flows for Lossless Compression,Rianne van den Berg;Alexey A. Gritsenko;Mostafa Dehghani;Casper Kaae S√∏nderby;Tim Salimans,~Rianne_van_den_Berg1;~Alexey_A._Gritsenko1;~Mostafa_Dehghani1;~Casper_Kaae_S√∏nderby1;~Tim_Salimans1,7;6;7;7,4;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,Google;Google;Google Brain;Google;Google,normalizing flows;lossless source compression;generative modeling,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,y,1
5783,ICLR,2021,Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning,Aviral Kumar;Rishabh Agarwal;Dibya Ghosh;Sergey Levine,~Aviral_Kumar2;~Rishabh_Agarwal2;~Dibya_Ghosh1;~Sergey_Levine1,6;8;7;5,2;4;3;4,Accept (Poster),0,16,0.0,yes,9/28/20,"University of California Berkeley;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of California Berkeley;University of Washington",deep Q-learning;data-efficient RL;rank-collapse;offline RL,-1;128;-1;11,7;73;7;29,m;m,usa,usa,y,
5784,ICLR,2021,Adaptive Procedural Task Generation for Hard-Exploration Problems,Kuan Fang;Yuke Zhu;Silvio Savarese;Fei-Fei Li,~Kuan_Fang3;~Yuke_Zhu1;~Silvio_Savarese1;~Fei-Fei_Li1,6;6;4;7,4;4;4;3,Accept (Poster),0,17,0.0,yes,9/28/20,"Stanford University;Computer Science Department, University of Texas, Austin;Salesforce;Stanford University",reinforcement learning;curriculum learning;procedural generation;task generation,5;-1;-1;5,2;-1;-1;2,m;f,usa,usa,n,4
5785,ICLR,2021,Complex Query Answering with Neural Link Predictors,Erik Arakelyan;Daniel Daza;Pasquale Minervini;Michael Cochez,erik.arakelyan.18@alumni.ucl.ac.uk;dfdazac@gmail.com;~Pasquale_Minervini1;~Michael_Cochez2,9;8;6;9,4;4;5;2,Accept (Oral),0,6,0.0,yes,9/28/20,University College London;Vrije Universiteit Amsterdam;University College London;VU Amsterdam,neural link prediction;complex query answering,53;-1;53;174,-1;116;-1;-1,m;m,europe,nl,n,3;10
5786,ICLR,2021,Language-Agnostic Representation Learning of Source Code from Structure and Context,Daniel Z√ºgner;Tobias Kirschstein;Michele Catasta;Jure Leskovec;Stephan G√ºnnemann,~Daniel_Z√ºgner1;tobias.kirschstein@tum.de;~Michele_Catasta1;~Jure_Leskovec1;~Stephan_G√ºnnemann1,6;6;7;7,5;4;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,Technical University Munich;Technical University Munich;Stanford University;Stanford University;Technical University Munich,machine learning for code;code summarization,-1;-1;5;5;-1,-1;-1;2;2;-1,m;m,NAN,NAN,n,
5787,ICLR,2021,Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime,Atsushi Nitanda;Taiji Suzuki,~Atsushi_Nitanda1;~Taiji_Suzuki1,7;7;8;8;8,2;3;2;4;5,Accept (Oral),0,7,0.0,yes,9/28/20,Kyushu Institute of Technology;The University of Tokyo,stochastic gradient descent;two-layer neural network;over-parameterization;neural tangent kernel,-1;71,1152;36,m;m,NAN,NAN,y,9
5788,ICLR,2021,A Geometric Analysis of Deep Generative Image Models and Its Applications,Binxu Wang;Carlos R Ponce,~Binxu_Wang1;~Carlos_R_Ponce1,5;6;6;5,4;4;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,"Washington University, St. Louis;Washington University, St. Louis",Deep generative model;Interpretability;GAN;Differential Geometry;Optimization;Model Inversion;Feature Visualization,-1;-1,-1;-1,m;m,usa,usa,n,5;4
5789,ICLR,2021,What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study,Marcin Andrychowicz;Anton Raichuk;Piotr Sta≈Ñczyk;Manu Orsini;Sertan Girgin;Rapha√´l Marinier;Leonard Hussenot;Matthieu Geist;Olivier Pietquin;Marcin Michalski;Sylvain Gelly;Olivier Bachem,~Marcin_Andrychowicz1;~Anton_Raichuk1;stanczyk@google.com;eorsini@google.com;sertan@google.com;~Rapha√´l_Marinier1;~Leonard_Hussenot1;~Matthieu_Geist1;~Olivier_Pietquin1;~Marcin_Michalski1;~Sylvain_Gelly1;~Olivier_Bachem1,9;7;9;7,3;4;3;4,Accept (Oral),0,5,0.0,yes,9/28/20,Google;Google;;;;;;;Google;Google;Google;Google Brain;Google;Google Brain;Google Brain,Reinforcement learning;continuous control,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5790,ICLR,2021,RODE: Learning Roles to Decompose Multi-Agent Tasks,Tonghan Wang;Tarun Gupta;Anuj Mahajan;Bei Peng;Shimon Whiteson;Chongjie Zhang,~Tonghan_Wang1;~Tarun_Gupta3;~Anuj_Mahajan1;~Bei_Peng2;~Shimon_Whiteson1;~Chongjie_Zhang1,8;7;6,3;4;4,Accept (Poster),0,3,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;University of Oxford;University of Oxford;University of Oxford;University of Oxford;Tsinghua University",Multi-Agent Reinforcement Learning;Role-Based Learning;Hierarchical Multi-Agent Learning;Multi-Agent Transfer Learning,4;46;46;46;46;4,20;1;1;1;1;20,m;m,asia,cn,n,1
5791,ICLR,2021,DOP: Off-Policy Multi-Agent Decomposed Policy Gradients,Yihan Wang;Beining Han;Tonghan Wang;Heng Dong;Chongjie Zhang,~Yihan_Wang1;~Beining_Han1;~Tonghan_Wang1;~Heng_Dong1;~Chongjie_Zhang1,7;3;9;7,4;5;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",Multi-Agent Reinforcement Learning;Multi-Agent Policy Gradients,4;4;4;4;4,20;20;20;20;20,u;m,asia,cn,y,
5792,ICLR,2021,Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic,Deunsol Yoon;Sunghoon Hong;Byung-Jun Lee;Kee-Eung Kim,~Deunsol_Yoon1;~Sunghoon_Hong2;~Byung-Jun_Lee1;~Kee-Eung_Kim4,7;9;7;7,4;4;3;2,Accept (Spotlight),0,9,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,power grid management;deep reinforcement learning;graph neural network,-1;-1;-1;-1,96;96;96;96,m;m,NAN,NAN,n,
5793,ICLR,2021,Acting in Delayed Environments with Non-Stationary Markov Policies,Esther Derman;Gal Dalal;Shie Mannor,~Esther_Derman1;~Gal_Dalal2;~Shie_Mannor2,6;6;8;5,4;4;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Israel Institute of Technology;NVIDIA;Israel Institute of Technology,reinforcement learning;delay,-1;-1;-1,408;-1;408,f;m,NAN,NAN,y,1;10
5794,ICLR,2021,GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing,Tao Yu;Chien-Sheng Wu;Xi Victoria Lin;bailin wang;Yi Chern Tan;Xinyi Yang;Dragomir Radev;richard socher;Caiming Xiong,~Tao_Yu5;~Chien-Sheng_Wu1;~Xi_Victoria_Lin1;~bailin_wang1;yichern.tan@yale.edu;x.yang@salesforce.com;~Dragomir_Radev2;~richard_socher1;~Caiming_Xiong1,7;7;5;7,4;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Yale University;Salesforce AI Research;Facebook;University of Edinburgh;Yale University;;;Yale University;SalesForce.com;Salesforce Research,text-to-sql;semantic parsing;pre-training;nlp,71;-1;-1;29;71;-1;-1;71;-1;-1,8;-1;-1;30;8;-1;-1;8;-1;-1,m;m,NAN,NAN,n,3;10
5795,ICLR,2021,The Recurrent Neural Tangent Kernel,Sina Alemohammad;Zichao Wang;Randall Balestriero;Richard Baraniuk,~Sina_Alemohammad1;~Zichao_Wang1;~Randall_Balestriero1;~Richard_Baraniuk1,7;6;6,4;4;3,Accept (Poster),0,3,0.0,yes,9/28/20,Rice University;Rice University;Rice University;William Marsh Rice University,Neural Tangent Kernel;Recurrent Neural Network;Gaussian Process;Overparameterization,92;92;92;92,124;124;124;124,m;m,NAN,NAN,y,1
5796,ICLR,2021,Calibration tests beyond classification,David Widmann;Fredrik Lindsten;Dave Zachariah,~David_Widmann1;fredrik.lindsten@liu.se;dave.zachariah@it.uu.se,9;5;7,4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,Uppsala University;Link√∂ping University;Uppsala University,calibration;uncertainty quantification;framework;integral probability metric;maximum mean discrepancy,174;-1;174,111;410;111,m;m,europe,se,y,
5797,ICLR,2021,Robust Curriculum Learning: from clean label detection to noisy label self-correction,Tianyi Zhou;Shengjie Wang;Jeff Bilmes,~Tianyi_Zhou1;~Shengjie_Wang1;~Jeff_Bilmes1,6;6;5;5,5;5;4;4,Accept (Poster),0,14,0.0,yes,9/28/20,"University of Washington;University of Washington;University of Washington, Seattle",curriculum learning;noisy label;robust learning;training dynamics;neural networks,11;11;11,29;29;29,m;m,NAN,NAN,n,1
5798,ICLR,2021,RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs,Meng Qu;Junkun Chen;Louis-Pascal Xhonneux;Yoshua Bengio;Jian Tang,~Meng_Qu2;chenjk17@mails.tsinghua.edu.cn;xhonneul@mila.quebec;~Yoshua_Bengio1;~Jian_Tang1,6;7;6;8,4;4;2;1,Accept (Poster),0,10,0.0,yes,9/28/20,"University of Montreal;Tsinghua University, Tsinghua University;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Montreal;HEC Montreal",Knowledge Graph Reasoning;Logic Rules;EM,128;4;128;128;-1,73;20;73;73;-1,m;m,canada,ca,y,1;10
5799,ICLR,2021,Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning,Dong Bok Lee;Dongchan Min;Seanie Lee;Sung Ju Hwang,~Dong_Bok_Lee1;~Dongchan_Min1;~Seanie_Lee1;~Sung_Ju_Hwang1,7;7;8;7,5;4;3;4,Accept (Spotlight),0,22,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Unsupervised Learning;Meta-Learning;Unsupervised Meta-learning;Variational Autoencoders,-1;-1;-1;-1,96;96;96;96,m;m,NAN,NAN,n,6;5
5800,ICLR,2021,Monte-Carlo Planning and Learning with Language Action Value Estimates,Youngsoo Jang;Seokin Seo;Jongmin Lee;Kee-Eung Kim,~Youngsoo_Jang2;~Seokin_Seo1;~Jongmin_Lee1;~Kee-Eung_Kim4,4;7;7;6,4;4;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,natural language processing;Monte-Carlo tree search;reinforcement learning;interactive fiction,-1;-1;-1;-1,96;96;96;96,m;m,NAN,NAN,n,3
5801,ICLR,2021,SEDONA: Search for Decoupled Neural Networks toward Greedy Block-wise Learning,Myeongjang Pyeon;Jihwan Moon;Taeyoung Hahn;Gunhee Kim,~Myeongjang_Pyeon1;~Jihwan_Moon2;~Taeyoung_Hahn1;~Gunhee_Kim1,7;6;7,4;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University,AutoML;Neural Architecture Search;Greedy Learning;Deep Learning,37;37;37;37,60;60;60;60,m;m,asia,kr,n,
5802,ICLR,2021,Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning,Rishabh Agarwal;Marlos C. Machado;Pablo Samuel Castro;Marc G Bellemare,~Rishabh_Agarwal2;~Marlos_C._Machado1;~Pablo_Samuel_Castro1;~Marc_G_Bellemare1,7;6;6;7,3;3;3;3,Accept (Spotlight),0,5,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;DeepMind;Google;McGill University",Reinforcement;Generalization;Contrastive learning;Bisimulation;Representation Learning,128;-1;-1;99,73;-1;-1;40,m;m,canada,ca,y,1
5803,ICLR,2021,Learning-based Support Estimation in Sublinear Time,Talya Eden;Piotr Indyk;Shyam Narayanan;Ronitt Rubinfeld;Sandeep Silwal;Tal Wagner,talyaa01@gmail.com;~Piotr_Indyk1;shyamsn@mit.edu;~Ronitt_Rubinfeld1;silwal@mit.edu;~Tal_Wagner1,8;7;8;7,4;4;3;4,Accept (Spotlight),0,11,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Microsoft,support estimation;sublinear;learning-based;distinct elements;chebyshev polynomial,5;5;5;5;5;-1,4;4;4;4;4;-1,f;m,NAN,NAN,y,1
5804,ICLR,2021,Multi-Time Attention Networks for Irregularly Sampled Time Series,Satya Narayan Shukla;Benjamin Marlin,~Satya_Narayan_Shukla1;~Benjamin_Marlin1,6;7;7;7,4;4;4;3,Accept (Poster),0,4,0.0,yes,9/28/20,"College of Information and Computer Sciences, University of Massachusetts, Amherst;University of Massachusetts, Amherst",irregular sampling;multivariate time series;attention;missing data,-1;23,210;210,m;m,usa,usa,n,8
5805,ICLR,2021,BUSTLE: Bottom-Up Program Synthesis Through Learning-Guided Exploration,Augustus Odena;Kensen Shi;David Bieber;Rishabh Singh;Charles Sutton;Hanjun Dai,~Augustus_Odena1;~Kensen_Shi1;~David_Bieber1;~Rishabh_Singh1;~Charles_Sutton1;~Hanjun_Dai1,5;9;6;8,3;5;4;3,Accept (Spotlight),0,9,0.0,yes,9/28/20,"Google;Google;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Google Brain;Google;Google Research",Program Synthesis,-1;-1;128;-1;-1;-1,-1;-1;73;-1;-1;-1,m;m,NAN,NAN,n,
5806,ICLR,2021,Evaluation of Similarity-based Explanations,Kazuaki Hanawa;Sho Yokoi;Satoshi Hara;Kentaro Inui,~Kazuaki_Hanawa1;~Sho_Yokoi1;~Satoshi_Hara1;~Kentaro_Inui1,6;7;6;5,3;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Tohoku University;Tohoku University;Osaka University;Tohoku University, Japan",Interpretability;Explainability,-1;-1;150;-1,213;213;350;213,m;m,NAN,NAN,n,
5807,ICLR,2021,CO2: Consistent Contrast for Unsupervised Visual Representation Learning,Chen Wei;Huiyu Wang;Wei Shen;Alan Yuille,~Chen_Wei2;~Huiyu_Wang1;~Wei_Shen2;~Alan_Yuille1,5;6;7;6,5;5;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Shanghai Jiao Tong University;Johns Hopkins University,unsupervised representation learning;contrastive learning;consistency regularization,71;71;29;71,12;12;100;12,f;m,usa,usa,n,2
5808,ICLR,2021,PMI-Masking: Principled masking of correlated spans,Yoav Levine;Barak Lenz;Opher Lieber;Omri Abend;Kevin Leyton-Brown;Moshe Tennenholtz;Yoav Shoham,~Yoav_Levine1;barakl@ai21.com;opherl@ai21.com;~Omri_Abend1;~Kevin_Leyton-Brown1;~Moshe_Tennenholtz1;~Yoav_Shoham1,8;8;7;6,4;4;4;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,Hebrew University of Jerusalem;;;Hebrew University of Jerusalem  Technion;University of British Columbia;Technion;Stanford University,Language modeling;BERT;pointwise mutual information,85;-1;-1;29;58;29;5,235;-1;-1;235;34;408;2,m;m,usa,usa,n,3
5809,ICLR,2021,$i$-Mix: A Domain-Agnostic Strategy for Contrastive Representation Learning,Kibok Lee;Yian Zhu;Kihyuk Sohn;Chun-Liang Li;Jinwoo Shin;Honglak Lee,~Kibok_Lee1;yianz@umich.edu;~Kihyuk_Sohn1;~Chun-Liang_Li1;~Jinwoo_Shin1;~Honglak_Lee2,7;7;3;7,3;5;4;5,Accept (Poster),0,9,0.0,yes,9/28/20,Amazon Web Services;University of Michigan;Google;Google;Korea Advanced Institute of Science and Technology;LG AI Research,self-supervised learning;unsupervised representation learning;contrastive representation learning;data augmentation;MixUp,-1;7;-1;-1;-1;-1,-1;22;-1;-1;96;-1,m;m,NAN,NAN,n,10
5810,ICLR,2021,Bypassing the Ambient Dimension: Private SGD with Gradient Subspace Identification,Yingxue Zhou;Steven Wu;Arindam Banerjee,~Yingxue_Zhou1;~Steven_Wu1;~Arindam_Banerjee1,6;7;6,3;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Minnesota, Minneapolis;Carnegie Mellon University;University of Minnesota-Twin Cities",,71;1;71,85;28;85,f;m,NAN,NAN,y,
5811,ICLR,2021,Lipschitz Recurrent Neural Networks,N. Benjamin Erichson;Omri Azencot;Alejandro Queiruga;Liam Hodgkinson;Michael W. Mahoney,~N._Benjamin_Erichson1;azencot@bgu.ac.il;afq@google.com;~Liam_Hodgkinson1;~Michael_W._Mahoney1,7;6;5;8,4;4;4;3,Accept (Poster),0,13,0.0,yes,9/28/20,University of California Berkeley;Ben-Gurion University of the Negev;Google;University of California Berkeley;University of California Berkeley,recurrent neural networks;dynamical systems;differential equations,-1;209;-1;-1;-1,7;-1;-1;7;7,m;m,usa,usa,y,3;2;1
5812,ICLR,2021,Adversarially-Trained Deep Nets Transfer Better: Illustration on Image Classification,Francisco Utrera;Evan Kravitz;N. Benjamin Erichson;Rajiv Khanna;Michael W. Mahoney,~Francisco_Utrera1;kravitz@berkeley.edu;~N._Benjamin_Erichson1;~Rajiv_Khanna1;~Michael_W._Mahoney1,6;7;6;6,3;4;4;4,Accept (Poster),0,15,0.0,yes,9/28/20,University of California Berkeley;;;University of California Berkeley;University of California Berkeley;University of California Berkeley,transfer learning;adversarial training;influence functions;limited data,-1;-1;-1;-1;-1;-1,7;-1;-1;7;7;7,m;m,usa,usa,n,6;4
5813,ICLR,2021,Probabilistic Numeric Convolutional Neural Networks,Marc Anton Finzi;Roberto Bondesan;Max Welling,~Marc_Anton_Finzi1;~Roberto_Bondesan1;~Max_Welling1,6;7;7;7,4;3;1;3,Accept (Poster),0,5,0.0,yes,9/28/20,"New York University;Qualcomm AI Research;Donald Bren School of Information and Computer Sciences, University of California, Irvine",probabilistic numerics;gaussian processes;discretization error;pde;superpixel;irregularly spaced time series;misssing data;spatial uncertainty,23;-1;-1,26;-1;98,m;m,NAN,NAN,y,
5814,ICLR,2021,Fast And Slow Learning Of Recurrent Independent Mechanisms,Kanika Madan;Nan Rosemary Ke;Anirudh Goyal;Bernhard Sch√∂lkopf;Yoshua Bengio,~Kanika_Madan3;~Nan_Rosemary_Ke1;~Anirudh_Goyal1;~Bernhard_Sch√∂lkopf1;~Yoshua_Bengio1,7;7;7;5,3;4;5;3,Accept (Poster),0,15,0.0,yes,9/28/20,"MILA, University of Montreal;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of Montreal",modular representations;better generalization;learning mechanisms,128;128;128;-1;128,73;73;73;-1;73,f;m,canada,ca,n,6;8;1
5815,ICLR,2021,Learning with Instance-Dependent Label Noise: A Sample Sieve Approach,Hao Cheng;Zhaowei Zhu;Xingyu Li;Yifei Gong;Xing Sun;Yang Liu,~Hao_Cheng5;~Zhaowei_Zhu1;~Xingyu_Li2;~Yifei_Gong1;~Xing_Sun1;~Yang_Liu3,6;6;8,4;4;5,Accept (Poster),0,10,0.0,yes,9/28/20,"Tencent Youtu Lab;University of California, Santa Cruz;University of California, Santa Cruz;Carnegie Mellon University;Tencent YouTu Lab;University of California, Santa Cruz",Learning with noisy labels;instance-based label noise;deep neural networks.,-1;-1;-1;1;-1;-1,-1;207;207;28;-1;207,m;m,usa,usa,y,1
5816,ICLR,2021,Blending MPC & Value Function Approximation for Efficient Reinforcement Learning,Mohak Bhardwaj;Sanjiban Choudhury;Byron Boots,~Mohak_Bhardwaj1;sanjiban.choudhury@gmail.com;~Byron_Boots1,6;6;5;7,3;4;3;4,Accept (Poster),0,12,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;Department of Computer Science, University of Washington;University of Washington",reinforcement learning;model-predictive control,11;11;11,29;29;29,m;m,usa,usa,y,
5817,ICLR,2021,On the Dynamics of Training Attention Models,Haoye Lu;Yongyi Mao;Amiya Nayak,~Haoye_Lu1;~Yongyi_Mao2;nayak@uottawa.ca,6;8;7;4,3;3;2;3,Accept (Poster),0,13,0.0,yes,9/28/20,University of Ottawa;University of Ottawa;University of Ottawa,,263;263;263,145;145;145,m;m,australasia,nz,y,3;8;1
5818,ICLR,2021,Sharpness-aware Minimization for Efficiently Improving Generalization,Pierre Foret;Ariel Kleiner;Hossein Mobahi;Behnam Neyshabur,~Pierre_Foret1;akleiner@google.com;~Hossein_Mobahi2;~Behnam_Neyshabur1,7;8;6;8,4;4;2;3,Accept (Spotlight),0,14,0.0,yes,9/28/20,Google;;;Google;Google,Sharpness Minimization;Generalization;Regularization;Training Method;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
5819,ICLR,2021,On the geometry of generalization and memorization in deep neural networks,Cory Stephenson;suchismita padhy;Abhinav Ganesh;Yue Hui;Hanlin Tang;SueYeon Chung,~Cory_Stephenson1;~suchismita_padhy2;abhinav.ganesh@intel.com;yueh@stanford.edu;~Hanlin_Tang1;~SueYeon_Chung1,7;7;7;7,3;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,Intel;University of California Berkeley;;;;Intel AI Lab;Columbia University,deep learning theory;representation learning;statistical physics methods;double descent,-1;-1;-1;-1;-1;-1;23,-1;7;-1;-1;-1;-1;17,m;f,usa,usa,n,1
5820,ICLR,2021,Individually Fair Gradient Boosting,Alexander Vargo;Fan Zhang;Mikhail Yurochkin;Yuekai Sun,ahsvargo@umich.edu;zhangfan4@shanghaitech.edu.cn;~Mikhail_Yurochkin1;~Yuekai_Sun1,7;7;7,4;4;2,Accept (Spotlight),0,4,0.0,yes,9/28/20,University of Michigan;ShanghaiTech University;International Business Machines;University of Michigan,Algorithmic fairness;boosting;non-smooth models,7;327;-1;7,22;-1;-1;22,m;m,usa,usa,y,10;7
5821,ICLR,2021,Dynamic Tensor Rematerialization,Marisa Kirisame;Steven Lyubomirsky;Altan Haan;Jennifer Brennan;Mike He;Jared Roesch;Tianqi Chen;Zachary Tatlock,jerry96@cs.washington.edu;~Steven_Lyubomirsky1;altanh@cs.washington.edu;jrb@cs.washington.edu;dh63@cs.washington.edu;jroesch@cs.washington.edu;~Tianqi_Chen1;~Zachary_Tatlock1,7;6;7;6,4;4;5;3,Accept (Spotlight),0,6,0.0,yes,9/28/20,"University of Washington;University of Washington;Department of Computer Science, University of Washington;University of Washington, Seattle;Department of Computer Science, University of Washington;OctoML;Carnegie Mellon University;University of Washington",Rematerialization;Memory-saving;Runtime Systems;Checkpointing,11;11;11;11;11;-1;1;11,29;29;29;29;29;-1;28;29,f;m,usa,usa,y,1;10
5822,ICLR,2021,Non-asymptotic Confidence Intervals of Off-policy Evaluation:  Primal and Dual Bounds ,Yihao Feng;Ziyang Tang;na zhang;qiang liu,~Yihao_Feng1;~Ziyang_Tang1;zhangna@pbcsf.tsinghua.edu.cn;~qiang_liu4,7;6;8;7,4;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,"University of Texas at Austin;University of Texas, Austin;Tsinghua University, Tsinghua University;University of Texas, Austin",Non-asymptotic Confidence Intervals;Off Policy Evaluation;Reinforcement Learnings,20;-1;4;-1,43;-1;20;-1,m;m,usa,usa,y,1
5823,ICLR,2021,Understanding the role of importance weighting for deep learning,Da Xu;Yuting Ye;Chuanwei Ruan,~Da_Xu2;yeyt@berkeley.edu;~Chuanwei_Ruan1,7;7;7;7,4;4;1;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;Stanford University,Importance Weighting;Deep Learning;Implicit Bias;Gradient Descent;Learning Theory,-1;-1;5,7;7;2,m;u,usa,usa,y,1
5824,ICLR,2021,Neural Networks for Learning Counterfactual G-Invariances from Single Environments,S Chandra Mouli;Bruno Ribeiro,~S_Chandra_Mouli1;~Bruno_Ribeiro1,7;7;5,2;3;4,Accept (Poster),0,20,0.0,yes,9/28/20,Purdue University;Purdue University,Extrapolation;G-invariance regularization;Counterfactual inference;Invariant subspaces,23;23,94;94,m;m,usa,usa,y,
5825,ICLR,2021,Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis,Rafael Valle;Kevin J. Shih;Ryan Prenger;Bryan Catanzaro,~Rafael_Valle1;~Kevin_J._Shih1;rprenger@nvidia.com;~Bryan_Catanzaro1,9;5;6;6,5;3;3;5,Accept (Poster),0,5,0.0,yes,9/28/20,NVIDIA;NVIDIA;;;University of California Berkeley,Text to speech synthesis;normalizing flows;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;7,m;m,usa,usa,n,5
5826,ICLR,2021,Statistical inference for individual fairness,Subha Maity;Songkai Xue;Mikhail Yurochkin;Yuekai Sun,~Subha_Maity1;sxue@umich.edu;~Mikhail_Yurochkin1;~Yuekai_Sun1,6;6;6,3;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Michigan, Ann Arbor;University of Michigan;International Business Machines;University of Michigan",,7;7;-1;7,22;22;-1;22,m;m,usa,usa,y,8;7;4
5827,ICLR,2021,LambdaNetworks: Modeling long-range Interactions without Attention,Irwan Bello,~Irwan_Bello1,6;6;6;6;8,3;3;4;3;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,Google,deep learning;neural networks;attention;transformer;vision;image classification,-1,-1,m,NAN,NAN,n,8;2
5828,ICLR,2021,Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization,Michael R Zhang;Thomas Paine;Ofir Nachum;Cosmin Paduraru;George Tucker;ziyu wang;Mohammad Norouzi,~Michael_R_Zhang1;~Thomas_Paine1;~Ofir_Nachum1;~Cosmin_Paduraru1;~George_Tucker1;~ziyu_wang1;~Mohammad_Norouzi1,7;6;7,3;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,University of Toronto;Google/DeepMind;Google;DeepMind;Google Brain;Google;Google Brain,Off-policy policy evaluation;autoregressive models;offline reinforcement learning;policy optimization,18;-1;-1;-1;-1;-1;-1,18;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5829,ICLR,2021,Benchmarks for Deep Off-Policy Evaluation,Justin Fu;Mohammad Norouzi;Ofir Nachum;George Tucker;ziyu wang;Alexander Novikov;Mengjiao Yang;Michael R Zhang;Yutian Chen;Aviral Kumar;Cosmin Paduraru;Sergey Levine;Thomas Paine,~Justin_Fu1;~Mohammad_Norouzi1;~Ofir_Nachum1;~George_Tucker1;~ziyu_wang1;~Alexander_Novikov1;~Mengjiao_Yang1;~Michael_R_Zhang1;~Yutian_Chen1;~Aviral_Kumar2;~Cosmin_Paduraru1;~Sergey_Levine1;~Thomas_Paine1,7;6;7;6,4;5;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,University of California Berkeley;Google Brain;Google;Google Brain;Google;Deep Mind;Google;University of Toronto;DeepMind;University of California Berkeley;DeepMind;University of Washington;Google/DeepMind,reinforcement learning;off-policy evaluation;benchmarks,-1;-1;-1;-1;-1;-1;-1;18;-1;-1;-1;11;-1,7;-1;-1;-1;-1;-1;-1;18;-1;7;-1;29;-1,m;m,NAN,NAN,n,
5830,ICLR,2021,Linear Mode Connectivity in Multitask and Continual Learning,Seyed Iman Mirzadeh;Mehrdad Farajtabar;Dilan Gorur;Razvan Pascanu;Hassan Ghasemzadeh,seyediman.mirzadeh@wsu.edu;~Mehrdad_Farajtabar1;~Dilan_Gorur1;~Razvan_Pascanu1;~Hassan_Ghasemzadeh1,7;7;7,5;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,"Washington State University, Pullman;Google;DeepMind;Google DeepMind;Washington State University, Pullman",continual learning;catastrophic forgetting;mode connectivity;multitask learning,174;-1;-1;-1;174,323;-1;-1;-1;323,m;m,NAN,NAN,n,
5831,ICLR,2021,Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks,Alexander Levine;Soheil Feizi,~Alexander_Levine2;~Soheil_Feizi2,8;7;6;4,4;4;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park",bagging;ensemble;robustness;certificate;poisoning;smoothing,12;12,90;90,m;m,usa,usa,n,1;4
5832,ICLR,2021,Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?,Zhiyuan Li;Yi Zhang;Sanjeev Arora,~Zhiyuan_Li2;~Yi_Zhang1;~Sanjeev_Arora1,7;7;8;7,4;3;4;4,Accept (Oral),0,5,0.0,yes,9/28/20,"Department of Computer Science, Princeton University;Princeton University;Princeton University",sample complexity separation;equivariance;convolutional neural networks;fully-connected,29;29;29,9;9;9,m;m,usa,usa,y,1
5833,ICLR,2021,Generative Time-series Modeling with Fourier Flows,Ahmed Alaa;Alex James Chan;Mihaela van der Schaar,~Ahmed_Alaa1;~Alex_James_Chan1;~Mihaela_van_der_Schaar2,5;7;7;6,4;4;4;3,Accept (Poster),0,12,0.0,yes,9/28/20,"University of California, Los Angeles;University of Cambridge;University of Cambridge",,-1;79;79,15;6;6,m;f,europe,uk,n,5;4
5834,ICLR,2021,Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS,Lin Chen;Sheng Xu,~Lin_Chen14;~Sheng_Xu5,8;7;5;7,4;4;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,University of California Berkeley;Yale University,Neural tangent kernel;Reproducing kernel Hilbert space;Laplace kernel;Singularity analysis,-1;71,7;8,m;m,europe,fi,y,1
5835,ICLR,2021,Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition,Yangming Li;lemao liu;Shuming Shi,~Yangming_Li1;~lemao_liu1;~Shuming_Shi1,6;7;5;8,4;4;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Tencent AI Lab;Tencent AI Lab;Tencent AI Lab,Named Entity Recognition;Unlabeled Entity Problem;Negative Sampling,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3
5836,ICLR,2021,Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning,Beliz Gunel;Jingfei Du;Alexis Conneau;Veselin Stoyanov,~Beliz_Gunel1;~Jingfei_Du1;~Alexis_Conneau1;~Veselin_Stoyanov2,7;6;5;6,3;4;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,Stanford University;Facebook;Facebook;Johns Hopkins University,pre-trained language model fine-tuning;supervised contrastive learning;natural language understanding;few-shot learning;robustness;generalization,5;-1;-1;71,2;-1;-1;12,f;m,usa,usa,n,3;1;6
5837,ICLR,2021,Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence Learning,Xuebo Liu;Longyue Wang;Derek F. Wong;Liang Ding;Lidia S. Chao;Zhaopeng Tu,~Xuebo_Liu1;~Longyue_Wang3;~Derek_F._Wong1;~Liang_Ding3;lidiasc@um.edu.mo;~Zhaopeng_Tu1,7;7;5;5,3;4;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Macau;Tencent AI Lab;University of Macau;University of Sydney;;;Tencent AI Lab,Encoder layer fusion;Transformer;Sequence-to-sequence learning;Machine translation;Summarization;Grammatical error correction,-1;-1;-1;71;-1;-1;-1,305;-1;305;51;-1;-1;-1,m;m,NAN,NAN,n,8;3
5838,ICLR,2021,"For self-supervised learning, Rationality implies generalization, provably",Yamini Bansal;Gal Kaplun;Boaz Barak,~Yamini_Bansal1;~Gal_Kaplun1;~Boaz_Barak2,7;3;4;7,4;4;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,Harvard University;Harvard University;Harvard University,Deep Learning Theory;Generalization Bounds;Self-supervised learning;Representation learning,53;53;53,3;3;3,f;m,usa,usa,y,1
5839,ICLR,2021,Mind the Pad -- CNNs Can Develop Blind Spots,Bilal Alsallakh;Narine Kokhlikyan;Vivek Miglani;Jun Yuan;Orion Reblitz-Richardson,~Bilal_Alsallakh1;narine@fb.com;vivekm@fb.com;junyuan@nyu.edu;orionr@fb.com,8;7;8;6,4;3;4;3,Accept (Spotlight),0,4,0.0,yes,9/28/20,Facebook AI;Facebook;Massachusetts Institute of Technology;New York University;Facebook AI,CNN;convolution;spatial bias;blind spots;foveation;padding;exposition;debugging;visualization,-1;-1;5;23;-1,-1;-1;4;26;-1,m;m,NAN,NAN,n,2
5840,ICLR,2021,Vector-output ReLU Neural Network Problems are Copositive Programs: Convex Analysis of Two Layer Networks and Polynomial-time Algorithms,Arda Sahiner;Tolga Ergen;John M. Pauly;Mert Pilanci,~Arda_Sahiner1;~Tolga_Ergen1;~John_M._Pauly1;~Mert_Pilanci3,7;7;7;7,4;2;5;3,Accept (Poster),0,11,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;Stanford University,neural networks;theory;convex optimization;copositive programming;convex duality;nonnegative PCA;semi-nonnegative matrix factorization;computational complexity;global optima;semi-infinite duality;convolutional neural networks,5;5;5;5,2;2;2;2,m;m,usa,usa,y,
5841,ICLR,2021,Convex Regularization behind Neural Reconstruction,Arda Sahiner;Morteza Mardani;Batu Ozturkler;Mert Pilanci;John M. Pauly,~Arda_Sahiner1;~Morteza_Mardani1;ozt@stanford.edu;~Mert_Pilanci3;~John_M._Pauly1,4;6;9;6,4;4;5;4,Accept (Poster),0,7,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,neural networks;image reconstruction;denoising;interpretability;robustness;neural reconstruction;convex duality;inverse problems;sparsity;convex optimization,5;5;5;5;5,2;2;2;2;2,m;m,usa,usa,y,9
5842,ICLR,2021,MONGOOSE: A Learnable LSH Framework for Efficient Neural Network Training,Beidi Chen;Zichang Liu;Binghui Peng;Zhaozhuo Xu;Jonathan Lingjie Li;Tri Dao;Zhao Song;Anshumali Shrivastava;Christopher Re,~Beidi_Chen1;~Zichang_Liu1;~Binghui_Peng1;~Zhaozhuo_Xu1;~Jonathan_Lingjie_Li1;~Tri_Dao1;~Zhao_Song3;~Anshumali_Shrivastava1;~Christopher_Re1,7;7;8;7,3;4;4;4,Accept (Oral),0,12,0.0,yes,9/28/20,"Stanford University;Rice University;Columbia University;Rice University;Computer Science Department, Stanford University;Stanford University;Institue for Advanced Study;Rice University;University of Wisconsin-Madison",Large-scale Deep Learning;Large-scale Machine Learning;Efficient Training;Randomized Algorithms,5;92;23;92;5;5;-1;92;18,2;124;17;124;2;2;-1;124;49,f;m,usa,usa,y,3;1
5843,ICLR,2021,Understanding and Improving Lexical Choice in Non-Autoregressive Translation,Liang Ding;Longyue Wang;Xuebo Liu;Derek F. Wong;Dacheng Tao;Zhaopeng Tu,~Liang_Ding3;~Longyue_Wang3;~Xuebo_Liu1;~Derek_F._Wong1;~Dacheng_Tao1;~Zhaopeng_Tu1,7;6;7,5;4;5,Accept (Poster),0,4,0.0,yes,9/28/20,University of Sydney;Tencent AI Lab;University of Macau;University of Macau;JD.com;Tencent AI Lab,,71;-1;-1;-1;-1;-1,51;-1;305;305;-1;-1,m;m,NAN,NAN,n,
5844,ICLR,2021,A Temporal Kernel Approach for Deep Learning with Continuous-time Information,Da Xu;Chuanwei Ruan;Evren Korpeoglu;Sushant Kumar;Kannan Achan,~Da_Xu2;~Chuanwei_Ruan1;~Evren_Korpeoglu1;~Sushant_Kumar1;~Kannan_Achan1,6;7;7;7,3;3;2;2,Accept (Poster),0,5,0.0,yes,9/28/20,University of California Berkeley;Stanford University;;Carnegie Mellon University;Walmart Labs,Kernel Learning;Continuous-time System;Spectral Distribution;Random Feature;Reparameterization;Learning Theory,-1;5;-1;1;-1,7;2;-1;28;-1,m;m,NAN,NAN,y,8;1
5845,ICLR,2021,Learning Energy-Based Models by Diffusion Recovery Likelihood,Ruiqi Gao;Yang Song;Ben Poole;Ying Nian Wu;Diederik P Kingma,~Ruiqi_Gao2;~Yang_Song1;~Ben_Poole1;~Ying_Nian_Wu1;~Diederik_P_Kingma1,6;7;7,3;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,"University of California, Los Angeles;Stanford University;Google;UCLA;Google",energy-based model;EBM;recovery likelihood;generative model;diffusion process;MCMC;Langevin dynamics;HMC,-1;5;-1;327;-1,15;2;-1;16;-1,f;m,NAN,NAN,n,5
5846,ICLR,2021,Are wider nets better given the same number of parameters?,Anna Golubeva;Guy Gur-Ari;Behnam Neyshabur,~Anna_Golubeva1;~Guy_Gur-Ari1;~Behnam_Neyshabur1,4;5;6,4;3;2,Accept (Poster),0,4,0.0,yes,9/28/20,University of Waterloo;Google;Google,network width;over-parametrization;understanding deep learning,34;-1;-1,232;-1;-1,f;m,NAN,NAN,n,
5847,ICLR,2021,Human-Level Performance in No-Press Diplomacy via Equilibrium Search,Jonathan Gray;Adam Lerer;Anton Bakhtin;Noam Brown,~Jonathan_Gray2;~Adam_Lerer1;~Anton_Bakhtin1;~Noam_Brown2,8;7;8;7,4;4;4;5,Accept (Oral),0,7,0.0,yes,9/28/20,Facebook AI Research;Facebook;Lomonosov Moscow State University;Facebook,multi-agent systems;regret minimization;no-regret learning;game theory;reinforcement learning,-1;-1;-1;-1,-1;-1;173;-1,m;m,NAN,NAN,n,4
5848,ICLR,2021,OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning,Anurag Ajay;Aviral Kumar;Pulkit Agrawal;Sergey Levine;Ofir Nachum,~Anurag_Ajay1;~Aviral_Kumar2;~Pulkit_Agrawal1;~Sergey_Levine1;~Ofir_Nachum1,6;6;7,3;4;3,Accept (Poster),0,19,0.0,yes,9/28/20,Massachusetts Institute of Technology;University of California Berkeley;Massachusetts Institute of Technology;University of Washington;Google,Offline Reinforcement Learning;Primitive Discovery;Unsupervised Learning,5;-1;5;11;-1,4;7;4;29;-1,m;m,NAN,NAN,y,6;1
5849,ICLR,2021,Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models,Zirui Wang;Yulia Tsvetkov;Orhan Firat;Yuan Cao,~Zirui_Wang1;~Yulia_Tsvetkov1;~Orhan_Firat1;~Yuan_Cao2,7;6;6;8,4;3;3;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Department of Computer Science, University of Washington;Google;Google Brain",Multi-task Learning;Multilingual Modeling,1;11;-1;-1,28;29;-1;-1,m;u,NAN,NAN,n,3
5850,ICLR,2021,Deformable DETR: Deformable Transformers for End-to-End Object Detection,Xizhou Zhu;Weijie Su;Lewei Lu;Bin Li;Xiaogang Wang;Jifeng Dai,~Xizhou_Zhu1;~Weijie_Su2;luotto@sensetime.com;binli@ustc.edu.cn;~Xiaogang_Wang2;~Jifeng_Dai1,8;7;8;9,5;4;4;5,Accept (Oral),0,7,0.0,yes,9/28/20,"SenseTime;University of Science and Technology of China;South China University of Technology, Tsinghua University;University of Science and Technology of China;Chinese University of Hong Kong;SenseTime Group Ltd",Efficient Attention Mechanism;Deformation Modeling;Multi-scale Representation;End-to-End Object Detection,-1;-1;4;-1;46;-1,-1;87;20;87;56;-1,u;m,NAN,NAN,n,8;2
5851,ICLR,2021,EEC: Learning to Encode and Regenerate Images for Continual Learning,Ali Ayub;Alan Wagner,~Ali_Ayub1;~Alan_Wagner2,6;4;4,2;5;5,Accept (Poster),0,3,0.0,yes,9/28/20,Pennsylvania State University;Pennsylvania State Univ University Park,Continual Learning;Catastrophic Forgetting;Cognitively-inspired Learning,44;-1,-1;-1,m;m,NAN,NAN,n,
5852,ICLR,2021,Understanding the failure modes of out-of-distribution generalization,Vaishnavh Nagarajan;Anders Andreassen;Behnam Neyshabur,~Vaishnavh_Nagarajan3;ajandreassen@google.com;~Behnam_Neyshabur1,8;6;6;5,3;3;4;3,Accept (Poster),0,10,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Google;Google",out-of-distribution generalization;spurious correlations;empirical risk minimization;theoretical study,1;-1;-1,28;-1;-1,m;m,NAN,NAN,y,
5853,ICLR,2021,Provably robust classification of adversarial examples with detection,Fatemeh Sheikholeslami;Ali Lotfi;J Zico Kolter,~Fatemeh_Sheikholeslami1;~Ali_Lotfi1;~J_Zico_Kolter1,5;6;7;5,3;5;4;3,Accept (Poster),0,12,0.0,yes,9/28/20,"Bosch Center for AI;University of Texas, Austin;Carnegie Mellon University",Adversarial robustness;robust deep learning,-1;-1;1,-1;-1;28,f;m,usa,usa,y,1;4
5854,ICLR,2021,PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable Physics,Zhiao Huang;Yuanming Hu;Tao Du;Siyuan Zhou;Hao Su;Joshua B. Tenenbaum;Chuang Gan,~Zhiao_Huang1;~Yuanming_Hu1;~Tao_Du1;elegyhunter@gmail.com;~Hao_Su1;~Joshua_B._Tenenbaum1;~Chuang_Gan1,7;7;9;6,3;3;3;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,"University of California, San Diego, University of California, San Diego;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Peking University;University of California - San Diego;Massachusetts Institute of Technology;MIT-IBM Watson AI Lab",Soft Body;Differentiable Physics;Benchmark,-1;5;5;14;-1;5;-1,33;4;4;23;33;4;-1,m;m,NAN,NAN,n,
5855,ICLR,2021,WrapNet:  Neural Net Inference with Ultra-Low-Precision Arithmetic,Renkun Ni;Hong-min Chu;Oscar Castaneda;Ping-yeh Chiang;Christoph Studer;Tom Goldstein,~Renkun_Ni1;hmchu@cs.umd.edu;~Oscar_Castaneda1;~Ping-yeh_Chiang1;~Christoph_Studer1;~Tom_Goldstein1,7;7;5;7,3;5;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park;Swiss Federal Institute of Technology;University of Maryland, College Park;Swiss Federal Institute of Technology;University of Maryland, College Park",quantization;efficient inference,-1;-1;-1;12;-1;12,90;90;-1;90;-1;90,m;m,usa,usa,n,
5856,ICLR,2021,Conditional Generative Modeling via Learning the Latent Space,Sameera Ramasinghe;Kanchana Nisal Ranasinghe;Salman Khan;Nick Barnes;Stephen Gould,~Sameera_Ramasinghe1;~Kanchana_Nisal_Ranasinghe1;~Salman_Khan4;~Nick_Barnes3;~Stephen_Gould1,7;6;10;7,3;3;5;3,Accept (Poster),0,5,0.0,yes,9/28/20,Australian National University;Mohamed bin Zayed University of Artificial Intelligence;MBZ University of AI;Australian National University;Australian National University,Multimodal Spaces;Conditional Generation;Generative Modeling,99;-1;-1;99;99,59;874;-1;59;59,m;m,australasia,au,n,5
5857,ICLR,2021,DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION,Pengcheng He;Xiaodong Liu;Jianfeng Gao;Weizhu Chen,~Pengcheng_He2;~Xiaodong_Liu1;~Jianfeng_Gao1;~Weizhu_Chen1,6;7;6;6,5;4;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,Microsoft;Microsoft Research;Microsoft Research;Microsoft,Transformer;Attention;Natural Language Processing;Language Model Pre-training;Position Encoding,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3;8;1;4
5858,ICLR,2021,gradSim: Differentiable simulation for system identification and visuomotor control,J. Krishna Murthy;Miles Macklin;Florian Golemo;Vikram Voleti;Linda Petrini;Martin Weiss;Breandan Considine;J√©r√¥me Parent-L√©vesque;Kevin Xie;Kenny Erleben;Liam Paull;Florian Shkurti;Derek Nowrouzezahrai;Sanja Fidler,~J._Krishna_Murthy1;~Miles_Macklin1;~Florian_Golemo1;~Vikram_Voleti1;~Linda_Petrini1;~Martin_Weiss4;~Breandan_Considine2;~J√©r√¥me_Parent-L√©vesque2;kevincxie@cs.toronto.edu;kenny@di.ku.dk;~Liam_Paull1;~Florian_Shkurti1;~Derek_Nowrouzezahrai1;~Sanja_Fidler1,7;7;7,3;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Montreal;NVIDIA;Mila;University of Montreal;Google;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;McGill University;University of Montreal;Department of Computer Science, University of Toronto;;;University of Montreal;Department of Computer Science, University of Toronto;McGill University;Department of Computer Science, University of Toronto",Differentiable simulation;System identification;Physical parameter estimation;3D scene understanding;3D vision;Differentiable rendering;Differentiable physics,128;-1;150;128;-1;128;99;128;18;-1;-1;128;18;99;18,73;-1;370;73;-1;73;40;73;18;-1;-1;73;18;40;18,m;f,NAN,NAN,n,10
5859,ICLR,2021,Topology-Aware Segmentation Using Discrete Morse Theory,Xiaoling Hu;Yusu Wang;Li Fuxin;Dimitris Samaras;Chao Chen,~Xiaoling_Hu1;~Yusu_Wang1;~Li_Fuxin1;~Dimitris_Samaras3;~Chao_Chen1,8;6;5;7,3;4;3;2,Accept (Spotlight),0,7,0.0,yes,9/28/20,"State University of New York, Stony Brook;University of California, San Diego;Oregon State University;Stony Brook University;State University of New York, Stony Brook",Topology;Morse theory;Image segmentation,-1;-1;79;42;-1,-1;33;424;312;-1,m;m,NAN,NAN,n,2;1
5860,ICLR,2021,Predicting Inductive Biases of Pre-Trained Models,Charles Lovering;Rohan Jha;Tal Linzen;Ellie Pavlick,~Charles_Lovering1;rohan_jha@brown.edu;~Tal_Linzen1;~Ellie_Pavlick1,7;6;8,2;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,Brown University;Brown University;New York University;Brown University,information-theoretical probing;probing;challenge sets;natural language processing,85;85;23;85,61;61;26;61,m;f,usa,usa,n,3
5861,ICLR,2021,INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving,Yuhuai Wu;Albert Jiang;Jimmy Ba;Roger Baker Grosse,~Yuhuai_Wu1;~Albert_Jiang1;~Jimmy_Ba1;~Roger_Baker_Grosse1,8;6;7;6,4;4;2;2,Accept (Poster),0,10,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of Oxford;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",Theorem proving;Synthetic benchmark dataset;Generalization;Transformers;Graph neural networks;Monte Carlo Tree Search,18;46;18;18,18;1;18;18,m;m,NAN,NAN,n,8;1;10
5862,ICLR,2021,Control-Aware Representations for Model-based Reinforcement Learning,Brandon Cui;Yinlam Chow;Mohammad Ghavamzadeh,bcui@fb.com;~Yinlam_Chow1;~Mohammad_Ghavamzadeh2,6;6;6,4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,Stanford University;Google Research;Google Research,,5;-1;-1,2;-1;-1,m;m,NAN,NAN,y,
5863,ICLR,2021,Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics,Daniel Kunin;Javier Sagastuy-Brena;Surya Ganguli;Daniel LK Yamins;Hidenori Tanaka,~Daniel_Kunin1;~Javier_Sagastuy-Brena1;~Surya_Ganguli1;~Daniel_LK_Yamins1;~Hidenori_Tanaka1,8;6;5;7,3;3;3;4,Accept (Poster),0,15,0.0,yes,9/28/20,"Stanford University;Stanford University;Stanford University;Stanford University;Physics & Informatics Labs, NTT Research, Inc.",learning dynamics;symmetry;loss landscape;stochastic differential equation;modified equation analysis;conservation law;hessian;geometry;physics;gradient flow,5;5;5;5;-1,2;2;2;2;-1,m;m,NAN,NAN,y,1
5864,ICLR,2021,When Optimizing  $f$-Divergence is Robust with Label Noise,Jiaheng Wei;Yang Liu,~Jiaheng_Wei1;~Yang_Liu3,7;6;7;7,3;3;3;2,Accept (Poster),0,6,0.0,yes,9/28/20,"University of California, Santa Cruz;University of California, Santa Cruz",$f-$divergence;robustness;learning with noisy labels,-1;-1,207;207,m;m,usa,usa,y,
5865,ICLR,2021,Tradeoffs in Data Augmentation: An Empirical Study,Raphael Gontijo-Lopes;Sylvia Smullin;Ekin Dogus Cubuk;Ethan Dyer,~Raphael_Gontijo-Lopes1;smullin-physics@stanfordalumni.org;~Ekin_Dogus_Cubuk1;~Ethan_Dyer1,6;6;5;8,4;4;5;4,Accept (Poster),0,12,0.0,yes,9/28/20,Google Brain;;;Google;Google,Generalization;Interpretability;Understanding Data Augmentation,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
5866,ICLR,2021,CompOFA ‚Äì Compound Once-For-All Networks for Faster Multi-Platform Deployment,Manas Sahni;Shreya Varshini;Alind Khare;Alexey Tumanov,~Manas_Sahni1;shreyavarshini@gatech.edu;~Alind_Khare1;atumanov@gatech.edu,7;6;5;4,4;3;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Efficient Deep Learning;Latency-aware Neural Architecture Search;AutoML,12;12;12;12,38;38;38;38,m;m,usa,usa,n,
5867,ICLR,2021,ANOCE: Analysis of Causal Effects with Multiple Mediators via Constrained Structural Learning,Hengrui Cai;Rui Song;Wenbin Lu,~Hengrui_Cai1;~Rui_Song2;wlu4@ncsu.edu,6;6;5;8,2;3;4;4,Accept (Poster),0,0,0.0,yes,9/28/20,North Carolina State University;North Carolina State University;North Carolina State University,Causal network;Constrained optimization;COVID-19;Individual mediation effects;Structure learning,92;92;92,340;340;340,f;m,usa,usa,y,10
5868,ICLR,2021,Transformer protein language models are unsupervised structure learners,Roshan Rao;Joshua Meier;Tom Sercu;Sergey Ovchinnikov;Alexander Rives,~Roshan_Rao1;~Joshua_Meier1;~Tom_Sercu1;~Sergey_Ovchinnikov1;~Alexander_Rives1,5;7;6;5,4;5;4;5,Accept (Poster),0,11,0.0,yes,9/28/20,University of California Berkeley;Facebook;Facebook;Harvard University;Facebook,proteins;language modeling;structure prediction;unsupervised learning;explainable,-1;-1;-1;53;-1,7;-1;-1;3;-1,m;m,NAN,NAN,n,8;3
5869,ICLR,2021,Data-Efficient Reinforcement Learning with Self-Predictive Representations,Max Schwarzer;Ankesh Anand;Rishab Goel;R Devon Hjelm;Aaron Courville;Philip Bachman,~Max_Schwarzer1;~Ankesh_Anand1;~Rishab_Goel3;~R_Devon_Hjelm1;~Aaron_Courville3;~Philip_Bachman1,7;6;7;7,4;5;4;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,"University of Montreal;Mila, University of Montreal;Mila;Microsoft;University of Montreal;Microsoft",Reinforcement Learning;Self-Supervised Learning;Representation Learning;Sample Efficiency,128;128;150;-1;128;-1,73;73;370;-1;73;-1,m;m,NAN,NAN,n,
5870,ICLR,2021,Estimating Lipschitz constants of monotone deep equilibrium models,Chirag Pabbaraju;Ezra Winston;J Zico Kolter,~Chirag_Pabbaraju1;~Ezra_Winston1;~J_Zico_Kolter1,6;7;6;5;5,5;4;3;4;4,Accept (Poster),0,13,0.0,yes,9/28/20,"Carnegie Mellon University;Machine Learning Department, School of Computer Science;Carnegie Mellon University",deep equilibrium models;Lipschitz constants,1;-1;1,28;-1;28,m;m,usa,usa,y,1
5871,ICLR,2021,Adaptive Extra-Gradient Methods for Min-Max Optimization and Games,Kimon Antonakopoulos;Veronica Belmega;Panayotis Mertikopoulos,~Kimon_Antonakopoulos1;~Veronica_Belmega1;~Panayotis_Mertikopoulos1,7;7;6;5,4;4;2;4,Accept (Poster),0,13,0.0,yes,9/28/20,INRIA;ETIS;French National Center for Scientific Research,min-max optimization;games;mirror-prox;adaptive methods;regime agnostic methods,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,9
5872,ICLR,2021,A Critique of Self-Expressive Deep Subspace Clustering,Benjamin David Haeffele;Chong You;Rene Vidal,~Benjamin_David_Haeffele1;~Chong_You2;~Rene_Vidal1,7;7;7;7,3;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,Johns Hopkins University;Google;Johns Hopkins University,Subspace clustering;Manifold clustering;Theory of deep learning;Autoencoders,71;-1;71,12;-1;12,m;m,usa,usa,y,
5873,ICLR,2021,VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models,Zhisheng Xiao;Karsten Kreis;Jan Kautz;Arash Vahdat,~Zhisheng_Xiao1;~Karsten_Kreis1;~Jan_Kautz1;~Arash_Vahdat3,7;8;6;7,4;4;3;5,Accept (Spotlight),0,5,0.0,yes,9/28/20,University of Chicago;NVIDIA;NVIDIA;NVIDIA,Energy-based Models;Variational Auto-encoder;MCMC,46;-1;-1;-1,10;-1;-1;-1,m;m,NAN,NAN,n,5
5874,ICLR,2021,Model-based micro-data reinforcement learning: what are the crucial model properties and which model to choose?,Bal√°zs K√©gl;Gabriel Hurtado;Albert Thomas,~Bal√°zs_K√©gl2;gabriel.j.hurtado@gmail.com;~Albert_Thomas1,7;6;7;7;5,3;4;3;2;3,Accept (Poster),0,17,0.0,yes,9/28/20,Huawei France;Huawei Technologies Ltd.;Huawei Technologies Ltd.,model-based reinforcement learning;generative models;mixture density nets;dynamic systems;heteroscedasticity,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1;5
5875,ICLR,2021,"Factorizing Declarative and Procedural Knowledge in Structured, Dynamical Environments",Anirudh Goyal;Alex Lamb;Phanideep Gampa;Philippe Beaudoin;Charles Blundell;Sergey Levine;Yoshua Bengio;Michael Curtis Mozer,~Anirudh_Goyal1;~Alex_Lamb1;gampa.phanideep.mat15@itbhu.ac.in;~Philippe_Beaudoin1;~Charles_Blundell1;~Sergey_Levine1;~Yoshua_Bengio1;~Michael_Curtis_Mozer1,6;7;8;5,4;4;4;3,Accept (Poster),0,10,0.0,yes,9/28/20,University of Montreal;University of Montreal;Indian Institute of Technology Varanasi;University of British Columbia;DeepMind;University of Washington;University of Montreal;University of Colorado at Boulder,procedural knowledge;declarative knowledge;Systematicity,128;128;-1;58;-1;11;128;-1,73;73;-1;34;-1;29;73;-1,m;m,usa,usa,n,8;1
5876,ICLR,2021,Recurrent Independent Mechanisms,Anirudh Goyal;Alex Lamb;Jordan Hoffmann;Shagun Sodhani;Sergey Levine;Yoshua Bengio;Bernhard Sch√∂lkopf,~Anirudh_Goyal1;~Alex_Lamb1;~Jordan_Hoffmann1;~Shagun_Sodhani1;~Sergey_Levine1;~Yoshua_Bengio1;~Bernhard_Sch√∂lkopf1,7;7;7;9,4;3;3;3,Accept (Spotlight),0,9,0.0,yes,9/28/20,"University of Montreal;University of Montreal;DeepMind;Facebook;University of Washington;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute",modular representations;better generalization;learning mechanisms,128;128;-1;-1;11;128;-1,73;73;-1;-1;29;73;-1,m;m,NAN,NAN,n,8;1
5877,ICLR,2021,DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues,Rishabh Joshi;Vidhisha Balachandran;Shikhar Vashishth;Alan Black;Yulia Tsvetkov,~Rishabh_Joshi1;~Vidhisha_Balachandran1;~Shikhar_Vashishth1;~Alan_Black1;~Yulia_Tsvetkov1,6;6;5;6,4;4;3;5,Accept (Poster),0,10,0.0,yes,9/28/20,"Carnegie Mellon University;Carnegie Mellon University;Language Technologies Institute, Carnegie Mellon University;Carnegie-Mellon University;Department of Computer Science, University of Washington",negotiation;dialogue;graph neural networks;interpretability;structure,1;1;1;1;11,28;28;28;28;29,m;f,NAN,NAN,n,10
5878,ICLR,2021,Trajectory Prediction using Equivariant Continuous Convolution,Robin Walters;Jinxi Li;Rose Yu,~Robin_Walters1;li.jinxi1@northeastern.edu;~Rose_Yu1,6;6;7;5,4;2;3;2,Accept (Poster),0,7,0.0,yes,9/28/20,"Northeastern University;Northeastern University;University of California, San Diego",equivariant;symmetry;trajectory prediction;continuous convolution;argoverse,16;16;-1,895;895;33,m;f,usa,usa,n,1
5879,ICLR,2021,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,Dmitry Lepikhin;HyoukJoong Lee;Yuanzhong Xu;Dehao Chen;Orhan Firat;Yanping Huang;Maxim Krikun;Noam Shazeer;Zhifeng Chen,lepikhin@google.com;hyouklee@google.com;yuanzx@google.com;dehao@google.com;~Orhan_Firat1;~Yanping_Huang1;krikun@google.com;~Noam_Shazeer1;~Zhifeng_Chen1,5;4;7;9,5;4;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,Lomonosov Moscow State University;Stanford University;Google;Google;Google;Google;Google;Duke University;Google,,-1;5;-1;-1;-1;-1;-1;46;-1,173;2;-1;-1;-1;-1;-1;20;-1,m;m,NAN,NAN,n,8;3
5880,ICLR,2021,Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization,Kaidi Cao;Yining Chen;Junwei Lu;Nikos Arechiga;Adrien Gaidon;Tengyu Ma,~Kaidi_Cao1;~Yining_Chen1;~Junwei_Lu1;nikos.arechiga@tri.global;~Adrien_Gaidon1;~Tengyu_Ma1,6;7;9;5,4;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"Stanford University;Stanford University;Harvard University;CMU, Carnegie Mellon University;Toyota Research Institute (TRI);Stanford University",deep learning;noise robust learning;imbalanced learning,5;5;53;1;-1;5,2;2;3;28;-1;2,m;m,usa,usa,y,1
5881,ICLR,2021,Graph Coarsening with Neural Networks,Chen Cai;Dingkang Wang;Yusu Wang,~Chen_Cai1;wang.6150@osu.edu;~Yusu_Wang1,6;6;7;7,4;3;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,"Ohio State University;Ohio State University;University of California, San Diego",graph coarsening;graph neural network;Doubly-weighted Laplace operator,58;58;-1,78;78;33,m;f,usa,usa,y,10
5882,ICLR,2021,Iterated learning for emergent systematicity in VQA,Ankit Vani;Max Schwarzer;Yuchen Lu;Eeshan Dhekane;Aaron Courville,~Ankit_Vani1;~Max_Schwarzer1;~Yuchen_Lu1;eeshandhekane@gmail.com;~Aaron_Courville3,6;8;7,4;3;3,Accept (Oral),0,9,0.0,yes,9/28/20,University of Montreal;University of Montreal;University of Montreal;;;University of Montreal,iterated learning;cultural transmission;neural module network;clevr;shapes;vqa;visual question answering;systematic generalization;compositionality,128;128;128;-1;-1;128,73;73;73;-1;-1;73,m;m,canada,ca,n,1
5883,ICLR,2021,Learning Invariant Representations for Reinforcement Learning without Reconstruction,Amy Zhang;Rowan Thomas McAllister;Roberto Calandra;Yarin Gal;Sergey Levine,~Amy_Zhang1;~Rowan_Thomas_McAllister1;~Roberto_Calandra1;~Yarin_Gal1;~Sergey_Levine1,9;7;7,5;3;4,Accept (Oral),0,3,0.0,yes,9/28/20,University of California Berkeley;Toyota Research Institute;Facebook;University of Oxford;University of Washington,rich observations;bisimulation metrics;representation learning;state abstractions,-1;-1;-1;46;11,7;-1;-1;1;29,f;m,usa,usa,y,1
5884,ICLR,2021,Does enhanced shape bias improve neural network robustness to common corruptions?,Chaithanya Kumar Mummadi;Ranjitha Subramaniam;Robin Hutmacher;Julien Vitay;Volker Fischer;Jan Hendrik Metzen,~Chaithanya_Kumar_Mummadi1;~Ranjitha_Subramaniam1;~Robin_Hutmacher1;~Julien_Vitay1;~Volker_Fischer1;~Jan_Hendrik_Metzen1,9;6;6;7,5;4;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Bosch Center for Artificial Intelligence;Chemnitz University of Technology;Robert Bosch GmbH, Bosch;Chemnitz University of Technology;Bosch Center for Artificial Intelligence;Bosch Center Artificial Intelligence",neural network robustness;shape bias;corruptions;distribution shift,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
5885,ICLR,2021,Progressive Skeletonization: Trimming more fat from a network at initialization,Pau de Jorge;Amartya Sanyal;Harkirat Behl;Philip Torr;Gr√©gory Rogez;Puneet K. Dokania,~Pau_de_Jorge1;~Amartya_Sanyal1;~Harkirat_Behl1;~Philip_Torr1;~Gr√©gory_Rogez1;~Puneet_K._Dokania1,7;7;6,3;4;3,Accept (Poster),0,3,0.0,yes,9/28/20,"University of Oxford, University of Oxford;Swiss Federal Institute of Technology;University of Oxford;University of Oxford;Naver Labs Europe;University of Oxford",Pruning;Pruning at initialization;Sparsity,46;-1;46;46;-1;46,1;-1;1;1;-1;1,m;m,europe,uk,n,
5886,ICLR,2021,Filtered Inner Product Projection for Crosslingual Embedding Alignment,Vin Sachidananda;Ziyi Yang;Chenguang Zhu,~Vin_Sachidananda1;~Ziyi_Yang1;~Chenguang_Zhu1,8;6;6,4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,multilingual representations;word embeddings;natural language processing,5;5;5,2;2;2,m;m,usa,usa,y,6;3
5887,ICLR,2021,Neural Thompson Sampling,Weitong ZHANG;Dongruo Zhou;Lihong Li;Quanquan Gu,~Weitong_ZHANG1;~Dongruo_Zhou1;~Lihong_Li1;~Quanquan_Gu1,7;7;7;6,3;3;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;Amazon;University of California, Los Angeles",Deep Learning;Contextual Bandits;Thompson sampling,-1;-1;-1;-1,15;15;-1;15,m;m,usa,usa,y,1
5888,ICLR,2021,In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning,Mamshad Nayeem Rizve;Kevin Duarte;Yogesh S Rawat;Mubarak Shah,~Mamshad_Nayeem_Rizve1;~Kevin_Duarte1;~Yogesh_S_Rawat1;~Mubarak_Shah3,5;9;6;6,4;5;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,University of Central Florida;University of Central Florida;University of Central Florida;University of Central Florida,Semi-Supervised Learning;Pseudo-Labeling;Uncertainty;Calibration;Deep Learning,71;71;71;71,633;633;633;633,m;m,usa,usa,n,
5889,ICLR,2021,Adaptive Federated Optimization,Sashank J. Reddi;Zachary Charles;Manzil Zaheer;Zachary Garrett;Keith Rush;Jakub Koneƒçn√Ω;Sanjiv Kumar;Hugh Brendan McMahan,~Sashank_J._Reddi1;~Zachary_Charles1;~Manzil_Zaheer1;zachgarrett@google.com;krush@google.com;~Jakub_Koneƒçn√Ω1;~Sanjiv_Kumar1;~Hugh_Brendan_McMahan1,6;6;6;7,4;4;5;4,Accept (Poster),0,4,0.0,yes,9/28/20,Google;Google;Zaheer;Google;Google;Google;Google;Google,Federated learning;optimization;adaptive optimization;distributed optimization,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
5890,ICLR,2021,End-to-End Egospheric Spatial Memory,Daniel James Lenton;Stephen James;Ronald Clark;Andrew Davison,~Daniel_James_Lenton1;~Stephen_James1;~Ronald_Clark2;~Andrew_Davison1,7;4;6,4;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,Imperial College London;Imperial College London;Imperial College London;Imperial College London,egocentric;differentiable memory;spatial awareness;mapping;image-to-action learning,53;53;53;53,11;11;11;11,m;m,europe,uk,n,2;10
5891,ICLR,2021,Linear Convergent Decentralized Optimization with Compression,Xiaorui Liu;Yao Li;Rongrong Wang;Jiliang Tang;Ming Yan,~Xiaorui_Liu1;liyao6@msu.edu;wangron6@msu.edu;~Jiliang_Tang1;myan@msu.edu,7;7;7,4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Michigan State University;Michigan State University;Michigan State University;Michigan State University;Michigan State University,Decentralized Optimization;Communication Compression;Linear Convergence;Heterogeneous data,110;110;110;110;110,105;105;105;105;105,m;m,usa,usa,y,1;9
5892,ICLR,2021,Contrastive Learning with Hard Negative Samples,Joshua David Robinson;Ching-Yao Chuang;Suvrit Sra;Stefanie Jegelka,~Joshua_David_Robinson1;~Ching-Yao_Chuang1;~Suvrit_Sra1;~Stefanie_Jegelka3,6;7;7;6,4;4;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,contrastive learning;unsupervised representation learning;hard negative sampling,5;5;5;5,4;4;4;4,m;f,usa,usa,y,
5893,ICLR,2021,Neural Spatio-Temporal Point Processes,Ricky T. Q. Chen;Brandon Amos;Maximilian Nickel,~Ricky_T._Q._Chen1;~Brandon_Amos1;~Maximilian_Nickel1,7;7;5;6,4;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,University of Toronto;Facebook;Facebook,point processes;normalizing flows;differential equations,18;-1;-1,18;-1;-1,m;m,NAN,NAN,n,
5894,ICLR,2021,Learning Neural Event Functions for Ordinary Differential Equations,Ricky T. Q. Chen;Brandon Amos;Maximilian Nickel,~Ricky_T._Q._Chen1;~Brandon_Amos1;~Maximilian_Nickel1,6;6;7;7,3;4;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,University of Toronto;Facebook;Facebook,differential equations;implicit differentiation;point processes,18;-1;-1,18;-1;-1,m;m,NAN,NAN,n,
5895,ICLR,2021,Individually Fair Rankings,Amanda Bower;Hamid Eftekhari;Mikhail Yurochkin;Yuekai Sun,~Amanda_Bower1;hamidef@umich.edu;~Mikhail_Yurochkin1;~Yuekai_Sun1,5;7;4;7,3;3;4;2,Accept (Poster),0,6,0.0,yes,9/28/20,Twitter;;;International Business Machines;University of Michigan,algorithmic fairness;learning to rank;optimal transport,-1;-1;-1;-1;7,-1;-1;-1;-1;22,f;m,usa,usa,y,7
5896,ICLR,2021,Quantifying Differences in Reward Functions,Adam Gleave;Michael D Dennis;Shane Legg;Stuart Russell;Jan Leike,~Adam_Gleave1;~Michael_D_Dennis1;~Shane_Legg1;~Stuart_Russell1;~Jan_Leike1,6;8;7;7,2;4;4;3,Accept (Spotlight),0,12,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;DeepMind;University of California - Berkeley;OpenAI,rl;irl;reward learning;distance;benchmarks,-1;-1;-1;-1;-1,7;7;-1;7;-1,m;m,NAN,NAN,y,1
5897,ICLR,2021,Minimum Width for Universal Approximation,Sejun Park;Chulhee Yun;Jaeho Lee;Jinwoo Shin,~Sejun_Park1;~Chulhee_Yun1;~Jaeho_Lee3;~Jinwoo_Shin1,8;7;7;7,4;3;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Massachusetts Institute of Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,universal approximation;neural networks,-1;5;-1;-1,96;4;96;96,m;m,NAN,NAN,y,1
5898,ICLR,2021,Estimating informativeness of samples with Smooth Unique Information,Hrayr Harutyunyan;Alessandro Achille;Giovanni Paolini;Orchid Majumder;Avinash Ravichandran;Rahul Bhotika;Stefano Soatto,~Hrayr_Harutyunyan1;~Alessandro_Achille1;~Giovanni_Paolini1;~Orchid_Majumder1;~Avinash_Ravichandran1;~Rahul_Bhotika1;~Stefano_Soatto1,6;7;6;6,3;3;4;4,Accept (Poster),0,15,0.0,yes,9/28/20,University of Southern California;California Institute of Technology;Amazon;Amazon Web Services;Amazon;Amazon;UCLA,sample information;information theory;stability theory;ntk;dataset summarization,37;150;-1;-1;-1;-1;327,53;4;-1;-1;-1;-1;16,m;m,asia,in,y,4
5899,ICLR,2021,Growing Efficient Deep Networks by Structured Continuous Sparsification,Xin Yuan;Pedro Henrique Pamplona Savarese;Michael Maire,~Xin_Yuan5;~Pedro_Henrique_Pamplona_Savarese1;~Michael_Maire1,7;7;7;8,4;4;3;4,Accept (Oral),0,5,0.0,yes,9/28/20,University of Chicago;Toyota Technological Institute at Chicago;University of Chicago,deep learning;computer vision;network pruning;neural architecture search,46;-1;46,10;-1;10,m;m,usa,usa,n,2;3
5900,ICLR,2021,Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning,Alihan H√ºy√ºk;Daniel Jarrett;Cem Tekin;Mihaela van der Schaar,~Alihan_H√ºy√ºk1;~Daniel_Jarrett1;~Cem_Tekin2;~Mihaela_van_der_Schaar2,7;6;7,3;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;Bilkent University;University of Cambridge,interpretable policy learning;understanding decision-making,79;79;327;79,6;6;636;6,m;f,europe,uk,y,11
5901,ICLR,2021,Drop-Bottleneck: Learning Discrete Compressed Representation for Noise-Robust Exploration,Jaekyeom Kim;Minjung Kim;Dongyeon Woo;Gunhee Kim,~Jaekyeom_Kim1;~Minjung_Kim2;~Dongyeon_Woo1;~Gunhee_Kim1,6;6;7;6,4;3;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Reinforcement learning;Information bottleneck,37;37;37;37,60;60;60;60,m;m,asia,kr,n,4
5902,ICLR,2021,HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark,Chaojian Li;Zhongzhi Yu;Yonggan Fu;Yongan Zhang;Yang Zhao;Haoran You;Qixuan Yu;Yue Wang;Cong Hao;Yingyan Lin,~Chaojian_Li1;~Zhongzhi_Yu1;~Yonggan_Fu1;~Yongan_Zhang1;~Yang_Zhao1;~Haoran_You1;~Qixuan_Yu1;~Yue_Wang3;hc.onioncc@gmail.com;~Yingyan_Lin1,7;7;6;7,4;5;3;3,Accept (Spotlight),0,12,0.0,yes,9/28/20,Rice University;Rice University;Rice University;Rice University;Rice University;Rice University;Rice University;Rice University;;;Rice University,Hardware-Aware Neural Architecture Search;AutoML;Benchmark,92;92;92;92;92;92;92;92;-1;-1;92,124;124;124;124;124;124;124;124;-1;-1;124,m;f,australasia,au,n,8
5903,ICLR,2021,Communication in Multi-Agent Reinforcement Learning: Intention Sharing,Woojun Kim;Jongeui Park;Youngchul Sung,~Woojun_Kim1;~Jongeui_Park1;~Youngchul_Sung1,6;4;5;6,4;3;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Multi-agent reinforcement learning;communication;intention;attention,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,8
5904,ICLR,2021,Mapping the Timescale Organization of Neural Language Models,Hsiang-Yun Sherry Chien;Jinhan Zhang;Christopher Honey,~Hsiang-Yun_Sherry_Chien1;~Jinhan_Zhang1;~Christopher_Honey1,6;3;6;7,4;4;4;3,Accept (Poster),0,15,0.0,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,natural language processing;LSTM;timescale;hierarchy;temporal context,71;71;71,12;12;12,f;m,usa,usa,n,3;1
5905,ICLR,2021,"Learning What-if"" Explanations for Sequential Decision-Making""",Ioana Bica;Daniel Jarrett;Alihan H√ºy√ºk;Mihaela van der Schaar,~Ioana_Bica1;~Daniel_Jarrett1;ah2075@cam.ac.uk;~Mihaela_van_der_Schaar2,7;6;7;5,4;2;3;3,Accept (Poster),0,12,0.0,yes,9/28/20,University of Oxford;University of Cambridge;University of Cambridge;University of Cambridge,counterfactuals;explaining decision-making;preference learning,46;79;79;79,1;6;6;6,f;f,europe,uk,n,
5906,ICLR,2021,Meta-Learning of Structured Task Distributions in Humans and Machines,Sreejan Kumar;Ishita Dasgupta;Jonathan Cohen;Nathaniel Daw;Thomas Griffiths,~Sreejan_Kumar1;~Ishita_Dasgupta1;~Jonathan_Cohen1;~Nathaniel_Daw1;~Thomas_Griffiths1,6;6;7;7,3;4;5;3,Accept (Poster),0,18,0.0,yes,9/28/20,Princeton University;DeepMind;Princeton University;Princeton University;Princeton University,meta-learning;human cognition;reinforcement learning;compositionality,29;-1;29;29;29,9;-1;9;9;9,m;m,usa,usa,n,6
5907,ICLR,2021,Multi-timescale Representation Learning in LSTM Language Models,Shivangi Mahto;Vy Ai Vo;Javier S. Turek;Alexander Huth,shivangi@utexas.edu;vy.vo@intel.com;~Javier_S._Turek1;~Alexander_Huth1,7;6;8;7,4;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,The University of Texas at Austin;Intel;Intel;The University of Texas at Austin,Language Model;LSTM;timescales,20;-1;-1;20,43;-1;-1;43,f;m,NAN,NAN,n,3;1
5908,ICLR,2021,CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding,Yanru Qu;Dinghan Shen;Yelong Shen;Sandra Sajeev;Weizhu Chen;Jiawei Han,~Yanru_Qu1;~Dinghan_Shen1;~Yelong_Shen2;ssajeev@microsoft.com;~Weizhu_Chen1;~Jiawei_Han1,6;7;5,4;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Microsoft;;;;Microsoft;University of Illinois, Urbana-Champaign",data augmentation;natural language understanding;consistency training;contrastive learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,usa,usa,n,3;8;1;4
5909,ICLR,2021,Conservative Safety Critics for Exploration,Homanga Bharadhwaj;Aviral Kumar;Nicholas Rhinehart;Sergey Levine;Florian Shkurti;Animesh Garg,~Homanga_Bharadhwaj1;~Aviral_Kumar2;~Nicholas_Rhinehart1;~Sergey_Levine1;~Florian_Shkurti1;~Animesh_Garg1,6;6;7;7,3;5;2;3,Accept (Poster),0,12,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;University of California Berkeley;University of California Berkeley;University of Washington;Department of Computer Science, University of Toronto;University of Toronto",Safe exploration;Reinforcement Learning,1;-1;-1;11;18;18,28;7;7;29;18;18,m;m,canada,ca,y,1
5910,ICLR,2021,How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?,Zixiang Chen;Yuan Cao;Difan Zou;Quanquan Gu,~Zixiang_Chen1;~Yuan_Cao1;~Difan_Zou1;~Quanquan_Gu1,8;6;7;6,5;2;2;4,Accept (Poster),0,7,0.0,yes,9/28/20,", University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",deep ReLU networks;neural tangent kernel;(stochastic) gradient descent;generalization error;classification,-1;-1;-1;-1,15;15;15;15,m;m,usa,usa,y,1
5911,ICLR,2021,Getting a CLUE: A  Method for Explaining Uncertainty Estimates,Javier Antoran;Umang Bhatt;Tameem Adel;Adrian Weller;Jos√© Miguel Hern√°ndez-Lobato,~Javier_Antoran1;~Umang_Bhatt1;~Tameem_Adel1;~Adrian_Weller1;~Jos√©_Miguel_Hern√°ndez-Lobato1,7;6;7;7,4;4;3;3,Accept (Oral),0,15,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;University of Cambridge;Alan Turing Institute;University of Cambridge,interpretability;uncertainty;explainability,79;79;79;-1;79,6;6;6;-1;6,m;m,europe,uk,n,11
5912,ICLR,2021,Hierarchical Autoregressive Modeling for Neural Video Compression,Ruihan Yang;Yibo Yang;Joseph Marino;Stephan Mandt,~Ruihan_Yang1;~Yibo_Yang1;~Joseph_Marino1;~Stephan_Mandt1,7;6;7;7,3;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,"University of California, Irvine;University of California, Irvine;California Institute of Technology;University of California, Irvine",Compression;Video Compression;Generative Models;Autoregressive Models,-1;-1;150;-1,98;98;4;98,u;m,usa,usa,n,5
5913,ICLR,2021,Model Patching: Closing the Subgroup Performance Gap with Data Augmentation,Karan Goel;Albert Gu;Yixuan Li;Christopher Re,~Karan_Goel1;~Albert_Gu1;~Yixuan_Li1;~Christopher_Re1,7;7;7;8,3;2;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Stanford University;Stanford University;University of Wisconsin, Madison;University of Wisconsin-Madison",Robust Machine Learning;Data Augmentation;Consistency Training;Invariant Representations,5;5;18;18,2;2;49;49,m;m,usa,usa,y,
5914,ICLR,2021,Parrot: Data-Driven Behavioral Priors for Reinforcement Learning,Avi Singh;Huihan Liu;Gaoyue Zhou;Albert Yu;Nicholas Rhinehart;Sergey Levine,~Avi_Singh1;~Huihan_Liu1;~Gaoyue_Zhou1;~Albert_Yu1;~Nicholas_Rhinehart1;~Sergey_Levine1,8;7;6;9,3;3;4;4,Accept (Oral),0,9,0.0,yes,9/28/20,"University of California Berkeley;University of Texas, Austin;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Washington",reinforcement learning;imitation learning,-1;-1;-1;-1;-1;11,7;-1;7;7;7;29,m;m,usa,usa,n,2;3
5915,ICLR,2021,Iterative Empirical Game Solving via Single Policy Best Response,Max Smith;Thomas Anthony;Michael Wellman,~Max_Smith1;~Thomas_Anthony1;~Michael_Wellman1,7;7;7;7,2;4;2;4,Accept (Spotlight),0,10,0.0,yes,9/28/20,University of Michigan;DeepMind;University of Michigan,Empirical Game Theory;Reinforcement Learning;Multiagent Learning,7;-1;7,22;-1;22,m;m,usa,usa,n,
5916,ICLR,2021,Fast Geometric Projections for Local Robustness Certification,Aymeric Fromherz;Klas Leino;Matt Fredrikson;Bryan Parno;Corina Pasareanu,~Aymeric_Fromherz1;~Klas_Leino1;~Matt_Fredrikson1;~Bryan_Parno1;~Corina_Pasareanu1,7;6;8;7,3;4;5;4,Accept (Spotlight),0,13,0.0,yes,9/28/20,"Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University",verification;robustness;safety,1;1;1;1;1,28;28;28;28;28,m;f,usa,usa,y,4
5917,ICLR,2021,PAC Confidence Predictions for Deep Neural Network Classifiers,Sangdon Park;Shuo Li;Insup Lee;Osbert Bastani,~Sangdon_Park1;lishuo1@seas.upenn.edu;~Insup_Lee1;~Osbert_Bastani1,6;7;6,4;2;4,Accept (Poster),0,14,0.0,yes,9/28/20,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,classification;calibration;probably approximated correct guarantee;fast DNN inference;safe planning,20;20;20;20,13;13;13;13,m;m,usa,usa,y,1
5918,ICLR,2021,Molecule Optimization by Explainable Evolution,Binghong Chen;Tianzhe Wang;Chengtao Li;Hanjun Dai;Le Song,~Binghong_Chen1;~Tianzhe_Wang1;~Chengtao_Li1;~Hanjun_Dai1;~Le_Song1,6;7;7;8,3;5;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Georgia Institute of Technology;Georgia Institute of Technology;Massachusetts Institute of Technology;Google Research;College of Computing, Georgia Institute of Technology",Molecule Design;Explainable Model;Evolutionary Algorithm;Reinforcement Learning;Graph Generative Model,12;12;5;-1;12,38;38;4;-1;38,m;m,NAN,NAN,n,
5919,ICLR,2021,Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks,Yanbang Wang;Yen-Yu Chang;Yunyu Liu;Jure Leskovec;Pan Li,~Yanbang_Wang1;yenyu@stanford.edu;~Yunyu_Liu1;~Jure_Leskovec1;~Pan_Li2,7;6;6;5,4;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Stanford University;;;Purdue University;Stanford University;Purdue University,temporal networks;inductive representation learning;anonymous walk;network motif,5;-1;-1;23;5;23,2;-1;-1;94;2;94,m;m,usa,usa,n,
5920,ICLR,2021,How Does Mixup Help With Robustness and Generalization?,Linjun Zhang;Zhun Deng;Kenji Kawaguchi;Amirata Ghorbani;James Zou,linjun.zhang@rutgers.edu;~Zhun_Deng1;~Kenji_Kawaguchi1;~Amirata_Ghorbani2;~James_Zou1,8;6;7;7,3;3;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,Rutgers University;Harvard University;Harvard University;Stanford University;Stanford University,Mixup;adversarial robustness;generalization,29;53;53;5;5,-1;3;3;2;2,m;m,usa,usa,y,1;4
5921,ICLR,2021,Long-tail learning via logit adjustment,Aditya Krishna Menon;Sadeep Jayasumana;Ankit Singh Rawat;Himanshu Jain;Andreas Veit;Sanjiv Kumar,~Aditya_Krishna_Menon1;~Sadeep_Jayasumana1;~Ankit_Singh_Rawat1;himj@google.com;~Andreas_Veit1;~Sanjiv_Kumar1,8;6;7;8,4;4;3;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,"Google;Google;Google;Indian Institute of Technology Delhi,;Google;Google",long-tail learning;class imbalance,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
5922,ICLR,2021,Distilling Knowledge from Reader to Retriever for Question Answering,Gautier Izacard;Edouard Grave,~Gautier_Izacard1;~Edouard_Grave1,7;7;7;6,4;3;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Ecole Normale Superieure;Facebook,question answering;information retrieval,128;-1,-1;-1,m;m,NAN,NAN,n,8;3
5923,ICLR,2021,Temporally-Extended Œµ-Greedy Exploration,Will Dabney;Georg Ostrovski;Andre Barreto,~Will_Dabney1;~Georg_Ostrovski1;~Andre_Barreto1,8;6;5;5;8,5;4;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,Google DeepMind;Google;DeepMind,reinforcement learning;exploration,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5924,ICLR,2021,Unsupervised Audiovisual Synthesis via Exemplar Autoencoders,Kangle Deng;Aayush Bansal;Deva Ramanan,~Kangle_Deng1;~Aayush_Bansal1;~Deva_Ramanan1,6;9;6,3;4;3,Accept (Poster),0,3,0.0,yes,9/28/20,"Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie-Mellon University",unsupervised learning;autoencoders;speech-impaired;assistive technology;audiovisual synthesis;voice conversion,1;1;1,28;28;28,m;m,usa,usa,n,
5925,ICLR,2021,Representing Partial Programs with Blended Abstract Semantics,Maxwell Nye;Yewen Pu;Matthew Bowers;Jacob Andreas;Joshua B. Tenenbaum;Armando Solar-Lezama,~Maxwell_Nye1;~Yewen_Pu1;mlbowers@mit.edu;~Jacob_Andreas1;~Joshua_B._Tenenbaum1;~Armando_Solar-Lezama1,7;7;7;6,4;4;4;4,Accept (Poster),0,15,0.0,yes,9/28/20,Massachusetts Institute of Technology;Autodesk;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,program synthesis;representation learning;abstract interpretation;modular neural networks,5;-1;5;5;5;5,4;-1;4;4;4;4,m;m,usa,usa,n,
5926,ICLR,2021,On the Universality of the Double Descent Peak in Ridgeless Regression,David Holzm√ºller,~David_Holzm√ºller1,7;6;6;7,3;3;2;3,Accept (Poster),0,5,0.0,yes,9/28/20,University of Stuttgart,Double Descent;Interpolation Peak;Linear Regression;Random Features;Random Weights Neural Networks,110,354,m,europe,de,y,1
5927,ICLR,2021,Learning from others' mistakes: Avoiding dataset biases without modeling them,Victor Sanh;Thomas Wolf;Yonatan Belinkov;Alexander M Rush,~Victor_Sanh1;~Thomas_Wolf1;~Yonatan_Belinkov1;~Alexander_M_Rush1,7;2;7;6,4;5;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Hugging Face;Ecole Polytechnique;Technion, Technion;Cornell University",dataset bias;product of experts;natural language processing,-1;-1;29;7,-1;89;-1;19,m;m,usa,usa,n,3
5928,ICLR,2021,Support-set bottlenecks for video-text representation learning,Mandela Patrick;Po-Yao Huang;Yuki Asano;Florian Metze;Alexander G Hauptmann;Joao F. Henriques;Andrea Vedaldi,~Mandela_Patrick1;~Po-Yao_Huang1;~Yuki_Asano1;~Florian_Metze1;~Alexander_G_Hauptmann1;~Joao_F._Henriques1;~Andrea_Vedaldi1,7;7;6;9,5;4;4;3,Accept (Spotlight),0,13,0.0,yes,9/28/20,University of Oxford;Facebook;University of Oxford;Facebook;Carnegie-Mellon University;University of Oxford;U Oxford,video representation learning;multi-modal learning;video-text learning;contrastive learning,46;-1;46;-1;1;46;-1,1;-1;1;-1;28;1;-1,m;m,NAN,NAN,n,5
5929,ICLR,2021,Towards Robustness Against Natural Language Word Substitutions,Xinshuai Dong;Anh Tuan Luu;Rongrong Ji;Hong Liu,~Xinshuai_Dong1;~Anh_Tuan_Luu2;~Rongrong_Ji5;~Hong_Liu9,7;7;7,3;3;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;Columbia University;National Institute of Informatics,Natural Language Processing;Adversarial Defense,44;44;23;-1,47;47;17;-1,m;m,NAN,NAN,y,3;4
5930,ICLR,2021,The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers,Preetum Nakkiran;Behnam Neyshabur;Hanie Sedghi,~Preetum_Nakkiran1;~Behnam_Neyshabur1;~Hanie_Sedghi1,5;6;7;4,3;4;5;3,Accept (Poster),0,8,0.0,yes,9/28/20,"Harvard University;Google;Google Research, Brain team",generalization;optimization;online learning;understanding deep learning;empirical investigation,53;-1;-1,3;-1;-1,m;f,NAN,NAN,n,1
5931,ICLR,2021,Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation,Peiye Zhuang;Oluwasanmi O Koyejo;Alex Schwing,~Peiye_Zhuang2;~Oluwasanmi_O_Koyejo1;~Alex_Schwing1,6;6;6;8,3;4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois - Urbana Champaign;University of Illinois, Urbana Champaign",Image manipulation;GANs;latent space of GANs,-1;-1;-1,-1;-1;-1,f;m,usa,usa,n,5;4
5932,ICLR,2021,Bayesian Context Aggregation for Neural Processes,Michael Volpp;Fabian Fl√ºrenbrock;Lukas Grossberger;Christian Daniel;Gerhard Neumann,~Michael_Volpp1;~Fabian_Fl√ºrenbrock1;~Lukas_Grossberger1;~Christian_Daniel1;~Gerhard_Neumann1,6;7;6;6,5;3;4;1,Accept (Poster),0,9,0.0,yes,9/28/20,"Bosch;Swiss Federal Institute of Technology;Bosch Center for AI, Robert Bosch GmbH;Bosch Center for Artificial Intelligence;Karlsruhe Institute of Technology",Aggregation Methods;Neural Processes;Latent Variable Models;Meta Learning;Multi-task Learning;Deep Sets,-1;-1;-1;-1;174,285;-1;-1;-1;202,m;m,europe,de,n,11
5933,ICLR,2021,Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics,Vinay Venkatesh Ramasesh;Ethan Dyer;Maithra Raghu,~Vinay_Venkatesh_Ramasesh1;~Ethan_Dyer1;~Maithra_Raghu1,6;6;7;7,5;4;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,University of California Berkeley;Google;Google Brain,Catastrophic forgetting;continual learning;representation analysis;representation learning,-1;-1;-1,7;-1;-1,m;f,NAN,NAN,y,
5934,ICLR,2021,Neural ODE Processes,Alexander Norcliffe;Cristian Bodnar;Ben Day;Jacob Moss;Pietro Li√≤,alex.norcliffe98@gmail.com;~Cristian_Bodnar1;~Ben_Day1;jm2311@cam.ac.uk;~Pietro_Li√≤1,7;7;7;7,4;3;3;2,Accept (Poster),0,9,0.0,yes,9/28/20,University College London;University of Cambridge;University of Cambridge;University of Cambridge;;University of Cambridge,differential equations;neural processes;dynamics;deep learning;neural ode,53;79;79;79;-1;79,-1;6;6;6;-1;6,m;m,europe,uk,n,
5935,ICLR,2021,Large Batch Simulation for Deep Reinforcement Learning,Brennan Shacklett;Erik Wijmans;Aleksei Petrenko;Manolis Savva;Dhruv Batra;Vladlen Koltun;Kayvon Fatahalian,~Brennan_Shacklett1;~Erik_Wijmans1;petrenko@usc.edu;~Manolis_Savva1;~Dhruv_Batra1;~Vladlen_Koltun1;~Kayvon_Fatahalian2,7;7;6;5;4,3;4;2;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,Stanford University;Georgia Institute of Technology;University of Southern California;Simon Fraser University;Virginia Polytechnic Institute and State University;Intel;Carnegie-Mellon University,reinforcement learning;simulation,5;12;37;58;-1;-1;1,2;38;53;271;245;-1;28,m;m,usa,usa,n,
5936,ICLR,2021,Is Attention Better Than Matrix Decomposition?,Zhengyang Geng;Meng-Hao Guo;Hongxu Chen;Xia Li;Ke Wei;Zhouchen Lin,~Zhengyang_Geng1;~Meng-Hao_Guo1;~Hongxu_Chen2;~Xia_Li3;~Ke_Wei1;~Zhouchen_Lin1,6;8;8;7,3;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,"Peking University;Tsinghua University, Tsinghua University;Fudan University;Swiss Federal Institute of Technology;Fudan University;Peking University",attention models;matrix decomposition;computer vision,14;4;71;-1;71;14,23;20;70;-1;70;23,m;m,asia,cn,y,8;2
5937,ICLR,2021,Negative Data Augmentation ,Abhishek Sinha;Kumar Ayush;Jiaming Song;Burak Uzkent;Hongxia Jin;Stefano Ermon,~Abhishek_Sinha1;~Kumar_Ayush2;~Jiaming_Song1;~Burak_Uzkent1;~Hongxia_Jin1;~Stefano_Ermon1,5;6;9;7,4;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Stanford University;Computer Science Department, Stanford University;Computer Science Department, Stanford University;Stanford University;Samsung Research America AI center;Stanford University",generative models;self-supervised learning;data augmentation;anomaly detection,5;5;5;5;-1;5,2;2;2;2;-1;2,m;m,usa,usa,y,2;1;5
5938,ICLR,2021,Geometry-Aware Gradient Algorithms for Neural Architecture Search,Liam Li;Mikhail Khodak;Nina Balcan;Ameet Talwalkar,~Liam_Li1;~Mikhail_Khodak1;~Nina_Balcan1;~Ameet_Talwalkar1,7;8;6,3;4;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie-Mellon University;University of California-Los Angeles,neural architecture search;automated machine learning;weight-sharing;optimization,1;1;1;-1,28;28;28;15,m;m,usa,usa,y,2;1
5939,ICLR,2021,The geometry of integration in text classification RNNs,Kyle Aitken;Vinay Venkatesh Ramasesh;Ankush Garg;Yuan Cao;David Sussillo;Niru Maheswaranathan,~Kyle_Aitken1;~Vinay_Venkatesh_Ramasesh1;~Ankush_Garg1;~Yuan_Cao2;~David_Sussillo1;~Niru_Maheswaranathan1,7;7;5;7;8,4;5;4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,"University of Washington, Seattle;University of California Berkeley;Google;Google Brain;Google;Facebook",Recurrent neural networks;dynamical systems;interpretability;document classification;reverse engineering,11;-1;-1;-1;-1;-1,29;7;-1;-1;-1;-1,m;m,NAN,NAN,n,
5940,ICLR,2021,Exploring the Uncertainty Properties of Neural Networks‚Äô Implicit Priors in the Infinite-Width Limit,Ben Adlam;Jaehoon Lee;Lechao Xiao;Jeffrey Pennington;Jasper Snoek,~Ben_Adlam1;~Jaehoon_Lee2;~Lechao_Xiao2;~Jeffrey_Pennington1;~Jasper_Snoek1,6;6;7;5,4;3;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,"Google;Google;Google Research, Brain Team;Google;Google",Deep Learning;Uncertainty;Infinite-Width Limit;Neural Network Gaussian Process;Bayesian Neural Networks;Gaussian Process,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;11
5941,ICLR,2021,FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders,Pengyu Cheng;Weituo Hao;Siyang Yuan;Shijing Si;Lawrence Carin,~Pengyu_Cheng1;~Weituo_Hao1;~Siyang_Yuan1;~Shijing_Si1;~Lawrence_Carin2,6;7;6;7,4;3;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,Duke University;Duke University;Duke University;Duke University;Duke University,Fairness;Contrastive Learning;Mutual Information;Pretrained Text Encoders,46;46;46;46;46,20;20;20;20;20,m;m,europe,se,n,3;7
5942,ICLR,2021,Model-Based Offline Planning,Arthur Argenson;Gabriel Dulac-Arnold,aarg@google.com;~Gabriel_Dulac-Arnold1,5;5;7;8,3;5;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,Google;Google Research,off-line reinforcement learning;model-based reinforcement learning;model-based control;reinforcement learning;model predictive control;robotics,-1;-1,-1;-1,m;m,NAN,NAN,n,6
5943,ICLR,2021,Contextual Transformation Networks for Online Continual Learning,Quang Pham;Chenghao Liu;Doyen Sahoo;Steven HOI,~Quang_Pham1;~Chenghao_Liu1;~Doyen_Sahoo1;~Steven_HOI1,7;7;6;6,4;3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,Singapore Management University;Zhejiang University;Singapore Management University;Singapore Management University,Continual Learning,79;42;79;79,-1;94;-1;-1,m;m,asia,sg,n,1
5944,ICLR,2021,Latent Convergent Cross Mapping,Edward De Brouwer;Adam Arany;Jaak Simm;Yves Moreau,~Edward_De_Brouwer1;~Adam_Arany1;~Jaak_Simm1;~Yves_Moreau2,6;7;6;6,4;4;4;2,Accept (Poster),0,10,0.0,yes,9/28/20,KU Leuven;KU Leuven;KU Leuven;University of Leuven,Causality;Time Series;Chaos;Neural ODE;Missing Values,150;150;150;-1,45;45;45;874,m;m,europe,no,y,
5945,ICLR,2021,ALFWorld: Aligning Text and Embodied Environments for Interactive Learning,Mohit Shridhar;Xingdi Yuan;Marc-Alexandre Cote;Yonatan Bisk;Adam Trischler;Matthew Hausknecht,~Mohit_Shridhar1;~Xingdi_Yuan2;~Marc-Alexandre_Cote1;~Yonatan_Bisk1;~Adam_Trischler1;~Matthew_Hausknecht1,4;6;7,5;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;Microsoft Research;Microsoft;Carnegie Mellon University;Toronto University;Microsoft",Textworld;Text-based Games;Embodied Agents;Language Grounding;Generalization;Imitation Learning;ALFRED,11;-1;-1;1;-1;-1,29;-1;-1;28;-1;-1,m;m,NAN,NAN,n,1
5946,ICLR,2021,Extracting Strong Policies for Robotics Tasks from Zero-Order Trajectory Optimizers,Cristina Pinneri;Shambhuraj Sawant;Sebastian Blaes;Georg Martius,~Cristina_Pinneri1;shambhuraj.sawant@tuebingen.mpg.de;sebastian.blaes@tuebingen.mpg.de;~Georg_Martius1,6;6;6;5,3;3;2;3,Accept (Poster),0,7,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Delft University of Technology;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems",reinforcement learning;zero-order optimization;policy learning;model-based learning;robotics;model predictive control,-1;-1;-1;-1,-1;78;-1;-1,f;m,NAN,NAN,n,
5947,ICLR,2021,Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting,Sayna Ebrahimi;Suzanne Petryk;Akash Gokul;William Gan;Joseph E. Gonzalez;Marcus Rohrbach;trevor darrell,~Sayna_Ebrahimi1;~Suzanne_Petryk1;akashgokul@berkeley.edu;wjgan@berkeley.edu;~Joseph_E._Gonzalez1;~Marcus_Rohrbach1;~trevor_darrell1,6;6;6;6,4;2;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California - Berkeley;Facebook;Electrical Engineering & Computer Science Department,Continual Learning;Lifelong Learning;Catastrophic Forgetting;XAI;Explainability,-1;-1;-1;-1;-1;-1;-1,7;7;7;7;7;-1;-1,f;m,NAN,NAN,n,6
5948,ICLR,2021,Regularized Inverse Reinforcement Learning,Wonseok Jeon;Chen-Yang Su;Paul Barde;Thang Doan;Derek Nowrouzezahrai;Joelle Pineau,~Wonseok_Jeon1;~Chen-Yang_Su1;~Paul_Barde1;~Thang_Doan1;~Derek_Nowrouzezahrai1;~Joelle_Pineau1,7;7;6;6;8,3;3;4;3;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,MILA/McGill University;MILA/McGill University;INRIA;Mila / McGill University;McGill University;Facebook,inverse reinforcement learning;reward learning;regularized markov decision processes;reinforcement learning,99;99;-1;99;99;-1,40;40;-1;40;40;-1,m;f,NAN,NAN,y,
5949,ICLR,2021,Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates,Zengyi Qin;Kaiqing Zhang;Yuxiao Chen;Jingkai Chen;Chuchu Fan,~Zengyi_Qin1;~Kaiqing_Zhang3;~Yuxiao_Chen1;~Jingkai_Chen2;~Chuchu_Fan2,6;7;8;8;4,3;3;2;4;4,Accept (Poster),0,23,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Multi-agent;safe;control barrier function;reinforcement learning,5;5;-1;5;5,4;4;-1;4;4,m;f,usa,usa,y,1
5950,ICLR,2021,Characterizing signal propagation to close the performance gap in unnormalized ResNets,Andrew Brock;Soham De;Samuel L Smith,~Andrew_Brock1;~Soham_De2;~Samuel_L_Smith1,7;7;5,3;4;5,Accept (Poster),0,7,0.0,yes,9/28/20,DeepMind;DeepMind;Google DeepMind,normalizers;signal propagation;deep learning;neural networks;ResNets;EfficientNets;ImageNet;CNNs;ConvNets,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
5951,ICLR,2021,Self-Supervised Learning of Compressed Video Representations,Youngjae Yu;Sangho Lee;Gunhee Kim;Yale Song,~Youngjae_Yu1;~Sangho_Lee1;~Gunhee_Kim1;~Yale_Song1,6;6;6,4;5;5,Accept (Poster),0,5,0.0,yes,9/28/20,Allen Institute for Artificial Intelligence;Seoul National University;Seoul National University;Microsoft Research,Compressed videos;self-supervised learning,-1;37;37;-1,-1;60;60;-1,m;m,NAN,NAN,n,8
5952,ICLR,2021,AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly,Yuchen Jin;Tianyi Zhou;Liangyu Zhao;Yibo Zhu;Chuanxiong Guo;Marco Canini;Arvind Krishnamurthy,~Yuchen_Jin1;~Tianyi_Zhou1;liangyu@cs.washington.edu;zhuyibo@bytedance.com;guochuanxiong@bytedance.com;~Marco_Canini1;~Arvind_Krishnamurthy1,5;7;7;6,4;4;4;2,Accept (Poster),0,13,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;University of Washington;;;UC Santa Barbara;;;KAUST;University of Washington",,11;11;-1;-1;-1;-1;-1;110;11,29;29;-1;-1;-1;-1;-1;-1;29,m;m,usa,usa,n,8;11;1
5953,ICLR,2021,Variational Information Bottleneck for Effective Low-Resource Fine-Tuning,Rabeeh Karimi mahabadi;Yonatan Belinkov;James Henderson,~Rabeeh_Karimi_mahabadi2;~Yonatan_Belinkov1;~James_Henderson1,4;4;8;7,4;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Swiss Federal Institute of Technology Lausanne;Technion, Technion;Idiap Research Institute",Transfer learning;NLP;large-scale pre-trained language models;over-fitting;robust;biases;variational information bottleneck,-1;29;-1,-1;-1;-1,f;m,NAN,NAN,n,3;1;6
5954,ICLR,2021,Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction,Wei Deng;Qi Feng;Georgios P. Karagiannis;Guang Lin;Faming Liang,~Wei_Deng1;qif@usc.edu;georgios.karagiannis@durham.ac.uk;~Guang_Lin1;~Faming_Liang1,6;7;5;7,3;3;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,Purdue University;University of Southern California;Durham University;Purdue University;Purdue University,variance reduction;replica exchange;parallel tempering;stochastic gradient Langevin dynamics;uncertainty quantification;change of measure;generalized Girsanov theorem;Dirichlet form;Markov jump process,23;37;263;23;23,94;53;149;94;94,m;m,usa,usa,y,1
5955,ICLR,2021,New Bounds For Distributed Mean Estimation and Variance Reduction,Peter Davies;Vijaykrishna Gurunanthan;Niusha Moshrefi;Saleh Ashkboos;Dan Alistarh,peter.davies@ist.ac.at;krishnavijay1999@gmail.com;n76.moshrefi@gmail.com;saleh.ashkboos@gmail.com;~Dan_Alistarh7,7;6;6;7,4;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Institute of Science and Technology Austria;Indian Institute of Technology Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology;;;Swiss Federal Institute of Technology;Institute of Science and Technology Austria",distributed machine learning;mean estimation;variance reduction;lattices,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
5956,ICLR,2021,What they do when in doubt: a study of inductive biases in seq2seq learners,Eugene Kharitonov;Rahma Chaabouni,~Eugene_Kharitonov1;~Rahma_Chaabouni1,7;7;4;6,4;3;3;4,Accept (Poster),0,14,0.0,yes,9/28/20,Facebook;Facebook,inductive biases;description length;sequence-to-sequence models,-1;-1,-1;-1,m;f,NAN,NAN,n,8;1
5957,ICLR,2021,Self-training For Few-shot Transfer Across Extreme Task Differences,Cheng Perng Phoo;Bharath Hariharan,~Cheng_Perng_Phoo1;~Bharath_Hariharan3,6;8;7;8,4;5;4;5,Accept (Oral),0,0,0.0,yes,9/28/20,Cornell University;Cornell University,few-shot learning;self-training;cross-domain few-shot learning,7;7,19;19,m;m,usa,usa,n,6
5958,ICLR,2021,Rao-Blackwellizing the Straight-Through Gumbel-Softmax Gradient Estimator,Max B Paulus;Chris J. Maddison;Andreas Krause,~Max_B_Paulus1;~Chris_J._Maddison1;~Andreas_Krause1,7;7;8,4;3;3,Accept (Oral),0,9,0.0,yes,9/28/20,Swiss Federal Institute of Technology;University of Toronto;Swiss Federal Institute of Technology,gumbel;softmax;gumbel-softmax;straight-through;straightthrough;rao;rao-blackwell,-1;18;-1,-1;18;-1,m;m,NAN,NAN,y,
5959,ICLR,2021,Learning and Evaluating Representations for Deep One-Class Classification,Kihyuk Sohn;Chun-Liang Li;Jinsung Yoon;Minho Jin;Tomas Pfister,~Kihyuk_Sohn1;~Chun-Liang_Li1;~Jinsung_Yoon1;minhojin@google.com;~Tomas_Pfister1,6;7;7;5,4;4;3;5,Accept (Poster),0,10,0.0,yes,9/28/20,Google;Google;Google;;;Google,deep one-class classification;self-supervised learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
5960,ICLR,2021,Learning to live with Dale's principle: ANNs with separate excitatory and inhibitory units,Jonathan Cornford;Damjan Kalajdzievski;Marco Leite;Am√©lie Lamarquette;Dimitri Michael Kullmann;Blake Aaron Richards,~Jonathan_Cornford1;damjank7354@gmail.com;marco.leite.11@ucl.ac.uk;al858@cam.ac.uk;d.kullmann@ucl.ac.uk;~Blake_Aaron_Richards1,6;6;9;6,4;4;5;3,Accept (Poster),0,11,0.0,yes,9/28/20,"McGill University;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;;;University of Cambridge;;;McGill University",,99;128;-1;-1;79;-1;-1;99,40;73;-1;-1;6;-1;-1;40,m;m,canada,ca,n,
5961,ICLR,2021,A PAC-Bayesian Approach to Generalization Bounds for Graph Neural Networks,Renjie Liao;Raquel Urtasun;Richard Zemel,~Renjie_Liao1;~Raquel_Urtasun1;~Richard_Zemel1,6;7;7;5,3;4;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of Toronto;University of Toronto",PAC Bayes;Generalization Bounds;Graph Neural Networks;Graph Convolutional Neural Networks;Message Passing GNNs,18;18;18,18;18;18,m;m,canada,ca,y,11;1;10
5962,ICLR,2021,Teaching Temporal Logics to Neural Networks,Christopher Hahn;Frederik Schmitt;Jens U. Kreber;Markus Norman Rabe;Bernd Finkbeiner,~Christopher_Hahn1;~Frederik_Schmitt1;~Jens_U._Kreber1;~Markus_Norman_Rabe1;finkbeiner@cispa.saarland,6;7;7;5,4;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"CISPA, saarland university, saarland informatics campus;Saarland University;Saarland University;Google;CISPA, saarland university, saarland informatics campus",Logic;Verification;Transformer,-1;92;92;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
5963,ICLR,2021,"On InstaHide, Phase Retrieval, and Sparse Matrix Factorization",Sitan Chen;Xiaoxiao Li;Zhao Song;Danyang Zhuo,~Sitan_Chen1;~Xiaoxiao_Li1;~Zhao_Song3;~Danyang_Zhuo1,4;8;7;7,4;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,Massachusetts Institute of Technology;Princeton University;Institue for Advanced Study;Duke University,Distributed learning;InstaHide;phase retrieval;matrix factorization,5;29;-1;46,4;9;-1;20,m;m,europe,se,y,
5964,ICLR,2021,Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech,Yoonhyung Lee;Joongbo Shin;Kyomin Jung,~Yoonhyung_Lee2;~Joongbo_Shin1;~Kyomin_Jung1,6;6;8;5,5;5;4;5,Accept (Poster),0,8,0.0,yes,9/28/20,Seoul National University;LG AI Research;Seoul National University,text-to-speech;speech synthesis;non-autoregressive;VAE,37;-1;37,60;-1;60,u;m,asia,kr,n,8;5
5965,ICLR,2021,Neural Delay Differential Equations,Qunxi Zhu;Yao Guo;Wei Lin,~Qunxi_Zhu1;~Yao_Guo3;~Wei_Lin1,6;5;6;7,4;4;3;4,Accept (Poster),0,10,0.0,yes,9/28/20,Fudan University;Fudan University;Fudan University,Delay differential equations;neural networks,71;71;71,70;70;70,m;m,asia,cn,y,
5966,ICLR,2021,SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing,Tao Yu;Rui Zhang;Alex Polozov;Christopher Meek;Ahmed Hassan Awadallah,~Tao_Yu5;~Rui_Zhang7;~Alex_Polozov1;~Christopher_Meek1;~Ahmed_Hassan_Awadallah1,7;4;7;7;6,4;5;4;3;4,Accept (Poster),0,14,0.0,yes,9/28/20,Yale University;Pennsylvania State University;Microsoft Research;Microsoft;Microsoft Research,,71;44;-1;-1;-1,8;-1;-1;-1;-1,m;m,NAN,NAN,n,3
5967,ICLR,2021,Variational Intrinsic Control Revisited,Taehwan Kwon,~Taehwan_Kwon1,6;6;5;6,4;4;4;4,Accept (Poster),0,19,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology,Unsupervised reinforcement learning;Information theory,-1,96,m,NAN,NAN,n,1
5968,ICLR,2021,Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration,Xavier Puig;Tianmin Shu;Shuang Li;Zilin Wang;Yuan-Hong Liao;Joshua B. Tenenbaum;Sanja Fidler;Antonio Torralba,~Xavier_Puig1;~Tianmin_Shu1;~Shuang_Li5;~Zilin_Wang2;~Yuan-Hong_Liao2;~Joshua_B._Tenenbaum1;~Sanja_Fidler1;~Antonio_Torralba1,6;6;7;6,3;4;3;5,Accept (Spotlight),0,7,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Swiss Federal Institute of Technology;University of Toronto;Massachusetts Institute of Technology;Department of Computer Science, University of Toronto;Massachusetts Institute of Technology",social perception;human-AI collaboration;theory of mind;multi-agent platform;virtual environment,5;5;5;-1;18;5;18;5,4;4;4;-1;18;4;18;4,m;m,usa,usa,n,
5969,ICLR,2021,Is Label Smoothing Truly Incompatible with Knowledge Distillation: An Empirical Study,Zhiqiang Shen;Zechun Liu;Dejia Xu;Zitian Chen;Kwang-Ting Cheng;Marios Savvides,~Zhiqiang_Shen1;~Zechun_Liu1;~Dejia_Xu1;~Zitian_Chen1;~Kwang-Ting_Cheng1;~Marios_Savvides1,6;6;8;6,3;5;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Mohamed bin Zayed University of Artificial Intelligence;CMU  Carnegie Mellon University;Peking University  Tsinghua University;University of Massachusetts  Amherst;HKUST;Carnegie Mellon University,label smoothing;knowledge distillation;image classification;neural machine translation;binary neural networks,-1;1;4;23;37;1,874;28;20;210;-1;28,m;m,usa,usa,n,3
5970,ICLR,2021,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,Alexey Dosovitskiy;Lucas Beyer;Alexander Kolesnikov;Dirk Weissenborn;Xiaohua Zhai;Thomas Unterthiner;Mostafa Dehghani;Matthias Minderer;Georg Heigold;Sylvain Gelly;Jakob Uszkoreit;Neil Houlsby,~Alexey_Dosovitskiy1;~Lucas_Beyer1;~Alexander_Kolesnikov2;~Dirk_Weissenborn1;~Xiaohua_Zhai2;~Thomas_Unterthiner1;~Mostafa_Dehghani1;~Matthias_Minderer1;~Georg_Heigold1;~Sylvain_Gelly1;~Jakob_Uszkoreit1;~Neil_Houlsby1,7;7;7;7,3;4;4;5,Accept (Oral),0,9,0.0,yes,9/28/20,Google;Google Brain;Google;German Research Center for Artificial Intelligence;Google;Google;Google Brain;Google;Google;Google Brain;Google;Google,computer vision;image recognition;self-attention;transformer;large-scale training,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;2;3
5971,ICLR,2021,A Unified Approach to Interpreting and Boosting Adversarial Transferability,Xin Wang;Jie Ren;Shuyun Lin;Xiangming Zhu;Yisen Wang;Quanshi Zhang,~Xin_Wang25;~Jie_Ren1;~Shuyun_Lin1;~Xiangming_Zhu2;~Yisen_Wang1;~Quanshi_Zhang1,6;5;10;6,3;3;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Peking University;Shanghai Jiao Tong University,Adversarial Learning;Interpretability;Adversarial Transferability,29;29;29;29;14;29,100;100;100;100;23;100,m;m,asia,cn,y,1;4
5972,ICLR,2021,Parameter Efficient Multimodal Transformers for Video Representation Learning,Sangho Lee;Youngjae Yu;Gunhee Kim;Thomas Breuel;Jan Kautz;Yale Song,~Sangho_Lee1;~Youngjae_Yu1;~Gunhee_Kim1;~Thomas_Breuel1;~Jan_Kautz1;~Yale_Song1,5;8;6;6,5;5;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,Seoul National University;Allen Institute for Artificial Intelligence;Seoul National University;;NVIDIA;Microsoft Research,Self-supervised learning;audio-visual representation learning;video representation learning,37;-1;37;-1;-1;-1,60;-1;60;-1;-1;-1,m;m,NAN,NAN,n,8;3
5973,ICLR,2021,Hyperbolic Neural Networks++,Ryohei Shimizu;YUSUKE Mukuta;Tatsuya Harada,~Ryohei_Shimizu1;~YUSUKE_Mukuta1;~Tatsuya_Harada1,7;7;6;8,4;3;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,The University of Tokyo;The University of Tokyo;RIKEN,Hyperbolic Geometry;Poincar√© Ball Model;Parameter-Reduced MLR;Geodesic-Aware FC Layer;Convolutional Layer;Attention Mechanism,71;71;-1,36;36;-1,m;m,NAN,NAN,y,8
5974,ICLR,2021,Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting,Yuan Yin;Vincent LE GUEN;J√©r√©mie DONA;Emmanuel de Bezenac;Ibrahim Ayed;Nicolas THOME;patrick gallinari,~Yuan_Yin1;~Vincent_LE_GUEN1;~J√©r√©mie_DONA2;~Emmanuel_de_Bezenac1;~Ibrahim_Ayed1;~Nicolas_THOME2;~patrick_gallinari1,8;7;9,4;3;3,Accept (Oral),0,6,0.0,yes,9/28/20,"Sorbonne Universit√©, LIP6;Conservatoire National des Arts et M√©tiers;MLIA;;LIP6;Cnam;Criteo AI Lab",spatio-temporal forecasting;deep learning;physics;differential equations;hybrid systems,-1;-1;-1;-1;453;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
5975,ICLR,2021,Hopfield Networks is All You Need,Hubert Ramsauer;Bernhard Sch√§fl;Johannes Lehner;Philipp Seidl;Michael Widrich;Lukas Gruber;Markus Holzleitner;Thomas Adler;David Kreil;Michael K Kopp;G√ºnter Klambauer;Johannes Brandstetter;Sepp Hochreiter,~Hubert_Ramsauer2;~Bernhard_Sch√§fl1;~Johannes_Lehner1;~Philipp_Seidl1;~Michael_Widrich2;~Lukas_Gruber2;~Markus_Holzleitner1;~Thomas_Adler1;openreview20@kreil.org;~Michael_K_Kopp1;~G√ºnter_Klambauer1;~Johannes_Brandstetter1;~Sepp_Hochreiter1,7;6;7,4;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,"Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;Institute for Machine Learning, Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;;;Institute of Advanced Research in Artificial Intelligence (IARAI);Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz",Modern Hopfield Network;Energy;Attention;Convergence;Storage Capacity;Hopfield layer;Associative Memory,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,8
5976,ICLR,2021,Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding,David A. Klindt;Lukas Schott;Yash Sharma;Ivan Ustyuzhaninov;Wieland Brendel;Matthias Bethge;Dylan Paiton,~David_A._Klindt1;~Lukas_Schott2;~Yash_Sharma1;~Ivan_Ustyuzhaninov1;~Wieland_Brendel1;~Matthias_Bethge1;dpaiton@gmail.com,7;9;9;8,3;4;3;4,Accept (Oral),0,11,0.0,yes,9/28/20,"Norwegian Institute of Technology;;Centre for Integrative Neuroscience, AG Bethge;University of T√ºbingen;T√ºbingen AI Center, University of T√ºbingen;University of Tuebingen;University of Tuebingen",disentanglement;independent component analysis;natural scene statistics,-1;-1;-1;128;128;128;128,-1;-1;-1;78;78;78;78,m;m,europe,de,y,1;5
5977,ICLR,2021,More or Less: When and How to Build Convolutional Neural Network Ensembles,Abdul Wasay;Stratos Idreos,~Abdul_Wasay1;~Stratos_Idreos1,5;8;7;8,4;4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Harvard University;Harvard University,ensemble learning;empirical study;machine learning systems;computer vision,53;53,3;3,m;m,usa,usa,n,
5978,ICLR,2021,Learning to Sample with Local and Global Contexts  in Experience Replay Buffer,Youngmin Oh;Kimin Lee;Jinwoo Shin;Eunho Yang;Sung Ju Hwang,~Youngmin_Oh2;~Kimin_Lee1;~Jinwoo_Shin1;~Eunho_Yang1;~Sung_Ju_Hwang1,7;6;6,4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Pohang University of Science and Technology;University of California Berkeley;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology,reinforcement learning;experience replay buffer;off-policy RL,-1;-1;-1;-1;-1,151;7;96;-1;96,m;m,NAN,NAN,n,
5979,ICLR,2021,A Trainable Optimal Transport Embedding for Feature Aggregation and its Relationship to Attention,Gr√©goire Mialon;Dexiong Chen;Alexandre d'Aspremont;Julien Mairal,~Gr√©goire_Mialon1;~Dexiong_Chen1;~Alexandre_d'Aspremont1;~Julien_Mairal1,6;6;7;7,3;2;4;2,Accept (Poster),0,6,0.0,yes,9/28/20,INRIA;INRIA;Ecole Normale Superieure;Inria,bioinformatics;optimal transport;kernel methods;attention;transformers,-1;-1;128;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,3;8;1
5980,ICLR,2021,Training independent subnetworks for robust prediction,Marton Havasi;Rodolphe Jenatton;Stanislav Fort;Jeremiah Zhe Liu;Jasper Snoek;Balaji Lakshminarayanan;Andrew Mingbo Dai;Dustin Tran,~Marton_Havasi1;~Rodolphe_Jenatton3;~Stanislav_Fort1;~Jeremiah_Zhe_Liu1;~Jasper_Snoek1;~Balaji_Lakshminarayanan1;~Andrew_Mingbo_Dai1;~Dustin_Tran1,6;6;7;8,4;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Cambridge;Google;Stanford University;Harvard University;Google;Google Brain;Google;Columbia University,Efficient ensembles;robustness,79;-1;5;53;-1;-1;-1;23,6;-1;2;3;-1;-1;-1;17,m;m,usa,usa,n,
5981,ICLR,2021,Sample-Efficient Automated Deep Reinforcement Learning,J√∂rg K.H. Franke;Gregor Koehler;Andr√© Biedenkapp;Frank Hutter,~J√∂rg_K.H._Franke1;~Gregor_Koehler1;~Andr√©_Biedenkapp1;~Frank_Hutter1,7;5;5;6,5;3;3;4,Accept (Poster),0,12,0.0,yes,9/28/20,"Universit√§t Freiburg;German Cancer Research Center (DKFZ);University of Freiburg, Universit√§t Freiburg;University of Freiburg & Bosch",AutoRL;Deep Reinforcement Learning;Hyperparameter Optimization;Neuroevolution,-1;-1;150;150,-1;-1;83;83,m;m,NAN,NAN,n,
5982,ICLR,2021,Shapley Explanation Networks,Rui Wang;Xiaoqian Wang;David I. Inouye,~Rui_Wang1;~Xiaoqian_Wang1;~David_I._Inouye1,6;7;6,4;4;3,Accept (Poster),0,8,0.0,yes,9/28/20,"Paul G. Allen School of Computer Science and Engineering, University of Washington;Purdue University;Purdue University",Shapley values;Feature Attribution;Interpretable Machine Learning,11;23;23,29;94;94,m;m,usa,usa,y,1
5983,ICLR,2021,Class Normalization for (Continual)? Generalized Zero-Shot Learning,Ivan Skorokhodov;Mohamed Elhoseiny,~Ivan_Skorokhodov1;~Mohamed_Elhoseiny1,7;7;8;3,5;5;5;4,Accept (Poster),0,21,0.0,yes,9/28/20,KAUST;KAUST,zero-shot learning;normalization;continual learning;initialization,110;110,-1;-1,m;m,europe,gr,y,6;8;1
5984,ICLR,2021,Certify or Predict: Boosting Certified Robustness with Compositional Architectures,Mark Niklas Mueller;Mislav Balunovic;Martin Vechev,~Mark_Niklas_Mueller2;~Mislav_Balunovic1;~Martin_Vechev1,6;6;7,5;5;3,Accept (Poster),0,19,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Provable Robustness;Network Architecture;Robustness;Adversarial Accuracy;Certified Robustness,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,4
5985,ICLR,2021,"On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines",Marius Mosbach;Maksym Andriushchenko;Dietrich Klakow,~Marius_Mosbach1;~Maksym_Andriushchenko1;~Dietrich_Klakow1,6;6;8;4,3;3;4;5,Accept (Poster),0,4,0.0,yes,9/28/20,Saarland University;Swiss Federal Institute of Technology Lausanne;Saarland University,fine-tuning stability;transfer learning;pretrained language model;BERT,92;-1;92,-1;-1;-1,m;m,europe,de,n,3;8;1
5986,ICLR,2021,Generalization in data-driven models of primary visual cortex,Konstantin-Klemens Lurz;Mohammad Bashiri;Konstantin Willeke;Akshay Jagadish;Eric Wang;Edgar Y. Walker;Santiago A Cadena;Taliah Muhammad;Erick Cobos;Andreas S. Tolias;Alexander S Ecker;Fabian H. Sinz,~Konstantin-Klemens_Lurz1;mohammad.bashiri@uni-tuebingen.de;konstantin-friedrich.willeke@uni-tuebingen.de;akshay-kumar.jagadish@student.uni-tuebingen.de;eric.wang2@bcm.edu;~Edgar_Y._Walker1;~Santiago_A_Cadena1;taliah.muhammad@bcm.edu;~Erick_Cobos1;~Andreas_S._Tolias1;~Alexander_S_Ecker1;~Fabian_H._Sinz1,6;7;8;8,5;3;4;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,"University of Tuebingen;University of Tuebingen;;;;;;;University of Tuebingen;University of Tuebingen;Baylor College of Medicine;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Baylor College of Medicine;University of Goettingen;University G√∂ttingen",neuroscience;cognitive science;multitask learning;transfer learning;representation learning;network architecture;computational biology;visual perception,128;128;-1;-1;-1;-1;-1;-1;128;128;-1;-1;-1;327;-1,78;78;-1;-1;-1;-1;-1;-1;78;78;-1;-1;-1;130;-1,m;m,NAN,NAN,n,6
5987,ICLR,2021,End-to-end Adversarial Text-to-Speech,Jeff Donahue;Sander Dieleman;Mikolaj Binkowski;Erich Elsen;Karen Simonyan,~Jeff_Donahue1;~Sander_Dieleman1;~Mikolaj_Binkowski1;~Erich_Elsen1;~Karen_Simonyan1,8;7;8;7,4;4;4;3,Accept (Oral),0,8,0.0,yes,9/28/20,DeepMind;DeepMind;DeepMind;Royal Caliber;DeepMind,text-to-speech;speech synthesis;adversarial;GAN;end-to-end;feed-forward;generative model,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,4
5988,ICLR,2021,FairBatch: Batch Selection for Model Fairness,Yuji Roh;Kangwook Lee;Steven Euijong Whang;Changho Suh,~Yuji_Roh1;~Kangwook_Lee1;~Steven_Euijong_Whang1;~Changho_Suh1,4;7;6;6,4;4;3;5,Accept (Poster),0,4,0.0,yes,9/28/20,"Korea Advanced Institute of Science and Technology;University of Wisconsin, Madison;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology",model fairness;bilevel optimization;batch selection,-1;18;-1;-1,96;49;96;96,f;m,NAN,NAN,y,7
5989,ICLR,2021,Mind the Gap when Conditioning Amortised Inference in Sequential Latent-Variable Models,Justin Bayer;Maximilian Soelch;Atanas Mirchev;Baris Kayalibay;Patrick van der Smagt,~Justin_Bayer1;~Maximilian_Soelch1;~Atanas_Mirchev1;~Baris_Kayalibay1;~Patrick_van_der_Smagt1,7;7;7;6,4;5;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,"VW Group;Technical University Munich;Technical University Munich;Data Lab, Volkswagen Group;Machine Learning Research Lab, Volkswagen Group",variational inference;state-space models;amortized inference;recurrent networks,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11;1;5
5990,ICLR,2021,On the role of planning in model-based deep reinforcement learning,Jessica B Hamrick;Abram L. Friesen;Feryal Behbahani;Arthur Guez;Fabio Viola;Sims Witherspoon;Thomas Anthony;Lars Holger Buesing;Petar Veliƒçkoviƒá;Theophane Weber,~Jessica_B_Hamrick1;~Abram_L._Friesen1;~Feryal_Behbahani1;~Arthur_Guez1;~Fabio_Viola2;switherspoon@google.com;~Thomas_Anthony1;~Lars_Holger_Buesing1;~Petar_Veliƒçkoviƒá1;~Theophane_Weber1,5;7;7;6,4;4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,DeepMind;DeepMind;DeepMind;Google DeepMind;DeepMind;;;DeepMind;Deepmind;DeepMind;Google DeepMind,model-based RL;planning;MuZero,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,1
5991,ICLR,2021,Memory Optimization for Deep Networks,Aashaka Shah;Chao-Yuan Wu;Jayashree Mohan;Vijay Chidambaram;Philipp Kraehenbuehl,~Aashaka_Shah1;~Chao-Yuan_Wu1;jaya@cs.utexas.edu;~Vijay_Chidambaram1;~Philipp_Kraehenbuehl1,7;7;8;6,4;4;4;3,Accept (Spotlight),0,5,0.0,yes,9/28/20,"University of Texas, Austin;Facebook;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",memory optimized training;memory efficient training;checkpointing;deep network training,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,usa,usa,n,
5992,ICLR,2021,In Search of Lost Domain Generalization,Ishaan Gulrajani;David Lopez-Paz,~Ishaan_Gulrajani1;~David_Lopez-Paz2,6;7;7;8,5;4;5;4,Accept (Poster),0,5,0.0,yes,9/28/20,Stanford University;Facebook,domain generalization;reproducible research,5;-1,2;-1,m;m,NAN,NAN,n,1
5993,ICLR,2021,"MultiModalQA: complex question answering over text, tables and images",Alon Talmor;Ori Yoran;Amnon Catav;Dan Lahav;Yizhong Wang;Akari Asai;Gabriel Ilharco;Hannaneh Hajishirzi;Jonathan Berant,~Alon_Talmor1;oriy@mail.tau.ac.il;amnoncatav@mail.tau.ac.il;lahav@mail.tau.ac.il;~Yizhong_Wang2;~Akari_Asai2;~Gabriel_Ilharco1;~Hannaneh_Hajishirzi1;~Jonathan_Berant1,6;6;8;6,3;1;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,"Tel Aviv University;Tel Aviv University;Tel Aviv University, Technion;Tel Aviv University;Department of Computer Science, University of Washington;University of Washington;Department of Computer Science, University of Washington;University of Washington;Tel Aviv University",NLP;Question Answering;Dataset;Multi-Modal;Multi-Hop,34;34;29;34;11;11;11;11;34,190;190;190;190;29;29;29;29;190,m;m,europe,il,n,10
5994,ICLR,2021,Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation,Biao Zhang;Ankur Bapna;Rico Sennrich;Orhan Firat,~Biao_Zhang2;~Ankur_Bapna1;~Rico_Sennrich1;~Orhan_Firat1,8;9;7;7,5;3;4;4,Accept (Oral),0,7,0.0,yes,9/28/20,University of Edinburgh;Google;University of Zurich;Google,language-specific modeling;conditional computation;multilingual translation;multilingual transformer,29;-1;128;-1,30;-1;73;-1,m;m,NAN,NAN,n,8
5995,ICLR,2021,Improving Adversarial Robustness via Channel-wise Activation Suppressing,Yang Bai;Yuyuan Zeng;Yong Jiang;Shu-Tao Xia;Xingjun Ma;Yisen Wang,~Yang_Bai1;~Yuyuan_Zeng1;~Yong_Jiang3;~Shu-Tao_Xia1;~Xingjun_Ma1;~Yisen_Wang1,7;7;7;8,4;5;4;4,Accept (Spotlight),0,9,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;;Graduate School at Shenzhen, Tsinghua University;Deakin University;Peking University",Adversarial robustness;channel suppressing;activation strategy.,4;4;-1;4;-1;14,20;20;-1;20;295;23,u;m,asia,cn,n,8;4
5996,ICLR,2021, Decentralized Attribution of Generative Models,Changhoon Kim;Yi Ren;Yezhou Yang,~Changhoon_Kim1;~Yi_Ren3;~Yezhou_Yang1,6;6;5,2;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,Arizona State University;Arizona State University;Arizona State University,GANs;Generative Model;Deepfake;Model Attribution,85;85;85,182;182;182,m;m,usa,usa,y,5;4
5997,ICLR,2021, Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning,Ruozi Huang;Huang Hu;Wei Wu;Kei Sawada;Mi Zhang;Daxin Jiang,~Ruozi_Huang1;~Huang_Hu1;~Wei_Wu1;kesawada@microsoft.com;mi_zhang@fudan.edu.cn;djiang@microsoft.com,6;6;7;7,3;5;3;4,Accept (Poster),0,12,0.0,yes,9/28/20,Fudan University;Microsoft;Microsoft Research;;;;;Microsoft,Multimodal Learning;Computer Vision;Sequence Modeling;Generative Models,71;-1;-1;-1;-1;-1;-1;-1,70;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
5998,ICLR,2021,Activation-level uncertainty in deep neural networks,Pablo Morales-Alvarez;Daniel Hern√°ndez-Lobato;Rafael Molina;Jos√© Miguel Hern√°ndez-Lobato,~Pablo_Morales-Alvarez1;~Daniel_Hern√°ndez-Lobato1;rms@decsai.ugr.es;~Jos√©_Miguel_Hern√°ndez-Lobato1,6;6;7;8,5;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Granada;Universidad Aut√≥noma de Madrid;;;University of Cambridge,Gaussian Processes;Uncertainty estimation;Deep Gaussian Processes;Bayesian Neural Networks,-1;-1;-1;-1;79,681;-1;-1;-1;6,m;m,europe,uk,n,11
5999,ICLR,2021,Sliced Kernelized Stein Discrepancy,Wenbo Gong;Yingzhen Li;Jos√© Miguel Hern√°ndez-Lobato,~Wenbo_Gong1;~Yingzhen_Li1;~Jos√©_Miguel_Hern√°ndez-Lobato1,6;8;6,4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,University of Cambridge;Imperial College London;University of Cambridge,kernel methods;variational inference;particle inference,79;53;79,6;11;6,m;m,europe,uk,y,5
6000,ICLR,2021,Training GANs with Stronger Augmentations via Contrastive Discriminator,Jongheon Jeong;Jinwoo Shin,~Jongheon_Jeong1;~Jinwoo_Shin1,7;6;6;7,3;4;4;4,Accept (Poster),0,12,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,generative adversarial networks;contrastive learning;data augmentation;visual representation learning;unsupervised learning,-1;-1,96;96,m;m,NAN,NAN,n,5;4
6001,ICLR,2021,Balancing Constraints and Rewards with Meta-Gradient D4PG,Dan A. Calian;Daniel J Mankowitz;Tom Zahavy;Zhongwen Xu;Junhyuk Oh;Nir Levine;Timothy Mann,dancalian@google.com;~Daniel_J_Mankowitz2;~Tom_Zahavy2;~Zhongwen_Xu1;~Junhyuk_Oh2;~Nir_Levine2;~Timothy_Mann1,6;7;7;7,4;4;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Google;Google;DeepMind;DeepMind;DeepMind;DeepMind;Google,reinforcement learning;meta-gradients;constraints,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
6002,ICLR,2021,Disentangling 3D Prototypical Networks for Few-Shot Concept Learning,Mihir Prabhudesai;Shamit Lal;Darshan Patil;Hsiao-Yu Tung;Adam W Harley;Katerina Fragkiadaki,~Mihir_Prabhudesai1;~Shamit_Lal1;~Darshan_Patil1;~Hsiao-Yu_Tung1;~Adam_W_Harley1;~Katerina_Fragkiadaki1,6;5;6;7,3;3;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,"BITS Pilani, Dhirubhai Ambani Institute Of Information and Communication Technology;Carnegie Mellon University;University of Montreal;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University",Disentanglement;Few Shot Learning;3D Vision;VQA,453;1;128;1;1;1,-1;28;73;28;28;28,m;f,usa,usa,n,6;2
6003,ICLR,2021,Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule,Shuhei Kurita;Kyunghyun Cho,~Shuhei_Kurita1;~Kyunghyun_Cho1,4;5;8;8,4;4;3;5,Accept (Poster),0,5,0.0,yes,9/28/20,RIKEN;New York University,vision-and-language-navigation,-1;23,-1;26,m;m,usa,usa,n,3;5
6004,ICLR,2021,Implicit Normalizing Flows,Cheng Lu;Jianfei Chen;Chongxuan Li;Qiuhao Wang;Jun Zhu,~Cheng_Lu5;~Jianfei_Chen1;~Chongxuan_Li1;~Qiuhao_Wang1;~Jun_Zhu2,8;7;8;7,4;4;4;3,Accept (Spotlight),0,7,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Peking University;Tsinghua University",Normalizing flows;deep generative models;probabilistic inference;implicit functions,4;4;4;14;4,20;20;20;23;20,m;m,asia,cn,y,
6005,ICLR,2021,Semantic Re-tuning with Contrastive Tension,Fredrik Carlsson;Amaru Cuba Gyllensten;Evangelia Gogoulou;Erik Ylip√§√§ Hellqvist;Magnus Sahlgren,~Fredrik_Carlsson1;~Amaru_Cuba_Gyllensten2;~Evangelia_Gogoulou1;~Erik_Ylip√§√§_Hellqvist1;~Magnus_Sahlgren1,6;7;5;9,4;5;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;Uppsala University;Research institutes of Sweden",Semantic Textual Similarity;Transformers;Language Modelling;Sentence Embeddings;Sentence Representations;Pre-training;Fine-tuning,174;174;174;174;-1,239;239;239;111;-1,m;m,NAN,NAN,n,8;3
6006,ICLR,2021,Generating Furry Cars: Disentangling Object Shape and Appearance across Multiple Domains,Utkarsh Ojha;Krishna Kumar Singh;Yong Jae Lee,~Utkarsh_Ojha1;~Krishna_Kumar_Singh4;~Yong_Jae_Lee2,7;5;7;5,3;4;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"University of California, Davis;Adobe Systems;UC Davis",multi-domain disentanglement;generative adversarial networks;appearance transfer,-1;-1;-1,64;-1;-1,m;m,NAN,NAN,n,5
6007,ICLR,2021,Randomized Ensembled Double Q-Learning: Learning Fast Without a Model,Xinyue Chen;Che Wang;Zijian Zhou;Keith W. Ross,~Xinyue_Chen1;~Che_Wang1;~Zijian_Zhou1;~Keith_W._Ross1,7;6;7;7,3;3;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,New York University;New York University;New York University;New York University,Artificial Integlligence;Machine Learning;Deep Reinforcement Learning,23;23;23;23,26;26;26;26,f;m,usa,usa,y,
6008,ICLR,2021,The Role of Momentum Parameters in the Optimal Convergence of Adaptive Polyak's Heavy-ball Methods,Wei Tao;Sheng Long;Gaowei Wu;Qing Tao,~Wei_Tao3;ls15186322349@163.com;gaowei.wu@ia.ac.cn;qing.tao@ia.ac.cn,6;6;5;6,4;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Academy of Military Science;;;Institute of Automation Chinese Academy of Sciences,Deep learning;convex optimization;momentum methods;adaptive heavy-ball methods;optimal convergence,-1;-1;-1;34,-1;-1;-1;-1,u;u,NAN,NAN,y,1;9
6009,ICLR,2021,How Benign is Benign Overfitting ?,Amartya Sanyal;Puneet K. Dokania;Varun Kanade;Philip Torr,~Amartya_Sanyal1;~Puneet_K._Dokania1;~Varun_Kanade1;~Philip_Torr1,6;7;7;8,3;3;3;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,Swiss Federal Institute of Technology;University of Oxford;University of Oxford;University of Oxford,benign overfitting;adversarial robustness;memorization;generalization,-1;46;46;46,-1;1;1;1,m;m,europe,uk,y,1;4
6010,ICLR,2021,Towards Impartial Multi-task Learning,Liyang Liu;Yi Li;Zhanghui Kuang;Jing-Hao Xue;Yimin Chen;Wenming Yang;Qingmin Liao;Wayne Zhang,~Liyang_Liu1;~Yi_Li15;~Zhanghui_Kuang4;~Jing-Hao_Xue1;~Yimin_Chen1;~Wenming_Yang1;~Qingmin_Liao1;~Wayne_Zhang2,7;5;4,4;5;5,Accept (Poster),0,4,0.0,yes,9/28/20,"Tsinghua University;sensetime;sensetime;University College London;City University of Hong Kong;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;SenseTime Research",Multi-task Learning;Impartial Learning;Scene Understanding,4;-1;-1;53;128;4;4;-1,20;-1;-1;-1;126;20;20;-1,f;m,NAN,NAN,y,
6011,ICLR,2021,Active Contrastive Learning of Audio-Visual Video Representations,Shuang Ma;Zhaoyang Zeng;Daniel McDuff;Yale Song,~Shuang_Ma3;~Zhaoyang_Zeng1;~Daniel_McDuff1;~Yale_Song1,7;6;7;7,3;4;5;3,Accept (Poster),0,5,0.0,yes,9/28/20,Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft Research,self-supervised learning;contrastive representation learning;active learning;audio-visual representation;video recognition,-1;-1;-1;-1,-1;293;-1;-1,f;m,NAN,NAN,n,1
6012,ICLR,2021,Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions,Zhengxian Lin;Kin-Ho Lam;Alan Fern,~Zhengxian_Lin1;~Kin-Ho_Lam1;~Alan_Fern1,7;8;7,5;4;2,Accept (Oral),0,4,0.0,yes,9/28/20,Oregon State University;Oregon State University;Oregon State University,Explainable AI;Deep Reinforcement Learning,79;79;79,424;424;424,m;m,usa,usa,y,
6013,ICLR,2021,Calibration of Neural Networks using Splines,Kartik Gupta;Amir Rahimi;Thalaiyasingam Ajanthan;Thomas Mensink;Cristian Sminchisescu;Richard Hartley,~Kartik_Gupta2;~Amir_Rahimi1;~Thalaiyasingam_Ajanthan1;~Thomas_Mensink1;~Cristian_Sminchisescu1;~Richard_Hartley1,8;7;8;5,4;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Australian National University;Australian National University;Australian National University;Google Research;Lund University;Australian National University,neural network calibration;uncertainty;calibration measure,99;99;99;-1;453;99,59;59;59;-1;103;59,m;m,australasia,au,y,
6014,ICLR,2021,Global Convergence of Three-layer Neural Networks in the Mean Field Regime,Huy Tuan Pham;Phan-Minh Nguyen,huypham@stanford.edu;~Phan-Minh_Nguyen1,7;7;7;9,3;2;3;2,Accept (Oral),0,4,0.0,yes,9/28/20,Stanford University;The Voleon Group,deep learning theory,5;-1,2;-1,m;m,NAN,NAN,y,1;9
6015,ICLR,2021,Generalized Variational Continual Learning,Noel Loo;Siddharth Swaroop;Richard E Turner,~Noel_Loo1;~Siddharth_Swaroop2;~Richard_E_Turner1,7;4;8;7,4;5;5;4,Accept (Poster),0,17,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;University of Cambridge,,79;79;79,6;6;6,m;m,europe,uk,n,
6016,ICLR,2021,A Good Image Generator Is What You Need for High-Resolution Video Synthesis,Yu Tian;Jian Ren;Menglei Chai;Kyle Olszewski;Xi Peng;Dimitris N. Metaxas;Sergey Tulyakov,~Yu_Tian2;~Jian_Ren2;~Menglei_Chai1;~Kyle_Olszewski1;~Xi_Peng1;~Dimitris_N._Metaxas1;~Sergey_Tulyakov1,8;6;8;6,5;3;5;2,Accept (Spotlight),0,5,0.0,yes,9/28/20,Rutgers University;Snap Inc.;Snap Inc.;Snap Inc.;University of Delaware;Rutgers University;Snap Inc.,high-resolution video generation;contrastive learning;cross-domain video generation,29;-1;-1;-1;209;29;-1,-1;-1;-1;-1;312;-1;-1,u;m,NAN,NAN,n,
6017,ICLR,2021,Optimal Regularization can Mitigate Double Descent,Preetum Nakkiran;Prayaag Venkat;Sham M. Kakade;Tengyu Ma,~Preetum_Nakkiran1;pvenkat@g.harvard.edu;~Sham_M._Kakade1;~Tengyu_Ma1,7;7;7;6,3;4;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,Harvard University;;;University of Washington;Stanford University,double descent;generalization;regularization;regression;monotonicity,53;-1;-1;11;5,3;-1;-1;29;2,m;m,usa,usa,y,1
6018,ICLR,2021,Clustering-friendly Representation Learning via Instance Discrimination and Feature Decorrelation,Yaling Tao;Kentaro Takagi;Kouta Nakata,~Yaling_Tao1;kentaro1.takagi@toshiba.co.jp;kouta.nakata@toshiba.co.jp,6;7;7,3;5;4,Accept (Poster),0,5,0.0,yes,9/28/20,university of tsukuba;Kyoto University;The University of Tokyo,clustering;representation learning;deep embedding,110;174;71,499;54;36,f;m,NAN,NAN,n,
6019,ICLR,2021,Adaptive and Generative Zero-Shot Learning,Yu-Ying Chou;Hsuan-Tien Lin;Tyng-Luh Liu,~Yu-Ying_Chou1;~Hsuan-Tien_Lin1;~Tyng-Luh_Liu1,5;7;6;7;6,5;4;3;5;5,Accept (Poster),0,5,0.0,yes,9/28/20,National Taiwan University;National Taiwan University;IIS/Academia Sinica,Generalized zero-shot learning;mixup,99;99;-1,97;97;-1,m;m,NAN,NAN,n,6;8;5
6020,ICLR,2021,Stochastic Security: Adversarial Defense Using Long-Run Dynamics of Energy-Based Models,Mitch Hill;Jonathan Craig Mitchell;Song-Chun Zhu,~Mitch_Hill1;~Jonathan_Craig_Mitchell1;~Song-Chun_Zhu1,7;9;5;4,5;3;4;2,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Central Florida;University of California, Los Angeles;University of California-Los Angeles",adversarial defense;adversarial robustness;energy-based model;Markov chain Monte Carlo;Langevin sampling;adversarial attack,71;-1;-1,633;15;15,m;m,usa,usa,n,4
6021,ICLR,2021,HyperDynamics: Meta-Learning Object and Agent Dynamics with Hypernetworks,Zhou Xian;Shamit Lal;Hsiao-Yu Tung;Emmanouil Antonios Platanios;Katerina Fragkiadaki,~Zhou_Xian1;~Shamit_Lal1;~Hsiao-Yu_Tung1;~Emmanouil_Antonios_Platanios1;~Katerina_Fragkiadaki1,7;6;6;6,4;3;4;4,Accept (Poster),0,14,0.0,yes,9/28/20,"Carnegie Mellon University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University",,1;1;1;1;1,28;28;28;28;28,m;f,usa,usa,n,6
6022,ICLR,2021,Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth,Thao Nguyen;Maithra Raghu;Simon Kornblith,~Thao_Nguyen3;~Maithra_Raghu1;~Simon_Kornblith1,7;6;8;6,3;3;5;3,Accept (Poster),0,4,0.0,yes,9/28/20,Google;Google Brain;Google,Representation learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y,
6023,ICLR,2021,SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization,A F M Shahab Uddin;Mst. Sirazam Monira;Wheemyung Shin;TaeChoong Chung;Sung-Ho Bae,~A_F_M_Shahab_Uddin1;~Mst._Sirazam_Monira1;wheemi@khu.ac.kr;tcchung@khu.ac.kr;~Sung-Ho_Bae1,7;3;3;9;7,4;4;3;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,"KyungHee University;Islamic University, Bangladesh;;;;;Kyung Hee University",SaliencyMix;Saliency Guided Data Augmentation;Data Augmentation;Regularization,453;-1;-1;-1;-1;-1;453,265;-1;-1;-1;-1;-1;265,m;m,asia,kr,n,2;1;4
6024,ICLR,2021,Representation learning for improved interpretability and classification accuracy of clinical factors from EEG,Garrett Honke;Irina Higgins;Nina Thigpen;Vladimir Miskovic;Katie Link;Sunny Duan;Pramod Gupta;Julia Klawohn;Greg Hajcak,ghonk@google.com;~Irina_Higgins1;nthigpen@google.com;~Vladimir_Miskovic1;katielink@google.com;sunnyd@google.com;pramodg@google.com;julia.klawohn@hu-berlin.de;~Greg_Hajcak1,6;7;7,4;4;3,Accept (Poster),0,10,0.0,yes,9/28/20,State University of New York  Binghamton;DeepMind;;State University of New York at Binghamton;;;;;Florida State University College of Medicine,EEG;ERP;electroencephalography;depression;representation learning;disentanglement;beta-VAE,-1;-1;-1;-1;-1;-1;-1;-1;128,-1;-1;-1;-1;-1;-1;-1;-1;284,m;m,NAN,NAN,n,5
6025,ICLR,2021,Concept Learners for Few-Shot Learning,Kaidi Cao;Maria Brbic;Jure Leskovec,~Kaidi_Cao1;~Maria_Brbic1;~Jure_Leskovec1,6;7;5;6,3;4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,few-shot learning;meta learning,5;5;5,2;2;2,m;m,usa,usa,n,6;1
6026,ICLR,2021,Model-Based Visual Planning with Self-Supervised Functional Distances,Stephen Tian;Suraj Nair;Frederik Ebert;Sudeep Dasari;Benjamin Eysenbach;Chelsea Finn;Sergey Levine,~Stephen_Tian1;~Suraj_Nair1;~Frederik_Ebert1;~Sudeep_Dasari2;~Benjamin_Eysenbach1;~Chelsea_Finn1;~Sergey_Levine1,7;7;7;7,4;3;5;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,University of California Berkeley;Stanford University;University of California Berkeley;Carnegie Mellon University;Carnegie Mellon University;Stanford University;University of Washington,planning;model learning;distance learning;reinforcement learning;robotics,-1;5;-1;1;1;5;11,7;2;7;28;28;2;29,m;m,usa,usa,n,
6027,ICLR,2021,Improving Zero-Shot Voice Style Transfer via Disentangled Representation Learning,Siyang Yuan;Pengyu Cheng;Ruiyi Zhang;Weituo Hao;Zhe Gan;Lawrence Carin,~Siyang_Yuan1;~Pengyu_Cheng1;~Ruiyi_Zhang3;~Weituo_Hao1;~Zhe_Gan1;~Lawrence_Carin2,6;6;6;7,5;5;1;2,Accept (Poster),0,4,0.0,yes,9/28/20,Duke University;Duke University;Duke University;Duke University;Microsoft;Duke University,Style Transfer;Mutual Information;Zero-shot Learning;Disentanglement,46;46;46;46;-1;46,20;20;20;20;-1;20,f;m,europe,se,y,6
6028,ICLR,2021,Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering,Yuxuan Zhang;Wenzheng Chen;Huan Ling;Jun Gao;Yinan Zhang;Antonio Torralba;Sanja Fidler,~Yuxuan_Zhang1;~Wenzheng_Chen1;~Huan_Ling1;~Jun_Gao3;~Yinan_Zhang2;~Antonio_Torralba1;~Sanja_Fidler1,8;6;8,3;3;4,Accept (Oral),0,4,0.0,yes,9/28/20,"University of Waterloo;University of Toronto;Department of Computer Science, University of Toronto;NVIDIA;Stanford University;Massachusetts Institute of Technology;Department of Computer Science, University of Toronto",Differentiable rendering;inverse graphics;GANs,34;18;18;-1;5;5;18,232;18;18;-1;2;4;18,m;f,NAN,NAN,n,10;5;4
6029,ICLR,2021,BERTology Meets Biology: Interpreting Attention in Protein Language Models,Jesse Vig;Ali Madani;Lav R. Varshney;Caiming Xiong;richard socher;Nazneen Rajani,~Jesse_Vig1;madani@berkeley.edu;~Lav_R._Varshney1;~Caiming_Xiong1;~richard_socher1;~Nazneen_Rajani1,7;6;7;7;6,4;4;4;4;4,Accept (Poster),0,14,0.0,yes,9/28/20,"Salesforce Research;SalesForce.com;University of Illinois at Urbana-Champaign;Salesforce Research;SalesForce.com;University of Texas, Austin",interpretability;black box;computational biology;representation learning;attention;transformers;visualization;natural language processing,-1;-1;-1;-1;-1;-1,-1;-1;48;-1;-1;-1,m;f,usa,usa,n,8
6030,ICLR,2021,SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments,Glen Berseth;Daniel Geng;Coline Manon Devin;Nicholas Rhinehart;Chelsea Finn;Dinesh Jayaraman;Sergey Levine,~Glen_Berseth1;dangengdg@berkeley.edu;~Coline_Manon_Devin1;~Nicholas_Rhinehart1;~Chelsea_Finn1;~Dinesh_Jayaraman2;~Sergey_Levine1,7;7;7;8,4;4;4;4,Accept (Oral),0,15,0.0,yes,9/28/20,"University of California Berkeley;;;DeepMind;University of California Berkeley;Stanford University;School of Engineering and Applied Science, University of Pennsylvania;University of Washington",Reinforcement learning,-1;-1;-1;-1;-1;5;20;11,7;-1;-1;-1;7;2;13;29,m;m,usa,usa,n,
6031,ICLR,2021,Clairvoyance: A Pipeline Toolkit for Medical Time Series,Daniel Jarrett;Jinsung Yoon;Ioana Bica;Zhaozhi Qian;Ari Ercole;Mihaela van der Schaar,~Daniel_Jarrett1;~Jinsung_Yoon1;~Ioana_Bica1;~Zhaozhi_Qian1;ae105@cam.ac.uk;~Mihaela_van_der_Schaar2,8;4;6;5,5;4;4;2,Accept (Poster),0,20,0.0,yes,9/28/20,University of Cambridge;Google;University of Oxford;University of Cambridge;;;University of Cambridge,reproducibility;healthcare;medical time series;pipeline toolkit;software,79;-1;46;79;-1;-1;79,6;-1;1;6;-1;-1;6,m;f,europe,uk,n,
6032,ICLR,2021,AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights,Byeongho Heo;Sanghyuk Chun;Seong Joon Oh;Dongyoon Han;Sangdoo Yun;Gyuwan Kim;Youngjung Uh;Jung-Woo Ha,~Byeongho_Heo1;~Sanghyuk_Chun1;~Seong_Joon_Oh1;~Dongyoon_Han1;~Sangdoo_Yun1;~Gyuwan_Kim1;~Youngjung_Uh2;~Jung-Woo_Ha1,5;7;6;6,4;4;4;2,Accept (Poster),0,17,0.0,yes,9/28/20,"NAVER;NAVER;NAVER;NAVER Corp, CLOVA AI.;NAVER;Clova AI, NAVER Corp.;Yonsei University;Seoul National University",momentum optimizer;scale-invariant weights;normalize layer;effective learning rate,-1;-1;-1;-1;-1;-1;150;37,-1;-1;-1;-1;-1;-1;186;60,m;m,asia,kr,y,3;1
6033,ICLR,2021,Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers,Benjamin Eysenbach;Shreyas Chaudhari;Swapnil Asawa;Sergey Levine;Ruslan Salakhutdinov,~Benjamin_Eysenbach1;~Shreyas_Chaudhari1;~Swapnil_Asawa1;~Sergey_Levine1;~Ruslan_Salakhutdinov1,8;6;7;6,4;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;University of Pittsburgh;University of Washington;Carnegie-Mellon University,reinforcement learning;transfer learning;domain adaptation,1;1;79;11;1,28;28;133;29;28,m;m,usa,usa,n,1
6034,ICLR,2021,Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization,Tatsuya Matsushima;Hiroki Furuta;Yutaka Matsuo;Ofir Nachum;Shixiang Gu,~Tatsuya_Matsushima1;~Hiroki_Furuta1;~Yutaka_Matsuo1;~Ofir_Nachum1;~Shixiang_Gu1,8;7;5;7,4;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,The University of Tokyo;The University of Tokyo;The University of Tokyo;Google;Google,Reinforcement Learning;deployment-efficiency;offline RL;Model-based RL,71;71;71;-1;-1,36;36;36;-1;-1,m;m,NAN,NAN,n,
6035,ICLR,2021,Systematic generalisation with group invariant predictions,Faruk Ahmed;Yoshua Bengio;Harm van Seijen;Aaron Courville,~Faruk_Ahmed1;~Yoshua_Bengio1;~Harm_van_Seijen1;~Aaron_Courville3,8;8;6;6,3;4;3;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,University of Montreal;University of Montreal;Microsoft Research;University of Montreal,Systematic generalisation;invariance penalty;semantic anomaly detection,128;128;-1;128,73;73;-1;73,m;m,canada,ca,y,
6036,ICLR,2021,C-Learning: Learning to Achieve Goals via Recursive Classification,Benjamin Eysenbach;Ruslan Salakhutdinov;Sergey Levine,~Benjamin_Eysenbach1;~Ruslan_Salakhutdinov1;~Sergey_Levine1,6;7;8;7;4,2;5;3;3;4,Accept (Poster),0,9,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie-Mellon University;University of Washington,reinforcement learning;goal reaching;density estimation;Q-learning;hindsight relabeling,1;1;11,28;28;29,m;m,usa,usa,y,
6037,ICLR,2021,Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics,Yanchao Sun;Da Huo;Furong Huang,~Yanchao_Sun1;~Da_Huo1;~Furong_Huang1,6;6;7;6,3;4;5;3,Accept (Poster),0,20,0.0,yes,9/28/20,"University of Maryland, College Park;Shanghai Jiao Tong University;Department of Computer Science, University of Maryland",poisoning attack;policy gradient;vulnerability of RL;deep RL,12;29;-1,90;100;-1,f;f,NAN,NAN,y,4
6038,ICLR,2021,Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data,Jonathan Pilault;Amine El hattami;Christopher Pal,~Jonathan_Pilault1;~Amine_El_hattami1;~Christopher_Pal1,8;7;6;6;6,4;4;3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,Polytechnique Montreal;Polytechnique Montreal;Polytechnique Montreal,Multi-Task Learning;Adaptive Learning;Transfer Learning;Natural Language Processing,327;327;327,-1;-1;-1,m;m,canada,ca,n,8;3
6039,ICLR,2021,Robust and Generalizable Visual Representation Learning via Random Convolutions,Zhenlin Xu;Deyi Liu;Junlin Yang;Colin Raffel;Marc Niethammer,~Zhenlin_Xu1;~Deyi_Liu1;~Junlin_Yang1;~Colin_Raffel1;~Marc_Niethammer1,6;6;7;6,4;4;3;3,Accept (Poster),0,11,0.0,yes,9/28/20,"University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;Yale University;Hugging Face;University of North Carolina",domain generalization;robustness;representation learning;data augmentation,64;64;71;-1;64,-1;-1;8;-1;56,m;m,usa,usa,y,2;1
6040,ICLR,2021,Planning from Pixels using Inverse Dynamics Models,Keiran Paster;Sheila A. McIlraith;Jimmy Ba,~Keiran_Paster1;~Sheila_A._McIlraith1;~Jimmy_Ba1,6;6;6;6,4;3;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,"University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",model based reinforcement learning;deep reinforcement learning;multi-task learning;deep learning;goal-conditioned reinforcement learning,18;18;18,18;18;18,m;m,NAN,NAN,n,
6041,ICLR,2021,Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation,Emilio Parisotto;Russ Salakhutdinov,~Emilio_Parisotto1;~Russ_Salakhutdinov1,7;5;7;8,4;4;4;4,Accept (Poster),0,12,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Carnegie Mellon University",Deep Reinforcement Learning;Memory;Transformers;Distillation,1;1,28;28,m;m,usa,usa,n,8
6042,ICLR,2021,Isotropy in the Contextual Embedding Space: Clusters and Manifolds,Xingyu Cai;Jiaji Huang;Yuchen Bian;Kenneth Church,~Xingyu_Cai1;~Jiaji_Huang1;~Yuchen_Bian1;~Kenneth_Church1,7;7;7,3;4;4,Accept (Poster),0,12,0.0,yes,9/28/20,Baidu;Baidu;Pennsylvania State University;Baidu,Contextual embedding space;Isotropy;Clusters;Manifolds,-1;-1;44;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
6043,ICLR,2021,Neural Synthesis of Binaural Speech From Mono Audio,Alexander Richard;Dejan Markovic;Israel D. Gebru;Steven Krenn;Gladstone Alexander Butler;Fernando Torre;Yaser Sheikh,~Alexander_Richard1;~Dejan_Markovic1;~Israel_D._Gebru1;~Steven_Krenn1;~Gladstone_Alexander_Butler1;~Fernando_Torre1;~Yaser_Sheikh1,7;7;9,5;4;5,Accept (Oral),0,7,0.0,yes,9/28/20,"Facebook Reality Labs;Facebook;Facebook;Carnegie Mellon University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie-Mellon University",binaural audio;sound spatialization;neural sound synthesis;binaural speech;speech processing;speech generation,-1;-1;-1;1;1;1;1,-1;-1;-1;28;28;28;28,m;m,usa,usa,y,
6044,ICLR,2021,Influence Functions in Deep Learning Are Fragile,Samyadeep Basu;Phil Pope;Soheil Feizi,~Samyadeep_Basu1;~Phil_Pope1;~Soheil_Feizi2,6;7;6;6,5;3;3;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Microsoft;University of Maryland, College Park;University of Maryland, College Park",Influence Functions;Interpretability,-1;12;12,-1;90;90,m;m,usa,usa,n,
6045,ICLR,2021,Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network,James Diffenderfer;Bhavya Kailkhura,~James_Diffenderfer1;~Bhavya_Kailkhura1,6;7;4;7,3;3;4;3,Accept (Poster),0,18,0.0,yes,9/28/20,Lawrence Livermore National Labs;Lawrence Livermore National Laboratory,Binary Neural Networks;Pruning;Lottery Ticket Hypothesis,-1;-1,-1;-1,m;m,NAN,NAN,y,
6046,ICLR,2021,Understanding the effects of data parallelism and sparsity on neural network training,Namhoon Lee;Thalaiyasingam Ajanthan;Philip Torr;Martin Jaggi,~Namhoon_Lee1;~Thalaiyasingam_Ajanthan1;~Philip_Torr1;~Martin_Jaggi1,7;5;7,4;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,University of Oxford;Australian National University;University of Oxford;EPFL,data parallelism;sparsity;neural network training,46;99;46;23,1;59;1;-1,m;m,europe,ch,y,1
6047,ICLR,2021,Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes,Mike Gartrell;Insu Han;Elvis Dohmatob;Jennifer Gillenwater;Victor-Emmanuel Brunel,~Mike_Gartrell1;~Insu_Han1;~Elvis_Dohmatob1;~Jennifer_Gillenwater1;~Victor-Emmanuel_Brunel1,7;8;9,4;4;5,Accept (Oral),0,6,0.0,yes,9/28/20,Criteo AI Lab;Korea Advanced Institute of Science and Technology;Facebook;Google;Ensae ParisTech,determinantal point processes;unsupervised learning;representation learning;submodular optimization,-1;-1;-1;-1;-1,-1;96;-1;-1;-1,m;m,NAN,NAN,y,8
6048,ICLR,2021,Mixed-Features Vectors and Subspace Splitting,Alejandro Pimentel-Alarc√≥n;Daniel L. Pimentel-Alarc√≥n,~Alejandro_Pimentel-Alarc√≥n2;~Daniel_L._Pimentel-Alarc√≥n1,6;6;6,3;4;3,Accept (Poster),0,4,0.0,yes,9/28/20,"UNAM;University of Wisconsin, Madison",,92;18,-1;49,m;m,usa,usa,y,1
6049,ICLR,2021,"Cut out the annotator, keep the cutout: better segmentation with weak supervision",Sarah Hooper;Michael Wornow;Ying Hang Seah;Peter Kellman;Hui Xue;Frederic Sala;Curtis Langlotz;Christopher Re,~Sarah_Hooper1;mwornow@stanford.edu;yinghang@stanford.edu;kellmanp@nhlbi.nih.gov;hui.xue@nih.gov;~Frederic_Sala1;~Curtis_Langlotz1;~Christopher_Re1,5;6;4;6;7,4;2;3;4;4,Accept (Poster),0,13,0.0,yes,9/28/20,"Stanford University;Stanford University;;;;;;;University of Wisconsin, Madison;;Stanford University;University of Wisconsin-Madison",Weak supervision;segmentation;CNN;latent variable;medical imaging,5;5;-1;-1;-1;-1;-1;-1;18;-1;5;18,2;2;-1;-1;-1;-1;-1;-1;49;-1;2;49,f;m,usa,usa,n,6;2
6050,ICLR,2021,Conditional Negative Sampling for Contrastive Learning of Visual Representations,Mike Wu;Milan Mosse;Chengxu Zhuang;Daniel Yamins;Noah Goodman,~Mike_Wu1;mmosse19@stanford.edu;~Chengxu_Zhuang1;~Daniel_Yamins1;~Noah_Goodman1,6;5;5;7,4;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,Stanford University;;;Stanford University;Stanford University;Stanford University,contrastive learning;hard negative mining;mutual information;lower bound;detection;segmentation;MoCo,5;-1;-1;5;5;5,2;-1;-1;2;2;2,m;m,usa,usa,y,2;1
6051,ICLR,2021,BREEDS: Benchmarks for Subpopulation Shift,Shibani Santurkar;Dimitris Tsipras;Aleksander Madry,~Shibani_Santurkar1;~Dimitris_Tsipras1;~Aleksander_Madry1,6;6;7,3;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,benchmarks;distribution shift;hierarchy;robustness,5;5;5,4;4;4,f;m,usa,usa,n,
6052,ICLR,2021,Lifelong Learning of Compositional Structures,Jorge A Mendez;ERIC EATON,~Jorge_A_Mendez1;~ERIC_EATON1,7;6;6;6;9,3;4;3;3;4,Accept (Poster),0,14,0.0,yes,9/28/20,University of Pennsylvania;University of Pennsylvania,lifelong learning;continual learning;compositional learning;modular networks,20;20,13;13,m;m,usa,usa,n,
6053,ICLR,2021,Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks,Ingmar Schubert;Ozgur S Oguz;Marc Toussaint,~Ingmar_Schubert1;~Ozgur_S_Oguz1;~Marc_Toussaint1,7;6;7;3,4;3;4;4,Accept (Poster),0,16,0.0,yes,9/28/20,Technische Universit√§t Berlin / Learning and Intelligent Systems Group;Max-Planck Institute;;TU Berlin,reinforcement learning;reward shaping;plan-based reward shaping;robotics;robotic manipulation,-1;-1;-1;128,-1;-1;-1;-1,m;m,europe,de,y,
6054,ICLR,2021,Integrating Categorical Semantics into Unsupervised Domain Translation,Samuel Lavoie-Marchildon;Faruk Ahmed;Aaron Courville,~Samuel_Lavoie-Marchildon1;~Faruk_Ahmed1;~Aaron_Courville3,7;4;7;7,2;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,University of Montreal;University of Montreal;University of Montreal,Unsupervised Domain Translation;Unsupervised Learning;Image-to-Image Translation;Deep Learning;Representation Learning,128;128;128,73;73;73,m;m,canada,ca,n,
6055,ICLR,2021,Fast convergence of stochastic subgradient method under interpolation,Huang Fang;Zhenan Fan;Michael Friedlander,~Huang_Fang1;zhenanf@cs.ubc.ca;mpf@cs.ubc.ca,7;6;8;7,4;4;5;4,Accept (Poster),0,11,0.0,yes,9/28/20,University of British Columbia;University of British Columbia;University of British Columbia,Optimization;stochastic subgradient method;interpolation;convergence analysis,58;58;58,34;34;34,m;m,canada,ca,y,1
6056,ICLR,2021,Multi-Level Local SGD: Distributed SGD for Heterogeneous Hierarchical Networks,Timothy Castiglia;Anirban Das;Stacy Patterson,~Timothy_Castiglia1;dasa2@rpi.edu;~Stacy_Patterson1,7;6;6;6,5;4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute,Machine Learning;Stochastic Gradient Descent;Federated Learning;Hierarchical Networks;Distributed;Heterogeneous;Convergence Analysis,263;263;263,527;527;527,m;f,usa,usa,y,
6057,ICLR,2021,DiffWave: A Versatile Diffusion Model for Audio Synthesis,Zhifeng Kong;Wei Ping;Jiaji Huang;Kexin Zhao;Bryan Catanzaro,z4kong@eng.ucsd.edu;~Wei_Ping1;~Jiaji_Huang1;kexinzhao@baidu.com;~Bryan_Catanzaro1,7;9;8;7;7,5;4;3;5;3,Accept (Oral),0,5,0.0,yes,9/28/20,"University of California, San Diego;NVIDIA;Baidu;;;University of California Berkeley",diffusion probabilistic models;audio synthesis;speech synthesis;generative models,-1;-1;-1;-1;-1;-1,33;-1;-1;-1;-1;7,m;m,usa,usa,n,1;5
6058,ICLR,2021,Learning Task Decomposition with Ordered Memory Policy Network,Yuchen Lu;Yikang Shen;Siyuan Zhou;Aaron Courville;Joshua B. Tenenbaum;Chuang Gan,~Yuchen_Lu1;~Yikang_Shen1;~Siyuan_Zhou2;~Aaron_Courville3;~Joshua_B._Tenenbaum1;~Chuang_Gan1,6;6;6;4,4;3;4;2,Accept (Poster),0,21,0.0,yes,9/28/20,University of Montreal;University of Montreal;Peking University;University of Montreal;Massachusetts Institute of Technology;MIT-IBM Watson AI Lab,Task Segmentation;Hierarchical Imitation Learning;Network Inductive Bias,128;128;14;128;5;-1,73;73;23;73;4;-1,m;m,NAN,NAN,n,1
6059,ICLR,2021,Long Range Arena : A Benchmark for Efficient Transformers ,Yi Tay;Mostafa Dehghani;Samira Abnar;Yikang Shen;Dara Bahri;Philip Pham;Jinfeng Rao;Liu Yang;Sebastian Ruder;Donald Metzler,~Yi_Tay1;~Mostafa_Dehghani1;~Samira_Abnar1;~Yikang_Shen1;~Dara_Bahri1;~Philip_Pham1;~Jinfeng_Rao2;yangliuy@google.com;~Sebastian_Ruder2;metzler@google.com,7;7;7;6,4;4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,"Google;Google Brain;University of Amsterdam;University of Montreal;Google Research;Waymo;University of Maryland, College Park;University of Massachusetts, Amherst;Google;Google",Transformers;Attention;Deep Learning,-1;-1;128;128;-1;-1;12;23;-1;-1,-1;-1;66;73;-1;-1;90;210;-1;-1,m;m,NAN,NAN,n,8
6060,ICLR,2021,Diverse Video Generation using a Gaussian Process Trigger,Gaurav Shrivastava;Abhinav Shrivastava,~Gaurav_Shrivastava1;~Abhinav_Shrivastava2,6;6;6,3;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park",video synthesis;future frame generation;video generation;gaussian process priors;diverse video generation,-1;-1,90;90,m;m,NAN,NAN,n,
6061,ICLR,2021,DINO: A Conditional Energy-Based GAN for Domain Translation,Konstantinos Vougioukas;Stavros Petridis;Maja Pantic,~Konstantinos_Vougioukas1;~Stavros_Petridis1;~Maja_Pantic1,7;7;7,2;2;3,Accept (Poster),0,9,0.0,yes,9/28/20,Imperial College London;Imperial College London;Imperial College London,Generative Modelling;Domain Translation;Conditional GANs;Energy-Based GANs,53;53;53,11;11;11,m;f,europe,uk,n,5;4
6062,ICLR,2021,Deep Equals Shallow for ReLU Networks in Kernel Regimes,Alberto Bietti;Francis Bach,~Alberto_Bietti1;~Francis_Bach1,6;7;6;9,4;5;3;5,Accept (Poster),0,5,0.0,yes,9/28/20,New York University;Ecole Normale Superieure,deep learning;kernels;approximation;neural tangent kernels,23;128,26;-1,m;m,europe,fr,y,
6063,ICLR,2021,Structured Prediction as Translation between Augmented Natural Languages,Giovanni Paolini;Ben Athiwaratkun;Jason Krone;Jie Ma;Alessandro Achille;RISHITA ANUBHAI;Cicero Nogueira dos Santos;Bing Xiang;Stefano Soatto,~Giovanni_Paolini1;~Ben_Athiwaratkun1;kronej@amazon.com;~Jie_Ma3;~Alessandro_Achille1;~RISHITA_ANUBHAI2;~Cicero_Nogueira_dos_Santos1;~Bing_Xiang2;~Stefano_Soatto1,7;6;8;6,4;4;4;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,Amazon;Amazon;Amazon;Cornell University;California Institute of Technology;Stanford University;Amazon Web Services;Amazon;UCLA,language models;few-shot learning;transfer learning;structured prediction;generative modeling;sequence to sequence;multi-task learning,-1;-1;-1;7;150;5;-1;-1;327,-1;-1;-1;19;4;2;-1;-1;16,m;m,asia,in,n,3
6064,ICLR,2021,Disentangled Recurrent Wasserstein Autoencoder ,Jun Han;Martin Renqiang Min;Ligong Han;Li Erran Li;Xuan Zhang,~Jun_Han4;~Martin_Renqiang_Min1;~Ligong_Han1;~Li_Erran_Li1;~Xuan_Zhang3,7;7;7,4;4;3,Accept (Spotlight),0,4,0.0,yes,9/28/20,"PCG, Tencent;NEC Laboratories America;Rutgers University;Amazon;Texas A&M",Sequential  Representation Learning;Disentanglement;Recurrent Generative Model,-1;-1;29;-1;46,-1;-1;-1;-1;195,u;u,NAN,NAN,y,1;5
6065,ICLR,2021,Robust Pruning at Initialization,Soufiane Hayou;Jean-Francois Ton;Arnaud Doucet;Yee Whye Teh,~Soufiane_Hayou1;~Jean-Francois_Ton1;~Arnaud_Doucet2;~Yee_Whye_Teh1,6;6;7,3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Oxford;;Google DeepMind;University of Oxford and DeepMind,Pruning;Initialization;Compression,46;-1;-1;46,1;-1;-1;1,m;m,NAN,NAN,y,
6066,ICLR,2021,Learning from Demonstration with Weakly Supervised Disentanglement,Yordan Hristov;Subramanian Ramamoorthy,~Yordan_Hristov1;~Subramanian_Ramamoorthy1,5;7;7,4;4;3,Accept (Poster),0,3,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh,representation learning for robotics;physical symbol grounding;semi-supervised learning,29;29,30;30,m;m,europe,uk,n,5
6067,ICLR,2021,Average-case Acceleration for Bilinear Games and Normal Matrices,Carles Domingo-Enrich;Fabian Pedregosa;Damien Scieur,~Carles_Domingo-Enrich1;~Fabian_Pedregosa1;~Damien_Scieur3,7;7;6,2;4;3,Accept (Poster),0,3,0.0,yes,9/28/20,"New York University;Google;Department of Computer Science, Princeton University",Smooth games;First-order Methods;Acceleration;Bilinear games;Average-case Analysis;Orthogonal Polynomials,23;-1;29,26;-1;9,m;m,NAN,NAN,y,1;5;4
6068,ICLR,2021,NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation,Angtian Wang;Adam Kortylewski;Alan Yuille,~Angtian_Wang2;~Adam_Kortylewski1;~Alan_Yuille1,7;6;7;6,4;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,Pose Estimation;Robust Deep Learning;Contrastive Learning;Render-and-Compare,71;71;71,12;12;12,m;m,usa,usa,n,2;5
6069,ICLR,2021,Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images,Rewon Child,~Rewon_Child1,8;7;8;7,5;4;4;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,OpenAI,VAE;generative modeling;deep learning;likelihood-based models,-1,-1,m,NAN,NAN,y,1;5
6070,ICLR,2021,EigenGame: PCA as a Nash Equilibrium,Ian Gemp;Brian McWilliams;Claire Vernade;Thore Graepel,~Ian_Gemp1;~Brian_McWilliams2;~Claire_Vernade1;~Thore_Graepel1,8;7;8,3;3;3,Accept (Oral),0,7,0.0,yes,9/28/20,DeepMind;Deepmind;Google;;University College London,pca;principal components analysis;nash;games;eigendecomposition;svd;singular value decomposition,-1;-1;-1;-1;53,-1;-1;-1;-1;-1,m;m,europe,uk,n,
6071,ICLR,2021,Nonseparable Symplectic Neural Networks,Shiying Xiong;Yunjin Tong;Xingzhe He;Shuqi Yang;Cheng Yang;Bo Zhu,~Shiying_Xiong1;yunjin.tong.22@dartmouth.edu;~Xingzhe_He1;~Shuqi_Yang2;yangcheng.iron@bytedance.com;~Bo_Zhu2,6;6;6;7,3;3;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Dartmouth College;Dartmouth College;University of British Columbia;Dartmouth College;Shanghai Jiao Tong University;Dartmouth College,Data-driven modeling;nonseparable Hailtonian system;symplectic networks,174;174;58;174;29;174,100;100;34;100;100;100,m;m,usa,usa,n,8;1
6072,ICLR,2021,HalentNet: Multimodal Trajectory Forecasting with Hallucinative Intents,Deyao Zhu;Mohamed Zahran;Li Erran Li;Mohamed Elhoseiny,~Deyao_Zhu1;~Mohamed_Zahran1;~Li_Erran_Li1;~Mohamed_Elhoseiny1,6;5;8;6,4;5;3;3,Accept (Poster),0,9,0.0,yes,9/28/20,KAUST;Udacity;Amazon;KAUST,,110;-1;-1;110,-1;-1;-1;-1,m;m,europe,gr,n,5
6073,ICLR,2021,Relating by Contrasting: A Data-efficient Framework for Multimodal Generative Models,Yuge Shi;Brooks Paige;Philip Torr;Siddharth N,~Yuge_Shi1;~Brooks_Paige1;~Philip_Torr1;~Siddharth_N1,6;5;6;7,4;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,University of Oxford;University College London;University of Oxford;University of Edinburgh,Deep generative model;multi-modal learning;representation learning,46;53;46;29,1;-1;1;30,f;m,europe,uk,n,5
6074,ICLR,2021,CT-Net: Channel Tensorization Network for Video Classification,Kunchang Li;Xianhang Li;Yali Wang;Jun Wang;Yu Qiao,~Kunchang_Li1;~Xianhang_Li1;~Yali_Wang1;~Jun_Wang7;~Yu_Qiao1,7;7;5;5,3;4;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;University of Central Florida;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;University of Central Florida;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",Video Classification;3D Convolution;Channel Tensorization,34;71;34;71;34,-1;633;-1;633;-1,m;m,NAN,NAN,n,8
6075,ICLR,2021,IsarStep: a Benchmark for High-level Mathematical Reasoning,Wenda Li;Lei Yu;Yuhuai Wu;Lawrence C. Paulson,~Wenda_Li1;~Lei_Yu4;~Yuhuai_Wu1;lp15@cam.ac.uk,6;7;6;9,4;5;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,University of Cambridge;DeepMind;Department of Computer Science  University of Toronto;University of Cambridge,mathematical reasoning;dataset;benchmark;reasoning;transformer,79;-1;18;79,6;-1;18;6,m;m,europe,uk,n,8;1
6076,ICLR,2021,DARTS-: Robustly Stepping out of Performance Collapse Without Indicators,Xiangxiang Chu;Xiaoxing Wang;Bo Zhang;Shun Lu;Xiaolin Wei;Junchi Yan,~Xiangxiang_Chu1;figure1_wxx@sjtu.edu.cn;~Bo_Zhang7;~Shun_Lu1;weixiaolin02@meituan.com;~Junchi_Yan2,6;8;6;6,5;5;3;2,Accept (Poster),0,6,0.0,yes,9/28/20,MeiTuan;Shanghai Jiao Tong University;Meituan Inc.;Chinese Academy of Sciences;;;Shanghai Jiao Tong University,neural architecture search;DARTS stability,-1;29;-1;34;-1;-1;29,-1;100;-1;-1;-1;-1;100,m;m,asia,cn,n,
6077,ICLR,2021,Learning a Latent Search Space for Routing Problems using Variational Autoencoders,Andr√© Hottung;Bhanu Bhandari;Kevin Tierney,~Andr√©_Hottung1;bhanubhandar@cs.umass.edu;~Kevin_Tierney1,7;6;7;5,4;3;2;4,Accept (Poster),0,9,0.0,yes,9/28/20,"Bielefeld University;Department of Computer Science, University of Massachusetts, Amherst;Bielefeld University",heuristic search;variational autoencoders;learning to optimize;routing problems;traveling salesperson problem;vehicle routing problem;combinatorial optimization,327;-1;327,158;210;158,m;m,europe,de,n,5
6078,ICLR,2021,DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs,Aayam Kumar Shrestha;Stefan Lee;Prasad Tadepalli;Alan Fern,~Aayam_Kumar_Shrestha1;~Stefan_Lee1;~Prasad_Tadepalli1;~Alan_Fern1,6;7;7;7;7,4;3;3;4;3,Accept (Spotlight),0,9,0.0,yes,9/28/20,Oregon State University;Oregon State University;Oregon State University;Oregon State University,Offline Reinforcement Learning;Planning,79;79;79;79,424;424;424;424,m;m,usa,usa,y,6;1
6079,ICLR,2021,DDPNOpt: Differential Dynamic Programming Neural Optimizer,Guan-Horng Liu;Tianrong Chen;Evangelos Theodorou,~Guan-Horng_Liu1;~Tianrong_Chen1;~Evangelos_Theodorou1,7;7;7;8,3;3;4;2,Accept (Spotlight),0,10,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,deep learning training;optimal control;trajectory optimization;differential dynamica programming,12;12;12,38;38;38,m;m,usa,usa,y,8;1
6080,ICLR,2021,Generalized Energy Based Models,Michael Arbel;Liang Zhou;Arthur Gretton,~Michael_Arbel1;liang.zhou.18@ucl.ac.uk;~Arthur_Gretton1,6;5;6,3;3;4,Accept (Poster),0,16,0.0,yes,9/28/20,University College London;University College London;University College London,Sampling;MCMC;Generative Models;Adversarial training;Optimization;Density estimation,53;53;53,-1;-1;-1,m;m,europe,uk,y,5
6081,ICLR,2021,Learning What To Do by Simulating the Past,David Lindner;Rohin Shah;Pieter Abbeel;Anca Dragan,~David_Lindner1;~Rohin_Shah1;~Pieter_Abbeel2;~Anca_Dragan1,5;7;7;5,4;2;4;2,Accept (Poster),0,6,0.0,yes,9/28/20,ETH Zurich;DeepMind;Covariant;University of California-Berkeley,imitation learning;reward learning;reinforcement learning,9;-1;-1;-1,14;-1;-1;7,m;f,usa,usa,n,
6082,ICLR,2021,On Graph Neural Networks versus Graph-Augmented MLPs,Lei Chen;Zhengdao Chen;Joan Bruna,~Lei_Chen4;~Zhengdao_Chen1;~Joan_Bruna1,7;8;7;5,3;3;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,New York University;New York University;New York University,Graph Neural Networks;expressive power;feature propagation;rooted graphs;attributed walks;community detection;depth separation,23;23;23,26;26;26,m;m,usa,usa,y,1;10
6083,ICLR,2021,A Block Minifloat Representation for Training Deep Neural Networks,Sean Fox;Seyedramin Rasoulinezhad;Julian Faraone;david boland;Philip Leong,~Sean_Fox2;seyedramin.rasoulinezhad@sydney.edu.au;~Julian_Faraone1;david.boland@sydney.edu.au;~Philip_Leong1,7;7;6,3;5;4,Accept (Poster),0,3,0.0,yes,9/28/20,University of Sydney;University of Sydney;University of Sydney;;;;University of Sydney,,71;71;71;-1;-1;-1;71,51;51;51;-1;-1;-1;51,m;m,europe,uk,n,
6084,ICLR,2021,Deconstructing the Regularization of BatchNorm,Yann Dauphin;Ekin Dogus Cubuk,~Yann_Dauphin1;~Ekin_Dogus_Cubuk1,6;4;7,3;4;5,Accept (Poster),0,10,0.0,yes,9/28/20,Google;Google,deep learning;batch normalization;regularization;understanding neural networks,-1;-1,-1;-1,m;m,NAN,NAN,n,1
6085,ICLR,2021,SkipW: Resource Adaptable RNN with Strict Upper Computational Limit,Tsiry Mayet;Anne Lambert;Pascal Leguyadec;Francoise Le Bolzer;Fran√ßois Schnitzler,mayet.tsiry@gmail.com;anne.lambert@interdigital.com;pascal.leguyadec@interdigital.com;francoise.lebolzer@interdigital.com;~Fran√ßois_Schnitzler1,5;6;6;6,5;3;5;2,Accept (Poster),0,15,0.0,yes,9/28/20,InterDigital;InterDigital;;;InterDigital,Recurrent neural networks;Flexibility;Computational resources,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
6086,ICLR,2021,Influence Estimation for Generative Adversarial Networks,Naoyuki Terashita;Hiroki Ohashi;Yuichi Nonaka;Takashi Kanemaru,~Naoyuki_Terashita1;~Hiroki_Ohashi1;yuichi.nonaka.zy@hitachi.com;takashi.kanemaru.kf@hitachi.com,7;7;6,3;3;3,Accept (Spotlight),0,8,0.0,yes,9/28/20,Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;;Hitachi Ltd. R&D group,influence;generative adversarial networks;data cleansing,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
6087,ICLR,2021,Learning advanced mathematical computations from examples,Francois Charton;Amaury Hayat;Guillaume Lample,~Francois_Charton1;amaury.hayat@enpc.fr;~Guillaume_Lample1,7;6;3;8,4;3;4;4,Accept (Poster),0,17,0.0,yes,9/28/20,Facebook;ENPC;Facebook,differential equations;computation;transformers;deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,8;1
6088,ICLR,2021,Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks,Shikuang Deng;Shi Gu,~Shikuang_Deng1;~Shi_Gu1,5;7;7,3;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,"University of Electronic Science and Technology of China;University of Electronic Science and Technology of China, Tsinghua University",spiking neural network;weight balance;second-order approximation,-1;4,553;20,m;m,NAN,NAN,n,
6089,ICLR,2021,Efficient Wasserstein Natural Gradients for Reinforcement Learning,Ted Moskovitz;Michael Arbel;Ferenc Huszar;Arthur Gretton,~Ted_Moskovitz1;~Michael_Arbel1;~Ferenc_Huszar1;~Arthur_Gretton1,6;8;5,4;4;2,Accept (Poster),0,11,0.0,yes,9/28/20,Gatsby Computational Neuroscience Unit;University College London;University of Cambridge;University College London,reinforcement learning;optimization,-1;53;79;53,-1;-1;6;-1,m;m,europe,uk,y,
6090,ICLR,2021,"Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation",Jungo Kasai;Nikolaos Pappas;Hao Peng;James Cross;Noah Smith,~Jungo_Kasai1;~Nikolaos_Pappas1;~Hao_Peng4;~James_Cross3;~Noah_Smith1,7;5;7;9,3;4;3;5,Accept (Poster),0,8,0.0,yes,9/28/20,"Paul G. Allen School of Computer Science & Engineering, University of Washington;Department of Computer Science, University of Washington;Department of Computer Science, University of Washington;Facebook;University of Washington",Machine Translation;Sequence Modeling;Natural Language Processing,11;11;11;-1;11,29;29;29;-1;29,m;m,usa,usa,n,3
6091,ICLR,2021,Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation,Hao Li;Chenxin Tao;Xizhou Zhu;Xiaogang Wang;Gao Huang;Jifeng Dai,haoli@link.cuhk.edu.hk;~Chenxin_Tao2;~Xizhou_Zhu1;~Xiaogang_Wang2;~Gao_Huang1;~Jifeng_Dai1,7;5;5;7,4;3;3;3,Accept (Poster),0,9,0.0,yes,9/28/20,"The Chinese University of Hong Kong;Tsinghua University, Tsinghua University;SenseTime;Chinese University of Hong Kong;Tsinghua University, Tsinghua University;SenseTime Group Ltd",Loss Function Search;Metric Surrogate;Semantic Segmentation,327;4;-1;46;4;-1,39;20;-1;56;20;-1,m;m,NAN,NAN,n,2
6092,ICLR,2021,Predicting Infectiousness for Proactive Contact Tracing,Yoshua Bengio;Prateek Gupta;Tegan Maharaj;Nasim Rahaman;Martin Weiss;Tristan Deleu;Eilif Benjamin Muller;Meng Qu;victor schmidt;Pierre-luc St-charles;hannah alsdurf;Olexa Bilaniuk;david buckeridge;gaetan caron;pierre luc carrier;Joumana Ghosn;satya ortiz gagne;Christopher Pal;Irina Rish;Bernhard Sch√∂lkopf;abhinav sharma;Jian Tang;andrew williams,~Yoshua_Bengio1;~Prateek_Gupta2;~Tegan_Maharaj1;~Nasim_Rahaman1;~Martin_Weiss4;~Tristan_Deleu1;~Eilif_Benjamin_Muller1;~Meng_Qu2;victor.schmidt@mila.quebec;~Pierre-luc_St-charles1;halsdurf@uottawa.ca;~Olexa_Bilaniuk1;david.buckeridge@mcgill.ca;gaetan.marceau.caron@mila.quebec;pierre.luc.carrier@mila.quebec;~Joumana_Ghosn1;satya.ortiz-gagne@mila.quebec;~Christopher_Pal1;~Irina_Rish1;~Bernhard_Sch√∂lkopf1;abhinav.sharma@mcgill.ca;~Jian_Tang1;andrew.williams@umontreal.ca,7;7;9,4;2;3,Accept (Spotlight),0,1,0.0,yes,9/28/20,"University of Montreal;University of Oxford;Ecole Polytechnique de Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Montreal;Element AI;University of Montreal;;;;√âcole Polytechnique de Montr√©al, Universit√© de Montr√©al;;;University of Montreal;;;;;;;Mila;;;Polytechnique Montreal;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute;;;HEC Montreal;University of Montreal",covid-19;contact tracing;distributed inference;set transformer;deepset;epidemiology;applications;domain randomization;retraining;simulation,128;46;-1;-1;128;128;-1;128;-1;-1;-1;-1;-1;-1;128;-1;-1;-1;-1;-1;-1;150;-1;-1;327;128;-1;-1;-1;-1;128,73;1;-1;-1;73;73;-1;73;-1;-1;-1;89;-1;-1;73;-1;-1;-1;-1;-1;-1;370;-1;-1;-1;73;-1;-1;-1;-1;73,m;m,canada,ca,n,
6093,ICLR,2021,Efficient Inference of Flexible Interaction in Spiking-neuron Networks,Feng Zhou;Yixuan Zhang;Jun Zhu,~Feng_Zhou9;yixuan.zhang@uts.edu.au;~Jun_Zhu2,6;7;6;6,3;4;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,Tsinghua University;;;Tsinghua University,neural spike train;nonlinear Hawkes process;auxiliary latent variable;conjugacy,4;-1;-1;4,20;-1;-1;20,m;m,asia,cn,n,
6094,ICLR,2021,Graph Information Bottleneck for Subgraph Recognition,Junchi Yu;Tingyang Xu;Yu Rong;Yatao Bian;Junzhou Huang;Ran He,~Junchi_Yu1;~Tingyang_Xu1;~Yu_Rong1;~Yatao_Bian1;~Junzhou_Huang2;~Ran_He1,7;3;8;2,3;4;2;2,Accept (Poster),0,7,0.0,yes,9/28/20,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;University of Texas, Arlington;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",,34;-1;-1;-1;-1;34,-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,10
6095,ICLR,2021,Spatially Structured Recurrent Modules,Nasim Rahaman;Anirudh Goyal;Muhammad Waleed Gondal;Manuel Wuthrich;Stefan Bauer;Yash Sharma;Yoshua Bengio;Bernhard Sch√∂lkopf,~Nasim_Rahaman1;~Anirudh_Goyal1;~Muhammad_Waleed_Gondal1;~Manuel_Wuthrich1;~Stefan_Bauer1;~Yash_Sharma1;~Yoshua_Bengio1;~Bernhard_Sch√∂lkopf1,7;6;7;6,4;4;4;3,Accept (Poster),0,15,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems;Swiss Federal Institute of Technology;Centre for Integrative Neuroscience, AG Bethge;University of Montreal;Max Planck Institute for Intelligent Systems, Max-Planck Institute",spatio-temporal modelling;modular architectures;recurrent neural networks;partially observed environments,-1;128;-1;-1;-1;-1;128;-1,-1;73;-1;-1;-1;-1;73;-1,m;m,NAN,NAN,n,
6096,ICLR,2021,Private Post-GAN Boosting,Marcel Neunhoeffer;Steven Wu;Cynthia Dwork,~Marcel_Neunhoeffer1;~Steven_Wu1;~Cynthia_Dwork2,6;7;8,2;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,University of Mannheim;Carnegie Mellon University;Harvard University,,263;1;53,140;28;3,m;f,usa,usa,y,5
6097,ICLR,2021,Learning Associative Inference Using Fast Weight Memory,Imanol Schlag;Tsendsuren Munkhdalai;J√ºrgen Schmidhuber,~Imanol_Schlag3;~Tsendsuren_Munkhdalai1;~J√ºrgen_Schmidhuber1,7;7;6;7,4;3;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,IDSIA;Google;IDSIA,memory-augmented neural networks;tensor product;fast weights,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,3
6098,ICLR,2021,Neural networks with late-phase weights,Johannes Von Oswald;Seijin Kobayashi;Joao Sacramento;Alexander Meulemans;Christian Henning;Benjamin F Grewe,~Johannes_Von_Oswald1;seijink@ethz.ch;~Joao_Sacramento1;~Alexander_Meulemans1;~Christian_Henning1;~Benjamin_F_Grewe1,6;6;7;7,4;2;4;4,Accept (Poster),0,15,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Insititute of Neuroinformatics, University of Zurich and ETH Zurich, Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology",,-1;-1;9;-1;-1;-1,-1;-1;14;-1;-1;-1,m;m,NAN,NAN,n,1
6099,ICLR,2021,"Physics-aware, probabilistic model order reduction with guaranteed stability",Sebastian Kaltenbach;Phaedon Stelios Koutsourelakis,~Sebastian_Kaltenbach1;~Phaedon_Stelios_Koutsourelakis1,6;7;7;6;7,3;4;4;5;3,Accept (Poster),0,7,0.0,yes,9/28/20,Technical University Munich;Princeton University,inductive bias;probabilistic generative models;state-space models;model order reduction;slowness;long-term stability,-1;29,-1;9,m;m,usa,usa,n,5
6100,ICLR,2021,Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors,Linfeng Zhang;Kaisheng Ma,~Linfeng_Zhang2;~Kaisheng_Ma1,6;6;7,4;4;5,Accept (Poster),0,3,0.0,yes,9/28/20,", Tsinghua University;Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University",Knowledge Distillation;Object Detection;Teacher-Student Learning;Non-Local Modules;Attention Modules,4;4,20;20,m;m,NAN,NAN,n,8;2
6101,ICLR,2021,AdaGCN: Adaboosting Graph Convolutional Networks into Deep Models,Ke Sun;Zhanxing Zhu;Zhouchen Lin,~Ke_Sun3;~Zhanxing_Zhu1;~Zhouchen_Lin1,5;6;7;7,4;5;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,University of Alberta;Peking University;Peking University,Graph Neural Networks;AdaBoost,110;14;14,131;23;23,m;m,asia,cn,y,10
6102,ICLR,2021,Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation,Justin Fu;Sergey Levine,~Justin_Fu1;~Sergey_Levine1,8;6;6,4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,University of California Berkeley;University of Washington,model-based optimization;normalized maximum likelihood,-1;11,7;29,m;m,usa,usa,y,4
6103,ICLR,2021,Combining Ensembles and Data Augmentation Can Harm Your Calibration,Yeming Wen;Ghassen Jerfel;Rafael Muller;Michael W Dusenberry;Jasper Snoek;Balaji Lakshminarayanan;Dustin Tran,~Yeming_Wen1;~Ghassen_Jerfel1;~Rafael_Muller1;~Michael_W_Dusenberry1;~Jasper_Snoek1;~Balaji_Lakshminarayanan1;~Dustin_Tran1,4;7;7;8,4;4;5;4,Accept (Poster),0,10,0.0,yes,9/28/20,"University of Texas, Austin;Duke University;Telecom SudParis;Google;Google;Google Brain;Columbia University",Ensembles;Uncertainty estimates;Calibration,-1;46;-1;-1;-1;-1;23,-1;20;551;-1;-1;-1;17,m;m,usa,usa,n,
6104,ICLR,2021,GraphCodeBERT: Pre-training Code Representations with Data Flow,Daya Guo;Shuo Ren;Shuai Lu;Zhangyin Feng;Duyu Tang;Shujie LIU;Long Zhou;Nan Duan;Alexey Svyatkovskiy;Shengyu Fu;Michele Tufano;Shao Kun Deng;Colin Clement;Dawn Drain;Neel Sundaresan;Jian Yin;Daxin Jiang;Ming Zhou,~Daya_Guo2;shuoren@buaa.edu.cn;lushuai96@pku.edu.cn;zyfeng@ir.hit.edu.cn;~Duyu_Tang1;~Shujie_LIU1;~Long_Zhou2;~Nan_Duan1;~Alexey_Svyatkovskiy1;shengyfu@microsoft.com;michele.tufano@microsoft.com;shao.deng@microsoft.com;colin.clement@microsoft.com;dawn.drain@microsoft.com;neels@microsoft.com;issjyin@mail.sysu.edu.cn;djiang@microsoft.com;~Ming_Zhou1,6;7;7;7,3;5;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,SUN YAT-SEN UNIVERSITY;Beihang University;Peking University;Harbin Institute of Technology;Harbin Institute of Technology;Microsoft;Microsoft Research Asia;Microsoft Research Asia;Microsoft;;;Microsoft;Microsoft;;Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft,Pre-training;BERT;Code Representations;Code Structure;Data Flow,-1;99;14;150;150;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,293;567;23;416;416;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;293;-1;-1,m;m,NAN,NAN,n,8;3;10
6105,ICLR,2021,The Risks of Invariant Risk Minimization,Elan Rosenfeld;Pradeep Kumar Ravikumar;Andrej Risteski,~Elan_Rosenfeld1;~Pradeep_Kumar_Ravikumar1;~Andrej_Risteski2,7;6;7;7,3;4;2;2,Accept (Poster),0,16,0.0,yes,9/28/20,"CMU, Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University",out-of-distribution generalization;causality;representation learning;deep learning,1;1;1,28;28;28,m;m,usa,usa,y,1
6106,ICLR,2021,On Learning Universal Representations Across Languages,Xiangpeng Wei;Rongxiang Weng;Yue Hu;Luxi Xing;Heng Yu;Weihua Luo,~Xiangpeng_Wei1;wengrx@alibaba-inc.com;huyue@iie.ac.cn;xingluxi@iie.ac.cn;yuheng.yh@alibaba-inc.com;weihua.luowh@alibaba-inc.com,7;7;5,5;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Institute of Information Engineering  Chinese Academy of Sciences;;;Chinese Academy of Sciences;  Chinese Academy of Sciences;Alibaba,universal representation learning;cross-lingual pretraining;hierarchical contrastive learning,34;-1;-1;34;34;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3
6107,ICLR,2021,Linear Last-iterate Convergence in Constrained Saddle-point Optimization,Chen-Yu Wei;Chung-Wei Lee;Mengxiao Zhang;Haipeng Luo,~Chen-Yu_Wei1;~Chung-Wei_Lee1;~Mengxiao_Zhang2;~Haipeng_Luo1,7;7;6;7,3;4;4;4,Accept (Poster),0,13,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California;University of Southern California,Saddle-point Optimization;Optimistic Mirror Decent;Optimistic Gradient Descent Ascent;Optimistic Multiplicative Weights Update;Last-iterate Convergence;Game Theory,37;37;37;37,53;53;53;53,m;m,usa,usa,y,8;1;9
6108,ICLR,2021,Unsupervised Meta-Learning through Latent-Space Interpolation in Generative Models,Siavash Khodadadeh;Sharare Zehtabian;Saeed Vahidian;Weijia Wang;Bill Lin;Ladislau Boloni,~Siavash_Khodadadeh1;sharare.zehtabian@knights.ucf.edu;~Saeed_Vahidian1;wweijia@eng.ucsd.edu;~Bill_Lin1;~Ladislau_Boloni1,6;6;6;7,5;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Central Florida;University of Central Florida;University of California, San Diego;University of California, San Diego;University of California, San Diego;University of Central Florida",Meta-learning;Unsupervised learning;GANs,71;71;-1;-1;-1;71,633;633;33;33;33;633,m;m,usa,usa,n,6;5
6109,ICLR,2021,Fourier Neural Operator for Parametric Partial Differential Equations,Zongyi Li;Nikola Borislavov Kovachki;Kamyar Azizzadenesheli;Burigede liu;Kaushik Bhattacharya;Andrew Stuart;Anima Anandkumar,~Zongyi_Li1;~Nikola_Borislavov_Kovachki1;~Kamyar_Azizzadenesheli1;bgl@caltech.edu;~Kaushik_Bhattacharya1;~Andrew_Stuart2;~Anima_Anandkumar1,5;8;6;7,5;4;2;3,Accept (Poster),0,5,0.0,yes,9/28/20,California Institute of Technology;California Institute of Technology;Purdue University;California Institute of Technology;California Institute of Technology;;California Institute of Technology;California Institute of Technology,Partial differential equation;Fourier transform;Neural operators,150;150;23;150;150;-1;150;150,4;4;94;4;4;-1;4;4,m;f,usa,usa,n,6
6110,ICLR,2021,VTNet: Visual Transformer Network for Object Goal Navigation,Heming Du;Xin Yu;Liang Zheng,~Heming_Du2;~Xin_Yu1;~Liang_Zheng4,6;6;6;6,4;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,Australian National University;University of Technology Sydney;Australian National University,,99;71;99,59;160;59,u;m,australasia,au,n,8
6111,ICLR,2021,Empirical or Invariant Risk Minimization? A Sample Complexity Perspective,Kartik Ahuja;Jun Wang;Amit Dhurandhar;Karthikeyan Shanmugam;Kush R. Varshney,~Kartik_Ahuja1;wangsidi76@gmail.com;~Amit_Dhurandhar1;~Karthikeyan_Shanmugam1;~Kush_R._Varshney1,7;6;7;7,4;2;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,Montreal Institute for Learning Algorithms;;;International Business Machines;International Business Machines;International Business Machines,invariant risk minimization;IRM,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6112,ICLR,2021,DynaTune: Dynamic Tensor Program Optimization in Deep Neural Network Compilation,Minjia Zhang;Menghao Li;Chi Wang;Mingqin Li,~Minjia_Zhang1;t-meli@microsoft.com;~Chi_Wang3;mingqli@microsoft.com,6;7;7;7,5;2;1;4,Accept (Poster),0,11,0.0,yes,9/28/20,"Microsoft AI and Research;Peking University;Microsoft Research;Tsinghua University, Tsinghua University",Efficient Deep Learning Inference;Scalability;Code Compilation;Bayesian Inference,-1;14;-1;4,-1;23;-1;20,m;f,NAN,NAN,n,11
6113,ICLR,2021,Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective,Wuyang Chen;Xinyu Gong;Zhangyang Wang,~Wuyang_Chen1;~Xinyu_Gong1;~Zhangyang_Wang1,6;4;8;6,4;5;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Neural Architecture Search;neural tangent kernel;number of linear regions,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,1
6114,ICLR,2021,Fuzzy Tiling Activations: A Simple Approach to Learning Sparse Representations Online,Yangchen Pan;Kirby Banman;Martha White,~Yangchen_Pan2;kdbanman@ualberta.ca;~Martha_White1,7;7;7;7,4;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,University of Alberta;University of Alberta;University of Alberta,Reinforcement learning;natural sparsity;sparse representation;fuzzy tiling activation function,110;110;110,131;131;131,m;f,canada,ca,y,6
6115,ICLR,2021,Shape-Texture Debiased Neural Network Training,Yingwei Li;Qihang Yu;Mingxing Tan;Jieru Mei;Peng Tang;Wei Shen;Alan Yuille;cihang xie,~Yingwei_Li4;~Qihang_Yu1;~Mingxing_Tan3;~Jieru_Mei2;~Peng_Tang1;~Wei_Shen2;~Alan_Yuille1;~cihang_xie1,6;4;7;7,3;4;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Johns Hopkins University;Johns Hopkins University;Google;Johns Hopkins University;Amazon;Shanghai Jiao Tong University;Johns Hopkins University;University of California, Santa Cruz",data augmentation;representation learning;debiased training,71;71;-1;71;-1;29;71;-1,12;12;-1;12;-1;100;12;207,m;m,usa,usa,n,4
6116,ICLR,2021,Uncertainty Sets for Image Classifiers using Conformal Prediction,Anastasios Nikolas Angelopoulos;Stephen Bates;Michael Jordan;Jitendra Malik,~Anastasios_Nikolas_Angelopoulos1;stephenbates@eecs.berkeley.edu;~Michael_Jordan1;~Jitendra_Malik2,7;7;7;7,4;4;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,"University of California Berkeley;;;Department of Computer and Information Science, University of Massachusetts, Amherst;UC Berkeley",classification;predictive uncertainty;conformal inference;computer vision;imagenet,-1;-1;-1;-1;-1,7;-1;-1;210;-1,m;m,NAN,NAN,y,
6117,ICLR,2021,Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning,Shauharda Khadka;Estelle Aflalo;Mattias Mardar;Avrech Ben-David;Santiago Miret;Shie Mannor;Tamir Hazan;Hanlin Tang;Somdeb Majumdar,~Shauharda_Khadka1;estelle.aflalo@intel.com;mattias.marder@intel.com;avrech@campus.technion.ac.il;~Santiago_Miret1;~Shie_Mannor2;~Tamir_Hazan1;~Hanlin_Tang1;~Somdeb_Majumdar1,6;7;7;5,4;4;4;5,Accept (Poster),0,12,0.0,yes,9/28/20,"Microsoft;Ecole polytechnique;KTH Royal Institute of Technology, Stockholm, Sweden;;;Intel;Technion;Technion;Intel AI Lab;Intel",Reinforcement Learning;Memory Mapping;Device Placement;Evolutionary Algorithms,-1;-1;174;-1;-1;-1;29;29;-1;-1,-1;89;239;-1;-1;-1;408;408;-1;-1,m;m,NAN,NAN,n,1;10
6118,ICLR,2021,Network Pruning That Matters:  A Case Study on Retraining Variants,Duong Hoang Le;Binh-Son Hua,~Duong_Hoang_Le2;~Binh-Son_Hua1,6;5;6;8,5;4;3;5,Accept (Poster),0,7,0.0,yes,9/28/20,VinAI Research;VinAI Research,Network Pruning,-1;-1,-1;-1,m;m,NAN,NAN,n,
6119,ICLR,2021,Shape or Texture: Understanding Discriminative Features in CNNs,Md Amirul Islam;Matthew Kowal;Patrick Esser;Sen Jia;Bj√∂rn Ommer;Konstantinos G. Derpanis;Neil Bruce,~Md_Amirul_Islam1;~Matthew_Kowal1;~Patrick_Esser1;~Sen_Jia1;~Bj√∂rn_Ommer2;~Konstantinos_G._Derpanis1;~Neil_Bruce1,8;4;7;4,3;4;4;4,Accept (Poster),0,16,0.0,yes,9/28/20,Ryerson University;Ryerson University;Heidelberg University;University of Waterloo;Heidelberg University;Ryerson University;York University,Shape;Texture;Shape Bias;Texture Bias;Shape Encoding;Mutual Information,327;327;209;34;209;327;209,785;785;42;232;42;785;452,m;m,asia,kr,n,
6120,ICLR,2021,Predicting Classification Accuracy When Adding New Unobserved Classes,Yuli Slavutsky;Yuval Benjamini,~Yuli_Slavutsky1;~Yuval_Benjamini1,6;6;6,4;4;3,Accept (Poster),0,4,0.0,yes,9/28/20,The Hebrew University of Jerusalem;Hebrew University of Jerusalem,multiclass classification;classification;extrapolation;accuracy;ROC,85;85,235;235,f;m,europe,il,y,2
6121,ICLR,2021,Nearest Neighbor Machine Translation,Urvashi Khandelwal;Angela Fan;Dan Jurafsky;Luke Zettlemoyer;Mike Lewis,~Urvashi_Khandelwal1;~Angela_Fan2;~Dan_Jurafsky1;~Luke_Zettlemoyer1;~Mike_Lewis1,4;4;6;8,3;5;5;4,Accept (Poster),0,7,0.0,yes,9/28/20,Stanford University;Facebook;Stanford University;Facebook;Facebook AI Research,nearest neighbors;machine translation,5;-1;5;-1;-1,2;-1;2;-1;-1,f;m,NAN,NAN,n,6;3
6122,ICLR,2021,SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness,Mikhail Yurochkin;Yuekai Sun,~Mikhail_Yurochkin1;~Yuekai_Sun1,7;7;7;7,3;4;2;3,Accept (Oral),0,5,0.0,yes,9/28/20,International Business Machines;University of Michigan,Algorithmic fairness;invariance,-1;7,-1;22,m;m,usa,usa,y,7
6123,ICLR,2021,Decoupling Global and Local Representations via Invertible Generative Flows,Xuezhe Ma;Xiang Kong;Shanghang Zhang;Eduard H Hovy,~Xuezhe_Ma1;~Xiang_Kong1;~Shanghang_Zhang4;~Eduard_H_Hovy1,6;7;7;8,4;4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,USC/ISI;Carnegie Mellon University;University of California Berkeley;Carnegie Mellon University,Generative Models;Generative Flow;Normalizing Flow;Image Generation;Representation Learning,-1;1;-1;1,-1;28;7;28,m;m,usa,usa,n,5
6124,ICLR,2021,Practical Real Time Recurrent Learning with a Sparse Approximation,Jacob Menick;Erich Elsen;Utku Evci;Simon Osindero;Karen Simonyan;Alex Graves,~Jacob_Menick1;~Erich_Elsen1;~Utku_Evci1;~Simon_Osindero1;~Karen_Simonyan1;~Alex_Graves1,7;7;6;8,3;4;4;5,Accept (Spotlight),0,8,0.0,yes,9/28/20,University College London;Royal Caliber;Google;Google;DeepMind;Google,recurrent neural networks;backpropagation;biologically plausible;forward mode;real time recurrent learning;rtrl;bptt,53;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,10
6125,ICLR,2021,NOVAS: Non-convex Optimization via Adaptive Stochastic Search for End-to-end Learning and Control,Ioannis Exarchos;Marcus Aloysius Pereira;Ziyi Wang;Evangelos Theodorou,~Ioannis_Exarchos1;~Marcus_Aloysius_Pereira1;~Ziyi_Wang1;~Evangelos_Theodorou1,6;6;4;6,2;2;2;3,Accept (Poster),0,6,0.0,yes,9/28/20,Stanford University;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,deep neural networks;nested optimization;stochastic control;deep FBSDEs,5;12;12;12,2;38;38;38,m;m,usa,usa,n,9
6126,ICLR,2021,Incorporating Symmetry into Deep Dynamics Models for Improved Generalization,Rui Wang;Robin Walters;Rose Yu,~Rui_Wang11;~Robin_Walters1;~Rose_Yu1,7;4;6;4,3;4;2;2,Accept (Poster),0,9,0.0,yes,9/28/20,"University of California, San Diego;Northeastern University;University of California, San Diego",deep sequence model;equivariant neural network;physics-guided deep learning;AI for earth science,-1;16;-1,33;895;33,m;f,usa,usa,y,1
6127,ICLR,2021,PDE-Driven Spatiotemporal Disentanglement,J√©r√©mie Don√†;Jean-Yves Franceschi;sylvain lamprier;patrick gallinari,jeremie.dona@lip6.fr;~Jean-Yves_Franceschi1;~sylvain_lamprier1;~patrick_gallinari1,7;7;5,5;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,MLIA;Sorbonne Universit√©;lip6 - UPMC;Criteo AI Lab,disentanglement;spatiotemporal prediction;representation learning;dynamical systems;separation of variables,-1;-1;-1;-1,-1;87;-1;-1,m;m,NAN,NAN,n,1
6128,ICLR,2021,Learning Generalizable Visual Representations via Interactive Gameplay,Luca Weihs;Aniruddha Kembhavi;Kiana Ehsani;Sarah M Pratt;Winson Han;Alvaro Herrasti;Eric Kolve;Dustin Schwenk;Roozbeh Mottaghi;Ali Farhadi,~Luca_Weihs1;~Aniruddha_Kembhavi1;~Kiana_Ehsani1;~Sarah_M_Pratt1;winsonh@allenai.org;alvaroh@allenai.org;~Eric_Kolve1;dustins@allenai.org;~Roozbeh_Mottaghi1;~Ali_Farhadi3,8;8;8;9,4;3;4;3,Accept (Oral),0,5,0.0,yes,9/28/20,Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;;;;Allen Institute for Artificial Intelligence;;;Allen Institute for Artificial Intelligence;University of Washington,representation learning;deep reinforcement learning;computer vision,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;11,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;29,m;m,usa,usa,n,4
6129,ICLR,2021,Reinforcement Learning with Random Delays,Yann Bouteiller;Simon Ramstedt;Giovanni Beltrame;Christopher Pal;Jonathan Binas,~Yann_Bouteiller1;~Simon_Ramstedt1;giovanni.beltrame@polymtl.ca;~Christopher_Pal1;~Jonathan_Binas1,6;3;6;8,3;3;4;4,Accept (Poster),0,17,0.0,yes,9/28/20,"Polytechnique Montreal;University of Montreal;Polytechnique Montreal;Polytechnique Montreal;Montreal Institute for Learning Algorithms, University of Montreal",Reinforcement Learning;Deep Reinforcement Learning,327;128;327;327;128,-1;73;-1;-1;73,m;m,NAN,NAN,y,
6130,ICLR,2021,Mastering Atari with Discrete World Models,Danijar Hafner;Timothy P Lillicrap;Mohammad Norouzi;Jimmy Ba,~Danijar_Hafner1;~Timothy_P_Lillicrap1;~Mohammad_Norouzi1;~Jimmy_Ba1,9;8;4;5,5;5;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;DeepMind;Google Brain;Department of Computer Science, University of Toronto",Atari;world models;model-based reinforcement learning;reinforcement learning;planning;actor critic,18;-1;-1;18,18;-1;-1;18,m;m,NAN,NAN,n,1
6131,ICLR,2021,Chaos of Learning Beyond Zero-sum and Coordination via Game Decompositions,Yun Kuen Cheung;Yixin Tao,~Yun_Kuen_Cheung1;yt851@nyu.edu,5;7;7;7,3;4;3;4,Accept (Poster),0,16,0.0,yes,9/28/20,"Royal Holloway, University of London;London School of Economics",Learning in Games;Lyapunov Chaos;Game Decomposition;Multiplicative Weights Update;Follow-the-Regularized-Leader;Volume Analysis;Dynamical Systems,150;-1,331;27,m;m,NAN,NAN,y,10;5
6132,ICLR,2021,Reducing the Computational Cost of Deep Generative Models with Binary Neural Networks,Thomas Bird;Friso Kingma;David Barber,~Thomas_Bird1;fhkingma@gmail.com;~David_Barber1,6;8;4;7,4;5;4;5,Accept (Poster),0,7,0.0,yes,9/28/20,University College London;Erasmus University Rotterdam;University College London,binary;generative;optimization;compression,53;-1;53,-1;72;-1,m;m,europe,uk,n,5
6133,ICLR,2021,Dataset Meta-Learning from Kernel Ridge-Regression,Timothy Nguyen;Zhourong Chen;Jaehoon Lee,~Timothy_Nguyen1;~Zhourong_Chen3;~Jaehoon_Lee2,4;7;6;6,4;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,Google;Google;Google,dataset distillation;dataset compression;meta-learning;kernel-ridge regression;neural kernels;infinite-width networks;dataset corruption,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,6
6134,ICLR,2021,Evolving Reinforcement Learning Algorithms,John D Co-Reyes;Yingjie Miao;Daiyi Peng;Esteban Real;Quoc V Le;Sergey Levine;Honglak Lee;Aleksandra Faust,~John_D_Co-Reyes1;~Yingjie_Miao1;~Daiyi_Peng1;ereal@google.com;~Quoc_V_Le1;~Sergey_Levine1;~Honglak_Lee2;~Aleksandra_Faust1,9;6;7,4;3;3,Accept (Oral),0,4,0.0,yes,9/28/20,University of California Berkeley;Google;;;;Google;University of Washington;LG AI Research;Google Brain,reinforcement learning;evolutionary algorithms;meta-learning;genetic programming,-1;-1;-1;-1;-1;-1;11;-1;-1,7;-1;-1;-1;-1;-1;29;-1;-1,m;f,NAN,NAN,n,6;1;10
6135,ICLR,2021,Gradient Projection Memory for Continual Learning,Gobinda Saha;Isha Garg;Kaushik Roy,~Gobinda_Saha1;~Isha_Garg1;~Kaushik_Roy1,6;8;8;8,5;5;5;5,Accept (Oral),0,10,0.0,yes,9/28/20,Purdue University;Purdue University;;Purdue University,Continual Learning;Representation Learning;Computer Vision;Deep learning,23;23;-1;23,94;94;-1;94,m;m,usa,usa,n,
6136,ICLR,2021,Contrastive Divergence Learning is a Time Reversal Adversarial Game,Omer Yair;Tomer Michaeli,~Omer_Yair1;~Tomer_Michaeli1,6;7;7;8,4;3;3;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,"Technion, Technion;Technion, Technion",Unsupervised learning;energy based model;adversarial learning;contrastive divergence;noise contrastive estimation,29;29,-1;-1,m;m,NAN,NAN,n,5;4
6137,ICLR,2021,Noise or Signal: The Role of Image Backgrounds in Object Recognition,Kai Yuanqing Xiao;Logan Engstrom;Andrew Ilyas;Aleksander Madry,~Kai_Yuanqing_Xiao1;~Logan_Engstrom1;~Andrew_Ilyas1;~Aleksander_Madry1,5;6;8;7,3;4;5;3,Accept (Poster),0,12,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Backgrounds;Model Biases;Robustness;Computer Vision,5;5;5;5,4;4;4;4,m;m,usa,usa,n,4
6138,ICLR,2021,Scaling Symbolic Methods using Gradients for Neural Model Explanation,Subham Sekhar Sahoo;Subhashini Venugopalan;Li Li;Rishabh Singh;Patrick Riley,subhamsahoo@google.com;~Subhashini_Venugopalan2;~Li_Li8;~Rishabh_Singh1;~Patrick_Riley2,5;7;5;7,3;4;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,Google;Google;Google;Google Brain;Google,Neural Model Explanation;SMT Solvers;Symbolic Methods,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
6139,ICLR,2021,Contrastive Syn-to-Real Generalization,Wuyang Chen;Zhiding Yu;Shalini De Mello;Sifei Liu;Jose M. Alvarez;Zhangyang Wang;Anima Anandkumar,~Wuyang_Chen1;~Zhiding_Yu1;~Shalini_De_Mello1;~Sifei_Liu2;~Jose_M._Alvarez2;~Zhangyang_Wang1;~Anima_Anandkumar1,7;6;6;6,4;4;4;4,Accept (Poster),0,8,0.0,yes,9/28/20,"University of Texas, Austin;NVIDIA;NVIDIA;NVIDIA;NVIDIA;University of Texas, Austin;California Institute of Technology",synthetic-to-real generalization;domain generalization,-1;-1;-1;-1;-1;-1;150,-1;-1;-1;-1;-1;-1;4,m;f,usa,usa,n,6;8;1
6140,ICLR,2021,Learning Value Functions in Deep Policy Gradients using Residual Variance,Yannis Flet-Berliac;reda ouhamma;odalric-ambrym maillard;Philippe Preux,~Yannis_Flet-Berliac1;~reda_ouhamma1;~odalric-ambrym_maillard1;~Philippe_Preux1,8;5;7,3;3;4,Accept (Poster),0,17,0.0,yes,9/28/20,Inria (SequeL team) / Univ. Lille;Universit√© de Lille;inria;Universit√© de Lille,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
6141,ICLR,2021,Multiscale Score Matching for Out-of-Distribution Detection,Ahsan Mahmood;Junier Oliva;Martin Andreas Styner,~Ahsan_Mahmood1;~Junier_Oliva1;~Martin_Andreas_Styner1,5;6;5;9,3;4;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Department of Computer Science, University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",out-of-distribution detection;score matching;deep learning;outlier detection,64;64;64,-1;-1;-1,m;m,NAN,NAN,n,
6142,ICLR,2021,PseudoSeg: Designing Pseudo Labels for Semantic Segmentation,Yuliang Zou;Zizhao Zhang;Han Zhang;Chun-Liang Li;Xiao Bian;Jia-Bin Huang;Tomas Pfister,~Yuliang_Zou1;~Zizhao_Zhang3;~Han_Zhang1;~Chun-Liang_Li1;~Xiao_Bian3;~Jia-Bin_Huang1;~Tomas_Pfister1,7;6;8,4;4;5,Accept (Poster),0,6,0.0,yes,9/28/20,Virginia Tech;Google;Rutgers University;Google;Google;Virginia Tech;Google,pseudo-labeling;semi-supervised;semantic-segmentation,64;-1;29;-1;-1;64;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2
6143,ICLR,2021,Grounded Language Learning Fast and Slow,Felix Hill;Olivier Tieleman;Tamara von Glehn;Nathaniel Wong;Hamza Merzic;Stephen Clark,~Felix_Hill1;~Olivier_Tieleman1;tamaravg@google.com;~Nathaniel_Wong1;~Hamza_Merzic1;~Stephen_Clark1,8;8;8;6,4;3;3;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,Computer Laboratory;DeepMind;;;;DeepMind;Cambridge Quantum Computing,language;cognition;fast-mapping;grounding;word-learning;memory;meta-learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
6144,ICLR,2021,Auxiliary Learning by Implicit Differentiation,Aviv Navon;Idan Achituve;Haggai Maron;Gal Chechik;Ethan Fetaya,~Aviv_Navon1;~Idan_Achituve1;~Haggai_Maron1;~Gal_Chechik1;~Ethan_Fetaya1,7;6;6;7;6,3;3;3;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Bar Ilan University, Technion;Bar Ilan University;NVIDIA;Bar Ilan University;Bar Ilan University",Auxiliary Learning;Multi-task Learning,29;110;-1;110;110,-1;570;-1;570;570,m;m,europe,il,n,2
6145,ICLR,2021,LEAF: A Learnable Frontend for Audio Classification,Neil Zeghidour;Olivier Teboul;F√©lix de Chaumont Quitry;Marco Tagliasacchi,~Neil_Zeghidour1;~Olivier_Teboul2;~F√©lix_de_Chaumont_Quitry1;~Marco_Tagliasacchi3,7;8;4;7,4;5;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,Google;Google;Google;Google,audio understanding;frontend;learnable;mel-filterbanks;time-frequency representations;sound classification,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
6146,ICLR,2021,Beyond Categorical Label Representations for Image Classification,Boyuan Chen;Yu Li;Sunand Raghupathi;Hod Lipson,~Boyuan_Chen1;yl4019@columbia.edu;sr3587@columbia.edu;~Hod_Lipson1,7;4;7;7,4;4;3;4,Accept (Poster),0,18,0.0,yes,9/28/20,Columbia University;;;Columbia University;;Columbia University,Label Representation;Image Classification;Representation Learning,23;-1;-1;23;-1;23,17;-1;-1;17;-1;17,m;m,usa,usa,n,4
6147,ICLR,2021,Learning perturbation sets for robust machine learning,Eric Wong;J Zico Kolter,~Eric_Wong1;~J_Zico_Kolter1,6;5;6;8,3;4;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,Massachusetts Institute of Technology;Carnegie Mellon University,adversarial examples;perturbation sets;robust machine learning;conditional variational autoencoder,5;1,4;28,m;m,usa,usa,y,1;5;4
6148,ICLR,2021,Variational State-Space Models for Localisation and Dense 3D Mapping in 6 DoF,Atanas Mirchev;Baris Kayalibay;Patrick van der Smagt;Justin Bayer,~Atanas_Mirchev1;~Baris_Kayalibay1;~Patrick_van_der_Smagt1;~Justin_Bayer1,6;7;6;6,3;4;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,"Technical University Munich;Data Lab, Volkswagen Group;Machine Learning Research Lab, Volkswagen Group;VW Group",Generative models;Bayesian inference;Variational inference;SLAM;Deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,11;5
6149,ICLR,2021,Primal Wasserstein Imitation Learning,Robert Dadashi;Leonard Hussenot;Matthieu Geist;Olivier Pietquin,~Robert_Dadashi2;~Leonard_Hussenot1;~Matthieu_Geist1;~Olivier_Pietquin1,6;6;8;6,4;3;5;4,Accept (Poster),0,4,0.0,yes,9/28/20,Google;Google;Google;Google Brain,Reinforcement Learning;Inverse Reinforcement Learning;Imitation Learning;Optimal Transport;Wasserstein distance,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,4
6150,ICLR,2021,Prototypical Representation Learning for Relation Extraction,Ning Ding;Xiaobin Wang;Yao Fu;Guangwei Xu;Rui Wang;Pengjun Xie;Ying Shen;Fei Huang;Hai-Tao Zheng;Rui Zhang,~Ning_Ding5;~Xiaobin_Wang1;~Yao_Fu3;~Guangwei_Xu2;~Rui_Wang16;~Pengjun_Xie2;~Ying_Shen3;~Fei_Huang2;~Hai-Tao_Zheng2;~Rui_Zhang11,4;5;7;6,4;5;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Soochow University, China;University of Edinburgh;University of Electronic Science and Technology of China;Vipshop (China) Co., Ltd.;;SUN YAT-SEN UNIVERSITY;Alibaba Group;Tsinghua University, Tsinghua University;Tsinghua University",NLP;Relation Extraction;Representation Learning,4;-1;29;-1;-1;-1;-1;-1;4;4,20;553;30;553;-1;-1;293;-1;20;20,m;m,asia,cn,n,6
6151,ICLR,2021,Distance-Based Regularisation of Deep Networks for Fine-Tuning,Henry Gouk;Timothy Hospedales;massimiliano pontil,~Henry_Gouk1;~Timothy_Hospedales1;~massimiliano_pontil1,5;7;6;7,4;4;4;4,Accept (Poster),0,18,0.0,yes,9/28/20,Edinburgh University  University of Edinburgh;University of Edinburgh;University College London,Deep Learning;Transfer Learning;Statistical Learning Theory,29;29;53,30;30;-1,m;m,europe,uk,y,6;1
6152,ICLR,2021,Separation and Concentration in Deep Networks,John Zarka;Florentin Guth;St√©phane Mallat,~John_Zarka1;~Florentin_Guth1;~St√©phane_Mallat1,6;7;8;6,4;3;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Ecole Normale Superieure;Ecole Normale Sup√©rieure;College de France,fisher ratio;neural collapse;mean separation;concentration;variance reduction;deep learning;image classification,128;128;-1,-1;-1;-1,m;m,NAN,NAN,y,1
6153,ICLR,2021,Degree-Quant: Quantization-Aware Training for Graph Neural Networks,Shyam Anil Tailor;Javier Fernandez-Marques;Nicholas Donald Lane,~Shyam_Anil_Tailor1;~Javier_Fernandez-Marques1;~Nicholas_Donald_Lane1,6;7;6,2;4;2,Accept (Poster),0,5,0.0,yes,9/28/20,"Computer Laboratory;University of Oxford;Department of Computer Science, University of Oxford",Graph neural networks;quantization;benchmark,-1;46;46,-1;1;1,m;m,NAN,NAN,n,10
6154,ICLR,2021,ResNet After All: Neural ODEs and Their Numerical Solution,Katharina Ott;Prateek Katiyar;Philipp Hennig;Michael Tiemann,~Katharina_Ott1;prateek.katiyar@de.bosch.com;~Philipp_Hennig1;~Michael_Tiemann1,7;6;7;5,4;4;3;4,Accept (Poster),0,17,0.0,yes,9/28/20,University of Tuebingen;;;University of Tuebingen;Bosch Center for Artificial Intelligence,,128;-1;-1;128;-1,78;-1;-1;78;-1,f;m,NAN,NAN,n,
6155,ICLR,2021,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,Michael Sejr Schlichtkrull;Nicola De Cao;Ivan Titov,~Michael_Sejr_Schlichtkrull1;~Nicola_De_Cao1;~Ivan_Titov1,7;7;7;6,4;4;3;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,University of Cambridge;University of Amsterdam;University of Edinburgh,Graph neural networks;interpretability;sparse stochastic gates;semantic role labeling;question answering,79;128;29,6;66;30,m;m,europe,uk,n,3;10
6156,ICLR,2021,Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning,Namyeong Kwon;Hwidong Na;Gabriel Huang;Simon Lacoste-Julien,~Namyeong_Kwon1;~Hwidong_Na1;~Gabriel_Huang1;~Simon_Lacoste-Julien1,5;7;6;5,4;5;4;2,Accept (Poster),0,13,0.0,yes,9/28/20,Samsung Advanced Institute of Technology;Samsung;University of Montreal;University of Montreal,Meta-learning;Few-shot learning;Out-of-domain;Uncertainty;Ensemble;Adversarial training;Stepsize optimization,-1;-1;128;128,-1;-1;73;73,m;m,canada,ca,n,6;4
6157,ICLR,2021,"Self-supervised Adversarial Robustness for the Low-label, High-data Regime",Sven Gowal;Po-Sen Huang;Aaron van den Oord;Timothy Mann;Pushmeet Kohli,~Sven_Gowal2;~Po-Sen_Huang1;~Aaron_van_den_Oord2;~Timothy_Mann1;~Pushmeet_Kohli1,7;7;6;4,4;4;4;4,Accept (Poster),0,13,0.0,yes,9/28/20,DeepMind;Google DeepMind;Google;;Microsoft Research Cambridge,self-supervised;adversarial training;robustness,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1;4
6158,ICLR,2021,Interpreting Knowledge Graph Relation Representation from Word Embeddings,Carl Allen;Ivana Balazevic;Timothy Hospedales,~Carl_Allen1;~Ivana_Balazevic1;~Timothy_Hospedales1,7;7;6;7,3;3;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh;University of Edinburgh,knowledge graphs;word embedding;representation learning,29;29;29,30;30;30,m;m,europe,uk,n,3;10
6159,ICLR,2021,Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling,ƒêorƒëe Miladinoviƒá;Aleksandar Staniƒá;Stefan Bauer;J√ºrgen Schmidhuber;Joachim M. Buhmann,~ƒêorƒëe_Miladinoviƒá1;~Aleksandar_Staniƒá1;~Stefan_Bauer1;~J√ºrgen_Schmidhuber1;~Joachim_M._Buhmann1,7;7;6;6,3;3;3;5,Accept (Poster),0,7,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;The Swiss AI Lab - IDSIA;Swiss Federal Institute of Technology;IDSIA;ETH Zurich Switzerland",Neural networks;Deep generative models;Image Modeling;Variational Autoencoders,-1;-1;-1;-1;9,-1;-1;-1;-1;14,m;m,NAN,NAN,n,5
6160,ICLR,2021,Learning the Pareto Front with Hypernetworks,Aviv Navon;Aviv Shamsian;Ethan Fetaya;Gal Chechik,~Aviv_Navon1;~Aviv_Shamsian1;~Ethan_Fetaya1;~Gal_Chechik1,6;6;7;6,3;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Bar Ilan University, Technion;Bar Ilan University, Technion;Bar Ilan University;Bar Ilan University",Multi-objective optimization;multi-task learning,29;29;110;110,-1;-1;570;570,m;m,europe,il,n,7
6161,ICLR,2021,Autoregressive Entity Retrieval,Nicola De Cao;Gautier Izacard;Sebastian Riedel;Fabio Petroni,~Nicola_De_Cao1;~Gautier_Izacard1;~Sebastian_Riedel1;~Fabio_Petroni2,8;8;8;7,4;4;4;5,Accept (Spotlight),0,5,0.0,yes,9/28/20,University of Amsterdam;Ecole Normale Superieure;Facebook;Facebook,entity retrieval;document retrieval;autoregressive language model;entity linking;end-to-end entity linking;entity disambiguation;constrained beam search,128;128;-1;-1,66;-1;-1;-1,m;m,NAN,NAN,n,
6162,ICLR,2021,Neural Approximate Sufficient Statistics for Implicit Models,Yanzhi Chen;Dinghuai Zhang;Michael U. Gutmann;Aaron Courville;Zhanxing Zhu,~Yanzhi_Chen1;~Dinghuai_Zhang1;~Michael_U._Gutmann1;~Aaron_Courville3;~Zhanxing_Zhu1,6;7;7;6,5;3;4;4,Accept (Spotlight),0,12,0.0,yes,9/28/20,"University of Edinburgh;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Edinburgh;University of Montreal;Peking University",likelihood-free inference;bayesian inference;mutual information;representation learning;summary statistics,29;128;29;128;14,30;73;30;73;23,m;m,asia,cn,y,11;5
6163,ICLR,2021,Partitioned Learned Bloom Filters,Kapil Vaidya;Eric Knorr;Michael Mitzenmacher;Tim Kraska,~Kapil_Vaidya1;eric_knorr@g.harvard.edu;~Michael_Mitzenmacher1;~Tim_Kraska1,7;7;6,3;3;3,Accept (Poster),0,3,0.0,yes,9/28/20,Massachusetts Institute of Technology;;;Harvard University;Brown University,optimization;data structures;algorithms;theory;learned algorithms,5;-1;-1;53;85,4;-1;-1;3;61,m;m,usa,usa,n,
6164,ICLR,2021,Computational Separation Between Convolutional and Fully-Connected Networks,eran malach;Shai Shalev-Shwartz,~eran_malach1;~Shai_Shalev-Shwartz1,6;8;8;5,4;3;3;4,Accept (Poster),0,4,0.0,yes,9/28/20,"Hebrew University of Jerusalem, Israel;Hebrew University of Jerusalem",Neural Networks;Deep Learning;Convolutional Networks;Fully-Connected Networks;Gradient Descent,85;85,235;235,m;m,europe,il,y,2
6165,ICLR,2021,Deep Learning meets Projective Clustering,Alaa Maalouf;Harry Lang;Daniela Rus;Dan Feldman,~Alaa_Maalouf1;~Harry_Lang1;~Daniela_Rus1;~Dan_Feldman1,5;4;7,3;3;4,Accept (Poster),0,10,0.0,yes,9/28/20,The University of Haifa;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Haifa,Compressing Deep Networks;NLP;Matrix Factorization;SVD,209;5;5;209,644;4;4;644,m;m,europe,il,n,3
6166,ICLR,2021,Rethinking Positional Encoding in Language Pre-training,Guolin Ke;Di He;Tie-Yan Liu,~Guolin_Ke3;~Di_He1;~Tie-Yan_Liu1,7;7;6;7,4;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Microsoft;Microsoft;Microsoft,Natural Language Processing;Pre-training,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,8;3
6167,ICLR,2021,Auction Learning as a Two-Player Game,Jad Rahme;Samy Jelassi;S. Matthew Weinberg,~Jad_Rahme1;~Samy_Jelassi1;~S._Matthew_Weinberg1,6;6;6;6;7,2;3;3;4;3,Accept (Poster),0,10,0.0,yes,9/28/20,Princeton University;Princeton University;Princeton University,Mechanism Design;Auction Theory;Game Theory;Deep Learning,29;29;29,9;9;9,m;m,usa,usa,y,
6168,ICLR,2021,On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections,Peizhao Li;Yifei Wang;Han Zhao;Pengyu Hong;Hongfu Liu,~Peizhao_Li1;~Yifei_Wang3;~Han_Zhao1;~Pengyu_Hong1;~Hongfu_Liu2,7;5;5;7,3;3;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Brandeis University;Brandeis University;University of Illinois, Urbana Champaign;Brandeis University;Brandeis University",algorithmic fairness;graph-structured data,263;263;-1;263;263,242;242;-1;242;242,m;m,usa,usa,y,10;7
6169,ICLR,2021,Early Stopping in Deep Networks: Double Descent and How to Eliminate it,Reinhard Heckel;Fatih Furkan Yilmaz,~Reinhard_Heckel1;~Fatih_Furkan_Yilmaz1,4;8;6;7,4;4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,Technical University Munich;Rice University,early stopping;double descent,-1;92,-1;124,m;m,australasia,au,y,1
6170,ICLR,2021,Cross-Attentional Audio-Visual Fusion for Weakly-Supervised Action Localization,Jun-Tae Lee;Mihir Jain;Hyoungwoo Park;Sungrack Yun,~Jun-Tae_Lee1;~Mihir_Jain1;hwoopark@qti.qualcomm.com;sungrack@qti.qualcomm.com,7;6;6;6,5;5;2;3,Accept (Poster),0,4,0.0,yes,9/28/20,"Qualcomm Inc, QualComm;QualComm;Korea Advanced Institute of Science and Technology;QualComm",Audio-Visual;Multimodal Attention;Action localization;Event localization;Weak-supervision,-1;-1;-1;-1,-1;-1;96;-1,m;m,NAN,NAN,n,8
6171,ICLR,2021,Reweighting Augmented Samples by Minimizing the Maximal Expected Loss,Mingyang Yi;Lu Hou;Lifeng Shang;Xin Jiang;Qun Liu;Zhi-Ming Ma,~Mingyang_Yi1;~Lu_Hou2;~Lifeng_Shang1;~Xin_Jiang1;~Qun_Liu1;~Zhi-Ming_Ma1,6;7;7,4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,University of Chinese Academy of Sciences;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Noah‚Äö√Ñ√¥s Ark Lab  Huawei Technologies;Noah's Ark Lab  Huawei Technologies Ltd.;Chinese Academy of Sciences,data augmentation;sample reweighting,34;-1;-1;-1;-1;34,-1;-1;-1;-1;-1;-1,m;m,asia,cn,y,3;8;1;4
6172,ICLR,2021,Robust early-learning: Hindering the memorization of noisy labels,Xiaobo Xia;Tongliang Liu;Bo Han;Chen Gong;Nannan Wang;Zongyuan Ge;Yi Chang,~Xiaobo_Xia1;~Tongliang_Liu1;~Bo_Han1;~Chen_Gong5;~Nannan_Wang1;~Zongyuan_Ge1;yichang@jlu.edu.cn,6;7;7;7,4;4;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,"The University of Sydney;University of Sydney;HKBU;Nanjing University of Science and Technology;Xidian University;Monash University;Jilin University, China, Tsinghua University",,71;71;-1;52;-1;92;4,51;51;-1;111;924;64;20,m;m,NAN,NAN,n,1
6173,ICLR,2021,Learning to Represent Action Values as a Hypergraph on the Action Vertices,Arash Tavakoli;Mehdi Fatemi;Petar Kormushev,~Arash_Tavakoli1;~Mehdi_Fatemi1;~Petar_Kormushev1,8;7;8;6;5,4;5;4;2;2,Accept (Poster),0,13,0.0,yes,9/28/20,Imperial College London;Microsoft;;Imperial College London,reinforcement learning;structural credit assignment;structural inductive bias;multi-dimensional discrete action spaces;learning action representations,53;-1;-1;53,11;-1;-1;11,m;m,europe,uk,n,8
6174,ICLR,2021,A Distributional Approach to Controlled Text Generation,Muhammad Khalifa;Hady Elsahar;Marc Dymetman,~Muhammad_Khalifa2;~Hady_Elsahar2;~Marc_Dymetman1,8;7;7,3;3;3,Accept (Oral),0,5,0.0,yes,9/28/20,Cairo University;Naver Labs Europe;Naver Labs Europe,Controlled NLG;Pretrained Language Models;Bias in Language Models;Energy-Based Models;Information Geometry;Exponential Families,-1;-1;-1,746;-1;-1,m;m,NAN,NAN,y,3
6175,ICLR,2021,"AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL",Lucio M. Dery;Yann Dauphin;David Grangier,~Lucio_M._Dery1;~Yann_Dauphin1;~David_Grangier1,6;6;5;6,3;5;2;3,Accept (Poster),0,7,0.0,yes,9/28/20,Carnegie Mellon University;Google;Google,pre-training;multitask learning;deeplearning;gradient decomposition,1;-1;-1,28;-1;-1,m;m,NAN,NAN,y,
6176,ICLR,2021,Graph Convolution with Low-rank Learnable Local Filters,Xiuyuan Cheng;Zichen Miao;Qiang Qiu,~Xiuyuan_Cheng1;~Zichen_Miao1;~Qiang_Qiu1,7;7;7;8,3;3;3;5,Accept (Spotlight),0,0,0.0,yes,9/28/20,Duke University;Purdue University;Purdue University,,46;23;23,20;94;94,m;m,usa,usa,y,10
6177,ICLR,2021,Uncertainty-aware Active Learning for Optimal Bayesian Classifier,Guang Zhao;Edward Dougherty;Byung-Jun Yoon;Francis Alexander;Xiaoning Qian,~Guang_Zhao1;~Edward_Dougherty1;~Byung-Jun_Yoon1;falexander@bnl.gov;~Xiaoning_Qian2,5;6;6;7,2;4;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,Texas A&M;;Brookhaven National Laboratory;;;Texas A&M,Active learning;Bayesian classification,46;-1;-1;-1;-1;46,195;-1;-1;-1;-1;195,m;m,NAN,NAN,y,11
6178,ICLR,2021,Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies,T. Konstantin Rusch;Siddhartha Mishra,~T._Konstantin_Rusch1;~Siddhartha_Mishra1,7;7;8;7,3;3;5;3,Accept (Oral),0,12,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,RNNs;Oscillators;Gradient stability;Long-term dependencies,-1;-1,-1;-1,m;m,NAN,NAN,y,1
6179,ICLR,2021,A Gradient Flow Framework For Analyzing Network Pruning,Ekdeep Singh Lubana;Robert Dick,~Ekdeep_Singh_Lubana1;~Robert_Dick1,6;6;7;9,4;5;3;5,Accept (Spotlight),0,9,0.0,yes,9/28/20,University of Michigan;University of Michigan,Network pruning;Gradient flow;Early pruning,7;7,22;22,m;m,usa,usa,n,
6180,ICLR,2021,Taking Notes on the Fly Helps Language Pre-Training,Qiyu Wu;Chen Xing;Yatao Li;Guolin Ke;Di He;Tie-Yan Liu,~Qiyu_Wu1;~Chen_Xing2;yatli@microsoft.com;~Guolin_Ke3;~Di_He1;~Tie-Yan_Liu1,6;6;7;6,4;3;4;4,Accept (Poster),0,17,0.0,yes,9/28/20,Peking University;SalesForce.com;;;Microsoft;Microsoft;Microsoft,Natural Language Processing;Pre-training,14;-1;-1;-1;-1;-1;-1,23;-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,3
6181,ICLR,2021,Impact of Representation Learning in Linear Bandits,Jiaqi Yang;Wei Hu;Jason D. Lee;Simon Shaolei Du,~Jiaqi_Yang2;~Wei_Hu1;~Jason_D._Lee1;~Simon_Shaolei_Du1,6;7;7;6;7,5;4;3;4;3,Accept (Poster),0,6,0.0,yes,9/28/20,University of California Berkeley;Princeton University;Princeton University;Facebook,linear bandits;representation learning;multi-task learning,-1;29;29;-1,7;9;9;-1,m;m,NAN,NAN,y,1
6182,ICLR,2021,HyperGrid Transformers: Towards A Single Model for Multiple Tasks,Yi Tay;Zhe Zhao;Dara Bahri;Donald Metzler;Da-Cheng Juan,~Yi_Tay1;~Zhe_Zhao3;~Dara_Bahri1;metzler@google.com;~Da-Cheng_Juan1,7;6;6,3;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,Google;Google;Google Research;Google;Google Research,Transformers;Multi-Task Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
6183,ICLR,2021,Mutual Information State Intrinsic Control,Rui Zhao;Yang Gao;Pieter Abbeel;Volker Tresp;Wei Xu,~Rui_Zhao1;~Yang_Gao1;~Pieter_Abbeel2;~Volker_Tresp1;~Wei_Xu13,7;8;7;7,3;5;5;3,Accept (Spotlight),0,9,0.0,yes,9/28/20,"Siemens AG;Tsinghua University, Tsinghua University;Covariant;Ludwig Maximilian University of Munich;Horizon Robotics",Intrinsically Motivated Reinforcement Learning;Intrinsic Reward;Intrinsic Motivation;Deep Reinforcement Learning;Reinforcement Learning,-1;4;-1;-1;-1,-1;20;-1;-1;-1,m;m,NAN,NAN,y,
6184,ICLR,2021,My Body is a Cage: the Role of Morphology in Graph-Based Incompatible Control,Vitaly Kurin;Maximilian Igl;Tim Rockt√§schel;Wendelin Boehmer;Shimon Whiteson,~Vitaly_Kurin1;~Maximilian_Igl1;~Tim_Rockt√§schel1;~Wendelin_Boehmer1;~Shimon_Whiteson1,7;7;7;7,4;4;4;2,Accept (Poster),0,9,0.0,yes,9/28/20,University of Oxford;University of Oxford;Facebook AI Research;Delft University of Technology;University of Oxford,Deep Reinforcement Learning;Multitask Reinforcement Learning;Graph Neural Networks;Continuous Control;Incompatible Environments,46;46;-1;-1;46,1;1;-1;78;1,m;m,europe,uk,n,8;10
6185,ICLR,2021,Graph Edit Networks,Benjamin Paassen;Daniele Grattarola;Daniele Zambon;Cesare Alippi;Barbara Eva Hammer,~Benjamin_Paassen1;~Daniele_Grattarola1;~Daniele_Zambon1;cesare.alippi@usi.ch;~Barbara_Eva_Hammer1,3;7;6;7,4;1;5;2,Accept (Poster),0,0,0.0,yes,9/28/20,"Humboldt Universit√§t Berlin;Universit√† della Svizzera Italiana;Universit√† della Svizzera Italiana;Northwestern Polytechnical University, Tsinghua University;Bielefeld University",graph neural networks;graph edit distance;time series prediction;structured prediction,-1;174;174;4;327,-1;282;282;20;158,m;f,europe,de,y,1;10
6186,ICLR,2021,MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering,Tsung Wei Tsai;Chongxuan Li;Jun Zhu,~Tsung_Wei_Tsai1;~Chongxuan_Li1;~Jun_Zhu2,6;8;6;5,5;3;5;4,Accept (Poster),0,10,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",unsupervised learning;clustering;self supervised learning;mixture of experts,4;4;4,20;20;20,u;m,asia,cn,y,1
6187,ICLR,2021,VCNet and Functional Targeted Regularization For Learning Causal Effects of Continuous Treatments,Lizhen Nie;Mao Ye;qiang liu;Dan Nicolae,lizhen@uchicago.edu;~Mao_Ye11;~qiang_liu4;nicolae@galton.uchicago.edu,6;9;5,5;4;4,Accept (Oral),0,5,0.0,yes,9/28/20,The University of Chicago;University of Texas  Austin;University of Texas  Austin;University of Chicago,causal inference;continuous treatment effect;doubly robustness,46;20;20;46,10;43;43;10,f;m,usa,usa,y,
6188,ICLR,2021,Online Adversarial Purification based on Self-supervised Learning,Changhao Shi;Chester Holtz;Gal Mishne,~Changhao_Shi1;~Chester_Holtz1;~Gal_Mishne1,7;6;7,5;4;3,Accept (Poster),0,13,0.0,yes,9/28/20,"University of California, San Diego;University of California, San Diego, University of California, San Diego;University of California, San Diego",Adversarial Robustness;Self-Supervised Learning,-1;-1;-1,33;33;33,m;f,usa,usa,n,4
6189,ICLR,2021,Learning A Minimax Optimizer: A Pilot Study,Jiayi Shen;Xiaohan Chen;Howard Heaton;Tianlong Chen;Jialin Liu;Wotao Yin;Zhangyang Wang,~Jiayi_Shen1;~Xiaohan_Chen1;~Howard_Heaton2;~Tianlong_Chen1;~Jialin_Liu1;~Wotao_Yin1;~Zhangyang_Wang1,6;7;7;7,4;4;4;4,Accept (Poster),0,12,0.0,yes,9/28/20,"Texas A&M;University of Texas, Austin;University of California, Los Angeles;University of Texas, Austin;Alibaba Group US;Alibaba Group US;University of Texas, Austin",Learning to Optimize;Minimax Optimization,46;-1;-1;-1;-1;-1;-1,195;-1;15;-1;-1;-1;-1,f;m,usa,usa,n,
6190,ICLR,2021,Wasserstein-2 Generative Networks,Alexander Korotin;Vage Egiazarian;Arip Asadulaev;Alexander Safin;Evgeny Burnaev,~Alexander_Korotin2;~Vage_Egiazarian1;~Arip_Asadulaev1;a.safin@skoltech.ru;~Evgeny_Burnaev1,5;6;8,4;2;4,Accept (Poster),0,9,0.0,yes,9/28/20,Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;ITMO University;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology,wasserstein-2 distance;optimal transport maps;non-minimax optimization;cycle-consistency regularization;input-convex neural networks,-1;-1;-1;-1;-1,-1;-1;534;-1;-1,m;m,europe,russia,y,5
6191,ICLR,2021,Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization,Alexander Korotin;Lingxiao Li;Justin Solomon;Evgeny Burnaev,~Alexander_Korotin2;lingxiao@mit.edu;~Justin_Solomon1;~Evgeny_Burnaev1,6;7;6;7,4;3;4;5,Accept (Poster),0,7,0.0,yes,9/28/20,Skolkovo Institute of Science and Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Skolkovo Institute of Science and Technology,wasserstein-2 barycenters;non-minimax optimization;cycle-consistency regularizer;input convex neural networks;continuous case,-1;5;5;-1,-1;4;4;-1,m;m,europe,russia,y,
6192,ICLR,2021,Randomized Automatic Differentiation,Deniz Oktay;Nick McGreivy;Joshua Aduol;Alex Beatson;Ryan P Adams,~Deniz_Oktay2;mcgreivy@princeton.edu;jaduol@princeton.edu;~Alex_Beatson1;~Ryan_P_Adams1,7;7;8;8,4;4;4;4,Accept (Oral),0,7,0.0,yes,9/28/20,Princeton University;Princeton University;Princeton University;Princeton University;Princeton University,automatic differentiation;autodiff;backprop;deep learning;pdes;stochastic optimization,29;29;29;29;29,9;9;9;9;9,m;m,usa,usa,n,
6193,ICLR,2021,Lossless Compression of Structured Convolutional Models via Lifting,Gustav Sourek;Filip Zelezny;Ondrej Kuzelka,~Gustav_Sourek1;zelezny@fel.cvut.cz;~Ondrej_Kuzelka1,6;5;6,3;2;1,Accept (Poster),0,4,0.0,yes,9/28/20,Czech Technical University in Prague;;;Czech Technical University in Prague,weight sharing;graph neural networks;lifted inference;relational learning;dynamic computation graphs;convolutional models,174;-1;-1;174,1045;-1;-1;1045,m;m,NAN,NAN,n,10
6194,ICLR,2021,A Better Alternative to Error Feedback for Communication-Efficient Distributed Learning,Samuel Horv√°th;Peter Richtarik,~Samuel_Horv√°th1;~Peter_Richtarik1,9;7;5;6,4;4;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,KAUST;KAUST,distributed optimization;communication efficiency,110;110,-1;-1,m;m,europe,gr,y,
6195,ICLR,2021,BiPointNet: Binary Neural Network for Point Clouds,Haotong Qin;Zhongang Cai;Mingyuan Zhang;Yifu Ding;Haiyu Zhao;Shuai Yi;Xianglong Liu;Hao Su,qinhaotong@buaa.edu.cn;~Zhongang_Cai1;~Mingyuan_Zhang1;~Yifu_Ding2;~Haiyu_Zhao1;~Shuai_Yi3;~Xianglong_Liu2;~Hao_Su1,4;7;7;8,5;3;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,Beihang University;SenseTime International Pte Ltd;Sensetime;Beihang University;Sensetime International PTE LTD;The Chinese University of Hong Kong;Beihang University;University of California - San Diego,point clouds;efficient deep learning;binary neural networks,99;-1;-1;99;-1;327;99;-1,567;-1;-1;567;-1;39;567;33,m;m,usa,usa,y,
6196,ICLR,2021,Entropic gradient descent algorithms and wide flat minima,Fabrizio Pittorino;Carlo Lucibello;Christoph Feinauer;Gabriele Perugini;Carlo Baldassi;Elizaveta Demyanenko;Riccardo Zecchina,~Fabrizio_Pittorino1;~Carlo_Lucibello1;~Christoph_Feinauer1;~Gabriele_Perugini1;~Carlo_Baldassi1;elizaveta.demyanenko@phd.unibocconi.it;~Riccardo_Zecchina1,6;5;7;6,4;4;3;5,Accept (Poster),0,5,0.0,yes,9/28/20,Bocconi University;Bocconi University;Bocconi University;Bocconi University;Bocconi University;Bocconi University;;Bocconi University;Polytechnic Institute of Turin,flat minima;entropic algorithms;statistical physics;belief-propagation,327;327;327;327;327;327;-1;327;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
6197,ICLR,2021,Loss Function Discovery for Object Detection via Convergence-Simulation Driven Search,Peidong Liu;Gengwei Zhang;Bochao Wang;Hang Xu;Xiaodan Liang;Yong Jiang;Zhenguo Li,~Peidong_Liu2;~Gengwei_Zhang1;~Bochao_Wang2;~Hang_Xu1;~Xiaodan_Liang2;~Yong_Jiang3;~Zhenguo_Li1,7;6;6;5,5;4;4;4,Accept (Poster),0,0,0.0,yes,9/28/20,Tsinghua University;SUN YAT-SEN UNIVERSITY;Huawei Noah‚Äòs Ark Lab;Huawei Noah‚Äòs Ark Lab;SUN YAT-SEN UNIVERSITY;;Huawei,Object detection;AutoML;Evolutionary algorithm;Loss function search,4;-1;-1;-1;-1;-1;-1,20;293;-1;-1;293;-1;-1,m;m,NAN,NAN,n,2;1
6198,ICLR,2021,Deep Repulsive Clustering of Ordered Data Based on Order-Identity Decomposition,Seon-Ho Lee;Chang-Su Kim,~Seon-Ho_Lee1;~Chang-Su_Kim4,7;6;7;6,4;3;4;3,Accept (Poster),0,8,0.0,yes,9/28/20,Korea University;Korea University,Clustering;order learning;age estimation;aesthetic assessment;historical color image classification,174;174,167;167,m;m,asia,kr,n,
6199,ICLR,2021,Can a Fruit Fly Learn Word Embeddings?,Yuchen Liang;Chaitanya Ryali;Benjamin Hoover;Leopold Grinberg;Saket Navlakha;Mohammed J Zaki;Dmitry Krotov,liangy7@rpi.edu;~Chaitanya_Ryali1;benjamin.hoover@ibm.com;leopoldgrinberg@gmail.com;navlakha@cshl.edu;~Mohammed_J_Zaki1;~Dmitry_Krotov2,7;7;7,4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,"Rensselaer Polytechnic Institute;University of California, San Diego;International Business Machines;;;;;Rensselaer Polytechnic Institute;Institue for Advanced Study, Princeton",neurobiology;neuroscience;fruit fly;locality sensitive hashing;word embedding;sparse representations,263;-1;-1;-1;-1;-1;-1;263;-1,527;33;-1;-1;-1;-1;-1;527;-1,m;m,NAN,NAN,n,3
6200,ICLR,2021,Undistillable: Making A Nasty Teacher That CANNOT teach students,Haoyu Ma;Tianlong Chen;Ting-Kuei Hu;Chenyu You;Xiaohui Xie;Zhangyang Wang,~Haoyu_Ma1;~Tianlong_Chen1;~Ting-Kuei_Hu1;~Chenyu_You1;~Xiaohui_Xie2;~Zhangyang_Wang1,7;7;7;7,4;4;4;4,Accept (Spotlight),0,9,0.0,yes,9/28/20,"University of California, Irvine;University of Texas, Austin;Texas A&M;Yale University;University of California, Irvine;University of Texas, Austin",knowledge distillation;avoid knowledge leaking,-1;-1;46;71;-1;-1,98;-1;195;8;98;-1,m;m,usa,usa,n,
6201,ICLR,2021,No MCMC for me: Amortized sampling for fast and stable training of energy-based models,Will Sussman Grathwohl;Jacob Jin Kelly;Milad Hashemi;Mohammad Norouzi;Kevin Swersky;David Duvenaud,~Will_Sussman_Grathwohl2;jacob.jin.kelly@gmail.com;~Milad_Hashemi1;~Mohammad_Norouzi1;~Kevin_Swersky1;~David_Duvenaud2,4;7;8,4;4;4,Accept (Poster),0,24,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Google;Google Brain;Google Brain;Department of Computer Science, University of Toronto",Generative Models;EBM;Energy-Based Models;Energy Based Models;semi-supervised learning;JEM,18;18;-1;-1;-1;18,18;18;-1;-1;-1;18,m;m,NAN,NAN,n,10
6202,ICLR,2021,Estimating and Evaluating Regression Predictive Uncertainty in Deep Object Detectors,Ali Harakeh;Steven L. Waslander,~Ali_Harakeh1;~Steven_L._Waslander1,6;6;6;9,2;4;3;5,Accept (Poster),0,9,0.0,yes,9/28/20,Toronto University;Toronto University,Object Detection;Predictive Uncertainty Estimation;Proper Scoring Rules;Variance Networks;Energy Score;Computer Vision,-1;-1,-1;-1,m;m,NAN,NAN,n,2
6203,ICLR,2021,Prediction and generalisation over directed actions by grid cells,Changmin Yu;Timothy Behrens;Neil Burgess,~Changmin_Yu1;behrens@fmrib.ox.ac.uk;n.burgess@ucl.ac.uk,4;7;5;5;7,4;4;1;4;4,Accept (Poster),0,0,0.0,yes,9/28/20,University College London;;;University College London,Computational neuroscience;grid cells;normative models,53;-1;-1;53,-1;-1;-1;-1,m;m,europe,uk,n,
6204,ICLR,2021,SACoD: Sensor Algorithm Co-Design Towards Efficient CNN-powered Intelligent PhlatCam,Yonggan Fu;Yang Zhang;Yue Wang;Zhihan Lu;Vivek Boominathan;Ashok Veeraraghavan;Yingyan Lin,~Yonggan_Fu1;~Yang_Zhang3;~Yue_Wang3;~Zhihan_Lu1;~Vivek_Boominathan1;~Ashok_Veeraraghavan1;~Yingyan_Lin1,6;6;6;6,4;3;1;4,Reject,0,5,0.0,yes,9/28/20,Rice University;International Business Machines;Rice University;Rice University;Rice University;William Marsh Rice University;Rice University,Sensor Network Co-design;neural architecture search,92;-1;92;92;92;92;92,124;-1;124;124;124;124;124,m;f,australasia,au,n,
6205,ICLR,2021,Efficient Certified Defenses Against Patch Attacks on Image Classifiers,Jan Hendrik Metzen;Maksym Yatsura,~Jan_Hendrik_Metzen1;~Maksym_Yatsura1,6;7;7;6,4;3;3;3,Accept (Poster),0,7,0.0,yes,9/28/20,Bosch Center Artificial Intelligence;Bosch Center for Artificial Intelligence,robustness;certified defense;adversarial patch;aversarial examples,-1;-1,-1;-1,m;m,NAN,NAN,n,4
6206,ICLR,2021,Adapting to Reward Progressivity via Spectral Reinforcement Learning,Michael Dann;John Thangarajah,~Michael_Dann1;john.thangarajah@rmit.edu.au,6;7;7;6,4;4;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,Royal Melbourne Institute of Technology;Royal Melbourne Institute of Technology,Reinforcement Learning;Deep Reinforcement Learning,-1;-1,-1;-1,m;m,NAN,NAN,y,
6207,ICLR,2021,Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs,Xingang Pan;Bo Dai;Ziwei Liu;Chen Change Loy;Ping Luo,~Xingang_Pan1;~Bo_Dai2;~Ziwei_Liu1;~Chen_Change_Loy2;~Ping_Luo2,7;8;8,3;5;4,Accept (Oral),0,3,0.0,yes,9/28/20,The Chinese University of Hong Kong;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;The University of Hong Kong,Generative Adversarial Network;3D Reconstruction,327;44;44;44;99,39;47;47;47;39,m;m,NAN,NAN,n,5
6208,ICLR,2021,Meta-learning Symmetries by Reparameterization,Allan Zhou;Tom Knowles;Chelsea Finn,~Allan_Zhou1;tknowles@stanford.edu;~Chelsea_Finn1,9;8;5;6,4;4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,Stanford University;;;Stanford University,meta-learning;equivariance;convolution;symmetry,5;-1;-1;5,2;-1;-1;2,m;f,usa,usa,y,1
6209,ICLR,2021,Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization,Zhenggang Tang;Chao Yu;Boyuan Chen;Huazhe Xu;Xiaolong Wang;Fei Fang;Simon Shaolei Du;Yu Wang;Yi Wu,tangzhenggang@pku.edu.cn;yc19@mails.tsinghua.edu.cn;~Boyuan_Chen2;~Huazhe_Xu1;~Xiaolong_Wang3;~Fei_Fang1;~Simon_Shaolei_Du1;~Yu_Wang3;~Yi_Wu1,6;6;7;5,3;4;2;3,Accept (Poster),0,7,0.0,yes,9/28/20,"Peking University;Tsinghua University, Tsinghua University;University of California Berkeley;University of California Berkeley;University of California, San Diego;Carnegie Mellon University;Facebook;Tsinghua University;Tsinghua University",strategic behavior;multi-agent reinforcement learning;reward randomization;diverse strategies,14;4;-1;-1;-1;1;-1;4;4,23;20;7;7;33;28;-1;20;20,m;m,asia,cn,y,
6210,ICLR,2021,SEED: Self-supervised Distillation For Visual Representation,Zhiyuan Fang;Jianfeng Wang;Lijuan Wang;Lei Zhang;Yezhou Yang;Zicheng Liu,~Zhiyuan_Fang1;~Jianfeng_Wang4;~Lijuan_Wang1;~Lei_Zhang23;~Yezhou_Yang1;~Zicheng_Liu1,6;7;7,5;4;5,Accept (Poster),0,3,0.0,yes,9/28/20,Arizona State University;University of Science and Technology of China;;Microsoft;Arizona State University;Microsoft,Self Supervised Learning;Knowledge Distillation;Representation Learning,85;-1;-1;-1;85;-1,182;87;-1;-1;182;-1,m;m,NAN,NAN,n,
6211,ICLR,2021,Behavioral Cloning from Noisy Demonstrations,Fumihiro Sasaki;Ryota Yamashina,~Fumihiro_Sasaki2;ryohta.yamashina@jp.ricoh.com,6;7;8,4;3;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,Ricoh Company  Ltd.;Ricoh Company  Ltd.,Imitation Learning;Inverse Reinforcement Learning;Noisy Demonstrations,-1;-1,-1;-1,m;m,NAN,NAN,y,5;4
6212,ICLR,2021,Teaching with Commentaries,Aniruddh Raghu;Maithra Raghu;Simon Kornblith;David Duvenaud;Geoffrey Hinton,~Aniruddh_Raghu1;~Maithra_Raghu1;~Simon_Kornblith1;~David_Duvenaud2;~Geoffrey_Hinton1,7;5;7;6,3;5;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Google Brain;Google;Department of Computer Science, University of Toronto;University of Toronto",learning to teach;metalearning;hypergradients,5;-1;-1;18;18,4;-1;-1;18;18,m;m,canada,ca,n,8
6213,ICLR,2021,R-GAP: Recursive Gradient Attack on Privacy,Junyi Zhu;Matthew B. Blaschko,~Junyi_Zhu1;~Matthew_B._Blaschko1,7;7;6,3;4;2,Accept (Poster),0,6,0.0,yes,9/28/20,KU Leuven;KU Leuven,privacy leakage from gradients;federated learning;collaborative learning,150;150,45;45,u;m,europe,be,n,4
6214,ICLR,2021,Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies,Dominik Schmidt;Georgia Koppe;Zahra Monfared;Max Beutelspacher;Daniel Durstewitz,~Dominik_Schmidt1;~Georgia_Koppe1;zahra.monfared@zi-mannheim.de;max.beutelspacher@mailbox.org;~Daniel_Durstewitz1,7;7;6;8,4;5;4;4,Accept (Spotlight),0,11,0.0,yes,9/28/20,ZI Mannheim;Central Institute of Mental Health;Heidelberg University(STRUCTURES);;;Heidelberg University,nonlinear dynamical systems;recurrent neural networks;attractors;computational neuroscience;vanishing gradient problem;LSTM,-1;-1;209;-1;-1;209,-1;-1;42;-1;-1;42,m;m,europe,de,y,1
6215,ICLR,2021,Usable Information and Evolution of Optimal Representations During Training,Michael Kleinman;Alessandro Achille;Daksh Idnani;Jonathan Kao,~Michael_Kleinman2;~Alessandro_Achille1;~Daksh_Idnani1;~Jonathan_Kao1,7;7;3;7,3;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"University of California, Los Angeles;California Institute of Technology;University of California, Los Angeles;University of California, Los Angeles",Usable Information;Representation Learning;Learning Dynamics;Initialization;SGD,-1;150;-1;-1,15;4;15;15,m;m,usa,usa,n,
6216,ICLR,2021,A Design Space Study for LISTA and Beyond,Tianjian Meng;Xiaohan Chen;Yifan Jiang;Zhangyang Wang,~Tianjian_Meng2;~Xiaohan_Chen1;~Yifan_Jiang2;~Zhangyang_Wang1,6;8;4;7,4;4;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Google Brain;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,y,
6217,ICLR,2021,Revisiting Few-sample BERT Fine-tuning,Tianyi Zhang;Felix Wu;Arzoo Katiyar;Kilian Q Weinberger;Yoav Artzi,~Tianyi_Zhang2;~Felix_Wu1;~Arzoo_Katiyar1;~Kilian_Q_Weinberger1;~Yoav_Artzi1,7;6;6;6,3;4;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,Stanford University;ASAPP Inc.;Pennsylvania State University;Cornell University;Cornell University,Fine-tuning;Optimization;BERT,5;-1;44;7;7,2;-1;-1;19;19,m;m,usa,usa,n,
6218,ICLR,2021,Implicit Gradient Regularization,David Barrett;Benoit Dherin,~David_Barrett1;dherin@google.com,6;7;6,4;5;4,Accept (Poster),0,16,0.0,yes,9/28/20,Google;Google,implicit regularization;deep learning;deep learning theory;theoretical issues in deep learning;theory;regularization,-1;-1,-1;-1,m;m,NAN,NAN,y,
6219,ICLR,2021,On the Transfer of Disentangled Representations in Realistic Settings,Andrea Dittadi;Frederik Tr√§uble;Francesco Locatello;Manuel Wuthrich;Vaibhav Agrawal;Ole Winther;Stefan Bauer;Bernhard Sch√∂lkopf,~Andrea_Dittadi1;~Frederik_Tr√§uble1;~Francesco_Locatello1;~Manuel_Wuthrich1;~Vaibhav_Agrawal1;~Ole_Winther1;~Stefan_Bauer1;~Bernhard_Sch√∂lkopf1,5;7;9;2,4;5;4;5,Accept (Poster),0,4,0.0,yes,9/28/20,"Technical University of Denmark;, Max Planck Institute for Intelligent Systems;Amazon;Max Planck Institute for Intelligent Systems;Max-Planck Institute;University of Copenhagen;Swiss Federal Institute of Technology;Max Planck Institute for Intelligent Systems, Max-Planck Institute",representation learning;disentanglement;real-world,-1;-1;-1;-1;-1;92;-1;-1,186;-1;-1;-1;-1;84;-1;-1,m;m,NAN,NAN,y,
6220,ICLR,2021,Improved Estimation of Concentration Under $\ell_p$-Norm Distance Metrics Using Half Spaces,Jack Prescott;Xiao Zhang;David Evans,jbp2jn@virginia.edu;~Xiao_Zhang2;~David_Evans1,6;6;7;7,4;4;3;2,Accept (Poster),0,4,0.0,yes,9/28/20,University of Virginia;University of Virginia;University of Virginia,Adversarial Examples;Concentration of Measure;Gaussian Isoperimetric Inequality,53;53;53,117;117;117,m;m,usa,usa,y,4
6221,ICLR,2021,Learnable Embedding sizes for Recommender Systems,Siyi Liu;Chen Gao;Yihong Chen;Depeng Jin;Yong Li,~Siyi_Liu1;~Chen_Gao3;~Yihong_Chen3;jindp@tsinghua.edu.cn;~Yong_Li3,7;7;7;6,4;4;3;4,Accept (Poster),0,10,0.0,yes,9/28/20,University of Electronic Science and Technology of China;Tsinghua University  Tsinghua University;University College London;;Tsinghua University,Recommender Systems;Deep Learning;Embedding Size,-1;4;53;-1;4,553;20;-1;-1;20,u;u,asia,cn,n,
6222,ICLR,2021,Isometric Propagation Network for Generalized Zero-shot Learning,Lu Liu;Tianyi Zhou;Guodong Long;Jing Jiang;Xuanyi Dong;Chengqi Zhang,~Lu_Liu7;~Tianyi_Zhou1;~Guodong_Long2;~Jing_Jiang6;~Xuanyi_Dong1;~Chengqi_Zhang1,7;6;7;4,4;3;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,University of Technology Sydney;University of Washington;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,Zero-shot learning;isometric;prototype propagation;alignment of semantic and visual space,71;11;71;71;71;71,160;29;160;160;160;160,f;m,australasia,au,n,6;1;10
6223,ICLR,2021,Why resampling outperforms reweighting for correcting sampling bias with stochastic gradients,Jing An;Lexing Ying;Yuhua Zhu,jingan@stanford.edu;~Lexing_Ying1;yuhuazhu@stanford.edu,6;6;7;7;5,3;3;3;3;4,Accept (Poster),0,21,0.0,yes,9/28/20,Stanford University;Stanford University;;Stanford University,biased sampling;reweighting;resampling;stability;stochastic asymptotics,5;5;-1;5,2;2;-1;2,f;f,usa,usa,y,
6224,ICLR,2021,Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies,Paul Pu Liang;Manzil Zaheer;Yuan Wang;Amr Ahmed,~Paul_Pu_Liang1;~Manzil_Zaheer1;~Yuan_Wang1;~Amr_Ahmed1,7;6;5,4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,"Carnegie Mellon University;Zaheer;Google;Research, Google",sparse embeddings;large vocabularies;text classification;language modeling;recommendation systems,1;-1;-1;-1,28;-1;-1;-1,m;m,NAN,NAN,y,11;3
6225,ICLR,2021,Hierarchical Reinforcement Learning by Discovering Intrinsic Options,Jesse Zhang;Haonan Yu;Wei Xu,~Jesse_Zhang3;~Haonan_Yu5;~Wei_Xu13,4;4;7;8,2;3;3;4,Accept (Poster),0,9,0.0,yes,9/28/20,University of Southern California;Horizon Robotics;Horizon Robotics,hierarchical reinforcement learning;reinforcement learning;options;unsupervised skill discovery;exploration,37;-1;-1,53;-1;-1,m;m,NAN,NAN,n,
6226,ICLR,2021,"GAN Steerability"" without optimization """,Nurit Spingarn;Ron Banner;Tomer Michaeli,~Nurit_Spingarn1;~Ron_Banner1;~Tomer_Michaeli1,6;8;6;8,5;4;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,"Technion, Technion;Intel;Technion, Technion",Generative Adversarial Network;semantic directions in latent space;nonlinear walk,29;-1;29,-1;-1;-1,f;m,NAN,NAN,n,5
6227,ICLR,2021,Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent,El Mahdi El Mhamdi;Rachid Guerraoui;S√©bastien Rouault,el-mahdi.el-mhamdi@polytechnique.edu;~Rachid_Guerraoui1;~S√©bastien_Rouault1,7;4;6;4,4;3;2;3,Accept (Poster),0,4,0.0,yes,9/28/20,Google;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Byzantine SGD;Distributed ML;Momentum,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,4
6228,ICLR,2021,Geometry-aware Instance-reweighted Adversarial Training,Jingfeng Zhang;Jianing Zhu;Gang Niu;Bo Han;Masashi Sugiyama;Mohan Kankanhalli,~Jingfeng_Zhang1;~Jianing_Zhu2;~Gang_Niu1;~Bo_Han1;~Masashi_Sugiyama1;~Mohan_Kankanhalli1,7;8;8,4;5;5,Accept (Oral),0,5,0.0,yes,9/28/20,RIKEN;Hong Kong Baptist University;RIKEN;HKBU;RIKEN Center for Advanced Intelligence Project;National University of Singapore,Adversarial robustness,-1;209;-1;-1;-1;17,-1;377;-1;-1;-1;25,m;m,asia,sg,n,4
6229,ICLR,2021,Neural gradients are near-lognormal: improved quantized  and sparse training,Brian Chmiel;Liad Ben-Uri;Moran Shkolnik;Elad Hoffer;Ron Banner;Daniel Soudry,~Brian_Chmiel1;liadgo2@gmail.com;~Moran_Shkolnik1;~Elad_Hoffer1;~Ron_Banner1;~Daniel_Soudry1,7;7;6;8,3;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Technion - Israel Institute of Technology, Technion;;;Technion, Technion;Habana Labs (Intel);Intel;Technion - Israel Institute of Technology",,29;-1;-1;29;-1;-1;29,-1;-1;-1;-1;-1;-1;408,m;m,NAN,NAN,n,
6230,ICLR,2021,MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond,Duy Kien Nguyen;Vedanuj Goswami;Xinlei Chen,~Duy_Kien_Nguyen1;~Vedanuj_Goswami1;~Xinlei_Chen1,7;7;6;6,3;4;5;3,Accept (Poster),0,4,0.0,yes,9/28/20,"University of Amsterdam;Georgia Institute of Technology;School of Computer Science, Carnegie Mellon University",visual counting;visual question answering;common object counting;visual reasoning;modulated convolution,128;12;1,66;38;28,m;m,NAN,NAN,n,1
6231,ICLR,2021,Fair Mixup: Fairness via Interpolation,Ching-Yao Chuang;Youssef Mroueh,~Ching-Yao_Chuang1;~Youssef_Mroueh1,5;7;7;6,4;4;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,Massachusetts Institute of Technology;IBM,fairness;data augmentation,5;453,4;-1,m;m,asia,in,y,10;1;7
6232,ICLR,2021,Continual learning in recurrent neural networks,Benjamin Ehret;Christian Henning;Maria Cervera;Alexander Meulemans;Johannes Von Oswald;Benjamin F Grewe,behret@ethz.ch;~Christian_Henning1;~Maria_Cervera1;~Alexander_Meulemans1;~Johannes_Von_Oswald1;~Benjamin_F_Grewe1,7;7;6,4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Recurrent Neural Networks;Continual Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
6233,ICLR,2021,Isometric Transformation Invariant and Equivariant Graph Convolutional Networks,Masanobu Horie;Naoki Morita;Toshiaki Hishinuma;Yu Ihara;Naoto Mitsume,~Masanobu_Horie1;morita@ricos.co.jp;hishinuma@ricos.co.jp;ihara@ricos.co.jp;mitsume@kz.tsukuba.ac.jp,7;6;5,4;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,The University of Tsukuba;;;;The University of Tsukuba,Machine Learning;Graph Neural Network;Invariance;Equivariance;Simulation;Mesh,110;-1;-1;-1;110,499;-1;-1;-1;499,m;m,NAN,NAN,y,10
6234,ICLR,2021,Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL,Xiaoyu Chen;Jiachen Hu;Lihong Li;Liwei Wang,~Xiaoyu_Chen2;~Jiachen_Hu1;~Lihong_Li1;~Liwei_Wang1,7;6;7;7,4;3;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Peking University;Peking University;Amazon;Peking University,reinforcement learning;factored MDP;constrained RL;learning theory,14;14;-1;14,23;23;-1;23,m;m,asia,cn,y,1
6235,ICLR,2021,FedMix: Approximation of Mixup under Mean Augmented Federated Learning,Tehrim Yoon;Sumin Shin;Sung Ju Hwang;Eunho Yang,~Tehrim_Yoon1;sym807@kaist.ac.kr;~Sung_Ju_Hwang1;~Eunho_Yang1,6;7;6,4;4;4,Accept (Poster),0,20,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology,federated learning;mixup,-1;-1;-1;-1,96;96;96;-1,m;m,NAN,NAN,y,
6236,ICLR,2021,Emergent Symbols through Binding in External Memory,Taylor Whittington Webb;Ishan Sinha;Jonathan Cohen,~Taylor_Whittington_Webb1;sinha.ishan@gmail.com;~Jonathan_Cohen1,6;7;7;7,4;4;4;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,"University of California, Los Angeles;;;Princeton University",abstract rules;out-of-distribution generalization;external memory;indirection;variable binding,-1;-1;-1;29,15;-1;-1;9,m;m,usa,usa,n,1
6237,ICLR,2021,Faster Binary Embeddings for Preserving Euclidean Distances,Jinjie Zhang;Rayan Saab,~Jinjie_Zhang1;~Rayan_Saab1,6;6;7;7;5,5;3;2;4;5,Accept (Poster),0,16,0.0,yes,9/28/20,"University of California, San Diego;University of California, San Diego",Binary Embeddings;Johnson-Lindenstrauss Transforms;Sigma Delta Quantization,-1;-1,33;33,m;m,usa,usa,y,1
6238,ICLR,2021,On the Universality of Rotation Equivariant Point Cloud Networks,Nadav Dym;Haggai Maron,nadavdym@gmail.com;~Haggai_Maron1,6;8;8;6,2;3;3;2,Accept (Poster),0,6,0.0,yes,9/28/20,Duke University;NVIDIA,3D deep learning;Rotation invariance;Invariant and equivariant deep networks;Universal approximation;Point clouds,46;-1,20;-1,m;m,NAN,NAN,y,8;2;10
6239,ICLR,2021,Rethinking Attention with Performers,Krzysztof Marcin Choromanski;Valerii Likhosherstov;David Dohan;Xingyou Song;Andreea Gane;Tamas Sarlos;Peter Hawkins;Jared Quincy Davis;Afroz Mohiuddin;Lukasz Kaiser;David Benjamin Belanger;Lucy J Colwell;Adrian Weller,~Krzysztof_Marcin_Choromanski1;vl304@cam.ac.uk;~David_Dohan1;~Xingyou_Song1;~Andreea_Gane1;~Tamas_Sarlos1;phawkins@google.com;~Jared_Quincy_Davis1;~Afroz_Mohiuddin1;~Lukasz_Kaiser1;~David_Benjamin_Belanger1;~Lucy_J_Colwell1;~Adrian_Weller1,8;7;8;7,4;5;4;3,Accept (Oral),0,10,0.0,yes,9/28/20,Google Brain Robotics & Columbia University;University of Cambridge;Google;Google;Google;Google Research;Google;Google;Google;Google;University of Massachusetts Amherst;University of Cambridge;Alan Turing Institute,performer;transformer;attention;softmax;approximation;linear;bert;bidirectional;unidirectional;orthogonal;random;features;FAVOR;kernel;generalized;sparsity;reformer;linformer;protein;trembl;uniprot,23;79;-1;-1;-1;-1;-1;-1;-1;-1;23;79;-1,17;6;-1;-1;-1;-1;-1;-1;-1;-1;210;6;-1,m;m,NAN,NAN,y,8
6240,ICLR,2021,CoCon: A Self-Supervised Approach for Controlled Text Generation,Alvin Chan;Yew-Soon Ong;Bill Pung;Aston Zhang;Jie Fu,~Alvin_Chan1;~Yew-Soon_Ong1;pung0013@e.ntu.edu.sg;~Aston_Zhang2;~Jie_Fu2,6;8;7;4,4;4;3;5,Accept (Poster),0,8,0.0,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;;;AWS;University of Montreal,Language modeling;text generation;controlled generation;self-supervised learning,44;44;-1;-1;209;128,47;47;-1;-1;-1;73,m;m,canada,ca,n,6;8;3
6241,ICLR,2021,Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures,Pedro Hermosilla;Marco Sch√§fer;Matej Lang;Gloria Fackelmann;Pere-Pau V√°zquez;Barbora Kozlikova;Michael Krone;Tobias Ritschel;Timo Ropinski,~Pedro_Hermosilla1;marco.schaefer@uni-tuebingen.de;242528@mail.muni.cz;gloria.fackelmann@uni-ulm.de;pere.pau@cs.upc.edu;kozlikova@fi.muni.cz;michael.krone@uni-tuebingen.de;~Tobias_Ritschel1;~Timo_Ropinski2,6;5;9;8;9,4;4;4;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,Ulm University;University of Tuebingen;;;;;;;;;;;University College London;Ulm University,classification;bioinformatics,-1;128;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;53;-1,140;78;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;140,m;m,europe,tr,n,
6242,ICLR,2021,On the Bottleneck of Graph Neural Networks and its Practical Implications,Uri Alon;Eran Yahav,~Uri_Alon1;~Eran_Yahav1,6;5;8;4;5,4;4;5;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,"Technion;Technion, Technion",graphs;GNNs;limitations;understanding;bottleneck;over-squashing,29;29,408;-1,m;m,NAN,NAN,n,10
6243,ICLR,2021,A statistical theory of cold posteriors in deep neural networks,Laurence Aitchison,~Laurence_Aitchison1,6;7;6;9,4;3;4;4,Accept (Poster),0,13,0.0,yes,9/28/20,University of Bristol,Bayesian inference;cold posteriors;sgld,110,91,m,europe,uk,n,11;1;5
6244,ICLR,2021,PC2WF: 3D Wireframe Reconstruction from Raw Point Clouds,Yujia Liu;Stefano D'Aronco;Konrad Schindler;Jan Dirk Wegner,~Yujia_Liu3;~Stefano_D'Aronco1;~Konrad_Schindler1;~Jan_Dirk_Wegner1,7;7;6;6,4;3;5;3,Accept (Poster),0,6,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,deep neural network;3d point cloud;wireframe model,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,
6245,ICLR,2021,Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs,Jonathan Frankle;David J. Schwab;Ari S. Morcos,~Jonathan_Frankle1;~David_J._Schwab1;~Ari_S._Morcos1,8;6;6;6,4;5;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,Massachusetts Institute of Technology;CUNY Graduate Center;Facebook AI Research (FAIR),affine parameters;random features;batchnorm,5;263;-1,4;-1;-1,m;m,NAN,NAN,n,
6246,ICLR,2021,Domain-Robust Visual Imitation Learning with Mutual Information Constraints,Edoardo Cetin;Oya Celiktutan,~Edoardo_Cetin1;~Oya_Celiktutan2,6;7;7;7,4;3;3;4,Accept (Poster),0,9,0.0,yes,9/28/20,King's College London;King's College London,Imitation Learning;Reinforcement Learning;Observational Imitation;Third-Person Imitation;Mutual Information;Domain Adaption;Machine Learning,174;174,35;35,m;f,europe,uk,n,5;4
6247,ICLR,2021,Revisiting Dynamic Convolution via Matrix Decomposition,Yunsheng Li;Yinpeng Chen;Xiyang Dai;mengchen liu;Dongdong Chen;Ye Yu;Lu Yuan;Zicheng Liu;Mei Chen;Nuno Vasconcelos,~Yunsheng_Li1;~Yinpeng_Chen1;~Xiyang_Dai2;mengcliu@microsoft.com;~Dongdong_Chen1;yu.ye@microsoft.com;~Lu_Yuan1;~Zicheng_Liu1;~Mei_Chen2;~Nuno_Vasconcelos1,7;7;6;6,3;2;3;3,Accept (Poster),0,9,0.0,yes,9/28/20,"University of California, San Diego;Microsoft;Microsoft;Tsinghua University, Tsinghua University;Microsoft Research;Microsoft;Microsoft;Microsoft;Microsoft;University of California San Diego",supervised representation learning;efficient network;dynamic network;matrix decomposition,-1;-1;-1;4;-1;-1;-1;-1;-1;-1,33;-1;-1;20;-1;-1;-1;-1;-1;33,m;m,usa,usa,n,8
6248,ICLR,2021,Rapid Task-Solving in Novel Environments,Samuel Ritter;Ryan Faulkner;Laurent Sartran;Adam Santoro;Matthew Botvinick;David Raposo,~Samuel_Ritter1;~Ryan_Faulkner2;~Laurent_Sartran1;~Adam_Santoro1;~Matthew_Botvinick1;~David_Raposo1,4;7;7;8,5;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,DeepMind;McGill University;Google;Google;;Google,deep reinforcement learning;meta learning;deep learning;exploration;planning,-1;99;-1;-1;-1;-1,-1;40;-1;-1;-1;-1,m;m,NAN,NAN,n,
6249,ICLR,2021,Differentiable Trust Region Layers for Deep Reinforcement Learning,Fabian Otto;Philipp Becker;Vien Anh Ngo;Hanna Carolin Maria Ziesche;Gerhard Neumann,~Fabian_Otto1;~Philipp_Becker1;~Vien_Anh_Ngo1;~Hanna_Carolin_Maria_Ziesche1;~Gerhard_Neumann1,6;6;7;6,4;5;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,"University of Tuebingen;Karlsruhe Institute of Technology;Bosch Center for Artificial Intelligence;Robert Bosch GmbH, Bosch;Karlsruhe Institute of Technology",reinforcement learning;trust region;policy gradient;projection;Wasserstein distance;Kullback-Leibler divergence;Frobenius norm,128;174;-1;-1;174,78;202;-1;-1;202,m;m,europe,de,y,
6250,ICLR,2021,Unsupervised Object Keypoint Learning using Local Spatial Predictability,Anand Gopalakrishnan;Sjoerd van Steenkiste;J√ºrgen Schmidhuber,~Anand_Gopalakrishnan1;~Sjoerd_van_Steenkiste1;~J√ºrgen_Schmidhuber1,9;6;7,3;1;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,Dalle Molle Institute for Artificial Intelligence Research;Dalle Molle Institute for Artificial Intelligence Research (IDSIA);IDSIA,unsupervised representation learning;object-keypoint representations;visual saliency,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,
6251,ICLR,2021,Learning Parametrised Graph Shift Operators,George Dasoulas;Johannes F. Lutzeyer;Michalis Vazirgiannis,~George_Dasoulas1;~Johannes_F._Lutzeyer1;~Michalis_Vazirgiannis1,7;7;5;7,4;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,Ecole polytechnique;Ecole polytechnique;;AUEB,graph neural networks;graph shift operators;graph classification;node classification;graph representation learning,-1;-1;-1;209,89;89;-1;-1,m;m,europe,gr,y,10
6252,ICLR,2021,Dataset Condensation with Gradient Matching,Bo Zhao;Konda Reddy Mopuri;Hakan Bilen,~Bo_Zhao4;~Konda_Reddy_Mopuri3;~Hakan_Bilen1,8;8;9,3;3;4,Accept (Oral),0,7,0.0,yes,9/28/20,University of Edinburgh;Indian Institute of Technology Tirupati;University of Edinburgh,dataset condensation;data-efficient learning;image generation,29;-1;29,30;-1;30,m;m,europe,uk,n,2;1
6253,ICLR,2021,Efficient Generalized Spherical CNNs,Oliver Cobb;Christopher G. R. Wallis;Augustine N. Mavor-Parker;Augustin Marignier;Matthew A. Price;Mayeul d'Avezac;Jason McEwen,~Oliver_Cobb1;christopher.wallis@kagenova.com;augustine.mavor-parker@kagenova.com;auggie.marignier@kagenova.com;matt.price@kagenova.com;mayeul.davezac@kagenova.com;~Jason_McEwen1,8;6;6;7,5;2;2;4,Accept (Poster),0,8,0.0,yes,9/28/20,Kagenova Ltd;;;;;;;;;;;University College London,,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;53,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,europe,uk,n,2;1
6254,ICLR,2021,Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning,Kanil Patel;William H. Beluch;Bin Yang;Michael Pfeiffer;Dan Zhang,~Kanil_Patel1;~William_H._Beluch1;~Bin_Yang5;~Michael_Pfeiffer1;~Dan_Zhang1,7;7;5,4;3;4,Accept (Poster),0,12,0.0,yes,9/28/20,"University of Stuttgart;Robert Bosch GmbH, Bosch;University of Stuttgart;Bosch Center for Artificial Intelligence;Bosch center for artificial intelligence",uncertainty calibration;post-hoc calibration;histogram binning;mutual information;deep neural networks,110;-1;110;-1;-1,354;-1;354;-1;-1,m;f,NAN,NAN,y,
6255,ICLR,2021,LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition,Valeriia Cherepanova;Micah Goldblum;Harrison Foley;Shiyuan Duan;John P Dickerson;Gavin Taylor;Tom Goldstein,~Valeriia_Cherepanova1;~Micah_Goldblum1;m211926@usna.edu;sduan1@umd.edu;~John_P_Dickerson1;~Gavin_Taylor1;~Tom_Goldstein1,7;6;7,3;4;5,Accept (Poster),0,3,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;;;;University of Maryland, College Park;Arthur AI;US Naval Academy;University of Maryland, College Park",facial recognition;adversarial attacks,12;12;-1;-1;-1;12;-1;-1;12,90;90;-1;-1;-1;90;-1;-1;90,f;m,usa,usa,n,2;4
6256,ICLR,2021,Task-Agnostic Morphology Evolution,Donald Joseph Hejna III;Pieter Abbeel;Lerrel Pinto,~Donald_Joseph_Hejna_III1;~Pieter_Abbeel2;~Lerrel_Pinto1,7;6;6;7,4;3;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,University of California Berkeley;Covariant;New York University,morphology;unsupervised;evolution;information theory;empowerment,-1;-1;23,7;-1;26,m;m,usa,usa,n,
6257,ICLR,2021,Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels,Denis Yarats;Ilya Kostrikov;Rob Fergus,~Denis_Yarats1;~Ilya_Kostrikov1;~Rob_Fergus1,7;7;7;7,5;3;4;5,Accept (Spotlight),0,6,0.0,yes,9/28/20,New York University;University of California Berkeley;New York University,,23;-1;23,26;7;26,m;m,usa,usa,n,2
6258,ICLR,2021,Colorization Transformer,Manoj Kumar;Dirk Weissenborn;Nal Kalchbrenner,~Manoj_Kumar1;~Dirk_Weissenborn1;~Nal_Kalchbrenner1,7;7;5;6,4;4;4;4,Accept (Poster),0,9,0.0,yes,9/28/20,Google;German Research Center for Artificial Intelligence;Google,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8
6259,ICLR,2021,An Unsupervised Deep Learning Approach for Real-World Image Denoising,Dihan Zheng;Sia Huat Tan;Xiaowen Zhang;Zuoqiang Shi;Kaisheng Ma;Chenglong Bao,~Dihan_Zheng1;~Sia_Huat_Tan1;~Xiaowen_Zhang2;~Zuoqiang_Shi1;~Kaisheng_Ma1;~Chenglong_Bao3,8;6;6;7,5;3;4;4,Accept (Poster),0,0,0.0,yes,9/28/20,"Tsinghua University;Tsinghua University, Tsinghua University;Hisilicon;Tsinghua University, Tsinghua University;Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University;Tsinghua University, Tsinghua University",Real-world image denoising;unsupervised image denoising,4;4;-1;4;4;4,20;20;-1;20;20;20,u;m,NAN,NAN,y,11
6260,ICLR,2021,Protecting DNNs from Theft using an Ensemble of Diverse Models,Sanjay Kariyappa;Atul Prakash;Moinuddin K Qureshi,~Sanjay_Kariyappa1;~Atul_Prakash1;~Moinuddin_K_Qureshi2,6;7;5;6,4;3;5;3,Accept (Poster),0,4,0.0,yes,9/28/20,Georgia Institute of Technology;University of Michigan;Georgia Institute of Technology,Model stealing;machine learning security,12;7;12,38;22;38,m;m,usa,usa,n,1;4
6261,ICLR,2021,Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning,Valerie Chen;Abhinav Gupta;Kenneth Marino,~Valerie_Chen2;~Abhinav_Gupta1;~Kenneth_Marino1,7;8;7;5,5;3;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"Carnegie Mellon University;Facebook;School of Computer Science, Carnegie Mellon University",,1;-1;1,28;-1;28,f;m,NAN,NAN,n,3;1;6
6262,ICLR,2021,What Can You Learn From Your Muscles? Learning Visual Representation from Human Interactions,Kiana Ehsani;Daniel Gordon;Thomas Hai Dang Nguyen;Roozbeh Mottaghi;Ali Farhadi,~Kiana_Ehsani1;~Daniel_Gordon1;~Thomas_Hai_Dang_Nguyen1;~Roozbeh_Mottaghi1;~Ali_Farhadi3,6;9;8;4,5;4;4;5,Accept (Poster),0,4,0.0,yes,9/28/20,"Allen Institute for Artificial Intelligence;Department of Computer Science, University of Washington;University of Washington, Seattle;Allen Institute for Artificial Intelligence;University of Washington",representation learning;computer vision,-1;11;11;-1;11,-1;29;29;-1;29,f;m,usa,usa,n,8;2
6263,ICLR,2021,Contextual Dropout: An Efficient Sample-Dependent Dropout Module,XINJIE FAN;Shujian Zhang;Korawat Tanwisuth;Xiaoning Qian;Mingyuan Zhou,~XINJIE_FAN2;~Shujian_Zhang1;korawat.tanwisuth@utexas.edu;~Xiaoning_Qian2;~Mingyuan_Zhou1,7;7;6,4;4;4,Accept (Poster),0,1,0.0,yes,9/28/20,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin;Texas A&M;The University of Texas at Austin",Efficient Inference Methods;Probabilistic Methods;Supervised Deep Networks,-1;-1;-1;46;20,-1;-1;-1;195;43,m;m,NAN,NAN,n,
6264,ICLR,2021,Are Neural Nets Modular? Inspecting Functional Modularity Through Differentiable Weight Masks,R√≥bert Csord√°s;Sjoerd van Steenkiste;J√ºrgen Schmidhuber,~R√≥bert_Csord√°s1;~Sjoerd_van_Steenkiste1;~J√ºrgen_Schmidhuber1,6;8;6;6,4;3;5;3,Accept (Poster),0,18,0.0,yes,9/28/20,IDSIA;Dalle Molle Institute for Artificial Intelligence Research (IDSIA);IDSIA,modularity;systematic generalization;compositionality,-1;-1;-1,-1;-1;-1,m;m,asia,in,n,1
6265,ICLR,2021,On the mapping between Hopfield networks and Restricted Boltzmann Machines,Matthew Smart;Anton Zilman,~Matthew_Smart1;zilmana@physics.utoronto.ca,7;7;10,4;4;4,Accept (Oral),0,5,0.0,yes,9/28/20,University of Toronto;University of Toronto,Hopfield Networks;Restricted Boltzmann Machines;Statistical Physics,18;18,18;18,m;m,canada,ca,n,
6266,ICLR,2021,Conditional Networks,Anthony Ortiz;Kris Sankaran;Olac Fuentes;Christopher Kiekintveld;Pascal Vincent;Yoshua Bengio;Doina Precup,~Anthony_Ortiz1;~Kris_Sankaran1;~Olac_Fuentes1;~Christopher_Kiekintveld2;~Pascal_Vincent1;~Yoshua_Bengio1;~Doina_Precup1,6;3;4;4,4;5;3;4,Reject,0,5,0.0,yes,9/28/20,"Microsoft;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Texas, El Paso;University of Texas at El Paso;University of Montreal;University of Montreal;DeepMind",Conditional Computation;Generalization,-1;128;327;327;128;128;-1,-1;73;-1;862;73;73;-1,m;f,NAN,NAN,n,2;1
6267,ICLR,2021,Bayesian Online Meta-Learning,Pauching Yap;Hippolyt Ritter;David Barber,~Pau_Ching_Yap1;~Hippolyt_Ritter1;~David_Barber1,6;7;5;6,4;4;4;3,Reject,0,14,0.0,yes,9/28/20,University College London;University College London;University College London,Bayesian online learning;few-shot learning;meta-learning,53;53;53,-1;-1;-1,f;m,europe,uk,n,6;11
6268,ICLR,2021,Deep Reinforcement Learning For Wireless Scheduling with Multiclass Services,Apostolos Avranas;Marios Kountouris;Philippe Ciblat,~Apostolos_Avranas1;marios.kountouris@eurecom.fr;~Philippe_Ciblat1,5;3;7;7,3;3;3;4,Reject,0,5,0.0,yes,9/28/20,Eurecom;Eurecom;T√©l√©com Paris,,-1;-1;-1,-1;-1;209,m;m,NAN,NAN,n,
6269,ICLR,2021,Geometry matters: Exploring language examples at the decision boundary,Debajyoti Datta;Shashwat Kumar;Laura Barnes;Tom Fletcher,~Debajyoti_Datta1;sk9epp@virginia.edu;~Laura_Barnes1;~Tom_Fletcher1,5;3;4;5,2;4;5;4,Reject,0,5,0.0,yes,9/28/20,"University of Virginia;University of Virginia;;University of Virginia, Charlottesville;University of Utah",Natural Language Processing;Text Classification;Information Geomtery;Sentiment Analysis,53;53;-1;53;58,117;117;-1;-1;239,m;m,europe,uk,n,3
6270,ICLR,2021,Online Learning of Graph Neural Networks: When Can Data Be Permanently Deleted,Lukas Paul Achatius Galke;Benedikt Franke;Tobias Zielke;Ansgar Scherp,~Lukas_Paul_Achatius_Galke1;benedikt.franke@uni-ulm.de;tobias-1.zielke@uni-ulm.de;~Ansgar_Scherp1,5;5;5;3,4;4;4;5,Reject,0,4,0.0,yes,9/28/20,Kiel University;Ulm University;;;Ulm University,graph neural networks;online learning,263;-1;-1;-1;-1,538;140;-1;-1;140,m;m,europe,tr,n,10
6271,ICLR,2021,Learning Collision-free Latent Space for Bayesian Optimization,Fengxue Zhang;Yair Altas;Louise Fan;Kaustubh Vinchure;Brian Nord;Yuxin Chen,~Fengxue_Zhang1;atlas99@uchicago.edu;siqi@uchicago.edu;vinchure@uchicago.edu;nord@uchicago.edu;~Yuxin_Chen1,4;5;4;3,4;4;4;3,Reject,0,5,0.0,yes,9/28/20,University of Chicago;;;University of Chicago;;;;;University of Chicago,Latent space;Bayesian Optimization;Collision,46;-1;-1;46;-1;-1;-1;-1;46,10;-1;-1;10;-1;-1;-1;-1;10,m;m,usa,usa,y,11;1
6272,ICLR,2021,Latent Causal Invariant Model,Xinwei Sun;Botong Wu;Chang Liu;Xiangyu Zheng;Wei Chen;Tao Qin;Tie-Yan Liu,~Xinwei_Sun1;~Botong_Wu1;~Chang_Liu10;~Xiangyu_Zheng1;~Wei_Chen1;~Tao_Qin1;~Tie-Yan_Liu1,4;6;5;6,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,"Peking University;Peking University, Tsinghua University;Microsoft;Peking University;Microsoft;Tsinghua University;Microsoft",invariance;causality;spurious correlation;out-of-distribution generalization;interpretability;variational auto-encoder,14;4;-1;14;-1;4;-1,23;20;-1;23;-1;20;-1,m;m,NAN,NAN,y,11;1
6273,ICLR,2021,Flow Neural Network for Traffic Flow Modelling in IP Networks,Xiangle Cheng;Yuchen He;Feifei Long;Shihan Xiao;Fenglin Li,~Xiangle_Cheng1;y325he@uwaterloo.ca;longfeifei@huawei.com;xiaoshihan@huawei.com;lifenglin@huawei.com,2;4;3;4,4;4;2;3,Reject,0,1,0.0,yes,9/28/20,Huawei Technologies Ltd.;University of Waterloo;;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Flow neural network;contrastive induction learning;representation learning;spatio-temporal induction,-1;34;-1;-1;-1,-1;232;-1;-1;-1,m;m,NAN,NAN,n,5
6274,ICLR,2021,Generative Adversarial User Privacy in Lossy Single-Server Information Retrieval,Chung-Wei Weng;Yauhen Yakimenka;Hsuan-Yin Lin;Eirik Rosnes;Joerg Kliewer,chungwei@simula.no;yauhen@simula.no;lin@simula.no;~Eirik_Rosnes1;~Joerg_Kliewer1,5;6;6,4;1;3,Reject,0,3,0.0,yes,9/28/20,University of Bergen;Simula UiB;Simula UiB;Simula UiB;New Jersey Institute of Technology,Generative adversarial network;generative adversarial privacy;information-theoretic privacy;compression;private information retrieval;data-driven framework,263;453;453;453;-1,219;-1;-1;-1;570,m;m,NAN,NAN,y,5;4
6275,ICLR,2021,"Triple-Search: Differentiable Joint-Search of Networks, Precision, and Accelerators",Yonggan Fu;Yongan Zhang;Haoran You;Yingyan Lin,~Yonggan_Fu1;~Yongan_Zhang1;~Haoran_You1;~Yingyan_Lin1,6;5;6;5,2;5;3;4,Reject,0,10,0.0,yes,9/28/20,Rice University;Rice University;Rice University;Rice University,neural architecture search;network hardware co-design,92;92;92;92,124;124;124;124,m;f,australasia,au,n,
6276,ICLR,2021,Learning Representations by Contrasting Clusters While Bootstrapping Instances,Junsoo Lee;Hojoon Lee;Inkyu Shin;Jaekyoung Bae;In So Kweon;Jaegul Choo,~Junsoo_Lee1;joonleesky@kaist.ac.kr;~Inkyu_Shin1;storm.b@kakaoenterprise.com;~In_So_Kweon2;~Jaegul_Choo1,4;6;5,5;3;3,Reject,0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;;;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,unsupervised;self-supervised;image clustering;visual representation learning,-1;-1;-1;-1;-1;-1;-1,96;96;96;-1;-1;96;96,m;m,NAN,NAN,n,2
6277,ICLR,2021,The shape and simplicity biases of adversarially robust ImageNet-trained CNNs,Peijie Chen;Chirag Agarwal;Anh Nguyen,peijiechenauburn@gmail.com;~Chirag_Agarwal1;~Anh_Nguyen1,6;5;6;3,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,Auburn University;Harvard University;Auburn University,shape bias;texture bias;interpretability;smoothness;visualization,453;53;453,678;3;678,f;m,usa,usa,n,1;4
6278,ICLR,2021,DISE: Dynamic Integrator Selection to Minimize Forward Pass Time in Neural ODEs,Soyoung Kang;Ganghyeon Park;Kwang-Sung Jun;Noseong Park,sy_k@yonsei.ac.kr;pgh300@yonsei.ac.kr;~Kwang-Sung_Jun1;~Noseong_Park1,4;6;6;5,3;3;3;4,Reject,0,8,0.0,yes,9/28/20,"Yonsei University, Seoul;;;University of Arizona;George Mason University",Neural ODE;DOPRI,150;-1;-1;209;85,-1;-1;-1;124;267,f;m,usa,usa,n,
6279,ICLR,2021,Interpretability Through Invertibility: A Deep Convolutional Network With Ideal Counterfactuals And Isosurfaces,Leon Sixt;Martin Schuessler;Philipp Wei√ü;Tim Landgraf,~Leon_Sixt1;schuessler@tu-berlin.de;philipp@itp.tu-berlin.de;~Tim_Landgraf1,6;6;5;5;6,4;4;5;3;4,Reject,0,9,0.0,yes,9/28/20,Freie Universit√§t Berlin;;;;;Freie Universit√§t Berlin,Interpretable Machine Learning;Counterfactuals;Computer Vision;Human Evaluation;User Study,327;-1;-1;-1;-1;327,-1;-1;-1;-1;-1;-1,m;m,europe,de,n,2;4
6280,ICLR,2021,Adaptive Single-Pass Stochastic Gradient Descent in Input Sparsity Time,Sepideh Mahabadi;David Woodruff;Samson Zhou,mahabadi@ttic.edu;~David_Woodruff1;~Samson_Zhou1,6;6;5;6,3;3;3;3,Reject,0,4,0.0,yes,9/28/20,"Toyota Technological Institute at Chicago;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University",stochastic gradient descent;streaming algorithm;stochastic optimization,-1;1;1,-1;28;28,f;m,NAN,NAN,y,9
6281,ICLR,2021,Counterfactual Thinking for Long-tailed Information Extraction,Guoshun Nan;Jiaqi Zeng;Rui Qiao;Wei Lu,~Guoshun_Nan1;~Jiaqi_Zeng1;rui_qiao@sutd.edu.sg;luwei@sutd.edu.sg,7;3;6;5,3;4;4;5,Reject,0,6,0.0,yes,9/28/20,Singapore University of Technology and Design;Shanghai Jiao Tong University;Singapore University of Technology and Design;Singapore University of Technology and Design,Information Extraction;Natural Language Processing;Long-tailed Classification;Causal Inference,-1;29;-1;-1,-1;100;-1;-1,m;m,NAN,NAN,n,6;2;10
6282,ICLR,2021,EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL,Seyed Kamyar Seyed Ghasemipour;Dale Schuurmans;Shixiang Gu,~Seyed_Kamyar_Seyed_Ghasemipour1;~Dale_Schuurmans1;~Shixiang_Gu1,6;4;6;6,3;4;4;3,Reject,0,7,0.0,yes,9/28/20,Google;University of Alberta;Google,Offline Reinforcement Learning;Off-Policy Reinforcement Learning,-1;110;-1,-1;131;-1,m;m,NAN,NAN,y,5
6283,ICLR,2021,Improving Hierarchical Adversarial Robustness of Deep Neural Networks,Avery Ma;Aladin Virmaux;Kevin Scaman;Juwei Lu,~Avery_Ma1;~Aladin_Virmaux1;~Kevin_Scaman1;~Juwei_Lu2,4;5;5;4,4;4;4;3,Reject,0,4,0.0,yes,9/28/20,University of Toronto;Huawei Technologies Ltd.;INRIA;Huawei Technologies Ltd.,Adversarial Robustness,18;-1;-1;-1,18;-1;-1;-1,m;m,NAN,NAN,n,4
6284,ICLR,2021,Deep Reinforcement Learning With Adaptive Combined Critics,Huihui Zhang;Wu Huang,~Huihui_Zhang1;~Wu_Huang1,3;3;5;3,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,Pennsylvania State University;Sichuan University,overestimation;continuous control;deep reinforcement learning;policy improvement,44;-1,-1;672,f;m,NAN,NAN,y,
6285,ICLR,2021,One Vertex Attack on Graph Neural Networks-based Spatiotemporal Forecasting,Fuqiang Liu;Luis Miranda Moreno;Lijun Sun,~Fuqiang_Liu2;luis.miranda-moreno@mcgill.ca;lijun.sun@mcgill.ca,4;4;8;4,3;5;3;3,Reject,0,5,0.0,yes,9/28/20,McGill University;;;McGill University,adversarial attack;graph neural networks;spatiotemporal forecasting,99;-1;-1;99,40;-1;-1;40,m;m,canada,ca,n,1;10;4
6286,ICLR,2021,A self-explanatory method for the black box problem on discrimination part of CNN,Jinwei Zhao;Qizhou Wang;Wanli Qiu;Guo Xie;Wei Wang;Xinhong Hei;Deyu Meng,~Jinwei_Zhao1;852333436@qq.com;axmaiqiu@foxmail.com;guoxie@xaut.edu.cn;wwang@xaut.edu.cn;heixinhong@xaut.edu.cn;~Deyu_Meng1,3;3;5,4;2;3,Reject,0,3,0.0,yes,9/28/20,Xi‚Äòan University of Technology;;;;;;Xi'an jiaotong university,Convolution neural network;Interpretability performance;Markov random field,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;445,m;m,NAN,NAN,y,1
6287,ICLR,2021,An Efficient Protocol for Distributed Column Subset Selection in the Entrywise $\ell_p$ Norm,Shuli Jiang;Dongyu Li;Irene Mengze Li;Arvind V. Mahankali;David Woodruff,~Shuli_Jiang1;dongyul@cs.cmu.edu;mengzeli@andrew.cmu.edu;~Arvind_V._Mahankali1;~David_Woodruff2,7;6;5,3;4;4,Reject,0,3,0.0,yes,9/28/20,Carnegie Mellon University;;;;;Carnegie Mellon University;Carnegie Mellon University,Column Subset Selection;Distributed Learning,1;-1;-1;-1;-1;1;1,28;-1;-1;-1;-1;28;28,f;m,usa,usa,y,2;1
6288,ICLR,2021,WordsWorth Scores for Attacking CNNs and LSTMs for Text Classification,Nimrah Shakeel,~Nimrah_Shakeel1,4;3;2,4;3;4,Reject,0,3,0.0,yes,9/28/20,Carnegie Mellon University,,1,28,f,usa,usa,n,4
6289,ICLR,2021,GINN: Fast GPU-TEE Based Integrity for Neural Network Training,Aref Asvadishirehjini;Murat Kantarcioglu;Bradley A. Malin,aref@utdallas.edu;~Murat_Kantarcioglu1;~Bradley_A._Malin1,5;7;3;6,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,"University of Texas, Dallas;University of Texas, Dallas;Vanderbilt University Medical Center",Deep Learning;Trusted Execution Environments;Integrity-Preserving Computation;Intel SGX,-1;-1;263,-1;-1;111,m;m,NAN,NAN,y,4
6290,ICLR,2021,Probabilistic Mixture-of-Experts for Efficient Deep Reinforcement Learning,Jie Ren;Yewen Li;Zihan Ding;Wei Pan;Hao Dong,~Jie_Ren4;~Yewen_Li1;~Zihan_Ding1;~Wei_Pan2;~Hao_Dong3,4;6;3;6,4;4;5;4,Reject,0,4,0.0,yes,9/28/20,Xidian University;Xidian University;Princeton University;Delft University of Technology;Peking University,Deep Reinforcement Learning;Sample Efficiency;Gaussian Mixture Models;Mixture-of-Experts,-1;-1;29;-1;14,924;924;9;78;23,m;m,asia,cn,n,
6291,ICLR,2021,SEQUENCE-LEVEL FEATURES: HOW GRU AND LSTM CELLS CAPTURE N-GRAMS,Xiaobing Sun;Wei Lu,~Xiaobing_Sun1;luwei@sutd.edu.sg,4;4;6;3;5,4;2;4;3;4,Reject,0,5,0.0,yes,9/28/20,Singapore University of Technology and Design;Singapore University of Technology and Design,GRU;LSTM;Sequence-level;Features;N-grams,-1;-1,-1;-1,m;m,NAN,NAN,n,3
6292,ICLR,2021,Monotonic Robust Policy Optimization with Model Discrepancy,Yuankun Jiang;Chenglin Li;Junni Zou;Wenrui Dai;Hongkai Xiong,~Yuankun_Jiang1;~Chenglin_Li2;~Junni_Zou1;~Wenrui_Dai1;~Hongkai_Xiong1,6;7;5;4,2;4;4;3,Reject,0,14,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;;Shanghai Jiaotong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Reinforcement Learning;generalization,4;29;-1;29;29;29,20;100;-1;100;100;100,m;m,asia,cn,y,1
6293,ICLR,2021,Expressive yet Tractable Bayesian Deep Learning via Subnetwork Inference,Erik Daxberger;Eric Nalisnick;James Allingham;Javier Antoran;Jos√© Miguel Hern√°ndez-Lobato,~Erik_Daxberger1;~Eric_Nalisnick1;jua23@cam.ac.uk;~Javier_Antoran1;~Jos√©_Miguel_Hern√°ndez-Lobato1,5;5;6;6,5;4;4;4,Reject,0,7,0.0,yes,9/28/20,"University of Cambridge & MPI for Intelligent Systems, T√ºbingen;University of Amsterdam;Google;University of Cambridge;University of Cambridge",,79;128;-1;79;79,6;66;-1;6;6,m;m,europe,uk,n,11
6294,ICLR,2021,Joint Perception and Control as Inference with an Object-based Implementation,Minne Li;Zheng Tian;Pranav Nashikkar;Ian Davies;Ying Wen;Jun Wang,~Minne_Li1;~Zheng_Tian1;pranav.nashikkar.15@ucl.ac.uk;ian.davies.12@ucl.ac.uk;~Ying_Wen1;~Jun_Wang2,4;4;5;4,4;3;4;4,Reject,0,5,0.0,yes,9/28/20,University College London;University College London;;;University College London;Shanghai Jiao Tong University;University College London,model-based reinforcement learning;perception modeling;object-based reinforcement learning,53;53;-1;-1;53;29;53,-1;-1;-1;-1;-1;100;-1,f;m,europe,uk,y,11
6295,ICLR,2021,Differentiable Learning of Graph-like Logical Rules from Knowledge Graphs,Hongzhi Shi;quanming yao;Yong Li,~Hongzhi_Shi1;~quanming_yao1;~Yong_Li3,5;4;3;6,4;3;4;2,Reject,0,6,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;4Paradigm Inc.;Tsinghua University,knowledge graph;logical rules;logical query,4;-1;4,20;-1;20,m;m,asia,cn,n,10
6296,ICLR,2021,Learning Contextual Perturbation Budgets for Training Robust Neural Networks,Jing Xu;Zhouxing Shi;Huan Zhang;Jinfeng Yi;Cho-Jui Hsieh;Liwei Wang,~Jing_Xu4;~Zhouxing_Shi1;~Huan_Zhang1;~Jinfeng_Yi1;~Cho-Jui_Hsieh1;~Liwei_Wang1,5;5;6;6,5;5;2;3,Reject,0,9,0.0,yes,9/28/20,"Peking University;University of California, Los Angeles;Carnegie Mellon University;JD AI Research;Amazon;Peking University",adversarial robustness;certified robustness;certfied robust training,14;-1;1;-1;-1;14,23;15;28;-1;-1;23,u;m,asia,cn,n,4
6297,ICLR,2021,Task Calibration for Distributional Uncertainty in Few-Shot Classification,Sungnyun Kim;Se-Young Yun,~Sungnyun_Kim1;~Se-Young_Yun1,5;4;5;4,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;KAIST,few-shot learning;meta-learning;uncertainty estimation,-1;15,96;96,m;m,asia,in,n,6
6298,ICLR,2021,Unsupervised Discovery of Interpretable Latent Manipulations in Language VAEs,Max Ryabinin;Artem Babenko;Elena Voita,~Max_Ryabinin1;~Artem_Babenko1;~Elena_Voita1,3;3;5;4,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,Yandex;Yandex;University of Edinburgh,interpretability;unsupervised interpretable directions;controllable text generation,-1;-1;29,-1;-1;30,m;f,europe,uk,n,8;5
6299,ICLR,2021,Transfer among Agents: An Efficient Multiagent Transfer Learning Framework,Tianpei Yang;Jianye HAO;Weixun Wang;Hongyao Tang;Zhaopeng Meng;Hangyu Mao;Dong Li;Wulong Liu;Yujing Hu;Yingfeng Chen;Changjie Fan,~Tianpei_Yang1;~Jianye_HAO1;~Weixun_Wang1;~Hongyao_Tang1;~Zhaopeng_Meng1;maohangyu1@huawei.com;lidong106@huawei.com;~Wulong_Liu1;huyujing@corp.netease.com;~Yingfeng_Chen1;~Changjie_Fan1,6;6;6;6;4,5;3;3;3;4,Reject,0,11,0.0,yes,9/28/20,"Tianjin University;Tianjin University;Tianjin University;College of Intelligence and Computing, Tianjin University;;Tianjin University;Peking University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Huawei Noah's Ark Lab;NetEase, Inc.;;University of Science and Technology of China",Multiagent learning;transfer learning;reinforcement learning,-1;-1;-1;-1;-1;-1;14;34;-1;-1;-1;-1,496;496;496;496;-1;496;23;-1;-1;-1;-1;87,f;m,NAN,NAN,n,6
6300,ICLR,2021,Dissecting graph measures performance for node clustering in LFR parameter space,Vladimir Ivashkin;Pavel Chebotarev,~Vladimir_Ivashkin1;pavel4e@gmail.com,6;5;3;4,4;2;5;5,Reject,0,7,0.0,yes,9/28/20,Yandex;Institute of Control Sciences of the Russian Academy of Sciences,graph theory;graph measures;kernel k-means;clustering,-1;-1,-1;-1,m;m,NAN,NAN,n,10
6301,ICLR,2021,Representation and Bias in Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling,Ada Wan,~Ada_Wan1,5;6;4;3,4;4;4;4,Reject,0,15,0.0,yes,9/28/20,University of Zurich,multilinguality;science for NLP;fundamental science in the era of AI/DL;representation learning for language;conditional language modeling;Transformer;Double Descent;non-monotonicity;fairness;meta evaluation;visualization or interpretation of learned representations,128,73,m,europe,ch,n,8;2;7;3;1
6302,ICLR,2021,Balancing training time vs. performance with Bayesian Early Pruning,Mohit Rajpal;Yehong Zhang;Bryan Kian Hsiang Low,~Mohit_Rajpal1;~Yehong_Zhang1;~Bryan_Kian_Hsiang_Low1,5;6;6;7,5;5;3;2,Reject,0,9,0.0,yes,9/28/20,National University of Singapore;Peng Cheng Laboratory;National University of Singapore,Efficient Training;Multi-Output Gaussian Process;Gaussian Process;Bayesian;Single-shot network pruning;Dynamic Sparse Reparameterization;Lottery Ticket Hypothesis,17;-1;17,25;-1;25,m;m,asia,sg,y,11
6303,ICLR,2021,Learning and Generalization in Univariate Overparameterized Normalizing Flows,Kulin Shah;Amit Deshpande;Navin Goyal,~Kulin_Shah1;~Amit_Deshpande1;~Navin_Goyal1,4;5;4;6,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,Microsoft;Microsoft Research;Microsoft,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
6304,ICLR,2021,Regularization Cocktails for Tabular Datasets,Arlind Kadra;Marius Lindauer;Frank Hutter;Josif Grabocka,~Arlind_Kadra1;~Marius_Lindauer1;~Frank_Hutter1;~Josif_Grabocka1,6;6;6;6,4;4;4;5,Reject,0,11,0.0,yes,9/28/20,Universit√§t Freiburg;Leibniz Universit√§t Hannover;University of Freiburg & Bosch;Universit√§t Freiburg,deep learning;regularization;hyperparameter optimization;benchmarks.,-1;-1;150;-1,-1;515;83;-1,m;m,NAN,NAN,n,10
6305,ICLR,2021,On Linear Identifiability of Learned Representations,Geoffrey Roeder;Luke Metz;Diederik P Kingma,~Geoffrey_Roeder1;~Luke_Metz1;~Diederik_P_Kingma1,4;6;7;6,4;3;3;3,Reject,0,9,0.0,yes,9/28/20,"Department of Computer Science, Princeton University;Google;Google",identifiability analysis;deep learning;representation learning;probabilistic discriminative models,29;-1;-1,9;-1;-1,m;m,NAN,NAN,y,
6306,ICLR,2021,A Transformer-based Framework for Multivariate Time Series Representation Learning,George Zerveas;Srideepika Jayaraman;Dhaval Patel;Anuradha Bhamidipaty;Carsten Eickhoff,~George_Zerveas1;j.srideepika@ibm.com;pateldha@us.ibm.com;anubham@us.ibm.com;~Carsten_Eickhoff1,4;4;4;4,4;3;5;4,Reject,0,16,0.0,yes,9/28/20,"Brown University;Department of Computer Science, University of Massachusetts, Amherst;;;International Business Machines;Brown University",transformer;multivariate time series;unsupervised representation learning;deep learning,85;-1;-1;-1;-1;85,61;210;-1;-1;-1;61,m;m,usa,usa,n,8
6307,ICLR,2021,Max-sliced Bures Distance for Interpreting Discrepancies,Austin J. Brockmeier;Claudio Cesar Claros;Carlos H. Mendoza-Cardenas;Y√ºksel Karahan;Matthew S. Emigh;Luis Gonzalo Sanchez Giraldo,~Austin_J._Brockmeier1;cesar@udel.edu;cmendoza@udel.edu;ykarahan@udel.edu;matthew.emigh@navy.mil;~Luis_Gonzalo_Sanchez_Giraldo2,7;5;6,3;3;2,Reject,0,3,0.0,yes,9/28/20,University of Delaware;University of Delaware;;;University of Delaware;;;University of Kentucky,covariance;covariate shift;distance metrics;divergence;generative adversarial networks;interpretable approaches;kernel methods;probability metric;RKHS,209;209;-1;-1;209;-1;-1;209,312;312;-1;-1;312;-1;-1;499,m;m,usa,usa,y,1;5;4
6308,ICLR,2021,Sandwich Batch Normalization,Xinyu Gong;Wuyang Chen;Tianlong Chen;Zhangyang Wang,~Xinyu_Gong1;~Wuyang_Chen1;~Tianlong_Chen1;~Zhangyang_Wang1,5;3;6;5,4;4;5;5,Reject,0,11,0.0,yes,9/28/20,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",normalization,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,n,5;4
6309,ICLR,2021,Explicit Connection Distillation,Lujun Li;Yikai Wang;Anbang Yao;Yi Qian;Xiao Zhou;Ke He,~Lujun_Li1;~Yikai_Wang2;~Anbang_Yao1;~Yi_Qian2;~Xiao_Zhou3;~Ke_He1,7;5;6;5,4;4;3;5,Reject,0,8,0.0,yes,9/28/20,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tsinghua University;Intel;Intel;Intel;Intel",,34;4;-1;-1;-1;-1,-1;20;-1;-1;-1;-1,m;m,NAN,NAN,n,
6310,ICLR,2021,Language Controls More Than Top-Down Attention: Modulating Bottom-Up Visual Processing with Referring Expressions,Ozan Arkan Can;Ilker Kesen;Deniz Yuret,~Ozan_Arkan_Can1;~Ilker_Kesen1;~Deniz_Yuret1,2;4;10;5,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,Koc University;Koc University;Koc University,Referring Expression Understanding;Language-Vision Problems;Grounded Language Understanding,453;453;453,483;483;483,m;m,asia,jp,n,8
6311,ICLR,2021,Zero-shot Fairness with Invisible Demographics,Thomas Kehrenberg;Viktoriia Sharmanska;Myles Scott Bartlett;Novi Quadrianto,~Thomas_Kehrenberg1;~Viktoriia_Sharmanska1;~Myles_Scott_Bartlett1;~Novi_Quadrianto1,6;5;5;4,5;4;3;3,Reject,0,5,0.0,yes,9/28/20,University of Sussex;Imperial College London;University of Sussex;University of Sussex,fairness;missing data;adversary;classification;disentanglement,327;53;327;327,160;11;160;160,m;m,europe,uk,n,8;7
6312,ICLR,2021,On the Effectiveness of Deep Ensembles for Small Data Tasks,Lorenzo Brigato;Luca Iocchi,~Lorenzo_Brigato1;~Luca_Iocchi1,5;4;3;5,5;4;4;5,Reject,0,5,0.0,yes,9/28/20,Sapienza University of Rome;;Sapienza University of Rome,small data;deep learning;ensembles;classification,99;-1;99,216;-1;216,m;m,europe,it,n,
6313,ICLR,2021,A new framework for tensor PCA based on trace invariants,Mohamed Ouerfelli;mohamed Tamaazousti;Vincent Rivasseau,~Mohamed_Ouerfelli1;~mohamed_Tamaazousti1;vincent.rivasseau@gmail.com,5;3;5,2;3;3,Reject,0,6,0.0,yes,9/28/20,"CEA;CEA/LIST/LVIC, The Vision and Content Engineering Laboratory;University Paris Sud",Tensor;Principal Component Analysis;Tensor decomposition;trace invariant,209;-1;-1,969;-1;-1,m;m,NAN,NAN,y,
6314,ICLR,2021,Ablation Path Saliency,Olivier Verdier;Justus Sagem√ºller,~Olivier_Verdier1;~Justus_Sagem√ºller1,4;4;6,4;4;3,Reject,0,5,0.0,yes,9/28/20,Western Norway University of Applied Sciences;Western Norway University of Applied Sciences,image classification;interpretability;feature attribution;saliency;ablation,-1;-1,-1;-1,m;m,NAN,NAN,y,
6315,ICLR,2021,Reconnaissance for reinforcement learning with safety constraints,Shin-ichi Maeda;Hayato Watahiki;Yi Ouyang;Shintarou Okada;Masanori Koyama,~Shin-ichi_Maeda2;~Hayato_Watahiki1;~Yi_Ouyang1;okada@preferred.jp;~Masanori_Koyama1,4;5;7,4;2;3,Reject,0,7,0.0,yes,9/28/20,"Preferred Networks, Inc.;The University of Tokyo;Preferred Networks, Inc.;;;Preferred Networks, Inc.",Reinforcement Learning;Safety constraints;Constrained Markov Decision Process,-1;71;-1;-1;-1;-1,-1;36;-1;-1;-1;-1,m;m,NAN,NAN,y,5
6316,ICLR,2021,Machine Reading Comprehension with Enhanced Linguistic Verifiers,Xianchao Wu,~Xianchao_Wu1,5;7;6;5,3;5;5;4,Reject,0,4,0.0,yes,9/28/20,NVIDIA,machine reading comprehension;BERT;linguistic verifiers;hierarchical attention networks,-1,-1,m,NAN,NAN,n,8
6317,ICLR,2021,Interpretable Relational Representations for Food Ingredient Recommendation Systems,Kana Maruyama;Michael Spranger,~Kana_Maruyama1;~Michael_Spranger2,3;5;7;5,4;5;3;4,Reject,0,0,0.0,yes,9/28/20,Sony AI;Sony AI,Metric Learning;Gastronomy;Memory Network;Knowledge Graph;Interpretable,-1;-1,-1;-1,f;m,NAN,NAN,n,
6318,ICLR,2021,What About Taking Policy as Input of Value Function: Policy-extended Value Function Approximator,Hongyao Tang;Zhaopeng Meng;Jianye HAO;Chen Chen;Daniel Graves;Dong Li;Wulong Liu;Yaodong Yang,~Hongyao_Tang1;~Zhaopeng_Meng1;~Jianye_HAO1;~Chen_Chen3;~Daniel_Graves1;lidong106@huawei.com;~Wulong_Liu1;yang.yaodong@huawei.com,3;7;5;5,5;3;4;4,Reject,0,13,0.0,yes,9/28/20,"College of Intelligence and Computing, Tianjin University;;Tianjin University;Tianjin University;Academy of Mathematics and Systems Science, Chinese Academy of Sciences;Huawei Technologies Ltd.;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Huawei Noah's Ark Lab;Huawei Technologies Ltd.",Reinforcement Learning;Value Function Approximation;Representation Learning,-1;-1;-1;-1;34;-1;34;-1;-1,496;-1;496;496;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6319,ICLR,2021,"Trust, but verify: model-based exploration in sparse reward environments",Konrad Czechowski;Tomasz Odrzyg√≥≈∫d≈∫;Micha≈Ç Izworski;Marek Zbysi≈Ñski;≈Åukasz Kuci≈Ñski;Piotr Mi≈Ço≈õ,~Konrad_Czechowski1;tomaszo@impan.pl;m.izworski@student.uw.edu.pl;marek.zbysinski@gmail.com;~≈Åukasz_Kuci≈Ñski1;~Piotr_Mi≈Ço≈õ1,4;2;6;4,3;4;3;4,Reject,0,4,0.0,yes,9/28/20,University of Warsaw;University of Warsaw;University of Warsaw;University of Warsaw;Institute of Mathematics Polish Academy of Sciences;Polish Academy of Science,reinforcement learning;model-based;exploration;on-line planning;imperfect environment model,128;128;128;128;-1;-1,818;818;818;818;-1;-1,m;m,NAN,NAN,n,10
6320,ICLR,2021,Fine-Tuning Offline Reinforcement Learning with Model-Based Policy Optimization,Adam Villaflor;John Dolan;Jeff Schneider,~Adam_Villaflor1;~John_Dolan1;~Jeff_Schneider1,5;4;3;4;5,4;4;4;4;2,Reject,0,5,0.0,yes,9/28/20,"CMU, Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;School of Computer Science",Offline Reinforcement Learning;Model-Based Reinforcement Learning;Off-policy Reinforcement Learning;uncertainty estimation,1;1;-1,28;28;-1,m;m,NAN,NAN,n,
6321,ICLR,2021,Certified Distributional Robustness via Smoothed Classifiers ,Jungang Yang;Liyao Xiang;Ruidong Chen;Yukun Wang;Wei Wang;Xinbing Wang,~Jungang_Yang2;~Liyao_Xiang1;chenruidong@sjtu.edu.cn;18250763559@sjtu.edu.cn;~Wei_Wang50;~Xinbing_Wang1,2;2;3;6,5;4;4;3,Reject,0,4,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;Huawei Technologies Ltd.;Shanghai Jiao Tong University, Tsinghua University;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology;Shanghai Jiao Tong University",,4;29;-1;4;-1;29,20;100;-1;20;56;100,m;m,asia,cn,y,8;1;4
6322,ICLR,2021,Co-complexity: An Extended Perspective on Generalization Error,Rohan Ghosh;Mehul Motani,~Rohan_Ghosh1;~Mehul_Motani1,4;5;7;4,4;4;4;3,Reject,0,6,0.0,yes,9/28/20,National University of Singapore;National University of Singapore,Generalization;Theoretical Machine Learning;Convolutional Neural Networks,17;17,25;25,m;m,asia,sg,y,1
6323,ICLR,2021,ERMAS: Learning Policies Robust to Reality Gaps in Multi-Agent Simulations,Eric Zhao;Alexander R Trott;Caiming Xiong;Stephan Zheng,~Eric_Zhao1;~Alexander_R_Trott1;~Caiming_Xiong1;~Stephan_Zheng1,6;6;6;7,1;3;3;3,Reject,0,10,0.0,yes,9/28/20,University of California Berkeley;Salesforce Research;Salesforce Research;SalesForce.com,Robustness;Multi-Agent Learning;Sim2Real;Reinforcement Learning,-1;-1;-1;-1,7;-1;-1;-1,m;m,NAN,NAN,n,6
6324,ICLR,2021,Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning,Jun Yan;Mrigank Raman;Tianyu Zhang;Ryan Rossi;Handong Zhao;Sungchul Kim;Nedim Lipka;Xiang Ren,~Jun_Yan5;mt1170736@iitd.ac.in;zhang-ty17@mails.tsinghua.edu.cn;~Ryan_Rossi1;~Handong_Zhao3;sukim@adobe.com;lipka@adobe.com;~Xiang_Ren1,7;6;5,3;4;3,Reject,0,15,0.0,yes,9/28/20,"University of Southern California;Indian Institute of Technology Delhi, Dhirubhai Ambani Institute Of Information and Communication Technology;;;Adobe Research;Adobe Systems;;;;;University of Southern California",,37;-1;-1;-1;-1;-1;-1;-1;-1;-1;37,53;-1;-1;-1;-1;-1;-1;-1;-1;-1;53,m;m,usa,usa,n,3;10
6325,ICLR,2021,Graph Joint Attention Networks,Tiantian He;Lu Bai;Yew-Soon Ong,~Tiantian_He1;bailu@ntu.edu.sg;~Yew-Soon_Ong1,4;5;5;7,5;3;4;4,Reject,0,11,0.0,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University,Graph attention networks;Joint attention mechanism;Graph transductive learning,44;44;44,47;47;47,m;m,asia,sg,y,8;1;10
6326,ICLR,2021,To Learn Effective Features: Understanding the Task-Specific Adaptation of MAML,Zhijie Lin;Zhou Zhao;Zhu Zhang;Huai Baoxing;Jing Yuan,~Zhijie_Lin1;~Zhou_Zhao2;~Zhu_Zhang3;huaibaoxing@huawei.com;nicholas.yuan@huawei.com,5;4;5;3,3;3;4;5,Reject,0,6,0.0,yes,9/28/20,Zhejiang University;Zhejiang University;Alibaba Group;;Huawei,Meta-Learning;Few-Shot Learning;Meta-initialization;Task-specific Adaptation,42;42;-1;-1;-1,94;94;-1;-1;-1,m;m,NAN,NAN,n,6
6327,ICLR,2021,Adversarial Problems for Generative Networks,Kalliopi Basioti;George V. Moustakides,~Kalliopi_Basioti1;moustaki@upatras.gr,7;4;6;4,3;3;4;4,Reject,0,4,0.0,yes,9/28/20,Rutgers University;Rutgers University,generative networks;adversarial generative networks,29;29,-1;-1,f;m,usa,usa,y,5;4
6328,ICLR,2021,Revisiting Prioritized Experience Replay: A Value Perspective,Ang A. Li;Zongqing Lu;Chenglin Miao,amazingang@pku.edu.cn;~Zongqing_Lu2;chenglin.miao@pku.edu.cn,4;5;3;6,4;4;4;3,Reject,0,5,0.0,yes,9/28/20,Peking University;Peking University;;Peking University,,14;14;-1;14,23;23;-1;23,m;m,asia,cn,y,1
6329,ICLR,2021,"On Episodes, Prototypical Networks, and Few-Shot Learning",Steinar Laenen;Luca Bertinetto,~Steinar_Laenen1;~Luca_Bertinetto1,5;4;7;5,4;5;5;3,Reject,0,15,0.0,yes,9/28/20,FiveAI;FiveAI,few-shot learning;meta-learning;metric learning;deep learning,-1;-1,-1;-1,m;m,NAN,NAN,n,6
6330,ICLR,2021,"Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search",Gyuwan Kim;Kyunghyun Cho,~Gyuwan_Kim1;~Kyunghyun_Cho1,5;5;4;6,4;4;4;5,Reject,0,5,0.0,yes,9/28/20,"Clova AI, NAVER Corp.;New York University",transformer;efficiency;anytime prediction;sequence length;evolutionary search,-1;23,-1;26,m;m,usa,usa,n,8;3
6331,ICLR,2021,Ensemble-based Adversarial Defense Using Diversified Distance Mapping,Ehsan Kazemi;Mohamed E. Hussein;Wael AbdAlmgaeed,~Ehsan_Kazemi3;~Mohamed_E._Hussein1;~Wael_AbdAlmgaeed1,4;5;5;5,3;3;3;4,Reject,0,0,0.0,yes,9/28/20,University of Central Florida;USC/ISI;University of Southern California,adversarial machine learning;ensemble;mahalanobis distance,71;-1;37,633;-1;53,m;m,usa,usa,n,4
6332,ICLR,2021,Approximation Algorithms for Sparse Principal Component Analysis,Agniva Chowdhury;Petros Drineas;David Woodruff;Samson Zhou,~Agniva_Chowdhury1;~Petros_Drineas1;~David_Woodruff2;~Samson_Zhou1,4;5;4;7,3;3;3;4,Reject,0,4,0.0,yes,9/28/20,"Purdue University;Purdue University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University",Sparse PCA;Principal component analysis;Randomized linear algebra;Singular value decomposition,23;23;1;1,94;94;28;28,m;m,NAN,NAN,y,
6333,ICLR,2021,Neuron Activation Analysis for Multi-Joint Robot Reinforcement Learning,Benedikt Feldotto;Heiko Lengenfelder;Alois Knoll,~Benedikt_Feldotto1;heiko.lengenfelder@tum.de;~Alois_Knoll1,5;4;5,4;4;3,Reject,0,0,0.0,yes,9/28/20,Technical University Munich;;;TU Munich,Reinforcement Learning;Machine Learning;Robot Motion Learning;DQN;Robot Manipulator;Target Reaching;Network Pruning,-1;-1;-1;58,-1;-1;-1;32,m;m,europe,de,n,
6334,ICLR,2021,ItNet: iterative neural networks for fast and efficient anytime prediction,Thomas Pfeil,~Thomas_Pfeil1,4;4;3;4,4;2;3;4,Reject,0,12,0.0,yes,9/28/20,Bosch,efficient deep neural network;semantic segmentation;parameter sharing;anytime prediction;tiny network graph;massively parallel hardware systems;recurrent convolutional network,-1,285,m,NAN,NAN,n,2;10
6335,ICLR,2021,Deep Graph Neural Networks with Shallow Subgraph Samplers,Hanqing Zeng;Muhan Zhang;Yinglong Xia;Ajitesh Srivastava;Rajgopal Kannan;Viktor Prasanna;Long Jin;Andrey Malevich;Ren Chen,~Hanqing_Zeng1;~Muhan_Zhang1;yxia@fb.com;~Ajitesh_Srivastava1;rajgopak@usc.edu;~Viktor_Prasanna1;longjin@fb.com;amalevich@fb.com;renchen@fb.com,5;5;7;6,4;2;3;4,Reject,0,14,0.0,yes,9/28/20,University of Southern California;Peking University;University of Southern California;University of Southern California;DoD HPCMP;University of Southern California;Facebook;Facebook;University of Southern California,Graph Neural Networks;Graph Sampling;Network Embedding,37;14;37;37;-1;37;-1;-1;37,53;23;53;53;-1;53;-1;-1;53,m;m,usa,usa,y,10
6336,ICLR,2021,Active Deep Probabilistic Subsampling,Hans van Gorp;Iris A.M. Huijben;Bastiaan S. Veeling;Nicola Pezzotti;Ruud Van Sloun,~Hans_van_Gorp1;~Iris_A.M._Huijben1;~Bastiaan_S._Veeling1;~Nicola_Pezzotti2;~Ruud_Van_Sloun1,6;6;6,4;3;4,Reject,0,8,0.0,yes,9/28/20,Eindhoven University of Technology;Eindhoven University of Technology;Google;Eindhoven University of Technology;Eindhoven University of Technology,Compressed Sensing;subsampling;active acquisition;accelerated MRI,-1;-1;-1;-1;-1,186;186;-1;186;186,m;m,NAN,NAN,n,
6337,ICLR,2021,BDS-GCN: Efficient Full-Graph Training of Graph Convolutional Nets with Partition-Parallelism and Boundary Sampling,Cheng Wan;Youjie Li;Nam Sung Kim;Yingyan Lin,~Cheng_Wan2;~Youjie_Li1;~Nam_Sung_Kim3;~Yingyan_Lin1,4;4;6;6,5;5;4;4,Reject,0,6,0.0,yes,9/28/20,"Rice University;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Rice University",Graph Neural Networks;Graph Convolutional Networks;Full-Graph Training;Large-Graph Training;Distributed Training;Partition Parallelism;Sampling,92;-1;-1;92,124;-1;-1;124,m;f,australasia,au,n,10
6338,ICLR,2021,Meta-Learning Bayesian Neural Network Priors Based on PAC-Bayesian Theory,Jonas Rothfuss;Martin Josifoski;Andreas Krause,~Jonas_Rothfuss1;martin.josifoski@epfl.ch;~Andreas_Krause1,7;4;7;6,2;4;4;4,Reject,0,10,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology,meta-learning;life-long learning;transfer;bayesian neural networks;prior;few-shot learning;pac-bayes;generalization bound,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,6;11;1
6339,ICLR,2021,Feature Integration and Group Transformers for Action Proposal Generation,He-Yen Hsieh;Ding-Jie Chen;Tung-Ying Lee;Tyng-Luh Liu,~He-Yen_Hsieh1;~Ding-Jie_Chen1;rilylee@berry-ai.com;~Tyng-Luh_Liu1,5;5;5;6,3;3;5;4,Reject,0,4,0.0,yes,9/28/20,"IIS, Academia Sinica;Academia Sinica;;;IIS/Academia Sinica",temporal action proposal;transformer;video analysis,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;m,NAN,NAN,n,8
6340,ICLR,2021,Offline Meta Learning of Exploration,Ron Dorfman;Aviv Tamar,~Ron_Dorfman2;~Aviv_Tamar2,6;7;5;6,4;4;3;3,Reject,0,10,0.0,yes,9/28/20,"Technion, Technion;Technion, Technion",Meta-RL;Offline RL;Bayesian RL,29;29,-1;-1,m;m,NAN,NAN,y,6;11
6341,ICLR,2021,Implicit Acceleration of Gradient Flow in Overparameterized Linear Models,Salma Tarmoun;Guilherme Fran√ßa;Benjamin David Haeffele;Rene Vidal,~Salma_Tarmoun1;~Guilherme_Fran√ßa1;~Benjamin_David_Haeffele1;~Rene_Vidal1,5;6;7;6,4;3;5;4,Reject,0,4,0.0,yes,9/28/20,Johns Hopkins University;;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,,71;-1;71;71;71,12;-1;12;12;12,f;m,usa,usa,y,1
6342,ICLR,2021,Improving Model Robustness with Latent Distribution Locally and Globally,Zhuang QIAN;Shufei Zhang;Kaizhu Huang;Qiufeng Wang;Rui Zhang;Xinping Yi,~Zhuang_QIAN1;~Shufei_Zhang1;~Kaizhu_Huang1;~Qiufeng_Wang2;~Rui_Zhang10;xinping.yi@liverpool.ac.uk,4;7;7;5,4;2;4;3,Reject,0,9,0.0,yes,9/28/20,Xi'an Jiaotong-Liverpool University;Xi'an Jiao-Tong Liverpool University;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University;University of Liverpool,adversarial example;robustness;data manifold;adversarial training,-1;-1;-1;-1;-1;110,608;-1;608;608;608;163,m;m,europe,uk,n,4
6343,ICLR,2021,Sparsifying Networks via Subdifferential Inclusion,Sagar Verma;Jean-Christophe Pesquet,~Sagar_Verma1;~Jean-Christophe_Pesquet1,7;9;5;5,5;3;2;3,Reject,0,6,0.0,yes,9/28/20,CentraleSupelec;CentraleSupelec,neural networks;pruning after training;weight pruning;proximal operator;fixed point iteration,-1;-1,578;578,m;m,NAN,NAN,y,3
6344,ICLR,2021,Learning Binary Trees via Sparse Relaxation,Valentina Zantedeschi;Matt Kusner;Vlad Niculae,~Valentina_Zantedeschi2;~Matt_Kusner1;~Vlad_Niculae2,4;7;3;6,4;3;3;4,Reject,0,8,0.0,yes,9/28/20,INRIA;University College London;University of Amsterdam,optimization;binary trees,-1;53;128,-1;-1;66,f;m,europe,nl,y,
6345,ICLR,2021,Reducing the number of neurons of Deep ReLU Networks based on the current theory of Regularization,Jakob Heiss;Alexis Stockinger;Josef Teichmann,~Jakob_Heiss1;~Alexis_Stockinger1;josef.teichmann@math.ethz.ch,2;2;3;2;4,5;4;4;5;4,Reject,0,10,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Reduction;Compression;Regularization;Theory;Pruning;Deep;Interpretability;Generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
6346,ICLR,2021,FTSO: Effective NAS via First Topology Second Operator,Likang Wang;Lei Chen,~Likang_Wang1;~Lei_Chen7,5;4;3,3;4;5,Reject,0,6,0.0,yes,9/28/20,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,Neural Architecture Search;DARTS,-1;-1,56;56,u;m,NAN,NAN,n,
6347,ICLR,2021,Adaptive Gradient Methods Can Be Provably Faster than SGD with Random Shuffling,Xunpeng Huang;Vicky Jiaqi Zhang;Hao Zhou;Lei Li,~Xunpeng_Huang1;~Vicky_Jiaqi_Zhang2;zhouhao.nlp@bytedance.com;~Lei_Li11,4;4;7;3,4;4;4;4,Reject,0,15,0.0,yes,9/28/20,University of Science and Technology of China;Massachusetts Institute of Technology;Bytedance;ByteDance AI Lab,,-1;5;-1;-1,87;4;-1;-1,u;m,NAN,NAN,y,1;9
6348,ICLR,2021,"High-Likelihood Area Matters --- Rewarding Correct,Rare Predictions Under Imbalanced Distributions",guangxiang zhao;Lei Li;Xuancheng Ren;Xu Sun;Bin He,~guangxiang_zhao2;lilei@stu.pku.edu.cn;~Xuancheng_Ren1;~Xu_Sun1;hebin.nlp@huawei.com,5;5;5;4,3;5;3;3,Reject,0,6,0.0,yes,9/28/20,Peking University;Peking University;Peking University;Peking University;Harbin Institute of Technology,classification;imbalance;long-tailed;likelihood;focal loss,14;14;14;14;150,23;23;23;23;416,m;m,asia,cn,n,
6349,ICLR,2021,Density estimation on low-dimensional manifolds: an inflation-deflation approach,Christian Horvat,~Christian_Horvat1,7;6;6;5,2;3;3;4,Reject,0,4,0.0,yes,9/28/20,Departmen of Physiology,Normalizing Flow;Density Estimation;low-dimensional manifolds;noise;normal space,-1,-1,m,NAN,NAN,y,
6350,ICLR,2021,Cooperating RPN's Improve Few-Shot Object Detection,Weilin Zhang;Yu-Xiong Wang;David Forsyth,~Weilin_Zhang1;~Yu-Xiong_Wang1;~David_Forsyth1,3;5;6;7,4;4;5;3,Reject,0,8,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;School of Computer Science, Carnegie Mellon University;University of Illinois, Urbana-Champaign",Few-shot learning;Object detection,-1;1;-1,-1;28;-1,f;m,usa,usa,n,6;2
6351,ICLR,2021,Differentiable Combinatorial Losses through Generalized Gradients of Linear Programs,Xi Gao;Han Zhang;Aliakbar Panahi;Tom Arodz,gaox2@vcu.edu;~Han_Zhang6;~Aliakbar_Panahi1;~Tom_Arodz1,3;7;6;8;5,5;4;3;3;4,Reject,0,5,0.0,yes,9/28/20,Virginia Commonwealth University;Virginia Commonwealth University;Virginia Commonwealth University;Virginia Commonwealth University,combinatorial optimization;linear programs;generalized gradient,263;263;263;263,-1;-1;-1;-1,u;m,usa,usa,y,10;9
6352,ICLR,2021,On the Explicit Role of Initialization on the Convergence and Generalization Properties of Overparametrized Linear Networks,Hancheng Min;Salma Tarmoun;Rene Vidal;Enrique Mallada,~Hancheng_Min1;~Salma_Tarmoun1;~Rene_Vidal1;~Enrique_Mallada1,3;6;5;9,5;4;4;4,Reject,0,5,0.0,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,,71;71;71;71,12;12;12;12,m;m,usa,usa,y,1;9
6353,ICLR,2021,A Distributional Perspective on Actor-Critic Framework,Daniel Wontae Nam;Younghoon Kim;Chan Youn Park,~Daniel_Wontae_Nam1;~Younghoon_Kim1;~Chan_Youn_Park1,6;5;5;7,2;5;4;5,Reject,0,18,0.0,yes,9/28/20,KC Machine Learning Lab;KC Machine Learning Lab;Rutgers University,Value distribution learning;reinforcement learning;deep learning;distributional reinforcement learning;distributional actor-critic,-1;-1;29,-1;-1;-1,m;m,usa,usa,n,1
6354,ICLR,2021,Hyperparameter Transfer Across Developer Adjustments,Danny Stoll;J√∂rg K.H. Franke;Diane Wagner;Simon Selg;Frank Hutter,~Danny_Stoll1;~J√∂rg_K.H._Franke1;wagnerd@cs.uni-freiburg.de;selgs@cs.uni-freiburg.de;~Frank_Hutter1,5;5;6;5,4;4;4;4,Reject,0,23,0.0,yes,9/28/20,"Universit√§t Freiburg;Universit√§t Freiburg;University of Freiburg, Universit√§t Freiburg;;;University of Freiburg & Bosch",Meta Learning;Hyperparameter Optimization;Transfer Learning,-1;-1;150;-1;-1;150,-1;-1;83;-1;-1;83,m;m,NAN,NAN,n,
6355,ICLR,2021,Learned ISTA with Error-based Thresholding for Adaptive Sparse Coding,Li Ziang;Wu Kailun;Yiwen Guo;Changshui Zhang,~Li_Ziang1;~Wu_Kailun1;~Yiwen_Guo1;~Changshui_Zhang2,5;6;6;7,4;1;5;3,Reject,0,9,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Alibaba Group;ByteDance;Tsinghua University",Sparse coding;Learned ISTA;Convergence Analysis,4;-1;-1;4,20;-1;-1;20,f;m,asia,cn,y,1
6356,ICLR,2021,Reducing Implicit Bias in Latent Domain Learning,Lucas Deecke;Timothy Hospedales;Hakan Bilen,~Lucas_Deecke1;~Timothy_Hospedales1;~Hakan_Bilen1,5;6;4;6,4;2;4;3,Reject,0,9,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh;University of Edinburgh,Latent Domain Learning;CNN Architectures,29;29;29,30;30;30,m;m,europe,uk,n,
6357,ICLR,2021,Iterative convergent computation is not a useful inductive bias for ResNets,Samuel Lippl;Benjamin Peters;Nikolaus Kriegeskorte,~Samuel_Lippl1;benjamin.peters@columbia.edu;~Nikolaus_Kriegeskorte3,5;5;6;5,4;4;4;3,Reject,0,11,0.0,yes,9/28/20,Columbia University;;Columbia University;Columbia University,Residual neural networks;Recurrent neural networks;Computer vision,23;-1;23;23,17;-1;17;17,m;m,usa,usa,n,2
6358,ICLR,2021,Deep Coherent Exploration For Continuous Control,Yijie Zhang;Herke van Hoof,~Yijie_Zhang1;~Herke_van_Hoof4,4;7;4;7,4;2;3;3,Reject,0,6,0.0,yes,9/28/20,University of Copenhagen;University of Amsterdam,reinforcement learning;exploration;latent variable models,92;128,84;66,m;m,europe,nl,n,
6359,ICLR,2021,Revisiting Explicit Regularization in Neural Networks for Reliable Predictive Probability,Taejong Joo;Uijung Chung,~Taejong_Joo1;~Uijung_Chung1,5;4;5;5;3,4;4;3;3;3,Reject,0,6,0.0,yes,9/28/20,ESTsoft;ESTsoft,deep learning;predictive uncertainty;explicit regularization,-1;-1,-1;-1,m;m,NAN,NAN,n,11;1
6360,ICLR,2021,Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural Networks via Bitwise Regularization,Jung Hyun Lee;Jihun Yun;Sung Ju Hwang;Eunho Yang,~Jung_Hyun_Lee1;~Jihun_Yun2;~Sung_Ju_Hwang1;~Eunho_Yang1,5;6;7,4;4;2,Reject,0,15,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology,Quantization;Compression;Efficient Inference;Deep Learning,-1;-1;-1;-1,96;96;96;-1,u;m,NAN,NAN,n,
6361,ICLR,2021,Learning Causal Semantic Representation for Out-of-Distribution Prediction,Chang Liu;Xinwei Sun;Jindong Wang;Tao Li;Tao Qin;Wei Chen;Tie-Yan Liu,~Chang_Liu10;~Xinwei_Sun1;~Jindong_Wang1;~Tao_Li9;~Tao_Qin1;~Wei_Chen1;~Tie-Yan_Liu1,6;5;7,3;3;3,Reject,0,5,0.0,yes,9/28/20,Microsoft;Peking University;Microsoft Research;Peking University;Tsinghua University;Microsoft;Microsoft,out-of-distribution;causality;latent variable model;generative model;variational auto-encoder;domain adaptation,-1;14;-1;14;4;-1;-1,-1;23;-1;23;20;-1;-1,m;m,NAN,NAN,y,10;1;5
6362,ICLR,2021,TEAC: Intergrating Trust Region and Max Entropy Actor Critic for Continuous Control,Hongyu Zang;Xin Li;Li Zhang;Peiyao Zhao;Mingzhong Wang,~Hongyu_Zang1;~Xin_Li31;~Li_Zhang18;~Peiyao_Zhao1;~Mingzhong_Wang1,5;5;5;7,4;3;2;1,Reject,0,9,0.0,yes,9/28/20,Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology;University of the Sunshine Coast,Reinforcement Learning;Trust region methods;Maximum Entropy Reinforcement Learning;Deep Reinforcement Learning,-1;-1;-1;-1;-1,584;584;584;584;678,m;m,NAN,NAN,n,1
6363,ICLR,2021,Transferable Recognition-Aware Image Processing,Zhuang Liu;Tinghui Zhou;Hung-Ju Wang;Zhiqiang Shen;Bingyi Kang;Evan Shelhamer;Trevor Darrell,~Zhuang_Liu1;~Tinghui_Zhou1;~Hung-Ju_Wang1;~Zhiqiang_Shen1;~Bingyi_Kang1;~Evan_Shelhamer2;~Trevor_Darrell2,5;6;5,4;3;4,Reject,0,6,0.0,yes,9/28/20,University of California Berkeley;;University of California Berkeley;Mohamed bin Zayed University of Artificial Intelligence;National University of Singapore;DeepMind;Electrical Engineering & Computer Science Department,Image processing;Image recognition;Transferability;Decision Boundary,-1;-1;-1;-1;17;-1;-1,7;-1;7;874;25;-1;-1,m;m,NAN,NAN,n,
6364,ICLR,2021,ABS: Automatic Bit Sharing for Model Compression,Jing Liu;Bohan Zhuang;Peng Chen;Yong Guo;Chunhua Shen;Jianfei Cai;Mingkui Tan,~Jing_Liu8;~Bohan_Zhuang1;~Peng_Chen2;~Yong_Guo1;~Chunhua_Shen1;~Jianfei_Cai1;~Mingkui_Tan2,6;4;6,4;4;3,Reject,0,6,0.0,yes,9/28/20,Monash University;Monash University;The University of Adelaide;South China University of Technology;University of Adelaide;Monash University;South China University of Technology,Quantization;Pruning;Model Compression;AutoML,92;92;110;-1;110;92;-1,64;64;118;411;118;64;411,m;m,NAN,NAN,n,
6365,ICLR,2021,Cubic Spline Smoothing Compensation for Irregularly Sampled Sequences,Jing Shi;Jing Bi;Yingru Liu;Chenliang Xu,~Jing_Shi1;~Jing_Bi1;~Yingru_Liu1;~Chenliang_Xu1,7;7;5;5,5;3;5;3,Reject,0,4,0.0,yes,9/28/20,"University of Rochester;University of Rochester;State University of New York, Stony Brook;University of Rochester",Neural Ordinary Differential Equations;Cubic Spline Interpolation;Irregular Time Series,110;110;-1;110,147;147;-1;147,m;m,europe,uk,y,
6366,ICLR,2021,Differentiable Spatial Planning using Transformers,Devendra Singh Chaplot;Deepak Pathak;Jitendra Malik,~Devendra_Singh_Chaplot2;~Deepak_Pathak1;~Jitendra_Malik2,5;4;6;7,4;5;3;3,Reject,0,5,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;UC Berkeley,Planning;Spatial planning;Path planning;Navigation;Manipulation;Robotics,1;1;-1,28;28;-1,m;m,NAN,NAN,n,8;1
6367,ICLR,2021,Iterative Image Inpainting with Structural Similarity Mask for Anomaly Detection,Hitoshi Nakanishi;Masahiro Suzuki;Yutaka Matsuo,~Hitoshi_Nakanishi1;~Masahiro_Suzuki1;~Yutaka_Matsuo1,4;2;5;6,4;5;3;1,Reject,0,4,0.0,yes,9/28/20,"The University of Tokyo, Tokyo Institute of Technology;The University of Tokyo, Tokyo Institute of Technology;The University of Tokyo",anomaly detection;unsupervised learning;structural similarity;generative adversarial network;deep learning,71;71;71,36;36;36,m;m,NAN,NAN,n,
6368,ICLR,2021,Uncertainty Calibration Error: A New Metric for Multi-Class Classification,Max-Heinrich Laves;Sontje Ihler;Karl-Philipp Kortmann;Tobias Ortmaier,~Max-Heinrich_Laves1;~Sontje_Ihler1;kortmann@imes.uni-hannover.de;ortmaier@imes.uni-hannover.de,5;6;4;4,3;3;3;4,Reject,0,18,0.0,yes,9/28/20,Leibniz Universit√§t Hannover;Leibniz University Hannover;Institute of Mechatronic Systems;Institute of Mechatronic Systems,variational inference;uncertainty;calibration;classification,-1;-1;-1;-1,515;515;-1;-1,m;m,NAN,NAN,y,11
6369,ICLR,2021,Generalizing and Tensorizing Subgraph Search in the Supernet,Hansi Yang;quanming yao,~Hansi_Yang1;~quanming_yao1,5;4;5;5,3;5;3;3,Reject,0,4,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;4Paradigm Inc.",deep learning;neural architecture search;tensor decomposition,4;-1,20;-1,u;m,NAN,NAN,y,2;3;10
6370,ICLR,2021,"Language-Mediated, Object-Centric Representation Learning",Ruocheng Wang;Jiayuan Mao;Samuel Gershman;Jiajun Wu,~Ruocheng_Wang2;~Jiayuan_Mao1;~Samuel_Gershman1;~Jiajun_Wu1,4;5;5;4,4;5;4;4,Reject,0,12,0.0,yes,9/28/20,Stanford University;Massachusetts Institute of Technology;Harvard University;Stanford University,Object-Centric Representation Learning;Concept Learning,5;5;53;5,2;4;3;2,m;m,usa,usa,n,8;2
6371,ICLR,2021,Non-decreasing Quantile Function Network with Efficient Exploration for Distributional Reinforcement Learning,Fan Zhou;Zhoufan Zhu;Qi Kuang;Liwen Zhang,~Fan_Zhou7;~Zhoufan_Zhu1;~Qi_Kuang1;~Liwen_Zhang3,6;5;4;6,5;4;4;5,Reject,0,7,0.0,yes,9/28/20,Shanghai University of Finance and Economics;Shanghai University of Finance and Economics;Shanghai University of Finance and Economics;Shanghai University of Finance and Economics,Non-decreasing Quantile Function;Distributional Reinforcement Learning;Distributional Prediction Error;Exploration,-1;-1;-1;-1,818;818;818;818,m;m,NAN,NAN,y,
6372,ICLR,2021,Unsupervised Class-Incremental Learning through Confusion,Shivam Khare;Kun Cao;James Matthew Rehg,~Shivam_Khare1;~Kun_Cao2;~James_Matthew_Rehg1,3;3;4;6,3;2;4;4,Reject,0,4,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Incremental Learning;Unsupervised Learning;Continual Learning;Novelty Detection;Out-of-Distribution Detection,12;12;12,38;38;38,m;m,usa,usa,n,
6373,ICLR,2021,Shuffle to Learn: Self-supervised learning from permutations via differentiable ranking,Andrew N Carr;Quentin Berthet;Mathieu Blondel;Olivier Teboul;Neil Zeghidour,~Andrew_N_Carr1;~Quentin_Berthet2;~Mathieu_Blondel1;~Olivier_Teboul2;~Neil_Zeghidour1,4;4;4,2;4;4,Reject,0,0,0.0,yes,9/28/20,Brigham Young University;Google;Google;Google;Google,,263;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
6374,ICLR,2021,InstantEmbedding: Efficient Local Node Representations,Stefan Postavaru;Anton Tsitsulin;Filipe Miguel Goncalves de Almeida;Yingtao Tian;Silvio Lattanzi;Bryan Perozzi,~Stefan_Postavaru1;~Anton_Tsitsulin1;~Filipe_Miguel_Goncalves_de_Almeida1;~Yingtao_Tian1;~Silvio_Lattanzi1;~Bryan_Perozzi1,4;4;6;6,3;5;4;3,Reject,0,7,0.0,yes,9/28/20,Google;Google;Google;Google;Google;Google,Node Embedding;Structural Graph Representations;Graph Embedding;Local Algorithms,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6375,ICLR,2021,Global Self-Attention Networks for Image Recognition,Zhuoran Shen;Irwan Bello;Raviteja Vemulapalli;Xuhui Jia;Ching-Hui Chen,~Zhuoran_Shen1;~Irwan_Bello1;~Raviteja_Vemulapalli1;~Xuhui_Jia1;~Ching-Hui_Chen2,5;4;5;4,3;4;5;5,Reject,0,15,0.0,yes,9/28/20,Google Research;Google;Google;The University of Hong Kong;Google,self-attention;neural network architecture;image classification;semantic segmentation,-1;-1;-1;99;-1,-1;-1;-1;39;-1,m;u,NAN,NAN,n,8;2
6376,ICLR,2021,Neural Architecture Search of SPD Manifold Networks,Rhea Sanjay Sukthanker;Zhiwu Huang;Suryansh Kumar;Erik Goron;Yan Wu;Luc Van Gool,~Rhea_Sanjay_Sukthanker1;~Zhiwu_Huang1;~Suryansh_Kumar1;~Erik_Goron1;~Yan_Wu4;~Luc_Van_Gool1,6;4;4;7,5;5;3;4,Reject,0,11,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology (ETH Zurich);Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;KTH,Neural Architecture Search;AutoML,-1;9;-1;-1;-1;174,-1;14;-1;-1;-1;239,f;m,asia,in,n,
6377,ICLR,2021,Identifying Informative Latent Variables Learned by GIN via Mutual Information,Chen Zhang;Yitong Sun;Mingtian Zhang,~Chen_Zhang6;~Yitong_Sun1;~Mingtian_Zhang1,6;5;5;6;4,2;3;3;4;3,Reject,0,7,0.0,yes,9/28/20,Huawei Technologies R&D (UK) Ltd.;University of Michigan;University College London,,-1;7;53,-1;22;-1,m;m,europe,uk,y,1;4
6378,ICLR,2021,Distribution-Based Invariant Deep Networks for Learning Meta-Features,Gwendoline de Bie;Herilalaina Rakotoarison;Gabriel Peyr√©;Mich√®le Sebag,~Gwendoline_de_Bie1;~Herilalaina_Rakotoarison1;~Gabriel_Peyr√©2;~Mich√®le_Sebag1,6;5;6;7,4;2;3;3,Reject,0,8,0.0,yes,9/28/20,√âcole normale sup√©rieure;INRIA;ENS;Universit√© Paris-Sud,invariant neural networks;universal approximation;meta-feature learning,-1;-1;92;-1,271;-1;62;-1,f;f,NAN,NAN,y,
6379,ICLR,2021,Differential-Critic GAN: Generating What You Want by a Cue of Preferences,Yinghua Yao;Yuangang Pan;Ivor Tsang;Xin Yao,~Yinghua_Yao1;~Yuangang_Pan2;~Ivor_Tsang1;~Xin_Yao1,5;5;5;5,4;4;4;4,Reject,0,12,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;Southern University of Science and Technology,GAN;user-desired data distribution;user preference;critic,71;71;71;-1,160;160;160;252,u;m,NAN,NAN,n,5;4
6380,ICLR,2021,Straight to the Gradient: Learning to Use Novel Tokens for Neural Text Generation,Xiang Lin;SIMENG HAN;Shafiq Joty,~Xiang_Lin2;~SIMENG_HAN1;~Shafiq_Joty1,4;6;5;6,4;4;5;3,Reject,0,0,0.0,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;SalesForce.com,text generation;text degeneration;language model;summarization;image captioning,44;44;-1,47;47;-1,m;m,NAN,NAN,n,3
6381,ICLR,2021,Model information as an analysis tool in deep learning,Xiao Zhang;Di Hu;Xingjian Li;Dejing Dou;Ji Wu,~Xiao_Zhang9;~Di_Hu1;lixingjian@baidu.com;~Dejing_Dou1;wuji_ee@mail.tsinghua.edu.cn,4;4;6;4,2;3;3;3,Reject,0,5,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;Renmin University of China;Baidu;University of Oregon Eugene;Tsinghua University,,4;85;-1;209;4,20;517;-1;346;20,m;m,asia,cn,n,
6382,ICLR,2021,Approximate Probabilistic Inference with Composed Flows,Jay Whang;Erik Lindgren;Alex Dimakis,~Jay_Whang1;~Erik_Lindgren1;~Alex_Dimakis1,5;6;7;4,5;3;4;4,Reject,0,10,0.0,yes,9/28/20,"University of Texas, Austin;Google;University of Texas at Austin",normalizing flow;probabilistic inference;variational inference;inverse problem,-1;-1;20,-1;-1;43,m;m,usa,usa,n,5
6383,ICLR,2021,A Communication Efficient Federated Kernel $k$-Means,Xiaochen Zhou;Xudong Wang,~Xiaochen_Zhou2;wxudong@sjtu.edu.cn,5;5;1;6,2;3;5;3,Reject,0,12,0.0,yes,9/28/20,"Shanghai Jiao Tong University;Shanghai Jiao Tong University, Tsinghua University",federated learning;kernel $k$-means;communication efficient,29;4,100;20,m;m,NAN,NAN,y,
6384,ICLR,2021,Neural Random Projection: From the Initial Task To the Input Similarity Problem,Alan Savushkin;Nikita Benkovich;Dmitry Golubev,~Alan_Savushkin1;nikita.benkovich@kaspersky.com;dmitry.s.golubev@kaspersky.com,4;7;3,4;3;4,Reject,0,3,0.0,yes,9/28/20,Kaspersky;Higher School of Economics;Kaspersky,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
6385,ICLR,2021,GRF: Learning a General Radiance Field for 3D Scene Representation and Rendering,Alex Trevithick;Bo Yang,amt6@williams.edu;~Bo_Yang7,5;4;6;7,4;3;4;4,Reject,0,9,0.0,yes,9/28/20,Williams College;The Hong Kong Polytechnic University,3D scene representation;novel view synthesis;neural rendering,-1;128,-1;129,m;m,asia,hk,n,
6386,ICLR,2021,Importance-based Multimodal Autoencoder,Sayan Ghosh;Eugene Laksana;Louis-Philippe Morency;Stefan Scherer,~Sayan_Ghosh1;~Eugene_Laksana1;~Louis-Philippe_Morency1;~Stefan_Scherer1,5;7;6;6,5;4;4;3,Reject,0,7,0.0,yes,9/28/20,USC Institute for Creative Technologies;;Carnegie Mellon University;University of Southern California,Neural networks;Speech analysis;Multimodal;Autoencoders;Representation Learning,-1;-1;1;37,-1;-1;28;53,m;m,usa,usa,n,
6387,ICLR,2021,Uncertainty in Neural Processes,Saeid Naderiparizi;Kenny Chiu;Benjamin Bloem-Reddy;Frank Wood,~Saeid_Naderiparizi1;kenny.chiu@stat.ubc.ca;benbr@stat.ubc.ca;~Frank_Wood2,5;5;5;8,4;4;3;4,Reject,0,6,0.0,yes,9/28/20,University of British Columbia;University of British Columbia;University of British Columbia;University of British Columbia,Neural Processes;Meta-learning;Variational Inference,58;58;58;58,34;34;34;34,m;m,canada,ca,n,8;5
6388,ICLR,2021,Fast 3D Acoustic Scattering via Discrete Laplacian Based Implicit Function Encoders,Hsien-Yu Meng;Zhenyu Tang;Dinesh Manocha,~Hsien-Yu_Meng1;~Zhenyu_Tang4;~Dinesh_Manocha2,4;6;3,4;3;3,Reject,0,5,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of North Carolina at Chapel Hill",wave equation;wave acoustics;geometric deep learning;sound simulation;shape laplacian,12;12;64,90;90;56,f;m,NAN,NAN,y,1
6389,ICLR,2021,Lipschitz-Bounded Equilibrium Networks,Max Revay;Ruigang Wang;Ian Manchester,~Max_Revay1;~Ruigang_Wang2;~Ian_Manchester1,6;6;7;8,3;2;4;4,Reject,0,6,0.0,yes,9/28/20,University of Sydney;University of Sydney;University of Sydney,Adversarial Robustness;Equilibrium Networks;Neural ODE,71;71;71,51;51;51,m;m,europe,uk,y,1;9;4
6390,ICLR,2021,Adaptive Hierarchical Hyper-gradient Descent,RENLONG JIE;Junbin Gao;Andrey Vasnev;Minh-Ngoc Tran,~RENLONG_JIE1;~Junbin_Gao1;andrey.vasnev@sydney.edu.au;~Minh-Ngoc_Tran1,5;5;5;5,3;4;2;3,Reject,0,10,0.0,yes,9/28/20,University of Sydney;University of Sydney;;;University of Sydney,learning rate adaptation;hyper-gradient descent;meta learning;optimisation;hierarchical system,71;71;-1;-1;71,51;51;-1;-1;51,m;m,europe,uk,y,
6391,ICLR,2021,Multi-Head Attention: Collaborate Instead of Concatenate,Jean-Baptiste Cordonnier;Andreas Loukas;Martin Jaggi,~Jean-Baptiste_Cordonnier2;~Andreas_Loukas1;~Martin_Jaggi1,5;5;6;5,4;3;5;3,Reject,0,9,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;EPFL,attention;self-attention;bert;multi-head;tensor factorization,-1;-1;23,-1;-1;-1,m;m,europe,ch,n,8;2;3
6392,ICLR,2021,Adversarial Deep Metric Learning,Thomas Kobber Panum;Zi Wang;Pengyu Kan;Earlence Fernandes;Somesh Jha,~Thomas_Kobber_Panum1;~Zi_Wang3;pkan2@cs.wisc.edu;earlence@cs.wisc.edu;~Somesh_Jha1,5;6;6;4,3;4;4;4,Reject,0,12,0.0,yes,9/28/20,"Department of Electronic Systems, Aalborg University;University of Wisconsin, Madison;;;University of Wisconsin, Madison;Department of Computer Science, University of Wisconsin, Madison",Deep metric learning;adversarial robustness;adversarial examples;adversarial perturbations;adversarial training,209;18;-1;-1;18;-1,218;49;-1;-1;49;-1,m;m,NAN,NAN,n,4
6393,ICLR,2021,PhraseTransformer: Self-Attention using Local Context for Semantic Parsing,Phuong Minh Nguyen;Vu Tran;Minh Le Nguyen,~Phuong_Minh_Nguyen3;vu.tran@jaist.ac.jp;nguyenml@jaist.ac.jp,5;3;3;7,5;5;3;4,Reject,0,4,0.0,yes,9/28/20,Japan Advanced Institute of Science and Technology  Tokyo Institute of Technology;;Japan Advanced Institute of Science and Technology,phrase transformer;logical form;semantic parsing;neural machine translation;meaning representation,174;-1;-1,312;-1;-1,u;u,NAN,NAN,n,8;3
6394,ICLR,2021,DJMix: Unsupervised Task-agnostic Augmentation for Improving Robustness,Ryuichiro Hataya;Hideki Nakayama,~Ryuichiro_Hataya1;~Hideki_Nakayama1,4;5;4;5,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,"The University of Tokyo;The University of Tokyo, Tokyo Institute of Technology",robustness;uncertainty;discretization;data augmentation,71;71,36;36,m;m,NAN,NAN,n,2
6395,ICLR,2021,SOAR: Second-Order Adversarial Regularization,Avery Ma;Fartash Faghri;Nicolas Papernot;Amir-massoud Farahmand,~Avery_Ma1;~Fartash_Faghri1;~Nicolas_Papernot1;~Amir-massoud_Farahmand1,7;7;4,3;4;5,Reject,0,8,0.0,yes,9/28/20,"University of Toronto;University of Toronto;University of Toronto;Department of Computer Science, University of Toronto",Adversarial Robustness,18;18;18;18,18;18;18;18,m;m,NAN,NAN,y,1;4
6396,ICLR,2021,Optimization Planning for 3D ConvNets,Zhaofan Qiu;Ting Yao;Chong-wah Ngo;Tao Mei,~Zhaofan_Qiu2;~Ting_Yao1;~Chong-wah_Ngo2;~Tao_Mei3,5;6;6;7,5;1;4;5,Reject,0,5,0.0,yes,9/28/20,University of Science and Technology of China;JD AI Research;City University of Hong Kong;JD.COM,3D ConvNets;Network Training;Video Recognition,-1;-1;128;-1,87;-1;126;-1,m;m,NAN,NAN,n,
6397,ICLR,2021,An Attention Free Transformer,Shuangfei Zhai;Walter Talbott;Nitish Srivastava;Chen Huang;Hanlin Goh;Joshua M. Susskind,~Shuangfei_Zhai3;~Walter_Talbott1;~Nitish_Srivastava1;~Chen_Huang6;~Hanlin_Goh2;~Joshua_M._Susskind1,4;6;5;4,4;3;4;5,Reject,0,5,0.0,yes,9/28/20,Apple;Apple;Apple Inc;Apple;Apple;Apple,Transformers;attention;efficient,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
6398,ICLR,2021,Data Instance Prior for Transfer Learning in GANs,Puneet Mangla;Nupur Kumari;Mayank Singh;Vineeth N. Balasubramanian;Balaji Krishnamurthy,~Puneet_Mangla1;~Nupur_Kumari1;~Mayank_Singh2;~Vineeth_N._Balasubramanian2;~Balaji_Krishnamurthy1,6;7;6;4,4;4;4;5,Reject,0,8,0.0,yes,9/28/20,"Indian Institute of Technology Hyderabad;CMU, Carnegie Mellon University;Indian Institute of Technology Kharagpur;Indian Institute of Technology Hyderabad;Adobe Systems",GAN;transfer learning;fewshot learning;image generation,-1;1;-1;-1;-1,693;28;-1;693;-1,m;m,NAN,NAN,n,6;5;4
6399,ICLR,2021,Improving Neural Network Accuracy and Calibration Under Distributional Shift with Prior Augmented Data ,Jeffrey Ryan Willette;Juho Lee;Sung Ju Hwang,~Jeffrey_Ryan_Willette1;~Juho_Lee2;~Sung_Ju_Hwang1,6;6;5;3,3;3;3;4,Reject,0,22,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;KAIST;Korea Advanced Institute of Science and Technology,Bayesian;Calibration,-1;15;-1,96;96;96,m;m,NAN,NAN,n,11
6400,ICLR,2021,Average Reward Reinforcement Learning with Monotonic Policy Improvement,Yiming Zhang;Keith W. Ross,~Yiming_Zhang1;~Keith_W._Ross1,5;6;6;6,4;4;3;5,Reject,0,9,0.0,yes,9/28/20,New York University;New York University,Reinforcement Learning;Deep Reinforcement Learning;Average Reward;Policy Optimization;Model Free RL,23;23,26;26,m;m,usa,usa,y,1
6401,ICLR,2021,To Understand Representation of Layer-aware Sequence Encoders as Multi-order-graph,Sufeng Duan;hai zhao;Rui Wang,~Sufeng_Duan1;~hai_zhao1;~Rui_Wang10,6;6;6,3;3;4,Reject,0,8,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,multigraph;Transformer;natural language process,29;29;29,100;100;100,m;m,asia,cn,n,8;3;10
6402,ICLR,2021,SiamCAN:Simple yet Effective Method to enhance Siamese Short-Term Tracking,Yue Zhao;Zhibin Yu,~Yue_Zhao10;~Zhibin_Yu3,3;4;5;3,5;5;4;4,Reject,0,4,0.0,yes,9/28/20,Southwest Jiaotong University;;Southwest Jiaotong University,Siamese trackers;cross-attention;light structure;anchor-free,-1;-1;-1,1089;-1;1089,u;m,NAN,NAN,n,
6403,ICLR,2021,AutoBayes: Automated Bayesian Graph Exploration for Nuisance-Robust Inference,Andac Demir;Toshiaki Koike-Akino;Ye Wang;Deniz Erdogmus,~Andac_Demir1;~Toshiaki_Koike-Akino1;~Ye_Wang2;~Deniz_Erdogmus1,5;5;4;5,3;4;3;3,Reject,0,4,0.0,yes,9/28/20,Northeastern University;Harvard University;Mitsubishi Electric Research Labs;Northeastern University,,16;53;-1;16,895;3;-1;895,m;m,usa,usa,n,6;11;10;4
6404,ICLR,2021,Simple deductive reasoning tests and numerical data sets for exposing limitation of today's deep neural networks,Kalidas Yeturu;Manish Kumar Srivastava,~Kalidas_Yeturu1;~Manish_Kumar_Srivastava1,4;3;3;3,3;5;5;3,Reject,0,2,0.0,yes,9/28/20,"Indian Institute of Technology Tirupati;Indian institute of technology, tirupati",inductive reasoning;deductive reasoning;neural network;memory;feature engineering,-1;-1,-1;-1,m;m,NAN,NAN,n,
6405,ICLR,2021,Low Complexity Approximate Bayesian Logistic Regression for Sparse Online Learning,Gil I. Shamir;Wojciech Szpankowski,~Gil_I._Shamir1;~Wojciech_Szpankowski1,4;6;4;4,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,Google;Purdue University,Bayesian methods;logistic regression;regret;online learning;MDL.,-1;23,-1;94,m;m,usa,usa,n,11
6406,ICLR,2021,Active Learning in CNNs via Expected Improvement Maximization,Udai G. Nagpal;David A. Knowles,~Udai_G._Nagpal1;~David_A._Knowles1,6;4;6,4;4;3,Reject,0,3,0.0,yes,9/28/20,Columbia University;Columbia University,active learning;batch-mode active learning;deep learning;convolutional neural networks;supervised learning;regression;classification;MC dropout;computer vision;computational biology,23;23,17;17,m;m,usa,usa,n,2
6407,ICLR,2021,PDE-regularized Neural Networks for Image Classification,Jungeun Kim;Seunghyun Hwang;Jihyun Hwang;Kookjin Lee;Dongeun Lee;Noseong Park,jekim5418@yonsei.ac.kr;hwangsh7415@gmail.com;hwanggh96@gmail.com;koolee@sandia.gov;dongeun.lee@tamuc.edu;~Noseong_Park1,5;7;6;6,4;4;4;3,Reject,0,10,0.0,yes,9/28/20,Yonsei University;Purdue University;Yonsei Univ.;Sandia National Laboratories;Texas A&M University-Commerce;George Mason University,Neural ODE;Partial Differential Equations;Image Classification,150;23;-1;-1;46;85,186;94;-1;-1;195;267,m;m,usa,usa,n,
6408,ICLR,2021,Generative Fairness Teaching,Rongmei Lin;Hanjun Dai;Li Xiong;Wei Wei,~Rongmei_Lin1;~Hanjun_Dai1;~Li_Xiong1;~Wei_Wei15,5;6;5;6,4;2;4;3,Reject,0,6,0.0,yes,9/28/20,Emory University;Google Research;Emory University;Google,fairness;student teacher model;counterfactual generative model,174;-1;174;-1,85;-1;85;-1,f;m,NAN,NAN,n,7;5
6409,ICLR,2021,ProGAE: A Geometric Autoencoder-based Generative Model for  Disentangling Protein Conformational Space,Norman Joseph Tatro;Payel Das;Pin-Yu Chen;Vijil Chenthamarakshan;Rongjie Lai,~Norman_Joseph_Tatro1;~Payel_Das1;~Pin-Yu_Chen1;~Vijil_Chenthamarakshan1;~Rongjie_Lai4,5;7;5;4,2;4;4;4,Reject,0,4,0.0,yes,9/28/20,Rensselaer Polytechnic Institute;Rice University;International Business Machines;International Business Machines;Rensselaer Polytechnic Institute,generative models;deep learning;interpretability,263;92;-1;-1;263,527;124;-1;-1;527,m;m,usa,usa,n,1;5
6410,ICLR,2021,DEMI: Discriminative Estimator of Mutual Information ,Ruizhi Liao;Daniel Moyer;Polina Golland;William M Wells,~Ruizhi_Liao3;~Daniel_Moyer3;~Polina_Golland1;~William_M_Wells1,5;6;4;7,5;3;4;2,Reject,0,5,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Computer Science and Artificial Intelligence Laboratory, Electrical Engineering & Computer Science;Massachusetts Institute of Technology;Harvard University",Mutual information estimation;discriminative classification,5;-1;5;53,4;-1;4;3,m;m,usa,usa,n,
6411,ICLR,2021,Which Mutual-Information Representation Learning Objectives are Sufficient for Control?,Kate Rakelly;Abhishek Gupta;Carlos Florensa;Sergey Levine,~Kate_Rakelly1;~Abhishek_Gupta1;~Carlos_Florensa1;~Sergey_Levine1,5;6;5;5;7,4;3;3;3;3,Reject,0,20,0.0,yes,9/28/20,University of California Berkeley;Google;University of California Berkeley;University of Washington,representation learning;reinforcement learning;information theory,-1;-1;-1;11,7;-1;7;29,f;m,usa,usa,y,
6412,ICLR,2021,PODS: Policy Optimization via Differentiable Simulation,Miguel Angel Zamora Mora;Momchil Peychev;Sehoon Ha;Martin Vechev;Stelian Coros,~Miguel_Angel_Zamora_Mora1;mpeychev@ethz.ch;sehoon.ha@gmail.com;~Martin_Vechev1;~Stelian_Coros1,6;4;6,4;5;4,Reject,0,3,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Georgia Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Reinforcement Learning;Decision and Control;Planning;Robotics.,-1;-1;12;-1;-1,-1;-1;38;-1;-1,m;m,NAN,NAN,n,
6413,ICLR,2021,On Nondeterminism and Instability in Neural Network Optimization,Cecilia Summers;Michael J. Dinneen,~Cecilia_Summers1;~Michael_J._Dinneen1,6;6;5;5,4;4;3;3,Reject,0,4,0.0,yes,9/28/20,University of Auckland;University of Auckland,Nondeterminism;Instability,263;263,147;147,f;m,australasia,nz,n,8
6414,ICLR,2021,Individuality in the hive - Learning to embed lifetime social behaviour of honey bees,Benjamin Wild;David Dormagen;Michael L Smith;Tim Landgraf,~Benjamin_Wild1;david.dormagen@fu-berlin.de;msmith@ab.mpg.de;~Tim_Landgraf1,6;6;5;5,3;4;3;4,Reject,0,7,0.0,yes,9/28/20,Freie Universit√§t Berlin;Freie Universit‚àö¬ßt Berlin;;Freie Universit√§t Berlin,matrix factorization;honey bees;explainable;social networks;implicit bias;dataset,327;327;-1;327,-1;-1;-1;-1,m;m,europe,de,n,
6415,ICLR,2021,Model-Agnostic Round-Optimal Federated Learning via Knowledge Transfer,Qinbin Li;Bingsheng He;Dawn Song,~Qinbin_Li1;~Bingsheng_He1;~Dawn_Song1,5;4;4;4,4;5;4;4,Reject,0,5,0.0,yes,9/28/20,"School of Computing, National University of Singapore;National University of Singapore;University of California Berkeley",Federated Learning;Communication-Bounded Learning,17;17;-1,25;25;7,m;f,usa,usa,y,
6416,ICLR,2021,Learning Blood Oxygen from Respiration Signals,Hao He;Ying-Cong Chen;Yuan Yuan;Dina Katabi,~Hao_He1;~Ying-Cong_Chen1;~Yuan_Yuan5;~Dina_Katabi1,3;6;4,4;4;4,Reject,0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,healthcare;medical application,5;5;5;5,4;4;4;4,m;f,usa,usa,n,
6417,ICLR,2021,Offline Meta-Reinforcement Learning with Advantage Weighting,Eric Mitchell;Rafael Rafailov;Xue Bin Peng;Sergey Levine;Chelsea Finn,~Eric_Mitchell1;rafailov@stanford.edu;~Xue_Bin_Peng1;~Sergey_Levine1;~Chelsea_Finn1,5;6;6;5,4;3;3;5,Reject,0,5,0.0,yes,9/28/20,Stanford University;Stanford University;University of California Berkeley;University of Washington;Stanford University,offline;meta-reinforcement learning;meta-learning;reinforcement learning;maml,5;5;-1;11;5,2;2;7;29;2,m;f,usa,usa,y,6
6418,ICLR,2021,Adversarial Meta-Learning,Chengxiang Yin;Jian Tang;Zhiyuan Xu;Yanzhi Wang,~Chengxiang_Yin1;~Jian_Tang5;~Zhiyuan_Xu1;~Yanzhi_Wang2,4;4;3;5;6,5;4;5;4;4,Reject,0,0,0.0,yes,9/28/20,Syracuse University;Syracuse University;Midea;Northeastern University,Meta-learning;Adversarial manner;Adversarial Meta-Learner;Adversarial samples,209;209;-1;16,346;346;-1;895,m;m,usa,usa,n,6;4
6419,ICLR,2021,Language Models are Open Knowledge Graphs,Chenguang Wang;Xiao Liu;Dawn Song,~Chenguang_Wang1;liuxiao17@mails.tsinghua.edu.cn;~Dawn_Song2,4;4;4;5,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,"University of California Berkeley;Tsinghua University, Tsinghua University;University of California-Berkeley",Language Models;Knowledge Graphs;Information Extraction,-1;4;-1,7;20;7,m;f,usa,usa,n,3;10
6420,ICLR,2021,Increasing-Margin Adversarial (IMA) training to Improve Adversarial Robustness of Neural Networks,Linhai Ma;Liang Liang,~Linhai_Ma1;~Liang_Liang2,4;4;6;4,1;4;3;4,Reject,0,8,0.0,yes,9/28/20,University of Miami;University of Miami,Robustness;CNN;Medical image classification,453;453,238;238,m;m,usa,usa,n,4
6421,ICLR,2021,Domain-slot Relationship Modeling using  a Pre-trained Language Encoder for Multi-Domain Dialogue State Tracking,Jinwon An;Misuk Kim;Sungzoon Cho;Junseong Bang,~Jinwon_An1;~Misuk_Kim1;~Sungzoon_Cho1;hjbang21pp@etri.re.kr,3;7;4;5,5;4;5;3,Reject,0,6,0.0,yes,9/28/20,Seoul National University;Sejong University;Seoul National University;Electronics and Telecommunications Research Institute,Dialogue State Tracking;Domain-slot Relationship Modeling;Pre-trained Language Encoder,37;-1;37;-1,60;331;60;-1,u;u,NAN,NAN,n,3
6422,ICLR,2021,Learning without Forgetting: Task Aware Multitask Learning for Multi-Modality Tasks,Sathish Reddy Indurthi;Mohd Abbas Zaidi;Nikhil Kumar Lakumarapu;Beomseok Lee;HyoJung Han;Sangha Kim;Inchul Hwang,~Sathish_Reddy_Indurthi2;~Mohd_Abbas_Zaidi2;~Nikhil_Kumar_Lakumarapu1;bsgunn.lee@samsung.com;~HyoJung_Han1;sangha01.kim@samsung.com;inc.hwang@samsung.com,4;4;5;4,4;4;3;5,Reject,0,20,0.0,yes,9/28/20,Samsung;Samsung;Samsung;;Samsung Research;;Samsung,Deep Learning;Joint Learning;Meta Learning;Multi-task Learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
6423,ICLR,2021,Beyond Prioritized Replay: Sampling States in Model-Based RL via Simulated Priorities,Jincheng Mei;Yangchen Pan;Martha White;Amir-massoud Farahmand;Hengshuai Yao,~Jincheng_Mei1;~Yangchen_Pan2;~Martha_White1;~Amir-massoud_Farahmand1;~Hengshuai_Yao2,5;4;6,3;3;2,Reject,0,5,0.0,yes,9/28/20,"University of Alberta;University of Alberta;University of Alberta;Department of Computer Science, University of Toronto;University of Alberta",Experience replay;prioritized sampling;model-based reinforcement learning;Dyna architecture,110;110;110;18;110,131;131;131;18;131,m;m,canada,ca,y,8;1
6424,ICLR,2021,Beyond COVID-19 Diagnosis: Prognosis with Hierarchical Graph Representation Learning,CHEN LIU;Jinze Cui;Dailin Gan;Guosheng Yin,~CHEN_LIU7;~Jinze_Cui2;~Dailin_Gan1;~Guosheng_Yin1,6;6;4,4;4;4,Reject,0,14,0.0,yes,9/28/20,The University of Hong Kong;The University of Hong Kong;The University of Hong Kong;The University of Hong Kong,COVID-19 Diagnosis;COVID-19 Prognosis;GCN,99;99;99;99,39;39;39;39,f;m,NAN,NAN,n,10
6425,ICLR,2021,Optimistic Exploration with Backward Bootstrapped Bonus for Deep Reinforcement Learning,Chenjia Bai;Lingxiao Wang;Peng Liu;Zhaoran Wang;Jianye HAO;Yingnan Zhao,~Chenjia_Bai2;~Lingxiao_Wang6;~Peng_Liu5;~Zhaoran_Wang1;~Jianye_HAO1;~Yingnan_Zhao1,6;4;6;7;6,3;4;4;4;4,Reject,0,18,0.0,yes,9/28/20,Harbin institute of technology;Northwestern University;Harbin Institute of Technology;Northwestern University;Tianjin University;Harbin Institute of Technology,optimistic exploration;backward bootstrapped bonus;posterior sampling;reinforcement learning,150;46;150;46;-1;150,416;24;416;24;496;416,m;f,asia,cn,y,10
6426,ICLR,2021,Neighbor Class Consistency on Unsupervised Domain Adaptation,Chang Liu;Kai Li;Yun Fu,liu.chang6@northeastern.edu;~Kai_Li3;~Yun_Fu1,5;4;6;5,5;5;3;3,Reject,0,9,0.0,yes,9/28/20,Northeastern University;Northeastern University;Northeastern University,Unsupervised domain adaptation;Consistency regularization;Neighbor,16;16;16,895;895;895,m;m,usa,usa,n,
6427,ICLR,2021,UNSUPERVISED ANOMALY DETECTION FROM SEMANTIC SIMILARITY SCORES,Nima Rafiee;Rahil Gholamipoor;Markus Kollmann,nima.rafiee@hhu.de;rahil.gholamipoorfard@hhu.de;~Markus_Kollmann1,5;5;7;5,4;3;3;4,Reject,0,7,0.0,yes,9/28/20,Mathematical Modeling for Biological Systems;Mathematical Modeling of Biological Systems Institute;Department of Biology/Department of Computer Science,Anomaly Detection;Out-of-Distribution Detection;Novelty Detection,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
6428,ICLR,2021,LATENT OPTIMIZATION VARIATIONAL AUTOENCODER FOR CONDITIONAL MOLECULAR GENERATION,Kisoo Kwon;Jung-Hyun Park;Kuhwan Jeong;Sunjae Lee;Hoshik Lee,~Kisoo_Kwon1;~Jung-Hyun_Park1;~Kuhwan_Jeong1;~Sunjae_Lee1;~Hoshik_Lee1,5;3;4;4,4;4;4;2,Reject,0,9,0.0,yes,9/28/20,Seoul National University;Samsung;Seoul National University;CHONNAM NATIONAL UNIVERSITY;College of William and Mary,latent optimization;Variational Autoencoder;molecular generation,37;-1;37;-1;209,60;-1;60;990;-1,m;m,usa,usa,n,5
6429,ICLR,2021,Self-Activating Neural Ensembles for Continual Reinforcement Learning,Sam Powers;Abhinav Gupta,~Sam_Powers1;~Abhinav_Gupta1,5;5;4;6,4;4;4;3,Reject,0,9,0.0,yes,9/28/20,Carnegie Mellon University;Facebook,continual reinforcement learning;lifelong learning;deep reinforcement learning,1;-1,28;-1,f;m,NAN,NAN,n,
6430,ICLR,2021,Daylight: Assessing Generalization Skills of Deep Reinforcement Learning Agents,Ezgi Korkmaz,~Ezgi_Korkmaz1,6;6;5,4;4;3,Reject,0,12,0.0,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden",deep reinforcement learning;generalization,174,239,f,NAN,NAN,n,1;4
6431,ICLR,2021,L2E: Learning to Exploit Your Opponent,Zhe Wu;Kai Li;Hang Xu;Meng Zhang;Haobo Fu;Bo An;Junliang Xing,wuzhe2019@ia.ac.cn;~Kai_Li2;xuhang2020@ia.ac.cn;zhangmeng2018@ia.ac.cn;~Haobo_Fu2;~Bo_An2;~Junliang_Xing1,6;6;4;6,4;3;3;3,Reject,0,18,0.0,yes,9/28/20,"University of Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;, Chinese Academy of Sciences;Tencent AI Lab;Nanyang Technological University;Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences",,34;34;34;34;-1;44;34;34,-1;-1;-1;-1;-1;47;-1;-1,u;m,asia,cn,n,1;4
6432,ICLR,2021,Rethinking Convolution: Towards an Optimal Efficiency,Tao Wei;Yonghong Tian;Chang Wen Chen,~Tao_Wei1;~Yonghong_Tian1;~Chang_Wen_Chen1,6;6;5;6,3;4;4;3,Reject,0,10,0.0,yes,9/28/20,"State University of New York, Buffalo;Peking University;State University of New York, Buffalo",,-1;14;-1,-1;23;-1,m;m,NAN,NAN,n,
6433,ICLR,2021,Progressively Stacking 2.0: A Multi-stage Layerwise Training Method for BERT Training Speedup,Cheng Yang;Shengnan Wang;Chao Yang;Yuechuan Li;Ru He;Jingqiao Zhang,~Cheng_Yang3;~Shengnan_Wang2;~Chao_Yang7;~Yuechuan_Li1;~Ru_He1;~Jingqiao_Zhang1,6;5;6;5,4;4;4;5,Reject,0,7,0.0,yes,9/28/20,Zhejiang University;Zhejiang University;Xi'an Jiaotong University;;Alibaba Group;Alibaba,BERT;Training speedup;Multi-stage training;Natural language processing,42;42;-1;-1;-1;-1,94;94;445;-1;-1;-1,u;u,NAN,NAN,n,3
6434,ICLR,2021,Defending against black-box adversarial attacks with gradient-free trained sign activation neural networks,Yunzhe Xue;Meiyan Xie;Zhibo Yang;Usman Roshan,yx277@njit.edu;mx42@njit.edu;zy328@njit.edu;~Usman_Roshan1,4;5;3,4;4;4,Reject,0,4,0.0,yes,9/28/20,New Jersey Institute of Technology;;New Jersey Institute of Technology;New Jersey Institute of Technology,sign activation neural network;gradient-free training;stochastic coordinate descent;black box adversarial attack;hopskipjump;transferability;image distortion,-1;-1;-1;-1,570;-1;570;570,m;m,NAN,NAN,n,4
6435,ICLR,2021,Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model,Xin Qiu;Risto Miikkulainen,~Xin_Qiu1;~Risto_Miikkulainen1,6;6;6;6,3;3;3;2,Reject,0,7,0.0,yes,9/28/20,"Cognizant Technology Solutions Corporation;The University of Texas, Austin",Neural Network Classifier;Error Detection;AI safety,-1;-1,-1;-1,m;m,NAN,NAN,n,4
6436,ICLR,2021,Once Quantized for All: Progressively Searching for Quantized Compact Models,Mingzhu Shen;Feng Liang;Chuming Li;Chen Lin;Ming Sun;Junjie Yan;Wanli Ouyang,~Mingzhu_Shen1;~Feng_Liang3;~Chuming_Li1;~Chen_Lin2;~Ming_Sun4;~Junjie_Yan4;~Wanli_Ouyang1,4;6;5;6,4;2;4;3,Reject,0,8,0.0,yes,9/28/20,"Sensetime Research;Tsinghua University, Tsinghua University;University of Electronic Science and Technology of China;University of Oxford, University of Oxford;Nankai University;SenseTime Group Limited;University of Sydney",quantized neural networks;network architecture search;compact models,-1;4;-1;46;-1;-1;71,-1;20;553;1;358;-1;51,f;m,europe,uk,n,8
6437,ICLR,2021,Estimation of Number of Communities in Assortative Sparse Networks,Neil Hwang;Jiarui Xu;Shirshendu Chatterjee;Sharmodeep Bhattacharyya,neilhwang@gmail.com;xujiar@oregonstate.edu;shirshendu@ccny.cuny.edu;~Sharmodeep_Bhattacharyya1,7;6;5;6,4;4;2;3,Reject,0,0,0.0,yes,9/28/20,City University of New York;;;Oregon State University,networks;number of communities;Bethe-Hessian;sparse networks;stochastic block model,-1;-1;-1;79,-1;-1;-1;424,m;m,usa,usa,y,1
6438,ICLR,2021,Exploring Routing Strategies for Multilingual Mixture-of-Experts Models,Sneha Kudugunta;Yanping Huang;Ankur Bapna;Maxim Krikun;Dmitry Lepikhin;Thang Luong;Orhan Firat,~Sneha_Kudugunta1;~Yanping_Huang1;~Ankur_Bapna1;krikun@google.com;lepikhin@google.com;~Thang_Luong1;~Orhan_Firat1,6;4;5,5;4;4,Reject,0,4,0.0,yes,9/28/20,"Indian Institute of Technology, Hyderabad;Google;Google;Google;Lomonosov Moscow State University;Google;Google",Mixture-of-Experts;Neural Machine Translation;Multilingual;Multi-Task Learning;Conditional Computation;Natural Language Processing,-1;-1;-1;-1;-1;-1;-1,693;-1;-1;-1;173;-1;-1,f;m,NAN,NAN,n,8
6439,ICLR,2021,AT-GAN: An Adversarial Generative Model for Non-constrained Adversarial Examples,Xiaosen Wang;Kun He;Chuanbiao Song;Liwei Wang;John E. Hopcroft,~Xiaosen_Wang1;~Kun_He1;~Chuanbiao_Song2;~Liwei_Wang1;~John_E._Hopcroft1,6;5;7,4;4;3,Reject,0,5,0.0,yes,9/28/20,Huazhong University of Science and Technology;Huazhong University of Sceince and Technology;Huazhong University of Science and Technology;Peking University;Cornell University,adversarial examples;adversarial attack;generation-based attack;adversarial generative model;non-constrained adversarial examples,-1;-1;-1;14;7,312;312;312;23;19,m;m,usa,usa,y,6;5;4
6440,ICLR,2021,Revealing the Structure of Deep Neural Networks via Convex Duality,Tolga Ergen;Mert Pilanci,~Tolga_Ergen1;~Mert_Pilanci3,6;3;8;6,4;5;3;4,Reject,0,6,0.0,yes,9/28/20,Stanford University;Stanford University,Convex optimization;non-convex optimization;deep learning;convex duality;regularization;ReLU activation;linear networks,5;5,2;2,m;m,usa,usa,y,1
6441,ICLR,2021,Necessary and Sufficient Conditions for Compositional Representations,Yuanpeng Li,~Yuanpeng_Li2,3;3;4;3,4;4;3;4,Reject,0,7,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University",Compositionality,4,20,m,NAN,NAN,y,8;1
6442,ICLR,2021,Robustness against Relational Adversary,Yizhen Wang;Xiaozhu Meng;Mihai Christodorescu;Somesh Jha;Ke Wang,~Yizhen_Wang1;xiaozhu.meng@rice.edu;mihai.christodorescu@visa.com;~Somesh_Jha1;~Ke_Wang1,4;6;6;7,5;2;5;4,Reject,0,12,0.0,yes,9/28/20,"VISA;;;;;Department of Computer Science, University of Wisconsin, Madison;Visa Research",Adversarial Machine Learning;Semantics-Preserving Attacks;Logic Relations;Normalization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,4
6443,ICLR,2021,Disentangling Action Sequences: Discovering Correlated Samples,Jiantao Wu;Chunxiuzi Liu;Lin Wang,~Jiantao_Wu1;lcxz2708@vip.qq.com;wangplanet@gmail.com,4;2;5;6;3,4;5;4;4;4,Reject,0,5,0.0,yes,9/28/20,University of Jinan;;;University of Jinan,disentanglement;representation learning;unsupervised;inductive bias,-1;-1;-1;-1,370;-1;-1;370,m;m,europe,de,n,5
6444,ICLR,2021,Zero-shot Transfer Learning for Gray-box Hyper-parameter Optimization,Hadi Samer Jomaa;Lars Schmidt-Thieme;Josif Grabocka,~Hadi_Samer_Jomaa1;~Lars_Schmidt-Thieme1;~Josif_Grabocka1,6;7;6;6;4,3;3;3;3;4,Reject,0,14,0.0,yes,9/28/20,University of Hildesheim;University of Hildesheim;Universit√§t Freiburg,Hyper-parameter Optimization;Transfer Learning;Meta-learning,453;453;-1,-1;-1;-1,m;m,NAN,NAN,n,6;11
6445,ICLR,2021,Achieving Explainability in a Visual Hard Attention Model through Content Prediction,Samrudhdhi Bharatkumar Rangrej;James J. Clark,~Samrudhdhi_Bharatkumar_Rangrej1;~James_J._Clark1,4;5;4;4,4;4;1;3,Reject,0,9,0.0,yes,9/28/20,McGill University;McGill University,visual hard attention;glimpses;explainability;bayesian optimal experiment design;variational autoencoder,99;99,40;40,f;m,canada,ca,n,8;11
6446,ICLR,2021,Adaptive Optimizers with Sparse Group Lasso,Yun Yue;Suo Tong;Zhen Zhang;Yongchao Liu;Chunyang Wen;Huanjun Bao;Jinjie Gu;Yixiang Mu,~Yun_Yue3;~Suo_Tong1;elliott.zz@antgroup.com;~Yongchao_Liu2;chengfu.wcy@antgroup.com;alex.bao@antgroup.com;jinjie.gujj@antgroup.com;yixiang.myx@antgroup.com,5;5;3;4,3;3;4;4,Reject,0,4,0.0,yes,9/28/20,antgroup;;;;;;Nanjing University;antgroup,adaptive optimizers;sparse group lasso;DNN models;online optimization,-1;-1;-1;-1;-1;-1;52;-1,-1;-1;-1;-1;-1;-1;111;-1,m;u,NAN,NAN,y,
6447,ICLR,2021,A priori guarantees of finite-time convergence for Deep Neural Networks,Anushree Rankawat;Mansi Rankawat;Harshal B. Oza,~Anushree_Rankawat1;~Mansi_Rankawat1;harshal.oza@sot.pdpu.ac.in,7;4;7;4,3;3;3;5,Reject,0,7,0.0,yes,9/28/20,University of Montreal;Georgia Institute of Technology;Pandit Deendayal Energy University,,128;12;-1,73;38;-1,f;m,NAN,NAN,y,1
6448,ICLR,2021,Concentric Spherical GNN for 3D Representation Learning,James S Fox;Bo Zhao;Sivasankaran Rajamanickam;Rampi Ramprasad;Le Song,~James_S_Fox1;bzhao68@gatech.edu;srajama@sandia.gov;rampi.ramprasad@mse.gatech;~Le_Song1,6;6;5;5,3;4;4;3,Reject,0,5,0.0,yes,9/28/20,"Georgia Institute of Technology;Georgia Institute of Technology;Sandia National Laboratories;;;College of Computing, Georgia Institute of Technology",spherical cnn;GNN;graph convolution;rotation equivariance;3D,12;12;-1;-1;-1;12,38;38;-1;-1;-1;38,m;m,NAN,NAN,n,2
6449,ICLR,2021,A Truly Constant-time Distribution-aware Negative Sampling,Shabnam Daghaghi;Tharun Medini;Beidi Chen;Mengnan Zhao;Anshumali Shrivastava,~Shabnam_Daghaghi1;~Tharun_Medini1;~Beidi_Chen1;mengnan.zhao@rice.edu;~Anshumali_Shrivastava1,4;5;7;3,4;4;2;4,Reject,0,4,0.0,yes,9/28/20,Rice University;Rice University;Stanford University;;;Rice University,,92;92;5;-1;-1;92,124;124;2;-1;-1;124,f;m,australasia,au,n,3
6450,ICLR,2021,ColdExpand: Semi-Supervised Graph Learning in Cold Start,Il-Jae Kwon;Kyoung-Woon On;Dong-Geon Lee;Byoung-Tak Zhang,~Il-Jae_Kwon1;~Kyoung-Woon_On1;~Dong-Geon_Lee1;~Byoung-Tak_Zhang1,6;6;9;5,5;4;5;3,Reject,0,11,0.0,yes,9/28/20,Seoul National University;Seoul National University;Yonsei University;Seoul National University,Graph Neural Networks;Cold Start;Semi-supervised Learning,37;37;150;37,60;60;186;60,m;m,asia,kr,n,1;10
6451,ICLR,2021,Video Prediction with Variational Temporal Hierarchies,Vaibhav Saxena;Jimmy Ba;Danijar Hafner,~Vaibhav_Saxena1;~Jimmy_Ba1;~Danijar_Hafner1,5;5;4;6,4;4;5;4,Reject,0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",latent dynamics;temporal abstraction;video prediction;probabilistic modeling;variational inference;deep learning,18;18;18,18;18;18,m;m,NAN,NAN,n,5
6452,ICLR,2021,"Decentralized SGD with Asynchronous, Local and Quantized Updates",Giorgi Nadiradze;Amirmojtaba Sabour;Peter Davies;Ilia Markov;Shigang Li;Dan Alistarh,~Giorgi_Nadiradze1;amsabour79@gmail.com;peter.davies@ist.ac.at;ilia.markov@ist.ac.at;shigangli.cs@gmail.com;~Dan_Alistarh7,6;7;5;5,4;3;4;5,Reject,0,6,0.0,yes,9/28/20,"Institute of Science and Technology Austria;Sharif University of Technology, Sharif University of Technology;Institute of Science and Technology Austria;;;Swiss Federal Institute of Technology;Institute of Science and Technology Austria",distributed machine learning;SGD;decentralized algorithms;quantization,-1;327;-1;-1;-1;-1;-1,-1;475;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1;10
6453,ICLR,2021,A Large-scale Study on Training Sample Memorization in Generative Modeling,Ching-Yuan Bai;Hsuan-Tien Lin;Colin Raffel;Wendy Kan,b05502055@csie.ntu.edu.tw;~Hsuan-Tien_Lin1;~Colin_Raffel1;~Wendy_Kan1,5;4;3,4;4;4,Reject,0,6,0.0,yes,9/28/20,National Taiwan University;National Taiwan University;Hugging Face;Google,GAN;generative adversarial networks;generative modeling;memorization,99;99;-1;-1,97;97;-1;-1,m;f,NAN,NAN,n,5
6454,ICLR,2021,Self-supervised and Supervised Joint Training for Resource-rich Machine Translation,Yong Cheng;Wei Wang.;Lu Jiang;Wolfgang Macherey,~Yong_Cheng3;~Wei_Wang.1;~Lu_Jiang1;~Wolfgang_Macherey1,5;7;5;5,5;4;5;4,Reject,0,12,0.0,yes,9/28/20,Google;Apple AI/ML;Carnegie Mellon University;Google,resource-rich machine translation;neural machine translation;pre-training;self-supervised learning;joint training,-1;-1;1;-1,-1;-1;28;-1,m;m,NAN,NAN,n,8;3
6455,ICLR,2021,Asynchronous Modeling: A Dual-phase Perspective for Long-Tailed Recognition,Hu Zhang;Linchao Zhu;Yi Yang,~Hu_Zhang1;~Linchao_Zhu1;~Yi_Yang4,6;3;5;6,5;5;4;3,Reject,0,5,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney;Zhejiang University,long-tailed classification;gradient distortion;asynchronous modeling,71;71;42,160;160;94,m;m,asia,cn,n,10
6456,ICLR,2021,Identifying Coarse-grained Independent Causal Mechanisms with Self-supervision,Xiaoyang Wang;Klara Nahrstedt;Oluwasanmi O Koyejo,~Xiaoyang_Wang6;~Klara_Nahrstedt1;~Oluwasanmi_O_Koyejo1,5;5;2,4;4;4,Reject,0,7,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Univ. of Illinois at Urbana-Champaign;University of Illinois - Urbana Champaign",Causal Mechanisms;Identifiability;Disentangled Representations,-1;2;-1,-1;-1;-1,f;m,usa,usa,y,1;5
6457,ICLR,2021,FERMI: Fair Empirical Risk Minimization via Exponential R√©nyi Mutual Information,Rakesh Pavan;Andrew Lowy;Sina Baharlouei;Meisam Razaviyayn;Ahmad Beirami,~Rakesh_Pavan1;lowya@usc.edu;~Sina_Baharlouei1;~Meisam_Razaviyayn1;~Ahmad_Beirami1,7;5;5,4;3;4,Reject,0,4,0.0,yes,9/28/20,National Institute of Technology Karnataka;University of Southern California;University of Southern California;University of Southern California;Facebook AI,algorithmic fairness,-1;37;37;37;-1,-1;53;53;53;-1,m;m,NAN,NAN,y,1;7
6458,ICLR,2021,Simplifying Models with Unlabeled Output Data,Sang Michael Xie;Tengyu Ma;Percy Liang,~Sang_Michael_Xie1;~Tengyu_Ma1;~Percy_Liang1,6;6;6,3;4;3,Reject,0,6,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,semi-supervised learning;structured prediction,5;5;5,2;2;2,m;m,usa,usa,n,8
6459,ICLR,2021,A framework for learned CountSketch,Simin Liu;Tianrui Liu;Ali Vakilian;Yulin Wan;David Woodruff,~Simin_Liu1;~Tianrui_Liu3;~Ali_Vakilian1;~Yulin_Wan2;~David_Woodruff1,7;6;5,4;2;3,Reject,0,3,0.0,yes,9/28/20,"Carnegie Mellon University;Nankai University,;Toyota Technological Institute at Chicago;Anhui University;Carnegie Mellon University",Compression;sketching,1;-1;-1;-1;1,28;358;-1;-1;28,f;m,usa,usa,y,1
6460,ICLR,2021,TOMA: Topological Map Abstraction for Reinforcement Learning,Zhao Heng Yin;Wu-Jun Li,~Zhao_Heng_Yin1;~Wu-Jun_Li1,4;5;3;5,4;3;5;3,Reject,0,4,0.0,yes,9/28/20,Nanjing University;Nanjing University,Planning;Reinforcement Learning;Representation Learning,52;52,111;111,m;m,asia,kr,n,10
6461,ICLR,2021,A Representational Model of Grid Cells' Path Integration Based on Matrix Lie Algebras,Ruiqi Gao;Jianwen Xie;Xue-Xin Wei;Song-Chun Zhu;Ying Nian Wu,~Ruiqi_Gao2;~Jianwen_Xie1;~Xue-Xin_Wei2;~Song-Chun_Zhu1;~Ying_Nian_Wu1,5;5;8;6,4;5;5;4,Reject,0,7,0.0,yes,9/28/20,"University of California, Los Angeles;Baidu Research;Columbia University;University of California-Los Angeles;UCLA",grid cells;path integration;representational model;Lie algebras;error correction,-1;-1;23;-1;327,15;-1;17;15;16,f;m,asia,in,y,
6462,ICLR,2021,Unsupervised Hierarchical Concept Learning,Sumegh Roychowdhury;Sumedh Anand Sontakke;Mausoom Sarkar;Nikaash Puri;Milan Aggarwal;Pinkesh Badjatiya;Balaji Krishnamurthy;Laurent Itti,~Sumegh_Roychowdhury1;~Sumedh_Anand_Sontakke1;~Mausoom_Sarkar1;~Nikaash_Puri1;~Milan_Aggarwal1;~Pinkesh_Badjatiya1;~Balaji_Krishnamurthy1;~Laurent_Itti1,4;4;6;5,4;4;3;3,Reject,0,9,0.0,yes,9/28/20,"Indian Institute of Technology Kharagpur;University of Southern California;Adobe;Delhi Technological University (Delhi College of Engineering), Dhirubhai Ambani Institute Of Information and Communication Technology;Indian Institute of  Technology (IIT) Delhi;Adobe Systems;Adobe Systems;;University of Southern California;University of Southern California",hierarchical learning;unsupervised learning;unsupervised hierarchical learning;video representation learning;learning from demonstrations,-1;37;-1;-1;-1;-1;-1;-1;37;37,-1;53;-1;914;-1;-1;-1;-1;53;53,m;m,usa,usa,n,8;3
6463,ICLR,2021,Smooth Activations and Reproducibility in Deep Networks,Gil I Shamir;Dong Lin;Lorenzo Coviello,gshamir@google.com;dongl@google.com;~Lorenzo_Coviello1,2;4;5;4,5;3;3;2,Reject,0,8,0.0,yes,9/28/20,Google;Google;Google,Deep networks;activation functions;reproducibility,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
6464,ICLR,2021,Adaptive Automotive Radar data Acquisition,Madhumitha Sakthi;Ahmed Tewfik,~Madhumitha_Sakthi1;~Ahmed_Tewfik1,4;3;4;4,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,University of Texas  Austin;University of Texas  Austin,Compressed Sensing;Adaptive acquisition;object detection,20;20,43;43,f;m,usa,usa,n,8;2
6465,ICLR,2021,Increasing the Coverage and Balance of Robustness Benchmarks by Using Non-Overlapping Corruptions,Alfred LAUGROS;Alice Caplier;Matthieu Ospici,~Alfred_LAUGROS1;~Alice_Caplier2;~Matthieu_Ospici1,5;4;6;5,3;5;4;5,Reject,0,6,0.0,yes,9/28/20,INP Grenoble;GIPSA LAB;Atos,Computer Vision;Robustness;Common Corruptions;Benchmark,-1;-1;-1,-1;-1;-1,m;m,europe,gr,n,
6466,ICLR,2021,Motif-Driven Contrastive Learning of Graph Representations,Shichang Zhang;Ziniu Hu;Arjun Subramonian;Yizhou Sun,~Shichang_Zhang2;~Ziniu_Hu1;arjunsub@ucla.edu;~Yizhou_Sun1,5;5;5;6,4;5;5;3,Reject,0,19,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",graph neural network;self-supervised learning;contrastive learning;graph motif learning,-1;-1;-1;-1,15;15;15;15,m;f,usa,usa,n,10
6467,ICLR,2021,Alpha Net: Adaptation with Composition in Classifier Space,Nadine Chang;Jayanth Koushik;Michael Tarr;Martial Hebert;Yu-Xiong Wang,~Nadine_Chang1;~Jayanth_Koushik1;~Michael_Tarr1;~Martial_Hebert1;~Yu-Xiong_Wang1,3;4;4;8,5;5;4;4,Reject,0,4,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;Carnegie-Mellon University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University",long-tail recognition;classifier composition,1;1;1;1;1,28;28;28;28;28,f;m,NAN,NAN,n,
6468,ICLR,2021,Hard Attention Control By Mutual Information Maximization,Himanshu Sahni;Charles Lee Isbell,~Himanshu_Sahni1;~Charles_Lee_Isbell1,6;4;4;4,2;4;3;4,Reject,0,5,0.0,yes,9/28/20,Georgia Institute of Technology;;Georgia Institute of Technology,reinforcement learning;attention;partial observability;mutual information;information theory,12;-1;12,38;-1;38,m;m,usa,usa,n,8
6469,ICLR,2021,Accurately Solving Rod Dynamics with Graph Learning,Han Shao;Tassilo Kugelstadt;Torsten H√§drich;Wojciech Pa≈Çubicki;Jan Bender;Soren Pirk;Dominik Michels,~Han_Shao3;kugelstadt@cs.rwth-aachen.de;torsten.hadrich@kaust.edu.sa;wp06@amu.edu.pl;~Jan_Bender1;~Soren_Pirk2;~Dominik_Michels1,6;6;6;4,4;4;4;4,Reject,0,13,0.0,yes,9/28/20,KAUST;RWTH Aachen University;;;AMU;RWTH Aachen University;Google Inc;KAUST,Dynamical Systems;Representation Learning,110;128;-1;-1;263;128;-1;110,-1;107;-1;-1;-1;107;-1;-1,m;m,europe,gr,n,10
6470,ICLR,2021,Empirical Studies on the Convergence of Feature Spaces in Deep Learning,Haoran Liu;Haoyi Xiong;Yaqing Wang;Haozhe An;Dongrui Wu;Dejing Dou,~Haoran_Liu2;~Haoyi_Xiong1;~Yaqing_Wang2;~Haozhe_An1;~Dongrui_Wu1;~Dejing_Dou1,3;5;6,4;3;4,Reject,0,9,0.0,yes,9/28/20,"Texas A&M;Baidu;Baidu Research;University of Maryland, College Park;Huazhong University of Science and Technology, Tsinghua University;University of Oregon Eugene",,46;-1;-1;12;4;209,195;-1;-1;90;20;346,m;u,NAN,NAN,n,1
6471,ICLR,2021,Improving Calibration through the Relationship with Adversarial Robustness,Yao Qin;Xuezhi Wang;Alex Beutel;Ed Chi,~Yao_Qin1;~Xuezhi_Wang3;~Alex_Beutel1;~Ed_Chi1,6;2;7;5,4;5;3;3,Reject,0,5,0.0,yes,9/28/20,University of California  San Diego;Google;Google;Google,Calibration;Uncertainty Estimates;Adversarial Robustness,-1;-1;-1;-1,33;-1;-1;-1,f;m,NAN,NAN,n,4
6472,ICLR,2021,Understanding Self-supervised Learning with Dual Deep Networks,Yuandong Tian;Lantao Yu;Xinlei Chen;Surya Ganguli,~Yuandong_Tian1;~Lantao_Yu2;~Xinlei_Chen1;~Surya_Ganguli1,6;8;5;7;3,4;2;2;4;4,Reject,0,24,0.0,yes,9/28/20,"Facebook AI Research;Computer Science Department, Stanford University;School of Computer Science, Carnegie Mellon University;Stanford University",self-supervised learning;teacher-student setting;theoretical analysis;hierarchical models;representation learning,-1;5;1;5,-1;2;28;2,m;m,usa,usa,y,1
6473,ICLR,2021,Partial Rejection Control for Robust Variational Inference in Sequential Latent Variable Models,Rahul Sharma;Soumya Banerjee;Dootika Vats;Piyush Rai,~Rahul_Sharma1;~Soumya_Banerjee1;~Dootika_Vats1;~Piyush_Rai1,6;5;7;7,3;4;4;5,Reject,0,14,0.0,yes,9/28/20,"IIT Kanpur;IIT Kanpur, IIT Kanpur;IIT Kanpur, Dhirubhai Ambani Institute Of Information and Communication Technology;IIT Kanpur, IIT Kanpur",dice enterprise;partial rejection control;sequential Monte-Carlo;Bernoulli factory;variational Inference;Rejection Sampling,128;128;128;128,-1;-1;-1;-1,m;m,NAN,NAN,y,1
6474,ICLR,2021,Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration,Yunhao Ge;Gan Xin;Zhi Xu;Yao Xiao;Yunkui Pang;Yining HE;Laurent Itti,~Yunhao_Ge1;~Gan_Xin1;~Zhi_Xu2;~Yao_Xiao3;~Yunkui_Pang1;~Yining_HE1;~Laurent_Itti1,3;4;3;5,4;5;5;4,Reject,0,6,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California;University of Southern California;University of Southern California;University of Southern California;;University of Southern California;University of Southern California,Generative autoencoder;disentangled representation learning;attribute controllable synthesis,37;37;37;37;37;37;-1;37;37,53;53;53;53;53;53;-1;53;53,m;m,usa,usa,n,7;5
6475,ICLR,2021,A Neural Network MCMC sampler that maximizes Proposal Entropy,ZENGYI LI;Yubei Chen;Friedrich Sommer,~ZENGYI_LI1;~Yubei_Chen1;~Friedrich_Sommer1,6;6;6;3,3;3;3;2,Reject,0,13,0.0,yes,9/28/20,University of California Berkeley;Facebook AI Research;University of California-Berkeley,MCMC;Adaptive MCMC;Neural MCMC;Normalizing Flow;Entropy based speed Measure;HMC;Energy-based Model;Sampling,-1;-1;-1,7;-1;7,m;m,usa,usa,n,
6476,ICLR,2021,H-divergence: A Decision-Theoretic Probability Discrepancy Measure ,Shengjia Zhao;Abhishek Sinha;Yutong He;Aidan Perreault;Jiaming Song;Stefano Ermon,~Shengjia_Zhao1;~Abhishek_Sinha1;~Yutong_He1;~Aidan_Perreault1;~Jiaming_Song1;~Stefano_Ermon1,6;5;9;7,4;4;4;5,Reject,0,6,0.0,yes,9/28/20,"Stanford University;Stanford University;Computer Science Department, Stanford University;Stanford University;Computer Science Department, Stanford University;Stanford University",probability divergence;two sample test;maximum mean discrepancy,5;5;5;5;5;5,2;2;2;2;2;2,m;m,usa,usa,y,1
6477,ICLR,2021,Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings,Linlin Liu;Thien Hai Nguyen;Shafiq Joty;Lidong Bing;Luo Si,~Linlin_Liu2;~Thien_Hai_Nguyen1;~Shafiq_Joty1;~Lidong_Bing2;~Luo_Si2,5;5;4;6,4;4;3;5,Reject,0,4,0.0,yes,9/28/20,Nanyang Technological University;Alibaba Group;SalesForce.com;Alibaba Group;;Purdue University,,44;-1;-1;-1;-1;23,47;-1;-1;-1;-1;94,m;m,usa,usa,n,6;3
6478,ICLR,2021,Architecture Agnostic Neural Networks,Sabera J Talukder;Guruprasad Raghavan;Yisong Yue,~Sabera_J_Talukder1;~Guruprasad_Raghavan1;~Yisong_Yue1,5;4;5;4,5;4;4;4,Reject,0,5,0.0,yes,9/28/20,California Institute of Technology;California Institute of Technology;California Institute of Technology,Architecture Agnostic;Sparse;Binary;Stochastic;Pruning;Biologically Inspired,150;150;150,4;4;4,f;m,usa,usa,n,
6479,ICLR,2021,Implicit Regularization of SGD via Thermophoresis,Mingwei Wei;David J. Schwab,~Mingwei_Wei1;~David_J._Schwab1,4;3;7,3;2;3,Reject,0,3,0.0,yes,9/28/20,Northwestern University;CUNY Graduate Center,SGD;regularization;generalization;statistical mechanics;thermophoresis,46;263,24;-1,m;m,NAN,NAN,y,1
6480,ICLR,2021,Transformers are Deep Infinite-Dimensional Non-Mercer Binary Kernel Machines,Matthew A Wright;Joseph E. Gonzalez,~Matthew_A_Wright1;~Joseph_E._Gonzalez1,7;4;6;6,4;4;4;4,Reject,0,9,0.0,yes,9/28/20,University of California Berkeley;University of California - Berkeley,Transformer models;attention models;kernel methods;reproducing kernel Banach spaces,-1;-1,7;7,m;m,usa,usa,y,3;8;1
6481,ICLR,2021,Global Node Attentions via Adaptive Spectral Filters,Shouheng Li;Dongwoo Kim;Qing Wang,~Shouheng_Li1;~Dongwoo_Kim1;qing.wang@anu.edu.au,4;7;7,5;4;1,Reject,0,7,0.0,yes,9/28/20,Australian National University;POSTECH;Australian National University,Graph Representation learning;Graph Convolutional Network;Graph Fourier transform,99;128;99,59;151;59,m;f,australasia,au,n,8;10
6482,ICLR,2021,SGD on Neural Networks learns Robust Features before Non-Robust,Vikram Nitin,~Vikram_Nitin1,5;5;5;4,4;4;4;4,Reject,0,10,0.0,yes,9/28/20,Columbia University,neural networks;gradient descent;sgd;adversarial;robustness;features,23,17,m,usa,usa,y,4
6483,ICLR,2021,Learning Consistent Deep Generative Models from Sparse Data via Prediction Constraints,Gabriel Hope;Madina Abdrakhmanova;Xiaoyin Chen;Michael C Hughes;Erik B Sudderth,~Gabriel_Hope1;~Madina_Abdrakhmanova1;xiaoyic6@uci.edu;~Michael_C_Hughes1;~Erik_B_Sudderth1,6;5;6;5,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,"University of California, Irvine;University of California, Irvine;University of California, Irvine;Tufts University;University of California, Irvine",Semisupervised learning;deep generative models;variational autoencoders,-1;-1;-1;174;-1,98;98;98;155;98,m;m,usa,usa,n,1;5
6484,ICLR,2021,Keep the Gradients Flowing: Using Gradient Flow to study Sparse Network Optimization,Kale-ab Tessera;Sara Hooker;Benjamin Rosman,~Kale-ab_Tessera1;~Sara_Hooker1;~Benjamin_Rosman1,3;5;5;5,3;3;4;4,Reject,0,9,0.0,yes,9/28/20,InstaDeep;Google Brain;University of the Witwatersrand,neural networks;sparsity;gradient flow;sparse network optimization,-1;-1;-1,-1;-1;206,m;m,NAN,NAN,n,
6485,ICLR,2021,Deep Positive Unlabeled Learning with a Sequential Bias,Walter Gerych;Thomas Hartvigsen;Luke Buquicchio;Kavin Chandrasekaran;Hamid Mansoor;Abdulaziz alajaji,~Walter_Gerych2;~Thomas_Hartvigsen1;ljbuquicchio@wpi.edu;kchandrasekaran@wpi.edu;hmansoor@wpi.edu;asalajaji@wpi.edu,5;6;5,3;4;5,Reject,0,7,0.0,yes,9/28/20,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute;;;Worcester Polytechnic Institute,,150;150;150;-1;-1;150,651;651;651;-1;-1;651,m;m,usa,usa,y,
6486,ICLR,2021,Deep $k$-NN Label Smoothing Improves Reproducibility of Neural Network Predictions,Dara Bahri;Heinrich Jiang,~Dara_Bahri1;~Heinrich_Jiang1,7;3;5;5,2;4;3;4,Reject,0,5,0.0,yes,9/28/20,Google Research;Google,$k$-nearest neighbors;neural networks;label smoothing;churn;reproducibility;stability;robustness,-1;-1,-1;-1,m;m,NAN,NAN,y,
6487,ICLR,2021,How Important is the Train-Validation Split in Meta-Learning?,Yu Bai;Minshuo Chen;Pan Zhou;Tuo Zhao;Jason D. Lee;Sham M. Kakade;Huan Wang;Caiming Xiong,~Yu_Bai1;~Minshuo_Chen1;~Pan_Zhou3;~Tuo_Zhao1;~Jason_D._Lee1;~Sham_M._Kakade1;~Huan_Wang1;~Caiming_Xiong1,5;5;6;6,3;3;2;3,Reject,0,11,0.0,yes,9/28/20,Salesforce Research;Georgia Institute of Technology;Sea Group;Georgia Institute of Technology;Princeton University;University of Washington;Yale University;Salesforce Research,Learning theory;meta-learning,-1;12;-1;12;29;11;71;-1,-1;38;-1;38;9;29;8;-1,m;m,NAN,NAN,y,6;1
6488,ICLR,2021,Recursive Neighborhood Pooling for Graph Representation Learning,Behrooz Tahmasebi;Stefanie Jegelka,~Behrooz_Tahmasebi1;~Stefanie_Jegelka3,4;6;6;6,4;4;4;1,Reject,0,4,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology,,5;5,4;4,m;f,usa,usa,y,1;10
6489,ICLR,2021,Are all negatives created equal in contrastive instance discrimination?,Tiffany Cai;Jonathan Frankle;David J. Schwab;Ari S. Morcos,tcai2718@gmail.com;~Jonathan_Frankle1;~David_J._Schwab1;~Ari_S._Morcos1,5;5;2;5,4;5;5;3,Reject,0,4,0.0,yes,9/28/20,Columbia University;Massachusetts Institute of Technology;CUNY Graduate Center;Facebook AI Research (FAIR),self-supervised learning;contrastive learning;contrastive instance discrimination;negatives;understanding self-supervised learning;ssl,23;5;263;-1,17;4;-1;-1,f;m,NAN,NAN,n,2
6490,ICLR,2021,Learning Continuous-Time Dynamics by Stochastic Differential Networks,Yingru Liu;Yucheng Xing;Xuewen Yang;Xin Wang;Jing Shi;Di Jin;Zhaoyue Chen,~Yingru_Liu1;~Yucheng_Xing1;~Xuewen_Yang1;~Xin_Wang7;~Jing_Shi1;~Di_Jin1;~Zhaoyue_Chen1,5;7;7;4,3;3;4;3,Reject,0,10,0.0,yes,9/28/20,"State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook;SUNY at Stony Brook;University of Rochester;Amazon;State University of New York, Stony Brook",Continuous-time Stochastic RNN;Neural SDE,-1;-1;-1;-1;110;-1;-1,-1;-1;-1;-1;147;-1;-1,m;u,NAN,NAN,y,11
6491,ICLR,2021,Jumpy Recurrent Neural Networks,Samuel James Greydanus;Stefan Lee;Alan Fern,~Samuel_James_Greydanus1;~Stefan_Lee1;~Alan_Fern1,5;7;5;5,5;4;4;4,Reject,0,6,0.0,yes,9/28/20,Dartmouth College;Oregon State University;Oregon State University,RNNs;temporal abstraction;planning;intuitive physics,174;79;79,100;424;424,m;m,usa,usa,n,
6492,ICLR,2021,AdaLead: A simple and robust adaptive greedy search algorithm for sequence design,Sam Sinai;Richard Wang;Alexander Whatley;Stewart Slocum;Elina Locane;Eric Kelsic,~Sam_Sinai1;richard@robustintelligence.com;alexander_whatley@berkeley.edu;sslocum3@jhu.edu;elina.locane@dynotx.com;eric.kelsic@dynotx.com,3;4;5;6,3;4;2;2,Reject,0,8,0.0,yes,9/28/20,Dyno Therapeutics;Robust Intelligence;;;;Dyno Therapeutics,Black-box Optimization;Model-guided sequence design;Computational biology,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11;5
6493,ICLR,2021,Transformers with Competitive Ensembles of Independent Mechanisms,Alex Lamb;Di He;Anirudh Goyal;Guolin Ke;Chien-Feng Liao;Mirco Ravanelli;Yoshua Bengio,~Alex_Lamb1;~Di_He1;~Anirudh_Goyal1;~Guolin_Ke3;~Chien-Feng_Liao1;~Mirco_Ravanelli1;~Yoshua_Bengio1,5;4;7;4,5;4;4;4,Reject,0,0,0.0,yes,9/28/20,"University of Montreal;Microsoft;University of Montreal;Microsoft;Academia Sinica;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Montreal",transformer;mechanism;modularity;modules;independence,128;-1;128;-1;-1;128;128,73;-1;73;-1;-1;73;73,m;m,canada,ca,n,8
6494,ICLR,2021,Beyond Trivial Counterfactual Generations with Diverse Valuable Explanations,Pau Rodriguez;Massimo Caccia;Alexandre Lacoste;Lee Zamparo;Issam H. Laradji;Laurent Charlin;David Vazquez,~Pau_Rodriguez2;~Massimo_Caccia1;~Alexandre_Lacoste1;~Lee_Zamparo1;~Issam_H._Laradji1;~Laurent_Charlin1;~David_Vazquez1,4;4;7;6,4;4;3;5,Reject,0,8,0.0,yes,9/28/20,"Element AI;University of Montreal;Element AI;Memorial Sloan Kettering Cancer Centre;McGill University;HEC Montreal;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal",Interpretability;Counterfactual;Explanations;Black-Box,-1;128;-1;-1;99;-1;128,-1;73;-1;-1;40;-1;73,m;m,NAN,NAN,n,8;2
6495,ICLR,2021,Fold2Seq: A Joint Sequence(1D)-Fold(3D) Embedding-based Generative Model for Protein Design,Yue Cao;Payel Das;Pin-Yu Chen;Vijil Chenthamarakshan;Igor Melnyk;Yang Shen,~Yue_Cao4;~Payel_Das1;~Pin-Yu_Chen1;~Vijil_Chenthamarakshan1;~Igor_Melnyk1;~Yang_Shen4,6;5;6;7,4;5;4;5,Reject,0,0,0.0,yes,9/28/20,Texas A&M;Rice University;International Business Machines;International Business Machines;International Business Machines;Texas A&M,Joint Embedding Learning;Generative Model;Transformer Autoencoder;Inverse Protein Folding;Sequence Design,46;92;-1;-1;-1;46,195;124;-1;-1;-1;195,m;m,NAN,NAN,n,8;5
6496,ICLR,2021,What Do Deep Nets Learn? Class-wise Patterns Revealed in the Input Space,Shihao Zhao;Xingjun Ma;Yisen Wang;James Bailey;Bo Li;Yu-Gang Jiang,~Shihao_Zhao1;~Xingjun_Ma1;~Yisen_Wang1;~James_Bailey1;~Bo_Li19;~Yu-Gang_Jiang1,6;7;4;7,4;4;5;4,Reject,0,11,0.0,yes,9/28/20,"Fudan University, Tsinghua University;Deakin University;Peking University;The University of Melbourne;University of Illinois, Urbana Champaign;;Fudan University;Fudan University",deep neural networks;deep learning understanding;backdoor vulnerability;adversarial vulnerability,4;-1;14;85;-1;-1;71;71,20;295;23;31;-1;-1;70;70,m;m,asia,cn,n,4
6497,ICLR,2021,Neural Lyapunov Model Predictive Control,Mayank Mittal;Marco Gallieri;Alessio Quaglino;Seyed Sina Mirrazavi Salehian;Jan Koutnik,~Mayank_Mittal1;~Marco_Gallieri1;~Alessio_Quaglino1;sina@nnaisense.com;~Jan_Koutnik1,3;7;5,4;3;4,Reject,0,10,0.0,yes,9/28/20,Swiss Federal Institute of Technology;NNAISENSE;NNAISENSE;;NNAISENSE,optimal control;mpc;lyapunov neural networks;safe-learning;safety,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6498,ICLR,2021,TwinDNN: A Tale of Two Deep Neural Networks,Hyunmin Jeong;Deming Chen,~Hyunmin_Jeong1;~Deming_Chen1,4;4;5;4,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Hardware Accelerator;High-Level-Synthesis;Machine Learning;Neural Network Quantization,-1;-1,-1;-1,m;m,usa,usa,n,
6499,ICLR,2021,Wasserstein diffusion on graphs with missing attributes,Zhixian Chen;Tengfei Ma;Yangqiu Song;Yang Wang,~Zhixian_Chen1;~Tengfei_Ma1;~Yangqiu_Song1;yangwang@ust.hk,7;5;3;4,3;3;4;4,Reject,0,8,0.0,yes,9/28/20,The Hong Kong University of Science and Technology;International Business Machines;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Wasserstein barycenter;graph learning;diffusion;missing features;matrix completion,-1;-1;-1;-1,56;-1;56;56,f;m,NAN,NAN,n,10
6500,ICLR,2021,Exploiting structured data for learning contagious diseases under incomplete testing,Maggie Makar;Lauren West;David Hooper;Eric Horvitz;Erica Shenoy;John Guttag,~Maggie_Makar1;lrwest@mgh.harvard.edu;dhooper@mgh.harvard.edu;~Eric_Horvitz1;eshenoy@mgh.harvard.edu;~John_Guttag2,3;4;5;7,4;2;2;2,Reject,0,6,0.0,yes,9/28/20,Massachusetts Institute of Technology;;;;;Microsoft;;;Massachusetts Institute of Technology,infectious diseases;neural networks;healthcare;regularization;structured data,5;-1;-1;-1;-1;-1;-1;-1;5,4;-1;-1;-1;-1;-1;-1;-1;4,f;m,usa,usa,n,
6501,ICLR,2021,Truly Deterministic Policy Optimization,Ehsan Saleh;Saba Ghaffari;Matthew West;Tim Bretl,~Ehsan_Saleh1;sabag2@illinois.edu;~Matthew_West1;~Tim_Bretl1,5;6;6;5,3;4;3;3,Reject,0,8,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois at Urbana-Champaign",Deterministic Policy Gradient;Deterministic Exploration;Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;48,m;m,NAN,NAN,y,
6502,ICLR,2021,Decoupling Representation Learning from Reinforcement Learning,Adam Stooke;Kimin Lee;Pieter Abbeel;Michael Laskin,~Adam_Stooke2;~Kimin_Lee1;~Pieter_Abbeel2;mlaskin@berkeley.edu,5;7;6;5,3;3;4;4,Reject,0,13,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;Covariant;University of California Berkeley,reinforcement learning;representation learning;unsupervised learning,-1;-1;-1;-1,7;7;-1;7,m;m,usa,usa,n,1
6503,ICLR,2021,Information Lattice Learning,Haizi Yu;James Evans;Lav R. Varshney,~Haizi_Yu1;~James_Evans1;~Lav_R._Varshney1,4;6;7;4,4;3;3;4,Reject,0,7,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Chicago;University of Illinois at Urbana-Champaign",,-1;46;-1,-1;10;48,m;m,NAN,NAN,n,1
6504,ICLR,2021,ScheduleNet: Learn to Solve MinMax mTSP Using Reinforcement Learning with Delayed Reward,Junyoung Park;Sanzhar Bakhtiyarov;Jinkyoo Park,~Junyoung_Park1;~Sanzhar_Bakhtiyarov1;~Jinkyoo_Park1,4;5;4;5,3;4;5;5,Reject,0,7,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,10
6505,ICLR,2021,Data-driven Learning of Geometric Scattering Networks,Alexander Tong;Frederik Wenkel;Kincaid Macdonald;Smita Krishnaswamy;Guy Wolf,~Alexander_Tong1;frederik.wenkel@umontreal.ca;kincaid.macdonald@yale.edu;~Smita_Krishnaswamy1;~Guy_Wolf1,6;4;8;6,4;3;5;3,Reject,0,11,0.0,yes,9/28/20,Yale University;University of Montreal;Yale University;Yale University;University of Montreal,Graph Neural Networks;GNNs;Geometric Scattering;Radial Basis Network;Graph Signal Processing;Wavelet,71;128;71;71;128,8;73;8;8;73,m;m,canada,ca,y,10
6506,ICLR,2021,Improving Sampling Accuracy of Stochastic Gradient MCMC Methods via Non-uniform Subsampling of Gradients,Ruilin Li;Xin Wang;Hongyuan Zha;Molei Tao,~Ruilin_Li1;xinwangmath@gmail.com;~Hongyuan_Zha1;~Molei_Tao1,6;5;4,3;4;3,Reject,0,3,0.0,yes,9/28/20,"Georgia Institute of Technology;;;The Chinese University of Hong Kong, Shenzhen;Georgia Institute of Technology",SG-MCMC;Non-uniform weight,12;-1;-1;46;12,38;-1;-1;39;38,f;m,usa,usa,y,
6507,ICLR,2021,Continual Lifelong Causal Effect Inference with Real World Evidence,Zhixuan Chu;Stephen Rathbun;Sheng Li,~Zhixuan_Chu1;rathbun@uga.edu;~Sheng_Li3,2;3;4;4,4;4;4;5,Reject,0,11,0.0,yes,9/28/20,University of Georgia;University of Georgia;University of Georgia,continual learning;incremental learning;causal effect inference;representation learning;treatment effect estimation,263;263;263,411;411;411,m;m,usa,usa,n,
6508,ICLR,2021,ATOM3D: Tasks On Molecules in Three Dimensions,Raphael John Lamarre Townshend;Martin Vogele;Patricia Suriana;Alex Derry;Alex Powers;Yianni Laloudakis;Sidhika Balachandar;Brandon M Anderson;Stephan Eismann;Risi Kondor;Russ Altman;Ron O. Dror,~Raphael_John_Lamarre_Townshend1;mvoegele@stanford.edu;psuriana@stanford.edu;aderry@stanford.edu;lxpowers@stanford.edu;jlalouda@stanford.edu;sidhikab@stanford.edu;~Brandon_M_Anderson1;~Stephan_Eismann1;~Risi_Kondor1;~Russ_Altman1;~Ron_O._Dror1,4;6;5,4;3;3,Reject,0,8,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;;;;;;;;;;Stanford University;Flatiron Institute;;;Stanford University,machine learning;structural biology;biomolecules,5;5;5;-1;-1;-1;-1;-1;-1;-1;-1;-1;5;-1;-1;-1;5,2;2;2;-1;-1;-1;-1;-1;-1;-1;-1;-1;2;-1;-1;-1;2,m;m,usa,usa,n,10
6509,ICLR,2021,Formalizing Generalization and Robustness of Neural Networks to Weight Perturbations,Yu-Lin Tsai;Chia-Yi Hsu;Chia-Mu Yu;Pin-Yu Chen,uriah1001@gmail.com;chiayihsu8315@gmail.com;~Chia-Mu_Yu1;~Pin-Yu_Chen1,7;6;3;7,4;3;4;4,Reject,0,17,0.0,yes,9/28/20,TCFSH;National Chiao Tung University;National Chiao Tung University;International Business Machines,Generalization;Robustness;Neural Network;Weight Perturbation;Rademacher complexity,-1;128;128;-1,-1;564;564;-1,u;m,NAN,NAN,y,1;4
6510,ICLR,2021,On Low Rank Directed Acyclic Graphs and Causal Structure Learning,Zhuangyan Fang;Shengyu Zhu;Jiji Zhang;Yue Liu;Zhitang Chen;Yangbo He,~Zhuangyan_Fang1;~Shengyu_Zhu1;~Jiji_Zhang1;liuyue52@huawei.com;~Zhitang_Chen1;heyb@pku.edu.cn,6;5;6;5,3;4;3;4,Reject,0,10,0.0,yes,9/28/20,Peking University;Huawei Noah's Ark Lab;Hong Kong Baptist University;;Huawei Technologies Ltd.;Peking University,causal discovery;structure learning;low rank graphs;directed acyclic graphs,14;-1;209;-1;-1;14,23;-1;377;-1;-1;23,m;m,asia,cn,y,10
6511,ICLR,2021,Learning representations from temporally smooth data,Shima Rahimi Moghaddam;Fanjun Bu;Christopher Honey,~Shima_Rahimi_Moghaddam1;fbu2@jhu.edu;~Christopher_Honey1,6;4;6;6,4;4;4;3,Reject,0,16,0.0,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,biologically plausible;incremental learning;leaky integrator;multiscale;hierarchical processing;timescales,71;71;71,12;12;12,f;m,usa,usa,n,
6512,ICLR,2021,Is deeper better? It depends on locality of relevant features,Takashi Mori;Masahito Ueda,~Takashi_Mori1;ueda@phys.s.u-tokyo.ac.jp,7;6;4;4,4;3;2;4,Reject,0,7,0.0,yes,9/28/20,RIKEN;The University of Tokyo,deep learning;generalization;overparameterization,-1;71,-1;36,m;m,NAN,NAN,n,1
6513,ICLR,2021,LEARNED HARDWARE/SOFTWARE CO-DESIGN OF NEURAL ACCELERATORS,Zhan Shi;Chirag Sakhuja;Milad Hashemi;Kevin Swersky;Calvin Lin,~Zhan_Shi3;chirag.sakhuja@utexas.edu;~Milad_Hashemi1;~Kevin_Swersky1;~Calvin_Lin1,5;4;7;6,2;5;4;3,Reject,0,13,0.0,yes,9/28/20,"Department of Computer Science, University of Texas, Austin;University of Texas, Austin;Google;Google Brain;University of Texas at Austin",deep learning accelerator;Bayesian optimization;design space exploration;hardware-software co-design,-1;-1;-1;-1;20,-1;-1;-1;-1;43,m;m,usa,usa,n,8;11
6514,ICLR,2021,Frequency Regularized Deep Convolutional Dictionary Learning and Application to Blind Denoising,Nikola Pavle Janjusevic;Amirhossein Khalilian-Gourtani;Yao Wang,~Nikola_Pavle_Janjusevic1;akg404@nyu.edu;~Yao_Wang2,4;3;4,5;3;4,Reject,0,3,0.0,yes,9/28/20,New York University;New York University;New York University,Dictionary learning;unrolled algorithm;convolutional sparse coding;interpretable deep learning;inverse problems;blind denoising;LISTA,23;23;23,26;26;26,m;f,usa,usa,n,
6515,ICLR,2021,Novelty Detection via Robust Variational Autoencoding,Chieh-Hsin Lai;Dongmian Zou;Gilad Lerman,~Chieh-Hsin_Lai1;~Dongmian_Zou1;~Gilad_Lerman1,8;4;6;5,3;4;3;4,Reject,0,10,0.0,yes,9/28/20,"University of Minnesota, Minneapolis;Duke Kunshan University;University of Minnesota, Minneapolis",novelty detection;variational autoencoding;robustness;Wasserstein metric;one-class classification;semi-supervised anomaly detection,71;-1;71,85;-1;85,m;m,NAN,NAN,y,5
6516,ICLR,2021,Optimizing Loss Functions Through Multivariate Taylor Polynomial Parameterization,Santiago Gonzalez;Risto Miikkulainen,~Santiago_Gonzalez1;~Risto_Miikkulainen1,5;5;6;6,4;4;2;4,Reject,0,5,0.0,yes,9/28/20,"University of Texas, Austin;The University of Texas, Austin",taylorglo;loss function;metalearning;evolution;deep networks;evolutionary strategies;taylor polynomials;glo,-1;-1,-1;-1,m;m,NAN,NAN,n,
6517,ICLR,2021,Gradient descent temporal difference-difference learning,Rong Zhu;James Murray,~Rong_Zhu4;jmurray9@uoregon.edu,5;5;5;3,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,Fudan University;University of Oregon,temporal difference learning;gradient-descent based temporal difference;Off-policy;regularization,71;209,70;346,m;m,europe,de,y,
6518,ICLR,2021,The Compact Support Neural Network,Adrian Barbu;Hongyu Mou,~Adrian_Barbu1;hm15f@my.fsu.edu,6;5;5;6,3;4;3;4,Reject,0,7,0.0,yes,9/28/20,Florida State University;Florida State University,RBF network;OOD detection;overconfident neural networks,128;128,284;284,m;m,usa,usa,n,
6519,ICLR,2021,SelfNorm and CrossNorm for Out-of-Distribution Robustness,Zhiqiang Tang;Yunhe Gao;Yi Zhu;Zhi Zhang;Mu Li;Dimitris N. Metaxas,~Zhiqiang_Tang1;~Yunhe_Gao2;~Yi_Zhu1;~Zhi_Zhang4;~Mu_Li1;~Dimitris_N._Metaxas1,7;5;7;6,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,Rutgers University;Rutgers University;Amazon;Amazon;School of Computer Science;Rutgers University,,29;29;-1;-1;-1;29,-1;-1;-1;-1;-1;-1,m;m,usa,usa,n,8;2;1
6520,ICLR,2021,Blind Pareto Fairness and Subgroup Robustness,Natalia Martinez;Martin Bertran;Afroditi Papadaki;Miguel R. D. Rodrigues;Guillermo Sapiro,~Natalia_Martinez1;martin.a.bertran@gmail.com;~Afroditi_Papadaki1;~Miguel_R._D._Rodrigues1;~Guillermo_Sapiro1,6;6;6,4;4;4,Reject,0,4,0.0,yes,9/28/20,Duke University;Duke University;University College London;University College London;Duke University,fairness;fairness in machine learning;fairness without demographics;robustness;subgroup robustness;blind fairness;pareto fairness,46;46;53;53;46,20;20;-1;-1;20,f;m,europe,se,pdf miss,7
6521,ICLR,2021,Trans-Caps: Transformer Capsule Networks with Self-attention Routing,Aryan Mobiny;Pietro Antonio Cicalese;Hien Van Nguyen,~Aryan_Mobiny1;~Pietro_Antonio_Cicalese1;~Hien_Van_Nguyen1,6;7;4;6,4;3;4;3,Reject,0,16,0.0,yes,9/28/20,University of Houston;;University of Houston;University of Houston,capsule network;self-attention,209;-1;209;209,557;-1;557;557,m;m,usa,usa,n,8;2
6522,ICLR,2021,NeurWIN: Neural Whittle Index Network for Restless Bandits via Deep RL,Khaled Nakhleh;Santosh Ganji;Ping-Chun Hsieh;I-Hong Hou;Srinivas Shakkottai,~Khaled_Nakhleh1;~Santosh_Ganji1;~Ping-Chun_Hsieh1;~I-Hong_Hou1;~Srinivas_Shakkottai1,4;7;7;4,4;4;3;4,Reject,0,12,0.0,yes,9/28/20,Texas A&M;Texas A&M;National Chiao Tung University;Texas A&M;Texas A&M,deep reinforcement learning;restless bandits;Whittle index,46;46;128;46;46,195;195;564;195;195,m;m,NAN,NAN,n,
6523,ICLR,2021,Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning,Sumedh Anand Sontakke;Arash Mehrjou;Theofanis Karaletsos;Laurent Itti;Bernhard Sch√∂lkopf,~Sumedh_Anand_Sontakke1;~Arash_Mehrjou1;~Theofanis_Karaletsos1;~Laurent_Itti2;~Bernhard_Sch√∂lkopf1,5;3;6;5,4;4;3;4,Reject,0,15,0.0,yes,9/28/20,"University of Southern California;Max Planck Institute;Facebook;University of Southern California;Max Planck Institute for Intelligent Systems, Max-Planck Institute",Causal Representation Learning;Unsupervised/Self-Supervised Reinforcement Learning,37;-1;-1;37;-1,53;-1;-1;53;-1,m;m,NAN,NAN,n,6
6524,ICLR,2021,Does Adversarial Transferability Indicate Knowledge Transferability?,Kaizhao Liang;Jacky Y. Zhang;Oluwasanmi O Koyejo;Bo Li,~Kaizhao_Liang1;~Jacky_Y._Zhang1;~Oluwasanmi_O_Koyejo1;~Bo_Li19,5;5;5;5,4;4;3;3,Reject,0,5,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois - Urbana Champaign;University of Illinois, Urbana Champaign",adversarial transferability;knowledge transferability,-1;-1;-1;-1,-1;-1;-1;-1,m;f,usa,usa,y,6;4
6525,ICLR,2021,Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs,Ramneet Kaur;Susmit Jha;Anirban Roy,ramneetk@seas.upenn.edu;~Susmit_Jha1;~Anirban_Roy3,4;6;5;5,5;2;5;4,Reject,0,25,0.0,yes,9/28/20,University of Pennsylvania;SRI International;SRI International,OOD;out of distribution;trust;model confidence;DNN;deep learning,20;-1;-1,13;-1;-1,f;m,NAN,NAN,n,8
6526,ICLR,2021,Differentiate Everything with a Reversible Domain-Specific Language,JinGuo Liu;Taine Zhao,~JinGuo_Liu1;thaut@logic.cs.tsukuba.ac.jp,5;6;5;6;4,3;4;3;2;4,Reject,0,6,0.0,yes,9/28/20,Institute of physics  Chinese academy of sciences;University of Tsukuba of Japan,Reversible computing;automatic differentiation;Julia,-1;110,-1;499,m;m,NAN,NAN,n,
6527,ICLR,2021,Understanding the Effect of Bias in Deep Anomaly Detection,Ziyu Ye;Yuxin Chen;Haitao Zheng,~Ziyu_Ye1;~Yuxin_Chen1;~Haitao_Zheng2,7;7;6;4,4;4;2;5,Reject,0,9,0.0,yes,9/28/20,University of Chicago;University of Chicago;University of Chicago,deep anomaly detection;bias;PAC guarantee,46;46;46,10;10;10,f;f,usa,usa,y,
6528,ICLR,2021,GANMEX: Class-Targeted One-vs-One Attributions using GAN-based Model Explainability,Sheng-Min Shih;Pin-Ju Tien;Zohar Karnin,~Sheng-Min_Shih1;pinju.tien@gmail.com;~Zohar_Karnin1,5;5;5;4,4;3;4;2,Reject,0,6,0.0,yes,9/28/20,Amazon;Hedge fund;Amazon,Deep Neural Networks;Attribution Methods;Generative Adversarial Networks;Interpretability;Explainability,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,7;5;4
6529,ICLR,2021,Near-Black-Box Adversarial Attacks on Graph Neural Networks as An Influence Maximization Problem,Jiaqi Ma;Junwei Deng;Qiaozhu Mei,~Jiaqi_Ma1;junweid@umich.edu;~Qiaozhu_Mei1,5;5;5;6,4;5;5;4,Reject,0,16,0.0,yes,9/28/20,University of Michigan;University of Michigan;University of Michigan Ann Arbor,Graph Neural Network;Adversarial Attack;Influence Maximization,7;7;7,22;22;22,m;m,NAN,NAN,y,10;4
6530,ICLR,2021,Adapt-and-Adjust: Overcoming the Long-tail Problem of Multilingual Speech Recognition,Genta Indra Winata;Guangsen Wang;Caiming Xiong;Steven Hoi,~Genta_Indra_Winata1;~Guangsen_Wang2;~Caiming_Xiong1;~Steven_Hoi2,5;5;4;5;6,4;4;4;4;3,Reject,0,12,0.0,yes,9/28/20,The Hong Kong University of Science and Technology;SalesForce.com;Salesforce Research;Salesforce Research Asia,speech recognition;multilingual;long-tail;adapter;logit adjustments,-1;-1;-1;-1,56;-1;-1;-1,m;m,NAN,NAN,n,8;3
6531,ICLR,2021,AUTOSAMPLING: SEARCH FOR EFFECTIVE DATA SAMPLING SCHEDULES,Ming Sun;Haoxuan Dou;Baopu Li;Junjie Yan;Wanli Ouyang,~Ming_Sun4;~Haoxuan_Dou1;~Baopu_Li1;~Junjie_Yan4;~Wanli_Ouyang1,3;6;5,5;4;4,Reject,0,3,0.0,yes,9/28/20,"Nankai University;University of California, Los Angeles;University of Pennsylvania;SenseTime Group Limited;University of Sydney",Hyper-parameter Learning;AutoML;Computer Vision,-1;-1;20;-1;71,358;15;13;-1;51,m;m,europe,uk,n,
6532,ICLR,2021,StructFormer: Joint Unsupervised Induction of Dependency and Constituency Structure from Masked Language Modeling,Yikang Shen;Yi Tay;Che Zheng;Dara Bahri;Donald Metzler;Aaron Courville,~Yikang_Shen1;~Yi_Tay1;chezheng@google.com;~Dara_Bahri1;metzler@google.com;~Aaron_Courville3,4;4;6;5,4;3;4;4,Reject,0,1,0.0,yes,9/28/20,University of Montreal;Google;;;Google Research;Google;University of Montreal,Unsupervised Dependency Parsing;Unsupervised Constituency Parsing;Masked Language Model,128;-1;-1;-1;-1;-1;128,73;-1;-1;-1;-1;-1;73,m;m,canada,ca,n,8;3;10
6533,ICLR,2021,Precondition Layer and Its Use for GANs,Tiantian Fang;Alex Schwing;Ruoyu Sun,~Tiantian_Fang1;~Alex_Schwing1;~Ruoyu_Sun1,7;4;5;6,4;3;3;3,Reject,0,7,0.0,yes,9/28/20,"University of Illinois, Urbana-Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana-Champaign",GAN;Preconditioning;Condition Number,-1;-1;-1,-1;-1;-1,f;m,usa,usa,n,5;4
6534,ICLR,2021,Optimal Neural Program Synthesis from Multimodal Specifications,Xi Ye;Qiaochu Chen;Isil Dillig;Greg Durrett,~Xi_Ye2;qchen@cs.utexas.edu;~Isil_Dillig1;~Greg_Durrett1,6;5;7;4,5;4;4;4,Reject,0,7,0.0,yes,9/28/20,"UT Austin;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",program synthesis,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,n,3
6535,ICLR,2021,Zero-Shot Recognition through Image-Guided Semantic Classification,Mei-Chen Yeh;Fang Li;Bo-Heng Li,~Mei-Chen_Yeh1;~Fang_Li5;a0917251699@gmail.com,4;3;3;4,4;4;5;5,Reject,0,5,0.0,yes,9/28/20,National Taiwan Normal Unversity;National Taiwan Normal University;National Taiwan Normal University,zero-shot learning;visual-semantic embedding;deep learning,-1;-1;-1,602;602;602,f;u,NAN,NAN,n,6
6536,ICLR,2021,Linking average- and worst-case perturbation robustness via class selectivity and dimensionality,Matthew L Leavitt;Ari S. Morcos,~Matthew_L_Leavitt1;~Ari_S._Morcos1,6;7;4;6,3;4;3;4,Reject,0,9,0.0,yes,9/28/20,Facebook;Facebook AI Research (FAIR),robustness;adversarial robustness;corruptions;class selectivity;deep learning,-1;-1,-1;-1,m;m,NAN,NAN,n,1;4
6537,ICLR,2021,Learning to Search for Fast Maximum Common Subgraph Detection,Yunsheng Bai;Derek Qiang Xu;Yizhou Sun;Wei Wang,~Yunsheng_Bai1;~Derek_Qiang_Xu2;~Yizhou_Sun1;~Wei_Wang13,5;5;7,3;4;4,Reject,0,13,0.0,yes,9/28/20,", University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",graph matching;maximum common subgraph;graph neural network;reinforcement learning;search,-1;-1;-1;-1,15;15;15;15,m;m,usa,usa,n,1;10
6538,ICLR,2021,TRIP: Refining Image-to-Image Translation via Rival Preferences,Yinghua Yao;Yuangang Pan;Ivor Tsang;Xin Yao,~Yinghua_Yao1;~Yuangang_Pan2;~Ivor_Tsang1;~Xin_Yao1,4;4;6;5,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;Southern University of Science and Technology,Fine-grained image-to-image translation;GAN;relative attributes;ranker,71;71;71;-1,160;160;160;252,u;m,NAN,NAN,n,4
6539,ICLR,2021,Neural Potts Model,Tom Sercu;Robert Verkuil;Joshua Meier;Brandon Amos;Zeming Lin;Caroline Chen;Jason Liu;Yann LeCun;Alexander Rives,~Tom_Sercu1;rverkuil@fb.com;~Joshua_Meier1;~Brandon_Amos1;~Zeming_Lin1;cachen@mit.edu;jasonliu@fb.com;~Yann_LeCun1;~Alexander_Rives1,6;6;6;7,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,Facebook;Facebook;Facebook;Facebook;University of Virginia;Massachusetts Institute of Technology;Stanford University;Facebook;Facebook,proteins;potts model;unsupervised learning;amortized optimization;structure prediction,-1;-1;-1;-1;53;5;5;-1;-1,-1;-1;-1;-1;117;4;2;-1;-1,m;m,NAN,NAN,n,
6540,ICLR,2021,NOSE Augment: Fast and Effective Data Augmentation Without Searching,Qingrui Li;Song Xie;Anƒ±l Oymagil;Mustafa Furkan Eseoglu;Ziyin Zhang;CM Lee,~Qingrui_Li1;xiesong@mail.nwpu.edu.cn;~Anƒ±l_Oymagil1;~Mustafa_Furkan_Eseoglu1;zhangziyin1@huawei.com;~CM_Lee1,3;4;5,5;3;4,Reject,0,9,0.0,yes,9/28/20,Huawei Technologies Ltd.;Northwestern Polytechnical University;Huawei Technologies Ltd.;D-Market Elektronik Hizmetler ve Tic. A.≈û.(Hepsiburada.com);Huawei Technologies Ltd.;Huawei Technologies Ltd.,data augmentation;stochastic policy;multi-stage augmentation,-1;-1;-1;-1;-1;-1,-1;538;-1;-1;-1;-1,m;u,NAN,NAN,n,2;1
6541,ICLR,2021,Federated Learning of a Mixture of Global and Local Models,Filip Hanzely;Peter Richtarik,~Filip_Hanzely2;~Peter_Richtarik1,4;6;4;4,5;4;4;4,Reject,0,16,0.0,yes,9/28/20,Toyota Technological Institute at Chicago;KAUST,optimization;federated learning;personalization;local SGD,-1;110,-1;-1,m;m,europe,gr,y,1
6542,ICLR,2021,CAT-SAC: Soft Actor-Critic with Curiosity-Aware Entropy Temperature,Junfan Lin;Changxin Huang;Xiaodan Liang;Liang Lin,~Junfan_Lin1;~Changxin_Huang1;~Xiaodan_Liang2;~Liang_Lin1,4;6;4;4,4;3;3;5,Reject,0,6,0.0,yes,9/28/20,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1;-1,293;293;293;293,m;m,NAN,NAN,n,
6543,ICLR,2021,Learning Efficient Planning-based Rewards for Imitation Learning,Xingrui Yu;Yueming Lyu;Ivor Tsang,~Xingrui_Yu1;~Yueming_Lyu1;~Ivor_Tsang1,6;5;6;6,3;3;3;2,Reject,0,7,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,,71;71;71,160;160;160,m;m,australasia,au,n,1
6544,ICLR,2021,Federated Learning with Decoupled Probabilistic-Weighted Gradient Aggregation,Jian-hui Duan;Wenzhong Li;Sanglu Lu,~Jian-hui_Duan1;~Wenzhong_Li1;~Sanglu_Lu1,3;6;3;4,3;4;3;4,Reject,0,7,0.0,yes,9/28/20,Nanjing University;Nanjing University;Nanjing University,Federated Learning;Gradient Aggregation;Variational Inference,52;52;52,111;111;111,m;f,asia,kr,y,1
6545,ICLR,2021,XLVIN: eXecuted Latent Value Iteration Nets,Andreea Deac;Petar Veliƒçkoviƒá;Ognjen Milinkovic;Pierre-Luc Bacon;Jian Tang;Mladen Nikolic,~Andreea_Deac1;~Petar_Veliƒçkoviƒá1;ognjen7amg@gmail.com;~Pierre-Luc_Bacon1;~Jian_Tang1;mladennik@gmail.com,6;6;7;6,3;3;4;2,Reject,0,14,0.0,yes,9/28/20,Montreal Institute for Learning Algorithms  University of Montreal  University of Montreal;DeepMind;Faculty of Mathematics  University of Belgrade;University of Montreal;HEC Montreal;University of Belgrade,value iteration;graph neural networks;reinforcement learning,128;-1;-1;128;-1;-1,73;-1;753;73;-1;753,f;m,NAN,NAN,n,10
6546,ICLR,2021,TOWARDS NATURAL ROBUSTNESS AGAINST ADVERSARIAL EXAMPLES,Haoyu Chu;Shikui Wei;Yao Zhao,~Haoyu_Chu1;~Shikui_Wei1;~Yao_Zhao1,3;5;5;3;3,5;4;4;5;4,Reject,0,6,0.0,yes,9/28/20,Beijing jiaotong univercity;Beijing jiaotong university;;Beijing Jiaotong University,,-1;-1;-1;-1,978;978;-1;978,m;m,NAN,NAN,y,1;4
6547,ICLR,2021,Towards Understanding Label Smoothing,Yi Xu;Yuanhong Xu;Qi Qian;Li Hao;Rong Jin,~Yi_Xu8;~Yuanhong_Xu1;~Qi_Qian1;~Li_Hao1;~Rong_Jin1,4;1;6;6,3;5;3;3,Reject,0,7,0.0,yes,9/28/20,"Alibaba Group;University of Electronic Science and Technology of China, Tsinghua University;Alibaba Group;Alibaba Group;Alibaba Group",Label Smoothing;Non-convex Optimization;Deep Learning Theory,-1;4;-1;-1;-1,-1;20;-1;-1;-1,m;m,NAN,NAN,y,9
6548,ICLR,2021,Task-similarity Aware Meta-learning through Nonparametric Kernel Regression,Arun Venkitaraman;Anders Hansson;Bo Wahlberg,~Arun_Venkitaraman1;anders.g.hansson@liu.se;~Bo_Wahlberg1,3;4;4;4,5;4;4;3,Reject,0,5,0.0,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden;;;KTH Royal Institute of Technology, Stockholm, Sweden",Task-similarity;Meta-learning;Kernel regression;Nonparametric regression;Task-descriptors,174;-1;-1;174,239;-1;-1;239,m;m,NAN,NAN,n,6
6549,ICLR,2021,Continual Invariant Risk Minimization,Francesco Alesiani;Shujian Yu;Mathias Niepert,~Francesco_Alesiani1;~Shujian_Yu1;~Mathias_Niepert1,3;5;6;6,4;5;4;2,Reject,0,13,0.0,yes,9/28/20,NEC;NEC;NEC,Supervised Learning;Causal Learning;Invariant Risk Minimization;Continual Learning,-1;-1;-1,440;440;440,m;m,europe,gr,y,11;1
6550,ICLR,2021,Rotograd: Dynamic Gradient Homogenization for Multitask Learning,Adri√°n Javaloy;Isabel Valera,~Adri√°n_Javaloy1;~Isabel_Valera1,4;4;4,4;4;4,Reject,0,6,0.0,yes,9/28/20,"Saarland University, Saarland University;Saarland University, Saarland University",multitask learning;deep learning;gradnorm,92;92,-1;-1,m;f,NAN,NAN,y,1
6551,ICLR,2021,Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization,Brandon Trabucco;Aviral Kumar;Xinyang Geng;Sergey Levine,~Brandon_Trabucco1;~Aviral_Kumar2;~Xinyang_Geng1;~Sergey_Levine1,5;6;7;5,4;4;4;2,Reject,0,16,0.0,yes,9/28/20,"Machine Learning Department, School of Computer Science;University of California Berkeley;University of California Berkeley;University of Washington",Model-Based Optimization;Benchmark;Offline,-1;-1;-1;11,-1;7;7;29,m;m,usa,usa,n,
6552,ICLR,2021,Data augmentation for deep learning based accelerated MRI reconstruction,Zalan Fabian;Reinhard Heckel;Mahdi Soltanolkotabi,~Zalan_Fabian1;~Reinhard_Heckel1;~Mahdi_Soltanolkotabi1,6;4;5;6;6,4;5;5;4;4,Reject,0,9,0.0,yes,9/28/20,University of Southern California;Technical University Munich;University of Southern California,fast MRI;deep learning for inverse problems;data augmentation;unrolled networks;learning with limited data,37;-1;37,53;-1;53,m;m,usa,usa,n,
6553,ICLR,2021,Goal-Driven Imitation Learning from Observation by Inferring Goal Proximity,Andrew Szot;Youngwoon Lee;Shao-Hua Sun;Joseph J Lim,~Andrew_Szot1;~Youngwoon_Lee1;~Shao-Hua_Sun1;~Joseph_J_Lim1,5;7;6;6;5,5;4;3;5;3,Reject,0,14,0.0,yes,9/28/20,Georgia Institute of Technology;University of Southern California;University of Southern California;University of Southern California,Imitation Learning;Learning from Observation,12;37;37;37,38;53;53;53,m;m,usa,usa,n,1
6554,ICLR,2021,Adaptive Gradient Methods Converge Faster with Over-Parameterization (and you can do a line-search),Sharan Vaswani;Issam H. Laradji;Frederik Kunstner;Si Yi Meng;Mark Schmidt;Simon Lacoste-Julien,~Sharan_Vaswani1;~Issam_H._Laradji1;~Frederik_Kunstner1;~Si_Yi_Meng1;~Mark_Schmidt1;~Simon_Lacoste-Julien1,7;5;5;6,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,University of Alberta;McGill University;University of British Columbia;University of British Columbia;University of Alberta;University of Montreal,Adaptive gradient methods;Over-parameterization;Stochastic line-search;Momentum,110;99;58;58;110;128,131;40;34;34;131;73,m;m,canada,ca,y,1;9
6555,ICLR,2021,Neural Partial Differential Equations with Functional Convolution,Ziqian Wu;Xingzhe He;Michael Zhang;Yijun Li;Cheng Yang;Rui Liu;Shiying Xiong;Bo Zhu,~Ziqian_Wu1;~Xingzhe_He1;~Michael_Zhang6;~Yijun_Li4;~Cheng_Yang4;~Rui_Liu7;~Shiying_Xiong1;~Bo_Zhu2,4;5;4;4,3;4;2;4,Reject,0,2,0.0,yes,9/28/20,"Dartmouth College;University of British Columbia;The Lawrenceville School;University of California, Los Angeles;Shanghai Jiao Tong University;Dartmouth College;Dartmouth College;Dartmouth College",neural PDE;functional convolution;adjoint method,174;58;-1;-1;29;174;174;174,100;34;-1;15;100;100;100;100,f;m,usa,usa,n,
6556,ICLR,2021,Self-Supervised Time Series Representation Learning by Inter-Intra Relational Reasoning,Haoyi Fan;Fengbin Zhang;Yue Gao,~Haoyi_Fan1;zhangfengbin@hrbust.edu.cn;~Yue_Gao4,5;6;5,4;3;4,Reject,0,11,0.0,yes,9/28/20,"Harbin University Of Science And Technology;;;Tsinghua University, Tsinghua University",self-supervised learning;time series;deep learning;relational reasoning,-1;-1;-1;4,-1;-1;-1;20,m;m,NAN,NAN,n,
6557,ICLR,2021,CaLFADS: latent factor analysis of dynamical systems in calcium imaging data,Luke Yuri Prince;Shahab Bakhtiari;Colleen J Gillon;Blake Aaron Richards,~Luke_Yuri_Prince1;~Shahab_Bakhtiari1;~Colleen_J_Gillon1;~Blake_Aaron_Richards1,5;4;7;5,4;4;4;4,Reject,0,15,0.0,yes,9/28/20,Mila;McGill University;Toronto University;McGill University,latent variable modelling;lfads;neuroscience;variational autoencoders;dynamical systems;calcium imaging;neural data analysis,150;99;-1;99,370;40;-1;40,m;m,canada,ca,n,5
6558,ICLR,2021,Towards a Reliable and Robust Dialogue System for Medical Automatic Diagnosis,Junfan Lin;Lin Xu;Ziliang Chen;Liang Lin,~Junfan_Lin1;~Lin_Xu3;~Ziliang_Chen1;~Liang_Lin1,6;4;6;6,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,SUN YAT-SEN UNIVERSITY;National University of Singapore;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;17;-1;-1,293;25;293;293,m;m,NAN,NAN,n,
6559,ICLR,2021,Adaptive Stacked Graph Filter,Hoang NT;Takanori Maehara;Tsuyoshi Murata,~Hoang_NT1;~Takanori_Maehara1;~Tsuyoshi_Murata1,5;4;5;5,4;5;5;5,Reject,0,13,0.0,yes,9/28/20,RIKEN AIP;Facebook;;Tokyo Institute of Technology,Graph Convolutional Network;vertex classification;graph signal processing;adaptive graph filter,-1;-1;-1;174,-1;-1;-1;312,m;m,asia,jp,y,10
6560,ICLR,2021,Latent Space Semi-Supervised Time Series Data Clustering,Andrew Hill;Katerina Kechris;Russell Bowler;Farnoush Kashani,~Andrew_Hill2;katerina.kechris@cuanschutz.edu;bowlerr@njhealth.org;~Farnoush_Kashani1,4;6;5;4,3;3;2;5,Reject,0,5,0.0,yes,9/28/20,"University of Colorado, Denver;;;;;University of Colorado, Denver",Semi-supervised clustering;clustering;deep learning;autoencoder,453;-1;-1;-1;-1;453,-1;-1;-1;-1;-1;-1,m;m,usa,usa,n,
6561,ICLR,2021,On the Estimation Bias in Double Q-Learning,Zhizhou Ren;Guangxiang Zhu;Beining Han;Jianglun Chen;Chongjie Zhang,~Zhizhou_Ren1;~Guangxiang_Zhu1;~Beining_Han1;~Jianglun_Chen2;~Chongjie_Zhang1,6;6;3;6,3;4;4;3,Reject,0,7,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",Reinforcement learning;Q-learning;Estimation bias,-1;4;4;4;4,-1;20;20;20;20,m;m,asia,cn,y,1
6562,ICLR,2021,Cut-and-Paste Neural Rendering,Anand Bhattad;David Forsyth,~Anand_Bhattad1;~David_Forsyth1,6;5;6,2;4;4,Reject,0,3,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana-Champaign",Neural Rendering;Reshading;Relighting;Computational Photography;Image Decomposition,-1;-1,-1;-1,m;m,usa,usa,n,2
6563,ICLR,2021,Uncertainty Prediction for Deep Sequential Regression Using Meta Models,Jiri Navratil;Matthew Arnold;Benjamin Elder,~Jiri_Navratil1;marnold@us.ibm.com;benjamin.elder@ibm.com,6;7;5;5,4;3;3;4,Reject,0,0,0.0,yes,9/28/20,International Business Machines;Rutgers University;Massachusetts Institute of Technology,Uncertainty Quantification;Uncertainty Prediction;Deep Learning;Regression;Meta Modeling,-1;29;5,-1;-1;4,m;m,usa,usa,n,
6564,ICLR,2021,An Empirical Exploration of Open-Set Recognition via Lightweight Statistical Pipelines,Shu Kong;Deva Ramanan,~Shu_Kong1;~Deva_Ramanan1,7;3;3;4,4;5;3;4,Reject,0,4,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie-Mellon University,open-set recognition;anomaly detection;statistical models;Gaussian Mixture Models;open-world image classification;open-world semantic segmentation,1;1,28;28,m;m,usa,usa,n,
6565,ICLR,2021,Accelerating DNN Training through Selective Localized Learning ,Sarada Krithivasan;Sanchari Sen;Swagath Venkataramani;Anand Raghunathan,~Sarada_Krithivasan1;~Sanchari_Sen1;swagath.venkataramani@us.ibm.com;~Anand_Raghunathan1,6;7;5;4;6,4;4;4;4;4,Reject,0,7,0.0,yes,9/28/20,Purdue University;Purdue University;;;Purdue University,Efficient DNN Training,23;23;-1;-1;23,94;94;-1;-1;94,f;m,usa,usa,n,
6566,ICLR,2021,Adaptive Multi-model Fusion Learning for Sparse-Reward Reinforcement Learning,Giseung Park;Whiyoung Jung;Sungho Choi;Youngchul Sung,~Giseung_Park1;~Whiyoung_Jung1;~Sungho_Choi1;~Youngchul_Sung1,5;7;5;6,4;4;3;3,Reject,0,8,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,sparse-reward RL;intrinsic reward generation;adaptive fusion;information geometry;scale-free property,-1;-1;-1;-1,96;96;96;96,m;m,NAN,NAN,n,
6567,ICLR,2021,Learning Deeply Shared Filter Bases for Efficient ConvNets,Woochul Kang;Daeyeon Kim,~Woochul_Kang1;ssregibility@gmail.com,5;5;6;4,3;4;3;4,Reject,0,6,0.0,yes,9/28/20,"Incheon National University, South Korea;Incheon National University, South Korea",Deep learning;ConvNets;parameter sharing;model compression;convolutional neural networks;recursive networks,-1;-1,1294;1294,m;m,NAN,NAN,n,
6568,ICLR,2021,MDP Playground: Controlling Orthogonal Dimensions of Hardness in Toy Environments,Raghu Rajan;Jessica Lizeth Borja Diaz;Suresh Guttikonda;Fabio Ferreira;Andr√© Biedenkapp;Frank Hutter,~Raghu_Rajan1;~Jessica_Lizeth_Borja_Diaz1;~Suresh_Guttikonda2;~Fabio_Ferreira1;~Andr√©_Biedenkapp1;~Frank_Hutter1,5;6;4;4,4;4;4;5,Reject,0,31,0.0,yes,9/28/20,"Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;University of Freiburg, Universit√§t Freiburg;University of Freiburg & Bosch",Reinforcement learning;Benchmarks;Efficiency;Reproducibility;Core issues;Algorithm analysis;Dimensions of hardness;OpenAI Gym,-1;-1;-1;-1;150;150,-1;-1;-1;-1;83;83,m;m,NAN,NAN,n,
6569,ICLR,2021,ReaPER: Improving Sample Efficiency in Model-Based Latent Imagination,Martin A Bertran;Guillermo Sapiro;mariano phielipp,~Martin_A_Bertran1;~Guillermo_Sapiro1;~mariano_phielipp1,4;5;4;6,3;5;3;4,Reject,0,3,0.0,yes,9/28/20,Duke University;Duke University;Intel AI Lab,model-based reinforcement learning;visual control;sample efficiency,46;46;-1,20;20;-1,m;m,NAN,NAN,pdf miss,
6570,ICLR,2021,Transferable Unsupervised Robust Representation Learning,De-An Huang;Zhiding Yu;Anima Anandkumar,~De-An_Huang1;~Zhiding_Yu1;~Anima_Anandkumar1,7;7;5,4;5;4,Reject,0,8,0.0,yes,9/28/20,NVIDIA;NVIDIA;California Institute of Technology,unsupervised representation learning;robustness;transfer learning,-1;-1;150,-1;-1;4,m;f,usa,usa,n,6;4
6571,ICLR,2021,Weights Having Stable Signs Are Important: Finding Primary Subnetworks and Kernels to Compress Binary Weight Networks,Zhaole Sun;Anbang Yao,~Zhaole_Sun1;~Anbang_Yao1,6;5;3;5,4;4;5;2,Reject,0,7,0.0,yes,9/28/20,"School of Informatics, University of Edinburgh;Intel",,29;-1,30;-1,u;m,NAN,NAN,n,
6572,ICLR,2021,FactoredRL: Leveraging Factored Graphs for Deep Reinforcement Learning,Bharathan Balaji;Petros Christodoulou;Xiaoyu Lu;Byungsoo Jeon;Jordan Bell-Masterson,~Bharathan_Balaji1;~Petros_Christodoulou1;~Xiaoyu_Lu1;byungsoj@cs.cmu.edu;~Jordan_Bell-Masterson1,6;5;6;6,3;4;4;3,Reject,0,6,0.0,yes,9/28/20,"Amazon;Imperial College London;Amazon;School of Computer Science, Carnegie Mellon University;University of Chicago",reinforcement learning;factored mdp;factored rl,-1;53;-1;1;46,-1;11;-1;28;10,m;m,usa,usa,n,10
6573,ICLR,2021,Near-Optimal Glimpse Sequences for Training Hard Attention Neural Networks,William Harvey;Michael Teng;Frank Wood,~William_Harvey1;~Michael_Teng1;~Frank_Wood2,5;4;6;7,4;4;2;2,Reject,0,10,0.0,yes,9/28/20,University of British Columbia;University of British Columbia;University of British Columbia,attention;hard attention;variational inference;bayesian optimal experimental design,58;58;58,34;34;34,m;m,canada,ca,n,8;2;11
6574,ICLR,2021,Evaluating Agents Without Rewards,Brendon Matusch;Jimmy Ba;Danijar Hafner,~Brendon_Matusch1;~Jimmy_Ba1;~Danijar_Hafner1,4;4;4;3,3;4;5;4,Reject,0,11,0.0,yes,9/28/20,"Stanford University;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",reinforcement learning;task-agnostic;agent evaluation;exploration;information gain;empowerment;curiosity,5;18;18,2;18;18,m;m,NAN,NAN,n,
6575,ICLR,2021,Learning to Reason in Large Theories without Imitation,Kshitij Bansal;Christian Szegedy;Markus Norman Rabe;Sarah M. Loos;Viktor Toman,~Kshitij_Bansal1;~Christian_Szegedy1;~Markus_Norman_Rabe1;sarahmloos@gmail.com;vtoman@ist.ac.at,4;6;6;6;6,4;3;4;4;3,Reject,0,12,0.0,yes,9/28/20,Google;Google;Google;;Institute of Science and Technology Austria,reinforcement learning;thoerem proving;exploration;mathematics,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
6576,ICLR,2021,Enabling counterfactual survival analysis with balanced representations,Paidamoyo Chapfuwa;Serge Assaad;Shuxi Zeng;Michael Pencina;Lawrence Carin;Ricardo Henao,~Paidamoyo_Chapfuwa1;~Serge_Assaad1;zengshx777@gmail.com;michal.pencina@duke.edu;~Lawrence_Carin2;~Ricardo_Henao1,4;7;7;5,5;4;4;4,Reject,0,7,0.0,yes,9/28/20,Stanford University;Duke University;Duke University;;;Duke University;Duke University,survival analysis;time-to-event;counterfactual inference;causal survival analysis,5;46;46;-1;-1;46;46,2;20;20;-1;-1;20;20,f;m,europe,se,n,
6577,ICLR,2021,One Size Doesn't Fit All: Adaptive Label Smoothing,Ujwal Krothapalli;Lynn Abbott,~Ujwal_Krothapalli1;~Lynn_Abbott1,4;4;4;4,4;3;4;4,Reject,0,6,0.0,yes,9/28/20,Virginia Tech;Virginia Tech,Uncertainty estimation;Calibration;Label smoothing,64;64,-1;-1,m;m,usa,usa,n,6
6578,ICLR,2021, Adding Recurrence to Pretrained Transformers,Davis Yoshida;Allyson Ettinger;Kevin Gimpel,~Davis_Yoshida1;~Allyson_Ettinger1;~Kevin_Gimpel1,4;7;7,4;5;2,Reject,0,4,0.0,yes,9/28/20,Toyota Technological Institute at Chicago;University of Chicago;Toyota Technological Institute at Chicago,Language modeling;Transformers;Recurrence;Gradient checkpointing;Pretraining,-1;46;-1,-1;10;-1,m;m,NAN,NAN,n,8;3
6579,ICLR,2021,Analyzing and Improving Generative Adversarial Training for Generative Modeling and Out-of-Distribution Detection,Xuwang Yin;Shiying li;Gustavo Rohde,~Xuwang_Yin2;sl8jx@virginia.edu;~Gustavo_Rohde1,7;4;5,3;4;5,Reject,0,10,0.0,yes,9/28/20,University of Virginia;;;Carnegie-Mellon University,Adversarial Training;Generative Modeling;Out-of-Distribution Detection;GANs;Generative adversarial networks,53;-1;-1;1,117;-1;-1;28,m;m,usa,usa,y,5;4
6580,ICLR,2021,Contrastive Learning of Medical Visual Representations from Paired Images and Text,Yuhao Zhang;Hang Jiang;Yasuhide Miura;Christopher D Manning;Curtis Langlotz,~Yuhao_Zhang3;hjian42@stanford.edu;ysmiura@stanford.edu;~Christopher_D_Manning1;~Curtis_Langlotz1,6;4;5,4;4;5,Reject,0,5,0.0,yes,9/28/20,"Amazon AWS AI;Stanford University;Stanford University;Computer Science Department, Stanford University;;Stanford University",visual representation learning;contrastive learning;medical image understanding;natural language processing,-1;5;5;5;-1;5,-1;2;2;2;-1;2,m;m,usa,usa,n,6
6581,ICLR,2021,Learning Online Data Association,Yilun Du;Joshua B. Tenenbaum;Tomas Perez;Leslie Pack Kaelbling,~Yilun_Du1;~Joshua_B._Tenenbaum1;~Tomas_Perez1;~Leslie_Pack_Kaelbling1,6;7;4;6,3;4;4;2,Reject,0,7,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Data Association,5;5;5;5,4;4;4;4,m;f,usa,usa,n,8
6582,ICLR,2021,Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream,Franziska Geiger;Martin Schrimpf;Tiago Marques;James J. DiCarlo,franzigeiger94@googlemail.com;~Martin_Schrimpf1;tmarques@mit.edu;~James_J._DiCarlo1,6;6;8;3,5;4;3;4,Reject,0,10,0.0,yes,9/28/20,Technical University Munich;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology,computational neuroscience;primate ventral stream;convolutional neural networks;biologically plausible learning,-1;5;5;-1;5,-1;4;4;-1;4,f;m,usa,usa,n,
6583,ICLR,2021,Revisiting the Stability of Stochastic Gradient Descent: A Tightness Analysis,Yikai Zhang;Samuel Bald;wenjia Zhang;Vamsi Pritham Pingali;Chao Chen;Mayank Goswami,~Yikai_Zhang1;~Samuel_Bald1;wenjia.zhang@rutgers.edu;vamsipritham@gmail.com;~Chao_Chen1;~Mayank_Goswami1,4;5;7;4,4;4;3;3,Reject,0,6,0.0,yes,9/28/20,"Rutgers University;The Graduate Center, CUNY;Rutgers University;State University of New York, Stony Brook;State University of New York, Stony Brook;CUNY Queens College",SGD;Stability;Generalization;Deep Learning,29;263;29;-1;-1;263,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6584,ICLR,2021,"Whitening and second order optimization both destroy information about the dataset, and can make generalization impossible",Neha S. Wadia;Daniel Duckworth;Samuel Stern Schoenholz;Ethan Dyer;Jascha Sohl-Dickstein,~Neha_S._Wadia1;~Daniel_Duckworth1;~Samuel_Stern_Schoenholz1;~Ethan_Dyer1;~Jascha_Sohl-Dickstein2,4;7;7;4,4;3;4;5,Reject,0,15,0.0,yes,9/28/20,"University of California Berkeley;Department of Computer Science, University of Massachusetts, Amherst;Google;Google;Google",whitening;second order optimization;deep networks;generalization,-1;-1;-1;-1;-1,7;210;-1;-1;-1,f;m,NAN,NAN,y,1
6585,ICLR,2021,Unsupervised Active Pre-Training for Reinforcement Learning,Hao Liu;Pieter Abbeel,~Hao_Liu1;~Pieter_Abbeel2,5;6;5,5;4;3,Reject,0,7,0.0,yes,9/28/20,University of California Berkeley;Covariant,Reinforcement Learning;Unsupervised Learning;Entropy Maximization;Contrastive Learning;Self-supervised Learning;Exploration,-1;-1,7;-1,m;m,NAN,NAN,n,1
6586,ICLR,2021,Non-Attentive Tacotron: Robust and controllable neural TTS synthesis including unsupervised duration modeling,Jonathan Shen;Ye Jia;Mike Chrzanowski;Yu Zhang;Isaac Elias;Heiga Zen;Yonghui Wu,~Jonathan_Shen1;~Ye_Jia1;~Mike_Chrzanowski2;~Yu_Zhang2;isaace@google.com;~Heiga_Zen1;~Yonghui_Wu1,4;8;5;6,4;4;3;2,Reject,0,7,0.0,yes,9/28/20,Google;Google;NVIDIA;Google;;Google;Google,tts;text-to-speech,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
6587,ICLR,2021,Unbiased Learning with State-Conditioned Rewards in Adversarial Imitation Learning,Dong-Sig Han;Hyunseo Kim;Hyundo Lee;Je-Hwan Ryu;Byoung-Tak Zhang,~Dong-Sig_Han2;hskim@bi.snu.ac.kr;hdlee@bi.snu.ac.kr;jhryu@bi.snu.ac.kr;~Byoung-Tak_Zhang1,4;4;5,5;5;4,Reject,0,9,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University;Seoul National University,Adversarial Learning;Imitation Learning;Inverse Reinforcement Learning;Reinforcement Learning;Transfer Learning,37;37;37;37;37,60;60;60;60;60,u;m,asia,kr,n,4
6588,ICLR,2021,Fourier Representations for Black-Box Optimization over Categorical Variables,Hamid Dadkhahi;Jesus Rios;Karthikeyan Shanmugam;Payel Das,~Hamid_Dadkhahi1;jriosal@us.ibm.com;~Karthikeyan_Shanmugam1;~Payel_Das1,6;5;6;6,3;3;3;1,Reject,0,6,0.0,yes,9/28/20,Amazon;International Business Machines;International Business Machines;Rice University,,-1;-1;-1;92,-1;-1;-1;124,m;f,australasia,au,y,
6589,ICLR,2021,Aspect-based Sentiment Classification via Reinforcement Learning,Lichen Wang;Bo Zong;Yunyu Liu;Can Qin;Wei Cheng;Wenchao Yu;Xuchao Zhang;Haifeng Chen;Yun Fu,~Lichen_Wang1;~Bo_Zong1;~Yunyu_Liu1;~Can_Qin1;~Wei_Cheng1;~Wenchao_Yu1;xuczhang@nec-labs.com;~Haifeng_Chen1;~Yun_Fu1,5;5;3,4;3;5,Reject,0,3,0.0,yes,9/28/20,"Northeastern University;NEC Labs America;Purdue University;Northeastern University;NEC-Labs;University of California, Los Angeles;Virginia Tech;;Northeastern University",Sentiment classification;reinforcement learning,16;-1;23;16;-1;-1;64;-1;16,895;-1;94;895;-1;15;-1;-1;895,m;m,usa,usa,n,8;1;10
6590,ICLR,2021,Variational inference for diffusion modulated Cox processes,Prateek Jaiswal;Harsha Honnappa;Vinayak Rao,~Prateek_Jaiswal1;~Harsha_Honnappa1;~Vinayak_Rao1,7;7;6,3;2;3,Reject,0,6,0.0,yes,9/28/20,Purdue University;Purdue University;Purdue University,Cox process;variational inference;stochastic differential equation;smoothing posterior density,23;23;23,94;94;94,m;m,usa,usa,y,1
6591,ICLR,2021,Analysing the Update step in Graph Neural Networks via Sparsification,changmin wu;Johannes F. Lutzeyer;Michalis Vazirgiannis,~changmin_wu1;~Johannes_F._Lutzeyer1;~Michalis_Vazirgiannis2,6;5;4;4,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,Ecole polytechnique;Ecole polytechnique;;AUEB,graph neural network architectures;message-passing neural networks;neural network sparsification;deep learning,-1;-1;-1;209,89;89;-1;-1,m;m,europe,gr,n,10
6592,ICLR,2021,Fuzzy c-Means Clustering for Persistence Diagrams,Thomas Davies;Jack Aspinall;Bryan Wilder;Long Tran-Thanh,~Thomas_Davies1;jack.aspinall@materials.ox.ac.uk;~Bryan_Wilder1;long.tran-thanh@warwick.ac.uk,6;6;4;3,4;5;4;5,Reject,0,9,0.0,yes,9/28/20,University of Southampton;;;Harvard University;The university of Warwick,Topological data analysis;fuzzy clustering,209;-1;-1;53;-1,127;-1;-1;3;77,m;m,NAN,NAN,y,1
6593,ICLR,2021,Response Modeling of Hyper-Parameters for Deep Convolutional Neural Networks,Mathieu Tuli;Mahdi S. Hosseini;Konstantinos N Plataniotis,mathieutuli@cs.toronto.edu;~Mahdi_S._Hosseini1;~Konstantinos_N_Plataniotis1,5;5;4;4,3;4;4;3,Reject,0,10,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of New Brunswick;Toronto University",Hyper-Parameter Optimization;Response Surface Modeling;Convolution Neural Network;Low-Rank Factorization,18;453;-1,18;849;-1,m;m,NAN,NAN,n,1
6594,ICLR,2021,Coordinated Multi-Agent Exploration Using Shared Goals,Iou-Jen Liu;Unnat Jain;Alex Schwing,~Iou-Jen_Liu1;~Unnat_Jain1;~Alex_Schwing1,5;6;4;5,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Multi-agent RL;Deep RL;Exploration,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,8
6595,ICLR,2021,Do Deeper Convolutional Networks Perform Better?,Eshaan Nichani;Adityanarayanan Radhakrishnan;Caroline Uhler,~Eshaan_Nichani1;~Adityanarayanan_Radhakrishnan1;~Caroline_Uhler1,5;5;6;6,4;3;5;4,Reject,0,20,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;Electrical Engineering & Computer Science, Massachusetts Institute of Technology",Depth;Over-parameterization;Neural Networks,5;5;5,4;4;4,m;f,NAN,NAN,n,1
6596,ICLR,2021,On Batch-size Selection for Stochastic Training for Graph Neural Networks,Yaochen Hu;Amit Levi;Ishaan Kumar;Yingxue Zhang;Mark Coates,~Yaochen_Hu1;amit.levi@huawei.com;ishaan.kumar@huawei.com;yingxue.zhang@huawei.com;~Mark_Coates1,5;4;4;4,3;4;4;4,Reject,0,4,0.0,yes,9/28/20,"University of Alberta;University of Waterloo;University of Montreal;Huawei Canada, Huawei Noah's Ark Lab;McGill University",,110;34;128;-1;99,131;232;73;-1;40,m;m,canada,ca,y,10
6597,ICLR,2021,Parametric Density Estimation with Uncertainty using Deep Ensembles,Abel Peirson;Taylor Howell;Marius Aurel Tirlea,~Abel_Peirson1;thowell@stanford.edu;mtirlea@stanford.edu,5;4;5;5,3;3;3;3,Reject,0,8,0.0,yes,9/28/20,Stanford University;;Stanford University,Deep ensembles;deep learning;computer vision;density estimation;uncertainty,5;-1;5,2;-1;2,m;u,usa,usa,n,
6598,ICLR,2021,SSW-GAN: Scalable Stage-wise Training of Video GANs,Lluis Castrejon;Nicolas Ballas;Aaron Courville,~Lluis_Castrejon1;~Nicolas_Ballas1;~Aaron_Courville3,6;3;3;6;7,5;4;3;3;5,Reject,0,12,0.0,yes,9/28/20,Facebook;Facebook;University of Montreal,video generation;GANs;scalable methods,-1;-1;128,-1;-1;73,m;m,canada,ca,n,5;4
6599,ICLR,2021,Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent,Bao Wang;Tan Minh Nguyen;Tao Sun;Andrea Bertozzi;Richard Baraniuk;Stanley Osher,~Bao_Wang1;~Tan_Minh_Nguyen1;~Tao_Sun7;~Andrea_Bertozzi1;~Richard_Baraniuk1;~Stanley_Osher1,6;6;4;5;5,4;4;4;3;4,Reject,0,24,0.0,yes,9/28/20,"University of Utah;University of Wisconsin, Madison;National University of Defense Technology;University of California-Los Angeles;William Marsh Rice University;University of California, Los Angeles",Nesterov Accelerated Gradient;Deep Learning;Image Classification,58;18;-1;-1;92;-1,239;49;-1;15;124;15,m;m,usa,usa,y,1;9
6600,ICLR,2021,Importance and Coherence: Methods for Evaluating Modularity in Neural Networks,Shlomi Hod;Stephen Casper;Daniel Filan;Cody Wild;Andrew Critch;Stuart Russell,~Shlomi_Hod1;~Stephen_Casper1;~Daniel_Filan1;~Cody_Wild1;~Andrew_Critch1;~Stuart_Russell1,5;4;4,4;4;3,Reject,0,14,0.0,yes,9/28/20,Boston University;Harvard University;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California - Berkeley,interpretability;modularity,79;53;-1;-1;-1;-1,54;3;7;7;7;7,m;m,usa,usa,n,10
6601,ICLR,2021,On the Importance of Looking at the Manifold,Nil Adell Mill;Jannis Born;Nathaniel Park;James Hedrick;Mar√≠a Rodr√≠guez Mart√≠nez;Matteo Manica,~Nil_Adell_Mill1;~Jannis_Born1;npark@us.ibm.com;~James_Hedrick1;mrm@zurich.ibm.com;~Matteo_Manica1,4;3;5;4,3;4;4;4,Reject,0,1,0.0,yes,9/28/20,Swiss Federal Institute of Technology;International Business Machines;;;;International Research Europe;International Business Machines,Topological Learning;GNN;VAE,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,10;5
6602,ICLR,2021,Neurosymbolic Deep Generative Models for Sequence Data with Relational Constraints,Halley Young;Maxwell Du;Osbert Bastani,~Halley_Young1;maxdu@seas.upenn.edu;~Osbert_Bastani1,4;6;7;6,4;4;4;4,Reject,0,1,0.0,yes,9/28/20,"University of Pennsylvania;School of Engineering and Applied Science, University of Pennsylvania;University of Pennsylvania",neurosymbolic;sequence;program synthesis;generative;constraint;music;poetry,20;20;20,13;13;13,f;m,usa,usa,n,5
6603,ICLR,2021,Certified robustness against physically-realizable patch attack via randomized cropping,Wan-Yi Lin;Fatemeh Sheikholeslami;jinghao shi;Leslie Rice;J Zico Kolter,~Wan-Yi_Lin1;~Fatemeh_Sheikholeslami1;~jinghao_shi1;~Leslie_Rice1;~J_Zico_Kolter1,5;5;4;5,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,Bosch research;Bosch Center for AI;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,adversarial machine learning;certifiable defense;patch attack,-1;-1;1;1;1,-1;-1;28;28;28,f;m,usa,usa,n,4
6604,ICLR,2021,Benchmarking Bias Mitigation Algorithms in Representation Learning through Fairness Metrics,Charan Reddy;Soroush Mehri;Deepak Sharma;Samira Shabanian;Sina Honari,~Charan_Reddy1;~Soroush_Mehri1;~Deepak_Sharma1;~Samira_Shabanian1;~Sina_Honari1,4;5;5;4,5;2;4;4,Reject,0,5,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Microsoft Research;McGill University;Microsoft;Swiss Federal Institute of Technology Lausanne",fairness model evaluation;fair deep learning;adversarial fairness,128;-1;99;-1;-1,73;-1;40;-1;-1,m;m,NAN,NAN,n,8;1;7
6605,ICLR,2021,Assisting the Adversary to Improve GAN Training,Andreas Munk;William Harvey;Frank Wood,~Andreas_Munk1;~William_Harvey1;~Frank_Wood2,4;4;3;6,4;4;5;2,Reject,0,5,0.0,yes,9/28/20,University of British Columbia;University of British Columbia;University of British Columbia,Generative Adversarial Networks;GANs,58;58;58,34;34;34,m;m,canada,ca,y,1;5
6606,ICLR,2021,Compressing gradients in distributed SGD by exploiting their temporal correlation,Tharindu Adikari;Stark Draper,~Tharindu_Adikari1;~Stark_Draper1,5;2;6;4,4;5;4;4,Reject,0,10,0.0,yes,9/28/20,Toronto University;Toronto University,distributed optimization;gradient compression;error-feedback,-1;-1,-1;-1,m;m,NAN,NAN,y,1;9
6607,ICLR,2021,Cortico-cerebellar networks as decoupled neural interfaces,Joseph Pemberton;Ellen Boven;Richard Apps;Rui Ponte Costa,oq19042@bristol.ac.uk;ellen.boven@bristol.ac.uk;r.apps@bristol.ac.uk;~Rui_Ponte_Costa3,3;5;7,3;5;3,Reject,0,4,0.0,yes,9/28/20,University of Bristol;University of Bristol;;University of Bristol,systems neuroscience;cerebellum;neocortex;decoupled neural interfaces;deep learning;decorrelation;inverse models;forward models,110;110;-1;110,91;91;-1;91,m;m,europe,uk,n,
6608,ICLR,2021,Score-based Causal Discovery from Heterogeneous Data,Chenwei Ding;Biwei Huang;Mingming Gong;Kun Zhang;Tongliang Liu;Dacheng Tao,~Chenwei_Ding1;~Biwei_Huang1;~Mingming_Gong1;~Kun_Zhang1;~Tongliang_Liu1;~Dacheng_Tao1,6;5;3;7,4;4;4;4,Reject,0,11,0.0,yes,9/28/20,University of Sydney;Carnegie Mellon University;The University of Melbourne;Carnegie Mellon University;University of Sydney;JD.com,causal discovery;heterogeneous data;structure learning,71;1;85;1;71;-1,51;28;31;28;51;-1,u;m,NAN,NAN,y,10
6609,ICLR,2021,ALFA: Adversarial Feature Augmentation for Enhanced Image Recognition,Tianlong Chen;Yu Cheng;Zhe Gan;Yu Hu;Zhangyang Wang;Jingjing Liu,~Tianlong_Chen1;~Yu_Cheng1;~Zhe_Gan1;~Yu_Hu3;~Zhangyang_Wang1;~Jingjing_Liu2,5;4;4;6,3;4;5;4,Reject,0,19,0.0,yes,9/28/20,"University of Texas, Austin;Microsoft Research;Microsoft;Microsoft;University of Texas, Austin;Microsoft",Adversarial Training;Image Recognition;Generalization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,1;4
6610,ICLR,2021,Efficiently Troubleshooting Image Segmentation Models with Human-In-The-Loop,Haotao Wang;Tianlong Chen;Zhangyang Wang;Kede Ma,~Haotao_Wang1;~Tianlong_Chen1;~Zhangyang_Wang1;~Kede_Ma2,8;3;4,4;4;4,Reject,0,6,0.0,yes,9/28/20,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin;City University of Hong Kong",,-1;-1;-1;128,-1;-1;-1;126,m;m,asia,hk,n,8;2;1
6611,ICLR,2021,Energy-based View of Retrosynthesis,Ruoxi Sun;Hanjun Dai;Li Li;Steven Kearnes;Bo Dai,~Ruoxi_Sun2;~Hanjun_Dai1;~Li_Li8;~Steven_Kearnes1;~Bo_Dai1,5;5;5;8,4;4;5;4,Reject,0,10,0.0,yes,9/28/20,Google;Google Research;Google;Stanford University;Google Brain,Applications;Retrosynthesis;Energy-based Model,-1;-1;-1;5;-1,-1;-1;-1;2;-1,f;m,NAN,NAN,n,3;11;1;10
6612,ICLR,2021,EXPLORING VULNERABILITIES OF BERT-BASED APIS,Xuanli He;Lingjuan Lyu;Lichao Sun;Xiaojun Chang;Jun Zhao,~Xuanli_He2;~Lingjuan_Lyu1;~Lichao_Sun1;~Xiaojun_Chang3;~Jun_Zhao1,6;6;6;4,5;4;3;3,Reject,0,10,0.0,yes,9/28/20,Monash University;the University of Melbourne;Lehigh University;Monash University;Nanyang Technological University,BERT-based models;vulnerabilities;attribute inference;transferability,92;85;263;92;44,64;31;613;64;47,u;m,asia,sg,n,3;4
6613,ICLR,2021,Benefits of Assistance over Reward Learning,Rohin Shah;Pedro Freire;Neel Alex;Rachel Freedman;Dmitrii Krasheninnikov;Lawrence Chan;Michael D Dennis;Pieter Abbeel;Anca Dragan;Stuart Russell,~Rohin_Shah1;~Pedro_Freire1;~Neel_Alex1;~Rachel_Freedman1;~Dmitrii_Krasheninnikov1;~Lawrence_Chan2;~Michael_D_Dennis1;~Pieter_Abbeel2;~Anca_Dragan1;~Stuart_Russell1,5;6;4;5;7,3;5;3;2;4,Reject,0,22,0.0,yes,9/28/20,DeepMind;University of California Berkeley;University of California Berkeley;University of California Berkeley;Sony Europe Ltd.;University of California Berkeley;University of California Berkeley;Covariant;University of California-Berkeley;University of California - Berkeley,assistance;reward learning;preference learning;active learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;7;7;7;-1;7;7;-1;7;7,m;m,usa,usa,y,
6614,ICLR,2021,Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning,Chi Zhang;Sirui Xie;Baoxiong Jia;Yixin Zhu;Ying Nian Wu;Song-Chun Zhu,~Chi_Zhang12;~Sirui_Xie1;~Baoxiong_Jia1;~Yixin_Zhu1;~Ying_Nian_Wu1;~Song-Chun_Zhu1,6;5;7;5,3;4;1;4,Reject,0,8,0.0,yes,9/28/20,"Amazon;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;UCLA;University of California-Los Angeles",,-1;-1;-1;-1;327;-1,-1;15;15;15;16;15,m;m,usa,usa,n,1
6615,ICLR,2021,A law of robustness for two-layers neural networks,Sebastien Bubeck;Yuanzhi Li;Dheeraj Mysore Nagaraj,~Sebastien_Bubeck1;~Yuanzhi_Li1;~Dheeraj_Mysore_Nagaraj1,5;5;7;7,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,"Microsoft;CMU, Carnegie Mellon University;Massachusetts Institute of Technology",neural networks;approximation theory;robust machine learning,-1;1;5,-1;28;4,m;m,usa,usa,y,1
6616,ICLR,2021,Model-Targeted Poisoning Attacks with Provable Convergence,Fnu Suya;Saeed Mahloujifar;David Evans;Yuan Tian,~Fnu_Suya1;~Saeed_Mahloujifar1;~David_Evans1;~Yuan_Tian2,6;3;7;5,3;4;5;4,Reject,0,7,0.0,yes,9/28/20,University of Virginia;Princeton University;University of Virginia;University of Virginia,adversarial machine learning;data poisoning attack;convergence,53;29;53;53,117;9;117;117,f;m,usa,usa,y,1;9;4
6617,ICLR,2021,Speeding up Deep Learning Training by Sharing Weights and Then Unsharing,Shuo Yang;Le Hou;Xiaodan Song;qiang liu;Denny Zhou,~Shuo_Yang6;~Le_Hou1;~Xiaodan_Song1;~qiang_liu4;~Denny_Zhou1,6;5;5;4,4;3;4;3,Reject,0,10,0.0,yes,9/28/20,"University of Texas, Austin;Google Research;University of Washington;University of Texas, Austin;Google",fast training;BERT;transformer;weight sharing;deep learning,-1;-1;11;-1;-1,-1;-1;29;-1;-1,m;m,NAN,NAN,y,8;2;3
6618,ICLR,2021,Information Condensing Active Learning,Siddhartha Jain;Ge Liu;David Gifford,~Siddhartha_Jain1;~Ge_Liu2;~David_Gifford1,6;6;6;8,4;3;3;4,Reject,0,9,0.0,yes,9/28/20,Amazon;Amazon AWS AI;Massachusetts Institute of Technology,active learning,-1;-1;5,-1;-1;4,m;m,usa,usa,n,11
6619,ICLR,2021,On the Certified Robustness for Ensemble Models and Beyond,Zhuolin Yang;Linyi Li;Xiaojun Xu;Bhavya Kailkhura;Bo Li,~Zhuolin_Yang1;~Linyi_Li1;~Xiaojun_Xu1;~Bhavya_Kailkhura1;~Bo_Li19,5;4;5;6,4;4;2;4,Reject,0,10,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois at Urbana-Champaign;University of Illinois, Urbana Champaign;Lawrence Livermore National Laboratory;University of Illinois, Urbana Champaign",Adversarial Machine Learning;Model Ensemble;Certified Robustness,-1;-1;-1;-1;-1,-1;48;-1;-1;-1,m;f,usa,usa,y,1;4
6620,ICLR,2021,Convergent Adaptive Gradient Methods in Decentralized Optimization,Xiangyi Chen;Belhal Karimi;Weijie Zhao;Ping Li,~Xiangyi_Chen1;~Belhal_Karimi1;weijiezhao@baidu.com;~Ping_Li3,3;8;4;7;3,3;4;5;1;5,Reject,0,10,0.0,yes,9/28/20,"University of Minnesota, Minneapolis;Baidu Research;Baidu;Baidu",Adam;decentralized optimization;adaptive gradient methods,71;-1;-1;-1,85;-1;-1;-1,u;m,NAN,NAN,y,8;1
6621,ICLR,2021,Decoy-enhanced Saliency Maps ,Yang Young Lu;Wenbo Guo;Xinyu Xing;William Noble,~Yang_Young_Lu1;~Wenbo_Guo1;~Xinyu_Xing1;~William_Noble1,6;7;6,4;3;2,Reject,0,8,0.0,yes,9/28/20,"University of Washington, Seattle;Pennsylvania State University;Pennsylvania State University;University of Washington, Seattle",Deep neural network;Explainable AI;Saliency methods;Decoys,11;44;44;11,29;-1;-1;29,m;m,NAN,NAN,y,4
6622,ICLR,2021,Deep Continuous Networks,Nergis Tomen;Silvia Laura Pintea;Jan van Gemert,~Nergis_Tomen1;~Silvia_Laura_Pintea1;~Jan_van_Gemert1,7;5;6,4;4;3,Reject,0,8,0.0,yes,9/28/20,Delft University of Technology;Delft University of Technology;Delft University of Technology,continuous representations;neuroscience;convolutional neural networks;gaussian scale-space;learnable scale;receptive field size;neural ODEs;pattern completion,-1;-1;-1,78;78;78,f;m,NAN,NAN,n,
6623,ICLR,2021,Uniform-Precision Neural Network Quantization via Neural Channel Expansion,Seongmin Park;Beomseok Kwon;Kyuyoung Sim;Jieun Lim;Tae-Ho Kim;Jungwook Choi,skstjdals@hanyang.ac.kr;qjatjr4828@hanyang.ac.kr;kysim@nota.ai;jieun.lim@nota.ai;~Tae-Ho_Kim2;~Jungwook_Choi1,6;6;5,5;4;5,Reject,0,6,0.0,yes,9/28/20,Hanyang University;Hanyang University;;;Seoul National University;Korea Advanced Institute of Science and Technology;Hanyang University,deep neural network;quantization;neural architecture search;image classification;reduced precision;inference,209;209;-1;-1;37;-1;209,380;380;-1;-1;60;96;380,m;m,asia,kr,n,
6624,ICLR,2021,Globally Injective ReLU networks,Michael Puthawala;Konik Kothari;Matti Lassas;Ivan Dokmaniƒá;Maarten V. de Hoop,map19@rice.edu;~Konik_Kothari1;~Matti_Lassas1;~Ivan_Dokmaniƒá1;~Maarten_V._de_Hoop2,5;5;8;5,4;2;3;3,Reject,0,8,0.0,yes,9/28/20,"University of California, Los Angeles;University of Illinois, Urbana Champaign;University of Helsinki;University of Basel;Rice University",Generative models;injectivity of neural networks;universal approximation;inference;compressed sensing with generative priors;well-posedness;random projections,-1;-1;209;453;92,15;-1;98;92;124,m;m,australasia,au,y,1;5
6625,ICLR,2021,Motion Forecasting with Unlikelihood Training,Deyao Zhu;Mohamed Zahran;Li Erran Li;Mohamed Elhoseiny,~Deyao_Zhu1;~Mohamed_Zahran1;~Li_Erran_Li1;~Mohamed_Elhoseiny1,4;4;5;6,5;5;4;3,Reject,0,12,0.0,yes,9/28/20,KAUST;Udacity;Amazon;KAUST,,110;-1;-1;110,-1;-1;-1;-1,m;m,europe,gr,n,
6626,ICLR,2021,Learning to Plan Optimistically: Uncertainty-Guided Deep Exploration via Latent Model Ensembles,Tim Seyde;Wilko Schwarting;Sertac Karaman;Daniela Rus,~Tim_Seyde1;~Wilko_Schwarting1;~Sertac_Karaman1;~Daniela_Rus1,6;6;4;5,5;4;4;4,Reject,0,10,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Model-Based Reinforcement Learning;Deep Exploration;Continuous Visual Control;UCB;Latent Space;Ensembling,5;5;5;5,4;4;4;4,m;f,usa,usa,n,1
6627,ICLR,2021,Understanding Mental Representations Of Objects Through Verbs Applied To Them,Ka Chun Lam;Francisco Pereira;Maryam Vaziri-Pashkam;Kristin Woodard;Emalie McMahon,~Ka_Chun_Lam1;~Francisco_Pereira1;~Maryam_Vaziri-Pashkam1;kristin.woodard@nih.gov;emaliemcmahon@jhu.edu,7;7;6;5,4;3;4;4,Reject,0,11,0.0,yes,9/28/20,National Institute of Health;National Institute of Mental Health;Laboratory of brain and cognition  National institute of mental Health;;Johns Hopkins University,Affordance;affordance embedding;object representation,-1;-1;-1;-1;71,-1;-1;-1;-1;12,m;f,usa,usa,n,
6628,ICLR,2021,GL-Disen: Global-Local disentanglement for unsupervised learning of graph-level representations,Thilini Cooray;Ngai-man Cheung;Wei Lu,~Thilini_Cooray1;~Ngai-man_Cheung1;~Wei_Lu4,5;4;5;6;3,4;4;3;4;4,Reject,0,15,0.0,yes,9/28/20,Singapore University of Technology and Design;Singapore University of Technology and Design;Singapore University of Technology and Design,Unsupervised Graph Representations;Disentanglement Learning;GNN;Unsupervised Learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,10;5
6629,ICLR,2021,Efficient Differentiable Neural Architecture Search with Model Parallelism,Yi-Wei Chen;Qingquan Song;Xia Hu,~Yi-Wei_Chen1;~Qingquan_Song1;~Xia_Hu4,5;5;6;5,3;4;4;4,Reject,0,13,0.0,yes,9/28/20,Texas A&M;Texas A&M;Texas A&M,Neural Architecture Search;Model Parallel,46;46;46,195;195;195,m;m,NAN,NAN,n,10
6630,ICLR,2021,Similarity Search for Efficient Active Learning and Search of Rare Concepts,Cody Coleman;Edward Chou;Sean Culatana;Peter Bailis;Alexander C. Berg;Roshan Sumbaly;Matei Zaharia;I. Zeki Yalniz,~Cody_Coleman1;ejchou@fb.com;seanchang.stat@gmail.com;~Peter_Bailis1;~Alexander_C._Berg1;rsumbaly@gmail.com;~Matei_Zaharia1;~I._Zeki_Yalniz1,4;8;5,4;3;5,Reject,0,6,0.0,yes,9/28/20,"Stanford University;;;;;Stanford University;Department of Computer Science, University of North Carolina, Chapel Hill;;;Stanford University;Facebook",active learning;active search,5;-1;-1;-1;-1;5;64;-1;-1;5;-1,2;-1;-1;-1;-1;2;-1;-1;-1;2;-1,m;m,NAN,NAN,n,2
6631,ICLR,2021,Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies,Yae Jee Cho;Jianyu Wang;Gauri Joshi,~Yae_Jee_Cho1;~Jianyu_Wang2;~Gauri_Joshi1,4;6;6;6,4;3;4;4,Reject,0,16,0.0,yes,9/28/20,"Carnegie Mellon University;CMU, Carnegie Mellon University;CMU, Carnegie Mellon University",distributed optimization;federated learning;client selection,1;1;1,28;28;28,m;m,NAN,NAN,y,
6632,ICLR,2021,Closing the Generalization Gap in One-Shot Object Detection,Claudio Michaelis;Matthias Bethge;Alexander S Ecker,~Claudio_Michaelis1;~Matthias_Bethge1;~Alexander_S_Ecker1,6;7;6;5,5;4;3;4,Reject,0,18,0.0,yes,9/28/20,University of Tuebingen;University of Tuebingen;University of Goettingen,One-Shot Learning;Few-Shot Learning;Object Detection;One-Shot Object Detection;Generalization,128;128;327,78;78;130,m;m,europe,de,n,6;2;1
6633,ICLR,2021,Dependency Structure Discovery from Interventions,Nan Rosemary Ke;Olexa Bilaniuk;Anirudh Goyal;Stefan Bauer;Bernhard Sch√∂lkopf;Michael Curtis Mozer;Hugo Larochelle;Christopher Pal;Yoshua Bengio,~Nan_Rosemary_Ke1;~Olexa_Bilaniuk1;~Anirudh_Goyal1;~Stefan_Bauer1;~Bernhard_Sch√∂lkopf1;~Michael_Curtis_Mozer1;~Hugo_Larochelle1;~Christopher_Pal1;~Yoshua_Bengio1,4;6;5;4,5;3;4;4,Reject,0,13,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Montreal;University of Montreal;Swiss Federal Institute of Technology;Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of Colorado at Boulder;Google;Polytechnique Montreal;University of Montreal",structure learning;deep learning;continuous;optimization,128;128;128;-1;-1;-1;-1;327;128,73;73;73;-1;-1;-1;-1;-1;73,f;m,canada,ca,n,11;10
6634,ICLR,2021,Exchanging Lessons Between Algorithmic Fairness and Domain Generalization,Elliot Creager;Joern-Henrik Jacobsen;Richard Zemel,~Elliot_Creager1;~Joern-Henrik_Jacobsen1;~Richard_Zemel1,4;5;4;6,4;3;3;2,Reject,0,7,0.0,yes,9/28/20,University of Toronto;Vector Institute;University of Toronto,algorithmic fairness;domain generalization;representation learning;invariance,18;-1;18,18;-1;18,m;m,canada,ca,y,1;7
6635,ICLR,2021,PettingZoo: Gym for Multi-Agent Reinforcement Learning,Justin K Terry;Benjamin Black;Mario Jayakumar;Ananth Hari;Luis Santos;Clemens Dieffendahl;Niall L Williams;Yashas Lokesh;Ryan Sullivan;Caroline Horsch;Praveen Ravi,~Justin_K_Terry1;benjamin.black@swarmlabs.com;mariojay@umd.edu;ahari1@umd.edu;luis.santos@swarmlabs.com;dieffendahl@campus.tu-berlin.de;niallw@umd.edu;yashloke@umd.edu;ryan.sullivan@swarmlabs.com;chorsch@umd.edu;pravi@umd.edu,7;5;6;3,3;4;3;3,Reject,0,7,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;;;TU Berlin;University of Maryland, College Park;Amazon;;;University of Maryland, College Park;University of Maryland, College Park",Reinforcement Learning;Multi-agent Reinforcement Learning,12;12;12;12;-1;-1;128;12;-1;-1;-1;12;12,90;90;90;90;-1;-1;-1;90;-1;-1;-1;90;90,m;m,usa,usa,n,
6636,ICLR,2021,Model-Free Counterfactual Credit Assignment,Thomas Mesnard;Theophane Weber;Fabio Viola;Shantanu Thakoor;Alaa Saade;Anna Harutyunyan;Will Dabney;Tom Stepleton;Nicolas Heess;Marcus Hutter;Lars Holger Buesing;Remi Munos,mesnard@google.com;~Theophane_Weber1;~Fabio_Viola2;thakoor@google.com;alaas@google.com;~Anna_Harutyunyan1;~Will_Dabney1;~Tom_Stepleton1;~Nicolas_Heess1;~Marcus_Hutter1;~Lars_Holger_Buesing1;~Remi_Munos1,3;5;5;6,3;4;3;3,Reject,0,14,0.0,yes,9/28/20,DeepMind;Google DeepMind;DeepMind;Google;DeepMind;DeepMind;Google DeepMind;;Google;DeepMind;Deepmind;DeepMind,credit assignment;model-free RL;causality;hindsight,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6637,ICLR,2021,Mixture Representation Learning with Coupled Autoencoding Agents,Yeganeh Marghi;Rohan Gala;Uygar S√ºmb√ºl,~Yeganeh_Marghi1;~Rohan_Gala1;~Uygar_S√ºmb√ºl2,6;6;5;5,5;3;3;3,Reject,0,8,0.0,yes,9/28/20,Northeastern University;Northeastern University;Allen Institute,Multi-agent network;representation learning;collective decision making;type-preserving data augmentation,16;16;-1,895;895;-1,f;u,NAN,NAN,y,5
6638,ICLR,2021,Impact-driven Exploration with Contrastive Unsupervised Representations,Min Jae Song;Dan Kushnir,~Min_Jae_Song1;~Dan_Kushnir1,7;4;4;4,3;4;4;3,Reject,0,12,0.0,yes,9/28/20,"New York University;Weizmann Institute, Technion",reinforcement learning;exploration;curiosity;episodic memory,23;29,26;-1,m;m,NAN,NAN,n,
6639,ICLR,2021,WeMix: How to Better Utilize Data Augmentation,Yi Xu;Asaf Noy;Ming Lin;Qi Qian;Li Hao;Rong Jin,~Yi_Xu8;asaf.noy@alibaba-inc.com;~Ming_Lin4;~Qi_Qian1;~Li_Hao1;~Rong_Jin1,4;5;7;4,3;3;4;2,Reject,0,4,0.0,yes,9/28/20,Alibaba Group;;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group,Data Augmentation;Data Bias;Non-convex Optimization;Deep Learning Theory,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6640,ICLR,2021,Boosting One-Point Derivative-Free Online Optimization via Residual Feedback,Yan Zhang;Yi Zhou;Kaiyi Ji;Michael Zavlanos,yan.zhang2@duke.edu;~Yi_Zhou2;~Kaiyi_Ji1;~Michael_Zavlanos1,4;4;4;8,4;4;4;4,Reject,0,19,0.0,yes,9/28/20,Duke University;University of Utah;Ohio State University;Duke University,zeroth-order optimization;online learning,46;58;58;46,20;239;78;20,m;m,europe,se,y,1
6641,ICLR,2021,CoLES: Contrastive learning for event sequences with self-supervision,Dmitrii Babaev;Nikita Ovsov;Ivan A Kireev;Gleb Gusev;Maria Ivanova;Alexander Tuzhilin,~Dmitrii_Babaev2;~Nikita_Ovsov1;~Ivan_A_Kireev1;~Gleb_Gusev1;~Maria_Ivanova2;~Alexander_Tuzhilin1,5;6;5,4;4;3,Reject,0,5,0.0,yes,9/28/20,Sberbank;Lomonosov Moscow State University;BMSTU;;Moscow Institute of Physics and Technology;New York University,representation learning;contrastive learning;neural networks;event sequiences,-1;-1;-1;-1;-1;23,-1;173;-1;-1;224;26,m;m,usa,usa,y,2
6642,ICLR,2021,Learning Active Learning in the Batch-Mode Setup with Ensembles of Active Learning Agents,Malte Ebner;Bernhard Kratzwald;Stefan Feuerriegel,~Malte_Ebner1;bkratzwald@ethz.ch;sfeuerriegel@ethz.ch,4;4;3;7,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,University of Stuttgart;;;Swiss Federal Institute of Technology,active learning;ensembles,110;-1;-1;-1,354;-1;-1;-1,m;m,NAN,NAN,n,
6643,ICLR,2021,Time-varying Graph Representation Learning via Higher-Order Skip-Gram with Negative Sampling,Simone Piaggesi;Andr√© Panisson,~Simone_Piaggesi1;panisson@gmail.com,5;5;4;7,3;4;4;3,Reject,0,5,0.0,yes,9/28/20,University of Bologna;ISI Foundation,representation learning;node embeddings;temporal graphs;tensor factorization;disease spreading,-1;-1,167;-1,u;m,NAN,NAN,n,10
6644,ICLR,2021,Acoustic Neighbor Embeddings,Woojay Jeon,~Woojay_Jeon1,6;6;6;6;6,4;4;4;3;4,Reject,0,13,0.0,yes,9/28/20,Apple,,-1,-1,m,NAN,NAN,n,
6645,ICLR,2021,Latent Programmer: Discrete Latent Codes for Program Synthesis,Joey Hong;David Dohan;Rishabh Singh;Charles Sutton;Manzil Zaheer,~Joey_Hong2;~David_Dohan1;~Rishabh_Singh1;~Charles_Sutton1;~Manzil_Zaheer1,3;7;4;7,4;4;4;3,Reject,0,12,0.0,yes,9/28/20,California Institute of Technology;Google;Google Brain;Google;Zaheer,,150;-1;-1;-1;-1,4;-1;-1;-1;-1,m;m,NAN,NAN,n,3
6646,ICLR,2021,The Advantage Regret-Matching Actor-Critic,Audrunas Gruslys;Marc Lanctot;Remi Munos;Finbarr Timbers;Martin Schmid;Julien Perolet;Dustin Morrill;Vinicius Zambaldi;Jean-Baptiste Lespiau;John Schultz;Mohammad Gheshlaghi Azar;Michael Bowling;Karl Tuyls,~Audrunas_Gruslys1;~Marc_Lanctot1;~Remi_Munos1;~Finbarr_Timbers1;~Martin_Schmid2;~Julien_Perolet1;~Dustin_Morrill1;~Vinicius_Zambaldi1;~Jean-Baptiste_Lespiau1;~John_Schultz1;~Mohammad_Gheshlaghi_Azar1;~Michael_Bowling1;~Karl_Tuyls1,6;6;6,3;3;5,Reject,0,3,0.0,yes,9/28/20,DeepMind;DeepMind;DeepMind;DeepMind;Google;DeepMind;University of Alberta;DeepMind;;;Columbus State Community College;Northwestern University;DeepMind;Google DeepMind,Nash Equilibrium;Games;CFR,-1;-1;-1;-1;-1;-1;110;-1;-1;-1;-1;46;-1;-1,-1;-1;-1;-1;-1;-1;131;-1;-1;-1;-1;24;-1;-1,m;m,NAN,NAN,y,
6647,ICLR,2021,Characterizing Structural Regularities of Labeled Data in Overparameterized Models,Ziheng Jiang;Chiyuan Zhang;Kunal Talwar;Michael Curtis Mozer,~Ziheng_Jiang1;~Chiyuan_Zhang1;~Kunal_Talwar1;~Michael_Curtis_Mozer1,5;5;4,4;4;4,Reject,0,6,0.0,yes,9/28/20,"University of Washington, Seattle;Google;Apple;University of Colorado at Boulder",,11;-1;-1;-1,29;-1;-1;-1,m;m,usa,usa,n,
6648,ICLR,2021,Quantifying Task Complexity Through Generalized Information Measures,Aditya Chattopadhyay;Benjamin David Haeffele;Donald Geman;Rene Vidal,~Aditya_Chattopadhyay1;~Benjamin_David_Haeffele1;~Donald_Geman2;~Rene_Vidal1,5;5;6,1;3;5,Reject,0,6,0.0,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,Task Complexity;Information Pursuit;Deep Generative Models;Information Theory;Variational Autoencoders;Normalizing Flows,71;71;71;71,12;12;12;12,m;m,usa,usa,y,1;5
6649,ICLR,2021,Learning One-hidden-layer Neural Networks on Gaussian Mixture Models with Guaranteed Generalizability,Hongkang Li;Shuai Zhang;Meng Wang,~Hongkang_Li1;~Shuai_Zhang6;~Meng_Wang4,6;4;7;6,3;4;4;4,Reject,0,12,0.0,yes,9/28/20,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute,neural networks;generalization;Gaussian mixture model;sample complexity;learning algorithm,263;263;263,527;527;527,u;f,usa,usa,y,1
6650,ICLR,2021,Sample weighting as an explanation for mode collapse in generative adversarial networks,Aksel Wilhelm Wold Eide;Eilif Solberg;Ingebj√∏rg K√•sen,~Aksel_Wilhelm_Wold_Eide1;eilif.solberg@ffi.no;ingebjorg.kasen@ffi.no,6;6;6;6,3;4;4;4,Reject,0,17,0.0,yes,9/28/20,Norwegian Defence Research Establishment (FFI);Forsvarets Forskningsinstitutt;Norwegian Defence Research Establishment (FFI),GAN;generative adversarial networks;generative model;image synthesis;sample weighting;importance weighting;cost function;loss;mode collapse;mode dropping;coverage;divergence;FID;training dynamics;NS-GAN;MM-GAN;non-saturating;minimax,-1;-1;-1,-1;-1;-1,u;u,NAN,NAN,n,1;5;4
6651,ICLR,2021,You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling,Zhanpeng Zeng;Yunyang Xiong;Sathya N. Ravi;Shailesh Acharya;Glenn Fung;Vikas Singh,~Zhanpeng_Zeng1;~Yunyang_Xiong2;~Sathya_N._Ravi1;sachary1@amfam.com;~Glenn_Fung2;~Vikas_Singh1,2;6;6;5,4;5;3;4,Reject,0,8,0.0,yes,9/28/20,"University of Wisconsin, Madison;University of Wisconsin, Madison;University of Illinois, Chicago;University of North Texas, Denton;American Family Insurance;University of Wisconsin, Madison",self-attention;efficient;linear complexity;language model;transformer;BERT,18;18;-1;263;-1;18,49;49;-1;-1;-1;49,m;m,usa,usa,n,8;3
6652,ICLR,2021,D2RL: Deep Dense Architectures in Reinforcement Learning,Samarth Sinha;Homanga Bharadhwaj;Aravind Srinivas;Animesh Garg,~Samarth_Sinha1;~Homanga_Bharadhwaj1;~Aravind_Srinivas1;~Animesh_Garg1,5;4;8;4,4;4;3;4,Reject,0,13,0.0,yes,9/28/20,"University of Toronto, Toronto University;School of Computer Science, Carnegie Mellon University;University of California Berkeley;University of Toronto",Deep Reinforcement learning;Policy architectures,18;1;-1;18,18;28;7;18,m;m,canada,ca,n,2;3;5
6653,ICLR,2021,Deep Jump Q-Evaluation for Offline Policy Evaluation in Continuous Action Space,Hengrui Cai;Chengchun Shi;Rui Song;Wenbin Lu,~Hengrui_Cai1;c.shi7@lse.ac.uk;~Rui_Song2;wlu4@ncsu.edu,8;5;6;6,1;3;3;3,Reject,0,0,0.0,yes,9/28/20,North Carolina State University;London School of Economics;North Carolina State University;North Carolina State University,Continuous action space;Deep learning;Multi-scale change point detection;Off-policy evaluation,92;-1;92;92,340;27;340;340,f;m,usa,usa,y,
6654,ICLR,2021,Balancing Robustness and Sensitivity using Feature Contrastive Learning,Seungyeon Kim;Daniel Glasner;Srikumar Ramalingam;Cho-Jui Hsieh;Kishore Papineni;Sanjiv Kumar,~Seungyeon_Kim1;~Daniel_Glasner2;~Srikumar_Ramalingam2;~Cho-Jui_Hsieh1;papineni@google.com;~Sanjiv_Kumar1,7;5;6;5,4;4;3;2,Reject,0,8,0.0,yes,9/28/20,Google;Google;Google;Amazon;;;Google,deep learning;non-adversarial robustness;sensitivity;input perturbation;contextual feature utility;contextual feature sensitivity.,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
6655,ICLR,2021,Jointly-Trained State-Action Embedding for Efficient Reinforcement Learning,Paul Julian Pritz;Liang Ma;Kin Leung,~Paul_Julian_Pritz1;~Liang_Ma4;~Kin_Leung1,4;5;5;3;6,4;5;4;3;2,Reject,0,26,0.0,yes,9/28/20,Imperial College London;Dataminr;Imperial College London,reinforcement learning;embedding;representation learning;state-action embedding,53;-1;53,11;-1;11,m;m,europe,uk,y,1
6656,ICLR,2021,MVP: Multivariate polynomials for conditional generation,Grigorios Chrysos;Yannis Panagakis,~Grigorios_Chrysos1;~Yannis_Panagakis1,6;5;5,4;3;3,Reject,0,16,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;National and Kapodistrian University of Athens,conditional image generation;generative models;polynomial neural networks,-1;327,-1;488,m;m,NAN,NAN,y,5;4
6657,ICLR,2021,Multilayer Dense Connections for Hierarchical Concept Classification,Toufiq Parag;Hongcheng Wang,~Toufiq_Parag3;~Hongcheng_Wang4,3;5;5;2,4;3;3;5,Reject,0,5,0.0,yes,9/28/20,Verisk Analytics;Comcast,Deep Learning: Applications;Methodology;and Theory;Recognition: Detection;Categorization;Retrieval and Matching;Scene Understanding;Visual Reasoning,-1;-1,-1;-1,m;m,NAN,NAN,n,2
6658,ICLR,2021,Minimum Description Length Recurrent Neural Networks,Nur Lan;Emmanuel Chemla;Roni Katzir,nurlan@mail.tau.ac.il;chemla@ens.fr;~Roni_Katzir1,3;4;6;4,3;3;3;5,Reject,0,4,0.0,yes,9/28/20,Tel Aviv University;;Tel Aviv University,recurrent neural network;neural network;language modeling;minimum description length;genetic algorithm;semantics;syntax,34;-1;34,190;-1;190,u;m,europe,il,n,1
6659,ICLR,2021,Communication-Efficient Sampling for Distributed Training of Graph Convolutional Networks,Peng Jiang;Masuma Akter Rumi,~Peng_Jiang4;masumaakter-rumi@uiowa.edu,5;4;4;6,3;5;5;3,Reject,0,4,0.0,yes,9/28/20,University of Iowa;University of Iowa,Graph Convolutional Networks;Sampling;Distributed Training,174;174,245;245,m;f,europe,de,n,10
6660,ICLR,2021,Integrating linguistic knowledge into DNNs: Application to online grooming detection,Jay Morgan;Adeline Paiement;Nuria Lorenzo-Dus;Anina Kinzel;Matteo Di Cristofaro,~Jay_Morgan1;~Adeline_Paiement1;n.lorenzo-dus@swansea.ac.uk;a.l.kinzel@swansea.ac.uk;mdc@infogrep.it,4;6;5,4;4;4,Reject,0,11,0.0,yes,9/28/20,Swansea University;University of Toulon;;;University of Modena and Reggio Emilia,Machine Learning;Corpus Linguistics,-1;-1;-1;-1;-1,287;-1;-1;-1;434,m;m,NAN,NAN,n,8
6661,ICLR,2021,Dual-Tree Wavelet Packet CNNs for Image Classification,Hubert Leterme;K√©vin Polisano;Val√©rie Perrier;Karteek Alahari,~Hubert_Leterme1;kevin.polisano@univ-grenoble-alpes.fr;valerie.perrier@grenoble-inp.fr;~Karteek_Alahari1,4;4;8;6,4;3;3;4,Reject,0,7,0.0,yes,9/28/20,University of Grenoble-Alpes;University of Grenoble-Alpes;;;Inria,convolutional neural networks;wavelet packet transform;dual-tree wavelet packet transform;image classification;deep learning;image processing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6662,ICLR,2021,Factorized linear discriminant analysis for phenotype-guided representation learning of neuronal gene expression data,Mu Qiao;Markus Meister,~Mu_Qiao3;~Markus_Meister1,5;6;5;5,3;4;2;3,Reject,0,8,0.0,yes,9/28/20,California Institute of Technology;California Institute of Technology,factorized linear discriminant analysis;phenotype;gene expression;representation learning,150;150,4;4,m;m,usa,usa,n,
6663,ICLR,2021,BasisNet: Two-stage Model Synthesis for Efficient Inference,Mingda Zhang;Andrey Zhmoginov;Andrew G. Howard;Brendan Jou;Yukun Zhu;Li Zhang;Rebecca Hwa;Adriana Kovashka,~Mingda_Zhang1;~Andrey_Zhmoginov1;~Andrew_G._Howard1;~Brendan_Jou1;~Yukun_Zhu1;zhl@google.com;~Rebecca_Hwa1;~Adriana_Kovashka1,3;6;7,5;4;5,Reject,0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Pittsburgh;University of California Berkeley;Google;Google;Google;;;University of Pittsburgh;University of Pittsburgh",,79;-1;-1;-1;-1;-1;-1;79;79,-1;7;-1;-1;-1;-1;-1;133;133,m;f,usa,usa,n,
6664,ICLR,2021,Bridging the Imitation Gap by Adaptive Insubordination,Luca Weihs;Unnat Jain;Jordi Salvador;Svetlana Lazebnik;Aniruddha Kembhavi;Alex Schwing,~Luca_Weihs1;~Unnat_Jain1;~Jordi_Salvador3;~Svetlana_Lazebnik1;~Aniruddha_Kembhavi1;~Alex_Schwing1,6;5;6;6,4;3;4;3,Reject,0,6,0.0,yes,9/28/20,"Allen Institute for Artificial Intelligence;University of Illinois, Urbana Champaign;Allen Institute for AI;University of Illinois at Urbana-Champaign;Allen Institute for Artificial Intelligence;University of Illinois, Urbana Champaign",Privileged Experts;Imitation Learning;Reinforcement Learning;Actor-Critic;Behavior Cloning;MiniGrid;Knowledge Distillation,-1;-1;-1;-1;-1;-1,-1;-1;-1;48;-1;-1,m;m,usa,usa,y,
6665,ICLR,2021,Can Kernel Transfer Operators Help Flow based Generative Models?,Zhichun Huang;Rudrasis Chakraborty;Xingjian Zhen;Vikas Singh,~Zhichun_Huang1;~Rudrasis_Chakraborty1;~Xingjian_Zhen1;~Vikas_Singh1,5;5;2;5,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,"CMU, Carnegie Mellon University;University of California Berkeley;University of Wisconsin, Madison;University of Wisconsin, Madison",,1;-1;18;18,28;7;49;49,u;m,usa,usa,y,5
6666,ICLR,2021,A Critical Analysis of Distribution Shift,Dan Hendrycks;Steven Basart;Norman Mu;Saurav Kadavath;Frank Wang;Evan Dorundo;Rahul Desai;Tyler Zhu;Samyak Parajuli;Mike Guo;Dawn Song;Jacob Steinhardt;Justin Gilmer,~Dan_Hendrycks1;~Steven_Basart1;~Norman_Mu1;~Saurav_Kadavath1;fkwang@google.com;edorundo@google.com;rahuldesai@berkeley.edu;tyler.zhu@berkeley.edu;~Samyak_Parajuli1;mike0221@berkeley.edu;~Dawn_Song1;~Jacob_Steinhardt1;~Justin_Gilmer1,5;4;8;7,4;5;4;5,Reject,0,14,0.0,yes,9/28/20,UC Berkeley;University of Chicago;University of California Berkeley;University of California Berkeley;;;;;;;;;University of California Berkeley;;;University of California Berkeley;University of California Berkeley;Google Brain,distribution shift;ood,-1;46;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;10;7;7;-1;-1;-1;-1;-1;-1;-1;-1;7;-1;-1;7;7;-1,m;m,NAN,NAN,n,
6667,ICLR,2021,ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY,Firas Laakom;Jenni Raitoharju;Alexandros Iosifidis;Moncef Gabbouj,~Firas_Laakom1;~Jenni_Raitoharju1;~Alexandros_Iosifidis2;~Moncef_Gabbouj1,5;3;5;6,4;3;4;3,Reject,0,7,0.0,yes,9/28/20,Tampere University;Finnish Environment Institute;Aarhus University;Tampere University,Deep learning,-1;-1;92;-1,301;-1;106;301,m;m,usa,usa,y,1
6668,ICLR,2021,Random Network Distillation as a Diversity Metric for Both Image and Text Generation,Liam H Fowl;Micah Goldblum;Arjun Gupta;Amr Sharaf;Tom Goldstein,~Liam_H_Fowl1;~Micah_Goldblum1;~Arjun_Gupta2;~Amr_Sharaf1;~Tom_Goldstein1,4;5;4;6;4,4;4;3;3;3,Reject,0,6,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Microsoft;University of Maryland, College Park",GAN;NLP;ImageNet;generative;diversity;VAE;CelebA;language model,12;12;12;-1;12,90;90;90;-1;90,m;m,usa,usa,n,6;5
6669,ICLR,2021,A REINFORCEMENT LEARNING FRAMEWORK FOR TIME DEPENDENT CAUSAL EFFECTS EVALUATION IN A/B TESTING,Chengchun Shi;Xiaoyu Wang;Shikai Luo;Rui Song;Hongtu Zhu;Jieping Ye,~Chengchun_Shi1;wxyinucas@gmail.com;luoshikai@didiglobal.com;~Rui_Song2;~Hongtu_Zhu2;~Jieping_Ye3,6;5;5,2;2;4,Reject,0,4,0.0,yes,9/28/20,London School of Economics;;North Carolina State University;North Carolina State University;University of North Carolina  Chapel Hill;DiDi,reinforcement learning;A/B testing;causal inference;sequential testing,-1;-1;92;92;64;-1,27;-1;340;340;56;-1,m;m,europe,dk,y,
6670,ICLR,2021,A Unified Bayesian Framework for Discriminative and Generative Continual Learning,Abhishek Kumar;Sunabha Chatterjee;Piyush Rai,abhi.kumar.chaudhary@gmail.com;sunabhac@gmail.com;~Piyush_Rai1,6;8;7;4,3;5;4;4,Reject,0,13,0.0,yes,9/28/20,"Indian Institute of Technology, Kanpur;;;IIT Kanpur, IIT Kanpur",continual learning;bayesian learning,-1;-1;-1;128,-1;-1;-1;-1,m;m,NAN,NAN,n,11;5
6671,ICLR,2021,On the use of linguistic similarities to improve Neural Machine Translation for African Languages,Tikeng Notsawo Pascal;NANDA ASSOBJIO Brice Yvan;James Assiene,~Tikeng_Notsawo_Pascal1;~NANDA_ASSOBJIO_Brice_Yvan1;~James_Assiene1,5;3;4;4,4;4;5;4,Reject,0,3,0.0,yes,9/28/20,"National Advanced School of Engineering Yaounde;Ecole Nationale Sup√©rieure Polytechnique de Yaound√©;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal",Machine Translation;Multilingualism;Linguistic similarity;Dataset;African languages;Multi-task learning,-1;-1;128,-1;-1;73,m;m,NAN,NAN,n,3
6672,ICLR,2021,Estimating Example Difficulty using Variance of Gradients,Chirag Agarwal;Sara Hooker,~Chirag_Agarwal1;~Sara_Hooker1,6;3;4;6;6,4;3;4;4;4,Reject,0,10,0.0,yes,9/28/20,Harvard University;Google Brain,interpretability;human in the loop learning;atypical examples,53;-1,3;-1,m;f,NAN,NAN,n,
6673,ICLR,2021,Sharing Less is More: Lifelong Learning in Deep Networks with Selective Layer Transfer,Seungwon Lee;Sima Behpour;ERIC EATON,~Seungwon_Lee2;~Sima_Behpour1;~ERIC_EATON1,4;6;7;6,5;2;4;3,Reject,0,7,0.0,yes,9/28/20,"Department of Computer and Information Science, School of Engineering and Applied Science;CMU, Carnegie Mellon University;University of Pennsylvania",lifelong learning;continual learning;architecture search,-1;1;20,-1;28;13,m;m,usa,usa,n,
6674,ICLR,2021,Semantic-Guided Representation Enhancement for Self-supervised Monocular Trained Depth Estimation,Rui Li;Qing Mao;Pei Wang;Xiantuo He;Yu Zhu;Jinqiu Sun;Yanning Zhang,~Rui_Li10;maoqing@mail.nwpu.edu.cn;wangpei23@mail.nwpu.edu.cn;xiantuohe@foxmail.com;yuzhu@nwpu.edu.cn;sunjinqiu@nwpu.edu.cn;~Yanning_Zhang1,5;6;7;5,5;5;4;4,Reject,0,10,0.0,yes,9/28/20,Northwestern Polytechnical University;;;;;;;;;;;;NWPU;Northwest Polytechnical University Xi'an,Self-supervised depth estimation;semantic-guided depth;multitask learning;semantic-guided attention mechanism,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;150;-1,538;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;2
6675,ICLR,2021,Redefining The Self-Normalization Property,Zhaodong Chen;Zhao WeiQin;Lei Deng;Guoqi Li;Yuan Xie,~Zhaodong_Chen1;~Zhao_WeiQin1;~Lei_Deng1;~Guoqi_Li1;~Yuan_Xie1,5;5;4;4,3;3;4;5,Reject,0,16,0.0,yes,9/28/20,"UC Santa Barbara;Beihang University;Tsinghua University;Tsinghua University, Tsinghua University;Alibaba Group",Self-normalizing Neural Network;Activation Function,-1;99;4;4;-1,-1;567;20;20;-1,m;m,NAN,NAN,y,1
6676,ICLR,2021,Hamiltonian Q-Learning: Leveraging Importance-sampling for Data Efficient RL,Udari Madhushani;Biswadip Dey;Naomi Leonard;Amit Chakraborty,~Udari_Madhushani1;~Biswadip_Dey2;~Naomi_Leonard1;~Amit_Chakraborty2,5;6;6;5,4;3;4;4,Reject,0,15,0.0,yes,9/28/20,Princeton University;Siemens Corporate Research;Princeton University;Siemens Corporate Research,Data efficient RL;$Q$-Learning;Hamiltonian Monte Carlo,29;-1;29;-1,9;-1;9;-1,u;m,NAN,NAN,y,
6677,ICLR,2021,Meta-Model-Based Meta-Policy Optimization,Takuya Hiraoka;Takahisa Imagawa;Voot Tangkaratt;Takayuki Osa;Takashi Onishi;Yoshimasa Tsuruoka,takuya-h1@nec.com;~Takahisa_Imagawa1;~Voot_Tangkaratt1;~Takayuki_Osa1;takashi.onishi@nec.com;~Yoshimasa_Tsuruoka1,5;5;5;6,3;3;3;3,Reject,0,6,0.0,yes,9/28/20,"NEC;AIST;RIKEN center for Advanced Intelligence Project;Kyushu Institute of Technology, Japan;;;The University of Tokyo",,-1;15;-1;-1;-1;-1;71,440;96;-1;-1;-1;-1;36,m;m,NAN,NAN,y,6;1
6678,ICLR,2021,Inferring Principal Components in the Simplex with Multinomial Variational Autoencoders,James Morton;Justin Silverman;Gleb Tikhonov;Harri L√§hdesm√§ki;Rich Bonneau,~James_Morton1;jsilve24@gmail.com;gleb.tikhonov@aalto.fi;~Harri_L√§hdesm√§ki1;rbonneau@flatironinstitute.org,4;5;6;7,3;3;3;3,Reject,0,4,0.0,yes,9/28/20,Simons Foundation;;;Aalto University;Flatiron Institute - Simons Foundation,Multinomial variational autoencoders;variational autoencoders;ILR transform;compositional PCA;probabilistic PCA;multinomial logistic normal,-1;-1;-1;128;-1,-1;-1;-1;220;-1,m;m,NAN,NAN,n,5
6679,ICLR,2021,Interactive Visualization for Debugging RL,Shuby Deshpande;Benjamin Eysenbach;Jeff Schneider,~Shuby_Deshpande1;~Benjamin_Eysenbach1;~Jeff_Schneider1,3;5;4;6,4;3;3;5,Reject,0,4,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;School of Computer Science",Reinforcement Learning;Interpretability;Visualization,1;1;-1,28;28;-1,m;m,NAN,NAN,n,
6680,ICLR,2021,Perfect density models cannot guarantee anomaly detection,Charline Le Lan;Laurent Dinh,~Charline_Le_Lan2;~Laurent_Dinh1,4;4;4;3,3;4;4;4,Reject,0,22,0.0,yes,9/28/20,University of Oxford;Google,anomaly detection;out-of-distribution detection;OOD detection;outlier detection;density estimation,46;-1,1;-1,f;m,NAN,NAN,n,5
6681,ICLR,2021,Efficient estimates of optimal transport via low-dimensional embeddings,Patric Fulop;Vincent Danos,~Patric_Fulop1;~Vincent_Danos1,4;2;4;4,4;5;4;3,Reject,0,5,0.0,yes,9/28/20,University of Edinburgh;Ecole Normale Superieure,optimal transport;sinkhorn divergences;robustness;neural networks;lipschitz;spectral norm,29;128,30;-1,m;m,europe,fr,n,
6682,ICLR,2021,Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression,Vincent Mai;Waleed Khamies;Liam Paull,~Vincent_Mai1;~Waleed_Khamies1;~Liam_Paull1,4;4;3,4;5;3,Reject,0,8,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;African Masters of Machine Intelligence;University of Montreal",Regression;Noisy labels;Supervised Learning;Uncertainty;Variance;Heteroscedastic;Privileged Information,128;-1;128,73;-1;73,m;m,canada,ca,n,
6683,ICLR,2021,Data-efficient Hindsight Off-policy Option Learning,Markus Wulfmeier;Dushyant Rao;Roland Hafner;Thomas Lampe;Abbas Abdolmaleki;Tim Hertweck;Michael Neunert;Dhruva Tirumala;Noah Yamamoto Siegel;Nicolas Heess;Martin Riedmiller,~Markus_Wulfmeier1;~Dushyant_Rao1;~Roland_Hafner1;~Thomas_Lampe1;~Abbas_Abdolmaleki3;thertweck@google.com;~Michael_Neunert1;~Dhruva_Tirumala1;~Noah_Yamamoto_Siegel1;~Nicolas_Heess1;~Martin_Riedmiller1,3;5;5;6,3;3;4;3,Reject,0,16,0.0,yes,9/28/20,DeepMind;Google DeepMind;;DeepMind;Google;;;Google DeepMind;University of Washington  Seattle;Google;Google,Hierarchical Reinforcement Learning;Off-Policy;Abstractions;Data-Efficiency,-1;-1;-1;-1;-1;-1;-1;-1;11;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;29;-1;-1,m;m,NAN,NAN,n,
6684,ICLR,2021,Learning to Noise: Application-Agnostic Data Sharing with Local Differential Privacy,Alex Mansbridge;Gregory Barbour;Davide Piras;Christopher Frye;Ilya Feige;David Barber,~Alex_Mansbridge1;~Gregory_Barbour1;~Davide_Piras1;~Christopher_Frye1;~Ilya_Feige1;~David_Barber2,6;6;3;6,3;2;4;5,Reject,0,9,0.0,yes,9/28/20,University College London;University College London;University College London;Faculty;University College London;University College London,Differential Privacy;Representation Learning;Variational Inference;Generative Modelling,53;53;53;-1;53;53,-1;-1;-1;-1;-1;-1,m;m,europe,uk,n,1
6685,ICLR,2021,Should Ensemble Members Be Calibrated?,Xixin Wu;Mark Gales,~Xixin_Wu1;~Mark_Gales1,6;5;6;4,3;3;3;3,Reject,0,17,0.0,yes,9/28/20,University of Cambridge;University of Cambridge,,79;79,6;6,m;m,europe,uk,y,11
6686,ICLR,2021,Revisiting BFfloat16 Training,Pedram Zamirai;Jian Zhang;Christopher R Aberger;Christopher De Sa,~Pedram_Zamirai1;~Jian_Zhang1;~Christopher_R_Aberger1;~Christopher_De_Sa2,3;6;5;3,5;3;5;4,Reject,0,11,0.0,yes,9/28/20,University of Michigan;Sambanova Systems Inc.;SambaNova Systems;Cornell University,16-bit training;Low precision training;Deep learning hardware,7;-1;-1;7,22;-1;-1;19,m;m,usa,usa,y,
6687,ICLR,2021,Q-Value Weighted Regression: Reinforcement Learning with Limited Data,Piotr Kozakowski;Lukasz Kaiser;Henryk Michalewski;Afroz Mohiuddin;Katarzyna Ka≈Ñska,~Piotr_Kozakowski3;~Lukasz_Kaiser1;~Henryk_Michalewski1;~Afroz_Mohiuddin1;kkanska@google.com,5;6;3;4,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,University of Warsaw;Google;Google;Google;University of Warsaw,reinforcement learning;rl;offline rl;continuous control;atari;sample efficiency,128;-1;-1;-1;128,818;-1;-1;-1;818,m;f,europe,de,y,
6688,ICLR,2021,iPTR: Learning a representation for interactive program translation retrieval,Binger Chen;Ziawasch Abedjan,~Binger_Chen1;abedjan@dbs.uni-hannover.de,5;4;6,4;4;3,Reject,0,6,0.0,yes,9/28/20,TU Berlin;Hasso Plattner Institute,,128;150,-1;-1,f;m,europe,de,n,
6689,ICLR,2021,Can Students Outperform Teachers in Knowledge Distillation based Model Compression?,Xiang Deng;Zhongfei Zhang,~Xiang_Deng1;~Zhongfei_Zhang1,6;6;3;5,4;5;5;4,Reject,0,5,0.0,yes,9/28/20,"State University of New York, Binghamton;State University of New York, Binghamton",Knowledge Distillation;Deep Learning;Supervised Learning;Model Compression,-1;-1,-1;-1,m;m,NAN,NAN,n,
6690,ICLR,2021,Random Coordinate Langevin Monte Carlo,Zhiyan Ding;Qin Li;Jianfeng Lu;Stephen Wright,~Zhiyan_Ding1;~Qin_Li1;~Jianfeng_Lu1;~Stephen_Wright1,6;6;4;4,4;5;4;4,Reject,0,6,0.0,yes,9/28/20,"University of Wisconsin, Madison;University of Wisconsin, Madison;Duke University;University of Wisconsin - Madison",Random coordinate descent;Langevin dynamics;Monte Carlo sampling,18;18;46;18,49;49;20;49,m;m,usa,usa,y,
6691,ICLR,2021,Approximating Pareto Frontier through Bayesian-optimization-directed Robust Multi-objective Reinforcement Learning,Xiangkun He;Jianye HAO;Dong Li;Bin Wang;Wulong Liu,~Xiangkun_He1;~Jianye_HAO1;~Dong_Li10;~Bin_Wang12;~Wulong_Liu1,5;3;5;5,4;5;4;4,Reject,0,19,0.0,yes,9/28/20,"Huawei Technologies Ltd.;Tianjin University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Huawei Noah's Ark Lab;Huawei Noah's Ark Lab",Reinforcement Learning;Multi‚Äìobjective Optimization;Adversarial Machine Learning;Bayesian Optimization,-1;-1;34;-1;-1,-1;496;-1;-1;-1,m;m,NAN,NAN,n,11;4
6692,ICLR,2021,A Probabilistic Model for Discriminative and Neuro-Symbolic Semi-Supervised Learning,Carl Allen;Ivana Balazevic;Timothy Hospedales,~Carl_Allen1;~Ivana_Balazevic1;~Timothy_Hospedales1,5;7;4;3,3;2;4;4,Reject,0,8,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh;University of Edinburgh,semi-supervised learning;probabilistic model;neuro-symbolic learning,29;29;29,30;30;30,m;m,europe,uk,n,5
6693,ICLR,2021,Iterative Amortized Policy Optimization,Joseph Marino;Alexandre Pich√©;Alessandro Davide Ialongo;Yisong Yue,~Joseph_Marino1;~Alexandre_Pich√©1;~Alessandro_Davide_Ialongo1;~Yisong_Yue1,6;5;5;5,4;2;3;3,Reject,0,11,0.0,yes,9/28/20,California Institute of Technology;University of Montreal;University of Cambridge;California Institute of Technology,Reinforcement Learning;Policy Optimization;Amortization;Variational Inference,150;128;79;150,4;73;6;4,m;m,usa,usa,n,
6694,ICLR,2021,Neural Point Process for Forecasting Spatiotemporal Events,Zihao Zhou;Xingyi Yang;Xinyi He;Ryan Rossi;Handong Zhao;Rose Yu,~Zihao_Zhou1;~Xingyi_Yang1;~Xinyi_He1;~Ryan_Rossi1;~Handong_Zhao3;~Rose_Yu1,4;4;5;8,4;5;4;4,Reject,0,5,0.0,yes,9/28/20,"University of California, San Diego;National University of Singapore;University of California, San Diego;Adobe Research;Adobe Systems;University of California, San Diego",spatiotemporal point process;deep sequence models;time series,-1;17;-1;-1;-1;-1,33;25;33;-1;-1;33,m;f,usa,usa,n,
6695,ICLR,2021,Improving Post Training Neural Quantization: Layer-wise Calibration and Integer Programming,Itay Hubara;Yury Nahshan;Yair Hanani;Ron Banner;Daniel Soudry,~Itay_Hubara1;~Yury_Nahshan1;~Yair_Hanani1;~Ron_Banner1;~Daniel_Soudry1,6;6;4;7;4,3;4;2;5;5,Reject,0,9,0.0,yes,9/28/20,"Technion, Technion;Intel;Tel Aviv University;Intel;Technion - Israel Institute of Technology",Efficient Deep Learning;Quantization;Compression,29;-1;34;-1;29,-1;-1;190;-1;408,m;m,NAN,NAN,n,8
6696,ICLR,2021,Direct Evolutionary Optimization of Variational Autoencoders with Binary Latents,Enrico Guiraud;Jakob Drefs;Jorg Lucke,~Enrico_Guiraud1;~Jakob_Drefs1;~Jorg_Lucke1,5;6;6;6,3;4;3;3,Reject,0,6,0.0,yes,9/28/20,University of Oldenburg;Carl von Ossietzky University of Oldenburg;University of Oldenburg,variational optimization;variational autoencoders;denoising;evolutionary algorithms,327;327;327,-1;-1;-1,m;m,europe,de,n,6;5
6697,ICLR,2021,Learning to Solve Multi-Robot Task Allocation with a Covariant-Attention based Neural Architecture,Steve Paul;Payam Ghassemi;Souma Chowdhury,~Steve_Paul1;~Payam_Ghassemi2;~Souma_Chowdhury1,5;4;7,4;4;4,Reject,0,23,0.0,yes,9/28/20,"State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo",Graph neural network;Attention mechanism;Reinforcement learning;Multi-robotic task allocation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;10
6698,ICLR,2021,Multi-Agent Trust Region Learning,Ying Wen;Hui Chen;Yaodong Yang;Zheng Tian;Minne Li;Xu Chen;Jun Wang,~Ying_Wen1;hcch.work.18@gmail.com;~Yaodong_Yang1;zheng.tian.11@ucl.ac.uk;~Minne_Li1;successcx@gmail.com;~Jun_Wang2,4;8;5;6,4;4;4;3,Reject,0,11,0.0,yes,9/28/20,Shanghai Jiao Tong University;University College London;King's College London;University College London;University College London;Renmin University of China;University College London,multi-agent learning;reinforcement learning;empirical game-theoretic analysis,29;53;174;53;53;85;53,100;-1;35;-1;-1;517;-1,m;m,europe,uk,y,1
6699,ICLR,2021,Polynomial Graph Convolutional Networks,Luca Pasa;Nicol√≤ Navarin;Alessandro Sperduti,~Luca_Pasa1;~Nicol√≤_Navarin1;~Alessandro_Sperduti1,5;4;5;5,4;4;5;4,Reject,0,9,0.0,yes,9/28/20,Universita' degli studi di Padova;Universita' degli studi di Padova;Universita' degli studi di Padova,Graph Convolutional Networks;Graph Neural Network;Deep Learning;Structured Data;Machine Learning on Graphs,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;10
6700,ICLR,2021,Thinking Like Transformers,Gail Weiss;Yoav Goldberg;Eran Yahav,~Gail_Weiss1;~Yoav_Goldberg1;~Eran_Yahav1,5;4;3;6,4;3;4;3,Reject,0,12,0.0,yes,9/28/20,"Technion, Technion;Bar-Ilan University;Technion, Technion",transformers;interpretability,29;110;29,-1;570;-1,f;m,NAN,NAN,n,8
6701,ICLR,2021,Intention Propagation for  Multi-agent Reinforcement Learning,Chao Qu;Hui Li;Chang Liu;Junwu Xiong;james zhang;Wei Chu;Weiqiang Wang;Yuan Qi;Le Song,~Chao_Qu2;~Hui_Li2;~Chang_Liu7;junwu.xjw@antgroup.com;james.z@antgroup.com;~Wei_Chu1;~Weiqiang_Wang4;alan.qi@gmail.com;~Le_Song1,6;7;5;6,2;4;4;4,Reject,0,10,0.0,yes,9/28/20,"Technion, Technion;Alibaba Group and Ant Financial Services Group;Shanghai Jiao Tong University;antgroup;Alipay;University College London;University of Southern California;;;College of Computing, Georgia Institute of Technology",,29;-1;29;-1;-1;53;37;-1;-1;12,-1;-1;100;-1;-1;-1;53;-1;-1;38,m;m,NAN,NAN,n,1
6702,ICLR,2021,Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble,Nanxiang Li;Shabnam Ghaffarzadegan;Liu Ren,~Nanxiang_Li1;~Shabnam_Ghaffarzadegan1;~Liu_Ren1,5;3;7,3;4;4,Reject,0,7,0.0,yes,9/28/20,"Bosch;University of Texas, Dallas;Bosch Research",Unsupervised disentangled representation learning;network ensemble;variational auto encoder,-1;-1;-1,285;-1;-1,m;m,NAN,NAN,n,5
6703,ICLR,2021,"Warpspeed Computation of Optimal Transport, Graph Distances, and Embedding Alignment",Johannes Klicpera;Marten Lienen;Stephan G√ºnnemann,~Johannes_Klicpera1;marten.lienen@in.tum.de;~Stephan_G√ºnnemann1,6;6;7;6,4;3;4;3,Reject,0,10,0.0,yes,9/28/20,Technical University Munich;Technical University Munich;Technical University Munich,Optimal transport;sinkhorn distance;locality sensitive hashing;nystr√∂m method;graph neural networks;embedding alignment,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,10
6704,ICLR,2021,Diffeomorphic Template Transformers,Tycho F.A. van der Ouderaa;Ivana Isgum;Wouter B. Veldhuis;Bob D. De Vos;Pim Moeskops,~Tycho_F.A._van_der_Ouderaa1;~Ivana_Isgum1;w.veldhuis@umcutrecht.nl;~Bob_D._De_Vos2;~Pim_Moeskops2,5;3;6;5,4;5;2;4,Reject,0,4,0.0,yes,9/28/20,Quantib;University Medical Center Utrecht;;;Utrecht University;Quantib BV,,-1;-1;-1;-1;209;-1,-1;-1;-1;-1;75;-1,m;m,NAN,NAN,n,8;2
6705,ICLR,2021,Federated Mixture of Experts,Matthias Reisser;Christos Louizos;Efstratios Gavves;Max Welling,~Matthias_Reisser1;~Christos_Louizos1;~Efstratios_Gavves1;~Max_Welling1,5;4;4;4,4;4;4;4,Reject,0,12,0.0,yes,9/28/20,"Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;University of Amsterdam;Donald Bren School of Information and Computer Sciences, University of California, Irvine",Federated Learning;personalized models;non-i.i.d data,-1;-1;128;-1,-1;-1;66;98,m;m,NAN,NAN,n,
6706,ICLR,2021,Online Limited Memory Neural-Linear Bandits,Tom Zahavy;Ofir Nabati;Leor Cohen;Shie Mannor,~Tom_Zahavy2;~Ofir_Nabati1;liorcohen5@gmail.com;~Shie_Mannor2,3;5;5,4;3;3,Reject,0,2,0.0,yes,9/28/20,DeepMind;Technion;;;Technion,,-1;29;-1;-1;29,-1;408;-1;-1;408,m;m,europe,il,y,
6707,ICLR,2021,Generating unseen complex scenes: are we there yet?,Arantxa Casanova;Michal Drozdzal;Adriana Romero,~Arantxa_Casanova1;~Michal_Drozdzal1;~Adriana_Romero1,6;5;4;4,5;3;5;4,Reject,0,6,0.0,yes,9/28/20,Polytechnique Montreal;Facebook;Facebook,generative adversarial networks;conditional scene generation;zero-shot generalization;out of distribution,327;-1;-1,-1;-1;-1,f;f,NAN,NAN,n,
6708,ICLR,2021,Learning a unified label space,Xingyi Zhou;Vladlen Koltun;Philipp Kraehenbuehl,~Xingyi_Zhou2;~Vladlen_Koltun1;~Philipp_Kraehenbuehl1,7;4;7;6,4;4;5;4,Reject,0,5,0.0,yes,9/28/20,"University of Texas, Austin;Intel;University of Texas, Austin",object detection;image recognition;computer vision,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,2
6709,ICLR,2021,Sequence Metric Learning as Synchronization of Recurrent Neural Networks,Paul Compagnon;Gr√©goire Lefebvre;Stefan Duffner;Christophe Garcia,~Paul_Compagnon1;gregoire.lefebvre@orange.com;~Stefan_Duffner1;~Christophe_Garcia1,4;3;6,5;3;3,Reject,0,4,0.0,yes,9/28/20,Orange-labs;Orange-labs;LIRIS  CNRS;Universit√© Claude Bernard Lyon 1,Metric learning;sequence processing;siamese recurrent neural network;dynamical systems,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3;1
6710,ICLR,2021,Learning Curves for Analysis of Deep Networks,Derek Hoiem;Tanmay Gupta;Zhizhong Li;Michal M Shlapentokh-Rothman,~Derek_Hoiem1;~Tanmay_Gupta1;~Zhizhong_Li1;~Michal_M_Shlapentokh-Rothman1,6;7;4;7,4;4;3;3,Reject,0,15,0.0,yes,9/28/20,"Reconstruct;Allen Institute for Artificial Intelligence;Amazon;University of Illinois, Urbana Champaign",learning curve;deep network;analysis;asymptotic error;learning efficiency;power law,-1;-1;-1;-1,-1;-1;-1;-1,m;u,usa,usa,n,
6711,ICLR,2021,The Bures Metric for Taming Mode Collapse in Generative Adversarial Networks,Hannes De Meulemeester;Joachim Schreurs;Micha√´l Fanuel;Bart De Moor;Johan Suykens,~Hannes_De_Meulemeester1;joachim.schreurs@esat.kuleuven.be;michael.fanuel@kuleuven.be;bart.demoor@esat.kuleuven.be;~Johan_Suykens1,3;5;6;6,4;4;4;4,Reject,0,9,0.0,yes,9/28/20,"KU Leuven;KU Leuven;CNRS, Univ. de Lille;;;KU Leuven",Generative Adversarial Networks;Deep Learning;Neural Networks,150;150;-1;-1;-1;150,45;45;-1;-1;-1;45,m;m,europe,be,y,5;4
6712,ICLR,2021,Representational aspects of depth and conditioning in normalizing flows,Frederic Koehler;Viraj Mehta;Andrej Risteski,~Frederic_Koehler1;~Viraj_Mehta1;~Andrej_Risteski2,6;7;7;3,3;3;3;4,Reject,0,14,0.0,yes,9/28/20,Massachusetts Institute of Technology;Carnegie Mellon University;Carnegie Mellon University,normalizing flows;representational power;conditioning;depth;theory,5;1;1,4;28;28,m;m,usa,usa,y,1;5
6713,ICLR,2021,Efficient Architecture Search for Continual Learning,Qiang Gao;Zhipeng Luo;Diego Klabjan;Fengli Zhang,~Qiang_Gao1;zhipeng.luo@northwestern.edu;~Diego_Klabjan1;fzhang@uestc.edu.cn,6;6;4;6,3;4;5;3,Reject,0,6,0.0,yes,9/28/20,University of Electronic Science and Technology of China;;Northwestern University;University of Electronic Science and Technology of China,continual learning;reinforcement learning;recurrent neural network;deep neural network,-1;-1;46;-1,553;-1;24;553,m;f,NAN,NAN,n,
6714,ICLR,2021,NETWORK ROBUSTNESS TO PCA PERTURBATIONS,Anan Kabaha;Dana Drachsler Cohen,~Anan_Kabaha3;~Dana_Drachsler_Cohen1,4;3;7;3,4;5;4;4,Reject,0,4,0.0,yes,9/28/20,"Technion, Technion;Technion, Technion",neural network robustness;adversarial examples,29;29,-1;-1,m;f,NAN,NAN,n,4
6715,ICLR,2021,Learning Self-Similarity in Space and Time as a Generalized Motion for Action Recognition,Heeseung Kwon;Manjin Kim;Suha Kwak;Minsu Cho,~Heeseung_Kwon2;~Manjin_Kim1;~Suha_Kwak3;~Minsu_Cho1,5;6;6;6,3;4;4;4,Reject,0,13,0.0,yes,9/28/20,POSTECH;POSTECH;POSTECH;POSTECH,Action recognition;Video understanding;Motion analysis,128;128;128;128,151;151;151;151,m;m,asia,kr,n,
6716,ICLR,2021,Test-Time Adaptation and Adversarial Robustness,Xi Wu;Yang Guo;Tianqi Li;Jiefeng Chen;Qicheng Lao;Yingyu Liang;Somesh Jha,~Xi_Wu1;~Yang_Guo4;~Tianqi_Li2;~Jiefeng_Chen2;~Qicheng_Lao2;~Yingyu_Liang1;~Somesh_Jha1,7;5;4;3,2;3;4;4,Reject,0,25,0.0,yes,9/28/20,"Google;Department of Computer Science, University of Wisconsin, Madison;University of Wisconsin, Madison;University of Wisconsin, Madison;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Wisconsin, Madison;Department of Computer Science, University of Wisconsin, Madison",test-time adaptation;adversarial robustness;unsupervised domain adaptation;threat model;maximin game,-1;-1;18;18;128;18;-1,-1;-1;49;49;73;49;-1,m;m,NAN,NAN,y,1;4
6717,ICLR,2021,Graph Structural Aggregation for Explainable Learning,Alexis Galland;marc lelarge,~Alexis_Galland1;~marc_lelarge1,4;6;3;7,4;5;5;5,Reject,0,0,0.0,yes,9/28/20,INRIA;inria,graph;deep;learning,-1;-1,-1;-1,u;m,NAN,NAN,n,10
6718,ICLR,2021,Directional graph networks,Dominique Beaini;Saro Passaro;Vincent Letourneau;William L. Hamilton;Gabriele Corso;Pietro Li√≤,~Dominique_Beaini1;sp976@cam.ac.uk;vincent@invivoai.com;~William_L._Hamilton1;gc579@cam.ac.uk;~Pietro_Li√≤1,5;7;5;4,2;4;3;5,Reject,0,7,0.0,yes,9/28/20,Polytechnique Montreal;University of Cambridge;;;McGill University;University of Cambridge;;University of Cambridge,graph;neural networks;deep learning;spectral theory;directional aggregation;over-smoothing,327;79;-1;-1;99;79;-1;79,-1;6;-1;-1;40;6;-1;6,u;m,europe,uk,y,10
6719,ICLR,2021,Federated learning using mixture of experts,Edvin Listo Zec;John Martinsson;Olof Mogren;Leon Ren√© S√ºtfeld;Daniel Gillblad,~Edvin_Listo_Zec1;~John_Martinsson1;~Olof_Mogren1;~Leon_Ren√©_S√ºtfeld1;~Daniel_Gillblad1,6;3;3;3,5;4;5;4,Reject,0,7,0.0,yes,9/28/20,RISE Research Institutes of Sweden;RISE Research Institutes of Sweden;RISE Research Institutes of Sweden;University of Osnabr√ºck;AI Sweden,federated learning;mixture of experts,-1;-1;-1;327;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
6720,ICLR,2021,Attention-Based Clustering: Learning a Kernel from Context,Samuel Coward;Erik Visse-Martindale;Chithrupa Ramesh,~Samuel_Coward1;erik.visse-martindale@uk.zuken.com;~Chithrupa_Ramesh1,4;5;4;5,3;3;5;3,Reject,0,11,0.0,yes,9/28/20,Zuken Limited;Leiden University;Zuken Limited,Similarity learning;kernel methods;constrained clustering;transformer analysis;spectral clustering;supervised learning;deep learning,-1;-1;-1,-1;70;-1,m;f,NAN,NAN,y,8
6721,ICLR,2021,Quantifying and Learning Disentangled Representations with Limited Supervision,Loek Tonnaer;Luis Armando P√©rez Rey;Vlado Menkovski;Mike Holenderski;Jacobus W. Portegies,~Loek_Tonnaer1;~Luis_Armando_P√©rez_Rey1;~Vlado_Menkovski2;~Mike_Holenderski1;j.w.portegies@tue.nl,4;5;5;6,3;3;3;3,Reject,0,8,0.0,yes,9/28/20,Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology,Representation Learning;Disentanglement;Group Theory,-1;-1;-1;-1;-1,186;186;186;186;186,m;m,NAN,NAN,n,1
6722,ICLR,2021,Joint Learning of Full-structure Noise in Hierarchical Bayesian Regression Models,Ali Hashemi;Chang Cai;Klaus Robert Muller;Srikantan Nagarajan;Stefan Haufe,~Ali_Hashemi1;cchangenergy@gmail.com;~Klaus_Robert_Muller1;~Srikantan_Nagarajan2;stefan.haufe@charite.de,5;4;4;4,3;3;3;5,Reject,0,7,0.0,yes,9/28/20,"TU Berlin;ccnu;TU Berlin;University of California-San Francisco;Charit√© - Universit√§tsmedizin Berlin, Germany",Full-structure Noise;Hierarchical Bayesian Regression Models;Sparse Bayesian Learning;Unsupervised Learning;Brain Source Imaging;Covariance Estimation.,128;-1;128;-1;-1,-1;-1;-1;-1;75,m;m,NAN,NAN,y,11
6723,ICLR,2021,Learning Robust Models using the Principle of Independent Causal Mechanisms,Jens M√ºller;Robert Schmier;Lynton Ardizzone;Carsten Rother;Ullrich Koethe,~Jens_M√ºller2;~Robert_Schmier1;~Lynton_Ardizzone1;~Carsten_Rother1;~Ullrich_Koethe1,6;6;6,4;4;4,Reject,0,6,0.0,yes,9/28/20,"Heidelberg University;Robert Bosch GmbH, Bosch;Heidelberg University;Heidelberg University;Heidelberg University",Causal Discovery;Principle of Independent Causal Mechanisms;Normalizing Flows;Domain Generalization,209;-1;209;209;209,42;-1;42;42;42,m;m,europe,de,y,1
6724,ICLR,2021,Policy Gradient with Expected Quadratic Utility Maximization: A New Mean-Variance Approach in Reinforcement Learning,Masahiro Kato;Kei Nakagawa,~Masahiro_Kato1;kei.nak.0315@gmail.com,4;5;6,5;4;4,Reject,0,7,0.0,yes,9/28/20,"Cyberagent;Nomura Asset Management co,ltd.",mean-variance reinforcement learning;finance,-1;-1,-1;-1,m;m,NAN,NAN,n,
6725,ICLR,2021,Target Training: Tricking Adversarial Attacks to Fail,Blerta Lindqvist,~Blerta_Lindqvist1,5;5;7;5,3;5;2;3,Reject,0,10,0.0,yes,9/28/20,Aalto University,adversarial machine learning,128,220,f,europe,dk,n,4
6726,ICLR,2021,A Robust Fuel Optimization Strategy For Hybrid Electric Vehicles: A Deep Reinforcement Learning Based Continuous Time Design Approach,Nilanjan Mukherjee;Sudeshna Sarkar,~Nilanjan_Mukherjee1;~Sudeshna_Sarkar1,3;5;4;2,4;3;2;3,Reject,0,5,0.0,yes,9/28/20,Indian Institute of Technology Kharagpur;IIT Kharagpur,Deep Reinforcement Learning;Optimal Control;Fuel Management System;Hybrid Electric vehicles;H‚àû Performance Index,-1;174,-1;-1,m;f,asia,in,n,
6727,ICLR,2021,Explainable Reinforcement Learning Through Goal-Based Interpretability,Gregory Bonaert;Youri Coppens;Denis Steckelmacher;Ann Nowe,~Gregory_Bonaert1;~Youri_Coppens1;~Denis_Steckelmacher1;~Ann_Nowe1,3;3;4;3,4;5;4;4,Reject,0,5,0.0,yes,9/28/20,Vrije Universiteit Brussel;Vrije Universiteit Brussel;Vrije Universiteit Brussel;Vrije Universiteit Brussel,explainable reinforcement learning;hierarchical reinforcement learning;goal-based interpretability,-1;-1;-1;-1,260;260;260;260,m;f,NAN,NAN,n,
6728,ICLR,2021,Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data,Sindy L√∂we;David Madras;Richard Zemel;Max Welling,~Sindy_L√∂we1;~David_Madras1;~Richard_Zemel1;~Max_Welling1,6;6;5;5,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,"University of Amsterdam;Department of Computer Science, University of Toronto;University of Toronto;Donald Bren School of Information and Computer Sciences, University of California, Irvine",,128;18;18;-1,66;18;18;98,f;m,NAN,NAN,y,10
6729,ICLR,2021,Contextual HyperNetworks  for Novel Feature Adaptation,Angus Lamb;Evgeny Saveliev;Yingzhen Li;Sebastian Tschiatschek;Camilla Longden;Simon Woodhead;Jos√© Miguel Hern√°ndez-Lobato;Richard E Turner;Pashmina Cameron;Cheng Zhang,~Angus_Lamb1;e.s.saveliev@gmail.com;~Yingzhen_Li1;~Sebastian_Tschiatschek1;camilla.longden@microsoft.com;simon.woodhead@eedi.co.uk;~Jos√©_Miguel_Hern√°ndez-Lobato1;~Richard_E_Turner1;~Pashmina_Cameron1;~Cheng_Zhang1,5;6;5;5,3;2;3;4,Reject,0,6,0.0,yes,9/28/20,University College London;;;Imperial College London;University of Vienna;;;Eedi;University of Cambridge;University of Cambridge;Microsoft;KTH,Meta learning;few-shot learning;continual learning;recommender systems;deep learning,53;-1;-1;53;174;-1;-1;-1;79;79;-1;174,-1;-1;-1;11;164;-1;-1;-1;6;6;-1;239,m;f,asia,in,n,6;5
6730,ICLR,2021,Benchmarking Unsupervised Object Representations for Video Sequences,Marissa A. Weis;Kashyap Chitta;Yash Sharma;Wieland Brendel;Matthias Bethge;Andreas Geiger;Alexander S Ecker,~Marissa_A._Weis1;~Kashyap_Chitta1;~Yash_Sharma1;~Wieland_Brendel1;~Matthias_Bethge2;~Andreas_Geiger3;~Alexander_S_Ecker1,5;4;5;7,2;1;3;3,Reject,0,5,0.0,yes,9/28/20,"University of Tuebingen;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Centre for Integrative Neuroscience, AG Bethge;T√ºbingen AI Center, University of T√ºbingen;University of Tuebingen;University of Tuebingen;University of Goettingen",Unsupervised learning;object-centric representations;benchmark;tracking,128;-1;-1;128;128;128;327,78;-1;-1;78;78;78;130,f;m,europe,de,n,8;2
6731,ICLR,2021,Multi-Agent Collaboration via Reward Attribution Decomposition,Tianjun Zhang;Huazhe Xu;Xiaolong Wang;Yi Wu;Kurt Keutzer;Joseph E. Gonzalez;Yuandong Tian,~Tianjun_Zhang1;~Huazhe_Xu1;~Xiaolong_Wang3;~Yi_Wu1;~Kurt_Keutzer1;~Joseph_E._Gonzalez1;~Yuandong_Tian1,6;5;7;6,3;2;3;4,Reject,0,8,0.0,yes,9/28/20,"University of California Berkeley;University of California Berkeley;University of California, San Diego;Tsinghua University;;Univ. of California - Berkeley;University of California, Berkeley;University of California - Berkeley;Facebook AI Research",multi-agent reinforcement leanring;ad hoc team play,-1;-1;-1;4;-1;10;-1;-1;-1,7;7;33;20;-1;-1;7;7;-1,m;m,NAN,NAN,y,
6732,ICLR,2021,Synthesising Realistic Calcium Traces of Neuronal Populations Using GAN,Bryan M. Li;Theoklitos Amvrosiadis;Nathalie Rochefort;Arno Onken,~Bryan_M._Li1;t.amvrosiadis@ed.ac.uk;n.rochefort@ed.ac.uk;~Arno_Onken1,5;4;3,4;4;5,Reject,0,3,0.0,yes,9/28/20,University of Edinburgh;;;;;University of Edinburgh,calcium imaging;calcium traces;generative adversarial networks;spike train analysis,29;-1;-1;-1;-1;29,30;-1;-1;-1;-1;30,m;m,europe,uk,n,7;5;4
6733,ICLR,2021,Enhancing Certified Robustness of Smoothed Classifiers via Weighted Model Ensembling,Chizhou Liu;Yunzhen Feng;Ranran Wang;Bin Dong,~Chizhou_Liu1;~Yunzhen_Feng1;ranranw@bibdr.org;~Bin_Dong1,6;6;5;6,3;3;4;4,Reject,0,14,0.0,yes,9/28/20,Peking University;Peking University;;;Peking University,Adversairal Robustness;Randomized Smoothing;Ensembling,14;14;-1;-1;14,23;23;-1;-1;23,u;m,asia,cn,y,4
6734,ICLR,2021,Stego Networks: Information Hiding on Deep Neural Networks,Youngwoo Cho;Beomsoo Kim;Jaegul Choo,~Youngwoo_Cho1;~Beomsoo_Kim2;~Jaegul_Choo1,3;7;7,3;3;4,Reject,0,9,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Steganography;Information Hiding;Security,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,
6735,ICLR,2021,Diverse Exploration via InfoMax Options,Yuji Kanagawa;Tomoyuki Kaneko,~Yuji_Kanagawa1;~Tomoyuki_Kaneko1,4;5;5;4,4;3;5;4,Reject,0,9,0.0,yes,9/28/20,Okinawa Institute of Science and Technology (OIST);The University of Tokyo,Reinforcement Learning;Hierachical Reinforcement Learning;Exploration,-1;71,-1;36,u;m,NAN,NAN,n,
6736,ICLR,2021,Nonvacuous Loss Bounds with Fast Rates for Neural Networks via Conditional Information Measures,Fredrik Hellstr√∂m;Giuseppe Durisi,~Fredrik_Hellstr√∂m1;~Giuseppe_Durisi1,6;7;6,4;4;3,Reject,0,13,0.0,yes,9/28/20,Chalmers University;Chalmers University,,-1;-1,235;235,m;m,europe,cz,y,11
6737,ICLR,2021,Lie Algebra Convolutional Neural Networks with Automatic Symmetry Extraction,Nima Dehmamy;Yanchen Liu;Robin Walters;Rose Yu,~Nima_Dehmamy1;lycrdfzpku@gmail.com;~Robin_Walters1;~Rose_Yu1,7;6;8,4;5;4,Reject,0,11,0.0,yes,9/28/20,"Northwestern University;Northeastern University;Northeastern University;University of California, San Diego",equivariance;group convolutional neural network;inductive bias;group equivariant architecture;Lie group;Lie algebra,46;16;16;-1,24;895;895;33,m;f,usa,usa,y,10
6738,ICLR,2021,Bypassing the Random Input Mixing in Mixup,Hongyu Guo,~Hongyu_Guo1,4;5;4;4,3;3;4;4,Reject,0,9,0.0,yes,9/28/20,National Research Council Canada,Deep Learning;Data Augmentation;Mixup,-1,-1,m,NAN,NAN,n,
6739,ICLR,2021,Out-of-Distribution Generalization Analysis via Influence Function,Haotian Ye;Chuanlong Xie;Yue Liu;Zhenguo Li,1800017704@pku.edu.cn;~Chuanlong_Xie1;liuyue52@huawei.com;~Zhenguo_Li1,4;5;4;7,4;4;5;5,Reject,0,12,0.0,yes,9/28/20,Peking University;Huawei Technologies Ltd.;;;Huawei,,14;-1;-1;-1;-1,23;-1;-1;-1;-1,m;m,NAN,NAN,n,1
6740,ICLR,2021,Learning a Transferable Scheduling Policy for Various Vehicle Routing Problems based on Graph-centric Representation Learning,Inwook Kim;Jinkyoo Park,inwukkim@gmail.com;~Jinkyoo_Park1,5;6;5,5;5;3,Reject,0,10,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Vehicle Routing Problem;Multiple Traveling Salesmen Problem;Capacitated Vehicle Routing Problem;Reinforcement Learning;Graph Neural Network,-1;-1,96;96,m;m,NAN,NAN,n,10
6741,ICLR,2021,SoGCN: Second-Order Graph Convolutional Networks,Peihao Wang;Yuehao Wang;Hua Lin;Jianbo Shi,~Peihao_Wang1;~Yuehao_Wang1;~Hua_Lin1;~Jianbo_Shi1,7;5;5;5,4;4;3;5,Reject,0,8,0.0,yes,9/28/20,"ShanghaiTech University;ShanghaiTech University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;University of Pennsylvania",Graph Convolutional Networks;Filter Representation Power;Graph Polynomial Filters,327;327;34;20,-1;-1;-1;13,m;m,usa,usa,y,10
6742,ICLR,2021,Policy Learning Using Weak Supervision,Jingkang Wang;Hongyi Guo;Zhaowei Zhu;Yang Liu,~Jingkang_Wang1;~Hongyi_Guo1;~Zhaowei_Zhu1;~Yang_Liu3,6;6;6;6,3;3;4;3,Reject,0,13,0.0,yes,9/28/20,"University of Toronto;Northwestern University, Northwestern University;University of California, Santa Cruz;University of California, Santa Cruz",Weak Supervision;Policy Learning;Correlated Agreement,18;46;-1;-1,18;24;207;207,m;m,usa,usa,y,
6743,ICLR,2021,EqCo:   Equivalent Rules for Self-supervised Contrastive Learning,Benjin Zhu;Junqiang Huang;Zeming Li;Xiangyu Zhang;Jian Sun,~Benjin_Zhu1;~Junqiang_Huang1;~Zeming_Li2;~Xiangyu_Zhang1;~Jian_Sun4,5;8;5;6,4;5;5;4,Reject,0,5,0.0,yes,9/28/20,"Megvii Technology Inc.;Peking University;Tsinghua University, Tsinghua University;MEGVII Technology;Megvii Technology",,-1;14;4;-1;-1,-1;23;20;-1;-1,m;m,NAN,NAN,y,1
6744,ICLR,2021,Novel Policy Seeking with Constrained Optimization,Hao Sun;Zhenghao Peng;Bo Dai;Jian Guo;Dahua Lin;Bolei Zhou,~Hao_Sun3;~Zhenghao_Peng1;~Bo_Dai2;guoj@pcl.ac.cn;~Dahua_Lin1;~Bolei_Zhou5,6;4;6;4,4;4;3;4,Reject,0,10,0.0,yes,9/28/20,The Chinese University of Hong Kong;Chinese University of Hong Kong;Nanyang Technological University;;;Toyota Technnological Institute;The Chinese University of Hong Kong,Novel Policy Seeking;Reinforcement Learning;Constrained Optimization,327;46;44;-1;-1;-1;327,39;56;47;-1;-1;-1;39,m;m,NAN,NAN,y,
6745,ICLR,2021,Faster Training of Word Embeddings,Eliza Wszola;Martin Jaggi;Markus P√ºschel,~Eliza_Wszola1;~Martin_Jaggi1;~Markus_P√ºschel1,5;4;7;5,3;4;3;3,Reject,0,5,0.0,yes,9/28/20,Swiss Federal Institute of Technology;EPFL;Department of Computer Science,multicore;performance;machine learning;word embeddings;word2vec;fasttext,-1;23;-1,-1;-1;-1,f;m,NAN,NAN,n,3
6746,ICLR,2021,FILTRA: Rethinking Steerable CNN by Filter Transform,Bo Li;Qili Wang;Gim Hee Lee,~Bo_Li16;~Qili_Wang1;~Gim_Hee_Lee1,6;6;5;6,4;3;5;4,Reject,0,5,0.0,yes,9/28/20,Baidu;jd;National University of Singapore,,-1;-1;17,-1;-1;25,m;m,asia,sg,y,1
6747,ICLR,2021,ProxylessKD: Direct Knowledge Distillation with Inherited Classifier for Face Recognition,Weidong Shi;Guanghui Ren;Yunpeng Chen;Shuicheng Yan,~Weidong_Shi2;~Guanghui_Ren1;~Yunpeng_Chen1;~Shuicheng_Yan2,5;6;4,3;3;4,Reject,0,3,0.0,yes,9/28/20,Northestern University of China;University of Chinese Academy of Sciences;YiTu Technology co. ltd;National University of Singapore,inherited classifier;embedding space alignment;face recognition;knowledge distillation,-1;34;-1;17,-1;-1;-1;25,m;m,asia,sg,n,2
6748,ICLR,2021,Improving Learning to Branch via Reinforcement Learning,Haoran Sun;Wenbo Chen;Hui Li;Le Song,~Haoran_Sun2;~Wenbo_Chen2;~Hui_Li2;~Le_Song1,4;7;7;8,5;3;3;3,Reject,0,7,0.0,yes,9/28/20,"Georgia Institute of Technology;Georgia Institute of Technology;Alibaba Group and Ant Financial Services Group;College of Computing, Georgia Institute of Technology",Mixed Integer Programming;Branching and Bound;Strong Branching;Reinforcement Learning;Evolution Strategy;Novelty Search,12;12;-1;12,38;38;-1;38,m;m,NAN,NAN,n,
6749,ICLR,2021,Iterated graph neural network system,Hanju Li,~Hanju_Li1,6;6;5;4,4;2;3;4,Reject,0,9,0.0,yes,9/28/20,"China Southern Power Grid Digital Power Grid Research Institute Co., Ltd",,-1,-1,u,NAN,NAN,y,1;10
6750,ICLR,2021,Sample efficient Quality Diversity for neural continuous control,Thomas PIERROT;Valentin Mac√©;Geoffrey Cideron;Nicolas Perrin;Karim Beguir;Olivier Sigaud,~Thomas_PIERROT1;~Valentin_Mac√©1;~Geoffrey_Cideron1;~Nicolas_Perrin1;kb@instadeep.com;~Olivier_Sigaud1,6;6;6;3,3;3;4;5,Reject,0,8,0.0,yes,9/28/20,"Universit√© Pierre et Marie Curie - Paris 6, Computer Science Lab  - Pierre and Marie Curie University, Paris, France;InstaDeep;INRIA;ISIR, UMR 7222;NYU, New York University;Sorbonne Universit√©",Deep Neuroevolution;Quality Diversity;Reinforcement Learning,-1;-1;-1;-1;23;-1,-1;-1;-1;-1;26;87,m;m,NAN,NAN,n,
6751,ICLR,2021,Hybrid-Regressive Neural Machine Translation,Qiang Wang;Heng Yu;Shaohui Kuang;Weihua Luo,~Qiang_Wang8;~Heng_Yu1;~Shaohui_Kuang1;weihua.luowh@alibaba-inc.com,7;5;6,4;4;5,Reject,0,8,0.0,yes,9/28/20,Alibaba Group;  Chinese Academy of Sciences;Alibaba Group;Alibaba Group,neural machine translation;non-autoregressive translation,-1;34;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
6752,ICLR,2021,Regression Prior Networks,Andrey Malinin;Sergey Chervontsev;Ivan Provilkov;Mark Gales,~Andrey_Malinin1;chervontsev@yandex-team.ru;iv-provilkov@yandex-team.ru;~Mark_Gales1,5;6;6;6,4;4;3;4,Reject,0,16,0.0,yes,9/28/20,Yandex;Higher School of Economics;Moscow Institute of Physics and Technology;University of Cambridge,uncertainty;prior networks;regression;ensemble distribution distillation;depth estimation.,-1;-1;-1;79,-1;-1;224;6,m;m,europe,uk,n,
6753,ICLR,2021,VECO: Variable Encoder-decoder Pre-training for Cross-lingual Understanding and Generation,Fuli Luo;Wei Wang;Jiahao Liu;Yijia Liu;Bin Bi;Songfang Huang;Fei Huang;Luo Si,~Fuli_Luo1;~Wei_Wang41;~Jiahao_Liu2;~Yijia_Liu1;~Bin_Bi1;~Songfang_Huang1;~Fei_Huang2;~Luo_Si3,4;7;5;4;9,5;4;4;5;5,Reject,0,8,0.0,yes,9/28/20,"Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;University of California, Los Angeles;Alibaba Group;Alibaba Group;Alibaba Group",Natural Language Processing;Representation Learning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;15;-1;-1;-1,f;m,NAN,NAN,n,8;3
6754,ICLR,2021,Rethinking the Truly Unsupervised Image-to-Image Translation,Kyungjune Baek;Yunjey Choi;Youngjung Uh;Jaejun Yoo;Hyunjung Shim,~Kyungjune_Baek1;~Yunjey_Choi3;~Youngjung_Uh2;~Jaejun_Yoo1;~Hyunjung_Shim1,5;6;6;6,3;5;4;5,Reject,0,8,0.0,yes,9/28/20,Yonsei University;NAVER;Yonsei University;Swiss Federal Institute of Technology Lausanne;Yonsei University,unsupervised approach;image-to-image translation;representation learning,150;-1;150;-1;150,186;-1;186;-1;186,u;f,asia,cn,n,
6755,ICLR,2021,A generalized probability kernel on discrete distributions and its application in two-sample test,Le Niu,~Le_Niu1,2;3;2;1,4;4;5;5,Reject,0,5,0.0,yes,9/28/20,Johns Hopkins University,maximum mean discrepancy;RKHS;two-sample test;empirical estimator;discrete distributions,71,12,m,usa,usa,y,
6756,ICLR,2021,Pre-Training by Completing Point Clouds,Hanchen Wang;Qi Liu;Xiangyu Yue;Joan Lasenby;Matt Kusner,~Hanchen_Wang1;~Qi_Liu5;~Xiangyu_Yue1;~Joan_Lasenby1;~Matt_Kusner1,7;7;4;5,4;4;4;5,Reject,0,8,0.0,yes,9/28/20,"University of Cambridge;Department of Computer Science, University of Oxford;University of California Berkeley;University of Cambridge;University College London",self-supervised learning;pre-training;point clouds,79;46;-1;79;53,6;1;7;6;-1,m;m,europe,uk,n,3;1
6757,ICLR,2021,Learning to communicate through imagination with model-based deep multi-agent reinforcement learning,Arnu Pretorius;Scott Cameron;Andries Petrus Smit;Elan van Biljon;Lawrence Francis;Femi Azeez;Alexandre Laterre;Karim Beguir,~Arnu_Pretorius1;scott.a.cameron@live.co.uk;dries.epos@gmail.com;elanvanbiljon@gmail.com;l.francis@instadeep.com;f.azeez@instadeep.com;~Alexandre_Laterre1;kb@instadeep.com,4;3;4;3,3;3;5;5,Reject,0,1,0.0,yes,9/28/20,"InstaDeep;;;Stellenbosch University;Stellenbosch University;InstaDeep;Carnegie Mellon University;InstaDeep;NYU, New York University",,-1;-1;-1;453;453;-1;1;-1;23,-1;-1;-1;285;285;-1;28;-1;26,m;m,NAN,NAN,n,
6758,ICLR,2021,Characterizing Lookahead Dynamics of Smooth Games,Junsoo Ha;Gunhee Kim,~Junsoo_Ha1;~Gunhee_Kim1,7;9;4;4,4;4;4;3,Reject,0,8,0.0,yes,9/28/20,Seoul National University;Seoul National University,Lookahead optimizer;game dynamics;smooth game,37;37,60;60,m;m,asia,kr,y,8;5;4;9
6759,ICLR,2021,Context-Agnostic Learning Using Synthetic Data,Charles Jin;Martin Rinard,~Charles_Jin1;~Martin_Rinard1,5;7;5;6,3;3;3;4,Reject,0,7,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology,machine learning;synthetic data;few-shot learning;domain adaptation,5;5,4;4,m;m,usa,usa,y,6
6760,ICLR,2021,Adaptive Spatial-Temporal Inception Graph Convolutional Networks for Multi-step Spatial-Temporal Network Data Forecasting,Xing Wang;Lin Zhu;Juan Zhao;Zhou Xu;Zhao Li;Junlan Feng;Chao Deng,~Xing_Wang4;~Lin_Zhu5;~Juan_Zhao2;~Zhou_Xu1;~Zhao_Li4;~Junlan_Feng2;~Chao_Deng3,3;3;3;5,5;4;5;5,Reject,0,4,0.0,yes,9/28/20,China Mobile;;Beijing University of Posts and Telecommunications;Beijing University of Post and Telecommunication  Tsinghua University;Beijing University of Post and Telecommunication  Tsinghua University;;China Mobile,,-1;-1;-1;4;4;-1;-1,-1;-1;-1;20;20;-1;-1,m;m,NAN,NAN,n,8;10
6761,ICLR,2021,Globetrotter: Unsupervised Multilingual Translation from Visual Alignment,Didac Suris Coll-Vinent;Dave Epstein;Carl Vondrick,~Didac_Suris_Coll-Vinent1;~Dave_Epstein1;~Carl_Vondrick2,5;5;5;7,4;4;5;3,Reject,0,9,0.0,yes,9/28/20,Columbia University;University of California Berkeley;Columbia University,cross-modal;multilingual;unsupervised translation;visual similarity,23;-1;23,17;7;17,m;m,usa,usa,n,3
6762,ICLR,2021,Exploring  the Potential of Low-Bit Training of Convolutional Neural Networks,Kai Zhong;Xuefei Ning;Tianchen Zhao;Zhenhua Zhu;Shulin Zeng;Guohao Dai;Yu Wang;Huazhong Yang,~Kai_Zhong2;~Xuefei_Ning1;~Tianchen_Zhao2;zhuzhenh18@mails.tsinghua.edu.cn;zengsl18@mails.tsinghua.edu.cn;daiguohao@mail.tsinghua.edu.cn;~Yu_Wang3;~Huazhong_Yang1,6;4;4;5,4;4;4;3,Reject,0,4,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University;BUAA;;;;;Tsinghua University, Tsinghua University;Tsinghua University;;Tsinghua University",CNN;training;quantization;low-bit;energy efficiency,4;4;327;-1;-1;-1;-1;4;4;-1;4,20;20;-1;-1;-1;-1;-1;20;20;-1;20,m;m,asia,cn,n,
6763,ICLR,2021,On Size Generalization in Graph Neural Networks,Gilad Yehudai;Ethan Fetaya;Eli Meirom;Gal Chechik;Haggai Maron,~Gilad_Yehudai2;~Ethan_Fetaya1;~Eli_Meirom2;~Gal_Chechik1;~Haggai_Maron1,7;5;4;5,3;3;5;4,Reject,0,8,0.0,yes,9/28/20,Weizmann Institute;Bar Ilan University;NVIDIA;Bar Ilan University;NVIDIA,graph neural networks;gnn;generalization;Weisfeiler-Lehman,110;110;-1;110;-1,-1;570;-1;570;-1,m;m,NAN,NAN,y,1;10
6764,ICLR,2021,Pea-KD: Parameter-efficient and accurate Knowledge Distillation,IKHYUN CHO;U Kang,~IKHYUN_CHO1;~U_Kang1,5;6;5;7,4;4;3;3,Reject,0,8,0.0,yes,9/28/20,Seoul National University;Seoul National University,BERT;Deep Learning;Natural Language Processing;Transformer;Knowledge Distillation;Parameter Sharing,37;37,60;60,m;m,asia,kr,n,
6765,ICLR,2021,Evaluating Online Continual Learning with CALM,Germ√°n Kruszewski;Ionut Teodor Sorodoc;Tomas Mikolov,~Germ√°n_Kruszewski1;~Ionut_Teodor_Sorodoc1;~Tomas_Mikolov1,6;4;3;4,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,Naver Labs Europe;Universitat Pompeu Fabra;Facebook,online continual learning;catastrophic forgetting;benchmark;language modelling,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3
6766,ICLR,2021,Bridging Graph Network to Lifelong Learning with Feature Interaction,Chen Wang;Yuheng Qiu;Sebastian Scherer,~Chen_Wang2;~Yuheng_Qiu1;~Sebastian_Scherer1,4;5;5;6,4;4;4;4,Reject,0,10,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Graph Neural Network;Continual Learning,1;1;1,28;28;28,m;m,usa,usa,n,10
6767,ICLR,2021,GeDi: Generative Discriminator Guided Sequence Generation,Ben Krause;Akhilesh Deepak Gotmare;Bryan McCann;Nitish Shirish Keskar;Shafiq Joty;richard socher;Nazneen Rajani,~Ben_Krause1;~Akhilesh_Deepak_Gotmare1;~Bryan_McCann1;~Nitish_Shirish_Keskar1;~Shafiq_Joty1;~richard_socher1;~Nazneen_Rajani1,6;5;4;6;5,4;4;5;4;3,Reject,0,7,0.0,yes,9/28/20,"SalesForce.com;Swiss Federal Institute of Technology Lausanne;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com;University of Texas, Austin",Language modeling;controllable generation;decoding schemes;auto-regressive models;language modeling safety,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;f,usa,usa,n,6;3;5
6768,ICLR,2021,Multimodal Variational Autoencoders for Semi-Supervised Learning: In Defense of Product-of-Experts,Svetlana Kutuzova;Oswin Krause;Douglas McCloskey;Mads Nielsen;Christian Igel,svegal@biosustain.dtu.dk;~Oswin_Krause1;domccl@biosustain.dtu.dk;~Mads_Nielsen2;~Christian_Igel1,4;4;5;6,4;4;3;2,Reject,0,4,0.0,yes,9/28/20,Technical University of Denmark;University of Copenhagen;;;University of Copenhagen;University of Copenhagen,variational autoencoder;multimodal data;product-of-experts;semi-supervised learning,-1;92;-1;-1;92;92,186;84;-1;-1;84;84,f;m,europe,dk,n,5
6769,ICLR,2021,Are Graph Convolutional Networks Fully Exploiting the Graph Structure?,Davide Buffelli;Fabio Vandin,~Davide_Buffelli1;~Fabio_Vandin2,4;5;6;4,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Universita' degli studi di Padova;Universita' degli studi di Padova,Graph Representation Learning;Graph Neural Networks;Random Walks,-1;-1,-1;-1,m;m,NAN,NAN,y,10
6770,ICLR,2021,Online Continual Learning  Under  Domain Shift,Quang Pham;Chenghao Liu;Steven HOI,~Quang_Pham1;~Chenghao_Liu1;~Steven_HOI1,5;5;3;4,3;4;5;4,Reject,0,4,0.0,yes,9/28/20,Singapore Management University;Zhejiang University;Singapore Management University,Continual Learning;Domain Generalization,79;42;79,-1;94;-1,m;m,asia,sg,n,4
6771,ICLR,2021,Training Invertible Linear Layers through Rank-One Perturbations,Andreas Kr√§mer;Jonas K√∂hler;Frank Noe,~Andreas_Kr√§mer1;~Jonas_K√∂hler1;~Frank_Noe1,6;2;6;5,1;5;3;3,Reject,0,7,0.0,yes,9/28/20,Freie Universit√§t Berlin;Freie Universit√§t Berlin;Freie Universit√§t Berlin,Parameter Perturbation;Reparameterization;Invertible Neural Networks;Normalizing Flows;Rank-one update,327;327;327,-1;-1;-1,m;m,europe,de,n,
6772,ICLR,2021,Conditional Generative Modeling for De Novo Hierarchical Multi-Label Functional Protein Design,Tim Kucera;Karsten Michael Borgwardt;Matteo Togninalli;Laetitia Papaxanthos,~Tim_Kucera1;karsten.borgwardt@bsse.ethz.ch;~Matteo_Togninalli1;~Laetitia_Papaxanthos2,3;4;7;3,4;4;3;5,Reject,0,6,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Visium;Google Research,protein design;conditional generative adversarial networks;gene ontology;hierarchical multi-label;GO;GAN,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,5;4
6773,ICLR,2021,Deep Clustering and Representation Learning that Preserves Geometric Structures,Lirong Wu;Zicheng Liu;Zelin Zang;Jun Xia;Siyuan Li;Stan Z. Li,~Lirong_Wu1;~Zicheng_Liu2;~Zelin_Zang2;~Jun_Xia1;~Siyuan_Li6;~Stan_Z._Li2,7;4;6;4,4;4;4;4,Reject,0,10,0.0,yes,9/28/20,"Westlake University;Westlake University;Westlake University;Westlake University, China;Westlake University;Westlake University",Deep Clustering;Manifold Representation Learning,263;263;263;263;263;263,-1;-1;-1;-1;-1;-1,u;m,asia,cn,n,
6774,ICLR,2021,"Spherical Motion Dynamics: Learning Dynamics of Neural Network with Normalization, Weight Decay, and SGD",Ruosi Wan;Zhanxing Zhu;Xiangyu Zhang;Jian Sun,~Ruosi_Wan4;~Zhanxing_Zhu1;~Xiangyu_Zhang1;~Jian_Sun4,7;4;5;6,4;4;3;2,Reject,0,11,0.0,yes,9/28/20,Megvii Technology Inc.;Peking University;MEGVII Technology;Megvii Technology,Normalization;Weight decay;SGD;Momentum,-1;14;-1;-1,-1;23;-1;-1,m;m,NAN,NAN,y,2;1
6775,ICLR,2021,Cross-Modal Domain Adaptation for Reinforcement Learning,Xiong-Hui Chen;Shengyi Jiang;Feng Xu;Yang Yu,~Xiong-Hui_Chen1;~Shengyi_Jiang2;~Feng_Xu6;~Yang_Yu5,5;5;4;5,3;4;4;3,Reject,0,13,0.0,yes,9/28/20,Nanjing University;Nanjing University;Nanjing University;Nanjing University,Domain Adaptation;Reinforcement Learning,52;52;52;52,111;111;111;111,m;m,asia,kr,n,
6776,ICLR,2021,Noisy Agents: Self-supervised Exploration by Predicting Auditory Events,Chuang Gan;Xiaoyu Chen;Phillip Isola;Antonio Torralba;Joshua B. Tenenbaum,~Chuang_Gan1;~Xiaoyu_Chen4;~Phillip_Isola1;~Antonio_Torralba1;~Joshua_B._Tenenbaum1,5;2;5;4;6;4,4;4;3;3;4;4,Reject,0,17,0.0,yes,9/28/20,"MIT-IBM Watson AI Lab;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology",Audio Curiosity;RL exploration,-1;4;5;5;5,-1;20;4;4;4,m;m,usa,usa,n,
6777,ICLR,2021,Disentangling Adversarial Robustness in Directions of the Data Manifold,Jiancong Xiao;Liusha Yang;Zhi-Quan Luo,~Jiancong_Xiao1;~Liusha_Yang1;~Zhi-Quan_Luo1,6;4;6;5,5;3;3;4,Reject,0,6,0.0,yes,9/28/20,"The Chinese University of Hong Kong, Shenzhen;The Hong Kong University of Science and Technology;University of Minnesota-Twin Cities",Adversarial Robustness;Adversarial Training;Generative Models,46;-1;71,39;56;85,u;m,NAN,NAN,y,8;1;5;4
6778,ICLR,2021,Loss Landscape Matters: Training Certifiably Robust Models with Favorable Loss Landscape,Sungyoon Lee;Woojin Lee;Jinseong Park;Jaewook Lee,~Sungyoon_Lee1;~Woojin_Lee1;~Jinseong_Park1;~Jaewook_Lee1,3;4;7,5;5;3,Reject,0,14,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Adversarial Examples;Certifiable Robustness;Certifiable Training;Loss Landscape;Deep Learning;Security,37;37;37;37,60;60;60;60,m;m,asia,kr,y,1;4
6779,ICLR,2021,Contextual Image Parsing via Panoptic Segment Sorting,Jyh-Jing Hwang;Tsung-Wei Ke;Stella Yu,~Jyh-Jing_Hwang1;~Tsung-Wei_Ke2;~Stella_Yu2,5;6;5;6,4;3;4;3,Reject,0,4,0.0,yes,9/28/20,University of Pennsylvania;University of California Berkeley;University of California Berkeley,metric learning;context encoding;context discovery;image parsing;panoptic segmentation,20;-1;-1,13;7;7,m;f,usa,usa,n,2
6780,ICLR,2021,Identifying Treatment Effects under Unobserved Confounding by Causal Representation Learning,Pengzhou Abel Wu;Kenji Fukumizu,~Pengzhou_Abel_Wu1;~Kenji_Fukumizu1,4;4;6;3,4;4;2;4,Reject,0,5,0.0,yes,9/28/20,The Institute of Statistical Mathematics;Perferred Networks,VAE;variational autoencoder;Representation Learning;treatment effects;causal inference;Unobserved Confounding;identifiability;CATE;ATE,-1;-1,-1;-1,m;m,NAN,NAN,y,5
6781,ICLR,2021,AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data,Koichi Kuriyama,~Koichi_Kuriyama1,3;4;6;5,5;4;3;3,Reject,0,7,0.0,yes,9/28/20,Kyoto University,Automatic Data Cleansing;Incorrect Labels;Multiple Objects,174,54,m,europe,fi,y,
6782,ICLR,2021,A Simple Unified Information Regularization Framework for Multi-Source Domain Adaptation,Geon Yeong Park;Sang wan Lee,~Geon_Yeong_Park1;sangwan@kaist.ac.kr,7;4;4;5,3;4;5;4,Reject,0,8,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Multi-source Domain Adaptation;Transfer learning;Adversarial learning;Information theory,-1;-1,96;96,u;m,NAN,NAN,y,4
6783,ICLR,2021,Experimental Design for Overparameterized Learning with Application to Single Shot Deep Active Learning,Neta Shoham;Haim Avron,~Neta_Shoham1;~Haim_Avron4,5;3;4;4,3;4;3;4,Reject,0,5,0.0,yes,9/28/20,"Tel Aviv University, Technion;Tel Aviv University, Technion",,29;29,190;190,m;m,NAN,NAN,y,1
6784,ICLR,2021,Democratizing Evaluation of Deep Model Interpretability through Consensus,Xuhong Li;Haoyi Xiong;Siyu Huang;Shilei Ji;Yanjie Fu;Dejing Dou,~Xuhong_Li3;~Haoyi_Xiong1;~Siyu_Huang2;jishilei@baidu.com;~Yanjie_Fu2;~Dejing_Dou1,4;5;3;6,4;5;3;3,Reject,0,13,0.0,yes,9/28/20,Baidu;Baidu;Nanyang Technological University;;;University of Central Florida;University of Oregon Eugene,interpretability evaluation;deep model interpretability,-1;-1;44;-1;-1;71;209,-1;-1;47;-1;-1;633;346,m;m,NAN,NAN,n,
6785,ICLR,2021,Does injecting linguistic structure into language models lead to better alignment with brain recordings?,Mostafa Abdou;Ana Valeria Gonz√°lez;Mariya K Toneva;Daniel Hershcovich;Anders S√∏gaard,~Mostafa_Abdou2;ana@di.ku.dk;~Mariya_K_Toneva1;~Daniel_Hershcovich1;~Anders_S√∏gaard1,6;7;5;7,3;4;3;3,Reject,0,10,0.0,yes,9/28/20,University of Copenhagen;University of Copenhagen;Carnegie Mellon University;University of Copenhagen;University of Copenhagen,neurolinguistics;natural language processing;computational neuroscience,92;92;1;92;92,84;84;28;84;84,m;m,europe,dk,n,8;3
6786,ICLR,2021,On the Stability of Multi-branch Network,Huishuai Zhang;Da Yu;Wei Chen;Tie-Yan Liu,~Huishuai_Zhang3;~Da_Yu1;~Wei_Chen1;~Tie-Yan_Liu1,3;4;5;5,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,Microsoft Research Asia;SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft,stability;multi-branch network;backward propagation,-1;-1;-1;-1,-1;293;-1;-1,m;m,NAN,NAN,y,
6787,ICLR,2021,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,Xinsong Zhang;Hang Li,~Xinsong_Zhang1;~Hang_Li4,5;3;7;5;4,5;4;3;4;4,Reject,0,7,0.0,yes,9/28/20,Bytedance AI Lab;The University of Tokyo,Pre-trained Language Model;Multi-Grained Tokenization,-1;71,-1;36,m;m,NAN,NAN,n,3
6788,ICLR,2021,Efficient randomized smoothing by denoising with learned score function,Kyungmin Lee;Seyoon Oh,~Kyungmin_Lee1;syoh@add.re.kr,3;6;6;6,5;1;3;2,Reject,0,12,0.0,yes,9/28/20,Agency for Defense Development;Agency for Defense Development,Adversarial Robustness;Provable Adversarial Defense;Randomized Smoothing;Image Denoising;Score Estimation,-1;-1,-1;-1,u;u,NAN,NAN,n,4
6789,ICLR,2021,Dropout's Dream Land: Generalization from Learned Simulators to Reality,Zac Wellmer;James Kwok,~Zac_Wellmer1;~James_Kwok1,6;4;6;3,4;3;3;4,Reject,0,8,0.0,yes,9/28/20,"Hong Kong University of Science and Technology;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",Reinforcement Learning,-1;-1,56;56,m;m,NAN,NAN,n,1;5
6790,ICLR,2021,Distantly Supervised Relation Extraction in Federated Settings,Dianbo Sui;Yubo Chen;Kang Liu;Jun Zhao,~Dianbo_Sui1;~Yubo_Chen1;~Kang_Liu1;~Jun_Zhao4,6;5;6;4;5,3;4;4;4;4,Reject,0,6,0.0,yes,9/28/20,"National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Science;Institute of automation, Chinese academy of science;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science",Distant Supervision;Relation Extraction;Federated Learning,-1;-1;34;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
6791,ICLR,2021,Automatic Data Augmentation for Generalization in Reinforcement Learning,Roberta Raileanu;Maxwell Goldstein;Denis Yarats;Ilya Kostrikov;Rob Fergus,~Roberta_Raileanu2;~Maxwell_Goldstein1;~Denis_Yarats1;~Ilya_Kostrikov1;~Rob_Fergus1,4;7;7;6,4;3;3;3,Reject,0,11,0.0,yes,9/28/20,New York University;New York University;New York University;University of California Berkeley;New York University,reinforcement learning;generalization;data augmentation,23;23;23;-1;23,26;26;26;7;26,f;m,usa,usa,n,1
6792,ICLR,2021,TAM: Temporal Adaptive Module for Video Recognition,Zhaoyang Liu;Limin Wang;Wayne Wu;Chen Qian;Tong Lu,~Zhaoyang_Liu1;~Limin_Wang1;~Wayne_Wu1;~Chen_Qian1;~Tong_Lu1,6;8;4,4;4;5,Reject,0,3,0.0,yes,9/28/20,Nanjing University;Nanjing University;Tsinghua University;The SenseTime Research;Nanjing University,Action Recognition;Temporal Adaptive Module;Temporal Adaptive Network,52;52;4;-1;52,111;111;20;-1;111,u;m,asia,kr,n,
6793,ICLR,2021,Learning not to learn: Nature versus nurture in silico,Robert Tjarko Lange;Henning Sprekeler,~Robert_Tjarko_Lange1;h.sprekeler@tu-berlin.de,5;7;5;6,4;4;4;4,Reject,0,14,0.0,yes,9/28/20,TU Berlin;TU Berlin,Meta-Learning;Reinforcement Learning,128;128,-1;-1,m;m,europe,de,n,6;11
6794,ICLR,2021,On the Role of Pre-training for Meta Few-Shot Learning,Chia-You Chen;Hsuan-Tien Lin;Gang Niu;Masashi Sugiyama,~Chia-You_Chen1;~Hsuan-Tien_Lin1;~Gang_Niu1;~Masashi_Sugiyama1,3;5;4;7,4;5;4;3,Reject,0,0,0.0,yes,9/28/20,"Department of computer science and informational engineering, National Taiwan University;National Taiwan University;RIKEN;RIKEN Center for Advanced Intelligence Project",Meta-Learning;Episodic Training;Pre-training;Disentanglement,99;99;-1;-1,-1;97;-1;-1,u;m,NAN,NAN,n,6
6795,ICLR,2021,How to Train Your Super-Net: An Analysis of Training Heuristics in Weight-Sharing NAS,Kaicheng Yu;Rene Ranftl;Mathieu Salzmann,~Kaicheng_Yu1;~Rene_Ranftl1;~Mathieu_Salzmann1,5;5;5;5,5;3;4;4,Reject,0,6,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Intel;Swiss Federal Institute of Technology Lausanne,autoML;neural architecture search;NAS;one-shot NAS;weight-sharing NAS;super-net,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
6796,ICLR,2021,A Surgery of the Neural Architecture Evaluators,Xuefei Ning;Wenshuo Li;Zixuan Zhou;Tianchen Zhao;Shuang Liang;Yin Zheng;Huazhong Yang;Yu Wang,~Xuefei_Ning1;~Wenshuo_Li1;zhouzx17@mails.tsinghua.edu.cn;~Tianchen_Zhao2;shuang.liang@novauto.com.cn;~Yin_Zheng1;~Huazhong_Yang1;~Yu_Wang3,4;5;3;5,4;4;3;3,Reject,0,0,0.0,yes,9/28/20,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;BUAA;;Weixin Group, Tencent;;Tsinghua University;Tsinghua University",Neural architecture search (NAS);Parameter Sharing NAS;Predictor-based NAS,4;4;4;327;-1;-1;-1;4;4,20;20;20;-1;-1;-1;-1;20;20,u;m,asia,cn,n,8
6797,ICLR,2021,Structure and randomness in planning and reinforcement learning,Piotr Kozakowski;Piotr Januszewski;Konrad Czechowski;≈Åukasz Kuci≈Ñski;Piotr Mi≈Ço≈õ,~Piotr_Kozakowski1;~Piotr_Januszewski1;~Konrad_Czechowski1;~≈Åukasz_Kuci≈Ñski1;~Piotr_Mi≈Ço≈õ1,6;3;6;3;4,4;4;2;4;3,Reject,0,10,0.0,yes,9/28/20,University of Warsaw;Gda≈Ñsk University of Technology;University of Warsaw;Institute of Mathematics Polish Academy of Sciences;Polish Academy of Science,reinforcement learning;uncertainty;model-based;MCTS,128;-1;128;-1;-1,818;1093;818;-1;-1,m;m,NAN,NAN,n,
6798,ICLR,2021,Accounting for Unobserved Confounding in Domain Generalization,Alexis Bellot;Mihaela van der Schaar,~Alexis_Bellot1;~Mihaela_van_der_Schaar2,9;3;7;5,4;5;2;4,Reject,0,5,0.0,yes,9/28/20,University of Cambridge;University of Cambridge,Causality;Robust Optimization;Domain Generalization,79;79,6;6,m;f,europe,uk,y,1
6799,ICLR,2021,AriEL: Volume Coding for Sentence Generation Comparisons,Luca Celotti;Simon Brodeur;Jean Rouat,~Luca_Celotti1;~Simon_Brodeur1;~Jean_Rouat1,3;5;4;7;6,4;3;4;4;2,Reject,0,10,0.0,yes,9/28/20,Universit√© de Sherbrooke;Universit√© de Sherbrooke;Universit√© de Sherbrooke,,327;327;327,-1;-1;-1,m;m,canada,ca,n,8;5
6800,ICLR,2021,Invariant Causal Representation Learning,Chaochao Lu;Yuhuai Wu;Jos√© Miguel Hern√°ndez-Lobato;Bernhard Sch√∂lkopf,~Chaochao_Lu1;~Yuhuai_Wu1;~Jos√©_Miguel_Hern√°ndez-Lobato1;~Bernhard_Sch√∂lkopf1,5;4;4,4;4;4,Reject,0,3,0.0,yes,9/28/20,"University of Cambridge;Department of Computer Science, University of Toronto;University of Cambridge;Max Planck Institute for Intelligent Systems, Max-Planck Institute",,79;18;79;-1,6;18;6;-1,m;m,NAN,NAN,y,1
6801,ICLR,2021,Second-Moment Loss: A Novel Regression Objective for Improved Uncertainties,Joachim Sicking;Maram Akila;Maximilian Alexander Pintz;Tim Wirtz;Asja Fischer;Stefan Wrobel,~Joachim_Sicking1;maram.akila@iais.fraunhofer.de;maximilian.alexander.pintz@iais.fraunhofer.de;~Tim_Wirtz1;~Asja_Fischer1;~Stefan_Wrobel1,4;5;6,5;3;3,Reject,0,8,0.0,yes,9/28/20,Fraunhofer IAIS;;;;;Phyisk;Ruhr-University Bochum;;University of Bonn,regression;uncertainty quantification;uncertainty evaluation;dropout,-1;-1;-1;-1;-1;-1;263;-1;128,-1;-1;-1;-1;-1;-1;257;-1;114,u;m,europe,uk,n,2
6802,ICLR,2021,What Preserves the Emergence of Language?,Ziluo Ding;Tiejun Huang;Zongqing Lu,~Ziluo_Ding1;~Tiejun_Huang1;~Zongqing_Lu2,6;3;5,3;5;3,Reject,0,8,0.0,yes,9/28/20,Peking University;Peking University;Peking University,emergence of language;reinforcement learning,14;14;14,23;23;23,m;m,asia,cn,n,1
6803,ICLR,2021,Neural Pooling for Graph Neural Networks,Sai Sree Harsha;Deepak Mishra,~Sai_Sree_Harsha1;deepak.mishra@iist.ac.in,3;4;3;2,4;5;5;5,Reject,0,4,0.0,yes,9/28/20,National Institute of Technology Karnataka;Indian Institute of Space Science and Technology,graph neural networks;graph pooling;representation learning,-1;-1,-1;-1,m;m,NAN,NAN,n,10
6804,ICLR,2021,UserBERT: Self-supervised User Representation Learning,Tianyu Li;Ali Cevahir;Derek Cho;Hao Gong;DuyKhuong Nguyen;Bjorn Stenger,~Tianyu_Li2;ali.cevahir@rakuten.com;derek.cho@rakuten.com;hao.gong@rakuten.com;duykhuong.nguyen@rakuten.com;bjorn.stenger@rakuten.com,4;5;3;4,3;5;5;4,Reject,0,5,0.0,yes,9/28/20,Rakuten Institute of Technology;;;;;Rakuten Institute of Technology,user representations;representation learning;self-supervised learning;pretraining;transfer learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
6805,ICLR,2021,On Disentangled Representations Extracted from Pretrained GANs,Valentin Khrulkov;Leyla Mirvakhabova;Ivan Oseledets;Artem Babenko,~Valentin_Khrulkov1;~Leyla_Mirvakhabova1;~Ivan_Oseledets1;~Artem_Babenko1,7;4;6,3;4;4,Reject,0,4,0.0,yes,9/28/20,Yandex;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Yandex,Disentanglement;representations;GANs,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,7;5
6806,ICLR,2021,Playing Nondeterministic Games through Planning with a Learned Model,Thomas Willkens;Jordan Pollack,~Thomas_Willkens1;~Jordan_Pollack1,5;7;6;4;3,4;1;4;4;4,Reject,0,5,0.0,yes,9/28/20,Brandeis University;Brandeis University,reinforcement learning;alphazero;muzero;mcts;planning;search,263;263,242;242,m;m,usa,usa,n,1
6807,ICLR,2021,Imbalanced Gradients: A New Cause of Overestimated Adversarial Robustness,Linxi Jiang;Xingjun Ma;Zejia Weng;James Bailey;Yu-Gang Jiang,lxjiang18@fudan.edu.cn;~Xingjun_Ma1;zjweng16@fudan.edu.cn;~James_Bailey1;~Yu-Gang_Jiang1,6;4;5;5,4;5;2;5,Reject,0,7,0.0,yes,9/28/20,Fudan University;Deakin University;;;The University of Melbourne;;Fudan University;Fudan University,Adversarial Attack;Robustness Evaluation;Adversarial Defense;Deep Neural Networks,71;-1;-1;-1;85;-1;71;71,70;295;-1;-1;31;-1;70;70,u;m,asia,cn,n,4
6808,ICLR,2021,Double Generative Adversarial Networks for Conditional Independence Testing,Chengchun Shi;Tianlin Xu;Wicher Pieter Bergsma;Lexin Li,~Chengchun_Shi1;~Tianlin_Xu1;~Wicher_Pieter_Bergsma1;~Lexin_Li1,5;6;6;5,4;4;3;2,Reject,0,5,0.0,yes,9/28/20,"London School of Economics;London School of Economics;London School of Economics;;University of California, Berkeley",conditional independence testing;generative adversarial networks;high dimensionality;statistical inference,-1;-1;-1;-1;-1,27;27;27;-1;7,m;m,usa,usa,y,5;4
6809,ICLR,2021,Filter pre-pruning for improved fine-tuning of quantized deep neural networks,Jun Nishikawa;Ryoji Ikegaya,~Jun_Nishikawa2;~Ryoji_Ikegaya1,6;5;5;6,3;3;3;4,Reject,0,9,0.0,yes,9/28/20,Waseda University;Sony,Deep Neural Networks;Quantization;Quantize;Pruning;MobileNet;compression,327;-1,867;-1,u;u,asia,cn,n,
6810,ICLR,2021,The Lipschitz Constant of Self-Attention,Hyunjik Kim;George Papamakarios;Andriy Mnih,~Hyunjik_Kim1;~George_Papamakarios1;~Andriy_Mnih1,7;7;5;5,4;2;3;4,Reject,0,6,0.0,yes,9/28/20,DeepMind;DeepMind;DeepMind,Lipschitz constant;self-attention;theory,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,8;5;4;3;1
6811,ICLR,2021,Efficient Graph Neural Architecture Search,Huan Zhao;Lanning Wei;quanming yao;Zhiqiang He,~Huan_Zhao2;~Lanning_Wei1;~quanming_yao1;hezq@levono.com,5;5;5;3,5;4;3;5,Reject,0,6,0.0,yes,9/28/20,4Paradigm Inc.;  Chinese Academy of Sciences;4Paradigm Inc.;Lenovo,graph neural network;neural architecture search;automated machine learning,-1;34;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6;10
6812,ICLR,2021,What's in the Box? Exploring the Inner Life of Neural Networks with Robust Rules,Jonas Fischer;Anna Ol√°h;Jilles Vreeken,~Jonas_Fischer1;aolah@mmci.uni-saarland.de;jv@cispa.de,6;8;3;5,4;3;4;3,Reject,0,11,0.0,yes,9/28/20,Max-Planck Institute for Informatics;;;CISPA Helmholtz Center for Information Security,Neural Networks;CNN;explaining;interpretable;Rules;black box,-1;-1;-1;99,-1;-1;-1;-1,m;m,NAN,NAN,n,
6813,ICLR,2021,Status-Quo Policy Gradient in Multi-agent Reinforcement Learning,Pinkesh Badjatiya;Mausoom Sarkar;Abhishek Sinha;Nikaash Puri;Jayakumar Subramanian;Siddharth Singh;Balaji Krishnamurthy,~Pinkesh_Badjatiya1;~Mausoom_Sarkar1;~Abhishek_Sinha1;~Nikaash_Puri1;~Jayakumar_Subramanian1;siddharth9820@gmail.com;~Balaji_Krishnamurthy1,5;4;6;7,3;4;5;2,Reject,0,9,0.0,yes,9/28/20,"Adobe Systems;Adobe;Stanford University;Delhi Technological University (Delhi College of Engineering), Dhirubhai Ambani Institute Of Information and Communication Technology;Adobe Systems;;Adobe Systems",multi-agent rl;reinforcement learning;social dilemma;policy gradient;game theory,-1;-1;5;-1;-1;-1;-1,-1;-1;2;914;-1;-1;-1,m;m,NAN,NAN,y,
6814,ICLR,2021,Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time,Ferran Alet;Kenji Kawaguchi;Maria Bauza Villalonga;Nurullah Giray Kuru;Tomas Perez;Leslie Pack Kaelbling,~Ferran_Alet1;~Kenji_Kawaguchi1;~Maria_Bauza_Villalonga1;ngkuru@mit.edu;~Tomas_Perez1;~Leslie_Pack_Kaelbling1,7;5;4;6,3;2;3;3,Reject,0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Harvard University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,inductive biases;meta-learning;semi-supervised learning;adversarial learning;representation learning;transductive learning,5;53;5;5;5;5,4;3;4;4;4;4,m;f,usa,usa,y,6;8;1;4
6815,ICLR,2021,Connecting Sphere Manifolds Hierarchically for Regularization,Damien Scieur;Youngsung Kim,~Damien_Scieur3;~Youngsung_Kim3,5;5;5;6,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,"Department of Computer Science, Princeton University;Samsung",Hierarchy;Manifold;Classification,29;-1,9;-1,m;m,NAN,NAN,n,
6816,ICLR,2021,Putting Theory to Work: From Learning Bounds to Meta-Learning Algorithms,Quentin Bouniot;Ievgen Redko;Romaric Audigier;Ang√©lique Loesch;Amaury Habrard,~Quentin_Bouniot1;~Ievgen_Redko2;romaric.audigier@cea.fr;angelique.loesch@cea.fr;~Amaury_Habrard1,5;5;4;4,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,"CEA;University Jean Monnet;CEA;CEA;Universit√© Saint-Etienne, Laboratoire Hubert Curien",meta-learning;few-shot learning,209;327;209;209;-1,969;-1;969;969;-1,m;m,NAN,NAN,n,6;1
6817,ICLR,2021,WAVEQ: GRADIENT-BASED DEEP QUANTIZATION OF NEURAL NETWORKS THROUGH SINUSOIDAL REGULARIZATION,Ahmed T. Elthakeb;Prannoy Pilligundla;Tarek Elgindi;Fatemehsadat Mireshghallah;Charles-Alban Deledalle;Hadi Esmaeilzadeh,~Ahmed_T._Elthakeb1;~Prannoy_Pilligundla1;telgindi@ucsd.edu;~Fatemehsadat_Mireshghallah1;~Charles-Alban_Deledalle2;~Hadi_Esmaeilzadeh1,4;7;5;7,5;4;4;4,Reject,0,5,0.0,yes,9/28/20,"University of California, San Diego;University of California, San Diego;;;University of California, San Diego;;University of California, San Diego",,-1;-1;-1;-1;-1;-1;-1,33;33;-1;-1;33;-1;33,m;m,usa,usa,y,8
6818,ICLR,2021,Uniform Manifold Approximation with Two-phase Optimization,Hyung-Kwon Ko;Jaemin Jo;Yung-Kyun Noh;Jinwook Seo,~Hyung-Kwon_Ko1;~Jaemin_Jo1;~Yung-Kyun_Noh1;~Jinwook_Seo1,6;4;5;5,4;5;4;4,Reject,0,6,0.0,yes,9/28/20,Seoul National University;Sungkyunkwan University;Hanyang University;George Washington University,Dimensionality Reduction;Manifold Learning;Visualization;Topological Data Analysis;UMAP,37;-1;209;209,60;100;380;186,m;m,usa,usa,n,
6819,ICLR,2021,Robustness to Pruning Predicts Generalization in Deep Neural Networks,Lorenz Kuhn;Clare Lyle;Aidan Gomez;Jonas Rothfuss;Yarin Gal,~Lorenz_Kuhn1;~Clare_Lyle1;~Aidan_Gomez1;~Jonas_Rothfuss1;~Yarin_Gal1,5;5;7;5,4;4;4;3,Reject,0,14,0.0,yes,9/28/20,Swiss Federal Institute of Technology;University of Oxford;University of Oxford;Swiss Federal Institute of Technology;University of Oxford,Generalization;Pruning;Generalization Measures,-1;46;46;-1;46,-1;1;1;-1;1,m;m,europe,uk,n,1
6820,ICLR,2021,Neural spatio-temporal reasoning with object-centric self-supervised learning,David Ding;Felix Hill;Adam Santoro;Matthew Botvinick,~David_Ding2;~Felix_Hill1;~Adam_Santoro1;~Matthew_Botvinick1,5;4;5;6,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,DeepMind;Computer Laboratory;Google;Google,self-attention;object representations;visual reasoning;dynamics;visual question answering,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
6821,ICLR,2021,Self-Labeling of Fully Mediating Representations by Graph Alignment,Martijn Oldenhof;Adam Arany;Yves Moreau;Jaak Simm,~Martijn_Oldenhof1;~Adam_Arany1;~Yves_Moreau2;~Jaak_Simm1,4;5;5;4,4;4;4;3,Reject,0,6,0.0,yes,9/28/20,KU Leuven;KU Leuven;University of Leuven;KU Leuven,domain adaptation;self-labeling;chemical graph recognition,150;150;-1;150,45;45;874;45,m;m,europe,be,n,10
6822,ICLR,2021,Self-Reflective Variational Autoencoder,Ifigeneia Apostolopoulou;Elan Rosenfeld;Artur Dubrawski,~Ifigeneia_Apostolopoulou1;~Elan_Rosenfeld1;~Artur_Dubrawski2,5;7;3,5;3;4,Reject,0,9,0.0,yes,9/28/20,"Carnegie Mellon University;CMU, Carnegie Mellon University;Carnegie-Mellon University",deep generative models;variational inference;approximate inference;variational auto encoder,1;1;1,28;28;28,f;m,usa,usa,n,5
6823,ICLR,2021,Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent Populations,Kalesha Bullard;Franziska Meier;Douwe Kiela;Joelle Pineau;Jakob Nicolaus Foerster,~Kalesha_Bullard1;~Franziska_Meier2;~Douwe_Kiela1;~Joelle_Pineau1;~Jakob_Nicolaus_Foerster1,5;6;6;6,4;1;3;3,Reject,0,6,0.0,yes,9/28/20,Facebook AI Research;Facebook;Facebook AI Research;Facebook;Facebook AI Research,emergent communication;multi-agent communication;multi-agent reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
6824,ICLR,2021,Better Optimization can Reduce Sample Complexity: Active Semi-Supervised Learning via Convergence Rate Control,Seo Taek Kong;Soomin Jeon;Jaewon Lee;Hong-Seok Lee;Kyu-Hwan Jung,~Seo_Taek_Kong1;soomin.jeon@vuno.co;~Jaewon_Lee2;hongseok@vuno.co;~Kyu-Hwan_Jung1,5;5;5;6,4;3;3;3,Reject,0,8,0.0,yes,9/28/20,"VUNO Inc.;Massachusetts General Hospital, Harvard University;Kangwon National University;Seoul National University;VUNO inc.",Active Learning;Semi-Supervised Learning;Neural Tangent Kernel;Deep Learning,-1;53;-1;37;-1,-1;3;1237;60;-1,m;m,NAN,NAN,y,1;9
6825,ICLR,2021,Learning from deep model via exploring local targets,Wenxian Shi;Yuxuan Song;Hao Zhou;Bohan Li;Lei Li,~Wenxian_Shi1;~Yuxuan_Song2;~Hao_Zhou6;libohan.05@bytedance.com;~Lei_Li11,4;4;3;5,5;5;5;3,Reject,0,4,0.0,yes,9/28/20,ByteDance AI-Lab;Bytedance;;;;ByteDance AI Lab,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
6826,ICLR,2021,Model-based Asynchronous Hyperparameter and Neural Architecture Search,Aaron Klein;Louis Chi-Chun Tiao;Thibaut Lienart;Cedric Archambeau;Matthias Seeger,~Aaron_Klein1;~Louis_Chi-Chun_Tiao1;~Thibaut_Lienart1;~Cedric_Archambeau1;~Matthias_Seeger2,6;6;6;6;5,4;3;2;4;5,Reject,0,9,0.0,yes,9/28/20,Amazon Berlin;University of Sydney;;Amazon Web Services;Amazon Development Center Germany,Bayesian Optimization;AutoML;Hyperparameter Optimization;Neural Architecture Search,-1;71;-1;-1;-1,-1;51;-1;-1;-1,m;m,NAN,NAN,n,11;3;10
6827,ICLR,2021,Private Split Inference of Deep Networks,Mohammad Samragh;Hossein Hosseini;Kambiz Azarian;Joseph Soriaga,~Mohammad_Samragh1;~Hossein_Hosseini4;kambiza@qti.qualcomm.com;jsoriaga@qti.qualcomm.com,5;5;5,3;5;4,Reject,0,4,0.0,yes,9/28/20,University of California  San Diego;Qualcomm Inc  QualComm;QualComm;QualComm,ML privacy;split inference,-1;-1;-1;-1,33;-1;-1;-1,m;m,NAN,NAN,n,
6828,ICLR,2021,Cluster & Tune: Enhance BERT Performance in Low Resource Text Classification,Eyal Shnarch;Ariel Gera;Alon Halfon;Lena Dankin;Leshem Choshen;Ranit Aharonov;Noam Slonim,~Eyal_Shnarch1;arielge@il.ibm.com;alonhal@il.ibm.com;lenad@il.ibm.com;~Leshem_Choshen1;~Ranit_Aharonov2;noams@il.ibm.com,6;6;8;3,4;3;3;4,Reject,0,4,0.0,yes,9/28/20,Bar Ilan University  Technion;Hebrew University of Jerusalem  Technion;Bar Ilan University  Technion;Tel Aviv University;hebrew university jerusalem israel;Hebrew University of Jerusalem  Technion;;IBM,low resource;BERT;clustering,29;29;29;34;-1;29;-1;453,-1;235;-1;190;-1;235;-1;-1,m;m,asia,in,n,
6829,ICLR,2021,Luring of transferable adversarial perturbations in the black-box paradigm,R√©mi Bernhard;Pierre-Alain Mo√´llic;Jean-Max Dutertre,~R√©mi_Bernhard1;~Pierre-Alain_Mo√´llic1;~Jean-Max_Dutertre1,5;6;8;5,2;4;3;4,Reject,0,8,0.0,yes,9/28/20,CEA;CEA LETI;Mines Saint-Etiennes,Neural Networks;Adversarial Machine Learning;Security,209;-1;-1,969;-1;-1,m;m,NAN,NAN,n,4
6830,ICLR,2021,All-You-Can-Fit 8-Bit Flexible Floating-Point Format for Accurate and Memory-Efficient Inference of Deep Neural Networks,Juinn-Dar Huang;Cheng-Wei Huang;Tim-Wei Chen,~Juinn-Dar_Huang1;~Cheng-Wei_Huang1;~Tim-Wei_Chen1,4;3;7;6,4;5;3;4,Reject,0,8,0.0,yes,9/28/20,National Chiao Tung University;National Chiao Tung University;National Yang Ming Chiao Tung University,8-bit floating-point format;accuracy loss minimization;numerics;memory-efficient inference;deep learning,128;128;-1,564;564;-1,m;m,NAN,NAN,n,
6831,ICLR,2021,"On Relating Why?"" and ""Why Not?"" Explanations""",Alexey Ignatiev;Nina Narodytska;Nicholas Asher;Joao Marques-Silva,~Alexey_Ignatiev1;~Nina_Narodytska1;nicholas.asher@irit.fr;~Joao_Marques-Silva1,5;5;6;8,5;2;2;3,Reject,0,5,0.0,yes,9/28/20,"Monash University;University of New South Wales;;;IRIT, CNRS",Explanability;contrastive explanations;duality,92;-1;-1;-1;-1,64;-1;-1;-1;-1,m;m,NAN,NAN,y,1
6832,ICLR,2021,"Don't be picky, all students in the right family can learn from good teachers",Roy Henha Eyono;Fabio Maria Carlucci;Pedro M Esperan√ßa;Binxin Ru;Philip Torr,~Roy_Henha_Eyono1;~Fabio_Maria_Carlucci2;~Pedro_M_Esperan√ßa1;~Binxin_Ru1;~Philip_Torr1,3;3;5,4;3;4,Reject,0,7,0.0,yes,9/28/20,University of the Witwatersrand;Facebook;Huawei Technologies Ltd.;University of Oxford;University of Oxford,knowledge distillation;neural architecture search;nas;automl;knowledge trasfer;model compression,-1;-1;-1;46;46,206;-1;-1;1;1,m;m,europe,uk,n,11;10
6833,ICLR,2021,Provable More Data Hurt in High Dimensional Least Squares Estimator,Zeng Li;Chuanlong Xie;QINWEN WANG,liz9@sustech.edu.cn;~Chuanlong_Xie1;~QINWEN_WANG1,7;6;6,4;3;4,Reject,0,5,0.0,yes,9/28/20,"Southern University of Science and Technology of China, Tsinghua University;Huawei Technologies Ltd.;Fudan University",,4;-1;71,20;-1;70,f;m,asia,cn,y,1
6834,ICLR,2021,A Multi-Modal and Multitask Benchmark in the Clinical Domain,Yong Huang;Edgar Mariano Marroquin;Volodymyr Kuleshov,~Yong_Huang3;~Edgar_Mariano_Marroquin1;vk379@cornell.edu,5;5;5,5;4;4,Reject,0,3,0.0,yes,9/28/20,Cornell University;Department of Computer Science  Cornell University;;Cornell University,multi-modal;multitask;machine learning in healthcare;benchmark,7;7;-1;7,19;19;-1;19,m;m,usa,usa,n,10
6835,ICLR,2021,Learning to Use Future Information in Simultaneous Translation,Xueqing Wu;Yingce Xia;Lijun Wu;Shufang Xie;Weiqing Liu;Tao Qin;Tie-Yan Liu,~Xueqing_Wu1;~Yingce_Xia1;~Lijun_Wu1;~Shufang_Xie1;weiqing.liu@microsoft.com;~Tao_Qin1;~Tie-Yan_Liu1,5;5;5;4,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,University of Science and Technology of China;Microsoft;Microsoft Research;Microsoft Research Asia;Microsoft;Tsinghua University;Microsoft,sequence learning;simultaneous machine translation,-1;-1;-1;-1;-1;4;-1,87;-1;-1;-1;-1;20;-1,u;m,NAN,NAN,n,8;3
6836,ICLR,2021,Learning-Augmented Sketches for Hessians,Yi Li;Honghao Lin;David Woodruff,~Yi_Li8;~Honghao_Lin1;~David_Woodruff2,4;6;6,5;4;3,Reject,0,5,0.0,yes,9/28/20,Nanyang Technological University;Carnegie Mellon University;Carnegie Mellon University,,44;1;1,47;28;28,m;m,usa,usa,y,
6837,ICLR,2021,Federated Continual Learning with Weighted Inter-client Transfer,Jaehong Yoon;Wonyong Jeong;Giwoong Lee;Eunho Yang;Sung Ju Hwang,~Jaehong_Yoon1;~Wonyong_Jeong1;~Giwoong_Lee1;~Eunho_Yang1;~Sung_Ju_Hwang1,5;6;7;6,4;5;3;5,Reject,0,21,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology,Continual Learning;Federated Learning;Deep Learning,-1;-1;-1;-1;-1,96;96;96;-1;96,m;m,NAN,NAN,n,
6838,ICLR,2021,Learning to Generate Questions by Recovering Answer-containing Sentences,Seohyun Back;Akhil Kedia;Sai Chetan Chinthakindi;Haejun Lee;Jaegul Choo,~Seohyun_Back1;~Akhil_Kedia1;~Sai_Chetan_Chinthakindi1;haejun82.lee@samsung.com;~Jaegul_Choo1,6;7;7;5,4;4;4;4,Reject,0,14,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;-;Indian Institute of Technology Bombay;;;Korea Advanced Institute of Science and Technology,Question Generation;Question Answering;Data Augmentation;Machine Reading Comprehension,-1;2;-1;-1;-1;-1,96;22;-1;-1;-1;96,u;m,NAN,NAN,n,5
6839,ICLR,2021,Learning to Solve Nonlinear Partial Differential Equation Systems To Accelerate MOSFET Simulation,Seungcheol Han;Jonghyun Choi;Sung-Min Hong,~Seungcheol_Han1;~Jonghyun_Choi1;~Sung-Min_Hong1,4;6;5;5;7,4;4;2;5;4,Reject,0,18,0.0,yes,9/28/20,Gwangju Institute of Science and Technology;Gwangju Institute of Science and Technology;Gwangju Institute of Science and Technology,Partial differential equation;nonlinear equation;Newton-Raphson method;convolutional neural network,-1;-1;-1,506;506;506,m;m,NAN,NAN,n,
6840,ICLR,2021,Class2Simi: A New Perspective on Learning with Label Noise,Songhua Wu;Xiaobo Xia;Tongliang Liu;Bo Han;Mingming Gong;Nannan Wang;Haifeng Liu;Gang Niu,~Songhua_Wu1;~Xiaobo_Xia1;~Tongliang_Liu1;~Bo_Han1;~Mingming_Gong1;~Nannan_Wang1;haifeng@leinao.ai;~Gang_Niu1,6;3;5;3;6,4;4;4;4;4,Reject,0,60,0.0,yes,9/28/20,University of Sydney;The University of Sydney;University of Sydney;HKBU;The University of Melbourne;Xidian University;;;RIKEN,,71;71;71;-1;85;-1;-1;-1;-1,51;51;51;-1;31;924;-1;-1;-1,m;m,NAN,NAN,y,1
6841,ICLR,2021,AUBER: Automated BERT Regularization,Hyun Dong Lee;Seongmin Lee;U Kang,~Hyun_Dong_Lee1;~Seongmin_Lee2;~U_Kang1,5;4;4;5,5;5;4;4,Reject,0,4,0.0,yes,9/28/20,Columbia University;Seoul National University;Seoul National University,BERT Regularization;Reinforcement Learning;Automated Regularization,23;37;37,17;60;60,m;m,asia,kr,y,8;3
6842,ICLR,2021,RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior,Hong-Ye Hu;Dian Wu;Yi-Zhuang You;Bruno Olshausen;Yubei Chen,~Hong-Ye_Hu1;wdphy16@pku.edu.cn;yzyou@physics.ucsd.edu;~Bruno_Olshausen1;~Yubei_Chen1,6;6;5;5,3;4;3;4,Reject,0,5,0.0,yes,9/28/20,"University of California, San Diego;Peking University;;;University of California Berkeley;Facebook AI Research",Unsupervised learning;representation learning;flow-based generative model;renormalization group;sparse encoding,-1;14;-1;-1;-1;-1,33;23;-1;-1;7;-1,m;m,NAN,NAN,n,5
6843,ICLR,2021,Unconditional Synthesis of Complex Scenes Using a Semantic Bottleneck,Samaneh Azadi;Michael Tschannen;Eric Tzeng;Sylvain Gelly;Trevor Darrell;Mario Lucic,~Samaneh_Azadi1;~Michael_Tschannen1;~Eric_Tzeng1;~Sylvain_Gelly1;~Trevor_Darrell2;~Mario_Lucic1,6;8;4;6,4;4;4;5,Reject,0,4,0.0,yes,9/28/20,University of California Berkeley;Apple;University of California Berkeley;Google Brain;Electrical Engineering & Computer Science Department;Google,Unconditional Image Synthesis;Complex Scene;GAN;Semantic Bottleneck,-1;-1;-1;-1;-1;-1,7;-1;7;-1;-1;-1,f;m,NAN,NAN,n,2;5
6844,ICLR,2021,RRL: A Scalable Classifier for Interpretable Rule-Based Representation Learning,Zhuo Wang;Wei Zhang;Ning Liu;Jianyong Wang,~Zhuo_Wang2;~Wei_Zhang27;~Ning_Liu3;~Jianyong_Wang2,5;6;5;7,4;5;4;2,Reject,0,8,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;East China Normal University;Tsinghua University;Tsinghua University, Tsinghua University",interpretable representation learning;rule-based model;scalability,4;-1;4;4,20;387;20;20,m;m,NAN,NAN,n,
6845,ICLR,2021,A Unifying Perspective on Neighbor Embeddings along the Attraction-Repulsion Spectrum,Niklas B√∂hm;Philipp Berens;Dmitry Kobak,~Niklas_B√∂hm1;~Philipp_Berens1;~Dmitry_Kobak2,6;5;5;4,4;3;2;5,Reject,0,11,0.0,yes,9/28/20,University of Tuebingen;University of Tuebingen;University of Tuebingen,visualization;t-SNE;UMAP;dimensionality reduction;nonlinear dimensionality reduction,128;128;128,78;78;78,m;m,europe,de,n,10
6846,ICLR,2021,VilNMN: A Neural Module Network approach to Video-Grounded Language Tasks,Hung Le;Nancy F. Chen;Steven Hoi,~Hung_Le2;~Nancy_F._Chen1;~Steven_Hoi2,5;5;5;4,3;2;5;4,Reject,0,4,0.0,yes,9/28/20,Singapore Management University;;Salesforce Research Asia,neural modular networks;video-grounded dialogues;dialogue understanding;video understanding;video QA;video-grounded language tasks,79;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
6847,ICLR,2021,Selective Sensing: A Data-driven Nonuniform Subsampling Approach for Computation-free On-Sensor Data Dimensionality Reduction,Zhikang Zhang;Kai Xu;Fengbo Ren,~Zhikang_Zhang1;kaixu@asu.edu;~Fengbo_Ren1,4;5;4;4,5;4;5;5,Reject,0,7,0.0,yes,9/28/20,Arizona State University;Arizona State University;Arizona State University,Compressive sensing;nonuniform subsampling;machine learning,85;85;85,182;182;182,m;m,usa,usa,n,1
6848,ICLR,2021,"Self-supervised Contrastive Zero to Few-shot Learning from Small, Long-tailed Text data",Nils Rethmeier;Isabelle Augenstein,~Nils_Rethmeier1;~Isabelle_Augenstein1,4;5;5,5;3;4,Reject,0,5,0.0,yes,9/28/20,University of Copenhagen;University of Copenhagen,self-supervised pretraining;zero-shot;few-shot;text-to-text;contrastive self-supervised learning;small data;long-tail;multi-label classification;NLP,92;92,84;84,m;f,europe,dk,n,6;3
6849,ICLR,2021,Distributed Adversarial Training to Robustify Deep Neural Networks at Scale,Gaoyuan Zhang;Songtao Lu;Sijia Liu;Xiangyi Chen;Pin-Yu Chen;Lee Martie;Lior Horesh;Mingyi Hong,~Gaoyuan_Zhang1;~Songtao_Lu1;~Sijia_Liu1;~Xiangyi_Chen1;~Pin-Yu_Chen1;lee.martie@ibm.com;~Lior_Horesh1;~Mingyi_Hong1,5;4;8;5,4;4;4;4,Reject,0,18,0.0,yes,9/28/20,"International Business Machines;IBM Thomas J. Watson Research Center;Michigan State University;University of Minnesota, Minneapolis;International Business Machines;International Business Machines;Columbia University;Iowa State University",Adversarial robustness;min-max;distributed learning,-1;-1;110;71;-1;-1;23;209,-1;-1;105;85;-1;-1;17;427,m;m,usa,usa,y,1;9;4
6850,ICLR,2021,Constraint-Driven Explanations of Black-Box ML Models,Aditya Aniruddha Shrotri;Nina Narodytska;Alexey Ignatiev;Joao Marques-Silva;Kuldeep S. Meel;Moshe Vardi,~Aditya_Aniruddha_Shrotri1;~Nina_Narodytska1;~Alexey_Ignatiev1;~Joao_Marques-Silva1;~Kuldeep_S._Meel2;~Moshe_Vardi1,5;6;7;6,4;3;3;4,Reject,0,12,0.0,yes,9/28/20,"Rice University;University of New South Wales;Monash University;IRIT, CNRS;National University of Singapore;Rice University",Explainability;constraints;uniform sampling,92;-1;92;-1;17;92,124;-1;64;-1;25;124,m;m,australasia,au,y,4
6851,ICLR,2021,Voting-based Approaches For Differentially Private Federated Learning,Yuqing Zhu;Xiang Yu;Yi-Hsuan Tsai;Francesco Pittaluga;Masoud Faraki;Manmohan Chandraker;Yu-Xiang Wang,~Yuqing_Zhu1;~Xiang_Yu1;~Yi-Hsuan_Tsai1;~Francesco_Pittaluga2;~Masoud_Faraki2;~Manmohan_Chandraker3;~Yu-Xiang_Wang1,5;6;4;6,4;2;4;2,Reject,0,5,0.0,yes,9/28/20,"UC Santa Barbara;NEC;NEC-Labs;NEC-Labs;NEC-Labs;University of California, San Diego;UC Santa Barbara",,-1;-1;-1;-1;-1;-1;-1,-1;440;-1;-1;-1;33;-1,f;m,NAN,NAN,y,4
6852,ICLR,2021,Rethinking Sampling in 3D Point Cloud Generative Adversarial Networks,He Wang;Zetian Jiang;Li Yi;Kaichun Mo;Hao Su;Leonidas Guibas,~He_Wang5;~Zetian_Jiang1;~Li_Yi2;~Kaichun_Mo1;~Hao_Su1;~Leonidas_Guibas1,7;5;6;4;6,5;3;4;4;5,Reject,0,9,0.0,yes,9/28/20,"Peking University;Shanghai Jiao Tong University, Tsinghua University;Stanford University;Stanford University;University of California - San Diego;Stanford University",3D point cloud;GAN;sampling pattern;evaluation metrics;discriminator,14;4;5;5;-1;5,23;20;2;2;33;2,m;m,usa,usa,n,8;5
6853,ICLR,2021,A Framework For Differentiable Discovery Of Graph Algorithms,Hanjun Dai;Xinshi Chen;Yu Li;Xin Gao;Le Song,~Hanjun_Dai1;~Xinshi_Chen1;~Yu_Li1;~Xin_Gao1;~Le_Song1,7;4;6,3;3;3,Reject,0,4,0.0,yes,9/28/20,"Google Research;Georgia Institute of Technology;KAUST;KAUST;College of Computing, Georgia Institute of Technology",graph neural networks;combinatorial optimization;differentiable search;model explanation,-1;12;110;110;12,-1;38;-1;-1;38,m;m,NAN,NAN,n,10
6854,ICLR,2021,Factor Normalization for Deep Neural Network Models,Haobo Qi;Jing Zhou;Hansheng Wang,qihaobo_gsm@pku.edu.cn;~Jing_Zhou3;hansheng@pku.edu.cn,5;4;4;4,4;3;3;3,Reject,0,0,0.0,yes,9/28/20,Peking University;;Renmin University of China;;Peking University,factor normalization;ultrahigh dimensional features;adaptive learning rate;factor decomposition,14;-1;85;-1;14,23;-1;517;-1;23,u;m,asia,cn,y,
6855,ICLR,2021,Better sampling in explanation methods can prevent dieselgate-like deception,Domen Vre≈°;Marko Robnik ≈†ikonja,~Domen_Vre≈°1;marko.robnik@fri.uni-lj.si,4;4;4;7,5;4;3;4,Reject,0,4,0.0,yes,9/28/20,University of Ljubljana;University of Ljubljana,Explaniable AI;explanation methods;robust explanations,-1;-1,808;808,u;m,NAN,NAN,n,7
6856,ICLR,2021,Efficient Long-Range Convolutions for Point Clouds,Yifan Peng;Lin Lin;Lexing Ying;Leonardo Zepeda-Nunez,pyf04142017@sjtu.edu.cn;~Lin_Lin1;~Lexing_Ying1;~Leonardo_Zepeda-Nunez1,6;6;5;5,4;3;4;4,Reject,0,6,0.0,yes,9/28/20,"Shanghai Jiao Tong University;University of California-Berkeley;Stanford University;University of Wisconsin, Madison",global convolution;point cloud;graph-cnn;NUFFT,29;-1;5;18,100;7;2;49,m;m,usa,usa,n,1
6857,ICLR,2021,RankingMatch: Delving into Semi-Supervised Learning with Consistency Regularization and Ranking Loss,Trung Quang Tran;Mingu Kang;Daeyoung Kim,~Trung_Quang_Tran1;~Mingu_Kang1;~Daeyoung_Kim3,3;5;6;4,5;3;4;5,Reject,0,11,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,BatchMean Triplet Loss;Semi-Supervised Learning;Consistency Regularization;Metric Learning,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,8;1
6858,ICLR,2021,Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient Exploration,Seungyul Han;Youngchul Sung,~Seungyul_Han1;~Youngchul_Sung1,6;5;5;5,3;4;4;4,Reject,0,16,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Entropy Regularization;Exploration,-1;-1,96;96,u;m,NAN,NAN,y,1
6859,ICLR,2021,BeBold: Exploration Beyond the Boundary of Explored Regions,Tianjun Zhang;Huazhe Xu;Xiaolong Wang;Yi Wu;Kurt Keutzer;Joseph E. Gonzalez;Yuandong Tian,~Tianjun_Zhang1;~Huazhe_Xu1;~Xiaolong_Wang3;~Yi_Wu1;~Kurt_Keutzer1;~Joseph_E._Gonzalez1;~Yuandong_Tian1,4;8;9;7;5,4;5;4;4;4,Reject,0,13,0.0,yes,9/28/20,"University of California Berkeley;University of California Berkeley;University of California, San Diego;Tsinghua University;;Univ. of California - Berkeley;University of California, Berkeley;University of California - Berkeley;Facebook AI Research",reinforcement learning;exploration,-1;-1;-1;4;-1;10;-1;-1;-1,7;7;33;20;-1;-1;7;7;-1,m;m,NAN,NAN,n,
6860,ICLR,2021,Domain-Free Adversarial Splitting for Domain Generalization,Xiang Gu;Jiasun Feng;Jian Sun;Zongben Xu,~Xiang_Gu1;fjs118@stu.xjtu.edu.cn;~Jian_Sun1;~Zongben_Xu1,5;5;6;5,3;4;2;4,Reject,0,9,0.0,yes,9/28/20,Xi'an Jiaotong University;;;Xi'an Jiaotong University;Xi'an Jiaotong University,domain generalization;adversarial splitting;meta-learning;image recognition,-1;-1;-1;-1;-1,445;-1;-1;445;445,m;m,NAN,NAN,y,6;8;1;4
6861,ICLR,2021,Single-Node Attack for Fooling Graph Neural Networks,Ben Finkelshtein;Chaim Baskin;Evgenii Zheltonozhskii;Uri Alon,benfin@campus.technion.ac.il;~Chaim_Baskin1;~Evgenii_Zheltonozhskii1;~Uri_Alon1,6;6;6;6;5,4;2;5;3;5,Reject,0,11,0.0,yes,9/28/20,"Technion, Technion;Technion, Technion;Technion;Technion",graphs;GNN;adversarial;attack,29;29;29;29,-1;-1;408;408,m;m,europe,il,n,10;4
6862,ICLR,2021,Adversarial Training using Contrastive Divergence,Hongjun Wang;Guanbin Li;Liang Lin,~Hongjun_Wang2;~Guanbin_Li2;~Liang_Lin1,5;5;6,3;4;2,Reject,0,3,0.0,yes,9/28/20,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Adversarial Training;Contrastive Divergence,-1;-1;-1,293;293;293,m;m,NAN,NAN,n,5;4
6863,ICLR,2021,Improving robustness of softmax corss-entropy loss via inference information,Bingbing Song;Wei He;Renyang Liu;Shui Yu;Ruxin Wang;Mingming Gong;Tongliang Liu;Wei Zhou,~Bingbing_Song1;hewei@mail.ynu.edu.cn;liurenyang@mail.ynu.edu.cn;~Shui_Yu1;~Ruxin_Wang1;~Mingming_Gong1;~Tongliang_Liu1;zwei@ynu.edu.cn,5;5;4;4,4;3;4;5,Reject,0,4,0.0,yes,9/28/20,Yunnan University;;;;;;University of Technology Sydney;;The University of Melbourne;University of Sydney;;Yunnan University,Adversarial defense;Loss function;Neural networks robustness,209;-1;-1;-1;-1;-1;71;-1;85;71;-1;209,421;-1;-1;-1;-1;-1;160;-1;31;51;-1;421,u;m,asia,cn,n,1;4
6864,ICLR,2021,Representational correlates of hierarchical phrase structure in deep language models,Matteo Alleman;Jonathan Mamou;Miguel A Del Rio;Hanlin Tang;Yoon Kim;SueYeon Chung,ma3811@columbia.edu;jonathan.mamou@intel.com;drmiguel@alum.mit.edu;~Hanlin_Tang1;~Yoon_Kim1;~SueYeon_Chung1,6;6;5;5;6,3;3;4;5;4,Reject,0,6,0.0,yes,9/28/20,Columbia University;Intel;;;Intel AI Lab;Massachusetts Institute of Technology;Columbia University,bertology;interpretability;computational neuroscience;population coding,23;-1;-1;-1;-1;5;23,17;-1;-1;-1;-1;4;17,m;f,usa,usa,n,8;3
6865,ICLR,2021,Interpretable Sequence Classification Via Prototype Trajectory,Dat Hong;Stephen Baek;Tong Wang,dat-hong@uiowa.edu;~Stephen_Baek1;~Tong_Wang4,5;6;4;7,3;3;5;4,Reject,0,26,0.0,yes,9/28/20,University of Iowa;University of Iowa;University of Iowa,interpretable;RNN;prototypes,174;174;174,245;245;245,m;f,europe,de,n,1
6866,ICLR,2021,On interaction between augmentations and corruptions in natural corruption robustness,Eric Mintun;Alexander Kirillov;Saining Xie,~Eric_Mintun1;~Alexander_Kirillov1;~Saining_Xie2,5;6;7;5,4;4;4;5,Reject,0,4,0.0,yes,9/28/20,Facebook;Facebook AI Research;Facebook,corruption robustness;data augmentation;perceptual similarity;deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2
6867,ICLR,2021,Temporal and Object Quantification Nets,Jiayuan Mao;Zhezheng Luo;Chuang Gan;Joshua B. Tenenbaum;Jiajun Wu;Leslie Pack Kaelbling;Tomer Ullman,~Jiayuan_Mao1;~Zhezheng_Luo1;~Chuang_Gan1;~Joshua_B._Tenenbaum1;~Jiajun_Wu1;~Leslie_Pack_Kaelbling1;~Tomer_Ullman1,3;6;6,4;4;4,Reject,0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;MIT-IBM Watson AI Lab;Massachusetts Institute of Technology;Stanford University;Massachusetts Institute of Technology;;Massachusetts Institute of Technology,Temporal Modeling;Object-Centric Representations,5;5;-1;5;5;5;-1;5,4;4;-1;4;2;4;-1;4,f;m,usa,usa,n,
6868,ICLR,2021,A Simple Sparse Denoising Layer for Robust Deep Learning,Yueming Lyu;Xingrui Yu;Ivor Tsang,~Yueming_Lyu1;~Xingrui_Yu1;~Ivor_Tsang1,5;4;5;5,3;4;3;4,Reject,0,5,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,Sparse Coding;Deep Learning,71;71;71,160;160;160,m;m,australasia,au,y,
6869,ICLR,2021,How to Design Sample and Computationally Efficient VQA Models,Karan Samel;Zelin Zhao;Kuan Wang;Robin Luo;Binghong Chen;Le Song,~Karan_Samel2;~Zelin_Zhao1;~Kuan_Wang1;robin1997@gatech.edu;~Binghong_Chen1;~Le_Song1,5;3;5,5;5;5,Reject,0,5,0.0,yes,9/28/20,"Georgia Institute of Technology;Shanghai Jiao Tong University;Georgia Institute of Technology;;;Georgia Institute of Technology;College of Computing, Georgia Institute of Technology",vqa;visual question answering;neural modules;probabilistic logic,12;29;12;-1;-1;12;12,38;100;38;-1;-1;38;38,m;m,NAN,NAN,n,10
6870,ICLR,2021,Uncertainty for deep image classifiers on out of distribution data. ,Tiago Salvador;Alexander Iannantuono;Adam M Oberman,tiago.saldanhasalvador@mail.mcgill.ca;alexander.iannantuono@mail.mcgill.ca;~Adam_M_Oberman1,5;6;6;4,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,McGill University;University of British Columbia;McGill University,uncertainty;confidence;out of distribution;outlier exposure;classification,99;58;99,40;34;40,m;m,canada,ca,n,
6871,ICLR,2021,Learning Two-Time-Scale Representations For Large Scale Recommendations,Xinshi Chen;Yan Zhu;Haowen Xu;Muhan Zhang;Liang Xiong;Le Song,~Xinshi_Chen1;yzhu@fb.com;~Haowen_Xu1;muhanzhang@fb.com;~Liang_Xiong1;~Le_Song1,6;3;7;6,4;5;4;5,Reject,0,5,0.0,yes,9/28/20,"Georgia Institute of Technology;Facebook;Carnegie Mellon University;Peking University;;College of Computing, Georgia Institute of Technology",Recommendation System;Large-scale Recommendation;User Behavior Modeling;Long-range sequences,12;-1;1;14;-1;12,38;-1;28;23;-1;38,f;m,NAN,NAN,y,
6872,ICLR,2021,Quantitative Understanding of VAE as a Non-linearly Scaled Isometric Embedding,Akira Nakagawa;Keizo Kato,~Akira_Nakagawa1;~Keizo_Kato1,4;4;5;5,3;4;2;1,Reject,0,5,0.0,yes,9/28/20,Fujitsu Laboratories Ltd.;FUJITSU LABORATORIES LTD.,unsupervised representation learning;deep image compression,-1;-1,-1;-1,m;m,NAN,NAN,n,1;5
6873,ICLR,2021,Multi-EPL: Accurate Multi-source Domain Adaptation,Seongmin Lee;Hyunsik Jeon;U Kang,~Seongmin_Lee2;jeon185@gmail.com;~U_Kang1,4;5;4;4,5;3;4;5,Reject,0,4,0.0,yes,9/28/20,Seoul National University;;;Seoul National University,Multi-Source Domain Adaptation;Label-wise Moment Matching;Pseudolabel;Ensemble of Feature Representation,37;-1;-1;37,60;-1;-1;60,f;m,asia,kr,y,
6874,ICLR,2021,Bayesian Learning to Optimize: Quantifying the Optimizer Uncertainty,Yue Cao;Tianlong Chen;Zhangyang Wang;Yang Shen,~Yue_Cao4;~Tianlong_Chen1;~Zhangyang_Wang1;~Yang_Shen4,4;5;6,4;2;3,Reject,0,4,0.0,yes,9/28/20,"Texas A&M;University of Texas, Austin;University of Texas, Austin;Texas A&M",Optimizer Uncertainty;Optimization;Uncertainty Quantification,46;-1;-1;46,195;-1;-1;195,m;m,NAN,NAN,n,11;4
6875,ICLR,2021,Driving through the Lens: Improving Generalization of Learning-based Steering using Simulated Adversarial Examples,Yu Shen;Laura Yu Zheng;Manli Shu;Weizi Li;Tom Goldstein;Ming Lin,~Yu_Shen1;~Laura_Yu_Zheng1;~Manli_Shu1;~Weizi_Li1;~Tom_Goldstein1;~Ming_Lin2,4;6;4;4,3;5;4;5,Reject,0,8,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Memphis;University of Maryland, College Park;University of Maryland, College Park",model robustness;data augmentation;adversarial training;image quality;autonomous driving;benchmark,12;12;12;327;12;12,90;90;90;827;90;90,m;f,usa,usa,n,1;4
6876,ICLR,2021,Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win,Utku Evci;Yani Ioannou;Cem Keskin;Yann Dauphin,~Utku_Evci1;~Yani_Ioannou1;~Cem_Keskin2;~Yann_Dauphin1,5;5;6;7,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Google;Google;Facebook;Google,sparse training;sparsity;pruning;lottery ticket hypothesis;lottery tickets;sparse initialization;initialization;deep learning;gradient flow,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
6877,ICLR,2021,CorrAttack: Black-box Adversarial Attack with Structured Search,Zhichao Huang;Yaowei Huang;Tong Zhang,~Zhichao_Huang1;~Yaowei_Huang2;~Tong_Zhang2,6;6;6;6,4;5;2;3,Reject,0,6,0.0,yes,9/28/20,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Google,adversarial examples;black-box attack;bandits,-1;-1;-1,56;56;-1,m;m,NAN,NAN,n,11;4
6878,ICLR,2021,Additive Poisson Process: Learning Intensity of Higher-Order Interaction in Stochastic Processes,Simon Luo;Feng Zhou;Lamiae Azizi;Mahito Sugiyama,~Simon_Luo1;~Feng_Zhou9;lamiae.azizi@sydney.edu.au;~Mahito_Sugiyama1,4;6;3,4;3;4,Reject,0,4,0.0,yes,9/28/20,University of Sydney;Tsinghua University;University of Sydney;National Institute of Informatics,Poisson Process;Log-Linear Model;Energy-Based Model;Generalized Additive Models;Information Geometry,71;4;71;-1,51;20;51;-1,m;m,NAN,NAN,n,9
6879,ICLR,2021,Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition,Randy Ardywibowo;Shahin Boluki;Zhangyang Wang;Bobak J Mortazavi;Shuai Huang;Xiaoning Qian,~Randy_Ardywibowo1;~Shahin_Boluki1;~Zhangyang_Wang1;~Bobak_J_Mortazavi1;~Shuai_Huang1;~Xiaoning_Qian2,4;3;4;9,3;5;4;5,Reject,0,12,0.0,yes,9/28/20,"Texas A&M;Texas A&M University;University of Texas, Austin;Texas A&M Engineering Experiment Station;;University of Washington;Texas A&M",dynamic feature selection;human activity recognition;sparse monitoring,46;46;-1;-1;-1;11;46,195;195;-1;-1;-1;29;195,m;m,NAN,NAN,n,
6880,ICLR,2021,ARMCMC: Online Model Parameters full probability Estimation in Bayesian Paradigm,Pedram Agand;Mo Chen;Hamid D. Taghirad,~Pedram_Agand1;~Mo_Chen1;taghirad@kntu.ac.ir,6;5;7,4;4;4,Reject,0,3,0.0,yes,9/28/20,Simon Fraser University;Simon Fraser University;;Khajeh Nasir Toosi University of Technology,Bayesian estimation;Full probability distribution;MCMC;Hybrid non-Gaussian system,58;58;-1;-1,271;271;-1;-1,m;m,NAN,NAN,n,11;1
6881,ICLR,2021,Autoencoder Image Interpolation by Shaping the Latent Space,Alon Oring;Zohar Yakhini;Yacov Hel-Or,~Alon_Oring1;zohar.yakhini@gmail.com;~Yacov_Hel-Or1,7;6;6;5,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,Interdisciplinary Center Herzliya;;;IDC,deep learning;autoencoders;deep generative models;representation learning,-1;-1;-1;453,-1;-1;-1;771,m;m,asia,in,n,
6882,ICLR,2021,Intriguing class-wise properties of adversarial training,Qi Tian;Kun Kuang;Fei Wu;Yisen Wang,~Qi_Tian6;~Kun_Kuang1;~Fei_Wu1;~Yisen_Wang1,4;4;4;6,4;4;5;5,Reject,0,6,0.0,yes,9/28/20,"Zhejiang University;Zhejiang University, Tsinghua University;;Zhejiang University;Peking University",adversarial training;class-wise properties;robustness;adversarial example,42;4;-1;42;14,94;20;-1;94;23,m;m,asia,cn,n,4
6883,ICLR,2021,NCP-VAE: Variational Autoencoders with Noise Contrastive Priors,Jyoti Aneja;Alex Schwing;Jan Kautz;Arash Vahdat,~Jyoti_Aneja2;~Alex_Schwing1;~Jan_Kautz1;~Arash_Vahdat3,6;5;8;5,4;3;5;4,Reject,0,11,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;NVIDIA;NVIDIA",Variational Autoencoders;Noise Contrastive Estimation;Sampling,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n,5
6884,ICLR,2021,Distribution Embedding Network for Meta-Learning with Variable-Length Input,Lang Liu;Mahdi Milani Fard;Sen Zhao,~Lang_Liu1;~Mahdi_Milani_Fard1;~Sen_Zhao1,5;4;4;4,2;3;4;3,Reject,0,1,0.0,yes,9/28/20,"University of Washington, Seattle;Google;Google",meta-learning;variable-length input;distribution embedding,11;-1;-1,29;-1;-1,m;m,NAN,NAN,y,6
6885,ICLR,2021,There is no trade-off: enforcing fairness can improve accuracy,Subha Maity;Debarghya Mukherjee;Mikhail Yurochkin;Yuekai Sun,~Subha_Maity1;mdeb@umich.edu;~Mikhail_Yurochkin1;~Yuekai_Sun1,6;4;6,4;3;4,Reject,0,5,0.0,yes,9/28/20,"University of Michigan, Ann Arbor;University of Michigan;International Business Machines;University of Michigan",,7;7;-1;7,22;22;-1;22,m;m,usa,usa,y,7
6886,ICLR,2021,Improving Abstractive Dialogue Summarization with Conversational Structure and Factual Knowledge,Lulu Zhao;Zeyuan Yang;Weiran Xu;Sheng Gao;Jun Guo,~Lulu_Zhao1;buptyzy@bupt.edu.cn;xuweiran@bupt.edu.cn;~Sheng_Gao1;~Jun_Guo1,5;6;6;6,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,"Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication, Tsinghua University;;;;Beijing University of Posts and Telecommunications;;Beijing University of Posts and Telecommunications",abstractive dialogue summarization;long-distance cross-sentence relation;conversational structure;factual knowledge;sparse relational graph self-attention network;dual-copy mechanism,-1;4;-1;-1;-1;-1;-1;-1,-1;20;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;10
6887,ICLR,2021,Non-Markovian Predictive Coding For Planning In Latent Space,Tung Nguyen;Rui Shu;Tuan Pham;Hung Bui;Stefano Ermon,~Tung_Nguyen2;~Rui_Shu1;v.tuanpa36@vinai.io;~Hung_Bui1;~Stefano_Ermon1,5;6;5;6,5;4;5;3,Reject,0,8,0.0,yes,9/28/20,"VinAI Research, Vietnam;Stanford University;Hanoi University of Science and Technology;Google DeepMind;Stanford University",representation learning;reinforcement learning;information theory,-1;5;-1;-1;5,-1;2;1158;-1;2,m;m,usa,usa,y,
6888,ICLR,2021,Recovering Geometric Information with Learned Texture Perturbations,Jane Wu;Yongxu Jin;Zhenglin Geng;Hui Zhou;Ronald Fedkiw,~Jane_Wu2;yxjin@stanford.edu;zhenglin@stanford.edu;hui.zhou@jd.com;~Ronald_Fedkiw1,5;4;3;4,4;3;2;4,Reject,0,5,0.0,yes,9/28/20,Stanford University;Stanford University;;;;;Stanford University,,5;5;-1;-1;-1;-1;5,2;2;-1;-1;-1;-1;2,f;m,usa,usa,n,
6889,ICLR,2021,Practical Marginalized Importance Sampling with the Successor Representation,Scott Fujimoto;David Meger;Doina Precup,~Scott_Fujimoto1;~David_Meger2;~Doina_Precup1,6;6;6;5,3;5;4;4,Reject,0,9,0.0,yes,9/28/20,McGill University;McGill University;DeepMind,marginalized importance sampling;off-policy evaluation;deep reinforcement learning;successor representation,99;99;-1,40;40;-1,m;f,NAN,NAN,y,
6890,ICLR,2021,Visual Explanation using Attention Mechanism in Actor-Critic-based Deep Reinforcement Learning,Hidenori Itaya;Tsubasa Hirakawa;Takayoshi Yamashita;Hironobu Fujiyoshi;Komei Sugiura,~Hidenori_Itaya1;~Tsubasa_Hirakawa1;~Takayoshi_Yamashita1;~Hironobu_Fujiyoshi2;~Komei_Sugiura1,4;5;5;4,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Chubu University;Chubu University;chubu university;Chubu University;Keio University,,-1;-1;-1;-1;263,1401;1401;962;1401;730,u;m,asia,jp,n,8
6891,ICLR,2021,Causal Inference Q-Network: Toward Resilient Reinforcement Learning,Chao-Han Huck Yang;Danny I-Te Hung;Yi Ouyang;Pin-Yu Chen,~Chao-Han_Huck_Yang1;ih2320@columbia.edu;~Yi_Ouyang1;~Pin-Yu_Chen1,4;7;4;7,3;4;4;3,Reject,0,16,0.0,yes,9/28/20,"Georgia Institute of Technology;Columbia University;Preferred Networks, Inc.;International Business Machines",Deep Reinforcement Learning;Causal Inference;Robust Reinforcement Learning;Adversarial Robustness,12;23;-1;-1,38;17;-1;-1,m;m,NAN,NAN,y,4
6892,ICLR,2021,Explore with Dynamic Map: Graph Structured Reinforcement Learning,Jiarui Jin;Sijin Zhou;Weinan Zhang;Rasool Fakoor;David Wipf;Tong He;Yong Yu;Zheng Zhang;Alex Smola,~Jiarui_Jin1;zhousijin@sjtu.edu.cn;~Weinan_Zhang1;~Rasool_Fakoor1;~David_Wipf1;~Tong_He5;~Yong_Yu1;~Zheng_Zhang1;~Alex_Smola1,6;4;5;6,4;4;3;3,Reject,0,7,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Amazon;Amazon AI Research Lab;Amazon;;New York University;Carnegie-Mellon University,Deep Reinforcement Learning;Graph Structured Reinforcement Learning;Exploration,29;29;29;-1;-1;-1;-1;23;1,100;100;100;-1;-1;-1;-1;26;28,u;m,usa,usa,y,8;10
6893,ICLR,2021,An empirical study of a pruning mechanism,Minju Jung;Hyounguk Shon;Eojindl Yi;SungHyun Baek;Junmo Kim,~Minju_Jung2;~Hyounguk_Shon2;~Eojindl_Yi1;~SungHyun_Baek1;~Junmo_Kim1,4;4;4;4,4;2;4;4,Reject,0,7,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;-1;-1;-1;-1,96;96;96;96;96,m;m,NAN,NAN,n,
6894,ICLR,2021,Meta-Learning with Implicit Processes,YIZHOU CHEN;DONG LI;NA LI;TONG LIANG;SHIZHUO ZHANG;Bryan Kian Hsiang Low,~YIZHOU_CHEN1;shiping@alibaba-inc.com;yuefan.ln@alibaba-inc.com;liangtong.lt@alibaba-inc.com;m180175@e.ntu.edu.sg;~Bryan_Kian_Hsiang_Low1,5;6;6,3;4;4,Reject,0,3,0.0,yes,9/28/20,National University of Singapore;;;;;;;;;National University of Singapore,,17;-1;-1;-1;-1;-1;-1;-1;-1;17,25;-1;-1;-1;-1;-1;-1;-1;-1;25,u;m,asia,sg,n,6;11
6895,ICLR,2021,Robust Learning Rate Selection for Stochastic Optimization via Splitting Diagnostic,Matteo Sordello;Hangfeng He;Weijie J Su,~Matteo_Sordello1;~Hangfeng_He3;~Weijie_J_Su1,3;5;7;7,4;4;3;3,Reject,0,7,0.0,yes,9/28/20,"University of Pennsylvania;University of Pennsylvania;The Wharton School, University of Pennsylvania",Optimization;Deep Learning;Stationarity;Adaptive,20;20;20,13;13;13,m;m,NAN,NAN,y,1
6896,ICLR,2021,Adversarial Environment Generation for Learning  to Navigate the Web,Izzeddin Gur;Natasha Jaques;Kevin Malta;Manoj Tiwari;Honglak Lee;Aleksandra Faust,~Izzeddin_Gur1;~Natasha_Jaques1;kmalta@google.com;mjtiwari@google.com;~Honglak_Lee2;~Aleksandra_Faust1,7;4;5;6,3;3;3;1,Reject,0,6,0.0,yes,9/28/20,Google;Google;;;;;LG AI Research;Google Brain,Web Navigation;Adversarial Environment Generation;Web Environment Design;Minimax Regret Adversary;Auto Curriculum,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,4
6897,ICLR,2021,Skinning a Parameterization of Three-Dimensional Space for Neural Network Cloth,Jane Wu;Zhenglin Geng;Hui Zhou;Ronald Fedkiw,~Jane_Wu2;zhenglin@stanford.edu;hui.zhou@jd.com;~Ronald_Fedkiw1,6;4;4;3,1;4;3;4,Reject,0,7,0.0,yes,9/28/20,Stanford University;;;;;Stanford University,,5;-1;-1;-1;-1;5,2;-1;-1;-1;-1;2,f;m,usa,usa,n,
6898,ICLR,2021,CTRLsum: Towards Generic Controllable Text Summarization,Junxian He;Wojciech Maciej Kryscinski;Bryan McCann;Nazneen Rajani;Caiming Xiong,~Junxian_He1;~Wojciech_Maciej_Kryscinski1;~Bryan_McCann1;~Nazneen_Rajani1;~Caiming_Xiong1,6;7;7;5,4;3;4;5,Reject,0,7,0.0,yes,9/28/20,"Carnegie Mellon University;KTH Royal Institute of Technology, Stockholm, Sweden;SalesForce.com;University of Texas, Austin;Salesforce Research",controllable text summarization,1;174;-1;-1;-1,28;239;-1;-1;-1,m;m,NAN,NAN,n,
6899,ICLR,2021,Formal Language Constrained Markov Decision Processes,Eleanor Quint;Dong Xu;Samuel W Flint;Stephen D Scott;Matthew Dwyer,~Eleanor_Quint1;~Dong_Xu1;~Samuel_W_Flint1;~Stephen_D_Scott1;~Matthew_Dwyer1,5;6;6;6,5;5;3;3,Reject,0,9,0.0,yes,9/28/20,"University of Nebraska, Lincoln;University of Virginia;University of Nebraska, Lincoln;Washington University, St. Louis;University of Nebraska-Lincoln",safe reinforcement learning;formal languages;constrained Markov decision process;safety gym;safety,209;53;209;-1;209,488;117;488;-1;488,f;m,NAN,NAN,n,
6900,ICLR,2021,Single Layers of Attention Suffice to Predict Protein Contacts,Nick Bhattacharya;Neil Thomas;Roshan Rao;Justas Daupras;Peter K Koo;David Baker;Yun S. Song;Sergey Ovchinnikov,~Nick_Bhattacharya1;nthomas@berkeley.edu;rmrao@berkeley.edu;justas@uw.edu;~Peter_K_Koo1;~David_Baker1;~Yun_S._Song1;so@g.harvard.edu,5;7;5;6,4;3;5;4,Reject,0,8,0.0,yes,9/28/20,"University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Washington, Seattle;Cold Spring Harbor Laboratory;University of Washington;University of California Berkeley;Harvard University",Protein Structure;Proteins;Contact Prediction;Representation Learning;Language Modeling;Attention;Transformer;BERT;Markov Random Fields;Potts Models;Self-supervised learning,-1;-1;-1;11;-1;11;-1;53,7;7;7;29;-1;29;7;3,m;m,usa,usa,n,8;10
6901,ICLR,2021,Near-Optimal Linear Regression under Distribution Shift,Qi Lei;Wei Hu;Jason D. Lee,~Qi_Lei1;~Wei_Hu1;~Jason_D._Lee1,6;6;6,3;2;4,Reject,0,4,0.0,yes,9/28/20,Princeton University;Princeton University;Princeton University,minimax estimator;covariate shift;model shift,29;29;29,9;9;9,f;m,usa,usa,y,6
6902,ICLR,2021,Guarantees for Tuning the Step Size using a Learning-to-Learn Approach,Xiang Wang;Shuai Yuan;Chenwei Wu;Rong Ge,~Xiang_Wang1;shuai@cs.duke.edu;~Chenwei_Wu1;~Rong_Ge1,8;4;4;4,3;3;5;4,Reject,0,5,0.0,yes,9/28/20,"Duke University;Department of Computer Science, Duke University;Duke University;Duke University",meta-learning;learning-to-learn;step size tuning;optimization;generalization,46;46;46;46,20;20;20;20,m;m,europe,se,y,1
6903,ICLR,2021,Composite Adversarial Training for Multiple Adversarial Perturbations and Beyond,Xinyang Zhang;Zheng Zhang;Ting Wang,~Xinyang_Zhang5;zxz147@psu.edu;~Ting_Wang1,5;6;5;5,3;3;3;4,Reject,0,4,0.0,yes,9/28/20,Pennsylvania State University;Pennsylvania State University;Lehigh University,adversarial examples;deep learning;robustness,44;44;263,-1;-1;613,m;m,usa,usa,y,4
6904,ICLR,2021,Supervision Accelerates Pre-training in Contrastive Semi-Supervised Learning of Visual Representations,Mido Assran;Nicolas Ballas;Lluis Castrejon;Michael Rabbat,~Mido_Assran1;~Nicolas_Ballas1;~Lluis_Castrejon1;~Michael_Rabbat1,4;4;6;4,5;5;3;3,Reject,0,7,0.0,yes,9/28/20,McGill University;Facebook;Facebook;McGill University,semi-supervised learning;contrastive learning;self-supervised learning;deep learning;representation learning;metric learning;visual representations,99;-1;-1;99,40;-1;-1;40,m;m,canada,ca,n,
6905,ICLR,2021,FAST GRAPH ATTENTION NETWORKS USING EFFECTIVE RESISTANCE BASED GRAPH SPARSIFICATION,Rakshith Sharma Srinivasa;Cao Xiao;Lucas Glass;Justin Romberg;Jimeng Sun,~Rakshith_Sharma_Srinivasa1;~Cao_Xiao2;lucas.glass@iqvia.com;~Justin_Romberg1;jimeng.sun@gmail.com,5;6;4;6,4;3;5;3,Reject,0,11,0.0,yes,9/28/20,"IQVIA;Amplitude;IQVIA;Georgia Institute of Technology;University of Illinois, Urbana Champaign",Graph neural networks;Graph attention networks;graph sparsification;spectral sparsification,-1;-1;-1;12;-1,-1;-1;-1;38;-1,m;m,usa,usa,y,8;1;10
6906,ICLR,2021,"STRATA: Simple, Gradient-free Attacks for Models of Code",Jacob M. Springer;Bryn Marie Reinstadler;Una-May O'Reilly,~Jacob_M._Springer1;~Bryn_Marie_Reinstadler1;~Una-May_O'Reilly1,4;4;5;4,4;4;3;5,Reject,0,7,0.0,yes,9/28/20,Los Alamos National Laboratory;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deep Learning;Models of Code;Black-box Adversarial Attacks;Adversarial Robustness,-1;5;5,-1;4;4,m;f,usa,usa,n,3;4
6907,ICLR,2021,CIGMO: Learning categorical invariant deep generative models from grouped data,Haruo Hosoya,~Haruo_Hosoya1,4;5;7;4,4;4;3;3,Reject,0,5,0.0,yes,9/28/20,ATR,variational autoencoders;disentangling;mixture;clustering,263,1019,m,europe,gr,n,5
6908,ICLR,2021,Memory-Efficient Semi-Supervised Continual Learning: The World is its Own Replay Buffer,James Smith;Jonathan C Balloch;Yen-Chang Hsu;Zsolt Kira,~James_Smith1;~Jonathan_C_Balloch1;~Yen-Chang_Hsu1;~Zsolt_Kira1,4;6;5;7,5;5;3;4,Reject,0,12,0.0,yes,9/28/20,"Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;Samsung Research America;Georgia Institute of Technology",continual learning;semi-supervised learning,12;12;-1;12,38;38;-1;38,m;m,usa,usa,n,
6909,ICLR,2021,Information Theoretic Regularization for Learning Global Features by Sequential VAE,Kei Akuzawa;Yusuke Iwasawa;Yutaka Matsuo,~Kei_Akuzawa1;~Yusuke_Iwasawa1;~Yutaka_Matsuo1,6;6;7,4;3;4,Reject,0,13,0.0,yes,9/28/20,The University of Tokyo;The University of Tokyo;The University of Tokyo,variational autoencoder;VAE;disentanglement;global features;sequential models;representation learning;mutual information,71;71;71,36;36;36,m;m,NAN,NAN,n,5;4
6910,ICLR,2021,Generating Plannable Lifted Action Models for Visually Generated Logical Predicates,Masataro Asai,~Masataro_Asai1,6;5;6,3;1;4,Reject,0,0,0.0,yes,9/28/20,IBM Research / MIT-IBM Watson AI Lab,Object-Centric Representation;Planning;Discrete VAE,-1,-1,m,NAN,NAN,n,
6911,ICLR,2021,"BayesAdapter: Being Bayesian, Inexpensively and Robustly, via Bayesian Fine-tuning",Zhijie Deng;Xiao Yang;Hao Zhang;Yinpeng Dong;Jun Zhu,~Zhijie_Deng1;~Xiao_Yang4;~Hao_Zhang2;~Yinpeng_Dong2;~Jun_Zhu2,6;6;5;6,3;4;4;4,Reject,0,17,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Petuum, Inc;Tsinghua University;Tsinghua University",Bayesian neural networks;Bayesian fine-tuning;uncertainty estimation;OOD detection,4;4;-1;4;4,20;20;-1;20;20,m;m,asia,cn,n,11
6912,ICLR,2021,Gradient Descent Ascent for Min-Max Problems on Riemannian Manifolds,Feihu Huang;Shangqian Gao;Heng Huang,~Feihu_Huang1;~Shangqian_Gao1;~Heng_Huang1,5;7;4;4,4;4;4;3,Reject,0,4,0.0,yes,9/28/20,University of Pittsburgh;University of Pittsburgh;University of Pittsburgh,Min-Max Optimization;Riemannian Manifold;Robust Training,79;79;79,133;133;133,m;m,usa,usa,y,1;9
6913,ICLR,2021,An Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Process,David Tran;Alexander V Valtchanov;Keshav R Ganapathy;Raymond Feng;Eric Victor Slud;Micah Goldblum;Tom Goldstein,~David_Tran1;~Alexander_V_Valtchanov2;~Keshav_R_Ganapathy1;~Raymond_Feng1;slud@umd.edu;~Micah_Goldblum1;~Tom_Goldstein1,6;3;6;5,3;3;3;3,Reject,0,5,0.0,yes,9/28/20,"University of California Berkeley;Princeton University;University of Maryland, College Park;Harvard University;;;University of Maryland, College Park;University of Maryland, College Park",Conference Review;OpenReview;Gender;Bias;Reproducibility;Fairness,-1;29;12;53;-1;-1;12;12,7;9;90;3;-1;-1;90;90,m;m,usa,usa,n,7
6914,ICLR,2021,Bidirectionally Self-Normalizing Neural Networks,Yao Lu;Stephen Gould;Thalaiyasingam Ajanthan,yao.lu@anu.edu.au;~Stephen_Gould1;~Thalaiyasingam_Ajanthan1,6;4;6;4,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,Australian National University;Australian National University;Australian National University,,99;99;99,59;59;59,m;m,australasia,au,y,1
6915,ICLR,2021,Symmetric Wasserstein Autoencoders,Sun Sun;Hongyu Guo,~Sun_Sun1;~Hongyu_Guo1,5;5;5;6,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,National Research Council Canada;National Research Council Canada,generative models;variational autoencoders,-1;-1,-1;-1,u;m,NAN,NAN,y,5
6916,ICLR,2021,A Provably Convergent and Practical Algorithm for Min-Max Optimization with Applications to GANs,Oren Mangoubi;Sushant Sachdeva;Nisheeth K Vishnoi,~Oren_Mangoubi1;~Sushant_Sachdeva1;~Nisheeth_K_Vishnoi1,4;6;6,4;3;2,Reject,0,10,0.0,yes,9/28/20,Worcester Polytechnic Institute;University of Toronto;Google,min-max optimization;GANs,150;18;-1,651;18;-1,m;m,NAN,NAN,y,5
6917,ICLR,2021,Network-Agnostic Knowledge Transfer for Medical Image Segmentation,Shuhang Wang;Eugene Cheah;Elham Yousef Kalafi;Mercy Asiedu;Alex Benjamin;Vivek Kumar Singh;Ge Zhang;Viksit Kumar;Anthony Edward Samir,~Shuhang_Wang1;echeah1@mgh.harvard.edu;ekalafi@mgh.harvard.edu;masiedu1@mgh.harvard.edu;abenjamin2@mgh.harvard.edu;vsingh11@mgh.harvard.edu;gzhang11@mgh.harvard.edu;vkumar14@mgh.harvard.edu;~Anthony_Edward_Samir1,3;4;7,4;3;4,Reject,0,7,0.0,yes,9/28/20,"Massachusetts General Hospital, Harvard University;;;Massachusetts General Hospital, Harvard University;Massachusetts Institute of Technology;;;;;;;;;Massachusetts General Hospital, Harvard University",Knowledge Transfer;Deep Learning;Medical Image Segmentation;Pseudo Annotation,53;-1;-1;53;5;-1;-1;-1;-1;-1;-1;-1;-1;53,3;-1;-1;3;4;-1;-1;-1;-1;-1;-1;-1;-1;3,m;m,NAN,NAN,n,6;2;5
6918,ICLR,2021,GraphLog: A Benchmark for Measuring Logical Generalization in Graph Neural Networks,Koustuv Sinha;Shagun Sodhani;Joelle Pineau;William L. Hamilton,~Koustuv_Sinha1;~Shagun_Sodhani1;~Joelle_Pineau1;~William_L._Hamilton1,5;5;4;6,4;4;4;3,Reject,0,11,0.0,yes,9/28/20,McGill University;Facebook;Facebook;McGill University,graph neural networks;dataset;benchmark;logic,99;-1;-1;99,40;-1;-1;40,m;m,canada,ca,n,1;10
6919,ICLR,2021,Simple and Effective VAE Training with Calibrated Decoders,Oleh Rybkin;Kostas Daniilidis;Sergey Levine,~Oleh_Rybkin1;~Kostas_Daniilidis1;~Sergey_Levine1,5;6;6,4;4;5,Reject,0,9,0.0,yes,9/28/20,University of Pennsylvania;University of Pennsylvania;University of Washington,variational autoencoders;Œ≤-VAE;representation learning,20;20;11,13;13;29,m;m,usa,usa,n,5
6920,ICLR,2021,Combining Imitation and Reinforcement Learning with Free Energy Principle,Ryoya Ogishima;Izumi Karino;Yasuo Kuniyoshi,~Ryoya_Ogishima1;karino@isi.imi.i.u-tokyo.ac.jp;~Yasuo_Kuniyoshi1,5;4;6;5,2;4;5;2,Reject,0,6,0.0,yes,9/28/20,The University of Tokyo;;;;University of Tokyo,Imitation;Reinforcement Learning;Free Energy Principle,71;-1;-1;-1;71,36;-1;-1;-1;36,m;m,asia,jp,n,11;1
6921,ICLR,2021,D4RL: Datasets for Deep Data-Driven Reinforcement Learning,Justin Fu;Aviral Kumar;Ofir Nachum;George Tucker;Sergey Levine,~Justin_Fu1;~Aviral_Kumar2;~Ofir_Nachum1;~George_Tucker1;~Sergey_Levine1,6;6;2;6,4;5;5;5,Reject,0,26,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;Google;Google Brain;University of Washington,reinforcement learning;deep learning;benchmarks,-1;-1;-1;-1;11,7;7;-1;-1;29,m;m,usa,usa,n,
6922,ICLR,2021,Safety Verification of Model Based Reinforcement Learning Controllers,akshita gupta;Inseok Hwang,~akshita_gupta1;~Inseok_Hwang1,7;3;7;5,4;4;2;3,Reject,0,14,0.0,yes,9/28/20,Purdue University;Purdue University,Reachable set;state constraints;safety verification;model-based reinforcement learning,23;23,94;94,f;m,usa,usa,y,
6923,ICLR,2021,Beyond GNNs: A Sample Efficient Architecture for Graph Problems,Pranjal Awasthi;Abhimanyu Das;Sreenivas Gollapudi,~Pranjal_Awasthi3;abhidas@google.com;~Sreenivas_Gollapudi2,4;5;8;5,3;3;3;3,Reject,0,0,0.0,yes,9/28/20,Google;University of Southern California;Google,Graph Neural Networks;Deep Learning Theory;Graph Connectivity;Minimum Spanning Trees,-1;37;-1,-1;53;-1,m;m,NAN,NAN,y,1;10
6924,ICLR,2021,Group-Connected Multilayer Perceptron Networks,Mohammad Kachuee;Sajad Darabi;Shayan Fazeli;Majid Sarrafzadeh,~Mohammad_Kachuee1;~Sajad_Darabi1;shayan@cs.ucla.edu;~Majid_Sarrafzadeh1,6;7;5,4;5;5,Reject,0,12,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California-Los Angeles",,-1;-1;-1;-1,15;15;15;15,m;m,usa,usa,n,10;7
6925,ICLR,2021,Stability analysis of SGD through the normalized loss function,Alexandre Lemire Paquin;Brahim Chaib-draa;Philippe Gigu√®re,~Alexandre_Lemire_Paquin1;~Brahim_Chaib-draa1;~Philippe_Gigu√®re1,6;4;6,3;4;4,Reject,0,4,0.0,yes,9/28/20,Laval university;Universite Laval  Laval university;Laval university,stability;neural networks;generalization bounds;normalized loss,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
6926,ICLR,2021,Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks,Kevin M. Potter;Steven Richard Sleder;Matthew David Smith;John Tencer,~Kevin_M._Potter1;ssleder@sandia.gov;mdsmith@sandia.gov;jtencer@sandia.gov,4;5;5,3;4;3,Reject,0,0,0.0,yes,9/28/20,Georgia Institute of Technology;Sandia National Laboratories;Sandia National Laboratories;;Sandia National Laboratories,graph convolutional neural network;superpixel;FAUST;differential operators,12;-1;-1;-1;-1,38;-1;-1;-1;-1,m;m,NAN,NAN,n,10
6927,ICLR,2021,Efficient Exploration for Model-based Reinforcement Learning with Continuous States and Actions,Ying Fan;Yifei Ming,~Ying_Fan2;~Yifei_Ming1,6;5;5;5,4;4;4;4,Reject,0,10,0.0,yes,9/28/20,"Department of Computer Science, University of Wisconsin, Madison;University of Wisconsin, Madison",Model-based reinforcement learning;posterior sampling;Bayesian reinforcement learning,-1;18,-1;49,f;u,usa,usa,y,11;1
6928,ICLR,2021,DiP Benchmark Tests: Evaluation Benchmarks for Discourse Phenomena in MT,Prathyusha Jwalapuram;Barbara Rychalska;Shafiq Joty;Dominika Basaj,~Prathyusha_Jwalapuram1;~Barbara_Rychalska1;~Shafiq_Joty1;~Dominika_Basaj1,4;4;7;6,4;4;3;4,Reject,0,13,0.0,yes,9/28/20,Nanyang Technological University;Warsaw University of Technology;SalesForce.com;Warsaw School of Technology,machine translation;discourse;evaluation;benchmark;testsets;leaderboard,44;-1;-1;-1,47;1194;-1;-1,f;f,NAN,NAN,n,3
6929,ICLR,2021,Forward Prediction for Physical Reasoning,Rohit Girdhar;Laura Gustafson;Aaron B. Adcock;Laurens van der Maaten,~Rohit_Girdhar5;~Laura_Gustafson1;~Aaron_B._Adcock1;~Laurens_van_der_Maaten3,5;5;5;5;6,4;3;4;3;5,Reject,0,6,0.0,yes,9/28/20,Facebook;Facebook;;Stanford University;Facebook,Forward prediction;physical reasoning,-1;-1;-1;5;-1,-1;-1;-1;2;-1,m;m,NAN,NAN,n,1
6930,ICLR,2021,Uncertainty Weighted Offline Reinforcement Learning,Yue Wu;Shuangfei Zhai;Nitish Srivastava;Joshua M. Susskind;Jian Zhang;Ruslan Salakhutdinov;Hanlin Goh,~Yue_Wu17;~Shuangfei_Zhai3;~Nitish_Srivastava1;~Joshua_M._Susskind1;~Jian_Zhang23;~Ruslan_Salakhutdinov1;~Hanlin_Goh2,4;7;8;5;6,4;4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Carnegie Mellon University;Apple;Apple Inc;Apple;Apple;Carnegie-Mellon University;Apple,reinforcement learning;offline;batch reinforcement learning;off-policy;uncertainty estimation;dropout;actor-critic;bootstrap error,1;-1;-1;-1;-1;1;-1,28;-1;-1;-1;-1;28;-1,m;m,NAN,NAN,y,
6931,ICLR,2021,Defining Benchmarks for Continual Few-Shot Learning,Antreas Antoniou;Massimiliano Patacchiola;Mateusz Ochal;Amos Storkey,~Antreas_Antoniou2;~Massimiliano_Patacchiola1;~Mateusz_Ochal1;~Amos_Storkey1,5;6;6;4,4;4;4;3,Reject,0,6,0.0,yes,9/28/20,University of Edinburgh;University of Cambridge;Heriot-Watt University;University of Edinburgh,few-shot learning;continual learning;benchmark,29;79;209;29,30;6;375;30,m;m,europe,uk,n,6
6932,ICLR,2021,not-so-big-GAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolution,Seungwook Han;Akash Srivastava;Cole Lincoln Hurwitz;Prasanna Sattigeri;David Daniel Cox,~Seungwook_Han1;~Akash_Srivastava1;~Cole_Lincoln_Hurwitz1;~Prasanna_Sattigeri1;~David_Daniel_Cox1,5;6;2,3;4;3,Reject,0,4,0.0,yes,9/28/20,MIT-IBM Watson AI Lab;Massachusetts Institute of Technology;University of Edinburgh;IBM Research;International Business Machines,deep generative modeling;GAN;super-resolution;wavelet transformation;energy efficient,-1;5;29;-1;-1,-1;4;30;-1;-1,m;m,NAN,NAN,n,5
6933,ICLR,2021,Temperature check: theory and practice for training models with softmax-cross-entropy losses,Atish Agarwala;Samuel Stern Schoenholz;Jeffrey Pennington;Yann Dauphin,~Atish_Agarwala1;~Samuel_Stern_Schoenholz1;~Jeffrey_Pennington1;~Yann_Dauphin1,5;3;6;6,2;3;3;1,Reject,0,11,0.0,yes,9/28/20,Google;Google;Google;Google,theory;learning dynamics;temperature;theory of deep learning;generalization,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
6934,ICLR,2021,Hidden Incentives for Auto-Induced Distributional Shift,David Krueger;Tegan Maharaj;Jan Leike,~David_Krueger1;~Tegan_Maharaj1;~Jan_Leike1,4;5;6;4,3;2;3;3,Reject,0,17,0.0,yes,9/28/20,University of Montreal;Ecole Polytechnique de Montreal;OpenAI,distributional shift;social impact of AI;content recommendation;incentives;meta-learning,128;-1;-1,73;-1;-1,m;m,NAN,NAN,n,6
6935,ICLR,2021,Weakly Supervised Scene Graph Grounding,Yizhou Zhang;Zhaoheng Zheng;Yan Liu,~Yizhou_Zhang3;~Zhaoheng_Zheng1;~Yan_Liu1,7;5;5;4,5;4;5;5,Reject,0,4,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,Weakly Supervised Learning;Scene Graph Grounding;Visual Relation;Computer Vision,37;37;37,53;53;53,m;f,usa,usa,n,10
6936,ICLR,2021,Implicit bias of gradient descent for mean squared error regression with wide neural networks,Hui Jin;Guido Montufar,~Hui_Jin1;~Guido_Montufar1,6;7;5;7;5,1;3;3;4;3,Reject,0,9,0.0,yes,9/28/20,"University of California, Los Angeles;Max Planck Institute MIS",Implicit bias;overparametrized neural network;cubic spline interpolation;spatially adaptive smoothing spline;effective capacity,-1;-1,15;-1,m;m,NAN,NAN,y,1
6937,ICLR,2021,Adversarial Boot Camp: label free certified robustness in one epoch,Ryan Campbell;Chris Finlay;Adam M Oberman,~Ryan_Campbell2;~Chris_Finlay1;~Adam_M_Oberman1,3;4;3;7,4;4;4;3,Reject,0,1,0.0,yes,9/28/20,McGill University;Deep Render;McGill University,machine;learning;adversarial;robustness;neural;networks;image;classification;computer;vision,99;-1;99,40;-1;40,m;m,canada,ca,y,4
6938,ICLR,2021,Mitigating bias in calibration error estimation,Rebecca Roelofs;Nicholas Cain;Jonathon Shlens;Michael Curtis Mozer,~Rebecca_Roelofs1;~Nicholas_Cain1;~Jonathon_Shlens1;~Michael_Curtis_Mozer1,6;7;4;4,3;3;4;4,Reject,0,12,0.0,yes,9/28/20,University of California Berkeley;Allen Institute for Brain Science;Google;University of Colorado at Boulder,calibration error;uncertainty estimation;statistical bias,-1;-1;-1;-1,7;-1;-1;-1,f;m,usa,usa,y,
6939,ICLR,2021,Compute- and Memory-Efficient Reinforcement Learning with Latent Experience Replay,Lili Chen;Kimin Lee;Aravind Srinivas;Pieter Abbeel,~Lili_Chen1;~Kimin_Lee1;~Aravind_Srinivas1;~Pieter_Abbeel2,6;5;7;6,4;5;4;3,Reject,0,7,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley;Covariant,reinforcement learning;deep learning;computational efficiency;memory efficiency,-1;-1;-1;-1,7;7;7;-1,m;m,NAN,NAN,n,6
6940,ICLR,2021,An Algorithm for Out-Of-Distribution Attack to Neural Network Encoder ,Liang Liang;Linhai Ma;Linchen Qian;Jiasong Chen,~Liang_Liang2;~Linhai_Ma1;lxq93@miami.edu;jasonchen@miami.edu,4;4;3;3,4;4;4;5,Reject,0,26,0.0,yes,9/28/20,University of Miami;University of Miami;University of Miami;;University of Miami,Out-Of-Distribution;DNN;image classification,453;453;453;-1;453,238;238;238;-1;238,m;m,usa,usa,n,4
6941,ICLR,2021,Discovering Parametric Activation Functions,Garrett Bingham;Risto Miikkulainen,~Garrett_Bingham1;~Risto_Miikkulainen1,6;5;5,5;5;5,Reject,0,5,0.0,yes,9/28/20,"University of Texas, Austin;The University of Texas, Austin",activation function;parametric;evolution,-1;-1,-1;-1,m;m,NAN,NAN,n,
6942,ICLR,2021,Sparse Binary Neural Networks,Riccardo Schiavone;Maria A Zuluaga,~Riccardo_Schiavone1;~Maria_A_Zuluaga1,5;5;4;3,4;4;4;5,Reject,0,5,0.0,yes,9/28/20,Eurecom;Eurecom,Binary Neural Networks;Sparsity;Deep Neural Network Compression,-1;-1,-1;-1,m;f,NAN,NAN,n,1
6943,ICLR,2021,R-MONet: Region-Based Unsupervised Scene Decomposition and Representation via Consistency of Object Representations,Shengxin Qian,~Shengxin_Qian1,6;6;3,3;3;3,Reject,0,10,0.0,yes,9/28/20,Duke University,unsupervised representation learning;unsupervised scene representation;unsupervised scene decomposition;generative models,46,20,u,europe,se,n,2;5
6944,ICLR,2021,Asynchronous Advantage Actor Critic: Non-asymptotic Analysis and Linear Speedup,Han Shen;Kaiqing Zhang;Mingyi Hong;Tianyi Chen,shenh5@rpi.edu;~Kaiqing_Zhang3;~Mingyi_Hong1;~Tianyi_Chen1,5;6;6,4;3;2,Reject,0,5,0.0,yes,9/28/20,Rensselaer Polytechnic Institute;Massachusetts Institute of Technology;Iowa State University;Rensselaer Polytechnic Institute,,263;5;209;263,527;4;427;527,m;m,usa,usa,y,
6945,ICLR,2021,AWAC: Accelerating Online Reinforcement Learning with Offline Datasets,Ashvin Nair;Murtaza Dalal;Abhishek Gupta;Sergey Levine,~Ashvin_Nair1;~Murtaza_Dalal1;~Abhishek_Gupta1;~Sergey_Levine1,6;6;3;6;4,4;4;4;3;5,Reject,0,12,0.0,yes,9/28/20,University of California Berkeley;Carnegie Mellon University;Google;University of Washington,reinforcement learning,-1;1;-1;11,7;28;-1;29,m;m,usa,usa,n,
6946,ICLR,2021,Predicting the Outputs of Finite Networks Trained with Noisy Gradients,Gadi Naveh;Oded Ben-David;Haim Sompolinsky;Zohar Ringel,~Gadi_Naveh1;oded.bendavid@mail.huji.ac.il;~Haim_Sompolinsky1;~Zohar_Ringel1,5;4;6;5,3;2;4;5,Reject,0,9,0.0,yes,9/28/20,"Hebrew University of Jerusalem;Hebrew University of Jerusalem;;Hebrew University of Jerusalem, Israel",Gaussian process;deep learning theory;finite DNNs;statistical mechanics,85;85;-1;85,235;235;-1;235,m;m,NAN,NAN,n,
6947,ICLR,2021,Generalized Universal Approximation for Certified Networks,Zi Wang;Aws Albarghouthi;Somesh Jha,~Zi_Wang3;~Aws_Albarghouthi1;~Somesh_Jha1,5;4;4;5,2;5;4;3,Reject,0,5,0.0,yes,9/28/20,"University of Wisconsin, Madison;University of Wisconsin, Madison;Department of Computer Science, University of Wisconsin, Madison",adversarial deep learning;neural network verification;interval analysis,18;18;-1,49;49;-1,m;m,NAN,NAN,y,1;4
6948,ICLR,2021,A Near-Optimal Recipe for Debiasing Trained Machine Learning Models,Ibrahim Alabdulmohsin;Mario Lucic,~Ibrahim_Alabdulmohsin1;~Mario_Lucic1,4;6;7,4;4;4,Reject,0,8,0.0,yes,9/28/20,Google;Google,Fairness;Classification;Statistical Parity;Deep Learning,-1;-1,-1;-1,m;m,NAN,NAN,y,1
6949,ICLR,2021,Search Data Structure Learning,Mathieu Duchesneau;Hansenclever Bassani;Alain Tapp,~Mathieu_Duchesneau1;~Hansenclever_Bassani1;tappa@iro.umontreal.ca,4;4;3;4,3;4;4;4,Reject,0,4,0.0,yes,9/28/20,University of Montreal;Universidade Federal de Pernambuco  Federal University of Pernambuco;;University of Montreal,Machine Learning;Search Data Structure;Information Retrieval;Binary Embeddings,128;-1;-1;128,73;1302;-1;73,m;m,canada,ca,n,1
6950,ICLR,2021,Activation Relaxation: A Local Dynamical Approximation to Backpropagation in the Brain,Beren Millidge;Alexander Tschantz;Anil K Seth;Christopher Buckley,~Beren_Millidge1;~Alexander_Tschantz1;~Anil_K_Seth1;~Christopher_Buckley1,7;4;8;4,4;4;2;4,Reject,0,4,0.0,yes,9/28/20,University of Edinburgh;University of Sussex;University of Sussex;University of Sussex,Neural Networks;Biological Plausibility;Backprop,29;327;327;327,30;160;160;160,m;m,europe,uk,n,10
6951,ICLR,2021,Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices,Evan Zheran Liu;Aditi Raghunathan;Percy Liang;Chelsea Finn,~Evan_Zheran_Liu1;~Aditi_Raghunathan1;~Percy_Liang1;~Chelsea_Finn1,7;6;4;5,2;3;4;4,Reject,0,12,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University;Stanford University,meta-reinforcement learning;reinforcement learning;exploration,5;5;5;5,2;2;2;2,m;f,usa,usa,n,
6952,ICLR,2021,Dynamic Relational Inference in Multi-Agent Trajectories,Ruichao Xiao;Manish Kumar Singh;Rose Yu,~Ruichao_Xiao1;~Manish_Kumar_Singh1;~Rose_Yu1,2;4;5;4,5;4;5;3,Reject,0,0,0.0,yes,9/28/20,"Northeastern University;University of California, San Diego;University of California, San Diego",deep generative model;relational inference;trajectory modeling;multi-agent learning,16;-1;-1,895;33;33,m;f,usa,usa,n,5
6953,ICLR,2021,Graph Neural Network Acceleration via Matrix Dimension Reduction,Shunhua Jiang;Yunze Man;Zhao Song;Danyang Zhuo,~Shunhua_Jiang1;~Yunze_Man2;~Zhao_Song3;~Danyang_Zhuo1,4;5;5,2;1;3,Reject,0,7,0.0,yes,9/28/20,Columbia University;Carnegie Mellon University;Institue for Advanced Study;Duke University,Graph Neural Networks;Deep learning;Optimization;Kernel Method,23;1;-1;46,17;28;-1;20,f;m,europe,se,y,1;10
6954,ICLR,2021,PABI: A Unified PAC-Bayesian Informativeness Measure for Incidental Supervision Signals,Hangfeng He;Mingyuan Zhang;Qiang Ning;Dan Roth,~Hangfeng_He3;myz@seas.upenn.edu;qning@amazon.com;~Dan_Roth3,5;5;8;7,3;3;3;3,Reject,0,11,0.0,yes,9/28/20,"University of Pennsylvania;University of Pennsylvania;University of Illinois, Urbana-Champaign;University of Illinois at Urbana-Champaign",informativeness measure;incidental supervision;natural language processing,20;20;-1;-1,13;13;-1;48,m;m,NAN,NAN,y,3;11;1
6955,ICLR,2021,AN ONLINE SEQUENTIAL TEST FOR QUALITATIVE TREATMENT EFFECTS,Chengchun Shi;Shikai Luo;Rui Song;Hongtu Zhu,~Chengchun_Shi1;luoshikai@didiglobal.com;~Rui_Song2;~Hongtu_Zhu2,7;6;3;4,3;2;4;1,Reject,0,4,0.0,yes,9/28/20,"London School of Economics;North Carolina State University;North Carolina State University;University of North Carolina, Chapel Hill",sequential testing;A/B testing;qualitative treatment effects;bootstrap,-1;92;92;64,27;340;340;-1,m;m,NAN,NAN,y,
6956,ICLR,2021,Improved Denoising Diffusion Probabilistic Models,Alexander Quinn Nichol;Prafulla Dhariwal,~Alexander_Quinn_Nichol1;~Prafulla_Dhariwal1,5;5;5;5,4;3;2;3,Reject,0,5,0.0,yes,9/28/20,OpenAI;OpenAI,neural networks;generative models;log-likelihood;diffusion models;denoising diffusion probabilistic models;image generation,-1;-1,-1;-1,m;m,NAN,NAN,n,5
6957,ICLR,2021,To be Robust or to be Fair: Towards Fairness in Adversarial Training,Han Xu;Xiaorui Liu;Yaxin Li;Jiliang Tang,~Han_Xu1;~Xiaorui_Liu1;liyaxin1@msu.edu;~Jiliang_Tang1,5;5;5;6,4;4;4;4,Reject,0,11,0.0,yes,9/28/20,Michigan State University;Michigan State University;Michigan State University;Michigan State University,Adversarial Examples;Robustness;Safety;Fairness,110;110;110;110,105;105;105;105,m;m,usa,usa,y,7;4
6958,ICLR,2021,A spherical analysis of Adam with Batch Normalization,Simon Roburin;Yann Dubois de Mont-Marin;Andrei Bursuc;Renaud Marlet;Patrick Perez;Mathieu Aubry,~Simon_Roburin1;~Yann_Dubois_de_Mont-Marin1;~Andrei_Bursuc1;~Renaud_Marlet1;~Patrick_Perez1;~Mathieu_Aubry3,5;5;4,4;4;4,Reject,0,4,0.0,yes,9/28/20,ENPC;INRIA;Valeo;Valeo;Valeo;ENPC,Deep Learning;Machine Learning;Adam;Batch Normalization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,europe,ch,y,
6959,ICLR,2021,Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks,Shuai Zhang;Meng Wang;Sijia Liu;Pin-Yu Chen;Jinjun Xiong,~Shuai_Zhang6;~Meng_Wang4;~Sijia_Liu1;~Pin-Yu_Chen1;~Jinjun_Xiong1,7;5;5;6,4;2;4;3,Reject,0,12,0.0,yes,9/28/20,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute;Michigan State University;International Business Machines;International Business Machines,Sparse neural network;Lottery Ticket Hypothesis;network pruning;generalization analysis;optimization landscape;sample complexity,263;263;110;-1;-1,527;527;105;-1;-1,m;m,NAN,NAN,y,3;2;1;9
6960,ICLR,2021,CLOPS: Continual Learning of Physiological Signals,Dani Kiyasseh;Tingting Zhu;David A. Clifton,~Dani_Kiyasseh1;tingting.zhu@eng.ox.ac.uk;~David_A._Clifton1,7;3;7;4,2;4;4;3,Reject,0,12,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,Continual learning;physiological signals;healthcare,46;46;46,1;1;1,m;m,europe,uk,n,
6961,ICLR,2021,NAS-Bench-301 and the Case for Surrogate Benchmarks for Neural Architecture Search,Julien Niklas Siems;Lucas Zimmer;Arber Zela;Jovita Lukasik;Margret Keuper;Frank Hutter,~Julien_Niklas_Siems1;~Lucas_Zimmer1;~Arber_Zela1;~Jovita_Lukasik1;~Margret_Keuper1;~Frank_Hutter1,7;3;8;5,4;5;5;4,Reject,0,16,0.0,yes,9/28/20,Universit√§t Freiburg;Swiss Federal Institute of Technology;Universit√§t Freiburg;University of Mannheim;University of Mannheim;University of Freiburg & Bosch,Neural Architecture Search;Benchmarking;Performance Prediction;Deep Learning,-1;-1;-1;263;263;150,-1;-1;-1;140;140;83,m;m,NAN,NAN,n,10
6962,ICLR,2021,Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization,Manli Shu;Zuxuan Wu;Micah Goldblum;Tom Goldstein,~Manli_Shu1;~Zuxuan_Wu1;~Micah_Goldblum1;~Tom_Goldstein1,5;6;5;3;5,4;4;4;5;4,Reject,0,10,0.0,yes,9/28/20,"University of Maryland, College Park;Fudan University;University of Maryland, College Park;University of Maryland, College Park",adversarial training;distributional shifts,12;71;12;12,90;70;90;90,f;m,usa,usa,n,2;1;4
6963,ICLR,2021,Contrastive Self-Supervised Learning of Global-Local Audio-Visual Representations,Shuang Ma;Zhaoyang Zeng;Daniel McDuff;Yale Song,~Shuang_Ma3;~Zhaoyang_Zeng1;~Daniel_McDuff1;~Yale_Song1,5;6;7;5,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft Research,Contrastive learning;self-supervised learning;video representation learning;audio-visual representation learning;multimodal representation learning,-1;-1;-1;-1,-1;293;-1;-1,f;m,NAN,NAN,n,
6964,ICLR,2021,Neural CDEs for Long Time Series via the Log-ODE Method,James Morrill;Patrick Kidger;Cristopher Salvi;James Foster;Terry Lyons,morrill@maths.ox.ac.uk;~Patrick_Kidger1;salvi@maths.ox.ac.uk;foster@maths.ox.ac.uk;tlyons@maths.ox.ac.uk,7;5;6,4;5;4,Reject,0,7,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford;University of Oxford;Alan Turing Institute,CDE;neural differential equation;time series;long time series;log-ODE,46;46;46;46;-1,1;1;1;1;-1,m;m,NAN,NAN,y,
6965,ICLR,2021,Guided Exploration with Proximal Policy Optimization using a Single Demonstration,Gabriele Libardi;Gianni De Fabritiis,~Gabriele_Libardi1;~Gianni_De_Fabritiis1,6;4;6,3;5;4,Reject,0,5,0.0,yes,9/28/20,Universitat Pompeu Fabra;Universitat Pompeu Fabra,PPO;sparse rewards;single demonstration;3D environment,-1;-1,-1;-1,m;m,NAN,NAN,n,
6966,ICLR,2021,Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel,Henrique Teles Maia;Chang Xiao;Dingzeyu Li;Eitan Grinspun;Changxi Zheng,~Henrique_Teles_Maia1;~Chang_Xiao1;~Dingzeyu_Li2;~Eitan_Grinspun3;~Changxi_Zheng1,7;5;4,4;4;4,Reject,0,10,0.0,yes,9/28/20,Columbia University;Columbia University;Adobe Research;Columbia University;Columbia University,side channel;model extraction;GPU;magnetic induction;sensors,23;23;-1;23;23,17;17;-1;17;17,m;m,usa,usa,n,10;4
6967,ICLR,2021,Symmetry Control Neural Networks,Marc Syvaeri;Sven Krippendorf,~Marc_Syvaeri1;~Sven_Krippendorf1,5;5;5;4,3;4;5;4,Reject,0,6,0.0,yes,9/28/20,"University of Munich, Institut f√ºr Physik;LMU Munich",Inductive (symmetry) Bias;Predictive Models;Hamiltonian Dynamics;Physics,-1;150,-1;32,m;m,europe,de,n,1
6968,ICLR,2021,Not All Memories are Created Equal: Learning to Expire,Sainbayar Sukhbaatar;Da JU;Spencer Poff;Stephen Roller;Arthur Szlam;Jason E Weston;Angela Fan,~Sainbayar_Sukhbaatar1;~Da_JU1;spoff@fb.com;~Stephen_Roller1;~Arthur_Szlam1;~Jason_E_Weston1;~Angela_Fan2,6;5;6,3;4;4,Reject,0,5,0.0,yes,9/28/20,Facebook;Facebook;Facebook;Facebook;CUNY City College;;Facebook,expire;long attention;memory;transformers,-1;-1;-1;-1;263;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;3
6969,ICLR,2021,Unsupervised Progressive Learning and the STAM Architecture,James Smith;Cameron Ethan Taylor;Seth Baer;Constantine Dovrolis,~James_Smith1;~Cameron_Ethan_Taylor1;~Seth_Baer1;~Constantine_Dovrolis1,5;6;7;2;5,3;3;3;5;3,Reject,0,5,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology;;Georgia Institute of Technology;Georgia Institute of Technology,continual learning;unsupervised learning;representation learning;online learning,12;12;-1;12;12,38;38;-1;38;38,m;m,usa,usa,n,
6970,ICLR,2021,Distributional Generalization: A New Kind of Generalization,Preetum Nakkiran;Yamini Bansal,~Preetum_Nakkiran1;~Yamini_Bansal1,7;4;6;5,3;3;3;3,Reject,0,6,0.0,yes,9/28/20,Harvard University;Harvard University,understanding deep learning;generalization;interpolating methods;empirical investigation,53;53,3;3,m;f,usa,usa,y,1
6971,ICLR,2021,Action Concept Grounding Network for Semantically-Consistent Video Generation,Wei Yu;Wenxin Chen;Animesh Garg,~Wei_Yu10;~Wenxin_Chen1;~Animesh_Garg1,5;5;5,5;4;5,Reject,0,6,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Toronto University;University of Toronto",action-conditional video prediction;self-supervised learning;counterfactual generation,18;-1;18,18;-1;18,m;m,canada,ca,n,2
6972,ICLR,2021,Unsupervised Video Decomposition using Spatio-temporal Iterative Inference,Polina Zablotskaia;Edoardo Alberto Dominici;Leonid Sigal;Andreas Lehrmann,~Polina_Zablotskaia1;~Edoardo_Alberto_Dominici1;~Leonid_Sigal2;~Andreas_Lehrmann1,6;4;6;7,3;3;4;4,Reject,0,7,0.0,yes,9/28/20,Google;University of British Columbia;University of British Columbia;Borealis AI,Unsupervised Learning;Representation Learning;Scene Decomposition;Computer Vision,-1;58;58;-1,-1;34;34;-1,f;m,NAN,NAN,n,2
6973,ICLR,2021,Active Tuning,Sebastian Otte;Matthias Karlbauer;Martin V. Butz,~Sebastian_Otte1;~Matthias_Karlbauer1;martin.butz@uni-tuebingen.de,8;3;5,3;4;3,Reject,0,5,0.0,yes,9/28/20,University of Tuebingen;University of Tuebingen;University of Tuebingen,Signal Filtering;Recurrent Neural Network;Time Series;Denoising;Temporal Gradients,128;128;128,78;78;78,m;m,europe,de,n,1
6974,ICLR,2021,Learning Irreducible Representations of Noncommutative Lie Groups,Noah Shutty;Casimir Wierzynski,~Noah_Shutty1;casimir.wierzynski@intel.com,4;5;5,3;2;4,Reject,0,4,0.0,yes,9/28/20,Stanford University;California Institute of Technology,equivariance;object tracking;equivariant neural networks;deep learning;point cloud;lie group;lie algebra;lorentz group;poincar√© group,5;150,2;4,m;m,usa,usa,n,
6975,ICLR,2021,Recurrent Neural Network Architecture based on Dynamic Systems Theory for Data Driven Modelling of Complex Physical Systems,Deniz Neufeld,~Deniz_Neufeld1,3;6;4;3,5;4;5;3,Reject,0,5,0.0,yes,9/28/20,Otto Friedrich University Bamberg,dynamic system identification;recurrent networks;explainable AI;time series modelling,-1,-1,u,NAN,NAN,n,
6976,ICLR,2021,Compositional Video Synthesis with Action Graphs,Amir Bar;Roei Herzig;Xiaolong Wang;Gal Chechik;Trevor Darrell;Amir Globerson,~Amir_Bar1;~Roei_Herzig2;~Xiaolong_Wang3;~Gal_Chechik1;~Trevor_Darrell2;~Amir_Globerson1,7;5;7;6,3;2;3;4,Reject,0,7,0.0,yes,9/28/20,"Tel Aviv University;Tel Aviv University;University of California, San Diego;Bar Ilan University;Electrical Engineering & Computer Science Department;Tel Aviv University",Video Synthesis;Vision and Language;Representation Learning,34;34;-1;110;-1;34,190;190;33;570;-1;190,m;m,europe,il,n,10;5
6977,ICLR,2021,BRAC+: Going Deeper with Behavior Regularized Offline Reinforcement Learning,Chi Zhang;Sanmukh Rao Kuppannagari;Viktor Prasanna,~Chi_Zhang16;~Sanmukh_Rao_Kuppannagari1;~Viktor_Prasanna1,5;7;7;5,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,offline reinforcement learning;behavior regularization,37;37;37,53;53;53,m;m,usa,usa,n,1
6978,ICLR,2021,Generative Learning With Euler Particle Transport,Yuan Gao;Jian Huang;Yuling Jiao;Jin Liu,xjtuygao@gmail.com;~Jian_Huang5;yulingjiaomath@whu.edu.cn;~Jin_Liu5,5;5;6,4;4;4,Reject,0,9,0.0,yes,9/28/20,Xi'an Jiaotong University;University of Iowa;Wuhan University;National University of Singapore,Deep density-ratio estimation;forward Euler method;Mckean-Vlasov equation;Monge-Ampere equation;residual map,-1;174;209;17,445;245;323;25,m;m,asia,sg,y,5
6979,ICLR,2021,Just How Toxic is Data Poisoning?  A Benchmark for Backdoor and Data Poisoning Attacks,Avi Schwarzschild;Micah Goldblum;Arjun Gupta;John P Dickerson;Tom Goldstein,~Avi_Schwarzschild1;~Micah_Goldblum1;~Arjun_Gupta2;~John_P_Dickerson1;~Tom_Goldstein1,7;8;5;4,4;4;4;5,Reject,0,5,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Arthur AI;University of Maryland, College Park",Poisoning;backdoor;attack;benchmark,12;12;12;-1;12,90;90;90;-1;90,m;m,usa,usa,n,4
6980,ICLR,2021,On the Decision Boundaries of Neural Networks. A Tropical Geometry Perspective,Motasem Alfarra;Adel Bibi;Hasan Abed Al Kader Hammoud;Mohamed Gaafar;Bernard Ghanem,~Motasem_Alfarra1;~Adel_Bibi1;~Hasan_Abed_Al_Kader_Hammoud1;~Mohamed_Gaafar1;~Bernard_Ghanem1,6;6;6;7,3;4;1;3,Reject,0,5,0.0,yes,9/28/20,KAUST;KAUST;KAUST;Zalando SE;KAUST,Tropical Geometry;Decision Boundaries;Neural Networks,110;110;110;-1;110,-1;-1;-1;-1;-1,m;m,europe,gr,y,4
6981,ICLR,2021,Quickly Finding a Benign Region via Heavy Ball Momentum in Non-Convex Optimization,Jun-Kun Wang;Jacob Abernethy,~Jun-Kun_Wang1;~Jacob_Abernethy1,6;7;4;6,3;3;4;4,Reject,0,4,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Tech Research Corporation,,12;-1,38;-1,u;m,NAN,NAN,y,9
6982,ICLR,2021,Disentangled cyclic reconstruction for domain adaptation,David Bertoin;Emmanuel Rachelson,~David_Bertoin1;~Emmanuel_Rachelson1,5;4;6,3;3;3,Reject,0,13,0.0,yes,9/28/20,Institut Sup√©rieur de l'A√©ronautique et de l'Espace;Institut Sup√©rieur de l'A√©ronautique et de l'Espace,Domain adaptation;Disentanglement,-1;-1,-1;-1,m;m,NAN,NAN,n,
6983,ICLR,2021,On Dynamic Noise Influence in Differential Private Learning,Junyuan Hong;Zhangyang Wang;Jiayu Zhou,~Junyuan_Hong1;~Zhangyang_Wang1;~Jiayu_Zhou1,5;7;6;4,4;3;4;3,Reject,0,13,0.0,yes,9/28/20,"Michigan State University;University of Texas, Austin;Michigan State University",privacy;private learning;dynamic policy,110;-1;110,105;-1;105,m;m,usa,usa,y,1
6984,ICLR,2021,F^2ed-Learning: Good Fences Make Good Neighbors,Lun Wang;Qi Pang;Shuai Wang;Dawn Song,~Lun_Wang1;~Qi_Pang1;~Shuai_Wang7;~Dawn_Song1,6;5;5;6,3;2;4;3,Reject,0,15,0.0,yes,9/28/20,"University of California Berkeley;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;University of California Berkeley",Byzantine-Robust Federated Learning;Secure Aggregation,-1;-1;-1;-1,7;56;56;7,m;f,usa,usa,y,4
6985,ICLR,2021,On the Predictability of Pruning Across Scales,Jonathan S Rosenfeld;Jonathan Frankle;Michael Carbin;Nir Shavit,~Jonathan_S_Rosenfeld1;~Jonathan_Frankle1;~Michael_Carbin1;~Nir_Shavit1,6;6;6;6,3;4;4;3,Reject,0,7,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,neural networks;deep learning;generalization error;scaling;scalability;pruning,5;5;5;5,4;4;4;4,m;m,usa,usa,n,
6986,ICLR,2021,Distributionally Robust Learning for Unsupervised Domain Adaptation,Haoxuan Wang;Anqi Liu;Zhiding Yu;Yisong Yue;Anima Anandkumar,hatchet25@sjtu.edu.cn;~Anqi_Liu2;~Zhiding_Yu1;~Yisong_Yue1;~Anima_Anandkumar1,6;5;7,3;3;4,Reject,0,4,0.0,yes,9/28/20,Shanghai Jiao Tong University;California Institute of Technology;NVIDIA;California Institute of Technology;California Institute of Technology,Distributionally Robust Learning;Domain Adaptation;Self-training;Density Ratio Estimation,29;150;-1;150;150,100;4;-1;4;4,m;f,usa,usa,y,
6987,ICLR,2021,BASGD: Buffered Asynchronous SGD for Byzantine Learning,Yi-Rui Yang;Wu-Jun Li,~Yi-Rui_Yang2;~Wu-Jun_Li1,5;7;5;6,3;3;4;3,Reject,0,11,0.0,yes,9/28/20,Nanjing University;Nanjing University,Distributed optimization;asynchronous Byzantine learning,52;52,111;111,m;m,asia,kr,y,8;4
6988,ICLR,2021,Fast Partial Fourier Transform,Yong-chan Park;Jun-Gi Jang;U Kang,~Yong-chan_Park1;~Jun-Gi_Jang1;~U_Kang1,5;5;6,4;3;5,Reject,0,4,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University,Fourier transform;time series;signal processing;anomaly detection;machine learning,37;37;37,60;60;60,m;m,asia,kr,y,
6989,ICLR,2021,Towards Robust and Efficient Contrastive Textual Representation Learning,Liqun Chen;Yizhe Zhang;Dianqi Li;Chenyang Tao;Dong Wang;Lawrence Carin,~Liqun_Chen2;~Yizhe_Zhang2;~Dianqi_Li1;~Chenyang_Tao1;~Dong_Wang2;~Lawrence_Carin2,6;6;3;5,3;4;3;3,Reject,0,4,0.0,yes,9/28/20,"Duke University;Microsoft;University of Washington, Seattle;Duke University;Duke University;Duke University",,46;-1;11;46;46;46,20;-1;29;20;20;20,m;m,europe,se,n,3
6990,ICLR,2021,CROSS-SUPERVISED OBJECT DETECTION,Zitian Chen;Zhiqiang Shen;Jiahui Yu;Erik Learned-Miller,~Zitian_Chen1;~Zhiqiang_Shen1;~Jiahui_Yu1;~Erik_Learned-Miller2,4;6;6;6,5;4;3;5,Reject,0,8,0.0,yes,9/28/20,"University of Massachusetts, Amherst;Mohamed bin Zayed University of Artificial Intelligence;Google Brain;Department of Computer Science, University of Massachusetts, Amherst",Object detection;weakly supervised;transfer leaning,23;-1;-1;-1,210;874;-1;210,m;m,NAN,NAN,n,2
6991,ICLR,2021,Gradient-based tuning of Hamiltonian Monte Carlo hyperparameters,Andrew Campbell;Wenlong Chen;Vincent Stimper;Jos√© Miguel Hern√°ndez-Lobato;Yichuan Zhang,~Andrew_Campbell4;wc327@cam.ac.uk;vs488@cam.ac.uk;~Jos√©_Miguel_Hern√°ndez-Lobato1;~Yichuan_Zhang1,6;5;4;5,3;4;4;5,Reject,0,10,0.0,yes,9/28/20,"University of Oxford;University of Cambridge;Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of Cambridge;University of Cambridge",Hamiltonian Monte Carlo;HMC;MCMC;Variational Inference,46;79;-1;79;79,1;6;-1;6;6,m;m,europe,uk,n,1;5
6992,ICLR,2021,Gated Relational Graph Attention Networks,Denis Lukovnikov;Asja Fischer,~Denis_Lukovnikov1;~Asja_Fischer1,4;7;5;2,4;5;4;4,Reject,0,10,0.0,yes,9/28/20,Rheinische Friedrich-Wilhelms-Universit√§t Bonn;Ruhr-University Bochum,graph neural networks;GNN;long-range dependencies;deep GNN;relational GNN,-1;263,-1;257,m;f,europe,de,n,8;10
6993,ICLR,2021,Provable Robustness by Geometric Regularization of ReLU Networks,Chester Holtz;Changhao Shi;Gal Mishne,~Chester_Holtz1;~Changhao_Shi1;~Gal_Mishne1,6;5;4,3;4;3,Reject,0,5,0.0,yes,9/28/20,"University of California, San Diego, University of California, San Diego;University of California, San Diego;University of California, San Diego",deep learning;adversarial attack;robust certification,-1;-1;-1,33;33;33,m;f,usa,usa,y,1;4
6994,ICLR,2021,Improving the Reconstruction of Disentangled Representation Learners via Multi-Stage Modelling,Akash Srivastava;Yamini Bansal;Yukun Ding;Cole Lincoln Hurwitz;Kai Xu;Bernhard Egger;Prasanna Sattigeri;Joshua B. Tenenbaum;Dan Gutfreund,~Akash_Srivastava1;~Yamini_Bansal1;~Yukun_Ding1;~Cole_Lincoln_Hurwitz1;~Kai_Xu4;~Bernhard_Egger1;~Prasanna_Sattigeri1;~Joshua_B._Tenenbaum1;~Dan_Gutfreund1,6;6;6;6,3;4;3;3,Reject,0,13,0.0,yes,9/28/20,Massachusetts Institute of Technology;Harvard University;University of Notre Dame;University of Edinburgh;University of Edinburgh;Friedrich-Alexander-Universit√§t Erlangen-N√ºrnberg;IBM Research;Massachusetts Institute of Technology;International Business Machines,disentanglement;disentangled representation learning;vae;generative model,5;53;128;29;29;-1;-1;5;-1,4;3;170;30;30;-1;-1;4;-1,m;m,NAN,NAN,n,5;4
6995,ICLR,2021,LLBoost: Last Layer Perturbation to Boost Pre-trained Neural Networks,Adityanarayanan Radhakrishnan;Neha Prasad;Caroline Uhler,~Adityanarayanan_Radhakrishnan1;nehap@mit.edu;~Caroline_Uhler1,6;4;5,3;4;2,Reject,0,10,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;Electrical Engineering & Computer Science, Massachusetts Institute of Technology",Pre-trained Neural Networks;Over-parameterization;Perturbations,5;5;5,4;4;4,m;m,NAN,NAN,y,3;1
6996,ICLR,2021,Box-To-Box Transformation for Modeling Joint Hierarchies,Shib Sankar Dasgupta;Xiang Li;Michael Boratko;Dongxu Zhang;Andrew McCallum,~Shib_Sankar_Dasgupta2;~Xiang_Li2;~Michael_Boratko1;~Dongxu_Zhang1;~Andrew_McCallum1,4;4;6;8,4;4;4;4,Reject,0,13,0.0,yes,9/28/20,"University of Massachusetts, Amherst;Department of Computer Science, University of Massachusetts, Amherst;University of Massachusetts, Amherst;Department of Computer Science, University of Massachusetts, Amherst;Department of Computer Science, University of Massachusetts, Amherst",Box embeddings;Representation Learning;Joint Hierarchy;transitive relations;knowledge graph embedding;relational learning.,23;-1;23;-1;-1,210;210;210;210;210,m;m,NAN,NAN,n,1;10
6997,ICLR,2021,Variational Structured Attention Networks for Dense Pixel-Wise Prediction,Guanglei Yang;Paolo Rota;Xavier Alameda-Pineda;Dan Xu;Mingli Ding;Elisa Ricci,~Guanglei_Yang1;~Paolo_Rota1;~Xavier_Alameda-Pineda1;~Dan_Xu4;dingml@hit.edu.cn;~Elisa_Ricci1,5;6;6;6,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,"University of Trento;Universit√† degli Studi di Genova, Istituto Italiano di Tecnologia;INRIA Grenoble;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology;Harbin Institute of Technology;University of Trento",attention network;pixel-wise prediction,150;-1;-1;-1;150;150,343;-1;-1;56;416;343,m;f,europe,gr,n,8
6998,ICLR,2021,End-to-end Quantized Training via Log-Barrier Extensions,Juncheng B Li;Shuhui Qu;Xinjian Li;Emma Strubell;Florian Metze,~Juncheng_B_Li1;~Shuhui_Qu1;~Xinjian_Li2;~Emma_Strubell1;~Florian_Metze1,3;5;6;3,5;5;5;4,Reject,0,6,0.0,yes,9/28/20,Carnegie Mellon University;Stanford University;Carnegie Mellon University;Carnegie Mellon University;Facebook,Quantization;Constrained Optimization;Mu-law;8-bit training,1;5;1;1;-1,28;2;28;28;-1,m;m,NAN,NAN,n,
6999,ICLR,2021,Learning Chess Blindfolded,Shubham Toshniwal;Sam Wiseman;Karen Livescu;Kevin Gimpel,~Shubham_Toshniwal1;~Sam_Wiseman1;~Karen_Livescu1;~Kevin_Gimpel1,5;5;7;7,4;3;4;4,Reject,0,13,0.0,yes,9/28/20,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago,Chess;Transformers;Language Modeling;World State,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
7000,ICLR,2021,Meta-Active Learning in Probabilistically-Safe Optimization,Mariah L Schrum;Mark Connolly;Eric Cole;Mihir Ghetiya;Robert Gross;Matthew C. Gombolay,~Mariah_L_Schrum1;mark.connolly@emory.edu;ercole@emory.edu;mihir.v.ghetiya@emory.edu;~Robert_Gross1;~Matthew_C._Gombolay1,6;6;5;5,3;3;3;2,Reject,0,13,0.0,yes,9/28/20,"Georgia Institute of Technology;Emory University;Georgia Institute of Technology;;;Emory University;College of Computing, Georgia Institute of Technology",meta-learning;active-learning;safe learning,12;174;12;-1;-1;174;12,38;85;38;-1;-1;85;38,f;m,NAN,NAN,n,6
7001,ICLR,2021,Model Compression via Hyper-Structure Network,Shangqian Gao;Feihu Huang;Heng Huang,~Shangqian_Gao1;~Feihu_Huang1;~Heng_Huang1,6;4;5;5,5;5;5;3,Reject,0,4,0.0,yes,9/28/20,University of Pittsburgh;University of Pittsburgh;University of Pittsburgh,,79;79;79,133;133;133,u;m,usa,usa,n,
7002,ICLR,2021,Privacy Preserving Recalibration under Domain Shift,Rachel Luo;Shengjia Zhao;Jiaming Song;Jonathan Kuck;Stefano Ermon;Silvio Savarese,~Rachel_Luo1;~Shengjia_Zhao1;~Jiaming_Song1;~Jonathan_Kuck1;~Stefano_Ermon1;~Silvio_Savarese1,5;7;5;6,4;4;4;3,Reject,0,5,0.0,yes,9/28/20,"Stanford University;Stanford University;Computer Science Department, Stanford University;;Stanford University;Salesforce",uncertainty calibration;differential privacy,5;5;5;-1;5;-1,2;2;2;-1;2;-1,f;m,NAN,NAN,y,
7003,ICLR,2021,Cross-model Back-translated Distillation for Unsupervised Machine Translation,Phi Xuan Nguyen;Shafiq Joty;Kui Wu;AiTi Aw,~Phi_Xuan_Nguyen1;~Shafiq_Joty1;wuk@i2r.a-star.edu.sg;~AiTi_Aw1,5;7;7;6,5;5;4;3,Reject,0,1,0.0,yes,9/28/20,Nanyang Technological University;SalesForce.com;I2R  A*STAR;I2R  A*STAR,unsupervised machine translation;NMT;machine translation,44;-1;-1;-1,47;-1;-1;-1,m;u,NAN,NAN,n,3
7004,ICLR,2021,Detecting Hallucinated Content in Conditional Neural Sequence Generation,Chunting Zhou;Jiatao Gu;Mona T. Diab;Paco Guzm√°n;Luke Zettlemoyer;Marjan Ghazvininejad,~Chunting_Zhou1;~Jiatao_Gu1;~Mona_T._Diab1;fguzman@fb.com;~Luke_Zettlemoyer1;~Marjan_Ghazvininejad1,5;5;6;5,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,"Language Technologies Institute, Carnegie Mellon University;Facebook AI Research;George Washington University;;;Facebook;Facebook AI Research",conditional text generation;hallucination detection;sequence generation evaluation;neural machine translation;abstractive text summarization,1;-1;209;-1;-1;-1;-1,28;-1;186;-1;-1;-1;-1,f;f,NAN,NAN,n,3
7005,ICLR,2021,Ruminating Word Representations with Random Noise Masking,Hwiyeol Jo;Byoung-Tak Zhang,~Hwiyeol_Jo1;~Byoung-Tak_Zhang1,3;4;4,4;4;4,Reject,0,0,0.0,yes,9/28/20,Seoul National University;Seoul National University,representation learning for natural language processing;pretrained word embeddings;iterative training method;model regularization,37;37,60;60,m;m,asia,kr,n,3
7006,ICLR,2021,Multiple Descent: Design Your Own Generalization Curve,Lin Chen;Yifei Min;Mikhail Belkin;amin karbasi,~Lin_Chen14;~Yifei_Min1;mbelkin@ucsd.edu;~amin_karbasi1,6;5;4;6,3;4;4;2,Reject,0,7,0.0,yes,9/28/20,"University of California Berkeley;Yale University;University of California, San Diego;Google",multiple descent;interpolation;overparametrization,-1;71;-1;-1,7;8;33;-1,m;m,NAN,NAN,y,1
7007,ICLR,2021,Graph Learning via Spectral Densification,Zhuo Feng;Yongyu Wang;Zhiqiang Zhao,~Zhuo_Feng3;~Yongyu_Wang1;~Zhiqiang_Zhao1,5;6;5;6,4;4;3;3,Reject,0,7,0.0,yes,9/28/20,Stevens Institute of Technology;Michigan Technological University;Stevens Institute of Technology,Spectral Graph Theory;Undirected Graphical models;Gaussian Markov Random Fields,150;327;150,567;-1;567,m;m,usa,usa,y,10
7008,ICLR,2021,SpreadsheetCoder: Formula Prediction from Semi-structured Context,Xinyun Chen;Petros Maniatis;Rishabh Singh;Charles Sutton;Hanjun Dai;Max Lin;Denny Zhou,~Xinyun_Chen1;~Petros_Maniatis1;~Rishabh_Singh1;~Charles_Sutton1;~Hanjun_Dai1;whlin@google.com;~Denny_Zhou1,7;7;3,5;3;3,Reject,0,7,0.0,yes,9/28/20,University of California Berkeley;Google Brain;Google Brain;Google;Google Research;;;Google,neural program synthesis;spreadsheet formula prediction,-1;-1;-1;-1;-1;-1;-1;-1,7;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,10
7009,ICLR,2021,Model Selection for Cross-Lingual Transfer using a Learned Scoring Function,Yang Chen;Alan Ritter,~Yang_Chen10;~Alan_Ritter1,7;6;7;7,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,Georgia Institute of Technology;Ohio State University,,12;58,38;78,m;m,usa,usa,n,6;8;3
7010,ICLR,2021,Least Probable Disagreement Region for Active Learning,Seong Jin Cho;Gwangsu Kim;Chang D. Yoo,~Seong_Jin_Cho1;~Gwangsu_Kim1;~Chang_D._Yoo1,4;5;7;4,4;4;3;2,Reject,0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,active learning;uncertainty sampling;disagreement region;variation ratio;deep learning;distance;decision boundary,-1;-1;-1,96;96;96,m;m,NAN,NAN,y,
7011,ICLR,2021,Learning to Generate Noise for Multi-Attack Robustness,Divyam Madaan;Jinwoo Shin;Sung Ju Hwang,~Divyam_Madaan1;~Jinwoo_Shin1;~Sung_Ju_Hwang1,5;6;6;6,4;5;5;1,Reject,0,21,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,adversarial learning;robust machine learning;robust optimization;meta learning,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,6;4
7012,ICLR,2021,Reservoir Transformers,Sheng Shen;Alexei Baevski;Ari S. Morcos;Kurt Keutzer;Michael Auli;Douwe Kiela,sheng.s@berkeley.edu;~Alexei_Baevski1;~Ari_S._Morcos1;~Kurt_Keutzer1;~Michael_Auli1;~Douwe_Kiela1,5;7;5,4;4;3,Reject,0,3,0.0,yes,9/28/20,"University of California Berkeley;Facebook;Facebook AI Research (FAIR);;Univ. of California - Berkeley;University of California, Berkeley;Facebook;Facebook AI Research",,-1;-1;-1;-1;10;-1;-1;-1,7;-1;-1;-1;-1;7;-1;-1,m;m,NAN,NAN,n,8;3
7013,ICLR,2021,VECoDeR - Variational Embeddings for Community Detection and Node Representation,Rayyan Ahmad Khan;Muhammad Umer Anwaar;Omran Kaddah;Martin Kleinsteuber,~Rayyan_Ahmad_Khan1;~Muhammad_Umer_Anwaar1;~Omran_Kaddah1;~Martin_Kleinsteuber1,5;5;5;6,4;5;5;4,Reject,0,6,0.0,yes,9/28/20,Technical University Munich;Technical University Munich;Technical University Munich;Technical University of Munich,Generative Models;Node representation;VECoDeR;Graph Neural Networks;Variational Embeddings,-1;-1;-1;-1,-1;-1;-1;41,m;m,NAN,NAN,n,10;5
7014,ICLR,2021,QTRAN++: Improved Value Transformation for Cooperative Multi-Agent Reinforcement Learning,Kyunghwan Son;Sungsoo Ahn;Roben D. Delos Reyes;Jinwoo Shin;Yung Yi,~Kyunghwan_Son1;~Sungsoo_Ahn1;rddelosreyes@kaist.ac.kr;~Jinwoo_Shin1;~Yung_Yi1,6;6;4;7,4;2;4;3,Reject,0,9,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Mohamed Bin Zayed University of Artificial Intelligence;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,multi-agent reinforcement learning,-1;-1;-1;-1;-1,96;874;96;96;96,u;m,NAN,NAN,n,
7015,ICLR,2021,D3C: Reducing the Price of Anarchy in Multi-Agent Learning,Ian Gemp;Kevin McKee;Richard Everett;Edgar Alfredo Duenez-Guzman;Yoram Bachrach;David Balduzzi;Andrea Tacchetti,~Ian_Gemp1;kevinrmckee@google.com;~Richard_Everett1;~Edgar_Alfredo_Duenez-Guzman1;~Yoram_Bachrach2;~David_Balduzzi1;~Andrea_Tacchetti1,6;6;3;7,2;3;3;3,Reject,0,8,0.0,yes,9/28/20,DeepMind;DeepMind;Google DeepMind;DeepMind;Google DeepMind;XTX Markets;DeepMind,multiagent;social dilemma;reinforcement learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
7016,ICLR,2021,How Important is Importance Sampling for Deep Budgeted Training?,Eric Arazo;Diego Ortego;Paul Albert;Noel O'Connor;Kevin McGuinness,~Eric_Arazo1;~Diego_Ortego2;~Paul_Albert2;~Noel_O'Connor1;~Kevin_McGuinness1,4;4;3;5,2;4;4;4,Reject,0,6,0.0,yes,9/28/20,Dublin City University;Dublin City University;Insight Centre for Data Analytics;Insight Centre for Data Analytics;Dublin City University,Budgeted training;importance sampling;data augmentation;deep learning,-1;-1;-1;-1;-1,560;560;-1;-1;560,m;m,NAN,NAN,n,2
7017,ICLR,2021,An Examination of Preference-based Reinforcement Learning for Treatment Recommendation,Nan Xu;Nitin Kamra;Yan Liu,~Nan_Xu2;~Nitin_Kamra1;~Yan_Liu1,4;4;4,4;4;3,Reject,0,9,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,Preference-based Reinforcement Learning;Treatment Recommendation;healthcare,37;37;37,53;53;53,f;f,usa,usa,n,
7018,ICLR,2021,TaskSet: A Dataset of Optimization Tasks,Luke Metz;Niru Maheswaranathan;Ruoxi Sun;C. Daniel Freeman;Ben Poole;Jascha Sohl-Dickstein,~Luke_Metz1;~Niru_Maheswaranathan1;~Ruoxi_Sun2;~C._Daniel_Freeman1;~Ben_Poole1;~Jascha_Sohl-Dickstein2,7;5;3;5,4;2;4;4,Reject,0,4,0.0,yes,9/28/20,Google;Facebook;Google;Google Research;Google;Google,optimizers;meta-learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;5;3;1;6
7019,ICLR,2021,Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets,Shixiang Wan;Shikai Luo;Hongtu Zhu,~Shixiang_Wan1;~Shikai_Luo1;~Hongtu_Zhu2,5;2;6;6,4;5;3;2,Reject,0,11,0.0,yes,9/28/20,"Didi Research;North Carolina State University;University of North Carolina, Chapel Hill",Spatio-temporal Prediction;Causal Inference;Efficient Transformers;Two-sided Markets,-1;92;64,-1;340;-1,m;m,NAN,NAN,n,8;10
7020,ICLR,2021,Automatic Music Production Using Generative Adversarial Networks,Giorgio Barnab√≤;Giovanni Trappolini;Lorenzo Lastilla;Cesare Campagnano;Angela Fan;Fabio Petroni;Fabrizio Silvestri,~Giorgio_Barnab√≤1;~Giovanni_Trappolini1;~Lorenzo_Lastilla1;campagnano.1615033@studenti.uniroma1.it;~Angela_Fan2;~Fabio_Petroni1;~Fabrizio_Silvestri2,5;4;2,4;3;5,Reject,0,3,0.0,yes,9/28/20,Sapienza University of Rome;Sapienza University of Rome;Sapienza University of Rome;Sapienza University of Rome;Facebook;Facebook;Sapienza University of Rome,music arrangement;generative adversarial networks;music generation,99;99;99;99;-1;-1;99,216;216;216;216;-1;-1;216,m;m,europe,it,n,5
7021,ICLR,2021,"CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients",Dani Kiyasseh;Tingting Zhu;David A. Clifton,~Dani_Kiyasseh1;tingting.zhu@eng.ox.ac.uk;~David_A._Clifton1,5;4;4;7,3;5;5;4,Reject,0,5,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,Contrastive learning;physiological signals;healthcare,46;46;46,1;1;1,m;m,europe,uk,n,1
7022,ICLR,2021,Learning Movement Strategies for Moving Target Defense,Sailik Sengupta;Subbarao Kambhampati,~Sailik_Sengupta1;~Subbarao_Kambhampati1,4;5;4;5,4;3;2;4,Reject,0,7,0.0,yes,9/28/20,Amazon;Arizona State University,Multi-agent Reinforcement Learning;Moving Target Defense;Stackelberg Security,-1;85,-1;182,m;m,usa,usa,y,11;4
7023,ICLR,2021,GENERATIVE MODEL-ENHANCED HUMAN MOTION PREDICTION,Anthony Bourached;Ryan-Rhys Griffiths;Robert Gray;Ashwani Jha;Parashkev Nachev,ucabab6@ucl.ac.uk;rrg27@cam.ac.uk;r.gray@ucl.ac.uk;ashwani.jha@ucl.ac.uk;p.nachev@ucl.ac.uk,5;3;4;5,4;5;3;4,Reject,0,4,0.0,yes,10/3/20,University College London;University of Cambridge;;;;;University College London,,53;79;-1;-1;-1;-1;53,-1;6;-1;-1;-1;-1;-1,m;m,europe,uk,n,5
7024,ICLR,2021,Removing Dimensional Restrictions on Complex/Hyper-complex Convolutions,Chase John Gaudet;Anthony S. Maida,~Chase_John_Gaudet1;~Anthony_S._Maida1,4;6;5;4,2;4;5;4,Reject,0,5,0.0,yes,9/28/20,University of Louisiana at Lafayette;University of Louisiana - Lafayette,CNNs;complex;hypercomplex,327;327,-1;-1,m;m,usa,usa,n,
7025,ICLR,2021,Effective Regularization Through Loss-Function Metalearning,Santiago Gonzalez;Risto Miikkulainen,~Santiago_Gonzalez1;~Risto_Miikkulainen1,7;5;8;3,3;4;4;3,Reject,0,9,0.0,yes,9/28/20,"University of Texas, Austin;The University of Texas, Austin",regularization;loss;loss function;metalearning;meta-learning;optimization;theory;robustness;adversarial attacks,-1;-1,-1;-1,m;m,NAN,NAN,y,4
7026,ICLR,2021,MeshMVS: Multi-view Stereo Guided Mesh Reconstruction,Rakesh Shrestha;Zhiwen Fan;Siyu Zhu;Zuozhuo Dai;Qingkun Su;Ping Tan,~Rakesh_Shrestha1;~Zhiwen_Fan1;~Siyu_Zhu1;~Zuozhuo_Dai1;~Qingkun_Su1;~Ping_Tan2,9;6;4,3;3;4,Reject,0,4,0.0,yes,9/28/20,"Simon Fraser University;Xiamen University;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology;;The Hong Kong University of Science and Technology;Simon Fraser University",Mesh Reconstruction;Multi-view Stereo;Deep Learning,58;-1;-1;-1;-1;58,271;527;56;-1;56;271,m;m,canada,ca,n,8;10
7027,ICLR,2021,Discriminative Representation Loss (DRL): A More Efficient Approach than Gradient Re-Projection in Continual Learning,Yu Chen;Tom Diethe;Peter Flach,~Yu_Chen10;~Tom_Diethe1;~Peter_Flach1,6;5;6,4;4;3,Reject,0,18,0.0,yes,9/28/20,University of Bristol;Amazon;University of Bristol,continual learning;episodic memory;GEM;experience replay;deep metric learning,110;-1;110,91;-1;91,f;m,europe,uk,y,
7028,ICLR,2021,"Waste not, Want not: All-Alive Pruning for Extremely Sparse Networks",Daejin Kim;Hyunjung Shim;Jongwuk Lee,~Daejin_Kim1;~Hyunjung_Shim1;~Jongwuk_Lee1,5;5;7;4,3;4;3;4,Reject,0,4,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Yonsei University;Sungkyunkwan University,Model compression;Network pruning;Iterative pruning;Dead connections,-1;150;-1,96;186;100,m;m,NAN,NAN,n,
7029,ICLR,2021,Unifying Regularisation Methods for Continual Learning,Frederik Benzing,~Frederik_Benzing1,5;6;3;5,4;5;4;3,Reject,0,17,0.0,yes,9/28/20,Swiss Federal Institute of Technology,Continual Learning;Regularisation;Fisher Information,-1,-1,m,NAN,NAN,n,
7030,ICLR,2021,Fine-grained Synthesis of Unrestricted Adversarial Examples,Omid Poursaeed;Tianxing Jiang;Yordanos Abraham Goshu;Harry Yang;Serge Belongie;Ser-Nam Lim,~Omid_Poursaeed2;tj258@cornell.edu;~Yordanos_Abraham_Goshu1;harryyang@fb.com;~Serge_Belongie1;~Ser-Nam_Lim3,7;6;6;4,3;3;2;5,Reject,0,5,0.0,yes,9/28/20,Cornell University;;;Cornell University;Facebook;Cornell University;Facebook,adversarial examples;unrestricted attacks;generative models;adversarial training;generative adversarial networks,7;-1;-1;7;-1;7;-1,19;-1;-1;19;-1;19;-1,m;m,NAN,NAN,n,2;5;4
7031,ICLR,2021,LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning,Yuhuai Wu;Markus Norman Rabe;Wenda Li;Jimmy Ba;Roger Baker Grosse;Christian Szegedy,~Yuhuai_Wu1;~Markus_Norman_Rabe1;~Wenda_Li1;~Jimmy_Ba1;~Roger_Baker_Grosse1;~Christian_Szegedy1,7;6;8;6,4;2;4;4,Reject,0,15,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Google;University of Cambridge;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Google",Theorem proving;Pre-training;Inductive bias;Reasoning.,18;-1;79;18;18;-1,18;-1;6;18;18;-1,m;m,NAN,NAN,n,8
7032,ICLR,2021,Maximum Reward Formulation In Reinforcement Learning,SaiKrishna Gottipati;Yashaswi Pathak;Rohan Nuttall;. Sahir;Raviteja Chunduru;Ahmed Touati;Sriram Ganapathi Subramanian;Matthew E. Taylor;Sarath Chandar,~SaiKrishna_Gottipati1;~Yashaswi_Pathak1;rnuttall@ualberta.ca;~._Sahir1;~Raviteja_Chunduru1;~Ahmed_Touati1;~Sriram_Ganapathi_Subramanian1;~Matthew_E._Taylor2;~Sarath_Chandar1,5;5;6;3;4,3;3;3;4;3,Reject,0,12,0.0,yes,9/28/20,AI Redefined Inc;International Institute of Information Technology Hyderabad;University of Alberta;University of Alberta;McGill University;University of Montreal;University of Waterloo;University of Alberta;Polytechnique Montreal,Reinforcement Learning;Theoretical Reinforcement Learning;Drug Discovery;Molecule Generation;de novo drug design,-1;-1;110;110;99;128;34;110;327,-1;-1;131;131;40;73;232;131;-1,m;m,canada,ca,n,1
7033,ICLR,2021,Learnable Uncertainty under Laplace Approximations,Agustinus Kristiadi;Matthias Hein;Philipp Hennig,~Agustinus_Kristiadi1;~Matthias_Hein2;~Philipp_Hennig1,7;4;4;6,3;4;2;4,Reject,0,8,0.0,yes,9/28/20,University of Tuebingen;University of T√ºbingen;University of Tuebingen,Bayesian deep learning;Laplace approximations;uncertainty quantification,128;128;128,78;78;78,u;m,europe,de,y,11
7034,ICLR,2021,Learning a Non-Redundant Collection of Classifiers,Daniel Pace;Alessandra Russo;Murray Shanahan,~Daniel_Pace1;~Alessandra_Russo1;~Murray_Shanahan1,4;4;5;6,3;4;4;3,Reject,0,7,0.0,yes,9/28/20,Imperial College London;Imperial College London;Google,,53;53;-1,11;11;-1,m;m,NAN,NAN,n,
7035,ICLR,2021,Non-iterative Parallel Text Generation via Glancing Transformer,Lihua Qian;Hao Zhou;Yu Bao;Mingxuan Wang;Lin Qiu;Weinan Zhang;Yong Yu;Lei Li,~Lihua_Qian1;zhouhao.nlp@bytedance.com;~Yu_Bao1;~Mingxuan_Wang1;lqiu@apex.sjtu.edu.cn;~Weinan_Zhang1;~Yong_Yu1;~Lei_Li11,5;5;7;6,4;4;5;3,Reject,0,9,0.0,yes,9/28/20,Shanghai Jiao Tong University;Bytedance;nanjing university;;;;Shanghai Jiao Tong University;;ByteDance AI Lab,,29;-1;52;-1;-1;-1;29;-1;-1,100;-1;111;-1;-1;-1;100;-1;-1,u;m,NAN,NAN,n,8;3
7036,ICLR,2021,Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting,Giorgos Bouritsas;Fabrizio Frasca;Stefanos Zafeiriou;Michael M. Bronstein,~Giorgos_Bouritsas1;~Fabrizio_Frasca1;~Stefanos_Zafeiriou1;~Michael_M._Bronstein1,5;4;6;3,5;4;4;5,Reject,0,9,0.0,yes,9/28/20,Imperial College London;Imperial College London;Imperial College London;Twitter,graph neural networks;graph representation learning;network analysis;network motifs;subgraph isomoprhism,53;53;53;-1,11;11;11;-1,m;m,NAN,NAN,y,10
7037,ICLR,2021,Explicit homography estimation improves contrastive self-supervised learning,David Torpey;Richard Klein,~David_Torpey1;~Richard_Klein1,4;4;4;4,5;3;4;3,Reject,0,8,0.0,yes,9/28/20,University of the Witwatersrand;University of the Witwatersrand,,-1;-1,206;206,m;m,NAN,NAN,n,
7038,ICLR,2021,LAYER SPARSITY IN NEURAL NETWORKS,Mohamed Hebiri;Johannes Lederer,mohamed.hebiri@univ-eiffel.fr;~Johannes_Lederer1,5;5;6;4,3;3;3;5,Reject,0,5,0.0,yes,9/28/20,Universit√© Gustave Eiffel;Ruhr-Universt√§t Bochum,,-1;-1,-1;-1,m;m,NAN,NAN,y,
7039,ICLR,2021,Sparse Linear Networks with a Fixed Butterfly Structure: Theory and Practice,Nir Ailon;Omer Leibovitch;Vineet Sreedharan Nair,~Nir_Ailon1;~Omer_Leibovitch1;~Vineet_Sreedharan_Nair1,6;5;7;5,3;3;5;5,Reject,0,6,0.0,yes,9/28/20,"Technion, Technion;Technion, Technion;Computer Science Departmen, Technion-Israel Institute of Technology",Butterfly Network;Matrix approximation;Encoder-Decoder Network;Optimization Landscape,29;29;29,-1;-1;-1,m;m,NAN,NAN,y,3
7040,ICLR,2021,Variational Multi-Task Learning,Jiayi Shen;Xiantong Zhen;Marcel Worring;Ling Shao,~Jiayi_Shen3;~Xiantong_Zhen1;~Marcel_Worring1;~Ling_Shao1,8;5;7;7,5;4;3;3,Reject,0,5,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam;University of Amsterdam;Inception Institute of Artificial Intelligence,multi-task learning;variational Bayesian inference;Gumbel-softmax priors,128;128;128;-1,66;66;66;-1,f;m,NAN,NAN,n,11
7041,ICLR,2021,Improved Communication Lower Bounds for Distributed Optimisation,Janne H. Korhonen;Dan Alistarh,~Janne_H._Korhonen2;~Dan_Alistarh7,6;5;5,3;3;2,Reject,0,4,0.0,yes,9/28/20,Institute of Science and Technology Austria;Institute of Science and Technology Austria,distributed optimization;lower bounds;upper bounds;communication complexity,-1;-1,-1;-1,m;m,NAN,NAN,y,
7042,ICLR,2021,Shape-Tailored Deep Neural Networks Using PDEs for Segmentation,Naeemullah Khan;Angira Sharma;Philip Torr;Ganesh Sundaramoorthi,~Naeemullah_Khan1;~Angira_Sharma1;~Philip_Torr1;~Ganesh_Sundaramoorthi1,6;6;5;6;6,3;4;3;4;4,Reject,0,6,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford;KAUST,robustness;covariance;invariance;convolutional neural nets;PDEs;segmentation,46;46;46;110,1;1;1;-1,m;m,europe,gr,y,2
7043,ICLR,2021,Sufficient and Disentangled Representation Learning,Jian Huang;Yuling Jiao;Xu Liao;Jin Liu;Zhou Yu,~Jian_Huang5;yulingjiaomath@whu.edu.cn;liaoxu@u.duke.nus.edu;jin.liu@duke-nus.edu.sg;zyu@stat.ecnu.edu.cn,5;6;7;4,4;4;4;5,Reject,0,4,0.0,yes,9/28/20,University of Iowa;Wuhan University;;National University of Singapore;East China Normal University,Conditional independence;f-divergence;rotation invariant;neural network;statistical guarantee,174;209;-1;17;-1,245;323;-1;25;387,m;m,NAN,NAN,y,1
7044,ICLR,2021,Multi-modal Self-Supervision from Generalized Data Transformations,Mandela Patrick;Yuki Asano;Polina Kuznetsova;Ruth Fong;Joao F. Henriques;Geoffrey Zweig;Andrea Vedaldi,~Mandela_Patrick1;~Yuki_Asano1;p0lina@fb.com;~Ruth_Fong1;~Joao_F._Henriques1;gzweig@fb.com;~Andrea_Vedaldi1,7;6;7;4,4;4;4;3,Reject,0,15,0.0,yes,9/28/20,University of Oxford;University of Oxford;;;University of Oxford;University of Oxford;;;U Oxford,video representation learning;multi-modal learning;self-supervised learning;audio-visual learning;noise-contrastive learning,46;46;-1;-1;46;46;-1;-1;-1,1;1;-1;-1;1;1;-1;-1;-1,m;m,NAN,NAN,n,
7045,ICLR,2021,Whitening for Self-Supervised Representation Learning,Aleksandr Ermolov;Aliaksandr Siarohin;Enver Sangineto;Nicu Sebe,~Aleksandr_Ermolov1;~Aliaksandr_Siarohin1;~Enver_Sangineto1;~Nicu_Sebe1,5;6;7;5,4;3;4;4,Reject,0,5,0.0,yes,9/28/20,University of Trento;Snap Inc.;University of Trento;University of Trento,self-supervised learning;unsupervised learning;contrastive loss;triplet loss;whitening,150;-1;150;150,343;-1;343;343,m;m,europe,gr,n,
7046,ICLR,2021,Variance Reduction in Hierarchical Variational Autoencoders,Adeel Pervez;Efstratios Gavves,~Adeel_Pervez1;~Efstratios_Gavves1,6;4;4,3;4;4,Reject,0,16,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam,,128;128,66;66,u;m,europe,nl,n,5
7047,ICLR,2021,Cross-Modal Retrieval Augmentation for Multi-Modal Classification,Shir Gur;Natalia Neverova;Chris Stauffer;Ser-Nam Lim;Douwe Kiela;Austin Reiter,~Shir_Gur1;~Natalia_Neverova1;~Chris_Stauffer2;~Ser-Nam_Lim3;~Douwe_Kiela1;~Austin_Reiter3,5;4;3,5;5;5,Reject,0,4,0.0,yes,9/28/20,"School of Computer Science, Tel Aviv University;Facebook AI Research (FAIR);Facebook;Facebook;Facebook AI Research;Facebook",Multi-Modal;VQA;Retrieval,34;-1;-1;-1;-1;-1,190;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
7048,ICLR,2021,Multi-scale Network Architecture Search for Object Detection,Yuxin Yue;Quanquan Li;Yujie Wang,~Yuxin_Yue1;~Quanquan_Li1;~Yujie_Wang2,4;5;4;3,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,Beihang University;SenseTime Group Limited;SenseTime Research,Object Detection;Neural Architecture Search,99;-1;-1,567;-1;-1,u;m,NAN,NAN,n,2
7049,ICLR,2021,Controllable Pareto Multi-Task Learning,Xi Lin;Zhiyuan YANG;Qingfu Zhang;Sam Kwong,~Xi_Lin2;~Zhiyuan_YANG1;qingfu.zhang@cityu.edu.hk;~Sam_Kwong1,7;4;5,4;5;4,Reject,0,13,0.0,yes,9/28/20,City University of Hong Kong;City University of Hong Kong;City University of Hong Kong;City University of Hong Kong,Multi-Task Learning;Multi-Objective Optimization,128;128;128;128,126;126;126;126,u;m,asia,hk,n,
7050,ICLR,2021,Maximum Entropy competes with Maximum Likelihood,Armen Allahverdyan,~Armen_Allahverdyan1,4;4;6;3,3;5;4;4,Reject,0,5,0.0,yes,9/28/20,Alikhanyan National Laboratory,maximum entropy;Bayesian statistics,-1,-1,m,NAN,NAN,n,11;1
7051,ICLR,2021,Towards Defending Multiple Adversarial Perturbations via Gated Batch Normalization,Aishan Liu;Shiyu Tang;Xianglong Liu;Xinyun Chen;Lei Huang;Zhuozhuo Tu;Dawn Song;Dacheng Tao,~Aishan_Liu1;~Shiyu_Tang1;~Xianglong_Liu2;~Xinyun_Chen1;~Lei_Huang1;~Zhuozhuo_Tu1;~Dawn_Song1;~Dacheng_Tao1,6;6;5,3;4;4,Reject,0,7,0.0,yes,9/28/20,Beihang University;Beihang University;Beihang University;University of California Berkeley;Beihang University;The University of Sydney;University of California Berkeley;JD.com,adversarial examples;multiple adversarial peturbation types;adversarial robustness,99;99;99;-1;99;71;-1;-1,567;567;567;7;567;51;7;-1,m;m,NAN,NAN,n,4
7052,ICLR,2021,GraphSAD: Learning Graph Representations with Structure-Attribute Disentanglement,Minghao Xu;Hang Wang;Bingbing Ni;Wenjun Zhang;Jian Tang,~Minghao_Xu1;~Hang_Wang1;~Bingbing_Ni3;~Wenjun_Zhang3;~Jian_Tang1,3;6;8;4,3;4;5;4,Reject,0,8,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Shanghai Jiao Tong University;Shanghai Jiao Tong University;;Shanghai Jiaotong University;HEC Montreal",Graph Representation Learning;Disentangled Representation Learning,128;29;29;-1;29;-1,73;100;100;-1;100;-1,m;m,canada,ca,y,10
7053,ICLR,2021,Overinterpretation reveals image classification model pathologies,Brandon Carter;Siddhartha Jain;Jonas Mueller;David Gifford,~Brandon_Carter1;~Siddhartha_Jain1;~Jonas_Mueller1;~David_Gifford1,5;6;2;3,4;3;4;5,Reject,0,6,0.0,yes,9/28/20,Massachusetts Institute of Technology;Amazon;Amazon;Massachusetts Institute of Technology,computer vision;benchmarks;datasets;convolutional neural networks;interpretability;robustness;overinterpretation,5;-1;-1;5,4;-1;-1;4,m;m,usa,usa,n,4
7054,ICLR,2021,Ranking Cost: One-Stage Circuit Routing by Directly Optimizing Global Objective Function,Shiyu Huang;Bin Wang;Dong Li;Jianye Hao;Jun Zhu;Ting Chen,~Shiyu_Huang2;~Bin_Wang12;lidong106@huawei.com;haojianye@huawei.com;~Jun_Zhu2;tingchen@tsinghua.edu.cn,6;5;5;5,3;3;4;3,Reject,0,14,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Huawei Noah's Ark Lab;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;;;Tsinghua University;Tsinghua University",Evolution Strategy;Circuit Routing;A*;PCB,4;-1;34;-1;-1;4;4,20;-1;-1;-1;-1;20;20,m;m,asia,cn,n,
7055,ICLR,2021,VEM-GCN: Topology Optimization with Variational EM for Graph Convolutional Networks,Rui Yang;Wenrui Dai;Chenglin Li;Junni Zou;Hongkai Xiong,~Rui_Yang7;~Wenrui_Dai1;~Chenglin_Li2;~Junni_Zou1;~Hongkai_Xiong1,6;8;6;6,5;4;5;4,Reject,0,8,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;;Shanghai Jiaotong University;Shanghai Jiao Tong University,Graph Convolutional Networks;Over-smoothing;Topology Optimization;Stochastic Block Model;Variational EM,29;29;29;-1;29;29,100;100;100;-1;100;100,m;m,asia,cn,n,10
7056,ICLR,2021,Learning the Step-size Policy for the Limited-Memory Broyden-Fletcher-Goldfarb-Shanno Algorithm,Lucas N. Egidio;Anders Hansson;Bo Wahlberg,~Lucas_N._Egidio1;anders.g.hansson@liu.se;~Bo_Wahlberg1,4;4;5;5,4;3;4;3,Reject,0,5,0.0,yes,9/28/20,"Link√∂ping University;;;KTH Royal Institute of Technology, Stockholm, Sweden",Unconstrained optimization;Step-size policy;L-BFGS;Learned optimizers,-1;-1;-1;174,410;-1;-1;239,m;m,NAN,NAN,n,
7057,ICLR,2021,Temporal Difference Uncertainties as a Signal for Exploration,Sebastian Flennerhag;Jane X Wang;Pablo Sprechmann;Francesco Visin;Alexandre Galashov;Steven Kapturowski;Diana L Borsa;Nicolas Heess;Andre Barreto;Razvan Pascanu,~Sebastian_Flennerhag1;~Jane_X_Wang1;~Pablo_Sprechmann1;~Francesco_Visin1;~Alexandre_Galashov1;~Steven_Kapturowski1;~Diana_L_Borsa1;~Nicolas_Heess1;~Andre_Barreto1;~Razvan_Pascanu1,5;5;5;7,4;2;3;4,Reject,0,5,0.0,yes,9/28/20,DeepMind;DeepMind;DeepMind;Politecnico di Milano;Ecole Polytechnique;DeepMind;DeepMind/Google;Google;DeepMind;Google DeepMind,deep reinforcement learning;deep-rl;exploration,-1;-1;-1;150;-1;-1;-1;-1;-1;-1,-1;-1;-1;370;89;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,10
7058,ICLR,2021,K-PLUG: KNOWLEDGE-INJECTED PRE-TRAINED LANGUAGE MODEL FOR NATURAL LANGUAGE UNDERSTANDING AND GENERATION,Song Xu;Haoran Li;Peng Yuan;Yujia Wang;Youzheng Wu;Xiaodong He;Ying Liu;Bowen Zhou,xusong28@jd.com;~Haoran_Li1;yuanpeng29@jd.com;wangyujia15@jd.com;~Youzheng_Wu2;~Xiaodong_He1;liu.ying@ruc.edu.cn;~Bowen_Zhou1,5;6;5;4,4;4;4;3,Reject,0,8,0.0,yes,9/28/20,Microsoft;;JD AI Research;;;JD AI Research;JD AI Research;;;JD AI Research,,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
7059,ICLR,2021,Reinforcement Learning for Control with Probabilistic Stability Guarantee,Minghao Han;Zhipeng Zhou;Lixian Zhang;Jun Wang;Wei Pan,~Minghao_Han2;~Zhipeng_Zhou3;lixianzhang@hit.edu.cn;~Jun_Wang2;~Wei_Pan2,6;6;5;5,3;4;3;4,Reject,0,1,0.0,yes,9/28/20,"Swiss Federal Institute of Technology, Zurich;Alibaba Group;;;University College London;Delft University of Technology",control;Lyapunov stability;REINFORCE;finite-sample bounds,-1;-1;-1;-1;53;-1,-1;-1;-1;-1;-1;78,m;m,NAN,NAN,y,1
7060,ICLR,2021,Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness,Pratyush Maini;Xinyun Chen;Bo Li;Dawn Song,~Pratyush_Maini1;~Xinyun_Chen1;~Bo_Li19;~Dawn_Song1,6;4;6;4,4;3;3;4,Reject,0,8,0.0,yes,9/28/20,"Indian Institute of Technology Delhi;University of California Berkeley;University of Illinois, Urbana Champaign;University of California Berkeley",adversarial examples;robustness;multiple perturbation types,-1;-1;-1;-1,-1;7;-1;7,m;f,usa,usa,y,4
7061,ICLR,2021,Cross-State Self-Constraint for Feature Generalization in Deep Reinforcement Learning,Guan Ting Liu;Pu-Jen Cheng;GuanYu Lin,~Guan_Ting_Liu1;~Pu-Jen_Cheng1;r09944017@csie.ntu.edu.tw,5;6;5;5,4;3;4;4,Reject,0,8,0.0,yes,9/28/20,Department of computer science and informational engineering  National Taiwan University;National Taiwan University;;Department of computer science and informational engineering,reinforcement learning;generalization;regularization,99;99;-1;-1,-1;97;-1;-1,u;u,NAN,NAN,n,1
7062,ICLR,2021,Rethinking the Pruning Criteria for Convolutional Neural Network,Zhongzhan Huang;Xinjiang Wang;Ping Luo,~Zhongzhan_Huang1;~Xinjiang_Wang1;~Ping_Luo2,4;5;5;3,4;4;4;5,Reject,0,7,0.0,yes,9/28/20,Sun Yat-Sen University;SenseTime Group;The University of Hong Kong,Pruning Criteria;Similarity;Convolution;Weight Distribution,128;-1;99,293;-1;39,m;m,NAN,NAN,y,
7063,ICLR,2021,End-to-End on-device Federated Learning: A case study,Hongyi Zhang;Jan Bosch;Helena Holmstr√∂m Olsson,~Hongyi_Zhang4;jan.bosch@chalmers.se;helena.holmstrom.olsson@mau.se,6;4;4;2,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,Chalmers University;;;;MalmÀÜ University,Federated Learning;Machine Learning;End-to-End Learning;Artificial Intelligence,-1;-1;-1;-1;-1,235;-1;-1;-1;-1,m;f,NAN,NAN,n,
7064,ICLR,2021,The Unbalanced Gromov Wasserstein Distance: Conic Formulation and Relaxation,Thibault Sejourne;Fran√ßois-Xavier Vialard;Gabriel Peyr√©,~Thibault_Sejourne2;~Fran√ßois-Xavier_Vialard2;~Gabriel_Peyr√©2,6;7;5;6,4;4;5;4,Reject,0,8,0.0,yes,9/28/20,Ecole Normale Superieure;Universit√© Paris-Est;ENS,Gromov-Wasserstein;Non-convex optimization;Optimal Transport;Partial matching,128;-1;92,-1;-1;62,m;m,asia,in,y,10;3;5;9
7065,ICLR,2021,Powers of layers for image-to-image translation,Hugo Touvron;Matthijs Douze;Matthieu Cord;Herve Jegou,~Hugo_Touvron1;~Matthijs_Douze1;~Matthieu_Cord1;~Herve_Jegou1,3;5;5;5,3;4;4;4,Reject,0,4,0.0,yes,9/28/20,Facebook;Facebook;Sorbonne University;Facebook,,-1;-1;-1;-1,-1;-1;87;-1,m;m,NAN,NAN,n,
7066,ICLR,2021,Explicit Pareto Front Optimization for Constrained Reinforcement Learning,Sandy Huang;Abbas Abdolmaleki;Philemon Brakel;Steven Bohez;Nicolas Heess;Martin Riedmiller;raia hadsell,~Sandy_Huang1;~Abbas_Abdolmaleki3;~Philemon_Brakel1;~Steven_Bohez1;~Nicolas_Heess1;~Martin_Riedmiller1;~raia_hadsell1,7;6;4,3;2;3,Reject,0,7,0.0,yes,9/28/20,DeepMind;Google;Google/DeepMind;DeepMind;Google;;Google,constrained reinforcement learning;multi-objective reinforcement learning;continuous control;deep reinforcement learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,f;f,NAN,NAN,n,
7067,ICLR,2021,Towards Understanding Linear Value Decomposition in Cooperative Multi-Agent Q-Learning,Jianhao Wang;Zhizhou Ren;Beining Han;Jianing Ye;Chongjie Zhang,~Jianhao_Wang1;~Zhizhou_Ren1;~Beining_Han1;~Jianing_Ye1;~Chongjie_Zhang1,6;5;5;5,4;4;5;4,Reject,0,7,0.0,yes,9/28/20,"Tsinghua University;University of Illinois, Urbana Champaign;Tsinghua University;Peking University;Tsinghua University",Multi-agent reinforcement learning;Fitted Q-iteration;Value factorization;Credit assignment,4;-1;4;14;4,20;-1;20;23;20,m;m,asia,cn,y,
7068,ICLR,2021,A Maximum Mutual Information Framework for Multi-Agent Reinforcement Learning,Woojun Kim;Whiyoung Jung;Myungsik Cho;Youngchul Sung,~Woojun_Kim1;~Whiyoung_Jung1;ms.cho@kaist.ac.kr;~Youngchul_Sung1,6;3;5;6,3;4;4;4,Reject,0,7,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Multi-agent reinforcement learning;coordination;mutual information,-1;-1;-1;-1,96;96;96;96,m;m,NAN,NAN,n,1
7069,ICLR,2021,Offline Adaptive Policy Leaning in Real-World Sequential Recommendation Systems,Xiong-Hui Chen;Yang Yu;Qingyang Li;Zhiwei Tony Qin;Wenjie Shang;Yiping Meng;Jieping Ye,~Xiong-Hui_Chen1;~Yang_Yu5;~Qingyang_Li4;~Zhiwei_Tony_Qin1;shangwenjie@didiglobal.com;~Yiping_Meng1;~Jieping_Ye3,4;4;7;7,4;4;3;2,Reject,0,7,0.0,yes,9/28/20,Nanjing University;Nanjing University;Didi AI Labs;Columbia University;Nanjing University;Institute of automation  Chinese academy of science  Chinese Academy of Sciences;University of Michigan,Reinforcement learning;Recommendation system,52;52;-1;23;52;34;7,111;111;-1;17;111;-1;22,u;m,usa,usa,y,
7070,ICLR,2021,Byzantine-Robust Learning on Heterogeneous Datasets via Resampling,Lie He;Sai Praneeth Karimireddy;Martin Jaggi,~Lie_He1;~Sai_Praneeth_Karimireddy1;~Martin_Jaggi1,6;7;5,4;3;3,Reject,0,6,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;EPFL,Byzantine robustness;distributed training;heterogeneous dataset,-1;-1;23,-1;-1;-1,u;m,europe,ch,y,8;4
7071,ICLR,2021,Rethinking Compressed Convolution Neural Network from a Statistical Perspective,Feiqing Huang;Yuefeng Si;Guodong Li,~Feiqing_Huang1;yuefeng_si@hku.hk;gdli@hku.hk,6;5;5,3;3;4,Reject,0,11,0.0,yes,9/28/20,The University of Hong Kong;The University of Hong Kong;The University of Hong Kong,Compressed Convolutional Neural Network;Tensor Decomposition;Sample Complexity Analysis,99;99;99,39;39;39,f;m,NAN,NAN,y,
7072,ICLR,2021,Extract Local Inference Chains of Deep Neural Nets,Haiyan Zhao;Tianyi Zhou;Guodong Long;Jing Jiang;Chengqi Zhang,~Haiyan_Zhao2;~Tianyi_Zhou1;~Guodong_Long2;~Jing_Jiang6;~Chengqi_Zhang1,6;5;6;6,4;2;3;3,Reject,0,7,0.0,yes,9/28/20,University of Technology Sydney;University of Washington;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,Model Interpretability;Model Pruning;Attribution;Model Visualization,71;11;71;71;71,160;29;160;160;160,u;m,australasia,au,n,
7073,ICLR,2021,A Simple Approach To Define Curricula For Training Neural Networks,Vinu Sankar Sadasivan;Anirban Dasgupta,~Vinu_Sankar_Sadasivan1;~Anirban_Dasgupta1,3;3;4;4,4;4;5;3,Reject,0,5,0.0,yes,9/28/20,IIT Gandhinagar;IIT Gandhinagar,Curriculum learning;neural networks,327;327,-1;-1,m;m,asia,in,n,1
7074,ICLR,2021,Class Imbalance in Few-Shot Learning,Mateusz Ochal;Massimiliano Patacchiola;Jose Vazquez;Amos Storkey;Sen Wang,~Mateusz_Ochal1;~Massimiliano_Patacchiola1;jose.vazquez@seebyte.com;~Amos_Storkey1;~Sen_Wang7,4;5;5;5,5;3;3;3,Reject,0,7,0.0,yes,9/28/20,Heriot-Watt University;University of Cambridge;University of Edinburgh;University of Edinburgh;Heriot-Watt University,few-shot learning;class imbalance,209;79;29;29;209,375;6;30;30;375,m;m,europe,uk,n,6
7075,ICLR,2021,Hippocampal representations emerge when training recurrent neural networks on a memory dependent maze navigation task,Justin Jude;Matthias Hennig,~Justin_Jude1;m.hennig@ed.ac.uk,5;7;4;7,5;4;4;4,Reject,0,10,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh,recurrent neural network;place cell;hippocampus;neural dynamics,29;29,30;30,m;m,europe,uk,n,
7076,ICLR,2021,Learning to Share in Multi-Agent Reinforcement Learning,Yuxuan Yi;Ge Li;Yaowei Wang;Zongqing Lu,~Yuxuan_Yi1;~Ge_Li2;~Yaowei_Wang1;~Zongqing_Lu2,8;4;4;8;3,3;4;4;3;4,Reject,0,7,0.0,yes,9/28/20,Peking University Shenzhen Graduate School;Peking University Shenzhen Graduate School;Pengcheng Laboratory;Peking University,,14;14;-1;14,23;23;-1;23,u;m,asia,cn,y,
7077,ICLR,2021,Grey-box Extraction of Natural Language Models,Santiago Zanella-Beguelin;Shruti Tople;Andrew Paverd;Boris K√∂pf,~Santiago_Zanella-Beguelin1;~Shruti_Tople2;andrew.paverd@microsoft.com;~Boris_K√∂pf1,5;4;7;3,4;5;4;4,Reject,0,7,0.0,yes,9/28/20,Microsoft;Microsoft Research;Microsoft;Microsoft,language models;transformer;model extraction;security,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,8;3;4
7078,ICLR,2021,Bounded Myopic Adversaries for Deep Reinforcement Learning Agents,Ezgi Korkmaz;Henrik Sandberg;Gyorgy Dan,~Ezgi_Korkmaz1;hsan@kth.se;gyuri@kth.se,5;6;6;6,4;3;4;4,Reject,0,13,0.0,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden;;;KTH Royal Institute of Technology, Stockholm, Sweden",deep reinforcement learning;adversarial,174;-1;-1;174,239;-1;-1;239,m;m,NAN,NAN,n,4
7079,ICLR,2021,Weak NAS Predictor Is All You Need,Junru Wu;Xiyang Dai;Dongdong Chen;Yinpeng Chen;Mengchen Liu;Ye Yu;Zhangyang Wang;Zicheng Liu;Mei Chen;Lu Yuan,~Junru_Wu2;~Xiyang_Dai2;~Dongdong_Chen1;~Yinpeng_Chen1;~Mengchen_Liu2;~Ye_Yu2;~Zhangyang_Wang1;~Zicheng_Liu1;~Mei_Chen2;~Lu_Yuan1,6;4;6;6,3;4;3;3,Reject,0,6,0.0,yes,9/28/20,"Texas A&M;Microsoft;Microsoft Research;Microsoft;Tsinghua University, Tsinghua University;Microsoft;University of Texas, Austin;Microsoft;Microsoft;Microsoft",performance predictor;neural architecture search,46;-1;-1;-1;4;-1;-1;-1;-1;-1,195;-1;-1;-1;20;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7080,ICLR,2021,Quantum Deformed Neural Networks,Roberto Bondesan;Max Welling,~Roberto_Bondesan1;~Max_Welling1,5;6;4;6;4,4;4;4;4;4,Reject,0,5,0.0,yes,9/28/20,"Qualcomm AI Research;Donald Bren School of Information and Computer Sciences, University of California, Irvine",Quantum machine learning;Binary neural networks;Bayesian deep learning,-1;-1,-1;98,m;m,NAN,NAN,n,
7081,ICLR,2021,Predictive Coding Approximates Backprop along Arbitrary Computation Graphs,Beren Millidge;Alexander Tschantz;Christopher Buckley,~Beren_Millidge1;~Alexander_Tschantz1;~Christopher_Buckley1,6;4;7;6,4;4;3;4,Reject,0,8,0.0,yes,9/28/20,University of Edinburgh;University of Sussex;University of Sussex,Predictive Coding;Backprop;Biological plausibility;neural networks,29;327;327,30;160;160,m;m,europe,uk,n,1;10
7082,ICLR,2021,Deep Learning Solution of the Eigenvalue Problem for Differential Operators,Ido Ben-Shaul;Leah Bar;Nir Sochen,~Ido_Ben-Shaul1;~Leah_Bar2;~Nir_Sochen1,3;4;4;9,3;5;2;2,Reject,0,5,0.0,yes,9/28/20,DeePathology;Tel Aviv University;Tel Aviv University,Eigenvalue problem;Unsupervised learning;Laplacian operator,-1;34;34,-1;190;190,m;m,europe,il,n,2
7083,ICLR,2021,Saliency Grafting: Innocuous Attribution-Guided Mixup with Calibrated Label Mixing,Joonhyung Park;June Yong Yang;Jinwoo Shin;Sung Ju Hwang;Eunho Yang,~Joonhyung_Park1;~June_Yong_Yang1;~Jinwoo_Shin1;~Sung_Ju_Hwang1;~Eunho_Yang1,6;5;7,4;4;4,Reject,0,15,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology,Deep learning;Data augmentation;Input attribution,-1;-1;-1;-1;-1,96;96;96;96;-1,m;m,NAN,NAN,n,8
7084,ICLR,2021,Secure Federated Learning of User Verification Models,Hossein Hosseini;Hyunsin Park;Sungrack Yun;Christos Louizos;Joseph Soriaga;Max Welling,~Hossein_Hosseini4;hyunsinp@qti.qualcomm.com;~Sungrack_Yun1;~Christos_Louizos1;jsoriaga@qti.qualcomm.com;mwelling@qti.qualcomm.com,6;2;7;8,4;4;5;3,Reject,0,8,0.0,yes,9/28/20,Qualcomm Inc  QualComm;QualComm;QualComm;Qualcomm Inc  QualComm;;;;University of Amsterdam,Federated learning;User verification models,-1;-1;-1;-1;-1;-1;-1;128,-1;-1;-1;-1;-1;-1;-1;66,m;m,europe,nl,y,
7085,ICLR,2021,Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets,Depen Morwani;Harish Guruprasad Ramaswamy,~Depen_Morwani1;~Harish_Guruprasad_Ramaswamy1,5;7;7;4,3;4;3;5,Reject,0,8,0.0,yes,9/28/20,"Indian Institute of Technology Madras;Indian Institute of Technology Madras,",Deep Learning Theory;Weight Normalization;Inductive Bias;Gradient Descent,-1;-1,-1;-1,m;m,NAN,NAN,y,9
7086,ICLR,2021,Drift Detection in Episodic Data: Detect When Your Agent Starts Faltering,Ido Greenberg;Shie Mannor,~Ido_Greenberg1;~Shie_Mannor2,5;5;6;6,3;4;3;3,Reject,0,6,0.0,yes,9/28/20,"Technion, Technion;Technion",Reinforcement learning reliability;Reinforcement learning stability;Drift detection;Degradation test;Bootstrapping,29;29,-1;408,m;m,europe,il,y,
7087,ICLR,2021,A Probabilistic Approach to Constrained Deep Clustering,Laura Manduchi;Kieran Chin-Cheong;Holger Michel;Sven Wellmann;Julia E Vogt,~Laura_Manduchi2;kieran.chincheong@inf.ethz.ch;holger.michel@barmherzige-regensburg.de;sven.wellmann@klinik.uni-regensburg.de;~Julia_E_Vogt1,5;4;5,5;4;5,Reject,0,8,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;University Children's Hospital Regensburg (KUNO), Department of Neonatology, Hospital St. Hedwig of the Order of St. John, University of Regensburg, Germany;;;Memorial Sloan Kettering Cancer Center",constrained clustering;semi-supervised representation learning;generative model;deep learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,f;f,NAN,NAN,n,8;5
7088,ICLR,2021,Fully Convolutional Approach for Simulating Wave Dynamics,Mario Lino Valencia;Chris D Cantwell;Eduardo Pignatelli;Stathi Fotiadis;Anil Anthony Bharath,~Mario_Lino_Valencia1;~Chris_D_Cantwell1;~Eduardo_Pignatelli1;~Stathi_Fotiadis1;~Anil_Anthony_Bharath2,5;4;7;3,4;4;4;4,Reject,0,3,0.0,yes,9/28/20,Imperial College London;Imperial College London;University College London;Imperial College London;Imperial College London,Convolutional neural network;spatio-temporal forecasting;data-driven physics;wave dynamics,53;53;53;53;53,11;11;-1;11;11,m;m,europe,uk,n,
7089,ICLR,2021,Improving the accuracy of neural networks in analog computing-in-memory systems by a generalized quantization method,Lingjun Dai;Qingtian Zhang;Huaqiang Wu,~Lingjun_Dai1;~Qingtian_Zhang1;~Huaqiang_Wu1,3;5;5;4,5;4;4;4,Reject,0,4,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",analog computing-in-memory;quantization algorithm;deep neural networks,4;4;4,20;20;20,u;u,NAN,NAN,n,2
7090,ICLR,2021,On Noise Injection in Generative Adversarial Networks,Ruili Feng;Deli Zhao;Zheng-Jun Zha,~Ruili_Feng1;~Deli_Zhao1;~Zheng-Jun_Zha2,7;6;6;7,2;3;3;4,Reject,0,6,0.0,yes,9/28/20,University of Science and Technology of China;Alibaba Group;University of Science and Technology of China,Generative Adversarial Networks;StyleGAN;learning theory,-1;-1;-1,87;-1;87,u;u,NAN,NAN,y,1;5;4
7091,ICLR,2021,Factoring out Prior Knowledge from Low-Dimensional Embeddings,Edith Heiter;Jonas Fischer;Jilles Vreeken,eheiter@mmci.uni-saarland.de;~Jonas_Fischer1;jv@cispa.de,5;6;5;5,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,Saarland University;;Max-Planck Institute for Informatics;CISPA Helmholtz Center for Information Security,embedding;visualization;prior;tsne;umap,92;-1;-1;99,-1;-1;-1;-1,f;m,NAN,NAN,n,
7092,ICLR,2021,"Laplacian Eigenspaces, Horocycles and Neuron Models on Hyperbolic Spaces",Ming-Xi Wang,~Ming-Xi_Wang1,8;5;5;4,4;5;2;3,Reject,0,8,0.0,yes,9/28/20,PAG,hyperbolic learning;hyperbolic neural network;Poincare embedding,-1,-1,u,asia,in,y,1
7093,ICLR,2021,Adversarial Synthetic Datasets for Neural Program Synthesis,Alexander Suh;Yuval Timen,~Alexander_Suh1;timen.yu@northeastern.edu,6;6;6;3,3;4;3;3,Reject,0,9,0.0,yes,9/28/20,Harvard University;;Northeastern University,Program Synthesis;Synthetic Data;Evolutionary Algorithm,53;-1;16,3;-1;895,m;m,usa,usa,n,4
7094,ICLR,2021,Out-of-distribution Prediction with Invariant Risk Minimization: The Limitation and An Effective Fix,Ruocheng Guo;Pengchuan Zhang;Hao Liu;Emre Kiciman,~Ruocheng_Guo1;~Pengchuan_Zhang1;~Hao_Liu2;~Emre_Kiciman1,7;4;6;4,4;5;3;4,Reject,0,15,0.0,yes,9/28/20,Arizona State University;California Institute of Technology;California Institute of Technology;Microsoft,Invariant Risk Minimization;Causal Machine Learning;Out-of-distribution Prediction,85;150;150;-1,182;4;4;-1,m;m,NAN,NAN,n,
7095,ICLR,2021,IALE: Imitating Active Learner Ensembles,Christoffer L√∂ffler;Christopher Mutschler,~Christoffer_L√∂ffler1;~Christopher_Mutschler1,4;5;6,4;4;3,Reject,0,4,0.0,yes,9/28/20,Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;Fraunhofer IIS,active learning;imitating learning;ensembles,-1;-1,-1;-1,m;m,NAN,NAN,n,
7096,ICLR,2021,Rewriting by Generating: Learn Heuristics for Large-scale Vehicle Routing Problems,Hansen Wang;Zefang Zong;Tong Xia;Shuyu Luo;Meng Zheng;Depeng Jin;Yong Li,~Hansen_Wang1;~Zefang_Zong1;~Tong_Xia1;syluo@hitachi.cn;mzheng@hitachi.cn;jindp@tsinghua.edu.cn;~Yong_Li3,6;4;6;7,3;5;5;5,Reject,0,8,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;Tsinghua University  Tsinghua University;Tsinghua University  Tsinghua University;;;;;;;Tsinghua University,vehicle routing problem;reinforcement learning;optimization,4;4;4;-1;-1;-1;-1;-1;-1;4,20;20;20;-1;-1;-1;-1;-1;-1;20,m;m,asia,cn,n,
7097,ICLR,2021,Distributed Associative Memory Network with Association Reinforcing Loss,Taewon Park;Inchul Choi;Minho Lee,~Taewon_Park1;~Inchul_Choi1;mholee@gmail.com,4;8;6;5;5,4;4;4;5;3,Reject,0,19,0.0,yes,9/28/20,Kyungpook National University;Kyungpook National University;Kyungpook National University,memory augmented neural network;distributed memory;memorization;relational reasoning,327;327;327,842;842;842,m;m,asia,kr,n,8
7098,ICLR,2021,Robust Multi-Agent Reinforcement Learning Driven by Correlated Equilibrium,Yizheng Hu;Kun Shao;Dong Li;Jianye HAO;Wulong Liu;Yaodong Yang;Jun Wang;Zhanxing Zhu,~Yizheng_Hu1;~Kun_Shao1;~Dong_Li10;~Jianye_HAO1;~Wulong_Liu1;~Yaodong_Yang1;~Jun_Wang2;~Zhanxing_Zhu1,5;4;3;6;4,4;3;4;3;3,Reject,0,5,0.0,yes,9/28/20,"Peking University;Huawei Noah's Ark Lab;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tianjin University;Huawei Noah's Ark Lab;King's College London;University College London;Peking University",Robust;Multi-agent;Reinforcement Learning;Correlated Equilibrium,14;-1;34;-1;-1;174;53;14,23;-1;-1;496;-1;35;-1;23,u;m,asia,cn,y,4
7099,ICLR,2021,Fourier Stochastic Backpropagation,Amine Echraibi;Joachim Flocon Cholet;St√©phane Gosselin;Sandrine Vaton,~Amine_Echraibi1;joachim.floconcholet@orange.com;stephane.gosselin@orange.com;sandrine.vaton@imt-atlantique.fr,10;6;5;5,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,T‚àö¬©l‚àö¬©com Bretagne;Orange;Orange Labs;;IMT Atlantique,Stochastic Backpropagation;Variational Inference;Probabilistic Graphical Models;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;358,m;f,NAN,NAN,y,
7100,ICLR,2021,Learning Hyperbolic Representations for Unsupervised 3D Segmentation,Joy Hsu;Jeffrey Gu;Gong Her Wu;Wah Chiu;Serena Yeung,~Joy_Hsu2;~Jeffrey_Gu1;wukon@stanford.edu;wahc@stanford.edu;~Serena_Yeung1,3;7;7;4,3;3;5;3,Reject,0,6,0.0,yes,9/28/20,Stanford University;Stanford University;;;Stanford University;Stanford University,unsupervised learning;representation learning;segmentation;biocomputing,5;5;-1;-1;5;5,2;2;-1;-1;2;2,f;f,usa,usa,n,2;5
7101,ICLR,2021,Dynamic Graph: Learning Instance-aware Connectivity for Neural Networks,Kun Yuan;Quanquan Li;Dapeng Chen;Aojun Zhou;Junjie Yan,~Kun_Yuan1;~Quanquan_Li1;~Dapeng_Chen4;~Aojun_Zhou2;~Junjie_Yan1,6;6;6;3,3;4;4;4,Reject,0,8,0.0,yes,9/28/20,SenseTime Research;SenseTime Group Limited;Electronic and Engineering;SenseTime Research;SenseTime Research,dynamic network;data-dependent;complete graph,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;u,NAN,NAN,n,2;1;10
7102,ICLR,2021,Relevance Attack on Detectors,Sizhe Chen;Fan He;Xiaolin Huang;Kun Zhang,~Sizhe_Chen1;hf-inspire@sjtu.edu.cn;~Xiaolin_Huang1;~Kun_Zhang1,4;4;5;6,3;4;3;4,Reject,0,7,0.0,yes,9/28/20,"Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University, Tsinghua University;Carnegie Mellon University",adversarial attack;relevance map;object detection;transferability;black-box attack,29;29;4;1,100;100;20;28,m;m,usa,usa,n,2;4
7103,ICLR,2021,Federated Learning With Quantized Global Model Updates,Mohammad Mohammadi Amiri;Deniz Gunduz;Sanjeev Kulkarni;H. Vincent Poor,~Mohammad_Mohammadi_Amiri1;d.gunduz@imperial.ac.uk;~Sanjeev_Kulkarni1;~H._Vincent_Poor1,5;6;5;5,4;3;3;3,Reject,0,7,0.0,yes,9/28/20,Princeton University;Imperial College London;Princeton University;Princeton University,Federated learning;lossy broadcasting,29;53;29;29,9;11;9;9,m;m,usa,usa,y,
7104,ICLR,2021,Efficient Robust Training via Backward Smoothing,Jinghui Chen;Yu Cheng;Zhe Gan;Quanquan Gu;Jingjing Liu,~Jinghui_Chen1;~Yu_Cheng1;~Zhe_Gan1;~Quanquan_Gu1;~Jingjing_Liu2,5;5;5;6,4;5;5;4,Reject,0,15,0.0,yes,9/28/20,"University of California, Los Angeles;Microsoft Research;Microsoft;University of California, Los Angeles;Microsoft",Efficient Robust Training;Backward Smoothing;Robustness,-1;-1;-1;-1;-1,15;-1;-1;15;-1,m;f,NAN,NAN,n,4
7105,ICLR,2021,Deep Q Learning from Dynamic Demonstration with Behavioral Cloning,Xiaoshuang Li;Junchen Jin;Xiao Wang;Fei-Yue Wang,~Xiaoshuang_Li1;junchen@kth.se;x.wang@ia.ac.cn;~Fei-Yue_Wang2,7;6;6;5,4;2;4;5,Reject,0,7,0.0,yes,9/28/20,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;;;;;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",,34;-1;-1;-1;-1;34,-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,
7106,ICLR,2021,World Model as a Graph: Learning Latent Landmarks for Planning,Lunjun Zhang;Ge Yang;Bradly C Stadie,~Lunjun_Zhang1;~Ge_Yang1;~Bradly_C_Stadie1,5;5;7;6,5;4;3;4,Reject,0,4,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Massachusetts Institute of Technology;University of California Berkeley",Reinforcement Learning;Planning,18;5;-1,18;4;7,m;m,usa,usa,n,1;10
7107,ICLR,2021,Towards Learning to Remember in Meta Learning of Sequential Domains,Zhenyi Wang;Tiehang Duan;Donglin Zhan;Changyou Chen,~Zhenyi_Wang1;~Tiehang_Duan1;~Donglin_Zhan1;~Changyou_Chen1,6;5;5;4,5;5;3;5,Reject,0,6,0.0,yes,9/28/20,"State University of New York, Buffalo;Facebook;Columbia University;State University of New York, Buffalo",Meta learning;Continual Learning;Sequential Domain Learning,-1;-1;23;-1,-1;-1;17;-1,u;m,NAN,NAN,n,6;1
7108,ICLR,2021,Numeric Encoding Options with Automunge,Nicholas Teague,~Nicholas_Teague1,2;3;3;2,4;4;4;4,Reject,0,15,0.0,yes,9/28/20,Automunge Inc.,tabular;feature engineering;preprocessing,-1,-1,m,NAN,NAN,n,10
7109,ICLR,2021,Gradient Descent Resists Compositionality,Yuanpeng Li;Liang Zhao;Joel Hestness;Kenneth Church;Mohamed Elhoseiny,~Yuanpeng_Li2;~Liang_Zhao2;~Joel_Hestness2;~Kenneth_Church1;~Mohamed_Elhoseiny1,4;5;1;3,3;3;4;3,Reject,0,10,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Samsung Research America;Cerebras Systems, Inc;Baidu;KAUST",Compositionality,4;-1;-1;-1;110,20;-1;-1;-1;-1,u;m,europe,gr,y,1
7110,ICLR,2021,Investigating and Simplifying Masking-based Saliency Methods for Model Interpretability,Jason Phang;Jungkyu Park;Krzysztof J. Geras,~Jason_Phang1;~Jungkyu_Park1;~Krzysztof_J._Geras1,6;4;7;6,4;5;3;2,Reject,0,8,0.0,yes,9/28/20,New York University;New York University;NYU Grossman School of Medicine,saliency maps;interpretability;explainable AI;image recognition;image masking;adversarial training,23;23;-1,26;26;-1,m;m,NAN,NAN,n,
7111,ICLR,2021,Ricci-GNN: Defending Against Structural Attacks Through a Geometric Approach,Ze Ye;Tengfei Ma;Chien-Chun Ni;Kin Sum Liu;Jie Gao;Chao Chen,~Ze_Ye1;~Tengfei_Ma1;chien-chun.ni@verizonmedia.com;kliu@twitter.com;jg1555@cs.rutgers.edu;~Chao_Chen1,6;5;5,5;5;4,Reject,0,10,0.0,yes,9/28/20,"State University of New York, Stony Brook;International Business Machines;Yahoo! Research;State University of New York, Stony Brook;Rutgers University;State University of New York, Stony Brook",Deep Learning;Graph Convolution;Ricci Flow;Robustness,-1;-1;-1;-1;29;-1,-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,1;10;4
7112,ICLR,2021,Learning Stochastic Behaviour from Aggregate Data,Shaojun Ma;Shu Liu;Hongyuan Zha;Hao-Min Zhou,~Shaojun_Ma1;sliu459@gatech.edu;~Hongyuan_Zha1;~Hao-Min_Zhou1,5;4;8,4;4;3,Reject,0,3,0.0,yes,9/28/20,"Georgia Institute of Technology;Georgia Institute of Technology;The Chinese University of Hong Kong, Shenzhen;Georgia Tech Research Corporation",Fokker Planck Equation;weak form;Wasserstein GAN,12;12;46;-1,38;38;39;-1,m;m,NAN,NAN,y,5;4
7113,ICLR,2021,Action and Perception as Divergence Minimization,Danijar Hafner;Pedro A Ortega;Jimmy Ba;Thomas Parr;Karl Friston;Nicolas Heess,~Danijar_Hafner1;~Pedro_A_Ortega1;~Jimmy_Ba1;thomas.parr.12@ucl.ac.uk;~Karl_Friston1;~Nicolas_Heess1,6;6;7;3,3;4;3;4,Reject,0,16,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;DeepMind;Department of Computer Science, University of Toronto;;;University College London;Google",objective functions;reinforcement learning;information theory;probabilistic modeling;control as inference;exploration;intrinsic motivation;world models,18;-1;18;-1;-1;53;-1,18;-1;18;-1;-1;-1;-1,m;m,NAN,NAN,n,
7114,ICLR,2021,Error Controlled Actor-Critic Method to Reinforcement Learning,Xingen Gao;Fei Chao;Changle Zhou;Zhen Ge;Chih-Min Lin;Longzhi Yang;Xiang Chang;Changjing Shang,31520160154529@stu.xmu.edu.cn;fchao@xmu.edu.cn;dozero@xmu.edu.cn;13290073@student.uts.edu.au;cml@saturn.yzu.edu.tw;longzhi.yang@northumbria.ac.uk;xic9@aber.ac.uk;cns@aber.ac.uk,5;3;3;6,4;5;5;4,Reject,0,14,0.0,yes,9/28/20,Xiamen University;Aberystwyth University;;;;;;;;;;;;Aberystwyth University,reinforcement learning;actor-critic;function approximation;approximation error;KL divergence,-1;453;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;453,527;499;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;499,u;m,europe,uk,n,
7115,ICLR,2021,Variable-Shot Adaptation for Online Meta-Learning,Tianhe Yu;Xinyang Geng;Chelsea Finn;Sergey Levine,~Tianhe_Yu1;~Xinyang_Geng1;~Chelsea_Finn1;~Sergey_Levine1,5;6;6;6,4;3;4;4,Reject,0,16,0.0,yes,9/28/20,Stanford University;University of California Berkeley;Stanford University;University of Washington,meta-learning;deep learning,5;-1;5;11,2;7;2;29,m;m,usa,usa,y,6
7116,ICLR,2021,Optimization Variance:  Exploring Generalization Properties of DNNs,Xiao Zhang;Dongrui Wu;Haoyi Xiong;Bo Dai,~Xiao_Zhang8;~Dongrui_Wu1;~Haoyi_Xiong1;~Bo_Dai2,5;5;7;5;5,4;3;5;3;4,Reject,0,10,0.0,yes,9/28/20,"Huazhong University of Science and Technology;Huazhong University of Science and Technology, Tsinghua University;Baidu;Nanyang Technological University",Double Descent;Neural Networks;Generalization,-1;4;-1;44,312;20;-1;47,m;m,asia,sg,n,1
7117,ICLR,2021,Improved Gradient based Adversarial Attacks for Quantized Networks,Kartik Gupta;Thalaiyasingam Ajanthan,~Kartik_Gupta2;~Thalaiyasingam_Ajanthan1,5;6;6;5;7,4;5;5;3;4,Reject,0,10,0.0,yes,9/28/20,Australian National University;Australian National University,binary neural network;gradient masking;fake robustness;temperature scaling;adversarial attack;signal propagation,99;99,59;59,m;m,australasia,au,y,1;4
7118,ICLR,2021,Non-Linear Rewards For Successor Features,Norman L Tasfi;Miriam Capretz,~Norman_L_Tasfi1;~Miriam_Capretz1,4;4;4;4,4;4;5;4,Reject,0,6,0.0,yes,9/28/20,University of Western Ontario;University of Western Ontario,,-1;-1,-1;-1,m;f,NAN,NAN,n,
7119,ICLR,2021,Shape Defense,ali borji,~ali_borji1,6;4;3;5,4;4;4;4,Reject,0,18,0.0,yes,9/28/20,HCL America,adversarial robustness;adversarial defense;adversarial attack;shape;background subtraction,-1,-1,m,NAN,NAN,n,5;4
7120,ICLR,2021,Robust Meta-learning with Noise via Eigen-Reptile,Dong Chen;Lingfei Wu;Siliang Tang;Fangli Xu;Juncheng Li;Chang Zong;Chilie Tan;Yueting Zhuang,~Dong_Chen5;~Lingfei_Wu1;~Siliang_Tang1;lili@yixue.us;junchengli@zju.edu.cn;zongchang@zju.edu.cn;chilie.tan@tongdun.net;~Yueting_Zhuang1,4;5;5;6,3;5;4;4,Reject,0,7,0.0,yes,9/28/20,Zhejiang University;JD.COM Silicon Valley Research Center;Zhejiang University;Squirrel AI Learning;;;Zhejiang University;;;;Zhejiang University;Zhejiang University,meta-learning;few-shot learning;generalization,42;-1;42;-1;-1;-1;42;-1;-1;-1;42;42,94;-1;94;-1;-1;-1;94;-1;-1;-1;94;94,m;m,asia,cn,y,6
7121,ICLR,2021,Center-wise Local Image Mixture For Contrastive Representation Learning,Hao Li;XIAOPENG ZHANG;Ruoyu Sun;Hongkai Xiong;Qi Tian,~Hao_Li11;~XIAOPENG_ZHANG7;~Ruoyu_Sun2;~Hongkai_Xiong1;~Qi_Tian3,6;6;6;5,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Shanghai Jiao Tong University;National University of Singapore;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Huawei Technologies Ltd.,Self-supervised Learning;Data Mixing;Contrastive Learning,29;17;29;29;-1,100;25;100;100;-1,m;m,NAN,NAN,n,
7122,ICLR,2021,Generative Adversarial Neural Architecture Search with Importance Sampling,SEYED SAEED CHANGIZ REZAEI;Fred X. Han;Di Niu;Mohammad Salameh;Keith G Mills;Shangling Jui,~SEYED_SAEED_CHANGIZ_REZAEI1;~Fred_X._Han1;dniu@ualberta.ca;msalameh@ualberta.ca;~Keith_G_Mills1;jui.shangling@huawei.com,5;5;6;4,2;4;3;4,Reject,0,8,0.0,yes,9/28/20,Huawei Technologies Ltd.;Huawei Technologies Ltd.;University of Alberta;Huawei Technologies Ltd.;University of Alberta;Huawei Technologies Ltd.,Nueral Architecture Search;Deep Learning;Generative Adversarial Network;Graph Neural Network;Computer Vision,-1;-1;110;-1;110;-1,-1;-1;131;-1;131;-1,u;m,NAN,NAN,pdf miss,5;4
7123,ICLR,2021,Learning Monotonic Alignments with Source-Aware GMM Attention,Tae Gyoon Kang;Ho-Gyeong Kim;Min-Joong Lee;Jihyun Lee;Seongmin Ok;Hoshik Lee;Young Sang Choi,~Tae_Gyoon_Kang1;hogyeong.kim@samsung.com;minjoong.lee@samsung.com;jihyun.s.lee@samsung.com;~Seongmin_Ok1;hoshik.lee@samsung.com;macho@samsung.com,5;5;6;5,4;4;5;4,Reject,0,7,0.0,yes,9/28/20,Samsung advanced institute of technology;Korea Advanced Institute of Science and Technology;;;;;Samsung Advanced Institute of Technology;College of William and Mary;;Samsung Advanced Institute of Technololgy,Monotonic alignments;sequence-to-sequence model;aligned attention;streaming speech recognition;long-form speech recognition,-1;-1;-1;-1;-1;-1;-1;209;-1;-1,-1;96;-1;-1;-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,8
7124,ICLR,2021,Parameter-Efficient Transfer Learning with Diff Pruning,Demi Guo;Alexander M Rush;Yoon Kim,~Demi_Guo1;~Alexander_M_Rush1;~Yoon_Kim1,5;6;4;8,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,Harvard;Cornell University;Massachusetts Institute of Technology,transfer learning;parameter efficiency,53;7;5,3;19;4,f;m,usa,usa,n,6;3
7125,ICLR,2021,Contrastive Code Representation Learning,Paras Jain;Ajay Jain;Tianjun Zhang;Pieter Abbeel;Joseph E. Gonzalez;Ion Stoica,~Paras_Jain1;~Ajay_Jain1;~Tianjun_Zhang1;~Pieter_Abbeel2;~Joseph_E._Gonzalez1;~Ion_Stoica1,6;6;4,3;4;4,Reject,0,10,0.0,yes,9/28/20,University of California Berkeley;Google;University of California Berkeley;Covariant;University of California - Berkeley;;Univ. of California - Berkeley,programming languages;representation learning;contrastive learning;unsupervised learning;self-supervised learning;transfer learning;nlp;pretraining;type inference;summarization,-1;-1;-1;-1;-1;-1;10,7;-1;7;-1;7;-1;-1,m;m,NAN,NAN,n,6
7126,ICLR,2021,Generalisation Guarantees For Continual Learning With Orthogonal Gradient Descent,Mehdi Abbana Bennani;Thang Doan;Masashi Sugiyama,~Mehdi_Abbana_Bennani1;~Thang_Doan1;~Masashi_Sugiyama1,5;6;5,3;3;4,Reject,0,6,0.0,yes,9/28/20,Ecoles des Mines;Mila / McGill University;RIKEN Center for Advanced Intelligence Project,Continual Learning;Neural Tangent Kernel;Optimisation,-1;99;-1,-1;40;-1,m;m,NAN,NAN,y,6;1
7127,ICLR,2021,Learning What Not to Model: Gaussian Process Regression with Negative Constraints,Gaurav Shrivastava;Harsh Shrivastava;Abhinav Shrivastava,~Gaurav_Shrivastava1;~Harsh_Shrivastava1;~Abhinav_Shrivastava2,6;5;3;3,2;4;4;4,Reject,0,4,0.0,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;Microsoft;Department of Computer Science, University of Maryland, College Park",Gaussian Process;Gaussian Process Regression,-1;-1;-1,90;-1;90,m;m,NAN,NAN,n,
7128,ICLR,2021,Learning Private Representations with Focal Entropy,Tassilo Klein;Moin Nabi,~Tassilo_Klein1;~Moin_Nabi1,5;4;6;6,4;4;2;3,Reject,0,6,0.0,yes,9/28/20,Harvard University;SAP AI Research,,53;-1,3;-1,m;m,NAN,NAN,n,4
7129,ICLR,2021,Learn what you can't learn: Regularized Ensembles for Transductive out-of-distribution detection,Alexandru »öifrea;Eric Petru Stavarache;Fanny Yang,~Alexandru_»öifrea1;ericst@student.ethz.ch;~Fanny_Yang1,4;6;6;8,4;3;2;3,Reject,0,8,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,out-of-distribution detection;transductive;predictive uncertainty;ensembles;ensemble diversity;outlier detection,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n,1
7130,ICLR,2021,How much progress have we made in neural network training? A New Evaluation Protocol for Benchmarking Optimizers,Yuanhao Xiong;Xuanqing Liu;Li-Cheng Lan;Yang You;Si Si;Cho-Jui Hsieh,~Yuanhao_Xiong1;~Xuanqing_Liu1;~Li-Cheng_Lan1;~Yang_You1;~Si_Si1;~Cho-Jui_Hsieh1,6;7;6;5,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;National University of Singapore;Google;Amazon",deep learning;optimization;benchmarking,-1;-1;-1;17;-1;-1,15;15;15;25;-1;-1,m;m,NAN,NAN,n,2;3;10
7131,ICLR,2021,Symbol-Shift Equivariant Neural Networks,David Salinas;Hady Elsahar,~David_Salinas1;~Hady_Elsahar2,4;3;5,2;4;3,Reject,0,13,0.0,yes,9/28/20,Amazon;Naver Labs Europe,compositionality;Symbolic;Equivariance;question answering;Language Processing,-1;-1,-1;-1,m;m,NAN,NAN,n,3;1
7132,ICLR,2021,Reusing Preprocessing Data as Auxiliary Supervision in Conversational Analysis,Joshua Yee Kim;Kalina Yacef,~Joshua_Yee_Kim1;kalina.yacef@sydney.edu.au,5;5;6;6,5;4;4;4,Reject,0,5,0.0,yes,9/28/20,University of Sydney;;University of Sydney,Multitask Learning;Multimodal Conversational Analysis,71;-1;71,51;-1;51,m;f,europe,uk,n,
7133,ICLR,2021,Deep Partial Updating,Zhongnan Qu;Cong Liu;Junfeng Guo;Lothar Thiele,~Zhongnan_Qu1;~Cong_Liu2;~Junfeng_Guo2;~Lothar_Thiele1,5;6;6;6,3;3;3;3,Reject,0,6,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;University of Texas, Dallas;University of Texas, Dallas;Swiss Federal Institute of Technology",Partial updating;communication constraints;server-to-edge;deep neural networks,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
7134,ICLR,2021,Weighted Bellman Backups for Improved Signal-to-Noise in Q-Updates,Kimin Lee;Michael Laskin;Aravind Srinivas;Pieter Abbeel,~Kimin_Lee1;~Michael_Laskin1;~Aravind_Srinivas1;~Pieter_Abbeel2,3;5;5;8,4;4;4;4,Reject,0,11,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley;Covariant,Deep reinforcement learning;ensemble learning;Q-learning,-1;-1;-1;-1,7;7;7;-1,m;m,NAN,NAN,n,
7135,ICLR,2021,SoCal: Selective Oracle Questioning for Consistency-based Active Learning of Cardiac Signals,Dani Kiyasseh;Tingting Zhu;David A. Clifton,~Dani_Kiyasseh1;tingting.zhu@eng.ox.ac.uk;~David_A._Clifton1,5;5;4;4,3;4;4;3,Reject,0,5,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,Active learning;consistency-training;cardiac signals;healthcare,46;46;46,1;1;1,m;m,europe,uk,n,1
7136,ICLR,2021,Multi-hop Attention Graph Neural Network,Guangtao Wang;Zhitao Ying;Jing Huang;Jure Leskovec,~Guangtao_Wang1;~Zhitao_Ying1;~Jing_Huang3;~Jure_Leskovec1,6;5;6;5,4;5;3;5,Reject,0,4,0.0,yes,9/28/20,University of Michigan;Stanford University;JD AI Research;Stanford University,,7;5;-1;5,22;2;-1;2,m;m,usa,usa,y,8;10
7137,ICLR,2021,Crowd-sourced Phrase-Based Tokenization for Low-Resourced Neural Machine Translation: The case of Fon Language,Bonaventure F. P. Dossou;Chris Chinenye Emezue,~Bonaventure_F._P._Dossou1;~Chris_Chinenye_Emezue1,5;3;4,5;3;4,Reject,0,0,0.0,yes,9/28/20,Mila Quebec AI Institute;Technical University Munich,nmt;nlp;neural machine translation;natural language processing;deep learning;machine learning;machine translation;mt,-1;-1,-1;-1,m;m,NAN,NAN,n,3
7138,ICLR,2021,Tight Second-Order Certificates for Randomized Smoothing,Alexander Levine;Aounon Kumar;Tom Goldstein;Soheil Feizi,~Alexander_Levine2;aounon@umd.edu;~Tom_Goldstein1;~Soheil_Feizi2,6;4;5,3;3;5,Reject,0,6,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",certificates;adversarial;robustness;defenses;smoothing;curvature,12;12;12;12,90;90;90;90,m;m,usa,usa,y,1;4
7139,ICLR,2021,Robust Imitation via Decision-Time Planning,Carl Qi;Pieter Abbeel;Aditya Grover,~Carl_Qi1;~Pieter_Abbeel2;~Aditya_Grover1,3;6;4;4,5;3;5;5,Reject,0,7,0.0,yes,9/28/20,"University of California Berkeley;Covariant;Computer Science Department, Stanford University",imitation learning;reinforcement learning;inverse reinforcement learning,-1;-1;5,7;-1;2,m;m,NAN,NAN,n,6;1
7140,ICLR,2021,Revisiting Point Cloud Classification with a Simple and Effective Baseline,Ankit Goyal;Hei Law;Bowei Liu;Alejandro Newell;Jia Deng,~Ankit_Goyal1;~Hei_Law2;~Bowei_Liu2;~Alejandro_Newell2;~Jia_Deng1,7;7;7;4,4;4;4;5,Reject,0,6,0.0,yes,9/28/20,Princeton University;Princeton University;Princeton University;Princeton University;Princeton University,3D Vision;Point Cloud Processing,29;29;29;29;29,9;9;9;9;9,m;m,usa,usa,n,1
7141,ICLR,2021,Counterfactual Fairness through Data Preprocessing,Haoyu Chen;Wenbin Lu;Rui Song;Pulak Ghosh,~Haoyu_Chen4;~Wenbin_Lu1;~Rui_Song2;pulak.ghosh@iimb.ac.in,5;5;4,3;4;2,Reject,0,4,0.0,yes,9/28/20,North Carolina State University;North Carolina State University;North Carolina State University;;Indian Institute of Management Bangalore,Counterfactual fairness;data preprocessing;fairness test;discrimination detection;affirmative action,92;92;92;-1;-1,340;340;340;-1;-1,m;m,NAN,NAN,y,7
7142,ICLR,2021,Meta-Reinforcement Learning With Informed Policy Regularization,Pierre-Alexandre Kamienny;Matteo Pirotta;Alessandro Lazaric;Thibault Lavril;Nicolas Usunier;Ludovic Denoyer,~Pierre-Alexandre_Kamienny1;~Matteo_Pirotta1;~Alessandro_Lazaric2;thibautlav@fb.com;~Nicolas_Usunier1;~Ludovic_Denoyer1,5;5;6;6,4;4;3;4,Reject,0,17,0.0,yes,9/28/20,Facebook;Facebook;Facebook;;;Facebook;Criteo,meta-reinforcement learning;reinforcement learning;multi-task;non-stationary;task representations;regularization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7143,ICLR,2021,Hard Masking for Explaining Graph Neural Networks,Thorben Funke;Megha Khosla;Avishek Anand,~Thorben_Funke1;~Megha_Khosla1;~Avishek_Anand1,5;4;5,4;4;4,Reject,0,6,0.0,yes,9/28/20,"Universit√§t Bremen;L3S Research Center Hannover, Germany;Leibniz Universit√§t Hannover",Interpretability;Graph Neural Networks;Hard Masks,-1;-1;-1,-1;-1;515,m;m,NAN,NAN,y,10
7144,ICLR,2021,DROPS: Deep Retrieval of Physiological Signals via Attribute-specific Clinical Prototypes,Dani Kiyasseh;Tingting Zhu;David A. Clifton,~Dani_Kiyasseh1;tingting.zhu@eng.ox.ac.uk;~David_A._Clifton1,2;4;4,4;4;3,Reject,0,5,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,Contrastive learning;information retrieval;clustering;physiological signals;healthcare,46;46;46,1;1;1,m;m,europe,uk,n,7
7145,ICLR,2021,EM-RBR: a reinforced framework for knowledge graph completion from reasoning perspective,Bozhou Chen;Zhaochong An;Houde Quan;Qihui Lin;Hongzhi Wang,~Bozhou_Chen1;~Zhaochong_An1;~Houde_Quan1;~Qihui_Lin1;~Hongzhi_Wang2,4;4;3;3,4;4;3;4,Reject,0,0,0.0,yes,9/28/20,Harbin Institute of Technology;Harbin Institute of Technology;Harbin Institute of Technology;HIT;Harbin Institute of Technology,knowledge graph completion;bread first search,150;150;150;209;150,416;416;416;-1;416,m;m,asia,cn,n,10
7146,ICLR,2021,TextTN: Probabilistic Encoding of Language on Tensor Network,Peng Zhang;Jing Zhang;Xindian Ma;Siwei Rao;Guangjian Tian;Jun Wang,~Peng_Zhang17;~Jing_Zhang20;~Xindian_Ma1;~Siwei_Rao2;tian.guangjian@huawei.com;~Jun_Wang2,4;5;7;6,4;2;5;2,Reject,0,5,0.0,yes,9/28/20,"Tianjin University;Tianjin University;Tianjin University, Tianjin, China;Northeastern University;The Hong Kong Polytechnic University;University College London",Tensor Network;Language Representation;Natural Language Processing;Quantum Machine Learning;Entanglement Entropy,-1;-1;-1;16;128;53,496;496;496;895;129;-1,m;m,europe,uk,y,3;8;1;5
7147,ICLR,2021,Deformable Capsules for Object Detection,Rodney LaLonde;Naji Khosravan;Ulas Bagci,~Rodney_LaLonde1;~Naji_Khosravan1;~Ulas_Bagci1,6;6;4,3;4;3,Reject,0,5,0.0,yes,9/28/20,University of Central Florida;Zillow Group;University of Central Florida,Representation Learning;Capsule Networks;Object Detection,71;-1;71,633;-1;633,m;m,usa,usa,n,2
7148,ICLR,2021,Quantile Regularization : Towards Implicit Calibration of Regression Models,Saiteja Utpala;Piyush Rai,~Saiteja_Utpala1;~Piyush_Rai1,6;5;6;6,3;3;4;4,Reject,0,6,0.0,yes,9/28/20,"IIT Kanpur;IIT Kanpur, IIT Kanpur",Calibration;Reliable Uncertainty Quantification;Probabilistic Deep Learning,128;128,-1;-1,m;m,NAN,NAN,y,
7149,ICLR,2021,Reinforcement Learning with Bayesian Classifiers: Efficient Skill Learning from Outcome Examples,Kevin Li;Abhishek Gupta;Vitchyr H. Pong;Ashwin Reddy;Aurick Zhou;Justin Yu;Sergey Levine,kevintli@berkeley.edu;~Abhishek_Gupta1;~Vitchyr_H._Pong1;~Ashwin_Reddy1;~Aurick_Zhou1;justinvyu@berkeley.edu;~Sergey_Levine1,5;5;5;4,4;3;3;4,Reject,0,21,0.0,yes,9/28/20,"Electrical Engineering & Computer Science Department, University of California Berkeley;Google;University of California Berkeley;University of California Berkeley;University of California Berkeley;;;University of Washington",Reinforcement Learning;Goal Reaching;Bayesian Classification;Reward Inference,-1;-1;-1;-1;-1;-1;-1;11,-1;-1;7;7;7;-1;-1;29,m;m,usa,usa,y,1
7150,ICLR,2021,Higher-order Structure Prediction in Evolving Graph Simplicial Complexes,Manohar Kaul;Masaaki Imaizumi,~Manohar_Kaul1;~Masaaki_Imaizumi1,6;6;4,2;2;4,Reject,0,10,0.0,yes,9/28/20,Indian Institute of Technology Hyderabad (IITH);The University of Tokyo,Higher-order;graph simplicial complex;link prediction,-1;71,693;36,m;m,NAN,NAN,y,8;1;10
7151,ICLR,2021,Rethinking Content and Style: Exploring Bias for Unsupervised Disentanglement,Xuanchi Ren;Tao Yang;Wenjun Zeng;Yuwang Wang,~Xuanchi_Ren1;~Tao_Yang9;~Wenjun_Zeng3;~Yuwang_Wang3,4;7;4,4;4;4,Reject,0,4,0.0,yes,9/28/20,Hong Kong University of Science and Technology;Xi'an Jiaotong University;Microsoft;Microsoft,Unsupervised Disentanglement;Content and Style Disentanglement;Inductive Bias;Representation Learning,-1;-1;-1;-1,56;445;-1;-1,m;m,NAN,NAN,n,
7152,ICLR,2021,Class Balancing GAN with a Classifier in the Loop,Harsh Rangwani;Konda Reddy Mopuri;Venkatesh Babu Radhakrishnan,~Harsh_Rangwani1;~Konda_Reddy_Mopuri3;~Venkatesh_Babu_Radhakrishnan2,4;5;5;5,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,Indian Institute of Science;Indian Institute of Technology Tirupati;Indian Institute of Science,Long-tailed Learning;GAN;Universal Adversarial Perturbations,-1;-1;-1,323;-1;323,m;m,NAN,NAN,n,5;4
7153,ICLR,2021,Data-aware Low-Rank Compression for Large NLP Models,Patrick CHen;Hsiang-Fu Yu;Inderjit S Dhillon;Cho-Jui Hsieh,~Patrick_CHen1;rofu.yu@gmail.com;~Inderjit_S_Dhillon1;~Cho-Jui_Hsieh1,5;6;5;3,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,"University of California, Los Angeles;Amazon;University of Texas, Austin;Amazon",,-1;-1;-1;-1,15;-1;-1;-1,m;m,NAN,NAN,y,8;3
7154,ICLR,2021,Multi-Task Learning by a Top-Down Control Network,Hila Levi;Shimon Ullman,~Hila_Levi1;~Shimon_Ullman1,7;5;5,3;5;3,Reject,0,5,0.0,yes,9/28/20,Weizmann Institute;;Weizmann Institute of Science;Weizmann Institute of Science,multi task learning;computer vision,110;-1;110;110,-1;-1;-1;-1,f;m,europe,il,n,2
7155,ICLR,2021,Efficient Estimators for Heavy-Tailed Machine Learning,Vishwak Srinivasan;Adarsh Prasad;Sivaraman Balakrishnan;Pradeep Kumar Ravikumar,~Vishwak_Srinivasan1;~Adarsh_Prasad1;~Sivaraman_Balakrishnan1;~Pradeep_Kumar_Ravikumar1,6;6;6;5,4;3;4;5,Reject,0,8,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1,28;28;28;28,m;m,usa,usa,y,1;5;4
7156,ICLR,2021,Bractivate: Dendritic Branching in Medical Image Segmentation Neural Architecture Search,Leila Abdelrahman,~Leila_Abdelrahman1,3;4;4,3;4;4,Reject,0,0,0.0,yes,9/28/20,University of Miami,Neural Architecture Search;Segmentation;Computer Vision,453,238,f;m,usa,usa,n,2
7157,ICLR,2021,Stable Weight Decay Regularization,Zeke Xie;Issei Sato;Masashi Sugiyama,~Zeke_Xie1;~Issei_Sato1;~Masashi_Sugiyama1,5;5;6;5,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,The University of Tokyo;the University of Tokyo;RIKEN Center for Advanced Intelligence Project,Weight Decay;Regularization;Optimization;Deep Learning,71;71;-1,36;36;-1,u;m,NAN,NAN,y,
7158,ICLR,2021,Learning Predictive Communication by Imagination in Networked System Control,Yali Du;Yifan Zhao;Meng Fang;Jun Wang;Gangyan Xu;Haifeng Zhang,~Yali_Du1;zhaoyifan@stu.hit.edu.cn;~Meng_Fang1;~Jun_Wang2;gangyan@hit.edu.cn;haifeng.zhang@ia.ac.cn,4;4;5,4;2;4,Reject,0,5,0.0,yes,9/28/20,"University College London;Harbin Institute of Technology;Eindhoven University of Technology;University College London;;;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",Reinforcement Learning;Multi-agent Reinforcement Learning;Networked System Control,53;150;-1;53;-1;-1;34,-1;416;186;-1;-1;-1;-1,f;m,NAN,NAN,y,
7159,ICLR,2021,Predictive Attention Transformer: Improving Transformer with Attention Map Prediction,Yujing Wang;Yaming Yang;Jiangang Bai;Mingliang Zhang;Jing Bai;Jing Yu;Ce Zhang;Yunhai Tong,~Yujing_Wang1;~Yaming_Yang1;pku_bjg@pku.edu.cn;zml24@pku.edu.cn;jbai@microsoft.com;yujing02@iie.ac.cn;~Ce_Zhang1;~Yunhai_Tong1,2;6;6;6,4;4;4;4,Reject,0,15,0.0,yes,9/28/20,"Microsoft Research Asia;Peking University;;;;;University of Montreal, University of Montreal;Institute of Information Engineering, CAS;Swiss Federal Institute of Technology;Peking University",Transformer;Convolution;Attention Map,-1;14;-1;-1;-1;-1;128;-1;-1;14,-1;23;-1;-1;-1;-1;73;-1;-1;23,f;m,asia,cn,n,8;2;3
7160,ICLR,2021,A frequency domain analysis of gradient-based adversarial examples,Bochen Lv;Pu Yang;Zehao Wang;Zhanxing Zhu,bochen.lv@gmail.com;1700010695@pku.edu.cn;~Zehao_Wang2;~Zhanxing_Zhu1,4;3;5;7,4;5;4;4,Reject,0,5,0.0,yes,9/28/20,"State University of New York, Stony Brook;School of Mathematical Sciences;Peking University;Peking University",,-1;-1;14;14,-1;-1;23;23,m;m,asia,cn,y,4
7161,ICLR,2021,Memory Augmented Design of Graph Neural Networks,Tao Xiong;Liang Zhu;Ruofan Wu;Yuan Qi,~Tao_Xiong3;tailiang.zl@antgroup.com;~Ruofan_Wu1;yuan.qi@antgroup.com,5;5;5;3,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,Johns Hopkins University;;;Fudan University;;University of Colorado Boulder,,71;-1;-1;71;-1;64,12;-1;-1;70;-1;131,m;m,usa,usa,y,10
7162,ICLR,2021,TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series,Yang Jiao;Kai Yang;shaoyu dou;pan luo;Sijia Liu;Dongjin Song,yangjiao@tongji.edu.cn;~Kai_Yang3;shaoyu@tongji.edu.cn;lp@tongji.edu.cn;~Sijia_Liu1;~Dongjin_Song2,4;3;4,4;5;4,Reject,0,4,0.0,yes,9/28/20,Fudan University;;Tongji University  Tsinghua University;;;;;Michigan State University;University of Connecticut,representation learning;AutoML;irregularly sampled time series;anomaly detection;clustering,71;-1;4;-1;-1;-1;-1;110;174,70;-1;20;-1;-1;-1;-1;105;440,m;m,usa,usa,n,
7163,ICLR,2021,Frequency-aware Interface Dynamics with Generative Adversarial Networks,Lukas Prantl;Tassilo Kugelstadt;Jan Bender;Nils Thuerey,~Lukas_Prantl1;kugelstadt@cs.rwth-aachen.de;~Jan_Bender1;~Nils_Thuerey1,3;4;5,3;3;4,Reject,0,4,0.0,yes,9/28/20,Technical University Munich;RWTH Aachen University;RWTH Aachen University;Technical University Munich,physical simulations;spatio-temporal dynamics;generative adversarial networks;fluids;elasto-plasticity,-1;128;128;-1,-1;107;107;-1,m;m,NAN,NAN,n,5;4
7164,ICLR,2021,Orthogonal Subspace Decomposition: A New Perspective of Learning Discriminative Features for Face Clustering,Jianfeng Wang;Thomas Lukasiewicz;zhongchao shi,~Jianfeng_Wang2;~Thomas_Lukasiewicz2;~zhongchao_shi1,5;7;4,5;3;4,Reject,0,4,0.0,yes,9/28/20,"University of Oxford;Department of Computer Science, University of Oxford;Lenovo Research",,46;46;-1,1;1;-1,m;m,NAN,NAN,y,10
7165,ICLR,2021,On the Geometry of Deep Bayesian Active Learning,Xiaofeng Cao;Ivor Tsang,~Xiaofeng_Cao1;~Ivor_Tsang1,5;3;5;4,3;4;5;4,Reject,0,6,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney,Bayesian active learning;geometric interpretation;core-set construction;model uncertainty;ellipsoid.,71;71,160;160,u;m,australasia,au,y,11;1
7166,ICLR,2021,Unsupervised Learning of Global Factors in Deep Generative Models,Ignacio Peis;Pablo M. Olmos;Antonio Art√©s,~Ignacio_Peis1;~Pablo_M._Olmos1;~Antonio_Art√©s1,6;6;5;5,3;4;4;3,Reject,0,12,0.0,yes,9/28/20,Universidad Carlos II de Madrid;Universidad Carlos III de Madrid;Universidad Carlos III de Madrid,unsupervised;autoencoders;disentanglement;generative models;representation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1;5
7167,ICLR,2021,BBRefinement: an universal scheme to improve precision of box object detectors,Petr Hurtik;Marek Vajgl,~Petr_Hurtik1;~Marek_Vajgl1,2;2;4;4,5;5;5;4,Reject,0,6,0.0,yes,9/28/20,University of Ostrava;University of Ostrava,object detection;deep neural networks;refinement,-1;-1,1149;1149,m;m,canada,ca,n,
7168,ICLR,2021,Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation,Masahiro Kato;Takeshi Teshima,~Masahiro_Kato1;~Takeshi_Teshima1,6;6;5;6,3;4;3;2,Reject,0,5,0.0,yes,9/28/20,Cyberagent;RIKEN,density ratio estimation;bregman divergence,-1;-1,-1;-1,m;m,NAN,NAN,y,8;1
7169,ICLR,2021, Model-centric data manifold: the data through the eyes of the model,Luca Grementieri;Rita Fioresi,lgrementieri@nextbit.it;~Rita_Fioresi1,4;5;5;6,4;3;3;5,Reject,0,5,0.0,yes,9/28/20,Ecole Normale Superieure;University of Bologna,Deep Learning;Information Geometry;Data Manifold;Fisher matrix,128;-1,-1;167,m;f,NAN,NAN,y,
7170,ICLR,2021,Gradient Based Memory Editing for Task-Free Continual Learning,Xisen Jin;Junyi Du;Xiang Ren,~Xisen_Jin3;~Junyi_Du1;~Xiang_Ren1,6;3;7;5,4;5;4;5,Reject,0,8,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,Continual learning;task-free continual learning,37;37;37,53;53;53,m;m,usa,usa,n,
7171,ICLR,2021,MQES: Max-Q Entropy Search for Efficient Exploration in Continuous Reinforcement Learning,Jinyi Liu;Zhi Wang;Jianye HAO;YAN ZHENG,~Jinyi_Liu1;~Zhi_Wang4;~Jianye_HAO1;~YAN_ZHENG1,4;3;5;6;4,3;4;4;3;3,Reject,0,8,0.0,yes,9/28/20,"Tianjin University;Beijing University of Post and Telecommunication;Tianjin University;Tianjin Unibersity, China",,-1;-1;-1;-1,496;-1;496;-1,u;m,NAN,NAN,y,
7172,ICLR,2021,Regret Bounds and Reinforcement Learning Exploration of EXP-based Algorithms,Mengfan Xu;Diego Klabjan,~Mengfan_Xu1;~Diego_Klabjan1,4;4;4,3;4;3,Reject,0,3,0.0,yes,9/28/20,"Northwestern University, Northwestern University;Northwestern University",,46;46,24;24,f;m,usa,usa,y,
7173,ICLR,2021,Learning from multiscale wavelet superpixels using GNN with spatially heterogeneous pooling,Maxime Bassenne;Varun Vasudevan;Lei Xing,~Maxime_Bassenne1;devan@stanford.edu;~Lei_Xing1,2;5;7;5,4;4;4;3,Reject,0,5,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,Image classification;GNN;superpixel;SLIC;wavelet,5;5;5,2;2;2,m;m,usa,usa,n,10
7174,ICLR,2021,Energy-Based Models for Continual Learning,Shuang Li;Yilun Du;Gido Martijn van de Ven;Antonio Torralba;Igor Mordatch,~Shuang_Li5;~Yilun_Du1;~Gido_Martijn_van_de_Ven1;~Antonio_Torralba1;~Igor_Mordatch4,5;4;6;6,4;4;3;4,Reject,0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Cambridge;Massachusetts Institute of Technology;University of Washington,Continual learning;Energy-based model,5;5;79;5;11,4;4;6;4;29,f;m,usa,usa,n,
7175,ICLR,2021,Practical Locally Private Federated Learning with Communication Efficiency,Yan Feng;Tao Xiong;Ruofan Wu;Yuan Qi,~Yan_Feng2;weilue.xt@antgroup.com;~Ruofan_Wu1;yuan.qi@antgroup.com,5;6;3;5,2;3;4;4,Reject,0,5,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;;Fudan University;;University of Colorado Boulder,,4;-1;71;-1;64,20;-1;70;-1;131,m;m,usa,usa,y,
7176,ICLR,2021,Automated Concatenation of Embeddings for Structured Prediction,Xinyu Wang;Yong Jiang;Nguyen Bach;Tao Wang;Zhongqiang Huang;Fei Huang;Kewei Tu,~Xinyu_Wang3;~Yong_Jiang1;~Nguyen_Bach1;~Tao_Wang4;~Zhongqiang_Huang1;~Fei_Huang2;~Kewei_Tu1,4;6;5;6,4;4;3;4,Reject,0,8,0.0,yes,9/28/20,ShanghaiTech University;ShanghaiTech University;Alibaba Group;Huazhong University of Science and Technology;Alibaba Group;Alibaba Group;ShanghaiTech University,,327;327;-1;-1;-1;-1;327,-1;-1;-1;312;-1;-1;-1,m;m,asia,cn,n,
7177,ICLR,2021,Policy Optimization in Zero-Sum Markov Games: Fictitious Self-Play Provably Attains Nash Equilibria,Boyi Liu;Zhuoran Yang;Zhaoran Wang,~Boyi_Liu1;~Zhuoran_Yang1;~Zhaoran_Wang1,6;5;8;5,4;3;3;2,Reject,0,6,0.0,yes,9/28/20,"Northwestern University, Northwestern University;University of California Berkeley;Northwestern University",,46;-1;46,24;7;24,u;m,usa,usa,y,1
7178,ICLR,2021,Ordering-Based Causal Discovery with Reinforcement Learning,Xiaoqiang Wang;Yali Du;Shengyu Zhu;Liangjun Ke;Zhitang Chen;Jianye HAO;Jun Wang,~Xiaoqiang_Wang2;~Yali_Du1;~Shengyu_Zhu1;keljxjtu@xjtu.edu.cn;~Zhitang_Chen1;~Jianye_HAO1;~Jun_Wang2,5;5;5;5,4;3;4;3,Reject,0,5,0.0,yes,9/28/20,"Xi'an Jiaotong University,;University College London;Huawei Noah's Ark Lab;;;Huawei Technologies Ltd.;Tianjin University;University College London",Causal Discovery;Reinforcement Learning;Ordering Search,-1;53;-1;-1;-1;-1;-1;53,445;-1;-1;-1;-1;-1;496;-1,u;m,europe,uk,y,10
7179,ICLR,2021,Provable Memorization via Deep Neural Networks using Sub-linear Parameters,Sejun Park;Jaeho Lee;Chulhee Yun;Jinwoo Shin,~Sejun_Park1;~Jaeho_Lee3;~Chulhee_Yun1;~Jinwoo_Shin1,7;6;5,4;3;4,Reject,0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Massachusetts Institute of Technology;Korea Advanced Institute of Science and Technology,memorization,-1;-1;5;-1,96;96;4;96,u;m,NAN,NAN,y,
7180,ICLR,2021,REPAINT: Knowledge Transfer in Deep Actor-Critic Reinforcement Learning,Yunzhe Tao;Sahika Genc;TAO SUN;Sunil Mallya,~Yunzhe_Tao2;~Sahika_Genc1;~TAO_SUN4;~Sunil_Mallya1,7;4;4;6,4;4;4;4,Reject,0,13,0.0,yes,9/28/20,Amazon;University of Michigan;Amazon;Brown University,reinforcement learning;transfer learning;actor-critic RL;representation transfer;instance transfer;task similarity;MuJoCo;DeepRacer,-1;7;-1;85,-1;22;-1;61,m;m,usa,usa,n,
7181,ICLR,2021,Learn Goal-Conditioned Policy with Intrinsic Motivation for Deep Reinforcement Learning,Jinxin Liu;Donglin Wang;Qiangxing Tian;Zhengyu Chen,~Jinxin_Liu1;~Donglin_Wang1;~Qiangxing_Tian1;~Zhengyu_Chen2,6;6;7;5,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,Westlake University;Westlake University;Zhejiang University;Westlake University,unsupervised reinforcement learning;goal-conditioned policy;intrinsic reward,263;263;42;263,-1;-1;94;-1,m;m,asia,cn,n,
7182,ICLR,2021,Human Perception-based Evaluation Criterion for Ultra-high Resolution Cell Membrane Segmentation,Ruohua Shi;Wenyao Wang;Zhixuan Li;Liuyuan He;Kaiwen Sheng;Lei Ma;Kai Du;Tingting Jiang;Tiejun Huang,~Ruohua_Shi1;~Wenyao_Wang1;~Zhixuan_Li1;~Liuyuan_He1;~Kaiwen_Sheng1;~Lei_Ma3;~Kai_Du1;~Tingting_Jiang2;~Tiejun_Huang1,6;3;7;4,3;5;3;4,Reject,0,19,0.0,yes,9/28/20,"Peking University;Peking University;Peking University;Peking University, Tsinghua University;Peking University;Peking University;;Karolinska Institute Stockholm;Peking University;Peking University",Neuroscience;Connectomics;Human perception;EM dataset;Membrane segmentation;Evaluation criterion,14;14;14;4;14;14;-1;-1;14;14,23;23;23;20;23;23;-1;36;23;23,f;m,asia,cn,n,2
7183,ICLR,2021,Measuring Visual Generalization in Continuous Control from Pixels,Jake Grigsby;Yanjun Jane Qi,~Jake_Grigsby1;~Yanjun_Jane_Qi1,6;6;5;6,3;4;3;3,Reject,0,5,0.0,yes,9/28/20,University of Virginia;University of Virginia,Continuous Control;Reinforcement Learning,53;53,117;117,m;f,usa,usa,n,1;10
7184,ICLR,2021,Bi-tuning of Pre-trained Representations,Jincheng Zhong;Ximei Wang;Zhi Kou;Jianmin Wang;Mingsheng Long,zhongjinchengwork@gmail.com;~Ximei_Wang1;kz19@mails.tsinghua.edu.cn;~Jianmin_Wang1;~Mingsheng_Long5,4;4;5;8,5;4;3;4,Reject,0,6,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University",Deep learning;fine-tuning;pre-training,4;4;4;4;4,20;20;20;20;20,m;m,NAN,NAN,n,
7185,ICLR,2021,AdaDGS: An adaptive black-box optimization method with a nonlocal directional Gaussian smoothing gradient,Hoang A Tran;Guannan Zhang,~Hoang_A_Tran1;~Guannan_Zhang1,5;3;4;4,3;5;4;4,Reject,0,5,0.0,yes,9/28/20,Oak Ridge National Laboratory;Oak Ridge National Laboratory,,-1;-1,-1;-1,m;m,NAN,NAN,n,
7186,ICLR,2021,Universal Approximation Theorem for Equivariant Maps by Group CNNs,Wataru Kumagai;Akiyoshi Sannai,~Wataru_Kumagai2;~Akiyoshi_Sannai1,7;5;5,3;3;3,Reject,0,6,0.0,yes,9/28/20,The University of Tokyo;RIKEN,Universal Approximation Theorem;CNN;Deep Learning;Symmetry,71;-1,36;-1,u;u,NAN,NAN,y,1
7187,ICLR,2021,Structural Landmarking and Interaction Modelling: on Resolution Dilemmas in Graph Classification,Kai Zhang;Yaokang Zhu;Jun Wang;Haibin Ling;Jie Zhang;Hongyuan Zha,~Kai_Zhang1;~Yaokang_Zhu1;~Jun_Wang4;~Haibin_Ling1;~Jie_Zhang10;~Hongyuan_Zha1,6;6;6;6,2;4;4;3,Reject,0,7,0.0,yes,9/28/20,"Temple University;East China Normal University;Columbia University, Columbia University;State University of New York, Stony Brook;Fudan University;The Chinese University of Hong Kong, Shenzhen",Graph Pooling;Graph Classiciation;Interaction Preserving Graph Pooling;Structure Landmarking,209;-1;23;-1;71;46,308;387;17;-1;70;39,m;m,NAN,NAN,n,10
7188,ICLR,2021,Hierarchical Probabilistic Model for Blind Source Separation via Legendre Transformation,Simon Luo;Lamiae Azizi;Mahito Sugiyama,~Simon_Luo1;lamiae.azizi@sydney.edu.au;~Mahito_Sugiyama1,4;3;4;2,3;4;4;5,Reject,0,5,0.0,yes,9/28/20,University of Sydney;University of Sydney;National Institute of Informatics,blind source separation;log-linear model;energy-based model;information geometry,71;71;-1,51;51;-1,m;m,NAN,NAN,y,
7189,ICLR,2021,Robust Reinforcement Learning using Adversarial Populations,Eugene Vinitsky;Yuqing du;Kanaad V Parvate;Kathy Jang;Pieter Abbeel;Alexandre Bayen,~Eugene_Vinitsky1;yuqing_du@berkeley.edu;~Kanaad_V_Parvate1;~Kathy_Jang1;~Pieter_Abbeel2;~Alexandre_Bayen2,5;7;4;5,4;4;4;3,Reject,0,14,0.0,yes,9/28/20,"University of California Berkeley;University of California Berkeley;University of California Berkeley;;University of California, Berkeley;Covariant;University of California Berkeley",Robust Control;Reinforcement Learning;Multiagent Systems,-1;-1;-1;-1;-1;-1;-1,7;7;7;-1;7;-1;7,m;m,usa,usa,n,1;4
7190,ICLR,2021,ACT: Asymptotic Conditional Transport,Huangjie Zheng;Mingyuan Zhou,~Huangjie_Zheng1;~Mingyuan_Zhou1,6;6;5,3;4;4,Reject,0,10,0.0,yes,9/28/20,"University of Texas, Austin;The University of Texas at Austin",Statistical distance;Divergence;Optimal Transport;Implicit Distribution;Deep Generative Models;GANs,-1;20,-1;43,m;m,NAN,NAN,y,5;4
7191,ICLR,2021,Model-Based Reinforcement Learning via Latent-Space Collocation,Oleh Rybkin;Chuning Zhu;Anusha Nagabandi;Kostas Daniilidis;Igor Mordatch;Sergey Levine,~Oleh_Rybkin1;zchuning@seas.upenn.edu;~Anusha_Nagabandi1;~Kostas_Daniilidis1;~Igor_Mordatch4;~Sergey_Levine1,4;6;7;6,4;4;4;4,Reject,0,15,0.0,yes,9/28/20,University of Pennsylvania;University of Pennsylvania;University of California Berkeley;University of Pennsylvania;University of Washington;University of Washington,visual model-based reinforcement learning;visual planning;long-horizon planning;collocation,20;20;-1;20;11;11,13;13;7;13;29;29,m;m,usa,usa,n,
7192,ICLR,2021,Universal Sentence Representations Learning with Conditional Masked Language Model,Ziyi Yang;Yinfei Yang;Daniel M Cer;Jax Law;Eric Darve,~Ziyi_Yang1;~Yinfei_Yang1;~Daniel_M_Cer1;jaxlaw@google.com;~Eric_Darve1,6;4;5;7,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,Stanford University;University of Pennsylvania;Google;;;Stanford University,multilingual representations;sentence embeddings,5;20;-1;-1;-1;5,2;13;-1;-1;-1;2,m;m,usa,usa,n,3
7193,ICLR,2021,Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks,Maxwell Mbabilla Aladago;Lorenzo Torresani,~Maxwell_Mbabilla_Aladago1;~Lorenzo_Torresani1,5;7;6;4,3;4;4;2,Reject,0,8,0.0,yes,9/28/20,Dartmouth College;Dartmouth College,initialization;optimization,174;174,100;100,m;m,usa,usa,n,
7194,ICLR,2021,DEEP ADAPTIVE SEMANTIC LOGIC (DASL): COMPILING DECLARATIVE KNOWLEDGE INTO DEEP NEURAL NETWORKS,Karan Sikka;Andrew Silberfarb;John Byrnes;Indranil Sur;Ed Chow;Ajay Divakaran;Richard Rohwer,~Karan_Sikka1;andrew.silberfarb@sri.com;john.byrnes@sri.com;~Indranil_Sur1;ed.chow@sri.com;~Ajay_Divakaran1;richard.rohwer@sri.com,5;5;6;3,5;4;3;5,Reject,0,14,0.0,yes,9/28/20,SRI International;;;;;Arizona State University;;;SRI International;;SRI International,deep neural networks;first order logic;neuro-symbolic computing;knowledge;commonsense,-1;-1;-1;-1;-1;85;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;182;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7195,ICLR,2021,"Hey that's not an ODE'"": Faster ODE Adjoints with 12 Lines of Code""",Patrick Kidger;Ricky T. Q. Chen;Terry Lyons,~Patrick_Kidger1;~Ricky_T._Q._Chen1;tlyons@maths.ox.ac.uk,5;5;4;5,4;5;3;5,Reject,0,7,0.0,yes,9/28/20,University of Oxford;University of Toronto;Alan Turing Institute,,46;18;-1,1;18;-1,m;m,NAN,NAN,n,5
7196,ICLR,2021,Neural Nonnegative CP Decomposition for Hierarchical Tensor Analysis,Joshua Vendrow;Jamie Haddock;Deanna Needell,jvendrow@math.ucla.edu;~Jamie_Haddock1;~Deanna_Needell2,6;4;4,4;2;4,Reject,0,8,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",nonnegative tensor decompositions;topic modeling;hierarchical model;CP decomposition;neural network;backpropagation,-1;-1;-1,15;15;15,m;f,usa,usa,n,
7197,ICLR,2021,Outlier Robust Optimal Transport,Debarghya Mukherjee;Aritra Guha;Justin Solomon;Yuekai Sun;Mikhail Yurochkin,~Debarghya_Mukherjee1;~Aritra_Guha1;~Justin_Solomon1;~Yuekai_Sun1;~Mikhail_Yurochkin1,4;6;7;5,4;4;5;5,Reject,0,10,0.0,yes,9/28/20,University of Michigan;Duke University;Massachusetts Institute of Technology;University of Michigan;International Business Machines,Optimal transport;outliers;robustness,7;46;5;7;-1,22;20;4;22;-1,m;m,NAN,NAN,y,4
7198,ICLR,2021,Enforcing Predictive Invariance across Structured Biomedical Domains,Wengong Jin;Regina Barzilay;Tommi S. Jaakkola,~Wengong_Jin1;~Regina_Barzilay1;~Tommi_S._Jaakkola1,6;4;5;5,4;3;4;3,Reject,0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Domain Generalization;Molecular Property Prediction,5;5;5,4;4;4,m;m,usa,usa,y,
7199,ICLR,2021,The act of remembering: A study in partially observable reinforcement learning,Rodrigo Toro Icarte;Richard Valenzano;Toryn Q. Klassen;Phillip Christoffersen;Amir-massoud Farahmand;Sheila A. McIlraith,~Rodrigo_Toro_Icarte1;~Richard_Valenzano1;~Toryn_Q._Klassen1;~Phillip_Christoffersen1;~Amir-massoud_Farahmand1;~Sheila_A._McIlraith1,7;5;7;6,4;3;3;3,Reject,0,9,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;University of Toronto;University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",Reinforcement Learning;Partial Observability;Memory Representations;External Memories;POMDPs.,18;18;18;18;18;18,18;18;18;18;18;18,m;f,NAN,NAN,n,1
7200,ICLR,2021,Dynamically Stable Infinite-Width Limits of Neural Classifiers,Eugene Golikov,~Eugene_Golikov1,3;7;5;5,5;3;3;4,Reject,0,9,0.0,yes,9/28/20,Moscow Institute of Physics and Technology,neural tangent kernel;mean field limit,-1,224,m,NAN,NAN,y,
7201,ICLR,2021,Learning Lagrangian Fluid Dynamics with Graph Neural Networks,Zijie Li;Amir Barati Farimani,~Zijie_Li2;barati@cmu.edu,4;4;4;5,4;4;4;4,Reject,0,12,0.0,yes,9/28/20,"Carnegie Mellon University;CMU, Carnegie Mellon University",particle hydrodynamics;graph neural networks;Lagrangian fluids,1;1,28;28,m;m,NAN,NAN,n,1;10
7202,ICLR,2021,Energy-based Out-of-distribution Detection for Multi-label Classification,Haoran Wang;Weitang Liu;Alex Bocchieri;Yixuan Li,~Haoran_Wang5;~Weitang_Liu1;~Alex_Bocchieri1;~Yixuan_Li1,7;6;4;6,5;3;4;3,Reject,0,11,0.0,yes,9/28/20,"Fudan University;University of California, San Diego;University of Wisconsin, Madison;University of Wisconsin, Madison",,71;-1;18;18,70;33;49;49,m;f,usa,usa,n,
7203,ICLR,2021,Divide-and-Conquer Monte Carlo Tree Search,Giambattista Parascandolo;Lars Holger Buesing;Josh Merel;Leonard Hasenclever;John Aslanides;Jessica B Hamrick;Nicolas Heess;Alexander Neitz;Theophane Weber,~Giambattista_Parascandolo1;~Lars_Holger_Buesing1;~Josh_Merel1;~Leonard_Hasenclever1;~John_Aslanides1;~Jessica_B_Hamrick1;~Nicolas_Heess1;~Alexander_Neitz1;~Theophane_Weber1,7;5;8;5,3;3;4;4,Reject,0,9,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;Deepmind;DeepMind;DeepMind;DeepMind;DeepMind;Google;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Google DeepMind",MCTS;planning;goal-directed planning;divide and conquer,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
7204,ICLR,2021,Exploiting Safe Spots in Neural Networks for Preemptive Robustness and Out-of-Distribution Detection,Seungyong Moon;Gaon An;Hyun Oh Song,~Seungyong_Moon1;~Gaon_An1;~Hyun_Oh_Song1,6;6;7;5,4;5;3;2,Reject,0,15,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University,adversarial defense;out-of-distribution detection,37;37;37,60;60;60,m;m,asia,kr,n,8;4
7205,ICLR,2021,DCT-SNN: Using DCT to Distribute Spatial Information over Time for Learning Low-Latency Spiking Neural Networks,Isha Garg;Sayeed Shafayet Chowdhury;Kaushik Roy,~Isha_Garg1;~Sayeed_Shafayet_Chowdhury3;~Kaushik_Roy1,6;6;6;5,4;3;5;4,Reject,0,19,0.0,yes,9/28/20,Purdue University;Purdue University;;Purdue University,Spiking Neural Networks;Input Encoding;Low Latency;Discrete Cosine Transform;Temporal Information;Frequency Domain,23;23;-1;23,94;94;-1;94,f;m,usa,usa,n,
7206,ICLR,2021,HyperSAGE: Generalizing Inductive Representation Learning on Hypergraphs,Devanshu Arya;Deepak Gupta;Stevan Rudinac;Marcel Worring,~Devanshu_Arya1;~Deepak_Gupta2;s.rudinac@uva.nl;~Marcel_Worring1,6;4;5;6,3;4;3;4,Reject,0,8,0.0,yes,9/28/20,University of Amsterdam;Transmute AI Research;University of Amsterdam;University of Amsterdam,Hypergraph;Representation Learning;Inductive Learning;Geometric Deep Learning;Aggregation Methods,128;-1;128;128,66;-1;66;66,m;m,europe,nl,n,10
7207,ICLR,2021,A Unified Framework for Convolution-based Graph Neural Networks,Xuran Pan;Shiji Song;Gao Huang,~Xuran_Pan1;~Shiji_Song1;~Gao_Huang1,6;7;5;5,3;3;3;5,Reject,0,9,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Graph Representation Learning;Graph Convolution;Graph Signal Processing;Oversmoothing,4;4;4,20;20;20,m;m,NAN,NAN,n,8;10
7208,ICLR,2021,Function Contrastive Learning of Transferable Representations,Muhammad Waleed Gondal;Shruti Joshi;Nasim Rahaman;Stefan Bauer;Manuel Wuthrich;Bernhard Sch√∂lkopf,~Muhammad_Waleed_Gondal1;shruti.joshi@tuebingen.mpg.de;~Nasim_Rahaman1;~Stefan_Bauer1;~Manuel_Wuthrich1;~Bernhard_Sch√∂lkopf1,5;5;5;5,3;4;3;4,Reject,0,14,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Swiss Federal Institute of Technology;Max Planck Institute for Intelligent Systems;Max Planck Institute for Intelligent Systems, Max-Planck Institute",Representations Learning;Few-shot Learning;Contrastive Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6
7209,ICLR,2021,Manifold Regularization for Locally Stable Deep Neural Networks,Charles Jin;Martin Rinard,~Charles_Jin1;~Martin_Rinard1,5;4;4;5,4;4;3;4,Reject,0,21,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology,regularization;deep learning;adversarial robustness,5;5,4;4,m;m,usa,usa,y,4
7210,ICLR,2021,A Flexible Framework for Discovering Novel Categories with Contrastive Learning,Xuhui Jia;Kai Han;Yukun Zhu;Bradley Green,~Xuhui_Jia1;~Kai_Han1;~Yukun_Zhu1;~Bradley_Green3,5;4;6;5;5,3;4;4;3;4,Reject,0,12,0.0,yes,9/28/20,The University of Hong Kong;University of Bristol;Google;Google Research,deep learning;novel classes;clustering;self-supervised learning;unsupervised learning,99;110;-1;-1,39;91;-1;-1,m;m,NAN,NAN,n,
7211,ICLR,2021,Run Away From your Teacher: a New Self-Supervised Approach Solving the Puzzle of BYOL,Haizhou Shi;Dongliang Luo;Siliang Tang;Jian Wang;Yueting Zhuang,~Haizhou_Shi1;~Dongliang_Luo1;~Siliang_Tang1;~Jian_Wang14;~Yueting_Zhuang1,5;3;6;3,4;4;3;5,Reject,0,7,0.0,yes,9/28/20,Zhejiang University;Fudan University;Zhejiang University;Fudan University;;Zhejiang University;Zhejiang University,representation learning;self-supervised learning;contrastive learning;regularization;theory,42;71;42;71;-1;42;42,94;70;94;70;-1;94;94,m;m,asia,cn,y,1
7212,ICLR,2021,Variational Invariant Learning for Bayesian Domain Generalization,Zehao Xiao;Jiayi Shen;Xiantong Zhen;Ling Shao;Cees G. M. Snoek,~Zehao_Xiao1;~Jiayi_Shen3;~Xiantong_Zhen1;~Ling_Shao1;~Cees_G._M._Snoek1,8;5;6;6,4;3;3;3,Reject,0,4,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam;University of Amsterdam;Inception Institute of Artificial Intelligence;University of Amsterdam,domain generalization;variational invariant learning;Bayesian inference,128;128;128;-1;128,66;66;66;-1;66,u;m,europe,nl,n,11;1
7213,ICLR,2021,Minimal Geometry-Distortion Constraint for Unsupervised Image-to-Image Translation,Jiaxian Guo;Jiachen Li;Mingming Gong;Huan Fu;Kun Zhang;Dacheng Tao,~Jiaxian_Guo2;~Jiachen_Li4;~Mingming_Gong1;~Huan_Fu1;~Kun_Zhang1;~Dacheng_Tao1,4;7;4;7,5;4;4;3,Reject,0,9,0.0,yes,9/28/20,University of Sydney;Shanghai Jiao Tong University;The University of Melbourne;Alibaba Group;Carnegie Mellon University;JD.com,Unsupervised image translation;Geometry distortion,71;29;85;-1;1;-1,51;100;31;-1;28;-1,m;m,NAN,NAN,n,
7214,ICLR,2021,Rethinking Uncertainty in Deep Learning: Whether and How it Improves Robustness,Yilun Jin;Lixin Fan;Kam Woh Ng;Ce Ju;Qiang Yang,~Yilun_Jin1;~Lixin_Fan1;jinhewu@webank.com;~Ce_Ju1;~Qiang_Yang1,4;5;6;5,5;4;2;4,Reject,0,6,0.0,yes,9/28/20,"The Hong Kong University of Science and Technology;WeBank;University of Surrey;WeBank Co., Ltd. AI Department;Department of Computer Science and Engineering",Adversarial Robustness;Uncertainty Promotion;Adversarial Training,-1;-1;150;-1;-1,56;-1;260;-1;-1,m;m,NAN,NAN,n,4
7215,ICLR,2021,A Closer Look at Codistillation for Distributed Training,Shagun Sodhani;Olivier Delalleau;Mido Assran;Koustuv Sinha;Nicolas Ballas;Michael Rabbat,~Shagun_Sodhani1;~Olivier_Delalleau1;~Mido_Assran1;~Koustuv_Sinha1;~Nicolas_Ballas1;~Michael_Rabbat1,4;4;5;4,4;4;2;4,Reject,0,13,0.0,yes,9/28/20,Facebook;Facebook AI Research;McGill University;McGill University;Facebook;McGill University,Distributed Training;Distillation;Neural Networks;Deep Learning;Large-scale Learning,-1;-1;99;99;-1;99,-1;-1;40;40;-1;40,m;m,canada,ca,n,
7216,ICLR,2021,Descending through a Crowded Valley ‚Äî Benchmarking Deep Learning Optimizers,Robin Marc Schmidt;Frank Schneider;Philipp Hennig,~Robin_Marc_Schmidt1;~Frank_Schneider1;~Philipp_Hennig1,4;4;9;6,5;5;5;4,Reject,0,14,0.0,yes,9/28/20,University of T√ºbingen;University of T√ºbingen;University of Tuebingen,Deep learning;optimizers;benchmark,128;128;128,78;78;78,m;m,europe,de,n,
7217,ICLR,2021,Prior Preference Learning From Experts: Designing A Reward with Active Inference,Jin Young Shin;Cheolhyeong Kim;Hyung Ju Hwang,~Jin_Young_Shin1;~Cheolhyeong_Kim1;~Hyung_Ju_Hwang1,5;5;6,4;3;2,Reject,0,7,0.0,yes,9/28/20,POSTECH;POSTECH;POSTECH,Active Inference;Free Energy Principle;Reinforcement Learning;Reward Design,128;128;128,151;151;151,m;f,asia,kr,n,11
7218,ICLR,2021,Training By Vanilla SGD with Larger Learning Rates,Yueyao Yu;Jie Wang;Wenye Li;Yin Zhang,~Yueyao_Yu1;~Jie_Wang9;~Wenye_Li1;~Yin_Zhang4,5;4;3;6,4;5;4;3,Reject,0,4,0.0,yes,9/28/20,"The Chinese University of HongKong, shenzhen;Georgia Institute of Technology;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen",,-1;12;46;46,-1;38;39;39,u;m,NAN,NAN,y,3;9
7219,ICLR,2021,RSO: A Gradient Free Sampling Based Approach For Training Deep Neural Networks,Rohun Tripathi;Bharat Singh,~Rohun_Tripathi1;~Bharat_Singh2,7;6;8;3,4;2;5;5,Reject,0,6,0.0,yes,9/28/20,"IIT Kanpur;University of Maryland, College Park",,128;12,-1;90,m;m,usa,usa,n,
7220,ICLR,2021,Synthesizer: Rethinking Self-Attention for Transformer Models,Yi Tay;Dara Bahri;Donald Metzler;Da-Cheng Juan;Zhe Zhao;Che Zheng,~Yi_Tay1;~Dara_Bahri1;metzler@google.com;~Da-Cheng_Juan1;~Zhe_Zhao3;chezheng@google.com,4;7;5;7,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,Google;Google Research;Google;Google Research;Google;;Google,Transformers;Deep Learning;Attention,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
7221,ICLR,2021,Efficient Neural Machine Translation with Prior Word Alignment,Jeonghyeok Park;hai zhao,~Jeonghyeok_Park2;~hai_zhao1,4;5;3,4;4;5,Reject,0,4,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University",Word Alignment;Neural Machine Translation,4;29,20;100,m;m,asia,cn,n,3
7222,ICLR,2021,DO-GAN: A Double Oracle Framework for Generative Adversarial Networks,Aye Phyu Phyu Aung;Xinrun Wang;Runsheng Yu;Bo An;Senthilnath Jayavelu;Xiaoli Li,~Aye_Phyu_Phyu_Aung1;~Xinrun_Wang1;~Runsheng_Yu2;~Bo_An2;j_senthilnath@i2r.a-star.edu.sg;~Xiaoli_Li1,6;6;4;3,3;4;4;4,Reject,0,5,0.0,yes,9/28/20,"Nanyang Technological University;Nanyang Technological University;The Hong Kong University of Science and Technology;Nanyang Technological University;I2R, A*STAR;Nanyang Technological University",GAN;Generative Models;Adversarial Networks;Game Theory,44;44;-1;44;-1;44,47;47;56;47;-1;47,u;m,asia,sg,n,5;4
7223,ICLR,2021,Connection- and Node-Sparse Deep Learning: Statistical Guarantees,Johannes Lederer,~Johannes_Lederer1,5;4;6,3;4;3,Reject,0,0,0.0,yes,9/28/20,Ruhr-Universt√§t Bochum,,-1,-1,m,NAN,NAN,y,
7224,ICLR,2021,Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling,Chuizheng Meng;Sirisha Rambhatla;Yan Liu,~Chuizheng_Meng1;~Sirisha_Rambhatla1;~Yan_Liu1,5;6;3;6,3;2;5;1,Reject,0,10,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,Federated Learning;Graph Neural Network;Spatio-Temporal Data Modeling,37;37;37,53;53;53,m;f,usa,usa,n,10
7225,ICLR,2021,Tracking the progress of Language Models by extracting their underlying Knowledge Graphs,Carlos Aspillaga;Marcelo Mendoza;Alvaro Soto,~Carlos_Aspillaga1;~Marcelo_Mendoza1;~Alvaro_Soto1,6;4;5;6,4;2;4;4,Reject,0,4,0.0,yes,9/28/20,Pontificia Universidad Catolica de Chile;Universidad T√©cnica Federico Santa Mar√≠a;Universidad Cat√≥lica de Chile,Language Models;NLP;Knowledge Graphs;Probe tasks;Word2Vec;GloVe;ELMo;BERT;RoBERTa;XLNet;ALBERT;T5;GPT2,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3;10
7226,ICLR,2021,Bayesian Neural Networks with Variance Propagation for Uncertainty Evaluation,Yuki Mae;Wataru Kumagai;Takafumi Kanamori,~Yuki_Mae1;~Wataru_Kumagai2;~Takafumi_Kanamori1,4;4;3;4,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,DENSO CORPORATION;The University of Tokyo;Tokyo Institute of Technology,uncertainty evaluation;sampling-free method;variance propagation;LSTM;out-of-distribution,-1;71;174,-1;36;312,u;m,asia,jp,n,8;11;3
7227,ICLR,2021,Relational Learning with Variational Bayes,Kuang-Hung Liu,~Kuang-Hung_Liu1,6;6;6;5,3;3;3;3,Reject,0,34,0.0,yes,9/28/20,ExxonMobil,Relational learning;unsupervised learning;variational inference;probabilistic graphical model,-1,-1,m,NAN,NAN,n,10
7228,ICLR,2021,MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention,Carson Eisenach;Yagna Patel;Dhruv Madeka,~Carson_Eisenach1;~Yagna_Patel1;~Dhruv_Madeka1,5;6;6,3;3;2,Reject,0,6,0.0,yes,9/28/20,Amazon;Amazon;Amazon,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;3
7229,ICLR,2021,Improving Sequence Generative Adversarial Networks with Feature Statistics Alignment,Yekun Chai;Qiyue Yin;Junge Zhang,~Yekun_Chai1;~Qiyue_Yin1;~Junge_Zhang1,4;5;6;6,3;3;3;3,Reject,0,6,0.0,yes,9/28/20,"Institute of automation, Chinese academy of sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",,-1;34;34,-1;-1;-1,m;m,NAN,NAN,n,5;4
7230,ICLR,2021,MixCon: Adjusting the Separability of Data Representations for Harder Data Recovery,Xiaoxiao Li;YANGSIBO HUANG;Binghui Peng;Zhao Song;Kai Li,~Xiaoxiao_Li1;~YANGSIBO_HUANG1;~Binghui_Peng1;~Zhao_Song3;~Kai_Li8,5;5;5,4;3;3,Reject,0,7,0.0,yes,9/28/20,Princeton University;Princeton University;Columbia University;Institue for Advanced Study;Princeton University,Data Recovery;Data Separability;Distributed Deep Learning,29;29;23;-1;29,9;9;17;-1;9,f;m,usa,usa,y,4
7231,ICLR,2021,Attainability and Optimality: The Equalized-Odds Fairness Revisited,Zeyu Tang;Kun Zhang,~Zeyu_Tang1;~Kun_Zhang1,6;6;5;5;5,3;3;4;4;4,Reject,0,5,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University,algorithmic fairness,1;1,28;28,m;m,usa,usa,y,1;7
7232,ICLR,2021,On the Power of Abstention and Data-Driven Decision Making for Adversarial Robustness,Nina Balcan;Avrim Blum;Dravyansh Sharma;Hongyang Zhang,~Nina_Balcan1;~Avrim_Blum1;~Dravyansh_Sharma1;~Hongyang_Zhang1,4;6;3;4,4;3;2;4,Reject,0,9,0.0,yes,9/28/20,Carnegie-Mellon University;Toyota Technological Institute at Chicago;Carnegie Mellon University;University of Waterloo,Adversarial Machine Learning;Learning Theory,1;-1;1;34,28;-1;28;232,f;m,canada,ca,y,1;4
7233,ICLR,2021,Learning Deep Latent Variable Models via Amortized Langevin Dynamics,Shohei Taniguchi;Yusuke Iwasawa;Yutaka Matsuo,~Shohei_Taniguchi1;~Yusuke_Iwasawa1;~Yutaka_Matsuo1,6;5;6,4;3;3,Reject,0,6,0.0,yes,9/28/20,The University of Tokyo;The University of Tokyo;The University of Tokyo,Langevin dynamics;amortized inference;deep generative model,71;71;71,36;36;36,m;m,NAN,NAN,n,5
7234,ICLR,2021,Provably Faster Algorithms for Bilevel Optimization and Applications to Meta-Learning,Kaiyi Ji;Junjie Yang;Yingbin Liang,~Kaiyi_Ji1;~Junjie_Yang2;~Yingbin_Liang1,6;7;3;5,2;3;2;4,Reject,0,6,0.0,yes,9/28/20,Ohio State University;Ohio State University;The Ohio State University,Bilevel Optimization;Computational Complexity;Meta-Learning;Hyper-Parameter Optimization,58;58;58,78;78;-1,m;f,NAN,NAN,y,6;9
7235,ICLR,2021,Adversarial Masking: Towards Understanding Robustness Trade-off for Generalization,Minhao Cheng;Zhe Gan;Yu Cheng;Shuohang Wang;Cho-Jui Hsieh;Jingjing Liu,~Minhao_Cheng1;~Zhe_Gan1;~Yu_Cheng1;~Shuohang_Wang1;~Cho-Jui_Hsieh1;~Jingjing_Liu2,6;5;7;7,4;5;2;4,Reject,0,7,0.0,yes,9/28/20,"University of California, Los Angeles;Microsoft;Microsoft Research;Microsoft;Amazon;Microsoft",Adversarial Machine Learning;Adversarial Robustness;Adversarial Training;Generalization,-1;-1;-1;-1;-1;-1,15;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,1;4
7236,ICLR,2021,On the Importance of Sampling in Training GCNs: Convergence Analysis and Variance Reduction,Weilin Cong;Morteza Ramezani;Mehrdad Mahdavi,~Weilin_Cong1;~Morteza_Ramezani1;~Mehrdad_Mahdavi2,4;4;7;7,4;5;4;3,Reject,0,9,0.0,yes,9/28/20,Pennsylvania State University;Pennsylvania State University;Pennsylvania State University,Graph neural network;large-scale machine learning;convergence analysis,44;44;44,-1;-1;-1,m;m,usa,usa,y,10;9
7237,ICLR,2021,Improving Generalizability of Protein Sequence Models via Data Augmentations,Hongyu Shen;Layne C. Price;Mohammad Taha Bahadori;Franziska Seeger,hongyus@amazon.com;prilayne@amazon.com;~Mohammad_Taha_Bahadori1;fseeger@amazon.com,9;4;6;3,4;4;3;4,Reject,0,6,0.0,yes,9/28/20,University of Illinois  Urbana Champaign;;;Amazon;;Amazon,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;2;3
7238,ICLR,2021,Reverse engineering learned optimizers reveals known and novel mechanisms,Niru Maheswaranathan;David Sussillo;Luke Metz;Ruoxi Sun;Jascha Sohl-Dickstein,~Niru_Maheswaranathan1;~David_Sussillo1;~Luke_Metz1;~Ruoxi_Sun2;~Jascha_Sohl-Dickstein2,8;5;5;5,4;3;3;3,Reject,0,10,0.0,yes,9/28/20,Facebook;Google;Google;Google;Google,learned optimizers;optimization;recurrent neural networks;RNNs;interpretability,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7239,ICLR,2021,Deep Data Flow Analysis,Chris Cummins;Zacharias Fisches;Tal Ben-Nun;Torsten Hoefler;Hugh Leather;Michael O'Boyle,cummins@fb.com;zfisches@student.ethz.ch;~Tal_Ben-Nun1;torsten.hoefler@inf.ethz.ch;hleather@fb.com;~Michael_O'Boyle1,7;7;6;4;7,3;3;4;4;3,Reject,0,5,0.0,yes,9/28/20,University of Edinburgh;;;Swiss Federal Institute of Technology;;;University of Edinburgh,program representations;program analysis;compilers;graph neural networks,29;-1;-1;-1;-1;-1;29,30;-1;-1;-1;-1;-1;30,m;m,europe,uk,n,10
7240,ICLR,2021,(Updated submission 11/20/2020) MISIM: A Novel Code Similarity System,Fangke Ye;Shengtian Zhou;Anand Venkat;Ryan Marcus;Nesime Tatbul;Jesmin Jahan Tithi;Niranjan Hasabnis;Paul Petersen;Timothy G Mattson;Tim Kraska;Pradeep Dubey;Vivek Sarkar;Justin Gottschlich,yefangke@gatech.edu;~Shengtian_Zhou1;anand.venkat@intel.com;~Ryan_Marcus1;~Nesime_Tatbul1;jesmin.jahan.tithi@intel.com;niranjan.hasabnis@intel.com;paul.petersen@intel.com;timothy.g.mattson@intel.com;~Tim_Kraska1;~Pradeep_Dubey1;~Vivek_Sarkar2;~Justin_Gottschlich1,4;5;7;5,5;5;3;4,Reject,0,5,0.0,yes,9/28/20,"Intel;Intel;Intel;Computer Science and Artificial Intelligence Laboratory, Electrical Engineering & Computer Science;Intel Labs;State University of New York, Stony Brook;Intel;Intel;Intel;Brown University;Purdue University;Georgia Tech Research Corporation;Intel Labs",Machine Programming;Machine Learning;Code Similarity;Code Representation,-1;-1;-1;-1;-1;-1;-1;-1;-1;85;23;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;61;94;-1;-1,u;m,NAN,NAN,n,
7241,ICLR,2021,JAKET: Joint Pre-training of Knowledge Graph and Language Understanding,Donghan Yu;Chenguang Zhu;Yiming Yang;Michael Zeng,~Donghan_Yu2;~Chenguang_Zhu1;~Yiming_Yang1;~Michael_Zeng1,5;5;5;6,5;4;5;4,Reject,0,7,0.0,yes,9/28/20,Carnegie Mellon University;Stanford University;School of Computer Science  Carnegie Mellon University; Microsoft,Pre-training;Knowledge Graph;Language Understanding;Graph Neural Network,1;5;1;-1,28;2;28;-1,m;m,NAN,NAN,n,3;10
7242,ICLR,2021,On The Adversarial Robustness of 3D Point Cloud Classification,Jiachen Sun;Karl Koenig;Yulong Cao;Qi Alfred Chen;Zhuoqing Mao,~Jiachen_Sun1;kamako@umich.edu;yulongc@umich.edu;~Qi_Alfred_Chen1;~Zhuoqing_Mao1,6;5;7;5,4;2;3;4,Reject,0,11,0.0,yes,9/28/20,"University of Michigan;University of Michigan;University of Michigan;University of California, Irvine;University of Michigan",Adversarial Machine Learning;Point Cloud Classification;Adversarial Training,7;7;7;-1;7,22;22;22;98;22,m;f,usa,usa,n,4
7243,ICLR,2021,Leveraging affinity cycle consistency to isolate factors of variation in learned representations,Kieran A Murphy;Varun Jampani;Srikumar Ramalingam;Ameesh Makadia,~Kieran_A_Murphy1;~Varun_Jampani2;~Srikumar_Ramalingam2;~Ameesh_Makadia1,6;3;4;4,3;4;3;4,Reject,0,9,0.0,yes,9/28/20,Google;Google Research;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,5
7244,ICLR,2021,Generalizing Graph Convolutional Networks via Heat Kernel,Jialin Zhao;Yuxiao Dong;Jie Tang;Ming Ding;Kuansan Wang,~Jialin_Zhao1;~Yuxiao_Dong1;~Jie_Tang1;dm18@mails.tsinghua.edu.cn;~Kuansan_Wang1,5;6;5;6,4;5;5;4,Reject,0,5,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;Facebook;Tsinghua University  Tsinghua University;Tsinghua University; Microsoft,graph networks,4;-1;4;4;-1,20;-1;20;20;-1,u;m,NAN,NAN,n,10
7245,ICLR,2021,"For interpolating kernel machines, minimizing the norm of the ERM solution minimizes stability",Akshay Rangamani;Lorenzo Rosasco;Tomaso Poggio,~Akshay_Rangamani1;~Lorenzo_Rosasco1;~Tomaso_Poggio1,6;8;6;8,3;4;4;5,Reject,0,7,0.0,yes,9/28/20,Massachusetts Institute of Technology;Universit‚àö‚Ä† degli Studi di Genova;Massachusetts Institute of Technology,Stability;Linear Regression;Kernel Regression;Cross Validation Leave One Out Stability;Minimum norm solutions;Interpolation;Double Descent,5;-1;5,4;-1;4,m;m,usa,usa,y,1
7246,ICLR,2021,VideoGen: Generative Modeling of Videos using VQ-VAE and Transformers,Yunzhi Zhang;Wilson Yan;Pieter Abbeel;Aravind Srinivas,yunzhi@berkeley.edu;~Wilson_Yan1;~Pieter_Abbeel2;~Aravind_Srinivas1,4;4;4;4,4;5;4;5,Reject,0,6,0.0,yes,9/28/20,Stanford University;University of California Berkeley;Covariant;University of California Berkeley,video generation;vqvae;transformers;gpt,5;-1;-1;-1,2;7;-1;7,f;m,usa,usa,n,8;5
7247,ICLR,2021,Robust Temporal Ensembling,Abel Brown;Benedikt Schifferer;Robert DiPietro,~Abel_Brown1;~Benedikt_Schifferer2;~Robert_DiPietro1,6;5;5;6,4;5;4;3,Reject,0,7,0.0,yes,9/28/20,NVIDIA;NVIDIA;NVIDIA,learning with noise;robust task loss;consistency regularization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
7248,ICLR,2021,Correcting Momentum in Temporal Difference Learning,Emmanuel Bengio;Joelle Pineau;Doina Precup,~Emmanuel_Bengio1;~Joelle_Pineau1;~Doina_Precup1,6;6;6;4,4;3;4;4,Reject,0,6,0.0,yes,9/28/20,McGill University;Facebook;DeepMind,Momentum;Reinforcement Learning;Temporal Difference;Deep Reinforcement Learning,99;-1;-1,40;-1;-1,m;f,NAN,NAN,n,
7249,ICLR,2021,Adversarial Feature Desensitization,Pouya Bashivan;Mojtaba Faramarzi;Touraj Laleh;Blake Aaron Richards;Irina Rish,~Pouya_Bashivan1;~Mojtaba_Faramarzi1;~Touraj_Laleh1;~Blake_Aaron_Richards1;~Irina_Rish1,6;4;5;4,5;4;5;5,Reject,0,4,0.0,yes,9/28/20,"McGill University;Mila;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;McGill University;University of Montreal",adversarial robustness;adversarial learning;convolutional neural networks,99;150;128;99;128,40;370;73;40;73,m;m,canada,ca,y,1;4
7250,ICLR,2021,Boundary Effects in CNNs: Feature or Bug?,Md Amirul Islam;Matthew Kowal;Sen Jia;Konstantinos G. Derpanis;Neil Bruce,~Md_Amirul_Islam1;~Matthew_Kowal1;~Sen_Jia1;~Konstantinos_G._Derpanis1;~Neil_Bruce1,7;3;3;8,4;4;4;3,Reject,0,8,0.0,yes,9/28/20,Ryerson University;Ryerson University;University of Waterloo;Ryerson University;York University,Boundary Effects;Absolute Position Information;Padding;Canvas color;Location Dependent Task,327;327;34;327;209,785;785;232;785;452,m;m,asia,kr,n,
7251,ICLR,2021,Improved Contrastive Divergence Training of Energy Based Models,Yilun Du;Shuang Li;Joshua B. Tenenbaum;Igor Mordatch,~Yilun_Du1;~Shuang_Li5;~Joshua_B._Tenenbaum1;~Igor_Mordatch4,5;4;5;5,5;5;4;5,Reject,0,7,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Washington,Contrastive Divergence;Energy Based Modeling,5;5;5;11,4;4;4;29,m;m,usa,usa,n,
7252,ICLR,2021,Extrapolatable Relational Reasoning With Comparators in Low-Dimensional Manifolds,Duo Wang;Mateja Jamnik;Pietro Li√≤,~Duo_Wang1;~Mateja_Jamnik1;~Pietro_Li√≤1,6;4;5;4;5,4;4;3;5;4,Reject,0,6,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;;University of Cambridge,Visual Reasoning;Relational Reasoning;Generalisation,79;79;-1;79,6;6;-1;6,m;m,europe,uk,n,1
7253,ICLR,2021,Systematic Analysis of Cluster Similarity Indices: How to Validate Validation Measures,Martijn G√∂sgens;Liudmila Prokhorenkova;Aleksei Tikhonov,~Martijn_G√∂sgens1;~Liudmila_Prokhorenkova1;~Aleksei_Tikhonov1,7;7;6;7,4;4;3;3,Reject,0,9,0.0,yes,9/28/20,Eindhoven University of Technology;Higher School of Economics;Moscow Institute of Physics and Technology,cluster similarity indices;cluster validation;clustering;community detection;constant baseline,-1;-1;-1,186;-1;224,m;m,NAN,NAN,y,
7254,ICLR,2021,Deep Learning with Data Privacy via Residual Perturbation,Wenqi Tao;Huaming Ling;Zuoqiang Shi;Bao Wang,twq17@mails.tsinghua.edu.cn;linghm18@mails.tsinghua.edu.cn;~Zuoqiang_Shi1;~Bao_Wang1,4;6;6;5,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,Tsinghua University;Tsinghua University  Tsinghua University;Tsinghua University  Tsinghua University;University of Utah,Data Privacy;Residual Perturbation;Deep Learning,4;4;4;58,20;20;20;239,u;m,europe,uk,y,1
7255,ICLR,2021,Safe Reinforcement Learning with Natural Language Constraints,Tsung-Yen Yang;Michael Hu;Yinlam Chow;Peter Ramadge;Karthik R Narasimhan,~Tsung-Yen_Yang2;~Michael_Hu1;~Yinlam_Chow1;~Peter_Ramadge1;~Karthik_R_Narasimhan1,6;7;5;5,3;4;4;3,Reject,0,9,0.0,yes,9/28/20,Princeton University;Princeton University;Google Research;Princeton University;Princeton University,Safe reinforcement learning;Language grounding,29;29;-1;29;29,9;9;-1;9;9,m;m,usa,usa,n,3
7256,ICLR,2021,Dynamic Backdoor Attacks Against Deep Neural Networks,Ahmed Salem;Rui Wen;Michael Backes;Shiqing Ma;Yang Zhang,~Ahmed_Salem2;rui.wen@cispa.saarland;~Michael_Backes1;shiqing.ma@rutgers.edu;~Yang_Zhang15,5;6;5,4;3;4,Reject,0,5,0.0,yes,9/28/20,"The CISPA Helmholtz Center for Information Security;CISPA, saarland university, saarland informatics campus;;Rutgers University;CISPA Helmholtz Center for Information Security",Backdoor attack;Deep Neural Networks security,99;-1;-1;29;99,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
7257,ICLR,2021,Intelligent Matrix Exponentiation,Thomas Fischbacher;Iulia Maria Comsa;Krzysztof Potempa;Moritz Firsching;Luca Versari;Jyrki Alakuijala,~Thomas_Fischbacher1;~Iulia_Maria_Comsa1;krzysztof.potempa@gmail.com;~Moritz_Firsching1;~Luca_Versari1;~Jyrki_Alakuijala1,4;5;5;5,4;3;3;4,Reject,0,6,0.0,yes,9/28/20,Google Research;Google Research;;;Google Research;University of Pisa;Google,matrix exponential;tensor methods;supervised learning;domain extrapolation;certified robustness,-1;-1;-1;-1;-1;263;-1,-1;-1;-1;-1;-1;440;-1,m;m,NAN,NAN,y,
7258,ICLR,2021,UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning,Tarun Gupta;Anuj Mahajan;Bei Peng;Wendelin Boehmer;Shimon Whiteson,~Tarun_Gupta3;~Anuj_Mahajan1;~Bei_Peng2;~Wendelin_Boehmer1;~Shimon_Whiteson1,6;3;5;5,5;5;2;4,Reject,0,11,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford;Delft University of Technology;University of Oxford,multi-agent reinforcement learning;deep Q-learning;universal value functions;successor features;relative overgeneralization,46;46;46;-1;46,1;1;1;78;1,m;m,europe,uk,y,
7259,ICLR,2021,Robust Constrained Reinforcement Learning for Continuous Control with Model Misspecification,Daniel J Mankowitz;Dan Andrei Calian;Rae Jeong;Cosmin Paduraru;Nicolas Heess;Sumanth Dathathri;Martin Riedmiller;Timothy Mann,~Daniel_J_Mankowitz2;~Dan_Andrei_Calian1;raejeong@google.com;~Cosmin_Paduraru1;~Nicolas_Heess1;~Sumanth_Dathathri1;~Martin_Riedmiller1;~Timothy_Mann1,5;4;4;5,4;4;2;4,Reject,0,8,0.0,yes,9/28/20,Google;Google;;;DeepMind;Google;California Institute of Technology;;Google,reinforcement learning;constraints;robustness,-1;-1;-1;-1;-1;-1;150;-1;-1,-1;-1;-1;-1;-1;-1;4;-1;-1,m;m,NAN,NAN,n,
7260,ICLR,2021,Environment Predictive Coding for Embodied Agents,Santhosh Kumar Ramakrishnan;Tushar Nagarajan;Ziad Al-Halah;Kristen Grauman,~Santhosh_Kumar_Ramakrishnan1;~Tushar_Nagarajan1;~Ziad_Al-Halah2;~Kristen_Grauman1,5;6;6;4,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,"University of Texas, Austin;Facebook;University of Texas at Austin;Facebook",Self-supervised learning;visual navigation,-1;-1;20;-1,-1;-1;43;-1,m;f,NAN,NAN,n,
7261,ICLR,2021,A Sharp Analysis of Model-based Reinforcement Learning with Self-Play,Qinghua Liu;Tiancheng Yu;Yu Bai;Chi Jin,~Qinghua_Liu1;~Tiancheng_Yu1;~Yu_Bai1;~Chi_Jin1,5;4;7;8,4;5;2;4,Reject,0,8,0.0,yes,9/28/20,Princeton University;Massachusetts Institute of Technology;Salesforce Research;Princeton University,Reinforcement learning theory;Markov games;model-based RL;task-agnostic RL;multi-agent RL,29;5;-1;29,9;4;-1;9,m;m,usa,usa,y,1
7262,ICLR,2021,Consistency and Monotonicity Regularization for Neural Knowledge Tracing,Seewoo Lee;Youngduck Choi;Juneyoung Park;Byungsoo Kim;Jinwoo Shin,~Seewoo_Lee1;~Youngduck_Choi2;~Juneyoung_Park1;~Byungsoo_Kim1;~Jinwoo_Shin1,4;7;5;6,3;4;4;2,Reject,0,8,0.0,yes,9/28/20,Riiid! AI Research;Riiid! AI Research;Riiid! AI Research;Riiid! AI Research;Korea Advanced Institute of Science and Technology,knowledge tracing;data augmentation;regularization,-1;-1;-1;-1;-1,-1;-1;-1;-1;96,m;m,NAN,NAN,n,1
7263,ICLR,2021,Neural SDEs Made Easy: SDEs are Infinite-Dimensional GANs,Patrick Kidger;James Foster;Xuechen Li;Harald Oberhauser;Terry Lyons,~Patrick_Kidger1;~James_Foster4;~Xuechen_Li1;oberhauser@maths.ox.ac.uk;tlyons@maths.ox.ac.uk,6;5;4;3,4;4;4;3,Reject,0,10,0.0,yes,9/28/20,University of Oxford;University of Oxford;Stanford University;University of Oxford;Alan Turing Institute,neural differential equation;neural ODE;SDE;GAN,46;46;5;46;-1,1;1;2;1;-1,m;m,NAN,NAN,y,1;5
7264,ICLR,2021,Differentiable Optimization of Generalized Nondecomposable Functions using Linear Programs,Zihang Meng;Lopamudra Mukherjee;Vikas Singh;Sathya N. Ravi,~Zihang_Meng1;~Lopamudra_Mukherjee1;~Vikas_Singh1;~Sathya_N._Ravi1,5;3;6;5,5;5;2;4,Reject,0,8,0.0,yes,9/28/20,"University of Wisconsin, Madison;University of Wisconsin-Whitewater;University of Wisconsin, Madison;University of Illinois, Chicago",linear programming;nondecomposable functions;differentiable;AUC;Fscore,18;-1;18;-1,49;-1;49;-1,m;m,usa,usa,y,
7265,ICLR,2021,Coverage as a Principle for Discovering Transferable Behavior in Reinforcement Learning,V√≠ctor Campos;Pablo Sprechmann;Steven Stenberg Hansen;Andre Barreto;Charles Blundell;Alex Vitvitskyi;Steven Kapturowski;Adria Puigdomenech Badia,~V√≠ctor_Campos1;~Pablo_Sprechmann1;~Steven_Stenberg_Hansen1;~Andre_Barreto1;~Charles_Blundell1;avlife@google.com;~Steven_Kapturowski1;~Adria_Puigdomenech_Badia2,4;8;5;4,4;3;4;4,Reject,0,8,0.0,yes,9/28/20,DeepMind;DeepMind;DeepMind;DeepMind;DeepMind;;;DeepMind;DeepMind,deep reinforcement learning;transfer learning;unsupervised learning;exploration,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7266,ICLR,2021,A Unified Paths Perspective for Pruning at Initialization,Thomas Gebhart;Udit Saxena;Paul R. Schrater,~Thomas_Gebhart1;udit.umass@gmail.com;~Paul_R._Schrater1,4;4;6;6,5;3;3;3,Reject,0,5,0.0,yes,9/28/20,"University of Minnesota, Minneapolis;University of Massachusetts, Amherst;University of Minnesota - Twin Cities",Pruning;Paths;Neural Networks;Neural Tangent Kernel,71;23;71,85;210;85,m;m,NAN,NAN,y,8;1
7267,ICLR,2021,ROMUL: Scale Adaptative Population Based Training,Daniel HAZIZA;J√©r√©my Rapin;Gabriel Synnaeve,~Daniel_HAZIZA2;jrapin@fb.com;~Gabriel_Synnaeve1,6;4;4;3,5;4;4;4,Reject,0,8,0.0,yes,9/28/20,Facebook AI Research (FAIR);Facebook;Facebook,hyperparameter search;population based training;differential evolution;hyperparameter optimization;online optimization;deep learning,-1;-1;-1,-1;-1;-1,u;m,NAN,NAN,n,3
7268,ICLR,2021,Differentiable Weighted Finite-State Transducers,Awni Hannun;Vineel Pratap;Jacob Kahn;Wei-Ning Hsu,~Awni_Hannun1;vineelkpratap@fb.com;~Jacob_Kahn1;~Wei-Ning_Hsu2,6;4;5;6,5;5;4;5,Reject,0,5,0.0,yes,9/28/20,Facebook;;;Facebook AI Research;Massachusetts Institute of Technology,weighted automata;automatic differentiation;sequence models,-1;-1;-1;-1;5,-1;-1;-1;-1;4,m;m,usa,usa,n,10
7269,ICLR,2021,Task-Agnostic and Adaptive-Size BERT Compression,Jin Xu;Xu Tan;Renqian Luo;Kaitao Song;Li Jian;Tao Qin;Tie-Yan Liu,~Jin_Xu5;~Xu_Tan1;~Renqian_Luo1;~Kaitao_Song1;~Li_Jian1;~Tao_Qin1;~Tie-Yan_Liu1,7;6;6;5,3;4;5;5,Reject,0,12,0.0,yes,9/28/20,"Institute for Interdisciplinary Information Sciences, Tsinghua University;Microsoft;University of Science and Technology of China;Nanjing University of Science and Technology;University of Maryland, College Park;Tsinghua University;Microsoft",BERT compression;neural architecture search;adaptive sizes;across tasks;knowledge distillation,4;-1;-1;52;12;4;-1,20;-1;87;111;90;20;-1,m;m,NAN,NAN,n,3
7270,ICLR,2021,Deepening Hidden Representations from Pre-trained Language Models,Junjie Yang;hai zhao,~Junjie_Yang3;~hai_zhao1,5;6;4,4;4;5,Reject,0,4,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Natural Language Processing;Representation Learning,29;29,100;100,m;m,asia,cn,n,8;3
7271,ICLR,2021,BAFFLE: TOWARDS RESOLVING FEDERATED LEARNING‚ÄôS DILEMMA - THWARTING BACKDOOR  AND INFERENCE ATTACKS,Thien Duc Nguyen;Phillip Rieger;Hossein Yalame;Helen M√∂llering;Hossein Fereidooni;Samuel Marchal;Markus Miettinen;Azalia Mirhoseini;Ahmad-Reza Sadeghi;Thomas Schneider;Shaza Zeitouni,ducthien.nguyen@trust.tu-darmstadt.de;phillip.rieger@trust.tu-darmstadt.de;yalame@encrypto.cs.tu-darmstadt.de;moellering@encrypto.cs.tu-darmstadt.de;hossein.fereidooni@trust.tu-darmstadt.de;samuel.marchal@aalto.fi;markus.miettinen@trust.tu-darmstadt.de;~Azalia_Mirhoseini1;ahmad.sadeghi@trust.tu-darmstadt.de;schneider@encrypto.cs.tu-darmstadt.de;shaza.zeitouni@trust.tu-darmstadt.de,6;6;4;6,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,Technical University of Darmstadt;TU Darmstadt;;;Technical University of Darmstadt;;;;;TU Darmstadt;;;;;;;Technical University of Darmstadt,federated learning;secure machine learning;backdoor attacks;inference attacks;data privacy,-1;64;-1;-1;-1;-1;-1;-1;-1;64;-1;-1;-1;-1;-1;-1;-1,302;-1;-1;-1;302;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;302,m;u,NAN,NAN,n,4
7272,ICLR,2021,Information distance for neural network functions,Xiao Zhang;Dejing Dou;Ji Wu,~Xiao_Zhang9;~Dejing_Dou1;wuji_ee@mail.tsinghua.edu.cn,4;6;4;5,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;University of Oregon Eugene;;Tsinghua University,,4;209;-1;4,20;346;-1;20,u;u,asia,cn,n,
7273,ICLR,2021,Calibrated Adversarial Refinement for Stochastic Semantic Segmentation,Elias Kassapis;Georgi Dikov;Deepak Gupta;Cedric Nugteren,~Elias_Kassapis1;~Georgi_Dikov1;~Deepak_Gupta2;~Cedric_Nugteren1,6;6;6;4,4;3;3;4,Reject,0,12,0.0,yes,9/28/20,TomTom;TomTom;Transmute AI Research;TomTom,stochastic semantic segmentation;conditional generative models;adversarial training;calibration;uncertainty,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,2;4
7274,ICLR,2021,Isometric Autoencoders,Amos Gropp;Matan Atzmon;Yaron Lipman,amos.gropp@weizmann.ac.il;~Matan_Atzmon1;~Yaron_Lipman1,7;6;4;6,4;4;3;2,Reject,0,4,0.0,yes,9/28/20,"Weizmann Institute, Technion;Weizmann Institute;Facebook",manifold learning;autoencoders,29;110;-1,-1;-1;-1,m;m,NAN,NAN,y,1
7275,ICLR,2021,Learning disentangled representations with the Wasserstein Autoencoder,Benoit Gaujac;Ilya Feige;David Barber,~Benoit_Gaujac1;~Ilya_Feige1;~David_Barber2,8;5;5;6,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,University College London;University College London;University College London,generative modeling;disentangle learning;wasserstein autoencoder,53;53;53,-1;-1;-1,m;m,europe,uk,n,5
7276,ICLR,2021,Decentralized Deterministic Multi-Agent Reinforcement Learning,Antoine Grosnit;Desmond Cai;Laura Wynter,antoine.grosnit@polytechnique.edu;desmond.cai@gmail.com;~Laura_Wynter1,6;5;5;4;5,3;4;5;3;4,Reject,0,6,0.0,yes,9/28/20,Ecole Normale Superieure;California Institute of Technology;IBM Research,multiagent reinforcement learning;MARL;decentralized actor-critic algorithm,128;150;-1,-1;4;-1,m;f,NAN,NAN,y,
7277,ICLR,2021,Selfish Sparse RNN Training,SHiwei Liu;Decebal Constantin Mocanu;Yulong Pei;Mykola Pechenizkiy,~SHiwei_Liu1;~Decebal_Constantin_Mocanu1;~Yulong_Pei1;~Mykola_Pechenizkiy1,4;7;6;7,3;5;3;3,Reject,0,6,0.0,yes,9/28/20,Eindhoven University of Technology;University of Twente;Eindhoven University of Technology;Eindhoven University of Technology,dynamic sparse training;sparse neural networks;dynamic sparse RNN training;recurrent neural networks,-1;150;-1;-1,186;242;186;186,m;m,NAN,NAN,n,
7278,ICLR,2021,Addressing the Topological Defects of Disentanglement,Diane Bouchacourt;Mark Ibrahim;Stephane Deny,~Diane_Bouchacourt3;marksibrahim@fb.com;~Stephane_Deny1,5;3;7;6;6,4;4;4;3;4,Reject,0,13,0.0,yes,9/28/20,Facebook AI Research;Facebook AI Research (FAIR);Facebook AI (FAIR),Disentanglement;Equivariance;Topology;Representation theory;Character theory,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y,1
7279,ICLR,2021,A new accelerated gradient method inspired by continuous-time perspective,Yasong Feng;Weiguo Gao,~Yasong_Feng1;wggao@fudan.edu.cn,4;4;4;4,3;4;4;3,Reject,0,9,0.0,yes,9/28/20,Fudan University;Fudan University,accelerated gradient method;matrix completion;first-order methods;differential equation,71;71,70;70,u;m,asia,cn,y,
7280,ICLR,2021,Defective Convolutional Networks,Tiange Luo;Tianle Cai;Mengxiao Zhang;Siyu Chen;Di He;Liwei Wang,~Tiange_Luo1;~Tianle_Cai1;~Mengxiao_Zhang2;~Siyu_Chen1;~Di_He1;~Liwei_Wang1,6;6;6,4;3;4,Reject,0,6,0.0,yes,9/28/20,Peking University;Peking University;University of Southern California;Peking University;Microsoft;Peking University,Representation Learning;Robustness,14;14;37;14;-1;14,23;23;53;23;-1;23,m;m,asia,cn,n,4
7281,ICLR,2021,Improving Local Effectiveness for Global Robustness Training,JINGYUE LU;M. Pawan Kumar,~JINGYUE_LU1;~M._Pawan_Kumar1,4;5;5;5,5;5;5;4,Reject,0,6,0.0,yes,9/28/20,University of Oxford;University of Oxford,,46;46,1;1,u;m,europe,uk,n,
7282,ICLR,2021,Real-time Uncertainty Decomposition for Online Learning Control,Jonas Umlauft;Armin Lederer;Thomas Beckers;Sandra Hirche,~Jonas_Umlauft1;armin.lederer@tum.de;~Thomas_Beckers1;~Sandra_Hirche1,7;3;6;5,4;3;3;3,Reject,0,7,0.0,yes,9/28/20,Technical University Munich;Technical University Munich;Chair of Information-oriented Control;Technical University Munich,uncertainty decomposition;epistemic uncertainty;online learning;real-time control,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,
7283,ICLR,2021,Adversarial Privacy Preservation in MRI Scans of the Brain,Lennart Alexander Van der Goten;Tobias Hepp;Zeynep Akata;Kevin Smith,~Lennart_Alexander_Van_der_Goten1;~Tobias_Hepp1;~Zeynep_Akata1;~Kevin_Smith1,6;7;3;6;3,4;3;4;4;4,Reject,0,5,0.0,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden;Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of T√ºbingen;KTH Royal Institute of Technology",medical imaging;generative modeling;privacy;de-identification,174;-1;128;174,239;-1;78;239,m;m,europe,se,n,2;5
7284,ICLR,2021,Sparse Uncertainty Representation in Deep Learning with Inducing Weights,Hippolyt Ritter;Martin Kukla;Cheng Zhang;Yingzhen Li,~Hippolyt_Ritter1;~Martin_Kukla1;~Cheng_Zhang1;~Yingzhen_Li1,6;5;6;6,4;2;4;4,Reject,0,16,0.0,yes,9/28/20,University College London;University of Cambridge;KTH;Imperial College London,Bayesian neural networks;uncertainty estimation;memory efficiency,53;79;174;53,-1;6;239;11,u;u,europe,uk,n,11
7285,ICLR,2021,Membership Attacks on Conditional Generative Models Using Image Difficulty,Avital Shafran;Shmuel Peleg;Yedid Hoshen,avital.shafran@mail.huji.ac.il;~Shmuel_Peleg1;~Yedid_Hoshen3,6;5;6;6,3;3;3;3,Reject,0,4,0.0,yes,9/28/20,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Membership Inference Attack;Image translation,85;85;85,235;235;235,f;m,europe,il,n,4
7286,ICLR,2021,Inverse Constrained Reinforcement Learning,Shehryar Malik;Usman Anwar;Alireza Aghasi;Ali Ahmed,~Shehryar_Malik1;usman.anwar@itu.edu.pk;~Alireza_Aghasi2;~Ali_Ahmed1,7;4;6;5,4;4;4;4,Reject,0,16,0.0,yes,9/28/20,"ITU of Punjab Lahore, Pakistan;ITU of Punjab Lahore, Pakistan;Georgia State University;ITU of Punjab Lahore, Pakistan",Constrained reinforcement learning;constrain inference;safe reinforcement learning,-1;-1;327;-1,-1;-1;494;-1,m;m,NAN,NAN,n,10
7287,ICLR,2021,Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization,Stanislaw Kamil Jastrzebski;Devansh Arpit;Oliver √Östrand;Giancarlo Kerg;Huan Wang;Caiming Xiong;richard socher;Kyunghyun Cho;Krzysztof J. Geras,~Stanislaw_Kamil_Jastrzebski1;~Devansh_Arpit2;~Oliver_√Östrand1;~Giancarlo_Kerg1;~Huan_Wang1;~Caiming_Xiong1;~richard_socher1;~Kyunghyun_Cho1;~Krzysztof_J._Geras1,6;5;6;6,4;5;3;4,Reject,0,15,0.0,yes,9/28/20,Jagiellonian University;Salesforce Research;New York University;University of Montreal;Yale University;Salesforce Research;SalesForce.com;New York University;NYU Grossman School of Medicine,early phase of training;implicit regularization;SGD;learning rate;batch size;Hessian;Fisher Information Matrix;curvature;gradient norm,-1;-1;23;128;71;-1;-1;23;-1,596;-1;26;73;8;-1;-1;26;-1,m;m,NAN,NAN,n,1
7288,ICLR,2021,Dynamic of Stochastic Gradient Descent with State-dependent Noise,Qi Meng;Shiqi Gong;Wei Chen;Zhi-Ming Ma;Tie-Yan Liu,~Qi_Meng1;~Shiqi_Gong1;~Wei_Chen1;~Zhi-Ming_Ma1;~Tie-Yan_Liu1,6;5;6;5,4;5;3;3,Reject,0,7,0.0,yes,9/28/20,"Microsoft;Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Chinese Academy of Sciences;Microsoft;;Microsoft",state-dependent noise;power-law dynamic;stochastic gradient descent;generalization;deep neural network;heavy-tailed;escape time,-1;34;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
7289,ICLR,2021,Succinct Network Channel and Spatial Pruning via Discrete Variable QCQP,Yeonwoo Jeong;Deokjae Lee;Gaon An;Changyong Son;Hyun Oh Song,~Yeonwoo_Jeong1;~Deokjae_Lee1;~Gaon_An1;~Changyong_Son1;~Hyun_Oh_Song1,5;7;7;5,5;3;4;2,Reject,0,6,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Hanyang University;Seoul National University,Network Pruning;Channel pruning;Spatial pruning;Network Compression;MIQCQP;Specified target resource constraint,37;37;37;209;37,60;60;60;380;60,m;m,asia,kr,y,
7290,ICLR,2021,An information-theoretic framework for learning models of instance-independent label noise,Xia Huang;Kai Fong Ernest Chong,~Xia_Huang1;~Kai_Fong_Ernest_Chong1,4;5;5,4;3;3,Reject,0,11,0.0,yes,9/28/20,Singapore University of Technology and Design;Singapore University of Technology and Design,label noise;noise transition matrix;entropy;information theory;local intrinsic dimensionality,-1;-1,-1;-1,f;m,NAN,NAN,y,1
7291,ICLR,2021,Variance Based Sample Weighting for Supervised Deep Learning,Paul Novello;Ga√´l Po√´tte;David Lugato;Pietro Congedo,~Paul_Novello1;gael.poette@cea.fr;david.lugato@cea.fr;pietro.congedo@inria.fr,6;3;6;7,3;4;2;4,Reject,0,7,0.0,yes,9/28/20,CEA;;;;;;National research institute in digital sciences and technologies,supervised learning;sample distribution;statistical methods;sample weighting;approximation theory;Taylor expansion,209;-1;-1;-1;-1;-1;-1,969;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7292,ICLR,2021,Invertible Manifold Learning for Dimension Reduction,Siyuan Li;Haitao Lin;Zelin Zang;Lirong Wu;Jun Xia;Stan Z. Li,~Siyuan_Li6;~Haitao_Lin2;~Zelin_Zang2;~Lirong_Wu1;~Jun_Xia1;~Stan_Z._Li2,4;4;5;8,4;4;4;4,Reject,0,11,0.0,yes,9/28/20,"Westlake University;Westlake University;Westlake University;Westlake University;Westlake University, China;Westlake University",Manifold Learning;Inverse Model;Representation Learing,263;263;263;263;263;263,-1;-1;-1;-1;-1;-1,m;m,asia,cn,n,
7293,ICLR,2021,Learning the Connections in Direct Feedback Alignment,Matthew Bailey Webster;Jonghyun Choi;changwook Ahn,~Matthew_Bailey_Webster1;~Jonghyun_Choi1;cwan@gist.ac.kr,5;5;6,4;3;3,Reject,0,3,0.0,yes,9/28/20,Gwangju Institute of Science and Technology;Gwangju Institute of Science and Technology;;Gwangju Institute of Science and Technology,Deep Learning;Feedback Alignment;Backpropagation,-1;-1;-1;-1,506;506;-1;506,m;m,NAN,NAN,n,
7294,ICLR,2021,Efficient Reinforcement Learning in Resource Allocation Problems Through Permutation Invariant Multi-task Learning,Desmond Cai;Shiau Hong Lim;Laura Wynter,desmond.cai@gmail.com;~Shiau_Hong_Lim1;~Laura_Wynter1,5;7;5;5,3;4;2;2,Reject,0,4,0.0,yes,9/28/20,California Institute of Technology;IBM Research;IBM Research,,150;-1;-1,4;-1;-1,m;f,NAN,NAN,y,1
7295,ICLR,2021,ADIS-GAN: Affine Disentangled GAN,Letao Liu;Martin Saerbeck;Justin Dauwels,~Letao_Liu1;martin.saerbeck@tuvsud.com;jdauwels@ntu.edu.sg,5;4;3,2;2;2,Reject,0,3,0.0,yes,9/28/20,Nanyang Technological University;;;;Delft University of Technology,Deep Learning;Disentangled Representation;Generative Adversarial Network;Computer Vision,44;-1;-1;-1;-1,47;-1;-1;-1;78,u;m,NAN,NAN,n,1;5;4
7296,ICLR,2021,Contextual Knowledge Distillation for Transformer Compression,Geondo Park;Gyeongman Kim;Eunho Yang,~Geondo_Park1;~Gyeongman_Kim1;~Eunho_Yang1,5;6;5;6,3;5;4;4,Reject,0,14,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology,Knowledge Distillation;Transformer Compression;BERT,-1;-1;-1,96;96;-1,m;m,NAN,NAN,n,3
7297,ICLR,2021,On Disentangled Representations Learned From Correlated Data,Frederik Tr√§uble;Elliot Creager;Niki Kilbertus;Anirudh Goyal;Francesco Locatello;Bernhard Sch√∂lkopf;Stefan Bauer,~Frederik_Tr√§uble1;~Elliot_Creager1;~Niki_Kilbertus1;~Anirudh_Goyal1;~Francesco_Locatello1;~Bernhard_Sch√∂lkopf1;~Stefan_Bauer1,6;7;3,5;3;4,Reject,0,9,0.0,yes,9/28/20,", Max Planck Institute for Intelligent Systems;University of Toronto;Helmholtz AI;University of Montreal;Amazon;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Swiss Federal Institute of Technology",representation learning;disentanglement,-1;18;-1;128;-1;-1;-1,-1;18;-1;73;-1;-1;-1,m;m,NAN,NAN,y,
7298,ICLR,2021,Graph Autoencoders with Deconvolutional Networks,Jia Li;Jianwei Yu;Da-Cheng Juan;HAN Zhichao;Arjun Gopalan;Hong Cheng;Andrew Tomkins,~Jia_Li4;jwyu@se.cuhk.edu.hk;~Da-Cheng_Juan1;~HAN_Zhichao1;arjung@google.com;~Hong_Cheng1;~Andrew_Tomkins2,5;6;3;6,4;4;5;4,Reject,0,6,0.0,yes,9/28/20,The Chinese University of Hong Kong;The Chinese University of Hong Kong;Google Research;Swiss Federal Institute of Technology;;;;Google,graph autoencoders;graph deconvolutional networks,327;327;-1;-1;-1;-1;-1;-1,39;39;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,10
7299,ICLR,2021,TextSETTR: Label-Free Text Style Extraction and Tunable Targeted Restyling,Parker Riley;Noah Constant;Mandy Guo;Girish Kumar;David Uthus;Zarana Parekh,~Parker_Riley1;~Noah_Constant1;~Mandy_Guo2;~Girish_Kumar1;~David_Uthus1;~Zarana_Parekh2,5;5;6;5,2;4;2;4,Reject,0,8,0.0,yes,9/28/20,"Department of Computer Science, University of Rochester;Google;Cornell University;Stanford University;Google;Carnegie Mellon University",style transfer;text style;text generation;generative models;conditional generation,110;-1;7;5;-1;1,147;-1;19;2;-1;28,m;f,usa,usa,n,
7300,ICLR,2021,Feature-Robust Optimal Transport for High-Dimensional Data,Mathis Petrovich;Chao Liang;Ryoma Sato;Yanbin Liu;Yao-Hung Hubert Tsai;Linchao Zhu;Yi Yang;Ruslan Salakhutdinov;Makoto Yamada,mathis.petrovich@gmail.com;cs.chaoliang@zju.edu.cn;~Ryoma_Sato1;~Yanbin_Liu1;~Yao-Hung_Hubert_Tsai1;~Linchao_Zhu1;~Yi_Yang4;~Ruslan_Salakhutdinov1;~Makoto_Yamada3,4;3;6,4;3;4,Reject,0,4,0.0,yes,9/28/20,ENPC;Zhejiang University;Kyoto University;University of Technology Sydney;Carnegie Mellon University;University of Technology Sydney;Zhejiang University;Carnegie-Mellon University;Kyoto University,Optimal Transport;feature selection;semantic correspondence,-1;42;174;71;1;71;42;1;174,-1;94;54;160;28;160;94;28;54,m;m,europe,fi,y,5;4
7301,ICLR,2021,Reinforcement Learning with Latent Flow,Wenling Shang;Xiaofei Wang;Aravind Rajeswaran;Aravind Srinivas;Yang Gao;Pieter Abbeel;Michael Laskin,~Wenling_Shang1;w.xf@berkeley.edu;~Aravind_Rajeswaran1;~Aravind_Srinivas1;~Yang_Gao1;~Pieter_Abbeel2;~Michael_Laskin1,7;4;7;3,4;3;4;5,Reject,0,10,0.0,yes,9/28/20,"University of Amsterdam;University of California Berkeley;Facebook AI Research;University of California Berkeley;Tsinghua University, Tsinghua University;Covariant;University of California Berkeley",reinforcement learning;deep learning;machine learning;deep reinforcement learning,128;-1;-1;-1;4;-1;-1,66;7;-1;7;20;-1;7,f;m,usa,usa,n,
7302,ICLR,2021,Uncovering the impact of hyperparameters for global magnitude pruning,Janice Lan;Rudy Chin;Alexei Baevski;Ari S. Morcos,~Janice_Lan1;~Rudy_Chin2;~Alexei_Baevski1;~Ari_S._Morcos1,7;4;5;4,5;5;3;5,Reject,0,8,0.0,yes,9/28/20,Facebook;Carnegie Mellon University;Facebook;Facebook AI Research (FAIR),deep learning;pruning;understanding,-1;1;-1;-1,-1;28;-1;-1,f;m,NAN,NAN,n,
7303,ICLR,2021,Experience Replay with Likelihood-free Importance Weights,Samarth Sinha;Jiaming Song;Animesh Garg;Stefano Ermon,~Samarth_Sinha1;~Jiaming_Song1;~Animesh_Garg1;~Stefano_Ermon1,5;7;6;3,4;4;4;4,Reject,0,11,0.0,yes,9/28/20,"University of Toronto, Toronto University;Computer Science Department, Stanford University;University of Toronto;Stanford University",Experience Replay;Off-Policy Optimization;Deep Reinforcement Learning,18;5;18;5,18;2;18;2,m;m,usa,usa,y,
7304,ICLR,2021,RMIX: Risk-Sensitive Multi-Agent Reinforcement Learning,Wei Qiu;Xinrun Wang;Runsheng Yu;Xu He;Rundong Wang;Bo An;Svetlana Obraztsova;Zinovi Rabinovich,~Wei_Qiu3;~Xinrun_Wang1;runshengyu@gmail.com;hexu0003@e.ntu.edu.sg;~Rundong_Wang1;~Bo_An2;~Svetlana_Obraztsova1;~Zinovi_Rabinovich1,6;6;7;4,2;3;4;4,Reject,0,28,0.0,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;The Hong Kong University of Science and Technology;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University,Risk-sensitive learning;cooperative multi-agent reinforcement learning;reinforcement learning,44;44;-1;44;44;44;44;44,47;47;56;47;47;47;47;47,u;m,asia,sg,y,
7305,ICLR,2021,Learned Belief Search: Efficiently Improving Policies in Partially Observable Settings,Hengyuan Hu;Adam Lerer;Noam Brown;Jakob Nicolaus Foerster,~Hengyuan_Hu2;~Adam_Lerer1;~Noam_Brown2;~Jakob_Nicolaus_Foerster1,5;5;5;5;5,4;4;3;3;1,Reject,0,5,0.0,yes,9/28/20,Facebook AI Research;Facebook;Facebook;Facebook AI Research,Search;partially observable games;multi-agent learning;Hanabi,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
7306,ICLR,2021,Adversarially Robust Federated Learning for Neural Networks,Yao Zhou;Jun Wu;Jingrui He,~Yao_Zhou3;~Jun_Wu3;~Jingrui_He1,4;5;6;4,4;3;3;4,Reject,0,7,0.0,yes,9/28/20,"University of Illinois, Urbana-Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",federated learning;adversarial training;robustness;bias-variance decomposition,-1;-1;-1,-1;-1;-1,m;f,usa,usa,y,4
7307,ICLR,2021,Disentangled Generative Causal Representation Learning,Xinwei Shen;Furui Liu;Hanze Dong;Qing LIAN;Zhitang Chen;Tong Zhang,~Xinwei_Shen1;~Furui_Liu1;~Hanze_Dong1;~Qing_LIAN3;~Zhitang_Chen1;~Tong_Zhang2,5;6;6;5,4;3;4;5,Reject,0,8,0.0,yes,9/28/20,The Hong Kong University of Science and Technology;Huawei Technologies Ltd.;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Huawei Technologies Ltd.;Google,disentanglement;causality;representation learning;generative model,-1;-1;-1;-1;-1;-1,56;-1;56;56;-1;-1,f;m,NAN,NAN,y,5
7308,ICLR,2021,Adaptive Self-training for Neural Sequence Labeling with Few Labels,Yaqing Wang;Subhabrata Mukherjee;Haoda Chu;Yuancheng Tu;Ming Wu;Jing Gao;Ahmed Hassan Awadallah,~Yaqing_Wang1;~Subhabrata_Mukherjee2;haochu@microsoft.com;yuantu@microsoft.com;mingwu@microsoft.com;~Jing_Gao1;~Ahmed_Hassan_Awadallah1,7;7;4,2;3;4,Reject,0,8,0.0,yes,9/28/20,Purdue University;Microsoft;;;;;;Purdue University;Microsoft Research,Self-training;Neural Sequence Labeling;Meta Learning,23;-1;-1;-1;-1;-1;-1;23;-1,94;-1;-1;-1;-1;-1;-1;94;-1,m;m,NAN,NAN,n,6;3
7309,ICLR,2021,"Optimizing Transformers with Approximate Computing for Faster, Smaller and more Accurate NLP Models",Amrit Nagarajan;Sanchari Sen;Jacob R. Stevens;Anand Raghunathan,~Amrit_Nagarajan1;~Sanchari_Sen1;~Jacob_R._Stevens1;~Anand_Raghunathan1,4;5;7;6,5;4;4;4,Reject,0,7,0.0,yes,9/28/20,Purdue University;Purdue University;Purdue University;Purdue University,BERT;Transformer;NLP;Efficient;Faster;Smaller;Accurate,23;23;23;23,94;94;94;94,m;m,usa,usa,n,6;8;3
7310,ICLR,2021,Causal Screening to Interpret Graph Neural Networks,Xiang Wang;Yingxin Wu;An Zhang;Xiangnan He;Tat-seng Chua,~Xiang_Wang6;wuyxin@mail.ustc.edu.cn;~An_Zhang2;~Xiangnan_He1;~Tat-seng_Chua1,5;5;7;7,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,National University of Singapore;University of Science and Technology of China;National University of Singapore;University of Science and Technology of China;National University of Singapore,Feature Attribution;Graph Neural Networks;Explainable Methods;Causal Effect,17;-1;17;-1;17,25;87;25;87;25,m;m,asia,sg,n,8;10
7311,ICLR,2021,Near-Optimal Regret Bounds for Model-Free RL in Non-Stationary Episodic MDPs,Weichao Mao;Kaiqing Zhang;Ruihao Zhu;David Simchi-Levi;Tamer Basar,~Weichao_Mao1;~Kaiqing_Zhang3;~Ruihao_Zhu2;dslevi@mit.edu;~Tamer_Basar1,7;4;4;7,4;4;4;3,Reject,0,6,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;University of Illinois at Urbana-Champaign",reinforcement learning;non-stationary environment;model-free approach;regret analysis,-1;5;5;5;-1;-1,-1;4;4;4;-1;48,m;m,NAN,NAN,y,1
7312,ICLR,2021,Self-Supervised Video Representation Learning with Constrained Spatiotemporal Jigsaw,Yuqi Huo;Mingyu Ding;Haoyu Lu;Zhiwu Lu;Tao Xiang;Ji-Rong Wen;Ziyuan Huang;Jianwen Jiang;Shiwei Zhang;Mingqian Tang;Songfang Huang;Ping Luo,~Yuqi_Huo1;~Mingyu_Ding1;~Haoyu_Lu1;~Zhiwu_Lu1;~Tao_Xiang1;~Ji-Rong_Wen1;~Ziyuan_Huang1;~Jianwen_Jiang2;~Shiwei_Zhang2;~Mingqian_Tang1;~Songfang_Huang1;~Ping_Luo2,6;7;5;6,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,Renmin University of China;The University of Hong Kong;Renmin University of China;Renmin University of China;University of Surrey;Renmin University of China;National University of Singapore;Alibaba Group;Huazhong University of Science and Technology;Alibaba Group;Alibaba Group;The University of Hong Kong,self-supervised learning;video representation learning;spatiotemporal jigsaw,85;99;85;85;150;85;17;-1;-1;-1;-1;99,517;39;517;517;260;517;25;-1;312;-1;-1;39,u;m,NAN,NAN,n,
7313,ICLR,2021,Regioned Episodic Reinforcement Learning,Jiarui Jin;Cong Chen;Ming Zhou;Weinan Zhang;Rasool Fakoor;David Wipf;Yong Yu;Jun Wang;Alex Smola,~Jiarui_Jin1;chenconglzh@sjtu.edu.cn;~Ming_Zhou2;~Weinan_Zhang1;~Rasool_Fakoor1;~David_Wipf1;~Yong_Yu1;~Jun_Wang2;~Alex_Smola1,5;5;5;4,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,"Shanghai Jiao Tong University;Shanghai Jiao Tong University,;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Amazon;Amazon AI Research Lab;;University College London;Carnegie-Mellon University",Deep Reinforcement Learning;Episodic Memory;Sample Efficiency,29;29;29;29;-1;-1;-1;53;1,100;100;100;100;-1;-1;-1;-1;28,m;m,usa,usa,y,
7314,ICLR,2021,Signal Coding and Reconstruction using Spike Trains,Anik Chattopadhyay;Arunava Banerjee,~Anik_Chattopadhyay1;~Arunava_Banerjee2,5;3;7;3,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,University of Florida;;University of Florida,spike trains;signal encoding;reconstruction;kernel;representer theorem;compression;convolutional matching pursuit;COMP,150;-1;150,152;-1;152,m;m,usa,usa,y,9
7315,ICLR,2021,Efficient Sampling for Generative Adversarial Networks with Reparameterized Markov Chains,Yifei Wang;Yisen Wang;Jiansheng Yang;Zhouchen Lin,~Yifei_Wang1;~Yisen_Wang1;yjs@math.pku.edu.cn;~Zhouchen_Lin1,5;7;5;8,4;4;4;3,Reject,0,15,0.0,yes,9/28/20,Peking University;Peking University;;;Peking University,Generative Adverarial Networks;Sampling;Markov chain Monte Carlo;Reparameterization,14;14;-1;-1;14,23;23;-1;-1;23,m;m,asia,cn,n,5;4
7316,ICLR,2021,Differentially Private Generative Models Through Optimal Transport,Tianshi Cao;Alex Bie;Karsten Kreis;Sanja Fidler,~Tianshi_Cao1;abie@nvidia.com;~Karsten_Kreis1;~Sanja_Fidler1,4;4;6,3;3;2,Reject,0,7,0.0,yes,9/28/20,"University of Toronto;University of Waterloo;NVIDIA;Department of Computer Science, University of Toronto",Differential Privacy;Generative Learning;GAN;Optimal Transport,18;34;-1;18,18;232;-1;18,u;f,NAN,NAN,y,5;4
7317,ICLR,2021,MLR-SNet: Transferable LR Schedules for Heterogeneous Tasks,Jun Shu;Yanwen Zhu;Qian Zhao;Deyu Meng;Zongben Xu,~Jun_Shu1;zywwyz@stu.xjtu.edu.cn;~Qian_Zhao1;~Deyu_Meng1;~Zongben_Xu1,6;6;4;5,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Xi'an Jiaotong University;;;Xi'an Jiaotong University;;Xi'an Jiaotong University,Meta Learning;Hyperparameters Learning;Generalization on Tasks;Optimization;LR Schedules Learning;DNNs Training,-1;-1;-1;-1;-1;-1,445;-1;-1;445;-1;445,m;m,NAN,NAN,y,1;9
7318,ICLR,2021,Zero-Shot Learning with Common Sense Knowledge Graphs,Nihal Nayak;Stephen Bach,~Nihal_Nayak1;~Stephen_Bach1,7;4;4,5;4;5,Reject,0,9,0.0,yes,9/28/20,"Brown University;Computer Science Department, Brown University",Zero-Shot Learning;Common Sense Knowledge Graphs;Graph Neural Networks,85;85,61;61,m;m,NAN,NAN,n,6;8;10
7319,ICLR,2021,Open-world Semi-supervised Learning,Kaidi Cao;Maria Brbic;Jure Leskovec,~Kaidi_Cao1;mbrbic@cs.stanford.edu;~Jure_Leskovec1,6;6;6;6,4;4;3;4,Reject,0,7,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,deep learning;semi-supervised learning;novel class discovery;clustering,5;5;5,2;2;2,m;m,usa,usa,n,
7320,ICLR,2021,Rethinking Parameter Counting: Effective Dimensionality Revisited,Gregory Benton;Wesley Maddox;Andrew Gordon Wilson,~Gregory_Benton1;~Wesley_Maddox1;~Andrew_Gordon_Wilson1,6;6;4;5,3;3;4;3,Reject,0,9,0.0,yes,9/28/20,New York University;New York University;New York University,effective dimension;hessian;generalization;double descent,23;23;23,26;26;26,m;m,usa,usa,y,11;1
7321,ICLR,2021,Visual Imitation with Reinforcement Learning using Recurrent Siamese Networks,Glen Berseth;Florian Golemo;Christopher Pal,~Glen_Berseth1;~Florian_Golemo1;~Christopher_Pal1,4;5;4;6,4;4;3;4,Reject,0,18,0.0,yes,9/28/20,University of California Berkeley;Mila;Polytechnique Montreal,Reinforcement Learning;Imitation learning,-1;150;327,7;370;-1,m;m,canada,ca,n,
7322,ICLR,2021,Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction,Karl Willis;Yewen Pu;Jieliang Luo;Hang Chu;Tao Du;Joseph Lambourne;Armando Solar-Lezama;Wojciech Matusik,~Karl_Willis1;~Yewen_Pu1;~Jieliang_Luo1;~Hang_Chu4;~Tao_Du1;joseph.lambourne@autodesk.com;~Armando_Solar-Lezama1;~Wojciech_Matusik2,7;5;8;4,4;3;1;4,Reject,0,5,0.0,yes,9/28/20,Autodesk;Autodesk;Autodesk;Autodesk;Massachusetts Institute of Technology;Autodesk;Massachusetts Institute of Technology;Massachusetts Institute of Technology,CAD;dataset;3D;reconstruction;environment;design;sequence,-1;-1;-1;-1;5;-1;5;5,-1;-1;-1;-1;4;-1;4;4,m;m,usa,usa,n,
7323,ICLR,2021,Secure Byzantine-Robust Machine Learning,Lie He;Sai Praneeth Karimireddy;Martin Jaggi,~Lie_He1;~Sai_Praneeth_Karimireddy1;~Martin_Jaggi1,3;7;6;5,5;3;4;2,Reject,0,4,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;EPFL,Byzantine robustness;distributed learning;secure aggregation,-1;-1;23,-1;-1;-1,u;m,europe,ch,n,
7324,ICLR,2021,Parametric Copula-GP model for analyzing multidimensional neuronal and behavioral relationships,Nina Kudryashova;Theoklitos Amvrosiadis;Nathalie Dupuy;Nathalie Rochefort;Arno Onken,~Nina_Kudryashova1;t.amvrosiadis@ed.ac.uk;nathalie.dupuy@ed.ac.uk;n.rochefort@ed.ac.uk;~Arno_Onken1,7;5;5;6,4;4;4;3,Reject,0,9,0.0,yes,9/28/20,University of Edinburgh;;;;;;;University of Edinburgh,hierarchical vine copula model;copula;gaussian process;mutual information;neuroscience;neuronal activity;calcium imaging;visual cortex,29;-1;-1;-1;-1;-1;-1;29,30;-1;-1;-1;-1;-1;-1;30,f;m,europe,uk,n,11
7325,ICLR,2021,Cluster-Former: Clustering-based Sparse Transformer for Question Answering,Shuohang Wang;Luowei Zhou;Zhe Gan;Yen-Chun Chen;Yuwei Fang;Siqi Sun;Yu Cheng;Jingjing Liu,~Shuohang_Wang1;~Luowei_Zhou1;~Zhe_Gan1;~Yen-Chun_Chen1;yuwfan@microsoft.com;~Siqi_Sun2;~Yu_Cheng1;~Jingjing_Liu2,6;5;6;2,4;3;3;5,Reject,0,8,0.0,yes,9/28/20,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Toyota Technological Institute at Chicago;Microsoft Research;Microsoft,Transformer;Question Answering,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8
7326,ICLR,2021,Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds,Lirui Wang;Yu Xiang;Dieter Fox,~Lirui_Wang1;~Yu_Xiang3;~Dieter_Fox1,6;5;7,4;4;4,Reject,0,7,0.0,yes,9/28/20,"University of Washington, Seattle;NVIDIA;University of Washington",Robotics;Reinforcement Learning;Learning from Demonstration,11;-1;11,29;-1;29,m;m,usa,usa,n,
7327,ICLR,2021,Amortized Conditional Normalized Maximum Likelihood,Aurick Zhou;Sergey Levine,~Aurick_Zhou1;~Sergey_Levine1,6;5;6;5,3;3;3;3,Reject,0,7,0.0,yes,9/28/20,University of California Berkeley;University of Washington,Uncertainty Estimation;Calibration,-1;11,7;29,u;m,usa,usa,y,11
7328,ICLR,2021,Neuro-algorithmic Policies for Discrete Planning,Marin Vlastelica Poganƒçiƒá;Michal Rolinek;Georg Martius,~Marin_Vlastelica_Poganƒçiƒá1;~Michal_Rolinek2;~Georg_Martius1,3;4;7;3,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems",planning;reinforcement learning;combinatorial optimization;control;imitation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
7329,ICLR,2021,Parsed Categoric Encodings with Automunge,Nicholas Teague,~Nicholas_Teague1,4;6;4,4;2;5,Reject,0,13,0.0,yes,9/28/20,Automunge Inc.,tabular;feature engineering,-1,-1,m,NAN,NAN,n,10
7330,ICLR,2021,Brain-like approaches to unsupervised learning of hidden representations - a comparative study ,Naresh Balaji;Anders Lansner;Pawel Herman,~Naresh_Balaji1;ala@kth.se;paherman@kth.se,5;7;6;4,4;3;3;4,Reject,0,5,0.0,yes,9/28/20,KTH Royal Institute of Technology  Stockholm  Sweden;;;;KTH Royal Institute of Technology,neural networks;bio-inspired;brain-like;unsupervised learning;structural plasticity,174;-1;-1;-1;174,239;-1;-1;-1;239,m;m,europe,se,n,11
7331,ICLR,2021,Deep Goal-Oriented Clustering,Yifeng Shi;Christopher M Bender;Linnea Olsson;Melissa Troester;Katherine A Hoadley;Junier Oliva;Marc Niethammer,~Yifeng_Shi3;~Christopher_M_Bender1;lolsson@live.unc.edu;troester@unc.edu;hoadley@med.unc.edu;~Junier_Oliva1;~Marc_Niethammer1,3;4;5;6,4;4;3;4,Reject,0,6,0.0,yes,9/28/20,"Department of Computer Science, University of North Carolina, Chapel Hill;Department of Computer Science, University of North Carolina, Chapel Hill;;;;;;;University of North Carolina, Chapel Hill;University of North Carolina",clustering;variational inference,64;64;-1;-1;-1;-1;-1;-1;64;64,-1;-1;-1;-1;-1;-1;-1;-1;-1;56,m;m,usa,usa,n,
7332,ICLR,2021,Safety Aware Reinforcement Learning (SARL),Santiago Miret;Somdeb Majumdar;Carroll Wainwright,~Santiago_Miret1;~Somdeb_Majumdar1;carroll@partnershiponai.org,6;4;6;3,4;4;4;4,Reject,0,12,0.0,yes,9/28/20,"Intel;Intel;University of California, Santa Cruz",Reinforcement Learning;Safe RL;Probabilistic Distance Metrics,-1;-1;-1,-1;-1;207,m;m,usa,usa,n,
7333,ICLR,2021,Disentangling Representations of Text by Masking Transformers,Xiongyi Zhang;Jan-Willem van de Meent;Byron C Wallace,~Xiongyi_Zhang2;~Jan-Willem_van_de_Meent1;~Byron_C_Wallace1,6;6;5;5,4;4;4;3,Reject,0,8,0.0,yes,9/28/20,Northeastern University;Northeastern University;Northeastern University,disentanglement;model pruning;representation learning;transformers,16;16;16,895;895;895,m;m,usa,usa,n,8;3;5;4
7334,ICLR,2021,f-Domain-Adversarial Learning: Theory and Algorithms for Unsupervised Domain Adaptation with Neural Networks,David Acuna;Guojun Zhang;Marc T Law;Sanja Fidler,~David_Acuna1;~Guojun_Zhang1;~Marc_T_Law1;~Sanja_Fidler1,5;4;5;5,4;5;4;5,Reject,0,17,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of Waterloo;NVIDIA;Department of Computer Science, University of Toronto",Domain Adaptation;Adversarial Learning;Transfer Learning;Neural Networks;Deep Learning,18;34;-1;18,18;232;-1;18,m;f,NAN,NAN,y,1;4
7335,ICLR,2021,Augmented Sliced Wasserstein Distances,Xiongjie Chen;Yongxin Yang;Yunpeng Li,~Xiongjie_Chen1;~Yongxin_Yang1;~Yunpeng_Li1,7;6;4,3;4;3,Reject,0,4,0.0,yes,9/28/20,University of Surrey;University of Surrey;University of Surrey,,150;150;150,260;260;260,m;m,europe,uk,y,
7336,ICLR,2021,Adaptive Personalized Federated Learning,yuyang deng;Mohammad Mahdi Kamani;Mehrdad Mahdavi,~yuyang_deng1;~Mohammad_Mahdi_Kamani2;~Mehrdad_Mahdavi2,3;7;6;5,4;3;3;4,Reject,0,5,0.0,yes,9/28/20,Pennsylvania State University;Wyze Labs;Pennsylvania State University,Federated learning;Personalization;Optimization,44;-1;44,-1;-1;-1,m;m,usa,usa,y,1
7337,ICLR,2021,Block Skim Transformer for Efficient Question Answering,Yue Guan;Jingwen Leng;Yuhao Zhu;Minyi Guo,~Yue_Guan2;~Jingwen_Leng1;~Yuhao_Zhu1;~Minyi_Guo1,5;6;6;4,4;4;4;4,Reject,0,8,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of Rochester;Shanghai Jiao Tong University,Efficient Transformer;Question Answering,29;29;110;29,100;100;147;100,m;m,asia,cn,n,8;3
7338,ICLR,2021,"Poisoned classifiers are not only backdoored, they are fundamentally broken",Mingjie Sun;Siddhant Agarwal;J Zico Kolter,~Mingjie_Sun1;~Siddhant_Agarwal1;~J_Zico_Kolter1,7;2;5;5,4;5;3;3,Reject,0,8,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Indian Institute of Technology Kharagpur;Carnegie Mellon University",Backdoor Attacks;Denoised Smoothing;Perceptually-Aligned Gradients,1;-1;1,28;-1;28,u;m,usa,usa,n,4
7339,ICLR,2021,GenQu: A Hybrid System for Learning Classical Data in Quantum States,Samuel A. Stein;Ray Marie Tischio;Betis Baheri;Yiwen Chen;Ying Mao;Qiang Guan;Ang Li;Bo Fang,sstein17@fordham.edu;rtischio@fordham.edu;bbaheri@kent.edu;ychen638@fordham.edu;~Ying_Mao1;qguan@kent.edu;ang.li@pnnl.gov;bo.fang@pnnl.gov,3;4;3;2,4;4;5;5,Reject,0,6,0.0,yes,9/28/20,Fordham University;;;;;;;;Fordham University;;;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,Quantum Machine Learning;Qubits;Kernel Methods;Deep Neural Network,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7340,ICLR,2021,Uniform Priors for Data-Efficient Transfer,Samarth Sinha;Karsten Roth;Anirudh Goyal;Marzyeh Ghassemi;Hugo Larochelle;Animesh Garg,~Samarth_Sinha1;~Karsten_Roth1;~Anirudh_Goyal1;~Marzyeh_Ghassemi1;~Hugo_Larochelle1;~Animesh_Garg1,6;6;6;5,4;3;3;4,Reject,0,9,0.0,yes,9/28/20,"University of Toronto, Toronto University;University of Tuebingen;University of Montreal;University of Toronto;Google;University of Toronto",Meta Learning;Deep Metric Learning;Transfer Learning,18;128;128;18;-1;18,18;78;73;18;-1;18,m;m,canada,ca,n,6
7341,ICLR,2021,Linear Convergence and Implicit Regularization of Generalized Mirror Descent with Time-Dependent Mirrors,Adityanarayanan Radhakrishnan;Mikhail Belkin;Caroline Uhler,~Adityanarayanan_Radhakrishnan1;mbelkin@ucsd.edu;~Caroline_Uhler1,5;3;5;4,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,"Massachusetts Institute of Technology;University of California, San Diego;Electrical Engineering & Computer Science, Massachusetts Institute of Technology",Generalized Mirror Descent;Linear Convergence;Implicit Regularization,5;-1;5,4;33;4,m;f,NAN,NAN,y,1
7342,ICLR,2021,Continual learning using hash-routed convolutional neural networks,Ahmad Berjaoui,~Ahmad_Berjaoui1,6;4;6;4,4;4;3;4,Reject,0,7,0.0,yes,9/28/20,CentraleSupelec,Lifelong learning;continual learning;feature hashing,-1,578,m,NAN,NAN,n,
7343,ICLR,2021,Learning with Plasticity Rules: Generalization and Robustness,Rares C Cristian;Max Dabagia;Christos Papadimitriou;Santosh Vempala,~Rares_C_Cristian1;~Max_Dabagia1;~Christos_Papadimitriou2;~Santosh_Vempala1,5;7;7;4,4;3;3;4,Reject,0,5,0.0,yes,9/28/20,Massachusetts Institute of Technology;Georgia Institute of Technology;Columbia University;Georgia Institute of Technology,meta learning;plasticity;local learning;deep learning;machine learning;neural networks;RNNs;backpropagation;perceptron;evolution;adversarial examples,5;12;23;12,4;38;17;38,u;m,usa,usa,y,1;4
7344,ICLR,2021,Neural Architecture Search without Training,Joseph Mellor;Jack Turner;Amos Storkey;Elliot J. Crowley,joe.mellor@ed.ac.uk;~Jack_Turner1;~Amos_Storkey1;~Elliot_J._Crowley1,6;5;5;4,4;5;4;4,Reject,0,5,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh;University of Edinburgh;University of Edinburgh,NAS;efficiency;search;fast;cheap;convnets,29;29;29;29,30;30;30;30,m;m,europe,uk,n,
7345,ICLR,2021,It Is Likely That Your Loss Should be a Likelihood,Mark Hamilton;Evan Shelhamer;William T. Freeman,~Mark_Hamilton1;~Evan_Shelhamer2;~William_T._Freeman1,6;6;5;4,2;4;5;4,Reject,0,4,0.0,yes,9/28/20,Massachusetts Institute of Technology;DeepMind;Massachusetts Institute of Technology,Adaptive Losses;Outlier Detection;Adaptive Regularization;Recalibration;Robust Modelling,5;-1;5,4;-1;4,m;m,usa,usa,n,
7346,ICLR,2021,Optimal Transport Graph Neural Networks,Gary B√©cigneul;Octavian-Eugen Ganea;Benson Chen;Regina Barzilay;Tommi S. Jaakkola,~Gary_B√©cigneul1;~Octavian-Eugen_Ganea1;~Benson_Chen1;~Regina_Barzilay1;~Tommi_S._Jaakkola1,7;5;5;4,5;4;3;4,Reject,0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,graph neural networks;optimal transport;molecular representations;molecular property prediction,5;5;5;5;5,4;4;4;4;4,m;m,usa,usa,y,1;10
7347,ICLR,2021,Grounding Language to Entities for Generalization in Reinforcement Learning,H. J. Austin Wang;Karthik R Narasimhan,~H._J._Austin_Wang1;~Karthik_R_Narasimhan1,6;6;7;6;5,3;3;3;3;1,Reject,0,9,0.0,yes,9/28/20,Princeton University;Princeton University,reinforcement learning;language grounding,29;29,9;9,m;m,usa,usa,n,3;8;1;6
7348,ICLR,2021,Double Q-learning: New Analysis and Sharper Finite-time Bound,Lin Zhao;Huaqing Xiong;Yingbin Liang;Wei Zhang,~Lin_Zhao3;~Huaqing_Xiong1;~Yingbin_Liang1;~Wei_Zhang40,6;6;4;5,3;3;4;3,Reject,0,4,0.0,yes,9/28/20,National University of Singapore;Ohio State University;The Ohio State University;Southern University of Science and Technology of China,Double Q-learning;Finite-time analysis;Convergence rate;Stochastic approximation,17;58;58;-1,25;78;-1;87,m;m,NAN,NAN,y,9
7349,ICLR,2021,Practical Evaluation of Out-of-Distribution Detection Methods for Image Classification,Engkarat Techapanurak;Takayuki Okatani,~Engkarat_Techapanurak1;~Takayuki_Okatani1,4;4;8;3,4;4;5;3,Reject,0,6,0.0,yes,9/28/20,Tohoku University;RIKEN,out-of-distribution;novel class detection;domain shift;concept drift,-1;-1,213;-1,m;m,NAN,NAN,n,
7350,ICLR,2021,Equivariant Normalizing Flows for Point Processes and Sets,Marin Bilo≈°;Stephan G√ºnnemann,~Marin_Bilo≈°1;~Stephan_G√ºnnemann1,6;8;5;5,3;3;4;3,Reject,0,10,0.0,yes,9/28/20,Technical University Munich;Technical University Munich,point process;set;normalizing flow;equivariance,-1;-1,-1;-1,m;m,NAN,NAN,y,
7351,ICLR,2021,On Alignment in Deep Linear Neural Networks,Adityanarayanan Radhakrishnan;Eshaan Nichani;Daniel Bernstein;Caroline Uhler,~Adityanarayanan_Radhakrishnan1;~Eshaan_Nichani1;dibernst@mit.edu;~Caroline_Uhler1,4;4;7;4,4;4;3;5,Reject,0,5,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Electrical Engineering & Computer Science, Massachusetts Institute of Technology",Alignment;Linear Neural Networks;Implicit Regularization,5;5;5;5,4;4;4;4,m;f,NAN,NAN,y,1
7352,ICLR,2021,Debiased Graph Neural Networks with Agnostic Label Selection Bias,Shaohua Fan;Xiao Wang;Chuan Shi;Kun Kuang;Nian Liu;Bai Wang,~Shaohua_Fan1;xiaowang@bupt.edu.cn;shichuan@bupt.edu.cn;~Kun_Kuang1;nianliu@bupt.edu.cn;wangbai@bupt.edu.cn,5;4;8;4,4;4;4;2,Reject,0,8,0.0,yes,9/28/20,Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication  Tsinghua University;Zhejiang University  Tsinghua University;Beijing University of Post and Telecommunication  Tsinghua University;;Beijing University of Post and Telecommunication,GRAPH NEURAL NETWORKS;LABEL SELECTION BIAS,-1;-1;4;4;4;-1;-1,-1;-1;20;20;20;-1;-1,m;m,NAN,NAN,y,1;10
7353,ICLR,2021,GG-GAN: A Geometric Graph Generative Adversarial Network,Igor Krawczuk;Pedro Abranches;Andreas Loukas;Volkan Cevher,~Igor_Krawczuk1;pedro.abranches@epfl.ch;~Andreas_Loukas1;~Volkan_Cevher1,7;5;6;5;5,4;4;1;4;3,Reject,0,0,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,GAN;generative adversarial network;WGAN;GNN;graph neural network;generative model;graph,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,10;5;4
7354,ICLR,2021,Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?,Anna-Kathrin Kopetzki;Bertrand Charpentier;Daniel Z√ºgner;Sandhya Giri;Stephan G√ºnnemann,~Anna-Kathrin_Kopetzki1;~Bertrand_Charpentier2;~Daniel_Z√ºgner1;giri@in.tum.de;~Stephan_G√ºnnemann1,7;5;2;6,4;2;5;3,Reject,0,5,0.0,yes,9/28/20,"Department of Informatics, Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich",,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,4
7355,ICLR,2021,Breaking the Expressive Bottlenecks of Graph Neural Networks,Mingqi Yang;Yanming Shen;Heng Qi;Baocai Yin,~Mingqi_Yang1;shen@dlut.edu.cn;hengqi@dlut.edu.cn;~Baocai_Yin1,5;6;5;7;6,3;4;3;3;3,Reject,0,10,0.0,yes,9/28/20,Dalian University of Technology;Dalian University of Technology;;;Beijing University of Technology,graph representation learning;graph neural networks;expressive power,-1;-1;-1;-1;-1,694;694;-1;-1;1093,u;u,NAN,NAN,y,10
7356,ICLR,2021,Adversarial representation learning for synthetic replacement of private attributes,John Martinsson;Edvin Listo Zec;Daniel Gillblad;Olof Mogren,~John_Martinsson1;~Edvin_Listo_Zec1;~Daniel_Gillblad1;~Olof_Mogren1,5;5;4,2;3;4,Reject,0,3,0.0,yes,9/28/20,RISE Research Institutes of Sweden;RISE Research Institutes of Sweden;AI Sweden;RISE Research Institutes of Sweden,Deep learning;privacy;generative adversarial networks,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,4
7357,ICLR,2021,Variational Dynamic Mixtures,Chen Qiu;Stephan Mandt;Maja Rudolph,~Chen_Qiu1;~Stephan_Mandt1;~Maja_Rudolph3,7;7;4,3;4;3,Reject,0,6,0.0,yes,9/28/20,"Robert Bosch GmbH, Bosch;University of California, Irvine;Robert Bosch GmbH, Bosch",sequential latent variable models,-1;-1;-1,-1;98;-1,m;f,NAN,NAN,n,5
7358,ICLR,2021,Meta Adversarial Training,Jan Hendrik Metzen;Nicole Finnie;Robin Hutmacher,~Jan_Hendrik_Metzen1;~Nicole_Finnie2;~Robin_Hutmacher1,6;6;5,4;4;4,Reject,0,4,0.0,yes,9/28/20,"Bosch Center Artificial Intelligence;Bosch Center for Artificial Intelligence;Robert Bosch GmbH, Bosch",robustness;adversarial examples;adversarial training;physical-world adversarial attacks;adversarial patch;universal perturbation,-1;-1;-1,-1;-1;-1,m;u,NAN,NAN,n,6;4
7359,ICLR,2021,Autonomous Learning of Object-Centric Abstractions for High-Level Planning,Steven James;Benjamin Rosman;George Konidaris,~Steven_James1;~Benjamin_Rosman1;~George_Konidaris1,3;4;4;5,4;3;4;1,Reject,0,5,0.0,yes,9/28/20,University of the Witwatersrand;University of the Witwatersrand;Brown University,reinforcement learning;planning;PDDL;multitask;transfer;objects,-1;-1;85,206;206;61,m;m,usa,usa,n,
7360,ICLR,2021,One-class Classification Robust to Geometric Transformation,Hyunjun Ju;Dongha Lee;SeongKu Kang;Hwanjo Yu,~Hyunjun_Ju1;~Dongha_Lee1;seongku@postech.ac.kr;~Hwanjo_Yu1,5;4;4;6,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,POSTECH;POSTECH;POSTECH;POSTECH,one-class classification;image classification;object classification;self-supervised learning;geometric robustness,128;128;128;128,151;151;151;151,u;m,asia,kr,n,
7361,ICLR,2021,Self-Supervised Multi-View Learning via Auto-Encoding 3D Transformations,Xiang Gao;Wei Hu;Guo-Jun Qi,~Xiang_Gao2;~Wei_Hu6;~Guo-Jun_Qi1,7;4;6;6,4;5;4;2,Reject,0,4,0.0,yes,9/28/20,Peking University;Peking University;University of Central Florida,Self-supervised Learning;Multi-View Learning,14;14;71,23;23;633,m;m,usa,usa,n,2
7362,ICLR,2021,Which Model to Transfer? Finding the Needle in the Growing Haystack,Cedric Renggli;Andr√© Susano Pinto;Luka Rimanic;Joan Puigcerver;Carlos Riquelme Ruiz;Ce Zhang;Mario Lucic,~Cedric_Renggli1;~Andr√©_Susano_Pinto1;luka.rimanic@inf.ethz.ch;~Joan_Puigcerver1;~Carlos_Riquelme_Ruiz1;~Ce_Zhang1;~Mario_Lucic1,4;6;4;4,3;5;4;5,Reject,0,7,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;Research, Google;Swiss Federal Institute of Technology;Google;Google;Swiss Federal Institute of Technology;Google",,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
7363,ICLR,2021,ALT-MAS: A Data-Efficient Framework for Active Testing of Machine Learning Algorithms,Huong Ha;Sunil Gupta;Santu Rana;Svetha Venkatesh,~Huong_Ha3;~Sunil_Gupta2;~Santu_Rana1;~Svetha_Venkatesh1,3;4;8;6,4;5;4;4,Reject,0,6,0.0,yes,9/28/20,Royal Melbourne Institute of Technology;Deakin University;Deakin University;Deakin University,active learning;bayesian learning;machine learning testing;information theory,-1;-1;-1;-1,-1;295;295;295,f;f,asia,cn,n,11
7364,ICLR,2021,ChePAN: Constrained Black-Box Uncertainty Modelling with Quantile Regression,Axel Brando;Joan Gimeno;Jose Antonio Rodriguez-Serrano;Jordi Vitria,~Axel_Brando1;joan@maia.ub.edu;joseantonio.rodriguez.serrano@bbvadata.com;~Jordi_Vitria1,2;6;7;4;7,2;4;2;2;4,Reject,0,9,0.0,yes,9/28/20,Universitat de Barcelona;;;;;Universitat de Barcelona,Uncertainty modelling;Deep Learning;Black Box;Aleatoric;Quantile Regression;Chebyshev Polynomial;Neural networks,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7365,ICLR,2021,Hellinger Distance Constrained Regression,Egor Rotinov,~Egor_Rotinov1,4;3;4;5,5;4;4;2,Reject,0,5,0.0,yes,9/28/20,Bauman Moscow State Technical University,offline;Reinforcement Learning;off-policy;control,-1,483,m,NAN,NAN,y,1
7366,ICLR,2021,On the Effect of Consensus in Decentralized Deep Learning,Tao Lin;Lingjing Kong;Anastasia Koloskova;Martin Jaggi;Sebastian U Stich,~Tao_Lin1;lingjing.kong@epfl.ch;~Anastasia_Koloskova2;~Martin_Jaggi1;~Sebastian_U_Stich1,6;7;7;4,5;5;4;4,Reject,0,7,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Facebook;EPFL;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1;23;-1,-1;-1;-1;-1;-1,u;m,NAN,NAN,y,1
7367,ICLR,2021,A Simple and General Graph Neural Network with Stochastic Message Passing,Ziwei Zhang;Chenhao Niu;Peng Cui;Bo Zhang;Wei Cui;Wenwu Zhu,~Ziwei_Zhang1;nch16@mails.tsinghua.edu.cn;~Peng_Cui1;nevinzhang@tencent.com;cuiwei@songshuai.com;~Wenwu_Zhu1,3;6;7;8,5;2;4;4,Reject,0,17,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;;;Tsinghua University, Tsinghua University;;;;;Tsinghua University, Tsinghua University",Graph Neural Network;Node Proximity;Permutation-equivariant,4;-1;-1;4;-1;-1;-1;-1;4,20;-1;-1;20;-1;-1;-1;-1;20,m;m,NAN,NAN,y,1;10
7368,ICLR,2021,Deep Reinforcement Learning with Causality-based Intrinsic Reward,Peng Zhang;Furui Liu;Zhitang Chen;Jianye HAO;Jun Wang,~Peng_Zhang20;liufurui2@huawei.com;~Zhitang_Chen1;~Jianye_HAO1;~Jun_Wang2,5;6;6,3;3;4,Reject,0,6,0.0,yes,9/28/20,Tianjin University;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Tianjin University;University College London,Reinforcement Learning;Causal Relation,-1;-1;-1;-1;53,496;-1;-1;496;-1,m;m,europe,uk,n,10
7369,ICLR,2021,Addressing Distribution Shift in Online Reinforcement Learning with Offline Datasets,Seunghyun Lee;Younggyo Seo;Kimin Lee;Pieter Abbeel;Jinwoo Shin,~Seunghyun_Lee2;~Younggyo_Seo1;~Kimin_Lee1;~Pieter_Abbeel2;~Jinwoo_Shin1,6;5;4;3,2;4;4;4,Reject,0,11,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;University of California Berkeley;Covariant;Korea Advanced Institute of Science and Technology,reinforcement learning;offline reinforcement learning;control;distribution shift,-1;-1;-1;-1;-1,96;96;7;-1;96,m;m,NAN,NAN,n,
7370,ICLR,2021,Flatness is a False Friend,Diego Granziol,~Diego_Granziol1,4;6;3,4;3;5,Reject,0,0,0.0,yes,9/28/20,University of Oxford,,46,1,m,europe,uk,n,
7371,ICLR,2021,Conditional Coverage Estimation for High-quality Prediction Intervals,Ziyi Huang;Henry Lam;Haofeng Zhang,~Ziyi_Huang1;~Henry_Lam2;~Haofeng_Zhang1,4;4;8;7,3;4;4;4,Reject,0,18,0.0,yes,9/28/20,Columbia University;;Columbia University;Columbia University,,23;-1;23;23,17;-1;17;17,f;m,usa,usa,y,
7372,ICLR,2021,Deep Curvature Suite,Diego Granziol;Xingchen Wan;Timur Garipov,~Diego_Granziol1;~Xingchen_Wan1;~Timur_Garipov1,4;3;7;6,4;4;4;3,Reject,0,0,0.0,yes,9/28/20,"University of Oxford;University of Oxford, University of Oxford;Massachusetts Institute of Technology",Hessian computation;Deep Learning;Loss Curvature;Lanczos,46;46;5,1;1;4,m;m,usa,usa,y,11;1
7373,ICLR,2021,Early Stopping by Gradient Disparity,mahsa forouzesh;Patrick Thiran,~mahsa_forouzesh1;~Patrick_Thiran1,5;7;5;5,4;3;4;3,Reject,0,5,0.0,yes,9/28/20,"School of Computer and Communication Sciences, Swiss Federal Institute of Technology Lausanne;EPFL",Supervised Representation Learning;Deep Neural Networks;Generalization;Early Stopping,-1;23,-1;-1,f;m,europe,ch,y,1
7374,ICLR,2021,Learning Safe Policies with Cost-sensitive Advantage Estimation,Bingyi Kang;Shie Mannor;Jiashi Feng,~Bingyi_Kang1;~Shie_Mannor2;~Jiashi_Feng1,6;5;5;7;4,3;3;2;4;4,Reject,0,6,0.0,yes,9/28/20,National University of Singapore;Technion;National University of Singapore,Safe Reinforcement Learning,17;29;17,25;408;25,u;u,asia,sg,y,
7375,ICLR,2021,DIET-SNN: A Low-Latency Spiking Neural Network with Direct Input Encoding & Leakage and Threshold Optimization,Nitin Rathi;Kaushik Roy,~Nitin_Rathi1;~Kaushik_Roy1,5;6;3,4;4;4,Reject,0,10,0.0,yes,9/28/20,Purdue University;;Purdue University,Spiking neural networks;threshold optimization;leak optimization;input encoding;deep convolutional networks,23;-1;23,94;-1;94,m;m,usa,usa,n,
7376,ICLR,2021,Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams,Matthias De Lange;Tinne Tuytelaars,~Matthias_De_Lange1;~Tinne_Tuytelaars1,8;7;3,4;5;4,Reject,0,4,0.0,yes,9/28/20,"Department of Electrical Engineering, KU Leuven, Belgium, KU Leuven;KU Leuven",continual learning;prototypical learning;online learning;incremental learning;deep learning;representation learning;catastrophic forgetting;concept drift,150;150,45;45,m;f,europe,be,n,
7377,ICLR,2021,Revisiting the Train Loss: an Efficient Performance Estimator for Neural Architecture Search,Binxin Ru;Clare Lyle;Lisa Schut;Mark van der Wilk;Yarin Gal,~Binxin_Ru1;~Clare_Lyle1;~Lisa_Schut2;~Mark_van_der_Wilk1;~Yarin_Gal1,6;5;3,4;3;3,Reject,0,3,0.0,yes,9/28/20,"University of Oxford;University of Oxford;University of Oxford, University of Oxford;Imperial College London;University of Oxford",performance estimation;neural architecture search,46;46;46;53;46,1;1;1;11;1,m;m,europe,uk,n,11
7378,ICLR,2021,Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks,Sungryull Sohn;Sungtae Lee;Jongwook Choi;Harm van Seijen;Honglak Lee;Mehdi Fatemi,~Sungryull_Sohn1;~Sungtae_Lee1;~Jongwook_Choi1;~Harm_van_Seijen1;~Honglak_Lee2;~Mehdi_Fatemi1,6;6;6;6,3;4;5;3,Reject,0,12,0.0,yes,9/28/20,University of Michigan;Yonsei University;University of Michigan;Microsoft Research;LG AI Research;Microsoft,reinforcement learning;exploration;sample efficient reinforcement learning;sparse rewards,7;150;7;-1;-1;-1,22;186;22;-1;-1;-1,m;m,NAN,NAN,y,10
7379,ICLR,2021,Optimistic Policy Optimization with General Function Approximations,Qi Cai;Zhuoran Yang;Csaba Szepesvari;Zhaoran Wang,~Qi_Cai2;~Zhuoran_Yang1;~Csaba_Szepesvari1;~Zhaoran_Wang1,6;5;4;7,1;4;4;4,Reject,0,12,0.0,yes,9/28/20,Northwestern University;University of California Berkeley;University of Alberta;Northwestern University,,46;-1;110;46,24;7;131;24,u;m,usa,usa,y,
7380,ICLR,2021,Modifying Memories in Transformer Models,Chen Zhu;Ankit Singh Rawat;Manzil Zaheer;Srinadh Bhojanapalli;Daliang Li;Felix Yu;Sanjiv Kumar,~Chen_Zhu2;~Ankit_Singh_Rawat1;~Manzil_Zaheer1;~Srinadh_Bhojanapalli1;~Daliang_Li1;~Felix_Yu1;~Sanjiv_Kumar1,5;5;6;6,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;Google;Zaheer;Google;Harvard University;Google;Google",Transformers;memorization;question answering,-1;-1;-1;-1;53;-1;-1,90;-1;-1;-1;3;-1;-1,m;m,NAN,NAN,n,3;8;1
7381,ICLR,2021,Exploring single-path Architecture Search ranking correlations,Kevin Alexander Laube;Andreas Zell,~Kevin_Alexander_Laube1;~Andreas_Zell1,8;5;5;5,5;4;4;4,Reject,0,14,0.0,yes,9/28/20,University of Tuebingen;;University of T√ºbingen;Eberhard-Karls-Universit√§t T√ºbingen,Neural Architecture Search;AutoML;Neural Networks,128;-1;128;-1,78;-1;78;-1,m;m,NAN,NAN,n,6;8
7382,ICLR,2021,Global Attention Improves Graph Networks Generalization,Omri Puny;Heli Ben-Hamu;Yaron Lipman,~Omri_Puny1;~Heli_Ben-Hamu1;~Yaron_Lipman1,6;7;5;6,3;4;5;4,Reject,0,5,0.0,yes,9/28/20,"Weizmann Institute, Technion;Weizmann Institute, Technion;Facebook",Graph Neural Network;Self-Attention;Generalization of GNNs;Weisfeiler-Lehman,29;29;-1,-1;-1;-1,m;m,NAN,NAN,y,8;1;10
7383,ICLR,2021,BROS: A Pre-trained Language Model for Understanding Texts in Document,Teakgyu Hong;DongHyun Kim;Mingi Ji;Wonseok Hwang;Daehyun Nam;Sungrae Park,~Teakgyu_Hong1;~DongHyun_Kim3;~Mingi_Ji1;~Wonseok_Hwang1;~Daehyun_Nam2;~Sungrae_Park1,5;6;5;6,3;3;5;4,Reject,0,11,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;NAVER;Korea Advanced Institute of Science and Technology;NAVER;NAVER;UPSTAGE,Pre-trained model;language model;Document understanding;Document intelligence;OCR,-1;-1;-1;-1;-1;-1,96;-1;96;-1;-1;-1,u;m,NAN,NAN,n,2;3;10
7384,ICLR,2021,Measuring and Harnessing Transference in Multi-Task Learning,Chris Fifty;Ehsan Amid;Zhe Zhao;Tianhe Yu;Rohan Anil;Chelsea Finn,~Chris_Fifty1;~Ehsan_Amid1;~Zhe_Zhao3;~Tianhe_Yu1;~Rohan_Anil1;~Chelsea_Finn1,5;6;4;4,4;5;4;5,Reject,0,15,0.0,yes,9/28/20,Google;Google;Google;Stanford University;Google;Stanford University,multitask learning,-1;-1;-1;5;-1;5,-1;-1;-1;2;-1;2,m;f,usa,usa,n,
7385,ICLR,2021,On Proximal Policy Optimization's Heavy-Tailed Gradients ,Saurabh Garg;Joshua Zhanson;Emilio Parisotto;Adarsh Prasad;J Zico Kolter;Zachary Chase Lipton;Sivaraman Balakrishnan;Ruslan Salakhutdinov;Pradeep Kumar Ravikumar,~Saurabh_Garg3;jzhanson@andrew.cmu.edu;~Emilio_Parisotto1;~Adarsh_Prasad1;~J_Zico_Kolter1;~Zachary_Chase_Lipton1;~Sivaraman_Balakrishnan2;~Ruslan_Salakhutdinov1;~Pradeep_Kumar_Ravikumar1,7;8;5;5,4;4;3;4,Reject,0,8,0.0,yes,9/28/20,"Carnegie Mellon University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;;Carnegie Mellon University;Carnegie-Mellon University;Carnegie Mellon University",Heavy-tailed Gradients;Proximal Policy Optimization;Robust Estimation;Deep Reinforcement Learning,1;1;1;1;1;1;-1;1;1;1,28;28;28;28;28;28;-1;28;28;28,m;m,usa,usa,y,
7386,ICLR,2021,PriorityCut: Occlusion-aware Regularization for Image Animation,Wai Ting Cheung;Gyeongsu Chae,~Wai_Ting_Cheung1;~Gyeongsu_Chae1,4;2;5;5,3;5;2;4,Reject,0,7,0.0,yes,9/28/20,MoneyBrain Inc.;MoneyBrain Inc.,image animation;occlusion;inpainting;gan;augmentation;regularization,-1;-1,-1;-1,m;m,NAN,NAN,n,
7387,ICLR,2021,The Logical Options Framework,Brandon Araki;Xiao Li;Kiran Vodrahalli;Jonathan DeCastro;J Micah Fry;Daniela Rus,~Brandon_Araki1;~Xiao_Li1;~Kiran_Vodrahalli1;jonathan.decastro@tri.global;micah.fry@ll.mit.edu;~Daniela_Rus1,6;4;6;4,4;5;2;4,Reject,0,10,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Columbia University;Cornell University;;;Massachusetts Institute of Technology,reinforcement learning;hierarchical methods;formal methods;formal logic,5;5;23;7;-1;-1;5,4;4;17;19;-1;-1;4,m;f,usa,usa,n,1
7388,ICLR,2021,Accelerating Safe Reinforcement Learning with Constraint-mismatched Policies,Tsung-Yen Yang;Justinian Rosca;Karthik R Narasimhan;Peter Ramadge,~Tsung-Yen_Yang2;justinian.rosca@siemens.com;~Karthik_R_Narasimhan1;~Peter_Ramadge1,5;7;5;6,4;4;3;4,Reject,0,8,0.0,yes,9/28/20,Princeton University;Siemens Corp.;Princeton University;Princeton University,Reinforcement learning with constraints;Safe reinforcement learning,29;-1;29;29,9;-1;9;9,m;m,usa,usa,y,7
7389,ICLR,2021,OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data,Jongjin Park;Sukmin Yun;Jongheon Jeong;Jinwoo Shin,~Jongjin_Park1;~Sukmin_Yun1;~Jongheon_Jeong1;~Jinwoo_Shin1,7;4;5;4,4;4;5;5,Reject,0,6,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,semi-supervised learning;realistic semi-supervised learning;class-distribution mismatch;unsupervised learning,-1;-1;-1;-1,96;96;96;96,m;m,NAN,NAN,n,
7390,ICLR,2021,Continual Memory: Can We Reason After Long-Term Memorization?,Zhu Zhang;Chang Zhou;Zhou Zhao;Zhijie Lin;Jingren Zhou;Hongxia Yang,~Zhu_Zhang3;~Chang_Zhou2;~Zhou_Zhao2;~Zhijie_Lin1;~Jingren_Zhou1;~Hongxia_Yang2,6;4;5,4;2;3,Reject,0,6,0.0,yes,9/28/20,Alibaba Group;Peking University;Zhejiang University;Zhejiang University;;Duke University,Memory Augmented Neural Networks;Continual Memory;Reasoning After Long-Term Memorization,-1;14;42;42;-1;46,-1;23;94;94;-1;20,u;f,europe,se,n,
7391,ICLR,2021,A Reduction Approach to Constrained Reinforcement Learning,Tianchi Cai;Wenjie Shi;Lihong Gu;Xiaodong Zeng;Jinjie Gu,tianchi.ctc@antgroup.com;~Wenjie_Shi1;lihong.glh@antgroup.com;xiaodong.zxd@antgroup.com;jinjie.gujj@antgroup.com,5;6;7;5,4;3;2;2,Reject,0,4,0.0,yes,9/28/20,"Ant Group;Electronic Engineering, Tsinghua University, Tsinghua University;;;;Nanjing University",,-1;4;-1;-1;-1;52,-1;20;-1;-1;-1;111,m;u,asia,kr,y,1
7392,ICLR,2021,A Strong On-Policy Competitor To PPO,Xiangxiang Chu,~Xiangxiang_Chu1,5;5;5,4;4;4,Reject,0,5,0.0,yes,9/28/20,MeiTuan,proximal policy optimization;deep reinforcement learning,-1,-1,m,NAN,NAN,n,1
7393,ICLR,2021,Physics-aware Spatiotemporal Modules with Auxiliary Tasks for Meta-Learning,Sungyong Seo;Chuizheng Meng;Sirisha Rambhatla;Yan Liu,~Sungyong_Seo1;~Chuizheng_Meng1;~Sirisha_Rambhatla1;~Yan_Liu1,5;6;8;5;6,3;3;3;4;2,Reject,0,11,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California;University of Southern California,physics-aware learning;spatiotemporal graph signals;few shot learning,37;37;37;37,53;53;53;53,m;f,usa,usa,n,6
7394,ICLR,2021,Emergent Properties of Foveated Perceptual Systems,Arturo Deza;Talia Konkle,~Arturo_Deza1;talia_konkle@harvard.edu,5;3;7;7;7,4;4;3;3;4,Reject,0,17,0.0,yes,9/28/20,Massachusetts Institute of Technology;Harvard University,Hybrid Perceptual Systems;Foveation;Visual Crowding;Texture;Two-stage models,5;53,4;3,m;f,usa,usa,n,1
7395,ICLR,2021,PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks,Rudy Chin;Ari S. Morcos;Diana Marculescu,~Rudy_Chin2;~Ari_S._Morcos1;~Diana_Marculescu4,6;6;5;4,4;3;4;4,Reject,0,5,0.0,yes,9/28/20,"Carnegie Mellon University;Facebook AI Research (FAIR);University of Texas, Austin",Adaptive Neural Network;Slimmable Neural Network;Channel Optimization;Neural Architecture Search;Convolutional Neural Network;Image Classification,1;-1;-1,28;-1;-1,m;f,usa,usa,y,
7396,ICLR,2021,What's new? Summarizing Contributions in Scientific Literature,Hiroaki Hayashi;Wojciech Maciej Kryscinski;Bryan McCann;Nazneen Rajani;Caiming Xiong,~Hiroaki_Hayashi1;~Wojciech_Maciej_Kryscinski1;~Bryan_McCann1;~Nazneen_Rajani1;~Caiming_Xiong1,5;5;4;4,4;4;4;5,Reject,0,7,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;KTH Royal Institute of Technology, Stockholm, Sweden;SalesForce.com;University of Texas, Austin;Salesforce Research",abstractive summarization;scientific papers,1;174;-1;-1;-1,28;239;-1;-1;-1,u;m,NAN,NAN,n,
7397,ICLR,2021,Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations,Sarath Sreedharan;Utkarsh Soni;Mudit Verma;Siddharth Srivastava;Subbarao Kambhampati,~Sarath_Sreedharan1;~Utkarsh_Soni1;mverma13@asu.edu;~Siddharth_Srivastava2;~Subbarao_Kambhampati1,7;5;7;5;6,4;4;4;4;3,Reject,0,12,0.0,yes,9/28/20,Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University,Explanations;Concept based explanations;Learning symbolic representations;Sequential Decision Making;Planning;Reinforcement learning.,85;85;85;85;85,182;182;182;182;182,m;m,usa,usa,n,
7398,ICLR,2021,Overcoming barriers to the training of effective learned optimizers,Luke Metz;Niru Maheswaranathan;C. Daniel Freeman;Ben Poole;Jascha Sohl-Dickstein,~Luke_Metz1;~Niru_Maheswaranathan1;~C._Daniel_Freeman1;~Ben_Poole1;~Jascha_Sohl-Dickstein2,7;4;5,3;3;2,Reject,0,3,0.0,yes,9/28/20,Google;Facebook;Google Research;Google;Google,learned optimizers;meta-learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7399,ICLR,2021,Learning Flexible Classifiers with Shot-CONditional Episodic (SCONE) Training,Eleni Triantafillou;Vincent Dumoulin;Hugo Larochelle;Richard Zemel,~Eleni_Triantafillou1;~Vincent_Dumoulin1;~Hugo_Larochelle1;~Richard_Zemel1,6;6;4;5,5;3;4;1,Reject,0,9,0.0,yes,9/28/20,University of Toronto;Google;Google;University of Toronto,few-shot classification;few-shot learning;episodic training;meta-learning,18;-1;-1;18,18;-1;-1;18,f;m,canada,ca,n,6
7400,ICLR,2021,Decomposing Mutual Information for Representation Learning,Alessandro Sordoni;Nouha Dziri;Hannes Schulz;Geoff Gordon;Remi Tachet des Combes;Philip Bachman,~Alessandro_Sordoni2;dziri@ualberta.ca;~Hannes_Schulz1;~Geoff_Gordon2;~Remi_Tachet_des_Combes1;~Philip_Bachman1,5;5;6,3;5;3,Reject,0,6,0.0,yes,9/28/20,"Microsoft;, University of Alberta;University of Bonn;Microsoft;Microsoft Research;Microsoft",Mutual Information;Self-supervised learning,-1;110;128;-1;-1;-1,-1;131;114;-1;-1;-1,m;m,NAN,NAN,y,1
7401,ICLR,2021,Adaptive Discretization for Continuous Control using Particle Filtering Policy Network,Pei Xu;Ioannis Karamouzas,~Pei_Xu1;~Ioannis_Karamouzas1,5;7;5;4,3;3;4;3,Reject,0,8,0.0,yes,9/28/20,Clemson University;Clemson University,Reinforcement Learning;Continuous Control;Action Space Discretization;Policy Gradient,174;174,799;799,m;m,canada,ca,y,
7402,ICLR,2021,HALMA: Humanlike Abstraction Learning Meets Affordance in Rapid Problem Solving,Sirui Xie;Xiaojian Ma;Peiyu Yu;Yixin Zhu;Ying Nian Wu;Song-Chun Zhu,~Sirui_Xie1;~Xiaojian_Ma1;~Peiyu_Yu1;~Yixin_Zhu1;~Ying_Nian_Wu1;~Song-Chun_Zhu1,6;7;5;7,3;3;2;2,Reject,0,11,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;UCLA;University of California-Los Angeles",Visual Concept Development;Rapid Problem Solving;Abstract Reasoning,-1;-1;-1;-1;327;-1,15;15;15;15;16;15,m;m,usa,usa,n,1
7403,ICLR,2021,Offline policy selection under Uncertainty,Mengjiao Yang;Bo Dai;Ofir Nachum;George Tucker;Dale Schuurmans,~Mengjiao_Yang1;~Bo_Dai1;~Ofir_Nachum1;~George_Tucker1;~Dale_Schuurmans1,5;6;6,4;4;3,Reject,0,4,0.0,yes,9/28/20,Google;Google Brain;Google;Google Brain;University of Alberta,Off-policy selection;reinforcement learning;Bayesian inference,-1;-1;-1;-1;110,-1;-1;-1;-1;131,f;m,canada,ca,n,1
7404,ICLR,2021,Constructing Multiple High-Quality Deep Neural Networks: A TRUST-TECH Based Approach,Zhiyong Hao;Hsiao-Dong Chiang;Bin Wang,~Zhiyong_Hao1;~Hsiao-Dong_Chiang1;bw297@cornell.edu,6;5;6;5,3;3;4;3,Reject,0,7,0.0,yes,9/28/20,Cornell University;Cornell University;;Cornell University,Nonlinear Dynamical Systems;Global Optimization;Deep Neural Networks;Ensemble.,7;7;-1;7,19;19;-1;19,m;m,usa,usa,n,10
7405,ICLR,2021,Variational Auto-Encoder Architectures that Excel at Causal Inference,Negar Hassanpour;Russell Greiner,~Negar_Hassanpour1;~Russell_Greiner2,7;6;6;7,2;4;4;3,Reject,0,12,0.0,yes,9/28/20,University of Alberta;University of Alberta,Causal Inference;Generative Modelling;Distributional Shift,110;110,131;131,f;m,canada,ca,y,5
7406,ICLR,2021,Black-Box Optimization Revisited: Improving Algorithm Selection Wizards through Massive Benchmarking,Laurent Meunier;Herilalaina Rakotoarison;Jeremy Rapin;Paco Wong;Baptiste Roziere;Olivier Teytaud;Antoine Moreau;Carola Doerr,~Laurent_Meunier1;~Herilalaina_Rakotoarison1;jrapin@fb.com;paco.pkwong@gmail.com;broz@fb.com;~Olivier_Teytaud2;antoine.moreau@uca.fr;~Carola_Doerr1,6;5;7;9,3;4;3;5,Reject,0,18,0.0,yes,9/28/20,"Univerist√© Paris-Dauphine;INRIA;Facebook;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Facebook;Facebook;Universit√© Clermont Auvergne;LIP6, CNRS, Sorbonne Universit√©",black-box optimization;mujoco;wizard;benchmarking;BBOB;LSGO,-1;-1;-1;46;-1;-1;-1;-1,-1;-1;-1;39;-1;-1;-1;-1,m;f,NAN,NAN,n,
7407,ICLR,2021,Reducing Class Collapse in Metric Learning with Easy Positive Sampling,Elad Levi;Tete Xiao;Xiaolong Wang;trevor darrell,~Elad_Levi1;~Tete_Xiao1;~Xiaolong_Wang3;~trevor_darrell1,4;5;6;6,5;5;4;5,Reject,0,5,0.0,yes,9/28/20,"Hebrew University of Jerusalem, Technion;University of California Berkeley;University of California, San Diego;Electrical Engineering & Computer Science Department",,29;-1;-1;-1,235;7;33;-1,u;m,NAN,NAN,n,1
7408,ICLR,2021,Unpacking Information Bottlenecks: Surrogate Objectives for Deep Learning,Andreas Kirsch;Clare Lyle;Yarin Gal,~Andreas_Kirsch1;~Clare_Lyle1;~Yarin_Gal1,6;6;4;8,4;4;4;3,Reject,0,8,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,deep learning;information bottleneck;information theory,46;46;46,1;1;1,m;m,europe,uk,n,
7409,ICLR,2021,Fast Training of Contrastive Learning with Intermediate Contrastive Loss,Chengyue Gong;Xingchao Liu;qiang liu,~Chengyue_Gong1;~Xingchao_Liu1;~qiang_liu4,6;6;6;5,4;4;3;5,Reject,0,6,0.0,yes,9/28/20,"ut austin;University of Texas, Austin;University of Texas, Austin",,-1;-1;-1,-1;-1;-1,u;m,usa,usa,n,2
7410,ICLR,2021,PCPs: Patient Cardiac Prototypes,Dani Kiyasseh;Tingting Zhu;David A. Clifton,~Dani_Kiyasseh1;tingting.zhu@eng.ox.ac.uk;~David_A._Clifton1,2;5;7,5;4;3,Reject,0,5,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford,Contrastive learning;dataset distillation;patient-similarity;physiological signals;healthcare,46;46;46,1;1;1,m;m,europe,uk,n,
7411,ICLR,2021,Non-greedy Gradient-based Hyperparameter Optimization Over Long Horizons,Paul Micaelli;Amos Storkey,~Paul_Micaelli1;~Amos_Storkey1,7;7;5;6,2;2;2;4,Reject,0,7,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh,Hyperparameter optimization;Meta-learning,29;29,30;30,m;m,europe,uk,n,6
7412,ICLR,2021,SALR: Sharpness-aware Learning Rates for Improved Generalization,Xubo Yue;Maher Nouiehed;Raed Al Kontar,~Xubo_Yue1;~Maher_Nouiehed1;~Raed_Al_Kontar1,6;6;5;4,3;3;5;4,Reject,0,6,0.0,yes,9/28/20,University of Michigan;American University of Beirut;University of Michigan,Loss-surface;sharpness;learning rate;generalization,7;327;7,22;328;22,m;m,usa,usa,y,1
7413,ICLR,2021,Graph Deformer Network,Wenting Zhao;Yuan Fang;Zhen Cui;Tong Zhang;Jian Yang;Wei Liu,~Wenting_Zhao2;fangyuan@njust.edu.cn;~Zhen_Cui4;~Tong_Zhang8;~Jian_Yang1;~Wei_Liu3,5;4;7;5,4;4;5;5,Reject,0,0,0.0,yes,9/28/20,Nanjing University of Science and Technology;;;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Tencent AI Lab,Graph Convolution;Anchor Space;Anisotropic Convolution;Graph Classification;Node Classification,52;-1;-1;52;52;52;-1,111;-1;-1;111;111;111;-1,f;m,NAN,NAN,y,8;10
7414,ICLR,2021,Detection Booster Training: A detection booster training method for improving the accuracy of classifiers.,Ali Ghobadzadeh;Deepak Sridhar;Juwei Lu;Wei Li,~Ali_Ghobadzadeh1;~Deepak_Sridhar1;~Juwei_Lu2;~Wei_Li32,4;6;4,5;3;4,Reject,0,6,0.0,yes,9/28/20,Toronto University;Huawei Technologies Canada Co. Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd. (Canada),Representation Learning;Deep Learning Theory;Face Recognition;Image Classification;Parametric Estimation Theory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,2
7415,ICLR,2021,Neural Network Surgery: Combining Training with Topology Optimization,Elisabeth Schiessler;Roland Aydin;Kevin Linka;Christian Cyron,~Elisabeth_Schiessler1;~Roland_Aydin1;kevin.linka@tuhh.de;christian.cyron@hzg.de,4;4;5;4,4;4;2;4,Reject,0,2,0.0,yes,9/28/20,Helmholtz-Zentrum Geesthacht;Helmholtz-Zentrum Geesthacht;;Technische Universit√§t Hamburg;Hamburg University of Technology,Neural Architecture Search;Genetic Algorithm;SVD,-1;-1;-1;-1;453,-1;-1;-1;-1;608,f;m,europe,de,n,
7416,ICLR,2021,Meta-learning Transferable Representations with a Single Target Domain,Hong Liu;Jeff Z. HaoChen;Colin Wei;Tengyu Ma,~Hong_Liu5;~Jeff_Z._HaoChen1;~Colin_Wei1;~Tengyu_Ma1,6;6;5,3;4;3,Reject,0,10,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Stanford University;Computer Science Department, Stanford University;Stanford University",transfer learning;fine-tuning;supervised transfer learning,4;5;5;5,20;2;2;2,m;m,usa,usa,y,3;1;6
7417,ICLR,2021,A Unified Spectral Sparsification Framework for Directed Graphs,ying zhang;Zhiqiang Zhao;Zhuo Feng,yzhan232@stevens.edu;~Zhiqiang_Zhao1;~Zhuo_Feng3,3;5;4;7,3;4;2;4,Reject,0,9,0.0,yes,9/28/20,Stevens Institute of Technology;;Stevens Institute of Technology;Stevens Institute of Technology,Spectral Graph Theory;Spectral Sparsification;Directed Graphs;Laplacian Solver;PageRank Vectors,150;-1;150;150,567;-1;567;567,u;m,usa,usa,y,1;10
7418,ICLR,2021,Hybrid and Non-Uniform DNN quantization methods using Retro Synthesis data for efficient inference,TEJPRATAP GVSL;Raja Kumar;Pradeep NS,~TEJPRATAP_GVSL1;~Raja_Kumar2;pradeep.ns@samsung.com,6;4;4;4,5;5;4;4,Reject,0,8,0.0,yes,9/28/20,"Samsung;Indian Institute of Technology Kharagpur;BITS Pilani, Dhirubhai Ambani Institute Of Information and Communication Technology",quantization;dnn inference;data free quantization;synthetic data;model compression,-1;-1;453,-1;-1;-1,m;m,NAN,NAN,n,
7419,ICLR,2021,RetCL: A Selection-based Approach for Retrosynthesis via Contrastive Learning,Hankook Lee;Sungsoo Ahn;Seung-Woo Seo;You Young Song;Eunho Yang;Sung Ju Hwang;Jinwoo Shin,~Hankook_Lee1;~Sungsoo_Ahn1;~Seung-Woo_Seo3;~You_Young_Song1;~Eunho_Yang1;~Sung_Ju_Hwang1;~Jinwoo_Shin1,4;4;4;5,5;5;5;4,Reject,0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Mohamed Bin Zayed University of Artificial Intelligence;POSTECH;POSTECH;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,molecule;retrosynthesis;contrastive learning;graph representation learning,-1;-1;128;128;-1;-1;-1,96;874;151;151;-1;96;96,u;m,NAN,NAN,n,8;10
7420,ICLR,2021,Pointwise Binary Classification with Pairwise Confidence Comparisons,Lei Feng;Senlin Shu;Nan Lu;Bo Han;Miao Xu;Gang Niu;Bo An;Masashi Sugiyama,~Lei_Feng1;ssl2018@email.swu.edu.cn;~Nan_Lu1;~Bo_Han1;~Miao_Xu1;~Gang_Niu1;~Bo_An2;~Masashi_Sugiyama1,5;7;4,4;3;3,Reject,0,6,0.0,yes,9/28/20,"Nanyang Technological University, Singapore;Southwest University, China;The University of Tokyo;HKBU;University of Queensland;RIKEN;Nanyang Technological University;RIKEN Center for Advanced Intelligence Project",Binary classification;pairwise comparisons;unbiased risk estimator,44;-1;71;-1;209;-1;44;-1,47;-1;36;-1;62;-1;47;-1,m;m,NAN,NAN,y,1
7421,ICLR,2021,"With False Friends Like These, Who Can Have Self-Knowledge?",Lue Tao;Songcan Chen,~Lue_Tao1;~Songcan_Chen1,4;3;4;7,5;3;4;3,Reject,0,9,0.0,yes,9/28/20,Nanjing University of Aeronautics and Astronautics;Nanjing University of Aeronautics and Astronautics,Robustness;Adversarial Risk;Neural Networks;Machine Learning Security,52;52,1076;1076,m;m,NAN,NAN,y,1;4
7422,ICLR,2021,Attacking Few-Shot Classifiers with Adversarial Support Sets,Elre Talea Oldewage;John F Bronskill;Richard E Turner,~Elre_Talea_Oldewage1;~John_F_Bronskill1;~Richard_E_Turner1,6;6;4;6,4;3;4;3,Reject,0,7,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;University of Cambridge,meta-learning;few-shot learning;adversarial attacks;poisoning,79;79;79,6;6;6,f;m,europe,uk,n,6;4
7423,ICLR,2021,Semi-Supervised Learning of Multi-Object 3D Scene Representations,Cathrin Elich;Martin R. Oswald;Marc Pollefeys;Joerg Stueckler,~Cathrin_Elich1;~Martin_R._Oswald1;~Marc_Pollefeys2;~Joerg_Stueckler2,6;6;6,3;4;4,Reject,0,4,0.0,yes,9/28/20,"Swiss Federal Institute of Technology;ETH Zurich;Microsoft;Max Planck Institute for Intelligent Systems, Max-Planck Institute",scene understanding;representation learning;multi-object scene decomposition;pose estimation;shape and appearance estimation,-1;9;-1;-1,-1;14;-1;-1,f;m,NAN,NAN,n,5
7424,ICLR,2021,Information Theoretic Meta Learning with Gaussian Processes,Michalis Titsias;Sotirios Nikoloutsopoulos;Alexandre Galashov,~Michalis_Titsias1;snikolou@aueb.gr;~Alexandre_Galashov1,5;5;4;4,3;4;3;3,Reject,0,4,0.0,yes,9/28/20,Google DeepMind;Athens University of Economics and Business;Ecole Polytechnique,Meta Learning;Information Bottleneck;Gaussian Processes;Few-shot learning;Variational Inference,-1;-1;-1,-1;788;89,u;m,NAN,NAN,n,6
7425,ICLR,2021,AR-ELBO: Preventing Posterior Collapse Induced by Oversmoothing in Gaussian VAE,Yuhta Takida;Wei-Hsiang Liao;Toshimitsu Uesaka;Shusuke Takahashi;Yuki Mitsufuji,~Yuhta_Takida1;weihsiang.liao@sony.com;toshimitsu.uesaka@sony.com;shusuke.takahashi@sony.com;~Yuki_Mitsufuji1,7;6;4;6,4;4;3;4,Reject,0,6,0.0,yes,9/28/20,Sony Corporation;Sony Corporation;;;;Sony Corporation,Generative model;variational autoencoders;posterior collapse;regularization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,y,5
7426,ICLR,2021,Sparse Gaussian Process Variational Autoencoders,Matthew Ashman;Jonathan So;William Tebbutt;Vincent Fortuin;Michael Arthur Leopold Pearce;Richard E Turner,~Matthew_Ashman1;~Jonathan_So1;~William_Tebbutt1;~Vincent_Fortuin1;~Michael_Arthur_Leopold_Pearce1;~Richard_E_Turner1,6;6;6,4;3;3,Reject,0,6,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;University of Cambridge;Swiss Federal Institute of Technology;Anyvision;University of Cambridge,Gaussian process;variational inference;variational autoencoders;Bayesian inference,79;79;79;-1;-1;79,6;6;6;-1;-1;6,m;m,europe,uk,n,5
7427,ICLR,2021,Source-free Domain Adaptation via Distributional Alignment by Matching Batch Normalization Statistics,Masato Ishii;Masashi Sugiyama,~Masato_Ishii1;~Masashi_Sugiyama1,6;6;4,3;3;4,Reject,0,5,0.0,yes,9/28/20,Sony;RIKEN Center for Advanced Intelligence Project,domain adaptation;transfer learning,-1;-1,-1;-1,u;m,NAN,NAN,n,
7428,ICLR,2021,Few-Round Learning for Federated Learning,Younghyun Park;Dong-Jun Han;Do-Yeon Kim;Jun Seo;Jaekyun Moon,~Younghyun_Park1;~Dong-Jun_Han1;dy.kim@kaist.ac.kr;~Jun_Seo1;~Jaekyun_Moon2,4;5;4;3,5;4;4;5,Reject,0,7,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,Federated Learning,-1;-1;-1;-1;15,96;96;96;96;96,m;m,asia,in,n,6
7429,ICLR,2021,Gradient-based training of Gaussian Mixture Models for High-Dimensional Streaming Data,Alexander Gepperth;Benedikt Pf√ºlb,~Alexander_Gepperth1;~Benedikt_Pf√ºlb1,5;5;5;5;5,2;4;3;3;4,Reject,0,5,0.0,yes,9/28/20,HAW Fulda;University of Applied Sciences Fulda,Gaussian Mixture Models;Stochastic Gradient Descent;Unsupervised Representation Learning;Continual Learning,-1;-1,-1;-1,m;m,NAN,NAN,n,
7430,ICLR,2021,Stochastic Subset Selection for Efficient Training and Inference of Neural Networks,Andreis Bruno;Tuan Nguyen;Juho Lee;Eunho Yang;Sung Ju Hwang,~Andreis_Bruno1;~Tuan_Nguyen3;~Juho_Lee2;~Eunho_Yang1;~Sung_Ju_Hwang1,6;6;6;6,4;4;3;4,Reject,0,16,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;University of Oxford;KAIST;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology,efficient deep learning;meta learning;efficient training;data compression;instance selection,-1;46;15;-1;-1,96;1;96;-1;96,m;m,NAN,NAN,n,6
7431,ICLR,2021,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters,Ruize Wang;Duyu Tang;Nan Duan;zhongyu wei;Xuanjing Huang;Jianshu Ji;Guihong Cao;Daxin Jiang;Ming Zhou,~Ruize_Wang1;~Duyu_Tang1;~Nan_Duan1;~zhongyu_wei1;~Xuanjing_Huang1;jianshuj@microsoft.com;gucao@microsoft.com;djiang@microsoft.com;~Ming_Zhou1,6;7;4;6,3;3;4;4,Reject,0,6,0.0,yes,9/28/20,Fudan University;Harbin Institute of Technology;Microsoft Research Asia;Fudan University;Fudan University;;;;;Microsoft;Microsoft,,71;150;-1;71;71;-1;-1;-1;-1;-1;-1,70;416;-1;70;70;-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n,
7432,ICLR,2021,"Don't stack layers in graph neural networks, wire them randomly",Diego Valsesia;Giulia Fracastoro;Enrico Magli,~Diego_Valsesia1;~Giulia_Fracastoro1;~Enrico_Magli1,5;5;4;8,3;4;4;4,Reject,0,17,0.0,yes,9/28/20,Politecnico di Torino;Politecnico di Torino;Politecnico di Torino,Graph neural networks;random architectures,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;10
7433,ICLR,2021,Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution,Vihang Prakash Patil;Markus Hofmarcher;Marius-Constantin Dinu;Matthias Dorfer;Patrick M Blies;Johannes Brandstetter;Jose Arjona-Medina;Sepp Hochreiter,~Vihang_Prakash_Patil1;~Markus_Hofmarcher1;dinu@ml.jku.at;~Matthias_Dorfer1;~Patrick_M_Blies1;~Johannes_Brandstetter1;~Jose_Arjona-Medina1;~Sepp_Hochreiter1,6;5;7;7,3;4;4;4,Reject,0,8,0.0,yes,9/28/20,Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;EnliteAI GmbH;EnliteAI GmbH;Johannes Kepler University Linz;Institute for Machine Learning;Johannes Kepler University Linz,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
7434,ICLR,2021,CDT: Cascading Decision Trees for Explainable Reinforcement Learning,Zihan Ding;Pablo Hernandez-Leal;Gavin Weiguang Ding;Changjian Li;Ruitong Huang,~Zihan_Ding1;~Pablo_Hernandez-Leal2;~Gavin_Weiguang_Ding1;~Changjian_Li1;~Ruitong_Huang1,4;4;5;5,4;5;2;3,Reject,0,8,0.0,yes,9/28/20,Princeton University;Borealis AI;Borealis AI;University of Waterloo;Borealis AI,Explainable Reinforcement Learning;Decision Tree;Matrix Factorization,29;-1;-1;34;-1,9;-1;-1;232;-1,m;m,NAN,NAN,n,
7435,ICLR,2021,Transferring Inductive Biases through Knowledge Distillation,Samira Abnar;Mostafa Dehghani;Willem H. Zuidema,~Samira_Abnar1;~Mostafa_Dehghani1;~Willem_H._Zuidema1,7;3;5;5,4;5;4;3,Reject,0,33,0.0,yes,9/28/20,University of Amsterdam;Google Brain;;University of Amsterdam;University of Amsterdam,Knowledge Distillation;Inductive Biases;Analyzing and Understanding Neural Networks;Recurrent Inductive Bias,128;-1;-1;128;128,66;-1;-1;66;66,f;m,europe,nl,n,8
7436,ICLR,2021,A Unified View on Graph Neural Networks as Graph Signal Denoising,Yao Ma;Xiaorui Liu;Tong Zhao;Yozen Liu;Jiliang Tang;Neil Shah,~Yao_Ma3;~Xiaorui_Liu1;~Tong_Zhao3;yliu2@snap.com;~Jiliang_Tang1;nshah@snap.com,6;7;3;6;3,3;4;4;3;5,Reject,0,10,0.0,yes,9/28/20,Michigan State University;Michigan State University;University of Notre Dame;University of Southern California;Michigan State University;Snap Inc.,Graph Neural Networks;Graph Signal Denoising;Smoothness,110;110;128;37;110;-1,105;105;170;53;105;-1,m;m,NAN,NAN,y,10
7437,ICLR,2021,PIVEN: A Deep Neural Network for Prediction Intervals with Specific Value Prediction,Eli Simhayev;Gilad Katz;Lior Rokach,~Eli_Simhayev1;giladkz@post.bgu.ac.il;liorrk@post.bgu.ac.il,7;6;4;6,4;4;4;3,Reject,0,6,0.0,yes,9/28/20,"Ben Gurion University of the Negev;;;Ben Gurion University of the Negev, Technion",Prediction Intervals;Uncertainty Estimation;Regression,209;-1;-1;29,-1;-1;-1;-1,m;m,NAN,NAN,n,
7438,ICLR,2021,Sself: Robust Federated Learning against Stragglers and Adversaries,Jungwuk Park;Dong-Jun Han;Minseok Choi;Jaekyun Moon,savertm@kaist.ac.kr;~Dong-Jun_Han1;ejaqmf@jejunu.ac.kr;~Jaekyun_Moon2,4;4;5;4,4;3;3;3,Reject,0,5,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Jeju National University;KAIST,Federated Learning,-1;-1;-1;15,96;96;1328;96,m;m,asia,in,y,1;4
7439,ICLR,2021,CAFENet: Class-Agnostic Few-Shot Edge Detection Network,Younghyun Park;Jun Seo;Jaekyun Moon,~Younghyun_Park1;~Jun_Seo1;~Jaekyun_Moon2,4;6;4;4,5;3;5;5,Reject,0,4,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,Few-shot edge detection;Few-shot learning;Semantic edge detection,-1;-1;15,96;96;96,m;m,asia,in,n,6;2;8
7440,ICLR,2021,MC-LSTM: Mass-conserving LSTM,Pieter-Jan Hoedt;Frederik Kratzert;Daniel Klotz;Christina Halmich;Markus Holzleitner;Grey Nearing;Sepp Hochreiter;G√ºnter Klambauer,~Pieter-Jan_Hoedt1;~Frederik_Kratzert1;~Daniel_Klotz1;halmich@ml.jku.at;~Markus_Holzleitner1;gsnearing@google.com;~Sepp_Hochreiter1;~G√ºnter_Klambauer1,7;6;7;7,3;3;3;3,Reject,0,5,0.0,yes,9/28/20,Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz;;Johannes Kepler University Linz;;;Johannes Kepler University Linz;Johannes Kepler University Linz,LSTM;RNN;mass-conservation;neural arithmetic units;inductive bias;hydrology,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,2
7441,ICLR,2021,Beyond the Pixels: Exploring the Effects of Bit-Level Network and File Corruptions on Video Model Robustness,Trenton Chang;Daniel Yang Fu;Yixuan Li,~Trenton_Chang1;~Daniel_Yang_Fu1;~Yixuan_Li1,4;4;3;6,2;3;4;3,Reject,0,5,0.0,yes,9/28/20,"Stanford University;Stanford University;University of Wisconsin, Madison",robustness;machine learning;file corruption;network corruption;video,5;5;18,2;2;49,m;f,usa,usa,n,4
7442,ICLR,2021,Multi-agent Deep FBSDE Representation For Large Scale  Stochastic Differential Games,Tianrong Chen;Ziyi Wang;Ioannis Exarchos;Evangelos Theodorou,~Tianrong_Chen1;~Ziyi_Wang1;~Ioannis_Exarchos1;~Evangelos_Theodorou1,4;5;5,3;4;5,Reject,0,6,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology;Stanford University;Georgia Institute of Technology,Multi-agent Deep FBSDE Representation For Large Scale  Stochastic Differential Games,12;12;5;12,38;38;2;38,m;m,usa,usa,n,
7443,ICLR,2021,Apollo: An Adaptive Parameter-wised Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization,Xuezhe Ma,~Xuezhe_Ma1,4;5;5;4,4;4;3;4,Reject,0,7,0.0,yes,9/28/20,USC/ISI,Optimization;Stochastic Optimization;Nonconvex;Quasi-Newton;Neural Network;Deep Learning,-1,-1,m,NAN,NAN,y,1
7444,ICLR,2021,Hard-label Manifolds: Unexpected advantages of query efficiency for finding on-manifold adversarial examples,Washington Garcia;Pin-Yu Chen;Somesh Jha;Hamilton Scott Clouse;Kevin Butler,~Washington_Garcia1;~Pin-Yu_Chen1;~Somesh_Jha1;hamilton.clouse.1@us.af.mil;~Kevin_Butler1,4;5;3,2;3;4,Reject,0,8,0.0,yes,9/28/20,"University of Florida;International Business Machines;Department of Computer Science, University of Wisconsin, Madison;North Carolina State University;University of Florida",hard-label attacks;adversarial machine learning;generalization,150;-1;-1;92;150,152;-1;-1;340;152,m;m,usa,usa,n,1;4
7445,ICLR,2021,FedMes: Speeding Up Federated Learning with Multiple Edge Servers,Dong-Jun Han;Minseok Choi;Jungwuk Park;Jaekyun Moon,~Dong-Jun_Han1;ejaqmf@jejunu.ac.kr;savertm@kaist.ac.kr;~Jaekyun_Moon2,5;4;5,4;4;4,Reject,0,8,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Jeju National University;Korea Advanced Institute of Science and Technology;KAIST,Federated Learning;Edge Servers;Wireless Edge Networks,-1;-1;-1;15,96;1328;96;96,m;m,asia,in,n,
7446,ICLR,2021,Communication-Computation Efficient Secure Aggregation for Federated Learning,Beongjun Choi;Jy-yong Sohn;Dong-Jun Han;Jaekyun Moon,bbzang10@kaist.ac.kr;~Jy-yong_Sohn1;~Dong-Jun_Han1;~Jaekyun_Moon2,3;4;6;4,5;3;3;4,Reject,0,5,0.0,yes,9/28/20,"Korea Advanced Institute of Science and Technology;University of Wisconsin, Madison;Korea Advanced Institute of Science and Technology;KAIST",Federated Learning;Privacy;Graphs;Secure Aggregation;Communication-Efficient;Computation-Efficient,-1;18;-1;15,96;49;96;96,m;m,asia,in,y,10
7447,ICLR,2021,Differentiable Graph Optimization for Neural Architecture Search,Chengyue Huang;Lingfei Wu;Yadong Ding;Siliang Tang;Fangli Xu;Chang Zong;Chilie Tan;Yueting Zhuang,~Chengyue_Huang1;~Lingfei_Wu1;~Yadong_Ding1;~Siliang_Tang1;lili@yixue.us;zongchang@zju.edu.cn;chilie.tan@tongdun.net;~Yueting_Zhuang1,6;5;4,3;4;4,Reject,0,3,0.0,yes,9/28/20,Zhejiang University;JD.COM Silicon Valley Research Center;Zhejiang University;Zhejiang University;Squirrel AI Learning;Zhejiang University;;;;Zhejiang University;Zhejiang University,Neural Architecture Search;Graph Structure Learning,42;-1;42;42;-1;42;-1;-1;-1;42;42,94;-1;94;94;-1;94;-1;-1;-1;94;94,u;m,asia,cn,n,11;10
7448,ICLR,2021,Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning,Shariq Iqbal;Christian Schroeder de Witt;Bei Peng;Wendelin Boehmer;Shimon Whiteson;Fei Sha,~Shariq_Iqbal1;~Christian_Schroeder_de_Witt1;~Bei_Peng2;~Wendelin_Boehmer1;~Shimon_Whiteson1;~Fei_Sha3,5;5;7;6,4;3;4;4,Reject,0,6,0.0,yes,9/28/20,University of Southern California;University of Oxford;University of Oxford;Delft University of Technology;University of Oxford;University of Southern California,MARL;multi-agent reinforcement learning;value function factorization;attention,37;46;46;-1;46;37,53;1;1;78;1;53,m;m,usa,usa,n,8
7449,ICLR,2021,A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning,Dong-Ki Kim;Miao Liu;Matthew D Riemer;Chuangchuang Sun;Marwa Abdulhai;Golnaz Habibi;Sebastian Lopez-Cot;Gerald Tesauro;JONATHAN P HOW,~Dong-Ki_Kim1;~Miao_Liu1;~Matthew_D_Riemer1;~Chuangchuang_Sun1;abdulhai@mit.edu;~Golnaz_Habibi1;slcot@mit.edu;~Gerald_Tesauro1;~JONATHAN_P_HOW1,6;6;5;6,4;5;4;3,Reject,0,7,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Duke University;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;;IBM Research;Massachusetts Institute of Technology",Multiagent reinforcement learning;Meta-learning;Non-stationarity,5;46;128;5;5;5;-1;-1;-1;5,4;20;73;4;4;4;-1;-1;-1;4,m;m,usa,usa,n,1
7450,ICLR,2021,SketchEmbedNet: Learning Novel Concepts by Imitating Drawings,Alexander Wang;Mengye Ren;Richard Zemel,~Alexander_Wang1;~Mengye_Ren1;~Richard_Zemel1,6;6;4;9,3;4;3;4,Reject,0,8,0.0,yes,9/28/20,"Department of Computer Science, University of Toronto;University of Toronto;University of Toronto",generative;probabilistic;sketch;drawing;few-shot learning;classification;embedding learning,18;18;18,18;18;18,m;m,canada,ca,n,6;5
7451,ICLR,2021,Differentially Private Synthetic Data: Applied Evaluations and Enhancements,Lucas Rosenblatt;Xiaoyan Liu;Samira Pouyanfar;Eduardo de Leon;Anuj Desai;Joshua Allen,~Lucas_Rosenblatt1;~Xiaoyan_Liu1;sapouyan@microsoft.com;eddeleon@microsoft.com;andesai@microsoft.com;joshuaa@microsoft.com,4;4;4,4;3;4,Reject,0,5,0.0,yes,9/28/20,Brown University;Microsoft;Microsoft;;University of California Berkeley;;Microsoft,privacy;differential privacy;generative adversarial networks;gan;security;synthetic data;evaluation;benchmarking;ensemble,85;-1;-1;-1;-1;-1;-1,61;-1;-1;-1;7;-1;-1,m;m,NAN,NAN,n,10;5;4
7452,ICLR,2021,SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks,Bahare Fatemi;Seyed Mehran Kazemi;Layla El Asri,~Bahare_Fatemi1;~Seyed_Mehran_Kazemi1;~Layla_El_Asri2,5;5;7;5;5,4;4;3;4;3,Reject,0,11,0.0,yes,9/28/20,University of British Columbia;Borealis AI;Universite de Lorraine,Graph Neural Networks;Graph Representation Learning;Graph Structure Learning;Self-supervision,58;-1;-1,34;-1;-1,f;f,NAN,NAN,n,10
7453,ICLR,2021,On Single-environment Extrapolations in Graph Classification and Regression Tasks,Beatrice Bevilacqua;Yangze Zhou;Ryan L Murphy;Bruno Ribeiro,~Beatrice_Bevilacqua1;~Yangze_Zhou1;~Ryan_L_Murphy1;~Bruno_Ribeiro1,3;5;8,5;2;2,Reject,0,14,0.0,yes,9/28/20,Purdue University;Purdue University;Purdue University;Purdue University,Extrapolation;Graphs;GNNs;SCM;Causality;Counterfactual Inference,23;23;23;23,94;94;94;94,f;m,usa,usa,y,10
7454,ICLR,2021,Neural Ensemble Search for Uncertainty Estimation and Dataset Shift,Sheheryar Zaidi;Arber Zela;Thomas Elsken;Chris Holmes;Frank Hutter;Yee Whye Teh,~Sheheryar_Zaidi1;~Arber_Zela1;~Thomas_Elsken1;chris.holmes@stats.ox.ac.uk;~Frank_Hutter1;~Yee_Whye_Teh1,5;4;6;4,4;5;4;5,Reject,0,11,0.0,yes,9/28/20,"University of Oxford;Universit√§t Freiburg;Machine Learning Lab, University of Freiburg;;;University of Freiburg & Bosch;University of Oxford and DeepMind",uncertainty estimation;deep ensemble;dataset shift;robustness;uncertainty calibration,46;-1;150;-1;-1;150;46,1;-1;83;-1;-1;83;1,m;m,NAN,NAN,y,
7455,ICLR,2021,Training Federated GANs  with Theoretical Guarantees: A Universal Aggregation Approach,Yikai Zhang;Hui Qu;Huidong Liu;Qi Chang;Dimitris N. Metaxas;Chao Chen,~Yikai_Zhang1;~Hui_Qu1;~Huidong_Liu1;~Qi_Chang1;~Dimitris_N._Metaxas1;~Chao_Chen1,6;5;6;3,4;4;4;3,Reject,0,5,0.0,yes,9/28/20,"Rutgers University;Rutgers University;State University of New York, Stony Brook;Rutgers University;Rutgers University;State University of New York, Stony Brook",Federated Learning;GAN;Deep Learning,29;29;-1;29;29;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1;5;4
7456,ICLR,2021,Parallel Training of Deep Networks with Local Updates,Michael Laskin;Luke Metz;Seth Nabarro;Mark Saroufim;Badreddine Noune;Carlo Luschi;Jascha Sohl-Dickstein;Pieter Abbeel,~Michael_Laskin1;~Luke_Metz1;sethn@graphcore.ai;marks@graphcore.ai;badreddine@graphcore.ai;carlo@graphcore.ai;~Jascha_Sohl-Dickstein2;~Pieter_Abbeel2,9;6;3;4,3;4;5;3,Reject,0,4,0.0,yes,9/28/20,University of California Berkeley;Google;Imperial College London;Graphcore;University of Bristol;Graphcore;Google;Covariant,deep learning;parallelized training;local learning;compute-efficient learning;hebbian learning;biologically inspired learning,-1;-1;53;-1;110;-1;-1;-1,7;-1;11;-1;91;-1;-1;-1,m;m,NAN,NAN,n,
7457,ICLR,2021,On the Dynamic Regret of Online Multiple Mirror Descent,Nima Eshraghi;and Ben Liang,~Nima_Eshraghi1;~and_Ben_Liang1,5;4;4,4;4;4,Reject,0,6,0.0,yes,9/28/20,Toronto University;Toronto University,Online learning;Online Convex Optimization;Mirror Descent,-1;-1,-1;-1,m;m,NAN,NAN,y,1;9
7458,ICLR,2021,Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning,Amrita Saha;Shafiq Joty;Steven Hoi,~Amrita_Saha1;~Shafiq_Joty1;~Steven_Hoi2,6;4;7;5,2;4;3;3,Reject,0,10,0.0,yes,9/28/20,SalesForce Research;SalesForce.com;Salesforce Research Asia,neural module networks;machine reading comprehension;numerical reasoning over text,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,3
7459,ICLR,2021,Improving Few-Shot Visual Classification with Unlabelled Examples,Peyman Bateni;Jarred Barber;Jan-Willem van de Meent;Frank Wood,~Peyman_Bateni1;jarred.barber@gmail.com;~Jan-Willem_van_de_Meent1;~Frank_Wood2,6;5;5;6,3;4;3;3,Reject,0,8,0.0,yes,9/28/20,University of British Columbia;Johns Hopkins University;Northeastern University;University of British Columbia,Meta-learning;Few-shot image classification;Transductive few-shot learning,58;71;16;58,34;12;895;34,m;m,canada,ca,n,6
7460,ICLR,2021,ABSTRACTING INFLUENCE PATHS  FOR EXPLAINING (CONTEXTUALIZATION OF) BERT MODELS,Kaiji Lu;Zifan Wang;Piotr Mardziel;Anupam Datta,~Kaiji_Lu1;~Zifan_Wang1;piotrm@gmail.com;~Anupam_Datta2,6;6;6;6,3;4;3;4,Reject,0,8,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Truera;Carnegie-Mellon University,interpretability;natural language processing;transformer;BERT,1;1;-1;1,28;28;-1;28,m;m,usa,usa,n,8
7461,ICLR,2021,Encoded Prior Sliced Wasserstein AutoEncoder for learning latent manifold representations,Sanjukta Krishnagopal;Jacob Bedrossian,~Sanjukta_Krishnagopal1;jacob@math.umd.edu,7;5;5,4;4;4,Reject,0,12,0.0,yes,9/28/20,University College London;;University of Maryland,VAE;sliced Wasserstein distance;latent representation;interpolation;manifold embedding;geodesics;network algorithm,53;-1;12,-1;-1;90,f;m,NAN,NAN,n,10;5;4
7462,ICLR,2021,Active Feature Acquisition with Generative Surrogate Models,Yang Li;Junier Oliva,~Yang_Li19;~Junier_Oliva1,5;6;4;7,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,"University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",Reinforcement Learning;Active Feature Acquisition;Feature Selection,64;64,-1;-1,m;m,NAN,NAN,n,5
7463,ICLR,2021,Towards Practical Second Order Optimization for Deep Learning,Rohan Anil;Vineet Gupta;Tomer Koren;Kevin Regan;Yoram Singer,~Rohan_Anil1;~Vineet_Gupta1;~Tomer_Koren1;kevinregan@google.com;~Yoram_Singer3,6;7;7,3;4;2,Reject,0,6,0.0,yes,9/28/20,Google;Google;Tel Aviv University;University of Toronto;;Princeton University,large scale distributed deep learning;second order optimization;bert;resnet;criteo;transformer;machine translation,-1;-1;34;18;-1;29,-1;-1;190;18;-1;9,m;m,usa,usa,y,8;3
7464,ICLR,2021,Multiscale Invertible Generative Networks for High-Dimensional Bayesian Inference,Shumao Zhang;Thomas Hou;Pengchuan Zhang,~Shumao_Zhang1;~Thomas_Hou2;~Pengchuan_Zhang1,6;5;6,3;1;3,Reject,0,4,0.0,yes,9/28/20,California Institute of Technology;California Institute of Technology;California Institute of Technology,,150;150;150,4;4;4,m;m,usa,usa,y,11;5
7465,ICLR,2021,Semi-supervised regression with skewed data via adversarially forcing the distribution of predicted values,Dae-Woong Jeong;Kiyoung Kim;Changyoung Park;Sehui Han;Woohyung Lim,~Dae-Woong_Jeong1;elgee.kim@lgsp.co.kr;changyoung.park@lgsp.co.kr;hanssse.han@lgsp.co.kr;~Woohyung_Lim1,5;6;4;5,2;3;3;4,Reject,0,7,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Seoul National University;;;;;LG AI Research,Semi-supervised learning;Adversarial;regression,-1;37;-1;-1;-1;-1;-1,96;60;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,4
7466,ICLR,2021,Ask Question with Double Hints:  Visual Question Generation with Answer-awareness and Region-reference,Shen Kai;Lingfei Wu;Siliang Tang;Fangli Xu;Zhu Zhang;Yu Qiang;Yueting Zhuang,~Shen_Kai1;~Lingfei_Wu1;~Siliang_Tang1;~Fangli_Xu2;~Zhu_Zhang3;~Yu_Qiang1;~Yueting_Zhuang1,6;6;5;6,3;5;5;5,Reject,0,7,0.0,yes,9/28/20,Zhejiang University;JD.COM Silicon Valley Research Center;Zhejiang University;Squirrel AI Learning;Alibaba Group;Zhejiang University;;Zhejiang University;Zhejiang University,Semi-supervised Learning;graph neural network;vision and language;question generation,42;-1;42;-1;-1;42;-1;42;42,94;-1;94;-1;-1;94;-1;94;94,u;m,asia,cn,n,10
7467,ICLR,2021,Neural networks behave as hash encoders: An empirical study,Fengxiang He;Shiye Lei;Jianmin Ji;Dacheng Tao,~Fengxiang_He1;leishiye@gmail.com;jianmin@ustc.edu.cn;~Dacheng_Tao1,6;6;7;5,4;2;4;4,Reject,0,10,0.0,yes,9/28/20,"The University of Sydney;University of Sydney;University of Science and Technology of China, Tsinghua University;JD.com",Explainability of deep learning,71;71;4;-1,51;51;20;-1,m;m,NAN,NAN,n,
7468,ICLR,2021,Online Learning under Adversarial Corruptions,Pranjal Awasthi;Sreenivas Gollapudi;Kostas Kollias;Apaar Sadhwani,~Pranjal_Awasthi3;~Sreenivas_Gollapudi2;kostaskollias@google.com;apaar@google.com,5;7;5;5,4;4;3;4,Reject,0,0,0.0,yes,9/28/20,Google;Google;Google;Stanford University,Online Learning;Learning Theory;Bandits;Robustness;Adversarial Corruptions,-1;-1;-1;5,-1;-1;-1;2,m;m,usa,usa,y,4
7469,ICLR,2021,Sim2SG: Sim-to-Real Scene Graph Generation for Transfer Learning,Aayush Prakash;Shoubhik Debnath;Jean Francois Lafleche;Eric Cameracci;Gavriel State;Marc T Law,~Aayush_Prakash1;~Shoubhik_Debnath1;jlafleche@nvidia.com;ecameracci@nvidia.com;gstate@nvidia.com;~Marc_T_Law1,5;7;6;5,3;4;3;3,Reject,0,6,0.0,yes,9/28/20,NVIDIA;NVIDIA;Toronto University;University of Waterloo;NVIDIA;NVIDIA,computer vision;application;sim2real;scene graph;object detection;simulation in machine learning;transfer learning;synthetic data;driving simulation.,-1;-1;-1;34;-1;-1,-1;-1;-1;232;-1;-1,m;m,NAN,NAN,n,10;4
7470,ICLR,2021,Learning to generate Wasserstein barycenters,Julien Lacombe;Julie Digne;Nicolas Courty;Nicolas Bonneel,~Julien_Lacombe1;~Julie_Digne1;~Nicolas_Courty1;~Nicolas_Bonneel1,3;7;6,4;3;4,Reject,0,3,0.0,yes,9/28/20,"INSA de Lyon;LIRIS, CNRS;IRISA;CNRS",Wasserstein barycenters;Optimal Transport,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n,
7471,ICLR,2021,Informative Outlier Matters: Robustifying Out-of-distribution Detection Using Outlier Mining,Jiefeng Chen;Yixuan Li;Xi Wu;Yingyu Liang;Somesh Jha,~Jiefeng_Chen2;~Yixuan_Li1;~Xi_Wu1;~Yingyu_Liang1;~Somesh_Jha1,3;7;4;7,4;3;4;3,Reject,0,14,0.0,yes,9/28/20,"University of Wisconsin, Madison;University of Wisconsin, Madison;Google;University of Wisconsin, Madison;Department of Computer Science, University of Wisconsin, Madison",OOD detection;informative outlier mining;robustness,18;18;-1;18;-1,49;49;-1;49;-1,m;m,NAN,NAN,y,4
7472,ICLR,2021,Transformers for Modeling Physical Systems,Nicholas Geneva;Nicholas Zabaras,~Nicholas_Geneva1;nzabaras@gmail.com,6;7;7;6,4;3;5;3,Reject,0,9,0.0,yes,9/28/20,University of Notre Dame;;Cornell University,Scientific Machine Learning;Deep Learning;Physics;Surrogate Modeling;Koopman;Transformers;Attention,128;-1;7,170;-1;19,m;m,usa,usa,n,8
7473,ICLR,2021,Knowledge Distillation By Sparse Representation Matching,Dat Thanh Tran;Moncef Gabbouj;Alexandros Iosifidis,~Dat_Thanh_Tran1;~Moncef_Gabbouj1;~Alexandros_Iosifidis2,3;5;5;4,4;3;5;5,Reject,0,15,0.0,yes,9/28/20,Tampere University;Tampere University;Aarhus University,Knowledge Distillation;Sparse Representation;Transfer Learning,-1;-1;92,301;301;106,m;m,europe,dk,n,
7474,ICLR,2021,A Primal Approach to Constrained Policy Optimization: Global Optimality and Finite-Time Analysis,Tengyu Xu;Yingbin Liang;Guanghui Lan,~Tengyu_Xu1;~Yingbin_Liang1;~Guanghui_Lan1,6;7;5;5,3;4;2;3,Reject,0,4,0.0,yes,9/28/20,Ohio State University;The Ohio State University;Georgia Institute of Technology,safe reinforcement learning;constrained markov decision process;policy optimization,58;58;12,78;-1;38,m;m,usa,usa,y,1;9
7475,ICLR,2021,Semantic Hashing with Locality Sensitive Embeddings,Levi Boyles;Aniket Anand Deshmukh;Urun Dogan;Rajesh Koduru;Charles Denis;Eren Manavoglu,~Levi_Boyles1;~Aniket_Anand_Deshmukh1;~Urun_Dogan1;rkoduru@microsoft.com;cdx@microsoft.com;~Eren_Manavoglu1,4;6;4,5;4;4,Reject,0,8,0.0,yes,9/28/20,University of Oxford;Microsoft;University of Potsdam;;;;;Pennsylvania State University,Semantic Hashing;Approximate Nearest Neighbor,46;-1;453;-1;-1;-1;-1;44,1;-1;276;-1;-1;-1;-1;-1,m;f,usa,usa,y,
7476,ICLR,2021,Addressing Some Limitations of Transformers with Feedback Memory,Angela Fan;Thibaut Lavril;Edouard Grave;Armand Joulin;Sainbayar Sukhbaatar,~Angela_Fan2;thibautlav@fb.com;~Edouard_Grave1;~Armand_Joulin1;~Sainbayar_Sukhbaatar1,5;7;6;6,5;5;5;3,Reject,0,20,0.0,yes,9/28/20,Facebook;;;Facebook;Facebook;Facebook,Feedback;Memory;Transformers,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,8;3
7477,ICLR,2021,Robust Learning via Golden Symmetric Loss of (un)Trusted Labels,Amirmasoud Ghiassi;Robert Birke;Lydia Y. Chen,~Amirmasoud_Ghiassi1;~Robert_Birke1;~Lydia_Y._Chen1,5;3;4;4,4;5;4;3,Reject,0,4,0.0,yes,9/28/20,Delft University of Technology;ABB Future Labs;Delft University of Technology,,-1;-1;-1,78;-1;78,m;f,NAN,NAN,y,3;1;4
7478,ICLR,2021,Augmentation-Interpolative AutoEncoders for Unsupervised Few-Shot Image Generation,Davis Wertheimer;Omid Poursaeed;Bharath Hariharan,~Davis_Wertheimer1;~Omid_Poursaeed2;~Bharath_Hariharan3,5;4;4,4;4;5,Reject,0,3,0.0,yes,9/28/20,Cornell University;Cornell University;Cornell University,Interpolation;autoencoder;reconstruction;few-shot learning;few-shot image generation;generalization;augmentation,7;7;7,19;19;19,m;m,usa,usa,n,6;1
7479,ICLR,2021,Quickest change detection for multi-task problems under unknown parameters,Firas Jarboui;Vianney Perchet,~Firas_Jarboui1;~Vianney_Perchet3,7;7;7;6,2;4;4;3,Reject,0,6,0.0,yes,9/28/20,ENS Paris-Saclay;Ensae ParisTech,Quickest Change detection;Parametric approach;Multi-task,-1;-1,-1;-1,m;m,NAN,NAN,y,
7480,ICLR,2021,Learning Aggregation Functions,Giovanni Pellegrini;Alessandro Tibo;Paolo Frasconi;Andrea Passerini;Manfred Jaeger,~Giovanni_Pellegrini1;~Alessandro_Tibo1;~Paolo_Frasconi1;~Andrea_Passerini2;jaeger@cs.aau.dk,6;5;3;6,3;3;5;4,Reject,0,4,0.0,yes,9/28/20,University of Trento;Aalborg University;Universit√† di Firenze;University of Trento;Aalborg University,Deep learning;Neural networks;Relational and structured data;Aggregation functions,150;209;-1;150;209,343;218;-1;343;218,m;m,europe,dk,n,8
7481,ICLR,2021,Normalizing Flows for Calibration and Recalibration,Achintya Gopal;Aaron Key,~Achintya_Gopal1;~Aaron_Key1,7;5;4;3,1;3;4;5,Reject,0,6,0.0,yes,9/28/20,Johns Hopkins University;University of New Mexico,recalibration;normalizing flows;uncertainty,71;327,12;268,m;m,usa,usa,n,
7482,ICLR,2021,Contrastive estimation reveals topic posterior information to linear models,Christopher Tosh;Akshay Krishnamurthy;Daniel Hsu,~Christopher_Tosh1;~Akshay_Krishnamurthy1;~Daniel_Hsu1,5;7;6;6,4;4;2;3,Reject,0,1,0.0,yes,9/28/20,Columbia University;Microsoft Research;Columbia University,contrastive learning;self-supervised learning;representation learning;theory,23;-1;23,17;-1;17,m;m,usa,usa,y,1
7483,ICLR,2021,On the Latent Space of Flow-based Models,Mingtian Zhang;Yitong Sun;Steven McDonagh;Chen Zhang,~Mingtian_Zhang1;~Yitong_Sun1;~Steven_McDonagh1;~Chen_Zhang6,5;6;5;4;5,4;4;5;4;3,Reject,0,6,0.0,yes,9/28/20,University College London;University of Michigan;Huawei Technologies Ltd.;Huawei Technologies R&D (UK) Ltd.,flow-based mode;generative model;intrinsic dimension;manifold learning,53;7;-1;-1,-1;22;-1;-1,m;m,NAN,NAN,y,5
7484,ICLR,2021,Enabling Binary Neural Network Training on the Edge,Erwei Wang;James J. Davis;Daniele Moro;Piotr Zielinski;Claudionor Coelho;Satrajit Chatterjee;Peter Y. K. Cheung;George Anthony Constantinides,~Erwei_Wang1;james.davis@imperial.ac.uk;danielemoro@google.com;~Piotr_Zielinski1;claudionor.coelho@alumni.stanford.edu;~Satrajit_Chatterjee1;p.cheung@imperial.ac.uk;~George_Anthony_Constantinides1,8;5;5;6,5;3;3;4,Reject,0,5,0.0,yes,9/28/20,Imperial College London;Imperial College London;Boise State University;Google;Palo Alto Networks;Google;Imperial College London;Imperial College London,Binary neural network;edge computing;neural network training,53;53;453;-1;-1;-1;53;53,11;11;-1;-1;-1;-1;11;11,m;m,europe,uk,n,
7485,ICLR,2021,Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms,Chao Yu;Akash Velu;Eugene Vinitsky;Yu Wang;Alexandre Bayen;Yi Wu,yc19@mails.tsinghua.edu.cn;akashvelu@berkeley.edu;~Eugene_Vinitsky1;~Yu_Wang3;~Alexandre_Bayen2;~Yi_Wu1,6;3;4;4,3;4;3;4,Reject,0,5,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;University of California Berkeley;University of California Berkeley;Tsinghua University;University of California Berkeley;Tsinghua University",Multi-agent Reinforcement Learning;Benchmarking,4;-1;-1;4;-1;4,20;7;7;20;7;20,f;m,asia,cn,n,
7486,ICLR,2021,On the Reproducibility of Neural Network Predictions,Srinadh Bhojanapalli;Kimberly Jenney Wilber;Andreas Veit;Ankit Singh Rawat;Seungyeon Kim;Aditya Krishna Menon;Sanjiv Kumar,~Srinadh_Bhojanapalli1;~Kimberly_Jenney_Wilber1;~Andreas_Veit1;~Ankit_Singh_Rawat1;~Seungyeon_Kim1;~Aditya_Krishna_Menon1;~Sanjiv_Kumar1,5;4;5,4;3;2,Reject,0,4,0.0,yes,9/28/20,Google;Cornell University;Google;Google;Google;Google;Google,reproducibility;churn;confidence,-1;7;-1;-1;-1;-1;-1,-1;19;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,
7487,ICLR,2021,Non-robust Features through the Lens of Universal Perturbations,Sung Min Park;Kuo-An Wei;Kai Yuanqing Xiao;Jerry Li;Aleksander Madry,~Sung_Min_Park2;kuoanwei@mit.edu;~Kai_Yuanqing_Xiao1;~Jerry_Li1;~Aleksander_Madry1,5;7;5;6,4;4;2;4,Reject,0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial examples;robustness;non-robust features,5;5;5;5;5,4;4;4;4;4,m;m,usa,usa,n,4
7488,ICLR,2021,The Heavy-Tail Phenomenon in SGD,Mert Gurbuzbalaban;Umut Simsekli;Lingjiong Zhu,~Mert_Gurbuzbalaban1;~Umut_Simsekli1;~Lingjiong_Zhu1,6;5;5;7,3;4;3;4,Reject,0,6,0.0,yes,9/28/20,Rutgers University;INRIA;Florida State University,heavy tails;stochastic gradient descent;deep learning,29;-1;128,-1;-1;284,m;m,usa,usa,y,1
7489,ICLR,2021,On the Effectiveness of Weight-Encoded Neural Implicit 3D Shapes   ,Thomas Ryan Davies;Derek Nowrouzezahrai;Alec Jacobson,~Thomas_Ryan_Davies1;~Derek_Nowrouzezahrai1;~Alec_Jacobson1,8;4;7,4;3;5,Reject,0,4,0.0,yes,9/28/20,University of Toronto;McGill University;University of Toronto,,18;99;18,18;40;18,m;m,canada,ca,n,
7490,ICLR,2021,SyncTwin: Transparent Treatment Effect Estimation under Temporal Confounding,Zhaozhi Qian;Yao Zhang;Ioana Bica;Angela Wood;Mihaela van der Schaar,~Zhaozhi_Qian1;~Yao_Zhang3;~Ioana_Bica1;amw79@medschl.cam.ac.uk;~Mihaela_van_der_Schaar2,4;7;4;9;3,3;4;5;4;4,Reject,0,10,0.0,yes,9/28/20,University of Cambridge;University of Cambridge;University of Oxford;University of Cambridge;University of Cambridge,treatment effect;interpretability;healthcare;causal inference,79;79;46;79;79,6;6;1;6;6,u;m,europe,uk,y,
7491,ICLR,2021,Introducing Sample Robustness,Monty Maximilian Z√ºhlke,~Monty_Maximilian_Z√ºhlke1,4;4;2;5,4;3;4;3,Reject,0,5,0.0,yes,9/28/20,Leibniz Universit√§t Hannover,,-1,515,m,NAN,NAN,y,1
7492,ICLR,2021,Learn2Weight: Weights Transfer Defense against Similar-domain Adversarial Attacks,Siddhartha Datta,~Siddhartha_Datta1,3;5;4,3;5;3,Reject,0,3,0.0,yes,9/28/20,University of Oxford,adversarial attack;robustness;domain adaptation;privacy-preserving machine learning,46,1,m,europe,uk,n,3;8;1;4
7493,ICLR,2021,Reintroducing Straight-Through Estimators as Principled Methods for Stochastic Binary Networks,Alexander Shekhovtsov;Viktor Yanush,~Alexander_Shekhovtsov1;yanushviktor@gmail.com,5;7;7;5,3;2;2;3,Reject,0,10,0.0,yes,9/28/20,Czech Technical University in Prague;;Bayesian Methods Research Group,straight-through;binary;stochastic binary;mirror descent,174;-1;-1,1045;-1;-1,m;m,NAN,NAN,y,
7494,ICLR,2021,A Siamese Neural Network for Behavioral Biometrics Authentication,Jes√∫s Solano;Esteban Rivera;Alejandra Castelblanco;Lizzy Tengana;Christian Lopez;Martin Ochoa,~Jes√∫s_Solano1;esteban.rivera@appgate.com;alejandra.castelblanco@appgate.com;lizzy.tengana@appgate.com;christian.lopez@appgate.com;martin.ochoa@appgate.com,5;4;9,4;3;4,Reject,0,4,0.0,yes,9/28/20,AppGate Inc.;;;;;AppGate Inc.;;;;;AppGate Inc.,Deep Learning;Few-shot Learning;Behavioral Biometrics;Biometric Authentication,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6
7495,ICLR,2021,FTBNN: Rethinking Non-linearity for 1-bit CNNs and Going Beyond,Zhuo Su;Linpu Fang;Deke Guo;Dewen Hu;Matti Pietik√§inen;Li Liu,~Zhuo_Su2;~Linpu_Fang1;~Deke_Guo1;~Dewen_Hu2;~Matti_Pietik√§inen2;~Li_Liu9,5;6;3;4,4;2;5;5,Reject,0,4,0.0,yes,9/28/20,"Oulu University;South China University of Technology;National University of Defense Technology, Tsinghua University;National University of Defense Technology, Tsinghua University;University of Oulu;University of Oulu",Binary neural networks;network quantization;network compression,-1;-1;4;4;-1;-1,140;411;20;20;312;312,m;f,europe,de,n,
7496,ICLR,2021,A Mixture of Variational Autoencoders for Deep Clustering,Avi Caciularu;Jacob Goldberger,~Avi_Caciularu1;~Jacob_Goldberger1,5;5;6;5,4;4;4;3,Reject,0,6,0.0,yes,9/28/20,Bar-Ilan University;Bar-Ilan University,deep clustering;variational auto encoder;VAE,110;110,570;570,m;m,europe,il,n,5
7497,ICLR,2021,PURE: An Uncertainty-aware Recommendation Framework for Maximizing Expected Posterior Utility of Platform,Haokun Chen;Zhaoyang Liu;Chen Xu;Ziqian Chen;Jinyang Gao;Bolin Ding,~Haokun_Chen1;jingmu.lzy@alibaba-inc.com;~Chen_Xu2;~Ziqian_Chen1;jinyang.gjy@alibaba-inc.com;~Bolin_Ding3,4;4;5;6,4;1;5;3,Reject,0,5,0.0,yes,9/28/20,"APEX Lab, Shanghai Jiao Tong University;Shanghai Jiao Tong University;Peking University;Peking University;;;Alibaba Group",commercial recommendation;maximizing platform benefits;uncertainty-aware;influence of display policy;non-convex optimization,29;29;14;14;-1;-1;-1,100;100;23;23;-1;-1;-1,m;m,NAN,NAN,y,9
7498,ICLR,2021,Cross-Domain Few-Shot Learning by Representation Fusion,Thomas Adler;Johannes Brandstetter;Michael Widrich;Andreas Mayr;David Kreil;Michael K Kopp;G√ºnter Klambauer;Sepp Hochreiter,~Thomas_Adler1;~Johannes_Brandstetter1;~Michael_Widrich2;~Andreas_Mayr2;openreview20@kreil.org;~Michael_K_Kopp1;~G√ºnter_Klambauer1;~Sepp_Hochreiter1,4;5;4;6;4,5;3;4;3;4,Reject,0,7,0.0,yes,9/28/20,"Johannes Kepler University Linz;Johannes Kepler University Linz;Institute for Machine Learning, Johannes Kepler University Linz;Johannes Kepler University Linz;;;Institute of Advanced Research in Artificial Intelligence (IARAI);Johannes Kepler University Linz;Johannes Kepler University Linz",cross-domain learning;few-shot learning;Hebbian learning;ensemble learning;domain shift;domain adaptation;representation fusion,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6
7499,ICLR,2021,Variational Deterministic Uncertainty Quantification,Joost van Amersfoort;Lewis Smith;Andrew Jesson;Oscar Key;Yarin Gal,~Joost_van_Amersfoort1;~Lewis_Smith1;~Andrew_Jesson1;~Oscar_Key1;~Yarin_Gal1,5;5;5;2,4;4;4;3,Reject,0,5,0.0,yes,9/28/20,"University of Oxford;University of Oxford;Department of Computer Science, University of Oxford;University College London;University of Oxford",Uncertainty estimation;gaussian processes;deep learning;variational inference,46;46;46;53;46,1;1;1;-1;1,m;m,europe,uk,n,1
7500,ICLR,2021,Bayesian Metric Learning for Robust Training of Deep Models under Noisy Labels,Toan Tran;Hieu Vu;Gustavo Carneiro;Hung Bui,~Toan_Tran1;v.hieuvt11@vinai.io;~Gustavo_Carneiro1;~Hung_Bui1,7;3;4;5,2;4;5;4,Reject,0,4,0.0,yes,9/28/20,"VinAI Research, Vietnam;Hanoi University of Science and Technology;The University of Adelaide;Google DeepMind",Noisy labels;Deep metric learning;Bayesian inference;Variational inference,-1;-1;110;-1,-1;1158;118;-1,m;m,NAN,NAN,y,11
7501,ICLR,2021,Targeted VAE: Structured Inference and Targeted Learning for Causal Parameter Estimation,Matthew James Vowels;Necati Cihan Camgoz;Richard Bowden,~Matthew_James_Vowels1;~Necati_Cihan_Camgoz1;~Richard_Bowden1,6;3;5;6,4;5;4;4,Reject,0,5,0.0,yes,9/28/20,University of Surrey;University of Surrey;University of Surrey,causal inference;variational inference;disentanglement;variational autoencoder,150;150;150,260;260;260,m;m,europe,uk,n,5
7502,ICLR,2021,Unsupervised Task Clustering for Multi-Task Reinforcement Learning,Johannes Ackermann;Oliver Paul Richter;Roger Wattenhofer,~Johannes_Ackermann1;~Oliver_Paul_Richter1;~Roger_Wattenhofer1,5;6;5;5,3;5;5;4,Reject,0,6,0.0,yes,9/28/20,Technical University Munich;Swiss Federal Institute of Technology;;ETH Zurich;ETHZ - ETH Zurich,Reinforcement Learning;Multi-Task Learning;Clustering;Expectation-Maximization,-1;-1;-1;9;9,-1;-1;-1;14;14,m;m,NAN,NAN,n,6
7503,ICLR,2021,Switching-Aligned-Words Data Augmentation for Neural Machine Translation,Fengshun Xiao;Zuchao Li;hai zhao,~Fengshun_Xiao1;~Zuchao_Li1;~hai_zhao1,4;4;3;2,5;4;4;5,Reject,0,4,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Machine Translation;Data augmentation,4;29;29,20;100;100,m;m,asia,cn,n,3
7504,ICLR,2021,Post-Training Weighted Quantization of Neural Networks for Language Models,Se Jung Kwon;Dongsoo Lee;Yongkweon Jeon;Byeongwook Kim;Bae Seong Park;Yeonju Ro,~Se_Jung_Kwon1;~Dongsoo_Lee1;~Yongkweon_Jeon1;~Byeongwook_Kim1;~Bae_Seong_Park1;~Yeonju_Ro1,5;6;4;6,4;3;5;4,Reject,0,16,0.0,yes,9/28/20,Samsung Research;Samsung Research;Samsung;Samsung Research;Samsung Research;Samsung Research,Model Compression;Non-uniform Quantization;Post-training Quantization;Language Model,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,8;3
7505,ICLR,2021,Self-Supervised Variational Auto-Encoders,Ioannis Gatopoulos;Jakub Mikolaj Tomczak,johngatop@gmail.com;~Jakub_Mikolaj_Tomczak1,5;4;4;6,1;4;5;4,Reject,0,4,0.0,yes,9/28/20,University of Amsterdam;Vrije Universiteit Amsterdam,generative modeling;deep learning;deep autoencoders,128;-1,66;116,m;m,NAN,NAN,n,5
7506,ICLR,2021,How to compare adversarial robustness of classifiers from a global perspective,Niklas Risse;Jan Philip G√∂pfert;Christina G√∂pfert,~Niklas_Risse1;jgoepfert@techfak.uni-bielefeld.de;~Christina_G√∂pfert1,5;5;6;6,4;4;3;3,Reject,0,5,0.0,yes,9/28/20,Bielefeld University;Bielefeld University;Bielefeld University,adversarial robustness;robustness;adversarial defense;adversarial example,327;327;327,158;158;158,m;f,europe,de,y,8;1;4
7507,ICLR,2021,ResPerfNet: Deep Residual Learning for Regressional Performance Modeling of Deep Neural Networks,Chuan-Chi Wang;Ying-Chiao Liao;Chia-Heng Tu;Ming-Chang Kao;Wen-Yew Liang;Shih-Hao Hung,chuan-chi.wang@adlinktech.com;~Ying-Chiao_Liao1;chiaheng@ncku.edu.tw;fencer.kao@adlinktech.com;william.liang@adlinktech.com;~Shih-Hao_Hung1,4;4;5,3;4;3,Reject,0,6,0.0,yes,9/28/20,National Taiwan University;National Taiwan University;;;;;;National Taiwan University,,99;99;-1;-1;-1;-1;-1;99,97;97;-1;-1;-1;-1;-1;97,u;m,asia,tw,n,
7508,ICLR,2021,Continual learning with neural activation importance,Sohee Kim;Seungkyu Lee,soheekim@khu.ac.kr;~Seungkyu_Lee1,4;4;6;4,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,kyunghee univ;;kyunghee univ,,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,
7509,ICLR,2021,Deep Single Image Manipulation,Yael Vinker;Eliahu Horwitz;Nir Zabari;Yedid Hoshen,~Yael_Vinker1;eliahu.horwitz@mail.huji.ac.il;~Nir_Zabari1;~Yedid_Hoshen3,6;7;5,4;4;4,Reject,0,6,0.0,yes,9/28/20,"Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem, Technion;Hebrew University of Jerusalem",image translation;single image;conditional generation;image manipulation,85;85;29;85,235;235;235;235,f;m,europe,il,n,2;4
7510,ICLR,2021,Syntactic representations in the human brain: beyond effort-based metrics,Aniketh Janardhan Reddy;Leila Wehbe,ajreddy@cs.cmu.edu;~Leila_Wehbe1,5;6;8;4,4;4;4;3,Reject,0,10,0.0,yes,9/28/20,University of California Berkeley;Carnegie Mellon University,neuroscience;fMRI;syntactic representations;graph embeddings,-1;1,7;28,m;f,usa,usa,n,
7511,ICLR,2021,Learning a Max-Margin Classifier for Cross-Domain Sentiment Analysis,Mohammad Rostami;Aram Galstyan,~Mohammad_Rostami1;~Aram_Galstyan1,5;5;5;5,4;4;4;4,Reject,0,10,0.0,yes,9/28/20,University of Southern California;Information Sciences Institute,natural language processing;sentiment analysis;cross-domain data representation;distribution alignment,37;-1,53;-1,m;m,NAN,NAN,y,8
7512,ICLR,2021,Fast Predictive Uncertainty for Classification with Bayesian Deep Networks,Marius Hobbhahn;Agustinus Kristiadi;Philipp Hennig,~Marius_Hobbhahn1;~Agustinus_Kristiadi1;~Philipp_Hennig1,4;6;5;5,5;5;4;4,Reject,0,4,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of Tuebingen;University of Tuebingen",Bayesian Deep Learning;Approximate Inference,-1;128;128,-1;78;78,m;m,europe,de,n,11
7513,ICLR,2021,Towards Robust Graph Neural Networks against Label Noise,Jun Xia;Haitao Lin;Yongjie Xu;Lirong Wu;Zhangyang Gao;Siyuan Li;Stan Z. Li,~Jun_Xia1;~Haitao_Lin2;~Yongjie_Xu1;~Lirong_Wu1;~Zhangyang_Gao1;~Siyuan_Li6;~Stan_Z._Li2,6;5;4;7,4;4;5;4,Reject,0,6,0.0,yes,9/28/20,"Westlake University, China;Westlake University;;Westlake University;Westlake University, China;Westlake University;Westlake University",Graph Neural Networks;Graph Node Classification;Label Noise,263;263;-1;263;263;263;263,-1;-1;-1;-1;-1;-1;-1,m;m,asia,cn,y,10
7514,ICLR,2021,Towards Data Distillation for End-to-end Spoken Conversational Question Answering,Chenyu You;Nuo Chen;Fenglin Liu;Dongchao Yang;Zhiyang Xu;Yuexian Zou,~Chenyu_You1;~Nuo_Chen1;~Fenglin_Liu1;~Dongchao_Yang1;~Zhiyang_Xu1;~Yuexian_Zou1,6;5;4;5,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,"Yale University;Peking University;Peking University;Peking University;College of Information and Computer Science, University of Massachusetts, Amherst;Peking University",spoken question answering;natural language processing;speech and language processing;knowledge distillation,71;14;14;14;-1;14,8;23;23;23;210;23,m;f,asia,cn,n,
7515,ICLR,2021,A Text GAN for Language Generation with Non-Autoregressive Generator,Fei Huang;Jian Guan;Pei Ke;Qihan Guo;Xiaoyan Zhu;Minlie Huang,~Fei_Huang3;~Jian_Guan1;~Pei_Ke2;~Qihan_Guo1;~Xiaoyan_Zhu1;~Minlie_Huang1,6;6;6,4;4;4,Reject,0,9,0.0,yes,9/28/20,"Department of Computer Science and Technolog, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University",language generation;non-autoregressive text generation;generative adversarial networks;GANs;latent variable,4;4;4;4;4;4,20;20;20;20;20;20,u;m,NAN,NAN,n,3;5;4
7516,ICLR,2021,ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA,Yingbin Bai;Tongliang Liu,~Yingbin_Bai1;~Tongliang_Liu1,4;4;7;8,3;4;4;4,Reject,0,5,0.0,yes,9/28/20,University of Sydney;University of Sydney,label noise;hard confident examples,71;71,51;51,u;m,europe,uk,n,
7517,ICLR,2021,Efficiently Disentangle Causal Representations,Yuanpeng Li;Joel Hestness;Mohamed Elhoseiny;Liang Zhao;Kenneth Church,~Yuanpeng_Li2;~Joel_Hestness2;~Mohamed_Elhoseiny1;~Liang_Zhao2;~Kenneth_Church1,3;5;4,5;4;3,Reject,0,3,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Cerebras Systems, Inc;KAUST;Samsung Research America;Baidu",causality;representation learning,4;-1;110;-1;-1,20;-1;-1;-1;-1,u;m,NAN,NAN,y,1
7518,ICLR,2021,N-Bref : A High-fidelity Decompiler Exploiting Programming Structures ,Cheng Fu;Kunlin Yang;Xinyun Chen;Yuandong Tian;Jishen Zhao,~Cheng_Fu1;k6yang@eng.ucsd.edu;~Xinyun_Chen1;~Yuandong_Tian1;~Jishen_Zhao1,4;5;7;3,4;3;3;4,Reject,0,5,0.0,yes,9/28/20,"University of California, San Diego, University of California, San Diego;;;University of California Berkeley;Facebook AI Research;University of California, San Diego",Programming Language;Reverse engineering;neural machine translation;machine learning for system,-1;-1;-1;-1;-1;-1,33;-1;-1;7;-1;33,m;f,usa,usa,n,8;3
7519,ICLR,2021,Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting,Nidhi Gowdra;Roopak Sinha;Stephen MacDonell;WeiQi Yan,~Nidhi_Gowdra1;rsinha@aut.ac.nz;stephen.macdonell@aut.ac.nz;weiqi.yan@aut.ac.nz,5;4;3;5,4;5;4;3,Reject,0,0,0.0,yes,9/28/20,Auckland University of Technology;;;;;;Auckland University of Technology,,-1;-1;-1;-1;-1;-1;-1,254;-1;-1;-1;-1;-1;254,m;u,NAN,NAN,n,2;7
7520,ICLR,2021,Wasserstein Distributional Normalization : Nonparametric Stochastic Modeling for Handling Noisy Labels,Sung Woo Park;Junseok Kwon,~Sung_Woo_Park2;~Junseok_Kwon5,4;6;6;5;4,3;2;3;3;4,Reject,0,14,0.0,yes,9/28/20,ChungAng University;Chung-Ang University,Wasserstein distributional normalization;Noisy labels;Classification,-1;-1,618;618,m;m,NAN,NAN,y,
7521,ICLR,2021,Decentralized Knowledge Graph Representation Learning,Lingbing Guo;Weiqing Wang;Zequn Sun;Chenghao Liu;Wei Hu,~Lingbing_Guo1;teresa.wang@monash.edu;~Zequn_Sun1;~Chenghao_Liu1;whu@nju.edu.cn,4;4;5;5,3;4;4;2,Reject,0,4,0.0,yes,9/28/20,Zhejiang University;;Monash University;Nanjing University;Zhejiang University;Nanjing University,Representation Learning;Knowledge Graph;Entity Alignment;Knowledge Graph Completion;Knowledge Graph Embedding,42;-1;92;52;42;52,94;-1;64;111;94;111,m;m,asia,kr,n,10
7522,ICLR,2021,Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge,Trent Kyono;Ioana Bica;Zhaozhi Qian;Mihaela van der Schaar,~Trent_Kyono1;~Ioana_Bica1;~Zhaozhi_Qian1;~Mihaela_van_der_Schaar2,4;6;6;8,4;3;5;4,Reject,0,7,0.0,yes,9/28/20,"University of California, Los Angeles;University of Oxford;University of Cambridge;University of Cambridge",causal inference;treatment effects;healthcare,-1;46;79;79,15;1;6;6,m;f,europe,uk,y,
7523,ICLR,2021,Self-supervised Graph-level Representation Learning with Local and Global Structure,Minghao Xu;Hang Wang;Bingbing Ni;Hongyu Guo;Jian Tang,~Minghao_Xu1;~Hang_Wang1;~Bingbing_Ni3;~Hongyu_Guo1;~Jian_Tang1,5;5;6;8,5;4;3;4,Reject,0,17,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Shanghai Jiao Tong University;Shanghai Jiao Tong University;National Research Council Canada;HEC Montreal",Self-supervised Representation Learning;Graph Representation Learning;Hierarchical Semantic Learning,128;29;29;-1;-1,73;100;100;-1;-1,m;m,canada,ca,n,10
7524,ICLR,2021,Consensus Clustering with Unsupervised Representation Learning,Jayanth Reddy Regatti;Aniket Anand Deshmukh;Eren Manavoglu;Urun Dogan,~Jayanth_Reddy_Regatti1;~Aniket_Anand_Deshmukh1;~Eren_Manavoglu1;~Urun_Dogan1,5;5;4,4;3;5,Reject,0,11,0.0,yes,9/28/20,Ohio State University;Microsoft;Pennsylvania State University;University of Potsdam,Clustering;Ensemble Learning;Representation Learning,58;-1;44;453,78;-1;-1;276,u;u,europe,de,n,2
7525,ICLR,2021,Towards Noise-resistant Object Detection with Noisy Annotations,Junnan Li;Caiming Xiong;Steven Hoi,~Junnan_Li2;~Caiming_Xiong1;~Steven_Hoi2,5;5;6,4;5;4,Reject,0,3,0.0,yes,9/28/20,Salesforce Research Asia;Salesforce Research;Salesforce Research Asia,noisy annotation;object detection;label noise,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
7526,ICLR,2021,Counterfactual Self-Training,Ruijiang Gao;Max Biggs;Wei Sun;Ligong Han,~Ruijiang_Gao2;biggsm@darden.virginia.edu;sunw@us.ibm.com;lh599@scarletmail.rutgers.edu,4;6;5,5;4;3,Reject,0,3,0.0,yes,9/28/20,"University of Texas, Austin;;;IBM;Rutgers University",self-training;counterfactual inference,-1;-1;-1;453;29,-1;-1;-1;-1;-1,u;u,usa,usa,y,1
7527,ICLR,2021,Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests,Christopher Beckham;Martin Weiss;Florian Golemo;Sina Honari;Derek Nowrouzezahrai;Christopher Pal,~Christopher_Beckham1;~Martin_Weiss4;~Florian_Golemo1;~Sina_Honari1;~Derek_Nowrouzezahrai1;~Christopher_Pal1,4;6;4;4,3;4;4;3,Reject,0,7,0.0,yes,9/28/20,"Polytechnique Montreal;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Mila;Swiss Federal Institute of Technology Lausanne;McGill University;Polytechnique Montreal",vqa;clevr;contrastive learning;3d;inverse graphics,327;128;150;-1;99;327,-1;73;370;-1;40;-1,m;m,canada,ca,n,2;1
7528,ICLR,2021,Linear Representation Meta-Reinforcement Learning for Instant Adaptation,Matt Peng;Banghua Zhu;Jiantao Jiao,~Matt_Peng1;~Banghua_Zhu1;~Jiantao_Jiao1,6;5;7,4;3;4,Reject,0,5,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley,meta reinforcement learning;out-of-distribution;reinforcement learning,-1;-1;-1,7;7;7,m;m,usa,usa,n,
7529,ICLR,2021,Adam$^+$: A Stochastic Method with Adaptive Variance Reduction,Mingrui Liu;Wei Zhang;Francesco Orabona;Tianbao Yang,~Mingrui_Liu2;~Wei_Zhang33;~Francesco_Orabona1;~Tianbao_Yang1,5;4;5;6,4;4;3;3,Reject,0,5,0.0,yes,9/28/20,"Boston University;IBM, International Business Machines;Boston University;University of Iowa",Adaptive Gradient Methods;Deep Learning;Nonconvex Optimization,79;-1;79;174,54;-1;54;245,m;m,europe,de,y,3;9
7530,ICLR,2021,Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift,Marvin Mengxin Zhang;Henrik Marklund;Nikita Dhawan;Abhishek Gupta;Sergey Levine;Chelsea Finn,~Marvin_Mengxin_Zhang2;marklund@cs.stanford.edu;nikitadhawan@berkeley.edu;~Abhishek_Gupta1;~Sergey_Levine1;~Chelsea_Finn1,6;7;5,4;5;3,Reject,0,9,0.0,yes,9/28/20,University of California Berkeley;;;University of California Berkeley;Google;University of Washington;Stanford University,meta-learning;distribution shift;distributional robustness;test time adaptation,-1;-1;-1;-1;-1;11;5,7;-1;-1;7;-1;29;2,m;f,usa,usa,n,6
7531,ICLR,2021,When Are Neural Pruning Approximation Bounds Useful?,Mitchell A Gordon,~Mitchell_A_Gordon1,5;6;5,4;4;3,Reject,0,5,0.0,yes,9/28/20,Johns Hopkins University,neural network;pruning;coreset;approximation,71,12,m,usa,usa,y,
7532,ICLR,2021,A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms,Shangtong Zhang;Romain Laroche;Harm van Seijen;Shimon Whiteson;Remi Tachet des Combes,~Shangtong_Zhang1;~Romain_Laroche1;~Harm_van_Seijen1;~Shimon_Whiteson1;~Remi_Tachet_des_Combes1,6;4;6;4,4;4;4;3,Reject,0,11,0.0,yes,9/28/20,"Department of Computer Science, University of Oxford;Microsoft;Microsoft Research;University of Oxford;Microsoft Research",,46;-1;-1;46;-1,1;-1;-1;1;-1,m;m,NAN,NAN,y,
7533,ICLR,2021,Neural Dynamical Systems: Balancing Structure and Flexibility in Physical Prediction,Viraj Mehta;Ian Char;Willie Neiswanger;Youngseog Chung;Andrew Oakleigh Nelson;Mark D Boyer;Egemen Kolemen;Jeff Schneider,~Viraj_Mehta1;ichar@cs.cmu.edu;~Willie_Neiswanger1;youngsec@cs.cmu.edu;anelson@pppl.gov;mboyer@pppl.gov;ekolemen@pppl.gov;~Jeff_Schneider1,5;5;8;4,4;4;3;4,Reject,0,7,0.0,yes,9/28/20,"Carnegie Mellon University;Carnegie Mellon University;;CMU, Carnegie Mellon University;;;;;;;School of Computer Science",nuclear fusion;physics;differential equations;dynamical systems;control;dynamics,1;1;-1;1;-1;-1;-1;-1;-1;-1;-1,28;28;-1;28;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7534,ICLR,2021,A Bayesian-Symbolic Approach to Learning and Reasoning for Intuitive Physics,Kai Xu;Akash Srivastava;Dan Gutfreund;Felix Sosa;Tomer Ullman;Joshua B. Tenenbaum;Charles Sutton,~Kai_Xu4;~Akash_Srivastava1;~Dan_Gutfreund1;fsosa@fas.harvard.edu;~Tomer_Ullman1;~Joshua_B._Tenenbaum1;~Charles_Sutton1,6;6;6;5,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,University of Edinburgh;Massachusetts Institute of Technology;International Business Machines;;;;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Google,physics learning;symbolic regression;intuitive physics,29;5;-1;-1;-1;-1;5;5;-1,30;4;-1;-1;-1;-1;4;4;-1,m;m,NAN,NAN,n,11;5
7535,ICLR,2021,Local Information Opponent Modelling Using Variational Autoencoders,Georgios Papoudakis;Filippos Christianos;Stefano V Albrecht,~Georgios_Papoudakis1;f.christianos@ed.ac.uk;~Stefano_V_Albrecht1,7;6;3;6,4;3;4;3,Reject,0,10,0.0,yes,9/28/20,"University of Edinburgh;Edinburgh University, University of Edinburgh;University of Edinburgh",multi-agent systems;opponent modelling;reinforcement learning,29;29;29,30;30;30,m;m,europe,uk,n,5
7536,ICLR,2021,Learning Disconnected Manifolds: Avoiding The No Gan's Land by Latent Rejection,Thibaut Issenhuth;Ugo Tanielian;David Picard;Jeremie Mary,~Thibaut_Issenhuth1;~Ugo_Tanielian1;~David_Picard1;~Jeremie_Mary1,4;4;4,4;4;3,Reject,0,10,0.0,yes,9/28/20,"Criteo;Computer Science Lab  - Pierre and Marie Curie University, Paris, France;√âcole des Ponts;Criteo",,-1;-1;-1;-1,-1;-1;268;-1,m;m,NAN,NAN,y,5;4
7537,ICLR,2021,Explainability for fair machine learning,Tom Begley;Tobias Schwedes;Christopher Frye;Ilya Feige,~Tom_Begley1;~Tobias_Schwedes1;~Christopher_Frye1;~Ilya_Feige1,5;6;5,4;3;4,Reject,0,4,0.0,yes,9/28/20,Faculty;Faculty;Faculty;University College London,explainability;fairness;Shapley,-1;-1;-1;53,-1;-1;-1;-1,m;m,europe,uk,n,7
7538,ICLR,2021,Improving Random-Sampling Neural Architecture Search by Evolving the Proxy Search Space,Yuhong Li;Cong Hao;Xiaofan Zhang;Jinjun Xiong;Wen-mei Hwu;Deming Chen,~Yuhong_Li2;congh@illinois.edu;xiaofan3@illinois.edu;~Jinjun_Xiong1;~Wen-mei_Hwu1;~Deming_Chen1,6;4;5;5,2;3;4;4,Reject,0,4,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;;;University of Illinois, Urbana Champaign;International Business Machines;Univ. of Illinois at Urbana-Champaign;University of Illinois, Urbana Champaign",Neural Architecture Search;AutoML;Computer Vision,-1;-1;-1;-1;-1;2;-1,-1;-1;-1;-1;-1;-1;-1,m;m,usa,usa,n,3
7539,ICLR,2021,Online Testing of Subgroup Treatment Effects Based on Value Difference,Miao Yu;Wenbin Lu;Rui Song,~Miao_Yu5;~Wenbin_Lu1;~Rui_Song2,7;3;5;7,3;4;4;5,Reject,0,5,0.0,yes,9/28/20,North Carolina State University;North Carolina State University;North Carolina State University,online A/B testing;subgroup treatment effects testing;continuous monitoring;supervised representation learning;classification,92;92;92,340;340;340,f;f,usa,usa,y,
7540,ICLR,2021,Self-Organizing Intelligent Matter:  A blueprint for an AI generating algorithm,Karol Gregor;Frederic Besse,~Karol_Gregor1;~Frederic_Besse1,5;4;3;8,4;3;4;1,Reject,0,8,0.0,yes,9/28/20,Google;Google,Artificial Life;AI Generating Algorithms,-1;-1,-1;-1,u;m,NAN,NAN,n,
7541,ICLR,2021,Evaluating Gender Bias in Natural Language Inference ,Shanya Sharma;Manan Dey;Koustuv Sinha,~Shanya_Sharma1;~Manan_Dey2;~Koustuv_Sinha1,3;4;4,4;5;5,Reject,0,6,0.0,yes,9/28/20,Walmart Labs;KIIT  University;McGill University,Natural Language Inference;Natural Language Understanding;Natural Language Processing;Gender Bias;Societal Bias;Bias;Ethics;Debiasing Techniques;Data Augmentation,-1;-1;99,-1;1056;40,f;m,canada,ca,n,3;7
7542,ICLR,2021,Federated Generalized Bayesian Learning via  Distributed Stein Variational Gradient Descent,Rahif Kassab;Osvaldo Simeone,~Rahif_Kassab1;~Osvaldo_Simeone1,6;6;5;5,3;4;4;3,Reject,0,11,0.0,yes,9/28/20,King's College London;New Jersey Institute of Technology,Federated Learning;Distributed Variational Inference,174;-1,35;570,m;m,NAN,NAN,y,11
7543,ICLR,2021,Making Coherence Out of Nothing At All: Measuring Evolution of Gradient Alignment,Satrajit Chatterjee;Piotr Zielinski,~Satrajit_Chatterjee1;zielinski@google.com,5;5;8;6,3;3;4;3,Reject,0,9,0.0,yes,9/28/20,Google;Google,generalization;deep learning,-1;-1,-1;-1,m;u,NAN,NAN,y,1
7544,ICLR,2021,Provable Robust Learning for Deep Neural Networks under Agnostic Corrupted Supervision,Boyang Liu;Mengying Sun;Ding Wang;Pang-Ning Tan;Jiayu Zhou,~Boyang_Liu1;~Mengying_Sun1;wangdin1@msu.edu;~Pang-Ning_Tan1;~Jiayu_Zhou1,5;3;4;4,3;5;5;4,Reject,0,8,0.0,yes,9/28/20,Michigan State University;Michigan State University;Michigan State University;Michigan State University;Michigan State University,Noisy Label;Corrupted Supervision;Robustness;Optimization,110;110;110;110;110,105;105;105;105;105,m;m,usa,usa,y,1
7545,ICLR,2021,Dual Graph Complementary Network,Chenhua Liu;Kun Zhan,liuchh20@lzu.edu.cn;~Kun_Zhan1,3;2;4;4,5;4;5;5,Reject,0,4,0.0,yes,9/28/20,Lanzhou University;;Lanzhou University,,-1;-1;-1,862;-1;862,u;m,NAN,NAN,n,10
7546,ICLR,2021,AlgebraNets,Jordan Hoffmann;Simon Schmitt;Simon Osindero;Karen Simonyan;Erich Elsen,~Jordan_Hoffmann1;~Simon_Schmitt1;~Simon_Osindero1;~Karen_Simonyan1;~Erich_Elsen1,6;5;7,2;4;4,Reject,0,15,0.0,yes,9/28/20,DeepMind;Google;Google;DeepMind;Royal Caliber,Sparsity;Pruning;Efficiency;Mathematics,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;u,NAN,NAN,n,3
7547,ICLR,2021,Federated Averaging as Expectation Maximization,Christos Louizos;Matthias Reisser;Joseph Soriaga;Max Welling,~Christos_Louizos1;~Matthias_Reisser1;jsoriaga@qti.qualcomm.com;~Max_Welling1,5;7;5;4,4;2;4;4,Reject,0,6,0.0,yes,9/28/20,"Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;;;Donald Bren School of Information and Computer Sciences, University of California, Irvine",federated;learning;sparsity;expectation;maximization;efficient;FedAvg;FedSparse;EM,-1;-1;-1;-1;-1,-1;-1;-1;-1;98,m;m,NAN,NAN,n,
7548,ICLR,2021,Convex Regularization in Monte-Carlo Tree Search,Tuan Quang Dam;Carlo D'Eramo;Jan Peters;Joni Pajarinen,~Tuan_Quang_Dam1;~Carlo_D'Eramo2;~Jan_Peters3;~Joni_Pajarinen2,5;5;4;8,3;4;1;4,Reject,0,5,0.0,yes,9/28/20,TU Darmstadt;TU Darmstadt;TU Darmstadt;Aalto University,Monte-Carlo Tree Search;Entropy regularization;Reinforcement Learning,64;64;64;128,-1;-1;-1;220,m;m,europe,dk,y,1;9
7549,ICLR,2021,Modal Uncertainty Estimation via Discrete Latent Representations,Di Qiu;Zhanghan Ke;Peng Su;Lok Ming Lui,~Di_Qiu1;~Zhanghan_Ke1;~Peng_Su1;~Lok_Ming_Lui2,5;5;6,4;4;4,Reject,0,4,0.0,yes,9/28/20,The Chinese University of Hong Kong;City University of Hong Kong;SenseTime Research Institute;The Chinese University of Hong Kong,uncertainty estimation;one -to-many mapping;conditional generative model;discrete latent space;medical image segmentation,327;128;-1;327,39;126;-1;39,m;m,NAN,NAN,n,5
7550,ICLR,2021,Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation,Xinrong Hu;long wen;shushui wang;Dongpo Liang;Jian Zhuang;Yiyu Shi,~Xinrong_Hu1;wl960201@163.com;635386607@qq.com;41421891@qq.com;~Jian_Zhuang1;~Yiyu_Shi1,5;4;6;5,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,University of Notre Dame;GuangDong Cardiovascular Institute;;;;;Guangdong Provincal People's Hospital;University of Notre Dame,interpretability;multitask learning;attention mechanism;electrocardiography,128;-1;-1;-1;-1;-1;-1;128,170;-1;-1;-1;-1;-1;-1;170,m;m,usa,usa,n,8;2
7551,ICLR,2021,Iterative Graph Self-Distillation,Hanlin Zhang;Shuai Lin;Weiyang Liu;Pan Zhou;Jian Tang;Xiaodan Liang;Eric Xing,~Hanlin_Zhang1;~Shuai_Lin1;~Weiyang_Liu1;~Pan_Zhou3;~Jian_Tang1;~Xiaodan_Liang2;~Eric_Xing1,5;5;6;6,5;4;4;4,Reject,0,10,0.0,yes,9/28/20,Carnegie Mellon University;Sun Yat-sen University;University of Cambridge;Sea Group;HEC Montreal;SUN YAT-SEN UNIVERSITY;Carnegie Mellon University,graph-level representation learning;knowledge distillation,1;128;79;-1;-1;-1;1,28;293;6;-1;-1;293;28,m;m,usa,usa,n,8;10
7552,ICLR,2021,Approximate Birkhoff-von-Neumann decomposition: a differentiable approach,Andr√©s Hoyos-Idrobo,~Andr√©s_Hoyos-Idrobo1,4;4;5,1;3;3,Reject,0,1,0.0,yes,9/28/20,"Rakuten Institute of Technology, The University of Tokyo",Birkhoff-von-Neumann decomposition;doubly stochastic matrices;Riemannian optimization;Fairness exposure in ranking,71,36,m;m,NAN,NAN,y,7
7553,ICLR,2021,Acceleration in Hyperbolic and Spherical Spaces,David Mart√≠nez-Rubio,~David_Mart√≠nez-Rubio2,6;4;7;5;5,2;2;1;4;2,Reject,0,8,0.0,yes,9/28/20,University of Oxford,Riemannian optimization;acceleration;first-order methods,46,1,m,europe,uk,y,
7554,ICLR,2021,Prioritized Level Replay,Minqi Jiang;Edward Grefenstette;Tim Rockt√§schel,~Minqi_Jiang1;~Edward_Grefenstette1;~Tim_Rockt√§schel1,7;7;6;5,3;3;4;3,Reject,0,11,0.0,yes,9/28/20,University College London;Facebook;Facebook AI Research,Reinforcement Learning;Procedurally Generated Environments;Curriculum Learning;Procgen Benchmark,53;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
7555,ICLR,2021,Inductive Collaborative Filtering via Relation Graph Learning,Qitian Wu;Hengrui Zhang;Xiaofeng Gao;Hongyuan Zha,~Qitian_Wu1;sqstardust@sjtu.edu.cn;gao-xf@cs.sjtu.edu.cn;~Hongyuan_Zha1,6;4;6;6,5;5;4;4,Reject,0,4,0.0,yes,9/28/20,"Shanghai Jiao Tong University;University of Illinois, Chicago;;;The Chinese University of Hong Kong, Shenzhen",collaborative filtering;matrix completion;inductive learning;relation learning;recommender systems,29;-1;-1;-1;46,100;-1;-1;-1;39,m;m,NAN,NAN,y,10
7556,ICLR,2021,ARELU: ATTENTION-BASED RECTIFIED LINEAR UNIT,Chen Dengsheng;Jun Li;Kai Xu,~Chen_Dengsheng3;~Jun_Li4;~Kai_Xu5,7;3;5;6,3;4;5;3,Reject,0,7,0.0,yes,9/28/20,"National University of Defense Technology, Tsinghua University;University of Bonn;National University of Defense Technology",activation function;attention mechanism;rectified linear unit,4;128;-1,20;114;-1,m;m,NAN,NAN,n,6;8
7557,ICLR,2021,Learning Representation in Colour Conversion,Arash Akbarinia;Raquel Gil-Rodriguez;Alban Flachot;Matteo Toscani,~Arash_Akbarinia1;raquel.gil-rodriguez@psychol.uni-giessen.de;alban.flachot@psychol.uni-giessen.de;matteo.toscani@psychol.uni-giessen.de,4;6;7,5;3;5,Reject,0,3,0.0,yes,9/28/20,Justus Liebig University Giessen;;;Justus Liebig Universit‚àö¬ßt;;University of Giessen,Color representation;VAE;Color space;Unsupervised learning,-1;-1;-1;-1;-1;-1,419;-1;-1;-1;-1;-1,m;m,europe,de,n,2;5
7558,ICLR,2021,The Emergence of Individuality in Multi-Agent Reinforcement Learning,Jiechuan Jiang;Zongqing Lu,~Jiechuan_Jiang1;~Zongqing_Lu2,6;5;4;6,5;4;4;5,Reject,0,6,0.0,yes,9/28/20,Peking University;Peking University,,14;14,23;23,u;m,asia,cn,n,
7559,ICLR,2021,Adaptive Learning Rates for Multi-Agent Reinforcement Learning,Jiechuan Jiang;Zongqing Lu,~Jiechuan_Jiang1;~Zongqing_Lu2,5;4;4;5;5,2;2;2;4;3,Reject,0,6,0.0,yes,9/28/20,Peking University;Peking University,,14;14,23;23,u;m,asia,cn,n,
7560,ICLR,2021,A Chain Graph Interpretation of Real-World Neural Networks,Yuesong Shen;Daniel Cremers,~Yuesong_Shen1;~Daniel_Cremers1,6;4;4;3,2;3;4;4,Reject,0,9,0.0,yes,9/28/20,Technical University Munich;Technical University Munich,neural network interpretation;chain graph;deep learning theory;probabilistic graphical model,-1;-1,-1;-1,m;m,NAN,NAN,y,10
7561,ICLR,2021,On the Inductive Bias of a CNN for Distributions with Orthogonal Patterns,Alon Brutzkus;Amir Globerson,~Alon_Brutzkus1;~Amir_Globerson1,6;5;6;5,3;5;5;3,Reject,0,4,0.0,yes,9/28/20,Tel Aviv University;Tel Aviv University,Deep learning theory;generalization;overparemeterization;CNN,34;34,190;190,m;m,europe,il,y,1
7562,ICLR,2021,Deep Q-Learning with Low Switching Cost,Shusheng Xu;Simon Shaolei Du;Yi Wu,~Shusheng_Xu1;~Simon_Shaolei_Du1;~Yi_Wu1,5;5;5;4,3;4;3;5,Reject,0,1,0.0,yes,9/28/20,"IIIS, Tsinghua University;Facebook;Tsinghua University",deep Q-network;DQN;switching cost;deep Q-learning,4;-1;4,20;-1;20,u;m,asia,cn,y,
7563,ICLR,2021,Later Span Adaptation for Language Understanding,Rongzhou Bao;Zhuosheng Zhang;hai zhao,~Rongzhou_Bao1;~Zhuosheng_Zhang1;~hai_zhao1,6;6;4;4,3;4;4;4,Reject,0,6,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;Shanghai Jiao Tong University",,4;29;29,20;100;100,m;m,asia,cn,n,3;2;1
7564,ICLR,2021,Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes,Sebastian W. Ober;Laurence Aitchison,~Sebastian_W._Ober1;~Laurence_Aitchison1,7;7;6,3;3;3,Reject,0,3,0.0,yes,9/28/20,University of Cambridge;University of Bristol,Bayesian neural networks;deep Gaussian processes;variational inference;inducing points,79;110,6;91,m;m,europe,uk,n,11
7565,ICLR,2021,Attention-driven Robotic Manipulation,Stephen James;Andrew Davison,~Stephen_James1;~Andrew_Davison1,4;7;4,4;4;4,Reject,0,5,0.0,yes,9/28/20,Imperial College London;Imperial College London,Robotics;Robot Manipulation;Reinforcement Learning,53;53,11;11,m;m,europe,uk,n,8
7566,ICLR,2021,Learning from Noisy Data with Robust Representation Learning,Junnan Li;Caiming Xiong;Steven Hoi,~Junnan_Li2;~Caiming_Xiong1;~Steven_Hoi2,6;7;6;6,4;4;4;3,Reject,0,4,0.0,yes,9/28/20,Salesforce Research Asia;Salesforce Research;Salesforce Research Asia,label noise;out-of-distribution noise;contrastive learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8
7567,ICLR,2021,FLAGNet : Feature Label based Automatic Generation Network for symbolic music,SeongHyeon Go,~SeongHyeon_Go2,2;3;2;3,5;5;5;5,Reject,0,7,0.0,yes,9/28/20,SungKyunKwan University,cGAN;RNN;MIDI generation;music,-1,100,m,NAN,NAN,n,5;4
7568,ICLR,2021,A Half-Space Stochastic Projected Gradient Method for Group Sparsity Regularization,Tianyi Chen;Guanyi Wang;Tianyu DING;Bo Ji;Sheng Yi;Zhihui Zhu,tiachen@microsoft.com;~Guanyi_Wang1;~Tianyu_DING2;~Bo_Ji2;shengyi@microsoft.com;~Zhihui_Zhu1,6;5;5;5,3;2;3;3,Reject,0,7,0.0,yes,9/28/20,Johns Hopkins University;Georgia Institute of Technology;Johns Hopkins University;National University of Singapore;North Carolina State University;University of Denver,Group Sparsity;Stochastic Learning;Half-Space Projection;Group-Sparsity Identification,71;12;71;17;92;-1,12;38;12;25;340;416,m;m,europe,uk,y,1
7569,ICLR,2021,Robust Loss Functions for Complementary Labels Learning,Defu Liu;Guowu Yang,~Defu_Liu1;guowu@uestc.edu.cn,5;3;7;7,4;4;3;2,Reject,0,6,0.0,yes,9/28/20,University of Electronic Science and Technology of China  Tsinghua University;;University of Electronic Science and Technology of China,Complementary Labels;Robustness;Machine Learning,4;-1;-1,20;-1;553,m;m,NAN,NAN,y,8
7570,ICLR,2021,Density Constrained Reinforcement Learning,Zengyi Qin;Yuxiao Chen;Chuchu Fan,~Zengyi_Qin1;~Yuxiao_Chen1;~Chuchu_Fan2,7;7;5;6,3;2;4;4,Reject,0,12,0.0,yes,9/28/20,Massachusetts Institute of Technology;;Massachusetts Institute of Technology,Constrained Reinforcement Learning;Density;Safe AI,5;-1;5,4;-1;4,m;f,usa,usa,y,1
7571,ICLR,2021,Memory Representation in Transformer,Mikhail Burtsev;Yurii Kuratov;Anton Peganov;Grigory V. Sapunov,~Mikhail_Burtsev1;yurii.kuratov@phystech.edu;apeganov@nvidia.com;~Grigory_V._Sapunov1,4;4;3;5;3,5;4;4;4;4,Reject,0,14,0.0,yes,9/28/20,Moscow Institute of Physics and Technology;Moscow Institute of Physics and Technology;Moscow Institute of Physics and Technology;Intento,transformer;memory augmented networks,-1;-1;-1;-1,224;224;224;-1,m;m,NAN,NAN,n,8;3
7572,ICLR,2021,A Coach-Player Framework for Dynamic Team Composition,Bo Liu;qiang liu;Peter Stone;Animesh Garg;Yuke Zhu;Anima Anandkumar,~Bo_Liu13;~qiang_liu4;~Peter_Stone1;~Animesh_Garg1;~Yuke_Zhu1;~Anima_Anandkumar1,6;7;4;5,3;2;3;3,Reject,0,5,0.0,yes,9/28/20,"University of Texas, Austin;University of Texas, Austin;Sony AI;University of Toronto;Computer Science Department, University of Texas, Austin;California Institute of Technology",Multiagent reinforcement learning,-1;-1;-1;18;-1;150,-1;-1;-1;18;-1;4,m;f,usa,usa,y,6;8;1
7573,ICLR,2021,Understanding and Mitigating Accuracy Disparity in Regression,Jianfeng Chi;Han Zhao;Geoff Gordon;Yuan Tian,~Jianfeng_Chi1;~Han_Zhao1;~Geoff_Gordon2;~Yuan_Tian2,4;6;7;6,3;3;3;3,Reject,0,6,0.0,yes,9/28/20,"University of Virginia;University of Illinois, Urbana Champaign;Microsoft;University of Virginia",Algorithmic Fairness;Representation Learning,53;-1;-1;53,117;-1;-1;117,m;f,usa,usa,y,2;1;7
7574,ICLR,2021,NNGeometry: Easy and Fast Fisher Information Matrices and Neural Tangent Kernels in PyTorch,Thomas George,~Thomas_George2,7;4;5;4,3;4;2;3,Reject,0,5,0.0,yes,9/28/20,Mila - Universit√© de Montr√©al,,-1,-1,m,NAN,NAN,n,
7575,ICLR,2021,Parametric UMAP: learning embeddings with deep neural networks for representation and semi-supervised learning,Tim Sainburg;Leland McInnes;Timothy Q Gentner,~Tim_Sainburg1;leland.mcinnes@gmail.com;tgenter@ucsd.edu,7;4;4;9,5;5;5;5,Reject,0,28,0.0,yes,9/28/20,University of California  San Diego;;;;University of California  San Diego,unsupervised learning;representation learning;dimensionality reduction;UMAP;semi-supervised learning,-1;-1;-1;-1;-1,33;-1;-1;-1;33,m;m,usa,usa,n,10
7576,ICLR,2021,Towards Principled Representation Learning for Entity Alignment,Lingbing Guo;Zequn Sun;Mingyang Chen;Wei Hu;Huajun Chen,~Lingbing_Guo1;~Zequn_Sun1;mingyangchen@zju.edu.cn;whu@nju.edu.cn;~Huajun_Chen1,5;5;5;8,3;4;3;3,Reject,0,4,0.0,yes,9/28/20,Zhejiang University;Nanjing University;Zhejiang University;Nanjing University;;Zhejiang University;Zhejiang University,Representation Learning;Knowledge Graph;Entity Alignment;Knowledge Graph Embedding,42;52;42;52;-1;42;42,94;111;94;111;-1;94;94,m;m,asia,cn,y,8;3;10
7577,ICLR,2021,SHADOWCAST: Controllable Graph Generation with Explainability,Wesley Joon-Wie Tann;Ee-Chien Chang;Bryan Hooi,~Wesley_Joon-Wie_Tann1;~Ee-Chien_Chang1;~Bryan_Hooi1,5;5;5;4,4;4;5;5,Reject,0,6,0.0,yes,9/28/20,National University of Singapore;National University of Singapore;National University of Singapore,Controllable Graph Generation;Explainability;Conditional Generative Adversarial Network,17;17;17,25;25;25,m;m,asia,sg,n,10;5;4
7578,ICLR,2021,Geometry of Program Synthesis,James Clift;Daniel Murfet;James Wallbridge,~James_Clift1;~Daniel_Murfet1;~James_Wallbridge1,7;5;4,2;1;1,Reject,0,5,0.0,yes,9/28/20,The University of Melbourne;The University of Melbourne;Kavli IPMU,Program Synthesis;Singular Learning Theory;Bayesian Inference;MCMC,85;85;453,31;31;-1,m;m,NAN,NAN,y,1
7579,ICLR,2021,Stochastic Canonical Correlation Analysis: A Riemannian Approach,Zihang Meng;Rudrasis Chakraborty;Vikas Singh,~Zihang_Meng1;~Rudrasis_Chakraborty1;~Vikas_Singh1,7;6;4;6,3;2;4;4,Reject,0,10,0.0,yes,9/28/20,"University of Wisconsin, Madison;University of California Berkeley;University of Wisconsin, Madison",CCA;streaming;differential geometry;DeepCCA;fairness,18;-1;18,49;7;49,m;m,usa,usa,y,9
7580,ICLR,2021,Disentangling style and content for low resource video domain adaptation: a case study on keystroke inference attacks,John Lim;Fabian Monrose;Jan-Michael Frahm,~John_Lim1;~Fabian_Monrose1;~Jan-Michael_Frahm1,5;7;5;7,2;3;4;2,Reject,0,14,0.0,yes,9/28/20,"Department of Computer Science, University of North Carolina, Chapel Hill;University of North Carolina at Chapel Hill;Department of Computer Science, University of North Carolina, Chapel Hill",Applications;side channel attacks;supervised disentangled learning;video domain adaptation,64;64;64,-1;56;-1,m;m,NAN,NAN,n,4
7581,ICLR,2021,On Learning Read-once DNFs With Neural Networks,Ido Bronstein;Alon Brutzkus;Amir Globerson,~Ido_Bronstein2;~Alon_Brutzkus1;~Amir_Globerson1,5;7;4,4;2;3,Reject,0,3,0.0,yes,9/28/20,"Tel Aviv University, Technion;Tel Aviv University;Tel Aviv University",neural network;DNF;read-once;inductive bias;reconstruction;alignment,29;34;34,190;190;190,m;m,europe,il,y,1;10
7582,ICLR,2021,Exploring Transferability of Perturbations in Deep Reinforcement Learning,Ezgi Korkmaz,~Ezgi_Korkmaz1,4;3;4;6,4;4;4;3,Reject,0,13,0.0,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden",transferability;deep reinforcement learning;generalization;adversarial,174,239,f,NAN,NAN,n,4
7583,ICLR,2021,Subspace Clustering via Robust Self-Supervised Convolutional Neural Network,Dario Sitnik;Ivica Kopriva,~Dario_Sitnik1;ivica.kopriva@irb.hr,5;3;5,4;4;5,Reject,0,3,0.0,yes,9/28/20,Ru∆í√´er Bo‚âà¬∞kovi∆í√° Institute;;Ru∆í√´er Bo‚âà¬∞kovi∆í√° Institute,deep subspace clustering;convolutional neural networks;self-supervised learning;correntropy;generalization;robustness,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
7584,ICLR,2021,Cross-Probe BERT for Efficient and Effective Cross-Modal Search,TAN YU;Hongliang Fei;Ping Li,~TAN_YU2;~Hongliang_Fei2;~Ping_Li3,6;6;5;6,4;4;5;3,Reject,0,0,0.0,yes,9/28/20,Baidu;Baidu;Baidu,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;3
7585,ICLR,2021,Spectral Synthesis for Satellite-to-Satellite Translation,Thomas Vandal;Daniel McDuff;Weile Wang;Andrew Michaelis;Ramakrishna Nemani,~Thomas_Vandal1;~Daniel_McDuff1;weile.wang@gmail.com;michaelis@hyperplane.org;rama.nemani@nasa.gov,5;6;5,4;4;5,Reject,0,3,0.0,yes,9/28/20,NASA Ames Research Center;Microsoft;;;;;;NASA Ames Research Center,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,2
7586,ICLR,2021,Contrastive Learning with Stronger Augmentations,Xiao Wang;Guo-Jun Qi,~Xiao_Wang6;~Guo-Jun_Qi1,7;6;6;4,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,Purdue University;University of Central Florida,Contrastive learning;Self-supervised learning;Unsupervised learning;Stronger augmentations,23;71,94;633,m;m,usa,usa,n,6;2
7587,ICLR,2021,Learning to Observe with Reinforcement Learning,Mehmet Koseoglu;Ece Kunduracioglu;Ayca Ozcelikkale,~Mehmet_Koseoglu1;ecekundura@gmail.com;~Ayca_Ozcelikkale1,4;6;5;4,5;4;3;3,Reject,0,4,0.0,yes,9/28/20,Hacettepe University;;;Uppsala University,Reinforcement learning;observation strategies;active data collection,453;-1;-1;174,588;-1;-1;111,m;f,europe,se,n,
7588,ICLR,2021,Quantifying Statistical Significance of Neural Network Representation-Driven Hypotheses by Selective Inference,Vo Nguyen Le Duy;Shogo Iwazaki;Ichiro Takeuchi,~Vo_Nguyen_Le_Duy1;iwazaki.s.mllab.nit@gmail.com;~Ichiro_Takeuchi1,6;8;6;7,4;2;3;2,Reject,0,4,0.0,yes,9/28/20,Nagoya Institute of Technology;Nagoya Institute of Technology;Nagoya Institute of Technology,Deep Neural Network Representation;Reliability;Selective Inference;Statistical Hypothesis Testing;p-value,-1;-1;-1,1310;1310;1310,m;m,NAN,NAN,y,8
7589,ICLR,2021,Sobolev Training for the Neural Network Solutions of PDEs,Hwijae Son;Jin Woo Jang;Woo Jin Han;Hyung Ju Hwang,~Hwijae_Son1;jangjinw@iam.uni-bonn.de;wjhan@postech.ac.kr;~Hyung_Ju_Hwang1,5;4;7,4;5;4,Reject,0,5,0.0,yes,9/28/20,POSTECH;;;;;POSTECH,Sobolev Training;Partial Differential Equations;Neural Networks;Convergence,128;-1;-1;-1;-1;128,151;-1;-1;-1;-1;151,m;f,asia,kr,n,9
7590,ICLR,2021,Measuring Progress in Deep Reinforcement Learning Sample Efficiency ,Florian E. Dorner,~Florian_E._Dorner1,4;2;5;5,4;5;5;5,Reject,0,5,0.0,yes,9/28/20,Swiss Federal Institute of Technology,Deep Reinforcement Learning;Sample Efficiency,-1,-1,m,NAN,NAN,n,
7591,ICLR,2021,Hybrid Discriminative-Generative Training via Contrastive Learning,Hao Liu;Pieter Abbeel,~Hao_Liu1;~Pieter_Abbeel2,3;5;6;6,5;3;3;4,Reject,0,5,0.0,yes,9/28/20,University of California Berkeley;Covariant,Hybrid Models;Contrastive Learning;Energy-Based Models;Discriminative-Generative Models,-1;-1,7;-1,m;m,NAN,NAN,n,5;4
7592,ICLR,2021,Graph Representation Learning for Multi-Task Settings: a Meta-Learning Approach,Davide Buffelli;Fabio Vandin,~Davide_Buffelli1;~Fabio_Vandin2,5;6;7,4;5;3,Reject,0,5,0.0,yes,9/28/20,Universita' degli studi di Padova;Universita' degli studi di Padova,Graph Representation Learning;Multi-Task Learning;Meta-Learning;Graph Neural Networks,-1;-1,-1;-1,m;m,NAN,NAN,n,6;10
7593,ICLR,2021,Fixing Asymptotic Uncertainty of Bayesian Neural Networks with Infinite ReLU Features,Agustinus Kristiadi;Matthias Hein;Philipp Hennig,~Agustinus_Kristiadi1;~Matthias_Hein2;~Philipp_Hennig1,5;7;5,4;3;4,Reject,0,5,0.0,yes,9/28/20,University of Tuebingen;University of T√ºbingen;University of Tuebingen,Bayesian deep learning;Gaussian processes;uncertainty quantification,128;128;128,78;78;78,m;m,europe,de,y,11;1
7594,ICLR,2021,Multi-Task Multicriteria Hyperparameter Optimization,Kirill Akhmetzyanov;Alexander Yuzhakov,~Kirill_Akhmetzyanov1;uz@at.pstu.ru,3;2;2;3,4;4;4;4,Reject,0,9,0.0,yes,9/28/20,Perm National Research Polytechnic University;;Perm National Research Polytechnic University,hyperparameter optimization;machine learning;neural network,-1;-1;-1,1447;-1;1447,m;m,NAN,NAN,n,
7595,ICLR,2021,Shape Matters: Understanding the Implicit Bias of the Noise Covariance,Jeff Z. HaoChen;Colin Wei;Jason D. Lee;Tengyu Ma,~Jeff_Z._HaoChen1;~Colin_Wei1;~Jason_D._Lee1;~Tengyu_Ma1,6;6;7;6,4;3;3;3,Reject,0,5,0.0,yes,9/28/20,"Stanford University;Computer Science Department, Stanford University;Princeton University;Stanford University",implicit regularization;implicit bias;algorithmic regularization;over-parameterization;learning theory,5;5;29;5,2;2;9;2,m;m,usa,usa,y,
7596,ICLR,2021,D2p-fed:Differentially Private Federated Learning with Efficient Communication,Lun Wang;Ruoxi Jia;Dawn Song,~Lun_Wang1;ruoxijia@vt.edu;~Dawn_Song1,4;7;6;5,3;4;4;4,Reject,0,7,0.0,yes,9/28/20,University of California Berkeley;Virginia Tech;University of California Berkeley,Differential Privacy;Federated Learning;Communication Efficiency,-1;64;-1,7;-1;7,m;f,usa,usa,y,9
7597,ICLR,2021,Watching the World Go By: Representation Learning from Unlabeled Videos,Daniel Gordon;Kiana Ehsani;Dieter Fox;Ali Farhadi,~Daniel_Gordon1;~Kiana_Ehsani1;~Dieter_Fox1;~Ali_Farhadi3,4;8;5,5;3;3,Reject,0,3,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;Allen Institute for Artificial Intelligence;University of Washington;University of Washington",Representation Learning;Unsupervised Learning;Video Analytics,11;-1;11;11,29;-1;29;29,m;m,usa,usa,n,
7598,ICLR,2021,Federated Learning's Blessing: FedAvg has Linear Speedup,Zhaonan Qu;Kaixiang Lin;Zhaojian Li;Jiayu Zhou;Zhengyuan Zhou,zhaonanq@stanford.edu;~Kaixiang_Lin1;lizhaoj1@egr.msu.edu;~Jiayu_Zhou1;~Zhengyuan_Zhou2,6;5;6;5,3;3;4;4,Reject,0,7,0.0,yes,9/28/20,Stanford University;Amazon;;;Michigan State University;New York University,Federated learning,5;-1;-1;-1;110;23,2;-1;-1;-1;105;26,m;m,usa,usa,y,9
7599,ICLR,2021,Learning Disentangled Representations for Image Translation,Aviv Gabbay;Yedid Hoshen,~Aviv_Gabbay1;~Yedid_Hoshen3,6;6;4,4;5;3,Reject,0,3,0.0,yes,9/28/20,Hebrew University of Jerusalem;Hebrew University of Jerusalem,disentanglement;image translation;latent optimization,85;85,235;235,m;m,europe,il,n,5;4
7600,ICLR,2021,Imitation with Neural Density Models,Kuno Kim;Akshat Jindal;Yang Song;Jiaming Song;Yanan Sui;Stefano Ermon,~Kuno_Kim1;akshatj@cs.stanford.edu;~Yang_Song1;~Jiaming_Song1;~Yanan_Sui1;~Stefano_Ermon1,8;5;6;5,3;4;3;4,Reject,0,9,0.0,yes,9/28/20,"Stanford University;;;Stanford University;Computer Science Department, Stanford University;Tsinghua University;Stanford University",Imitation Learning;Reinforcement Learning;Density Estimation;Density Model;Maximum Entropy RL;Mujoco,5;-1;-1;5;5;4;5,2;-1;-1;2;2;20;2,m;m,usa,usa,y,4
7601,ICLR,2021,Graph Permutation Selection for Decoding of Error Correction Codes using Self-Attention,Nir Raviv;Avi Caciularu;Tomer Raviv;Jacob Goldberger;Yair Be'ery,nirraviv89@gmail.com;~Avi_Caciularu1;tomerraviv95@gmail.com;~Jacob_Goldberger1;ybeery@post.tau.ac.il,6;5;6;5;4,4;4;3;4;3,Reject,0,6,0.0,yes,9/28/20,Tel Aviv University;Bar-Ilan University;;;Bar-Ilan University;Tel Aviv University,decoding;error correcting codes;belief propagation;deep learning,34;110;-1;-1;110;34,190;570;-1;-1;570;190,m;m,europe,il,n,8
7602,ICLR,2021,A Technical and Normative Investigation of Social Bias Amplification,Angelina Wang;Olga Russakovsky,~Angelina_Wang1;~Olga_Russakovsky1,7;5;5,4;4;4,Reject,0,4,0.0,yes,9/28/20,Princeton University;Princeton University,bias amplification;fairness;societal considerations,29;29,9;9,f;f,usa,usa,n,7
7603,ICLR,2021,Towards Understanding Fast Adversarial Training,Bai Li;Shiqi Wang;Suman Jana;Lawrence Carin,~Bai_Li1;~Shiqi_Wang2;~Suman_Jana1;~Lawrence_Carin2,7;5;5;5,5;5;4;4,Reject,0,10,0.0,yes,9/28/20,Duke University;Columbia University;Columbia University;Duke University,fast adversarial training;adversarial examples,46;23;23;46,20;17;17;20,m;m,europe,se,n,4
7604,ICLR,2021,XLA: A Robust Unsupervised Data Augmentation Framework for Cross-Lingual NLP,M Saiful Bari;Tasnim Mohiuddin;Shafiq Joty,~M_Saiful_Bari2;~Tasnim_Mohiuddin1;~Shafiq_Joty1,5;6;6;5,4;3;4;3,Reject,0,8,0.0,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;SalesForce.com,multi-lingual;cross-lingual;data-augmentation;nlp,44;44;-1,47;47;-1,m;m,NAN,NAN,n,6;3
7605,ICLR,2021,MISSO: Minimization by Incremental Stochastic Surrogate Optimization for Large Scale Nonconvex and Nonsmooth Problems,Belhal Karimi;Hoi To Wai;Eric Moulines;Ping Li,~Belhal_Karimi1;~Hoi_To_Wai1;~Eric_Moulines1;~Ping_Li3,6;6;5;7;3,3;4;1;3;5,Reject,0,5,0.0,yes,9/28/20,Baidu Research;The Chinese University of Hong Kong;Ecole polytechnique;Baidu,nonconvex;optimization;stochastic;sampling;MCMC;majorization-minimization,-1;327;-1;-1,-1;39;89;-1,m;m,NAN,NAN,y,11
7606,ICLR,2021,Action Guidance: Getting the Best of Sparse Rewards and Shaped Rewards for Real-time Strategy Games,Shengyi Huang;Santiago Ontanon,~Shengyi_Huang1;~Santiago_Ontanon1,6;4;6;4,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,Drexel University;Google,reinforcement learning;real-time strategy games;sparse rewards;shaped rewards;policy gradient;sample-efficiency,327;-1,380;-1,m;m,NAN,NAN,n,
7607,ICLR,2021,Quantifying Exposure Bias for Open-ended Language Generation,Tianxing He;Jingzhao Zhang;Zhiming Zhou;James R. Glass,~Tianxing_He1;~Jingzhao_Zhang2;~Zhiming_Zhou2;~James_R._Glass1,6;6;3;3,4;4;4;4,Reject,0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Shanghai University of Finance and Economics;Massachusetts Institute of Technology,exposure bias;natural language generation;autoregressive,5;5;-1;5,4;4;818;4,m;m,usa,usa,n,3
7608,ICLR,2021,Chameleon: Learning Model Initializations Across Tasks With Different Schemas,Lukas Brinkmeyer;Rafael Rego Drumond;Randolf Scholz;Josif Grabocka;Lars Schmidt-Thieme,~Lukas_Brinkmeyer1;radrumond@ismll.uni-hildesheim.de;scholz@ismll.uni-hildesheim.de;~Josif_Grabocka1;~Lars_Schmidt-Thieme1,6;6;4;3;3,3;3;4;5;4,Reject,0,5,0.0,yes,9/28/20,University of Hildesheim;;;;;Universit√§t Freiburg;University of Hildesheim,Meta-Learning;Initialization;Few-shot classification,453;-1;-1;-1;-1;-1;453,-1;-1;-1;-1;-1;-1;-1,m;m,europe,de,n,6
7609,ICLR,2021,Generalized Gumbel-Softmax Gradient Estimator for Generic Discrete Random Variables,Weonyoung Joo;Dongjun Kim;Seungjae Shin;Il-chul Moon,~Weonyoung_Joo1;~Dongjun_Kim1;~Seungjae_Shin1;~Il-chul_Moon1,4;4;5;4,5;3;3;3,Reject,0,0,0.0,yes,9/28/20,Samsung Electronics;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Deep learning;Deep generative model;Unsupervised learning;Gradient estimator;Reparameterization trick;Discrete distribution;Gumbel-Softmax,-1;-1;-1;-1,-1;96;96;96,m;m,NAN,NAN,y,10;5
7610,ICLR,2021,Learning Latent Topology for Graph Matching,Tianshu Yu;Runzhong Wang;Junchi Yan;Baoxin Li,~Tianshu_Yu2;~Runzhong_Wang1;~Junchi_Yan2;~Baoxin_Li1,7;4;4;6;8,4;4;3;1;3,Reject,0,13,0.0,yes,9/28/20,Arizona State University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Arizona State University,Graph matching;generative graph model;latent structure learning,85;29;29;85,182;100;100;182,f;m,usa,usa,n,10;5
7611,ICLR,2021,Defuse: Debugging Classifiers Through Distilling Unrestricted Adversarial Examples,Dylan Z Slack;Nathalie Rauschmayr;Krishnaram Kenthapadi,~Dylan_Z_Slack1;rauscn@amazon.com;~Krishnaram_Kenthapadi1,6;4;4,3;4;4,Reject,0,4,0.0,yes,9/28/20,"University of California, Irvine;;;Amazon AWS AI",debugging;interpretability;explainability,-1;-1;-1;-1,98;-1;-1;-1,m;m,NAN,NAN,n,1;5;4
7612,ICLR,2021,Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning,Sai Praneeth Karimireddy;Martin Jaggi;Satyen Kale;Mehryar Mohri;Sashank J. Reddi;Sebastian U Stich;Ananda Theertha Suresh,~Sai_Praneeth_Karimireddy1;~Martin_Jaggi1;~Satyen_Kale2;~Mehryar_Mohri1;~Sashank_J._Reddi1;~Sebastian_U_Stich1;~Ananda_Theertha_Suresh1,6;4;4;5,2;4;4;3,Reject,0,5,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;EPFL;Google;;New York University;Google;Swiss Federal Institute of Technology Lausanne;Google,Federated learning;Federated optimization;Adaptive optimization;Adam;Variance Reduction;Distributed optimization;Decentralized optimization,-1;23;-1;-1;23;-1;-1;-1,-1;-1;-1;-1;26;-1;-1;-1,m;m,NAN,NAN,y,
7613,ICLR,2021,On the Universal Approximability and Complexity Bounds of Deep Learning in Hybrid Quantum-Classical Computing,Weiwen Jiang;Yukun Ding;Yiyu Shi,~Weiwen_Jiang1;~Yukun_Ding1;~Yiyu_Shi1,6;4;6,2;4;4,Reject,0,5,0.0,yes,9/28/20,University of Notre Dame;University of Notre Dame;University of Notre Dame,deep learning;hybrid quantum-classical computing;universal approximability,128;128;128,170;170;170,m;m,usa,usa,y,
7614,ICLR,2021,Revisiting Loss Modelling for Unstructured Pruning,C√©sar Laurent;Camille Ballas;Thomas George;Pascal Vincent;Nicolas Ballas,~C√©sar_Laurent1;~Camille_Ballas1;~Thomas_George2;~Pascal_Vincent1;~Nicolas_Ballas1,6;5;7;3,5;4;5;4,Reject,0,8,0.0,yes,9/28/20,University of Montreal;Insight Centre for Data Analytics;Mila - Universit√© de Montr√©al;University of Montreal;Facebook,Deep Learning;Network Pruning;Unstructured Pruning,128;-1;-1;128;-1,73;-1;-1;73;-1,m;m,NAN,NAN,n,
7615,ICLR,2021,Prior-guided Bayesian Optimization,Artur Souza;Luigi Nardi;Leonardo Oliveira;Kunle Olukotun;Marius Lindauer;Frank Hutter,~Artur_Souza1;~Luigi_Nardi1;~Leonardo_Oliveira1;~Kunle_Olukotun1;~Marius_Lindauer1;~Frank_Hutter1,3;4;6;4;8,4;4;5;4;4,Reject,0,7,0.0,yes,9/28/20,"Universidade Federal de Minas Gerais;Lund University / Lund Institute of Technology;Universidade Federal de Minas Gerais, Universidade Federal de Minas Gerais;Stanford University;Leibniz Universit√§t Hannover;University of Freiburg & Bosch",Bayesian Optimization;Automated Machine Learning,-1;453;-1;5;-1;150,-1;103;-1;2;515;83,m;m,NAN,NAN,y,11
7616,ICLR,2021,MetaPhys: Few-Shot Adaptation for Non-Contact Physiological Measurement,Xin Liu;Ziheng Jiang;Joshua Wolff Fromm;Xuhai Xu;Shwetak Patel;Daniel McDuff,~Xin_Liu8;~Ziheng_Jiang1;~Joshua_Wolff_Fromm1;~Xuhai_Xu1;~Shwetak_Patel1;~Daniel_McDuff1,4;5;6,3;3;5,Reject,0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;University of Washington, Seattle;OctoML;University of Washington, Seattle;University of Washington;Microsoft",Healthcare;Meta Learning;Computer Vision,11;11;-1;11;11;-1,29;29;-1;29;29;-1,m;m,NAN,NAN,n,6;8
7617,ICLR,2021,First-Order Optimization Algorithms via Discretization of Finite-Time Convergent Flows,Mouhacine Benosman;Orlando Romero;Anoop Cherian,~Mouhacine_Benosman1;orlando.rodrigues.romero@gmail.com;~Anoop_Cherian1,6;4;6;4,4;4;3;3,Reject,0,6,0.0,yes,9/28/20,Mitsubishi Electric Research Labs;;;Australian National University,Finite-time optimization;dynamical systems;deep neural networks optimization,-1;-1;-1;99,-1;-1;-1;59,m;m,australasia,au,y,
7618,ICLR,2021,Learning to Actively Learn: A Robust Approach,Jifan Zhang;Kevin Jamieson,~Jifan_Zhang1;~Kevin_Jamieson1,5;4;3;7,2;3;4;4,Reject,0,7,0.0,yes,9/28/20,"Department of Computer Science, University of Washington;University of Washington",Active Learning;Adversarial Learning;Bandit Algorithms;Meta-Learning,11;11,29;29,m;m,usa,usa,n,6;4
7619,ICLR,2021,Recall Loss for Imbalanced Image Classification and Semantic Segmentation,Junjiao Tian;Niluthpol Chowdhury Mithun;Zachary Seymour;Han-pang Chiu;Zsolt Kira,~Junjiao_Tian1;~Niluthpol_Chowdhury_Mithun1;~Zachary_Seymour1;~Han-pang_Chiu1;~Zsolt_Kira1,6;6;7;5,4;5;5;3,Reject,0,8,0.0,yes,9/28/20,Georgia Institute of Technology;SRI International;SRI International;SRI International;Georgia Institute of Technology,Data Imbalance;Classification;Semantic Segmentation;Deep Learning,12;-1;-1;-1;12,38;-1;-1;-1;38,m;m,usa,usa,n,2;4
7620,ICLR,2021,Testing Robustness Against Unforeseen Adversaries,Daniel Kang;Yi Sun;Dan Hendrycks;Tom B Brown;Jacob Steinhardt,~Daniel_Kang1;~Yi_Sun3;~Dan_Hendrycks1;~Tom_B_Brown1;~Jacob_Steinhardt1,5;4;5;5,5;3;3;4,Reject,0,5,0.0,yes,9/28/20,Stanford University;University of Chicago;UC Berkeley;;University of California Berkeley,adversarial examples;adversarial training;adversarial attacks,5;46;-1;-1;-1,2;10;-1;-1;7,m;m,usa,usa,n,4
7621,ICLR,2021,A Spectral Perspective on Deep Supervised Community Detection,Nathan Grinsztajn;Philippe Preux;Edouard Oyallon,~Nathan_Grinsztajn1;~Philippe_Preux1;~Edouard_Oyallon1,4;3;4;6,4;4;5;2,Reject,0,5,0.0,yes,9/28/20,INRIA;Universit√© de Lille;CNRS/LIP6,GCN;graph spectrum;stability;graph Laplacian,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
7622,ICLR,2021,On Trade-offs of Image Prediction in Visual Model-Based Reinforcement Learning,Mohammad Babaeizadeh;Mohammad Taghi Saffar;Danijar Hafner;Dumitru Erhan;Harini Kannan;Chelsea Finn;Sergey Levine,~Mohammad_Babaeizadeh1;~Mohammad_Taghi_Saffar1;~Danijar_Hafner1;~Dumitru_Erhan1;hkannan@google.com;~Chelsea_Finn1;~Sergey_Levine1,7;6;4;3,4;2;4;3,Reject,0,9,0.0,yes,9/28/20,"Google Brain;Google;Department of Computer Science, University of Toronto;Google;;;Stanford University;University of Washington",world models;model based reinforcement learning;latent planning;model-based reinforcement learning;model predictive control;video prediction,-1;-1;18;-1;-1;-1;5;11,-1;-1;18;-1;-1;-1;2;29,m;m,usa,usa,n,
7623,ICLR,2021,Multimodal Attention for Layout Synthesis in Diverse Domains,Kamal Gupta;Vijay Mahadevan;Alessandro Achille;Justin Lazarow;Larry S. Davis;Abhinav Shrivastava,~Kamal_Gupta1;~Vijay_Mahadevan1;~Alessandro_Achille1;~Justin_Lazarow1;~Larry_S._Davis1;~Abhinav_Shrivastava2,6;5;5;7,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,"University of Maryland, College Park;University of California, San Diego;California Institute of Technology;University of California, San Diego;Amazon;Department of Computer Science, University of Maryland, College Park",layout generation;layout synthesis;multimodal attention;transformers;document layouts;generative model;3D,12;-1;150;-1;-1;-1,90;33;4;33;-1;90,m;m,NAN,NAN,n,8;10
7624,ICLR,2021,On the Inversion of Deep Generative Models,Aviad Aberdam;Dror Simon;Michael Elad,~Aviad_Aberdam1;~Dror_Simon1;~Michael_Elad1,7;3;6,4;5;3,Reject,0,6,0.0,yes,9/28/20,"Technion, Technion;Computer Science Departmen, Technion-Israel Institute of Technology;Computer Science Departmen, Technion-Israel Institute of Technology",Sparse Representation;Inverse Problem;Deep Generative Models;Compressed Sensing,29;29;29,-1;-1;-1,m;m,NAN,NAN,y,1;5
7625,ICLR,2021,Analyzing Attention Mechanisms through Lens of Sample Complexity and Loss Landscape,Bingyuan Liu;Yogesh Balaji;Lingzhou Xue;Martin Renqiang Min,~Bingyuan_Liu2;~Yogesh_Balaji1;~Lingzhou_Xue1;~Martin_Renqiang_Min1,5;3;4;5,3;3;4;3,Reject,0,7,0.0,yes,9/28/20,"Pennsylvania State University;Department of Computer Science, University of Maryland, College Park;Pennsylvania State University;NEC Laboratories America",Attention mechanisms;deep learning;sample complexity;self-attention,44;-1;44;-1,-1;90;-1;-1,m;m,NAN,NAN,y,8
7626,ICLR,2021,Local SGD Meets Asynchrony,Bapi Chatterjee;Vyacheslav Kungurtsev;Dan Alistarh,~Bapi_Chatterjee1;~Vyacheslav_Kungurtsev1;~Dan_Alistarh7,5;4;4,4;3;4,Reject,0,3,0.0,yes,9/28/20,Institute of Science and Technology Austria;Czech Technical Univeresity in Prague;Institute of Science and Technology Austria,SGD;Data-parallel;Asynchronous;Optimization;Non-convex;Deep Neural Network,-1;-1;-1,-1;1045;-1,m;m,NAN,NAN,y,1
7627,ICLR,2021,Neighbor2Seq: Deep Learning on Massive Graphs by Transforming Neighbors to Sequences,Meng Liu;Shuiwang Ji,~Meng_Liu3;~Shuiwang_Ji1,4;5;5;7,3;4;4;4,Reject,0,14,0.0,yes,9/28/20,Texas A&M;Texas A&M University,Graph representation learning;large-scale;sequence,46;46,195;195,m;m,usa,usa,n,8;10
7628,ICLR,2021,Two steps at a time --- taking GAN training in stride with Tseng's method,Axel B√∂hm;Michael Sedlmayer;Ern√∂ Robert Csetnek;Radu Ioan Bot,~Axel_B√∂hm1;~Michael_Sedlmayer1;~Ern√∂_Robert_Csetnek1;radu.bot@univie.ac.at,6;4;4;4,3;4;5;3,Reject,0,6,0.0,yes,9/28/20,University of Vienna;University of Vienna;University of Vienna;;University of Vienna,,174;174;174;-1;174,164;164;164;-1;164,m;m,europe,at,y,1;5;4;9
7629,ICLR,2021,Multi-Agent Imitation Learning with Copulas,Hongwei Wang;Lantao Yu;Zhangjie Cao;Stefano Ermon,~Hongwei_Wang1;~Lantao_Yu2;~Zhangjie_Cao1;~Stefano_Ermon1,7;5;4,3;3;5,Reject,0,5,0.0,yes,9/28/20,"Stanford University;Computer Science Department, Stanford University;Stanford University;Stanford University",multi-agent imitation learning;dependence modeling;copula,5;5;5;5,2;2;2;2,m;m,usa,usa,n,
7630,ICLR,2021,NASOA: Towards Faster Task-oriented Online Fine-tuning,Hang Xu;Ning Kang;Gengwei Zhang;Xiaodan Liang;Zhenguo Li,~Hang_Xu1;kang.ning2@huawei.com;~Gengwei_Zhang1;~Xiaodan_Liang2;~Zhenguo_Li1,7;6;3;7,3;3;3;4,Reject,0,7,0.0,yes,9/28/20,Huawei Noah‚Äòs Ark Lab;The University of Hong Kong;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Huawei,Fine-tuning;AutoML;NAS,-1;99;-1;-1;-1,-1;39;293;293;-1,m;m,NAN,NAN,n,2
7631,ICLR,2021,Small Input Noise is Enough to Defend Against Query-based Black-box Attacks,Junyoung Byun;Hyojun Go;Changick Kim,~Junyoung_Byun2;gohyojun15@kaist.ac.kr;~Changick_Kim1,4;3;6;7,5;5;3;3,Reject,0,13,0.0,yes,9/28/20,"KAIST, Korea Advanced Institute of Science and Technology;;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology",Gaussian noise;input noise;adversarial defense;black-box attack;adversarial attack;query-based attack,15;-1;-1;-1,-1;-1;-1;96,m;m,NAN,NAN,n,8;4
7632,ICLR,2021,GLUECode: A Benchmark for Source Code Machine Learning Models,Anjan Karmakar;Julian Aron Prenner;Miltiadis Allamanis;Romain Robbes,~Anjan_Karmakar1;julianaron.prenner@unibz.it;~Miltiadis_Allamanis1;rrobbes@unibz.it,4;4;6;4,4;5;5;3,Reject,0,11,0.0,yes,9/28/20,Free University of Bozen-Bolzano;;;Microsoft;;Free University of Bozen-Bolzano,benchmark;source code;code understanding;deep learning,-1;-1;-1;-1;-1;-1,457;-1;-1;-1;-1;457,m;m,NAN,NAN,n,
7633,ICLR,2021,Deep Kernel Processes,Laurence Aitchison;Adam X. Yang;Sebastian W. Ober,~Laurence_Aitchison1;~Adam_X._Yang1;~Sebastian_W._Ober1,7;6;5;6,2;3;3;3,Reject,0,4,0.0,yes,9/28/20,University of Bristol;University of Bristol;University of Cambridge,Gaussian process;doubly stochastic variational inference;variational Inference;Bayesian Inference,110;110;79,91;91;6,m;m,europe,uk,n,11
7634,ICLR,2021,Asymmetric self-play for automatic goal discovery in robotic manipulation,OpenAI OpenAI;Matthias Plappert;Raul Sampedro;Tao Xu;Ilge Akkaya;Vineet Kosaraju;Peter Welinder;Ruben D'Sa;Arthur Petron;Henrique Ponde de Oliveira Pinto;Alex Paino;Hyeonwoo Noh;Lilian Weng;Qiming Yuan;Casey Chu;Wojciech Zaremba,robotics@openai.com;~Matthias_Plappert1;raul@openai.com;tao@openai.com;ilge@openai.com;~Vineet_Kosaraju1;pw@openai.com;ruben@openai.com;arthur@openai.com;hponde@openai.com;atpaino@openai.com;~Hyeonwoo_Noh1;~Lilian_Weng1;qiming@openai.com;~Casey_Chu1;~Wojciech_Zaremba1,7;6;6;7,4;4;3;2,Reject,0,6,0.0,yes,9/28/20,OpenAI;;OpenAI;Universidad Carlos II de Madrid;;;OpenAI;Stanford University;;;;;;;;;;;POSTECH;OpenAI;;;Stanford University;New York University,self-play;asymmetric self-play;automatic curriculum;automatic goal generation;robotic learning;robotic manipulation;reinforcement learning,-1;-1;-1;-1;-1;-1;-1;5;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;128;-1;-1;-1;5;23,-1;-1;-1;-1;-1;-1;-1;2;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;151;-1;-1;-1;2;26,u;m,usa,usa,n,
7635,ICLR,2021,Unifying Graph Convolutional Neural Networks and Label Propagation,Hongwei Wang;Jure Leskovec,~Hongwei_Wang1;~Jure_Leskovec1,6;5;3;5,3;4;4;4,Reject,0,8,0.0,yes,9/28/20,Stanford University;Stanford University,graph convolutional neural networks;label propagation;semi-supervised node classification,5;5,2;2,m;m,usa,usa,y,8;10;5
7636,ICLR,2021,Improving Tail Label Prediction for Extreme Multi-label Learning,Tong Wei;Wei-Wei Tu;Yu-Feng Li,~Tong_Wei1;~Wei-Wei_Tu1;~Yu-Feng_Li1,3;5;4,4;4;4,Reject,0,4,0.0,yes,9/28/20,"Nanjing University, China;4Paradigm Inc.;Nanjing University",classification;multi-label learning;extreme multi-label classification;tail label,52;-1;52,111;-1;111,m;m,asia,kr,n,
7637,ICLR,2021,The Benefit of Distraction: Denoising Remote Vitals Measurements Using Inverse Attention,Ewa Magdalena Nowara;Daniel McDuff;Ashok Veeraraghavan,~Ewa_Magdalena_Nowara2;~Daniel_McDuff1;~Ashok_Veeraraghavan1,4;5;9,5;4;4,Reject,0,3,0.0,yes,9/28/20,Rice University;Microsoft;William Marsh Rice University,convolutional attention networks;denoising;computer vision;camera-based physiology,92;-1;92,124;-1;124,f;m,NAN,NAN,n,8;2
7638,ICLR,2021,Enhancing Visual Representations for Efficient Object Recognition during Online Distillation,Shashanka Venkataramanan;Bruce W McIntosh;Abhijit Mahalanobis,~Shashanka_Venkataramanan1;~Bruce_W_McIntosh1;~Abhijit_Mahalanobis1,4;5;5;4,4;3;4;5,Reject,0,5,0.0,yes,9/28/20,University of Central Florida;University of Central Florida;University of Central Florida,,71;71;71,633;633;633,m;m,usa,usa,n,8
7639,ICLR,2021,Deep Ensemble Kernel Learning,Devanshu Agrawal;Jacob D Hinkle,dagrawa2@vols.utk.edu;~Jacob_D_Hinkle1,3;6;8;5,5;4;4;3,Reject,0,4,0.0,yes,9/28/20,"University of Tennessee, Knoxville;Oak Ridge National Laboratory",kernel-learning;gaussian-process;Bayesian;ensemble,209;-1,-1;-1,m;m,NAN,NAN,y,11
7640,ICLR,2021,Data augmentation as stochastic optimization,Boris Hanin;Yi Sun,~Boris_Hanin1;~Yi_Sun3,7;5;5;6,3;2;4;3,Reject,0,9,0.0,yes,9/28/20,Princeton University;University of Chicago,data augmentation;stochastic optimization;scheduling;convex optimization;overparametrization,29;46,9;10,m;m,usa,usa,y,1
7641,ICLR,2021,Leveraging Class Hierarchies with Metric-Guided Prototype Learning,Vivien Sainte Fare Garnot;Loic Landrieu,~Vivien_Sainte_Fare_Garnot1;~Loic_Landrieu1,4;6;4;4,4;3;3;5,Reject,0,8,0.0,yes,9/28/20,Universit√© Gustave Eiffel;IGN,hierarchical classification;prototypical networks,-1;453,-1;48,m;m,asia,in,n,2
7642,ICLR,2021,Matrix Shuffle-Exchange Networks for Hard 2D Tasks,Emƒ´ls Ozoli≈Ü≈°;Karlis Freivalds;Agris ≈†ostaks,~Emƒ´ls_Ozoli≈Ü≈°1;~Karlis_Freivalds1;agris.sostaks@lumii.lv,8;4;4,3;3;3,Reject,0,5,0.0,yes,9/28/20,University of Latvia;Univerity of Latvia;;University of Latvia,,-1;-1;-1;-1,733;733;-1;733,m;m,NAN,NAN,n,8;10
7643,ICLR,2021,The Surprising Power of Graph Neural Networks with Random Node Initialization,Ralph Abboud;Ismail Ilkan Ceylan;Martin Grohe;Thomas Lukasiewicz,ralph.abboud@cs.ox.ac.uk;~Ismail_Ilkan_Ceylan2;~Martin_Grohe1;~Thomas_Lukasiewicz2,7;5;5;7,3;4;4;3,Reject,0,12,0.0,yes,9/28/20,"University of Oxford;University of Oxford;RWTH Aachen University;Department of Computer Science, University of Oxford",graph representation learning;graph neural networks;expressiveness;universality;random node initialization;Weisfeiler-Lehman heuristic;higher-order graph neural networks,46;46;128;46,1;1;107;1,m;m,NAN,NAN,y,10;1;9
7644,ICLR,2021,Learning Visual Representations for Transfer Learning by Suppressing Texture,Shlok Kumar Mishra;Anshul Shah;Ankan Bansal;Jonghyun Choi;Abhinav Shrivastava;Abhishek Sharma;David Jacobs,~Shlok_Kumar_Mishra1;~Anshul_Shah1;~Ankan_Bansal1;~Jonghyun_Choi1;~Abhinav_Shrivastava2;~Abhishek_Sharma4;~David_Jacobs1,7;5;4,5;3;4,Reject,0,6,0.0,yes,9/28/20,"University of Maryland, College Park;Johns Hopkins University;Amazon;Gwangju Institute of Science and Technology;Department of Computer Science, University of Maryland, College Park;University of Maryland, College Park;University of Maryland - College Park",Suppressing Texture;Transfer learning;Self-Supervised Learning,12;71;-1;-1;-1;12;12,90;12;-1;506;90;90;90,m;m,usa,usa,n,6;2
7645,ICLR,2021,"On Flat Minima, Large Margins and Generalizability",Daniel Lengyel;Nicholas Jennings;Panos Parpas;Nicholas Kantas,~Daniel_Lengyel1;~Nicholas_Jennings1;~Panos_Parpas1;n.kantas@imperial.ac.uk,4;4;4;3,4;3;4;5,Reject,0,3,0.0,yes,9/28/20,Imperial College London;Imperial College London;Imperial College London;;Imperial College London,,53;53;53;-1;53,11;11;11;-1;11,m;m,europe,uk,y,
7646,ICLR,2021,Learning Graph Normalization for Graph Neural Networks,Yihao Chen;Xin Tang;Xianbiao Qi;Chun-Guang Li;Rong Xiao,~Yihao_Chen1;tangxint@gmail.com;~Xianbiao_Qi2;~Chun-Guang_Li3;~Rong_Xiao3,3;4;4;4,4;5;5;4,Reject,0,0,0.0,yes,9/28/20,"Pingan P&C insurance;Nanyang Technological University;ping an property & casualty insurance;Beijing University of Posts and Telecommunications, P.R. China;Pingan P&C insurance",Graph Neural Network;Normalization;Graph Normalization,-1;44;-1;-1;-1,-1;47;-1;-1;-1,m;m,NAN,NAN,n,10
7647,ICLR,2021,FMix: Enhancing Mixed Sample Data Augmentation,Ethan Harris;Antonia Marcu;Matthew Painter;Mahesan Niranjan;Adam Prugel-Bennett;Jonathon Hare,~Ethan_Harris1;am1g15@ecs.soton.ac.uk;mp2u16@ecs.soton.ac.uk;~Mahesan_Niranjan1;~Adam_Prugel-Bennett1;~Jonathon_Hare1,6;4;6;5,4;5;3;4,Reject,0,6,0.0,yes,9/28/20,University of Southampton;University of Southampton;;;University of Southampton;University of Southampton;University of Southampton,,209;209;-1;-1;209;209;209,127;127;-1;-1;127;127;127,m;m,europe,uk,n,8
7648,ICLR,2021,A Theory of Self-Supervised Framework for Few-Shot Learning,Zhong Cao;Jiang Lu;Jian Liang;Changshui Zhang,~Zhong_Cao1;~Jiang_Lu1;~Jian_Liang3;~Changshui_Zhang2,2;2;4;4;3,3;4;3;4;3,Reject,0,1,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Alibaba Group;Tsinghua University",,4;4;-1;4,20;20;-1;20,m;m,asia,cn,y,6;1
7649,ICLR,2021,Empirical Frequentist Coverage of Deep Learning Uncertainty Quantification Procedures,Benjamin Kompa;Jasper Snoek;Andrew Beam,~Benjamin_Kompa1;~Jasper_Snoek1;~Andrew_Beam1,3;4;4;4,5;4;4;3,Reject,0,4,0.0,yes,9/28/20,Harvard University;Google;Harvard University,uncertainty quantification;coverage;dataset shift,53;-1;53,3;-1;3,m;m,usa,usa,n,
7650,ICLR,2021,FSV: Learning to Factorize Soft Value Function for Cooperative Multi-Agent Reinforcement Learning,Yueheng Li;Tianhao Zhang;Chen Wang;Jinan Sun;Shikun Zhang;Guangming Xie,liyueheng@pku.edu.cn;~Tianhao_Zhang5;~Chen_Wang11;~Jinan_Sun1;~Shikun_Zhang2;~Guangming_Xie1,3;4;2;2;3,4;3;5;4;5,Reject,0,5,0.0,yes,9/28/20,Peking University;;Peking University;Peking University;Peking University;Peking University;Peking University  Tsinghua University,cooperative MARL;value function factorization;stochastic policy;continuous tasks,14;-1;14;14;14;14;4,23;-1;23;23;23;23;20,m;m,NAN,NAN,y,1
7651,ICLR,2021,Collaborative Filtering with Smooth Reconstruction of the Preference Function,Ali Shirali;Reza Kazemi;Arash Amini,~Ali_Shirali1;~Reza_Kazemi1;~Arash_Amini3,3;4;3;4,5;3;4;4,Reject,0,0,0.0,yes,9/28/20,Sharif University of Technology;Sharif University of Technology;Sharif University of Technology,collaborative filtering;recommender system;sampling theory,327;327;327,475;475;475,m;m,asia,ir,n,
7652,ICLR,2021,A Real-time Contribution Measurement Method for Participants in Federated Learning,Bingjie Yan;Yize Zhou;Boyi Liu;Jun Wang;Yuhan Zhang;Li Liu;Xiaolan Nie;Zhiwei Fan;Zhixuan Liang,~Bingjie_Yan1;yizezhou20001203@163.com;by.liu@ieee.org;20180581310080@hainanu.edu.cn;zhangyh01230@163.com;hainan_lily2001@163.com;niexiaolan25@163.com;hnufzw@gmail.com;~Zhixuan_Liang1,3;4;4;3,5;3;4;4,Reject,0,4,0.0,yes,9/28/20,"School of Computer Science and Cyberspace Security, Hainan University;Google;;;;;;;;;;;;;The Hong Kong Polytechnic University",Federated Learning;Contribution Evaluation;Multi-party Participation,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;128,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;129,m;m,asia,hk,n,1;7
7653,ICLR,2021,Learned Threshold Pruning,Kambiz Azarian;Yash Sanjay Bhalgat;Jinwon Lee;Tijmen Blankevoort,~Kambiz_Azarian1;~Yash_Sanjay_Bhalgat1;~Jinwon_Lee1;~Tijmen_Blankevoort1,6;6;4;4,4;3;5;5,Reject,0,4,0.0,yes,9/28/20,"QualComm;Qualcomm Inc, QualComm;Amazon;Qualcomm Inc, QualComm",Efficiency;Model Compression;Unstructured Pruning;Differentiable Pruning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
7654,ICLR,2021,Episodic Memory for Learning Subjective-Timescale Models,Alexey Zakharov;Matthew Crosby;Zafeirios Fountas,~Alexey_Zakharov1;m.crosby@imperial.ac.uk;~Zafeirios_Fountas1,4;4;5,4;3;3,Reject,0,7,0.0,yes,9/28/20,Huawei Technologies Ltd.;Imperial College London;Huawei Technologies Ltd.,Episodic Memory;Time Perception;Active Inference;Model-based Reinforcement Learning,-1;53;-1,-1;11;-1,m;m,NAN,NAN,n,
7655,ICLR,2021,PERIL: Probabilistic Embeddings for hybrid Meta-Reinforcement and Imitation Learning,Alvaro Prat;Edward Johns,~Alvaro_Prat1;~Edward_Johns1,4;3;4;4,4;5;4;3,Reject,0,4,0.0,yes,9/28/20,Imperial College London;Imperial College London,Meta-learning;Imitation Learning;Reinforcement Learning,53;53,11;11,m;m,europe,uk,n,
7656,ICLR,2021,Identifying the Sources of Uncertainty in Object Classification,Luis Armando P√©rez Rey;Berk ƒ∞≈üler;Mike Holenderski;Dmitri Jarnikov,~Luis_Armando_P√©rez_Rey1;berk.isler94@gmail.com;~Mike_Holenderski1;d.s.jarnikov@tue.nl,3;3;3,4;3;5,Reject,0,0,0.0,yes,9/28/20,Eindhoven University of Technology;;;Eindhoven University of Technology;;Eindhoven University of Technology,Classification;Interpretability;Disentangled Representations;Uncertainty Estimation,-1;-1;-1;-1;-1;-1,186;-1;-1;186;-1;186,m;m,NAN,NAN,n,
7657,ICLR,2021,QRGAN: Quantile Regression Generative Adversarial Networks,Sunyeop Lee;Tuan Anh Nguyen;Dugki Min,sunyeop97@gmail.com;~Tuan_Anh_Nguyen3;dkmin@konkuk.ac.kr,2;4;5;3;2,5;4;4;4;4,Reject,0,0,0.0,yes,9/28/20,Konkuk University;;Konkuk University;;Konkuk University,Quantile Regression;Generative Adversarial Networks (GANs);Frechet Inception Distance (FID);Generative Neural Networks,-1;-1;-1;-1;-1,608;-1;608;-1;608,m;m,NAN,NAN,n,5;4
7658,ICLR,2021,EpidemiOptim: A Toolbox for the Optimization of Control Policies in Epidemiological Models,C√©dric Colas;Boris Hejblum;S√©bastien Rouillon;Rodolphe Thiebaut;Pierre-Yves Oudeyer;Cl√©ment Moulin-Frier;M√©lanie Prague,~C√©dric_Colas1;boris.hejblum@u-bordeaux.fr;sebastien.rouillon@u-bordeaux.fr;rodolphe.thiebaut@inria.fr;~Pierre-Yves_Oudeyer1;~Cl√©ment_Moulin-Frier2;melanie.prague@u-bordeaux.fr,3;4;3,3;4;4,Reject,0,2,0.0,yes,9/28/20,INRIA;University of Bordeaux;;;;;Inria;Inria;;University of Bordeaux,epidemiology;covid19;reinforcement learning;evolutionary algorithms;multi-objective optimization;decision-making;toolbox,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;427;-1;-1;-1;-1;-1;-1;-1;427,m;f,NAN,NAN,n,
7659,ICLR,2021,Prediction of Enzyme Specificity using Protein Graph Convolutional Neural Networks,Changpeng Lu;Samuel Z Stentz;Joseph H Lubin;Sijian Wang;Sagar D Khare,~Changpeng_Lu1;samuelstentz@gatech.edu;jhl133@scarletmail.rutgers.edu;sijian.wang@stat.rutgers.edu;~Sagar_D_Khare1,3;4;4;3,5;4;3;4,Reject,0,0,0.0,yes,9/28/20,Rutgers University;;;Rutgers University;;;Rutgers University,graph convolutional neural networks;protease specificity;proteins;Rosetta energy function,29;-1;-1;29;-1;-1;29,-1;-1;-1;-1;-1;-1;-1,m;m,usa,usa,n,10
7660,ICLR,2021,Deep Ensembles for Low-Data Transfer Learning,Basil Mustafa;Carlos Riquelme Ruiz;Joan Puigcerver;Andr√© Susano Pinto;Daniel Keysers;Neil Houlsby,~Basil_Mustafa1;~Carlos_Riquelme_Ruiz1;~Joan_Puigcerver1;~Andr√©_Susano_Pinto1;~Daniel_Keysers2;~Neil_Houlsby1,5;3;3;4,4;3;4;5,Reject,0,4,0.0,yes,9/28/20,"Google;Google;Google;Research, Google;Google;Google",transfer learning;representation learning;computer vision;ensembles,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6
7661,ICLR,2021,Hindsight Curriculum Generation Based Multi-Goal Experience Replay,Xiaoyun Feng,~Xiaoyun_Feng1,4;4;3;3,4;4;4;4,Reject,0,0,0.0,yes,9/28/20,University of Science and Technology of China,reinforcement learning;multi-goal task;experience replay,-1,87,f,NAN,NAN,n,
7662,ICLR,2021,Deep Ecological Inference,Nic Fishman;Colin McAuliffe,~Nic_Fishman1;colin@dataforprogress.org,3;7;4;3,4;3;3;3,Reject,0,0,0.0,yes,9/28/20,Stanford University;Data for Progress,ecological inference;representation learning;multi-task learning;bayesian deep learning,5;-1,2;-1,m;m,NAN,NAN,n,11
7663,ICLR,2021,Succinct Explanations with Cascading Decision Trees,JIALU ZHANG;Mark Santolucito;Ruzica Piskac,~JIALU_ZHANG1;msantolu@barnard.edu;~Ruzica_Piskac1,4;3;5;3,5;4;3;4,Reject,0,0,0.0,yes,9/28/20,Yale University;;;Yale University,Decision Trees;Explainability;Interpretability,71;-1;-1;71,8;-1;-1;8,m;f,europe,fi,n,
7664,ICLR,2021,Pretrain-to-Finetune Adversarial Training via Sample-wise Randomized Smoothing,Lei Wang;Runtian Zhai;Di He;Liwei Wang;Li Jian,~Lei_Wang22;~Runtian_Zhai1;~Di_He1;~Liwei_Wang1;~Li_Jian1,4;4;6;5,4;4;4;2,Reject,0,4,0.0,yes,9/28/20,"Tsinghua University;Carnegie Mellon University;Microsoft;Peking University;University of Maryland, College Park",Adversarial Robustness;Provable Adversarial Defense;Sample-wise Randomized Smoothing.,4;1;-1;14;12,20;28;-1;23;90,f;m,usa,usa,n,4
7665,ICLR,2021,Addressing Extrapolation Error in Deep Offline Reinforcement Learning,Caglar Gulcehre;Sergio G√≥mez Colmenarejo;ziyu wang;Jakub Sygnowski;Thomas Paine;Konrad Zolna;Yutian Chen;Matthew Hoffman;Razvan Pascanu;Nando de Freitas,~Caglar_Gulcehre1;~Sergio_G√≥mez_Colmenarejo1;~ziyu_wang1;~Jakub_Sygnowski1;~Thomas_Paine1;~Konrad_Zolna1;~Yutian_Chen1;~Matthew_Hoffman1;~Razvan_Pascanu1;~Nando_de_Freitas1,3;4;4,4;4;4,Reject,0,8,0.0,yes,9/28/20,Deepmind;DeepMind;Google;Google;Google/DeepMind;Jagiellonian University;DeepMind;Google;Google DeepMind;DeepMind,Addressing Extrapolation Error in Deep Offline Reinforcement Learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;596;-1;-1;-1;-1,m;m,NAN,NAN,n,
7666,ICLR,2021,CANVASEMB: Learning Layout Representation with Large-scale Pre-training for Graphic Design,Yuxi Xie;Danqing Huang;Jinpeng Wang;Chin-Yew Lin,~Yuxi_Xie1;~Danqing_Huang1;wjp.pku@gmail.com;~Chin-Yew_Lin1,4;5;5,3;3;4,Reject,0,3,0.0,yes,9/28/20,"Peking University;Microsoft;Peking University, Tsinghua University;Microsoft",Layout Representation;Pre-training,14;-1;4;-1,23;-1;20;-1,f;m,NAN,NAN,n,3;10
7667,ICLR,2021,$\alpha$VIL: Learning to Leverage Auxiliary Tasks for Multitask Learning,Rafael Kourdis;Gabriel Gordon-Hall;Philip John Gorinski,rafael.kourdis@gmail.com;ggordonhall@gmail.com;~Philip_John_Gorinski1,3;4;4,4;4;4,Reject,0,4,0.0,yes,9/28/20,National Technical University of Athens;Huawei Technologies Ltd.;Huawei Noah's Ark Lab,multitask learning;meta-optimization;deep learning,327;-1;-1,803;-1;-1,m;m,NAN,NAN,n,
7668,ICLR,2021,Mutual Calibration between Explicit and Implicit Deep Generative Models,Qitian Wu;Rui Gao;Hongyuan Zha,~Qitian_Wu1;~Rui_Gao3;~Hongyuan_Zha1,5;3;6;5,3;5;4;3,Reject,0,0,0.0,yes,9/28/20,"Shanghai Jiao Tong University;University of Texas, Austin;The Chinese University of Hong Kong, Shenzhen",deep generative models;generative adversarial networks;density estimation,29;-1;46,100;-1;39,m;m,NAN,NAN,y,5
7669,ICLR,2021,Legendre Deep Neural Network (LDNN) and its application for approximation of nonlinear Volterra‚ÄìFredholm‚ÄìHammerstein integral equations,Kourosh Parand;Zeinab Hajimohammadi;Ali Ghodsi,kparand@sbu.ac.ir;~Zeinab_Hajimohammadi1;~Ali_Ghodsi1,4;3;5,4;5;2,Reject,0,0,0.0,yes,9/28/20,Shahid Beheshti University;;Shahid Beheshti University;University of Waterloo,Deep neural network;Volterra‚ÄìFredholm‚ÄìHammerstein integral equations;Legendre orthogonal polynomials;Gaussian quadrature method;Collocation method,-1;-1;-1;34,756;-1;756;232,m;m,canada,ca,n,
7670,ICLR,2021,Regression from Upper One-side Labeled Data,Takayuki Katsuki,~Takayuki_Katsuki2,5;5;4,5;4;4,Reject,0,7,0.0,yes,9/28/20,International Business Machines,regression;weakly-supervised learning;healthcare,-1,-1,m,NAN,NAN,n,
7671,ICLR,2021,Deep Learning Is Composite Kernel Learning,CHANDRA SHEKAR LAKSHMINARAYANAN;Amit Vikram Singh,~CHANDRA_SHEKAR_LAKSHMINARAYANAN1;~Amit_Vikram_Singh1,6;8;4;6,2;2;4;1,Reject,0,4,0.0,yes,9/28/20,"Indian Institute of Technology;Indian Institute of Technology, Palakkad",deep learning;kernel methods,-1;-1,355;-1,m;m,NAN,NAN,y,
7672,ICLR,2021,Using Deep Reinforcement Learning to Train and Evaluate Instructional Sequencing Policies for an Intelligent Tutoring System,Jithendaraa Subramanian;David Mostow,~Jithendaraa_Subramanian1;~David_Mostow1,2;4;2,3;4;5,Reject,0,3,0.0,yes,9/28/20,"National Institute of Technology, Trichy;Carnegie-Mellon University",Deep Reinforcement Learning;Intelligent Tutoring Systems;Adaptive policy;Instructional Sequencing,-1;1,-1;28,m;m,usa,usa,n,
7673,ICLR,2021,Median DC for Sign Recovery: Privacy can be Achieved by Deterministic Algorithms,Jiyuan Tu;Weidong Liu;Xiaojun Mao,~Jiyuan_Tu1;~Weidong_Liu2;~Xiaojun_Mao1,4;4;7;4,5;4;3;5,Reject,0,0,0.0,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Fudan University,Median-of-means;divide-and-conquer;privacy;sign recovery,29;29;71,100;100;70,m;m,asia,cn,y,
7674,ICLR,2021,Pseudo Label-Guided Multi Task Learning for Scene Understanding,Sunkyung Kim;Hyesong Choi;Dongbo Min,~Sunkyung_Kim1;~Hyesong_Choi1;~Dongbo_Min3,4;4;3,5;4;5,Reject,0,3,0.0,yes,9/28/20,Ewha Womans University;Ewha Womans University;Ewha Womans University,Multi-task learning;monocular depth estimation;semantic segmentation;pseudo label;cross-view consistency,-1;-1;-1,677;677;677,f;m,NAN,NAN,n,2
7675,ICLR,2021,"Stochastic Proximal Point Algorithm for Large-scale Nonconvex Optimization: Convergence, Implementation, and Application to Neural Networks",Aysegul Bumin;Kejun Huang,aysegul.bumin@ufl.edu;~Kejun_Huang1,4;3;3;4,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,University of Florida;University of Florida,,150;150,152;152,f;m,usa,usa,y,9
7676,ICLR,2021,A Chaos Theory Approach to Understand Neural Network Optimization,Michele Sasdelli;Thalaiyasingam Ajanthan;Tat-Jun Chin;Gustavo Carneiro,~Michele_Sasdelli1;~Thalaiyasingam_Ajanthan1;~Tat-Jun_Chin2;~Gustavo_Carneiro1,4;5;4,3;3;5,Reject,0,3,0.0,yes,9/28/20,The University of Adelaide;Australian National University;The University of Adelaide;The University of Adelaide,learning theory;stochastic gradient descent;deep learning;neural networks;dynamical systems;chaos theory;Lyapunov exponents,110;99;110;110,118;59;118;118,m;m,NAN,NAN,n,1
7677,ICLR,2021,Log representation as an interface for log processing applications,Mohammad Amin Sadeghi;Shameem Parambath;Ji Lucas;Youssef Meguebli;Maguette Toure;Fawaz Al Qahtani;Ting Yu;Sanjay Chawla,~Mohammad_Amin_Sadeghi3;spparambath@hbku.edu.qa;jlucas@hbku.edu.qa;youssef.meguebli@nokia.com;maguette.toure@nokia.com;fawalqahtani@qf.org.qa;tyu@hbku.edu.qa;~Sanjay_Chawla2,3;5;4;7,4;3;3;4,Reject,0,4,0.0,yes,9/28/20,Qatar Computing Research Institute;HBKU;;;;;--;IDKT-RDI QF;;;Qatar Computing Research Institute,Vector embedding;Logs;Search;Causal Analysis;Anomaly Detection,209;-1;-1;-1;-1;-1;-1;-1;-1;-1;209,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,asia,qa,n,8;3
7678,ICLR,2021,Image Modeling with Deep Convolutional Gaussian Mixture Models,Alexander Gepperth;Benedikt Pf√ºlb,~Alexander_Gepperth1;~Benedikt_Pf√ºlb1,3;2;4;3,4;5;4;4,Reject,0,0,0.0,yes,9/28/20,HAW Fulda;University of Applied Sciences Fulda,Gaussian Mixture Model;Deep Learning;Unsupervised Representation Learning;Sampling,-1;-1,-1;-1,m;m,NAN,NAN,n,
7679,ICLR,2021,Towards Finding Longer Proofs,Zsolt Zombori;Adri√°n Csisz√°rik;Henryk Michalewski;Cezary Kaliszyk;Josef Urban,~Zsolt_Zombori1;~Adri√°n_Csisz√°rik1;~Henryk_Michalewski1;~Cezary_Kaliszyk1;~Josef_Urban1,4;8;6,3;3;2,Reject,0,4,0.0,yes,9/28/20,"Alfr√©d R√©nyi Institute of Mathematics;Alfr√©d R√©nyi Institute of Mathematics;Google;University of Innsbruck;CIIRC, Czech Technical University",automated reasoning;reinforcement learning;reasoning by analogy,-1;-1;-1;-1;174,-1;-1;-1;398;-1,m;m,NAN,NAN,n,1
7680,ICLR,2021,Deep Gated Canonical Correlation Analysis,Ofir Lindenbaum;Moshe Salhov;Amir Averbuch;Yuval Kluger,~Ofir_Lindenbaum1;moshebar-s@013.net;~Amir_Averbuch1;~Yuval_Kluger1,4;4;5;5,4;3;3;4,Reject,0,0,0.0,yes,9/28/20,Yale University;;;Tel Aviv University;Yale University,,71;-1;-1;34;71,8;-1;-1;190;8,m;m,europe,fi,y,
7681,ICLR,2021,"More Side Information, Better Pruning: Shared-Label Classification as a Case Study",Omer Leibovitch;Nir Ailon,~Omer_Leibovitch1;~Nir_Ailon1,4;6;2;4;3,3;3;4;4;4,Reject,0,0,0.0,yes,9/28/20,"Technion, Technion;Technion, Technion",Pruning;Compression;CNN;LSTM;Image classification,29;29,-1;-1,m;m,NAN,NAN,n,
7682,ICLR,2021,AUL is a better optimization metric  in PU learning,Shangchuan Huang;Songtao Wang;Dan Li;Liwei Jiang,~Shangchuan_Huang1;~Songtao_Wang1;tolidan@tsinghua.edu.cn;lavender_jlw@126.com,3;5;5,3;3;4,Reject,0,0,0.0,yes,9/28/20,Tsinghua University;Tsinghua University  Tsinghua University;;;;Tsinghua University,,4;4;-1;-1;-1;4,20;20;-1;-1;-1;20,u;f,asia,cn,y,1
7683,ICLR,2021,ChemistryQA: A Complex Question Answering Dataset from Chemistry,Zhuoyu Wei;Wei Ji;Xiubo Geng;Yining Chen;Baihua Chen;Tao Qin;Daxin Jiang,~Zhuoyu_Wei1;jiwe@microsoft.com;xiubo.geng@microsoft.com;yining.chen@microsoft.com;baihua.chen@microsoft.com;~Tao_Qin1;djiang@microsoft.com,4;5;3;5,4;3;4;4,Reject,0,0,0.0,yes,9/28/20,Microsoft;;;;;;;;;Tsinghua University;Microsoft,,-1;-1;-1;-1;-1;-1;-1;-1;-1;4;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;20;-1,m;m,NAN,NAN,n,3;10
7684,ICLR,2021,DQSGD: DYNAMIC QUANTIZED STOCHASTIC GRADIENT DESCENT FOR COMMUNICATION-EFFICIENT DISTRIBUTED LEARNING,Guangfeng Yan;Shao-Lun Huang;Tian Lan;Linqi Song,~Guangfeng_Yan1;~Shao-Lun_Huang1;~Tian_Lan4;~Linqi_Song1,2;4;2;4,4;4;5;5,Reject,0,4,0.0,yes,9/28/20,"City University of Hong Kong;Tsinghua University, Tsinghua University;George Washington University;City University of Hong Kong",Distributed Learning;Communication;Gradient Quantization,128;4;209;128,126;20;186;126,m;m,asia,hk,y,2;3
7685,ICLR,2021,Sparse matrix products for neural network compression,Luc Giffon;hachem kadri;Stephane Ayache;Ronan Sicre;thierry artieres,~Luc_Giffon1;~hachem_kadri2;~Stephane_Ayache1;~Ronan_Sicre3;~thierry_artieres1,4;4;5;7,5;3;3;4,Reject,0,6,0.0,yes,9/28/20,Aix Marseille Universit√©;Aix Marseille Univ;Aix Marseille Univ;LIS / Ecole Centrale Marseille;Aix Marseille University,Compression;sparsity,-1;-1;-1;-1;-1,358;-1;-1;-1;358,m;m,NAN,NAN,n,
7686,ICLR,2021,Factored Action Spaces in Deep Reinforcement Learning,Thomas PIERROT;Valentin Mac√©;Jean-Baptiste Sevestre;Louis Monier;Alexandre Laterre;Nicolas Perrin;Karim Beguir;Olivier Sigaud,~Thomas_PIERROT1;~Valentin_Mac√©1;jb.sevestre@instadeep.com;l.monier@instadeep.com;~Alexandre_Laterre1;~Nicolas_Perrin1;kb@instadeep.com;~Olivier_Sigaud1,5;3;5,4;5;3,Reject,0,4,0.0,yes,9/28/20,"Universit√© Pierre et Marie Curie - Paris 6, Computer Science Lab  - Pierre and Marie Curie University, Paris, France;InstaDeep;;;;;InstaDeep;ISIR, UMR 7222;NYU, New York University;Sorbonne Universit√©",Deep Reinforcement Learning;Large action spaces;Parameterized action spaces;Multi-Agent;Continuous Control,-1;-1;-1;-1;-1;-1;-1;-1;23;-1,-1;-1;-1;-1;-1;-1;-1;-1;26;87,m;m,NAN,NAN,n,
7687,ICLR,2021,Semi-supervised counterfactual explanations,SURYA SHRAVAN KUMAR SAJJA;Sumanta Mukherjee;Satyam Dwivedi;Vikas C. Raykar,~SURYA_SHRAVAN_KUMAR_SAJJA1;~Sumanta_Mukherjee1;satwive@in.ibm.com;~Vikas_C._Raykar1,4;4;5;6,5;5;4;3,Reject,0,0,0.0,yes,9/28/20,University of Notre Dame;Indian Institute of Science;;;IBM Corporation,Semi-supervised feature representation;counterfactual explanations,128;-1;-1;-1;-1,170;323;-1;-1;-1,m;m,NAN,NAN,n,
7688,ICLR,2021,On the Importance of Distraction-Robust Representations for Robot Learning,Andy Wang;Antoine Cully,~Andy_Wang1;~Antoine_Cully1,4;3;3;4,4;3;4;4,Reject,0,1,0.0,yes,9/28/20,Imperial College London;Imperial College London,Unsupervised Representation Learning;Robot Control;Quality-Diversity,53;53,11;11,m;m,europe,uk,n,1
7689,ICLR,2021,Deep Quotient Manifold Modeling,Jiseob Kim;Seungjae Jung;Hyundo Lee;Byoung-Tak Zhang,~Jiseob_Kim1;sjjung@bi.snu.ac.kr;hdlee@bi.snu.ac.kr;~Byoung-Tak_Zhang1,4;6;5;8,5;5;2;4,Reject,0,0,0.0,yes,9/28/20,Kakao Brain;;;Seoul National University;Seoul National University,deep generative models;manifold learning,-1;-1;-1;37;37,-1;-1;-1;60;60,m;m,asia,kr,y,1;5
7690,ICLR,2021,AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering,Xingyu Xie;Minjuan Zhu;Yan Wang;Lei Zhang,~Xingyu_Xie2;~Minjuan_Zhu1;~Yan_Wang13;~Lei_Zhang25,5;3;5,3;3;3,Reject,0,0,0.0,yes,9/28/20,Sichuan University;Sichuan University;Sichuan University;Sichuan University,Unsupervised Representation Learning;Neighbor Clustering;Variational Autoencoder;Unsupervised Classification,-1;-1;-1;-1,672;672;672;672,m;m,NAN,NAN,n,5
7691,ICLR,2021,Universal Value Density Estimation for Imitation Learning and Goal-Conditioned Reinforcement Learning,Yannick Schroecker;Charles Lee Isbell,~Yannick_Schroecker1;~Charles_Lee_Isbell1,5;5;6;4,4;3;4;4,Reject,0,7,0.0,yes,9/28/20,DeepMind;;Georgia Institute of Technology,Imitation Learning;Reinforcement Learning;Universal Value Functions,-1;-1;12,-1;-1;38,m;m,usa,usa,n,
7692,ICLR,2021,A Gradient-based Kernel Approach for Efficient Network Architecture Search,Jingjing Xu;Liang Zhao;Junyang Lin;Xu Sun;Hongxia Yang,~Jingjing_Xu1;~Liang_Zhao8;junyang.ljy@alibaba-inc.com;~Xu_Sun1;~Hongxia_Yang2,4;4;3;4,5;4;4;5,Reject,0,0,0.0,yes,9/28/20,Peking University;;Peking University;Alibaba Group;Peking University;Duke University,NAS,14;-1;14;-1;14;46,23;-1;23;-1;23;20,f;f,europe,se,n,
7693,ICLR,2021,A straightforward line search approach on the expected empirical loss for stochastic deep learning problems,Maximus Mutschler;Andreas Zell,~Maximus_Mutschler1;~Andreas_Zell1,4;4;4;3,4;4;4;5,Reject,0,11,0.0,yes,9/28/20,University of Tuebingen;;University of T√ºbingen;Eberhard-Karls-Universit√§t T√ºbingen,Empirical Optimization;Expected Loss;Line Search,128;-1;128;-1,78;-1;78;-1,m;m,NAN,NAN,n,
7694,ICLR,2021,What to Prune and What Not to Prune at Initialization,Maham Haroon,~Maham_Haroon1,2;3;4;1,5;5;4;4,Reject,0,0,0.0,yes,9/28/20,"Department of Computer Science, University of Massachusetts, Amherst",Network Sparsity;Machine Learning;Initialization Pruning,-1,210,f,NAN,NAN,n,
7695,ICLR,2021,SkillBERT: ‚ÄúSkilling‚Äù the BERT to classify skills!,Amber Nigam;Shikha Tyagi;Kuldeep Tyagi;Arpan Saxena,ambernigam@hsph.harvard.edu;shikha@peoplestrong.com;kuldeep@peoplestrong.com;arpansaxena17may@gmail.com,6;4;4,4;5;5,Reject,0,3,0.0,yes,9/28/20,Harvard University;;;;;;Tata Consultancy Services,,53;-1;-1;-1;-1;-1;-1,3;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7696,ICLR,2021,Machine Learning Algorithms for Data Labeling: An Empirical Evaluation,Teodor Anders Fredriksson;David Issa Mattos;Jan Bosch;Helena Holmstr√∂m Olsson,~Teodor_Anders_Fredriksson1;davidis@chalmers.se;jan.bosch@chalmers.se;helena.holmstrom.olsson@mau.se,3;4;4;3,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,Chalmers University;;;;;;MalmÀÜ University,Data Labeling;Empirical Evaluation;Active Machine Learning;Semi-Supervised Learning,-1;-1;-1;-1;-1;-1;-1,235;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,11
7697,ICLR,2021,Monotonic neural network: combining deep learning with domain knowledge for chiller plants energy optimization,Fanhe Ma;Faen Zhang;Shenglan Ben;Shuxin Qin;pengcheng Zhou;Changsheng Zhou;Fengyi Xu,~Fanhe_Ma1;zhangfaen@ainnovation.com;~Shenglan_Ben2;~Shuxin_Qin1;zhoupengcheng@ainnovation.com;zhouchangsheng@ainnovation.com;xufengyi@ainnovation.com,3;2;3;4,4;4;5;4,Reject,0,0,0.0,yes,9/28/20,AInnovation;;;AInnocation;Institute of automation  Chinese academy of science  Chinese Academy of Sciences;;;;;Ainnovation,,-1;-1;-1;-1;34;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,u;f,NAN,NAN,n,3
7698,ICLR,2021,Solving NP-Hard Problems on Graphs with Extended AlphaGo Zero,Kenshin Abe;Zijian Xu;Issei Sato;Masashi Sugiyama,~Kenshin_Abe1;~Zijian_Xu1;~Issei_Sato1;~Masashi_Sugiyama1,5;4;4,4;4;4,Reject,0,3,0.0,yes,9/28/20,The University of Tokyo;The University of Tokyo;the University of Tokyo;RIKEN Center for Advanced Intelligence Project,Graph neural network;Combinatorial optimization;Reinforcement learning,71;71;71;-1,36;36;36;-1,m;m,NAN,NAN,n,1;10
7699,ICLR,2021,Untangle: Critiquing Disentangled Recommendations,Preksha Nema;Alexandros Karatzoglou;Filip Radlinski,~Preksha_Nema1;~Alexandros_Karatzoglou1;~Filip_Radlinski1,5;4;4;5,5;3;4;4,Reject,0,0,0.0,yes,9/28/20,Indian Institute of Technology Madras;Google;Department of Computer Science,Disentangling;Recommender Systems;VAE;Critiquing;Explainability,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,5
7700,ICLR,2021,ZCal: Machine learning methods for calibrating radio interferometric data ,Simphiwe Zitha;Arun aniyan;Oleg Smirnov;Risuna Nkolele,~Simphiwe_Zitha1;aka.bhagya@gmail.com;osmirnov@gmail.com;risunawisdom@gmail.com,4;2;3,5;5;4,Reject,0,0,0.0,yes,9/28/20,University of the Witwatersrand;;;;;;IBM Researcher,Radio astronomy;Calibration;Radio interferometry;ska;kat-7;MeerKat,-1;-1;-1;-1;-1;-1;-1,206;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,
7701,ICLR,2021,Wat zei je? Detecting Out-of-Distribution Translations with Variational Transformers,Tim Z. Xiao;Aidan Gomez;Yarin Gal,~Tim_Z._Xiao1;~Aidan_Gomez1;~Yarin_Gal1,3;5;5;6,4;4;4;4,Reject,0,10,0.0,yes,9/28/20,University College London;University of Oxford;University of Oxford,Bayesian Deep Learning;Uncertainty;NMT;Transformer,53;46;46,-1;1;1,m;m,europe,uk,n,8;11;3
7702,ICLR,2021,Differentiable Approximations for Multi-resource Spatial Coverage Problems,Nitin Kamra;Yan Liu,~Nitin_Kamra1;~Yan_Liu1,5;6;4;4,2;1;4;4,Reject,0,7,0.0,yes,9/28/20,University of Southern California;University of Southern California,Multi-agent coverage;Multi-resource coverage;Areal coverage;Differentiable approximations,37;37,53;53,m;f,usa,usa,n,1
7703,ICLR,2021,Probabilistic Meta-Learning for Bayesian Optimization,Felix Berkenkamp;Anna Eivazi;Lukas Grossberger;Kathrin Skubch;Jonathan Spitz;Christian Daniel;Stefan Falkner,~Felix_Berkenkamp1;anna.eivazi@de.bosch.com;~Lukas_Grossberger1;kathrin.skubch@de.bosch.com;spitz.jonathan@gmail.com;~Christian_Daniel1;~Stefan_Falkner1,5;4;4;5,5;4;4;4,Reject,0,7,0.0,yes,9/28/20,"Bosch;Bosch;Bosch Center for AI, Robert Bosch GmbH;Bosch Center for Artificial Intelligence;BCAI;Bosch Center for Artificial Intelligence;Robert Bosch GmbH",meta-learning;bayesian optimization;probabilistic modelling,-1;-1;-1;-1;209;-1;-1,285;285;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;11;5
7704,ICLR,2021,Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate Schedule,Nikhil Iyer;V Thejas;Nipun Kwatra;Ramachandran Ramjee;Muthian Sivathanu,~Nikhil_Iyer1;thejasvenkatesh97@gmail.com;~Nipun_Kwatra1;~Ramachandran_Ramjee1;~Muthian_Sivathanu1,3;4;5;6,5;2;3;3,Reject,0,11,0.0,yes,9/28/20,Microsoft Research India;BITS Pilani;Microsoft;Microsoft;Microsoft Research,deep learning;learning rate;generalization,-1;453;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3;1
7705,ICLR,2021,Local Clustering Graph Neural Networks,Jiezhong Qiu;Yukuo Cen;Qibin Chen;Chang Zhou;Jingren Zhou;Hongxia Yang;Jie Tang,~Jiezhong_Qiu1;~Yukuo_Cen1;~Qibin_Chen1;~Chang_Zhou2;~Jingren_Zhou1;~Hongxia_Yang2;~Jie_Tang1,4;5;6;5,5;4;3;4,Reject,0,4,0.0,yes,9/28/20,"Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Peking University;;Duke University;Tsinghua University, Tsinghua University",Graph Neural Networks;Local Clustering;Random Walk on Graphs;Open Graph Benchmark,4;4;4;14;-1;46;4,20;20;20;23;-1;20;20,m;m,NAN,NAN,y,10
7706,ICLR,2021,Accurate and fast detection of copy number variations from short-read whole-genome sequencing with deep convolutional neural network,Jiajin Li;Stephen Hwang;Luke Zhang;Jae Hoon Sul,~Jiajin_Li3;sjhwang@ucsc.edu;zhanglucasjifeng@gmail.com;~Jae_Hoon_Sul1,3;2;2;5,4;4;5;3,Reject,0,0,0.0,yes,9/28/20,University of California  Los Angeles;University of California  Santa Cruz;University of California  Los Angeles;University of California  Los Angeles,copy number variation;deep learning;convolutional neural network;computational biology;DNA sequencing,-1;-1;-1;-1,15;207;15;15,m;m,usa,usa,n,
7707,ICLR,2021,Distantly supervised end-to-end medical entity extraction from electronic health records with human-level quality,Alexander Nesterov;Dmitry Umerenkov,ainesterov@sberbank.ru;~Dmitry_Umerenkov1,5;4;4;3,5;4;4;4,Reject,0,0,0.0,yes,9/28/20,Sberbank of Russia;;Lomonosov Moscow State University,entity extraction;medical entity extraction;named entity recognition;named entity normalization;electronic health records;unsupervised learning;distant supervision.,-1;-1;-1,-1;-1;173,m;m,NAN,NAN,n,8
7708,ICLR,2021,Meta Auxiliary Labels with Constituent-based Transformer for Aspect-based Sentiment Analysis,Ling Min Serena Khoo;Hai Leong Chieu,~Ling_Min_Serena_Khoo1;~Hai_Leong_Chieu1,2;4;3,4;4;5,Reject,0,3,0.0,yes,9/28/20,DSO National Laboratories;DSO National Laboratories,Natural Language Processing;Sentiment Analysis,-1;-1,-1;-1,f;m,NAN,NAN,n,8;3
7709,ICLR,2021,Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification,Yunsheng Shi;Zhengjie Huang;shikun feng;Hui Zhong;Wenjin Wang;Yu Sun,shiyunsheng01@baidu.com;huangzhengjie@baidu.com;~shikun_feng1;zhonghui03@baidu.com;wangwenjin02@baidu.com;sunyu02@baidu.com,7;6;4;5,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,Dalian University of Technology  Tsinghua University;Sun Yat-sen University;Baidu;;;;;;Baidu,Unified Message Passing Model;Graph Neural Network;Label Propagation Algorithm;Semi-Supervised Classification.,4;128;-1;-1;-1;-1;-1;-1;-1,20;293;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;10
7710,ICLR,2021,An Empirical Study of the Expressiveness of Graph Kernels and Graph Neural Networks,Giannis Nikolentzos;George Panagopoulos;Michalis Vazirgiannis,~Giannis_Nikolentzos1;george.panagopoulos@polytechnique.edu;~Michalis_Vazirgiannis1,4;4;3;4,5;4;4;4,Reject,0,0,0.0,yes,9/28/20,Ecole polytechnique;Ecole polytechnique;;AUEB,,-1;-1;-1;209,89;89;-1;-1,m;m,europe,gr,n,10
7711,ICLR,2021,Distributional Reinforcement Learning for Risk-Sensitive Policies,Shiau Hong Lim;Ilyas Malik,~Shiau_Hong_Lim1;malikilyas1996@gmail.com,5;7;5;5,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,IBM Research;University of Oxford,,-1;46,-1;1,m;m,europe,uk,y,
7712,ICLR,2021,Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation,Lukas Pfahler;Katharina Morik,~Lukas_Pfahler1;~Katharina_Morik1,3;3;4;5,2;4;4;4,Reject,0,0,0.0,yes,9/28/20,TU Dortmund;TU Dortmund,Adversarial Learning;Natural Language Processing;BERT;News Recommendation;Attention,263;263,404;404,m;f,europe,de,n,8;4
7713,ICLR,2021,Stochastic Normalized Gradient Descent with Momentum for Large Batch Training,Shen-Yi Zhao;Yin-Peng Xie;Wu-Jun Li,~Shen-Yi_Zhao2;~Yin-Peng_Xie1;~Wu-Jun_Li1,4;4;4;3,4;4;5;3,Reject,0,0,0.0,yes,9/28/20,Nanjing University;Nanjing University;Nanjing University,normalized gradient;large batch training size,52;52;52,111;111;111,m;m,asia,kr,y,8;1;9
7714,ICLR,2021,Mitigating Mode Collapse by Sidestepping Catastrophic Forgetting,Karttikeya Mangalam;Rohin Garg;Jathushan Rajasegaran;Taesung Park,~Karttikeya_Mangalam1;~Rohin_Garg1;~Jathushan_Rajasegaran1;~Taesung_Park2,4;6;7;5,5;4;3;3,Reject,0,0,0.0,yes,9/28/20,University of California Berkeley;IIT Kanpur;University of Moratuwa;University of California Berkeley,mode collapse;catastrophic forgetting;multi-adversarial training,-1;128;-1;-1,7;-1;-1;7,m;m,usa,usa,n,5;4
7715,ICLR,2021,Convergence Analysis of Homotopy-SGD for Non-Convex Optimization,Matilde Gargiani;Andrea Zanelli;Moritz Diehl;Quoc Tran-Dinh;Frank Hutter,~Matilde_Gargiani1;~Andrea_Zanelli1;~Moritz_Diehl1;~Quoc_Tran-Dinh2;~Frank_Hutter1,5;5;5;4,4;4;4;4,Reject,0,6,0.0,yes,9/28/20,"ifA | Automatic Control Laboratory | ETH Zurich;Universit√§t Freiburg;Universit√§t Freiburg;University of North Carolina, Chapel Hill;University of Freiburg & Bosch",deep learning;numerical optimization;transfer learning,9;-1;-1;64;150,14;-1;-1;-1;83,f;m,NAN,NAN,y,9
7716,ICLR,2021,The Impact of the Mini-batch Size on the Dynamics of SGD: Variance and Beyond,Xin Qian;Diego Klabjan,~Xin_Qian2;~Diego_Klabjan1,3;4;6;5,5;4;4;4,Reject,0,8,0.0,yes,9/28/20,"Northwestern University, Northwestern University;Northwestern University",,46;46,24;24,m;m,usa,usa,y,1
7717,ICLR,2021,Multi-View Disentangled Representation,Zongbo Han;Changqing Zhang;Huazhu Fu;Qinghua Hu;Joey Tianyi Zhou,~Zongbo_Han1;~Changqing_Zhang1;~Huazhu_Fu4;~Qinghua_Hu1;~Joey_Tianyi_Zhou1,5;5;5;6,5;4;3;3,Reject,0,4,0.0,yes,9/28/20,"Tianjin University;Tianjin University;Inception Institute of Artificial Intelligence;Tianjin University;IHPC, A*STAR",,-1;-1;-1;-1;-1,496;496;-1;496;-1,m;m,NAN,NAN,n,
7718,ICLR,2021,Recycling sub-optimial Hyperparameter Optimization models to generate efficient Ensemble Deep Learning,Pierrick Pochelu;Bruno Conche;Serge G. Petiton,~Pierrick_Pochelu1;bruno.conche@total.com;serge.petiton@univ-lille.fr,3;3;3;4,5;4;5;4,Reject,0,0,0.0,yes,9/28/20,TOTAL SA & CRISTAL;;Universit‚àö¬© de Lille,Deep Learning;hyperparameter optimization;ensemble deep learning;multi-GPU,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
7719,ICLR,2021,The Negative Pretraining Effect in Sequential Deep Learning and Three Ways to Fix It,Julian G. Zilly;Franziska Eckert;Bhairav Mehta;Andrea Censi;Emilio Frazzoli,~Julian_G._Zilly1;~Franziska_Eckert1;~Bhairav_Mehta1;~Andrea_Censi1;~Emilio_Frazzoli1,5;4;4;6;4,2;3;4;4;4,Reject,0,0,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology,Transfer learning;Deep learning;Sequential learning;Critical learning periods;Curriculum learning,-1;-1;5;5;-1;5,-1;-1;4;4;-1;4,m;m,usa,usa,n,1
7720,ICLR,2021,Time Series Counterfactual Inference with Hidden Confounders,Guangyu Li;Jiahao Chen;Samuel A Assefa;Yan Liu,~Guangyu_Li2;~Jiahao_Chen1;samuel.a.assefa@jpmorgan.com;~Yan_Liu1,5;5;4;5,3;3;4;4,Reject,0,0,0.0,yes,9/28/20,University of Southern California;J.P. Morgan Chase;J.P. Morgan Chase;University of Southern California,Time Series Analysis;Counterfactual Inference;Differential Equations.,37;-1;-1;37,53;-1;-1;53,m;f,usa,usa,n,
7721,ICLR,2021,A Simple and Effective  Baseline for Out-of-Distribution Detection using Abstention,Sunil Thulasidasan;Sushil Thapa;Sayera Dhaubhadel;Gopinath Chennupati;Tanmoy Bhattacharya;Jeff Bilmes,~Sunil_Thulasidasan1;~Sushil_Thapa2;sayeradbl@lanl.gov;~Gopinath_Chennupati1;~Tanmoy_Bhattacharya1;~Jeff_Bilmes1,4;5;4;6,4;4;5;3,Reject,0,10,0.0,yes,9/28/20,"Los Alamos National Laboratory;Institute of Engineering, Thapathali campus;;;Los Alamos National Laboratory;;University of Washington, Seattle",deep learning;out-of-distribution detection,-1;-1;-1;-1;-1;-1;11,-1;-1;-1;-1;-1;-1;29,m;m,NAN,NAN,n,
7722,ICLR,2021,Redesigning the Classification Layer by Randomizing the Class Representation Vectors,Gabi Shalev;Gal Lev Shalev;Yossi Keshet,~Gabi_Shalev1;~Gal_Lev_Shalev1;~Yossi_Keshet1,5;5;4;4,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,"Bar Ilan University, Technion;Bar Ilan University;Bar-Ilan University",,29;110;110,-1;570;570,f;m,europe,il,n,1
7723,ICLR,2021,What are effective labels for augmented data? Improving robustness with AutoLabel,Yao Qin;Xuezhi Wang;Balaji Lakshminarayanan;Ed Chi;Alex Beutel,~Yao_Qin1;~Xuezhi_Wang3;~Balaji_Lakshminarayanan1;~Ed_Chi1;~Alex_Beutel1,4;4;4;5,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,"University of California, San Diego;Google;Google Brain;;Google",data augmentation;image classification;calibration;distributional shifts;adversarial robustness,-1;-1;-1;-1;-1,33;-1;-1;-1;-1,f;m,NAN,NAN,n,1;4
7724,ICLR,2021,Memformer: The Memory-Augmented Transformer,Qingyang Wu;Zhenzhong Lan;Jing Gu;Zhou Yu,~Qingyang_Wu1;lanzhenzhong@westlake.edu.cn;~Jing_Gu2;~Zhou_Yu1,6;5;4;3,3;3;4;4,Reject,0,5,0.0,yes,9/28/20,"University of California, Davis;Westlake University;University of California, Davis;University of California, Davis",transformer;language model;memory networks,-1;263;-1;-1,64;-1;64;64,m;f,usa,usa,n,8;3
7725,ICLR,2021,Multi-Level Generative Models for Partial Label Learning with Non-random Label Noise,Yan Yan;Yuhong Guo,~Yan_Yan10;~Yuhong_Guo1,7;6;5,4;3;4,Reject,0,0,0.0,yes,9/28/20,Northwestern Polytechnical University;Carleton University,,-1;209,538;588,f;f,canada,ca,n,5;4
7726,ICLR,2021,AttackDist: Characterizing Zero-day Adversarial Samples by Counter Attack,Simin Chen;Zihe Song;Lei Ma;Cong Liu;Wei Yang,~Simin_Chen1;~Zihe_Song1;~Lei_Ma1;~Cong_Liu2;wei.yang@utdallas.edu,3;3;5;5,5;5;3;4,Reject,0,1,0.0,yes,9/28/20,"University of Texas, Dallas;University of Texas, Dallas;University of Alberta;University of Texas, Dallas;University of Texas, Dallas",,-1;-1;110;-1;-1,-1;-1;131;-1;-1,m;m,usa,usa,y,1;4
7727,ICLR,2021,Towards certifying $\ell_\infty$ robustness using Neural networks with $\ell_\infty$-dist Neurons,Bohang Zhang;Zhou Lu;Tianle Cai;Di He;Liwei Wang,zhangbohang@pku.edu.cn;~Zhou_Lu1;~Tianle_Cai1;~Di_He1;~Liwei_Wang1,4;4;6;5,5;3;4;5,Reject,0,6,0.0,yes,9/28/20,Peking University;Princeton University;Peking University;Microsoft;Peking University,,14;29;14;-1;14,23;9;23;-1;23,m;m,asia,cn,y,1;4
7728,ICLR,2021,The large learning rate phase of deep learning,Aitor Lewkowycz;Yasaman Bahri;Ethan Dyer;Jascha Sohl-Dickstein;Guy Gur-Ari,~Aitor_Lewkowycz2;~Yasaman_Bahri1;~Ethan_Dyer1;~Jascha_Sohl-Dickstein2;~Guy_Gur-Ari1,5;3;4,4;4;4,Reject,0,3,0.0,yes,9/28/20,Google;Google Brain;Google;Google;Google,deep learning;wide networks;training dynamics,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
7729,ICLR,2021,Predicting the impact of dataset composition on model performance,Tatsunori Hashimoto,~Tatsunori_Hashimoto1,5;4;7;5,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,Stanford University,Experimental design;generalization;data collection,5,2,m,usa,usa,y,3;1
7730,ICLR,2021,SBEVNet: End-to-End Deep Stereo Layout Estimation,Divam Gupta;Wei Pu;Trenton Tabor;Jeff Schneider,~Divam_Gupta1;wpu@nrec.ri.cmu.edu;~Trenton_Tabor1;~Jeff_Schneider1,5;6;5;5,5;4;4;5,Reject,0,4,0.0,yes,9/28/20,Carnegie Mellon University;;;;School of Computer Science,Layout Estimation;Deep Stereo;Computer Vision,1;-1;-1;-1;-1,28;-1;-1;-1;-1,m;m,NAN,NAN,n,
7731,ICLR,2021,The impacts of known and unknown demonstrator irrationality on reward inference,Lawrence Chan;Andrew Critch;Anca Dragan,~Lawrence_Chan2;~Andrew_Critch1;~Anca_Dragan1,5;5;4;4,3;3;3;5,Reject,0,6,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California-Berkeley,irrationality;reward learning;irl,-1;-1;-1,7;7;7,m;f,usa,usa,y,
7732,ICLR,2021,CorDial: Coarse-to-fine Abstractive Dialogue Summarization with Controllable Granularity,Chien-Sheng Wu;Linqing Liu;Wenhao Liu;Pontus Stenetorp;Caiming Xiong,~Chien-Sheng_Wu1;likicode@gmail.com;wenhao.liu@salesforce.com;p.stenetorp@cs.ucl.ac.uk;~Caiming_Xiong1,4;5;5;6,5;4;4;4,Reject,0,4,0.0,yes,9/28/20,Salesforce AI Research;;;;;University College London;Salesforce Research,dialogue;summarization;controllable generation;natural language processing,-1;-1;-1;-1;-1;53;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7733,ICLR,2021,Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling,Russell Mendonca;Xinyang Geng;Chelsea Finn;Sergey Levine,~Russell_Mendonca1;~Xinyang_Geng1;~Chelsea_Finn1;~Sergey_Levine1,5;4;5;6,5;4;3;4,Reject,0,6,0.0,yes,9/28/20,Carnegie Mellon University;University of California Berkeley;Stanford University;University of Washington,Meta-Reinforcement Learning;Meta Learning;Reinforcement Learning,1;-1;5;11,28;7;2;29,m;m,usa,usa,n,
7734,ICLR,2021,Localized Meta-Learning: A PAC-Bayes Analysis for Meta-Learning Beyond Global Prior,Chenghao Liu;Tao Lu;Doyen Sahoo;Yuan Fang;Kun Zhang;Steven Hoi,~Chenghao_Liu1;~Tao_Lu2;~Doyen_Sahoo1;~Yuan_Fang1;~Kun_Zhang1;~Steven_Hoi2,5;5;6;5,3;4;3;4,Reject,0,4,0.0,yes,9/28/20,Zhejiang University;;Zhejiang University;Singapore Management University;Singapore Management University;Carnegie Mellon University;Salesforce Research Asia,localized meta-learning;PAC-Bayes;meta-learning,42;-1;42;79;79;1;-1,94;-1;94;-1;-1;28;-1,m;m,NAN,NAN,y,6;1
7735,ICLR,2021,Privacy-preserving Learning via Deep Net Pruning,YANGSIBO HUANG;Xiaoxiao Li;Yushan Su;Sachin Ravi;Zhao Song;Sanjeev Arora;Kai Li,~YANGSIBO_HUANG1;~Xiaoxiao_Li1;yushans@princeton.edu;~Sachin_Ravi1;~Zhao_Song3;~Sanjeev_Arora1;~Kai_Li8,4;5;4;2,4;5;4;5,Reject,0,4,0.0,yes,9/28/20,Princeton University;Princeton University;;;Apple;Institue for Advanced Study;Princeton University,Neural Network Pruning;Differential Privacy,29;29;-1;-1;-1;-1;29,9;9;-1;-1;-1;-1;9,f;m,usa,usa,y,1;4
7736,ICLR,2021,Improving Self-supervised Pre-training via a Fully-Explored Masked Language Model,Mingzhi Zheng;Dinghan Shen;yelong shen;Weizhu Chen;Lin Xiao,~Mingzhi_Zheng1;~Dinghan_Shen1;~yelong_shen1;~Weizhu_Chen1;~Lin_Xiao1,5;4;5;6;6,3;5;3;4;4,Reject,0,0,0.0,yes,9/28/20,Microsoft;Microsoft;Kent State University;Microsoft;Facebook,representation learning;natural language processing,-1;-1;263;-1;-1,-1;-1;814;-1;-1,m;m,NAN,NAN,y,3
7737,ICLR,2021,GraphCGAN: Convolutional Graph Neural Network with Generative Adversarial Networks,Sheng Zhang;Rui Song;Wenbin Lu,~Sheng_Zhang8;~Rui_Song2;~Wenbin_Lu1,5;5;5;4,4;5;2;4,Reject,0,4,0.0,yes,9/28/20,North Carolina State University;North Carolina State University;North Carolina State University,,92;92;92,340;340;340,m;m,usa,usa,n,10;5;4
7738,ICLR,2021,Outlier Preserving Distribution Mapping Autoencoders ,Walter Gerych;Elke Rundensteiner;Emmanuel Agu,~Walter_Gerych2;~Elke_Rundensteiner2;~Emmanuel_Agu1,3;4;6;5,5;3;4;3,Reject,0,0,0.0,yes,9/28/20,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute,,150;150;150,651;651;651,m;m,usa,usa,y,1
7739,ICLR,2021,Play to Grade: Grading Interactive Coding Games as Classifying Markov Decision Process,Allen Nie;Emma Brunskill;Chris Piech,~Allen_Nie1;~Emma_Brunskill2;chrisjpiech@gmail.com,4;3;5,4;4;4,Reject,0,0,0.0,yes,9/28/20,Stanford University;Stanford University;Stanford University,Deep Reinforcement Learning;Education;Automated Grading;Program Testing,5;5;5,2;2;2,m;m,usa,usa,n,1
7740,ICLR,2021,Provably More Efficient Q-Learning in the One-Sided-Feedback/Full-Feedback Settings,Xiao-Yue Gong;David Simchi-Levi,~Xiao-Yue_Gong1;~David_Simchi-Levi2,5;4;6;5,4;2;3;4,Reject,0,4,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Q-learning;episodic MDP;full-feedback;one-sided-feedback;inventory control;inventory,5;5,4;4,f;m,usa,usa,y,
7741,ICLR,2021,Three Dimensional Reconstruction of Botanical Trees with Simulatable Geometry,Ed Quigley;Winnie Lin;Yilin Zhu;Ronald Fedkiw,~Ed_Quigley1;~Winnie_Lin1;~Yilin_Zhu1;~Ronald_Fedkiw1,4;4;3;6,4;3;4;3,Reject,0,4,0.0,yes,9/28/20,Industrial Light & Magic;Stanford University;Stanford University;Stanford University,,-1;5;5;5,-1;2;2;2,m;m,usa,usa,n,
7742,ICLR,2021,Systematic Evaluation of Causal Discovery in Visual Model Based Reinforcement Learning,Nan Rosemary Ke;Aniket Rajiv Didolkar;Sarthak Mittal;Anirudh Goyal;Guillaume Lajoie;Stefan Bauer;Danilo Jimenez Rezende;Michael Curtis Mozer;Yoshua Bengio;Christopher Pal,~Nan_Rosemary_Ke1;~Aniket_Rajiv_Didolkar1;~Sarthak_Mittal1;~Anirudh_Goyal1;~Guillaume_Lajoie1;~Stefan_Bauer1;~Danilo_Jimenez_Rezende2;~Michael_Curtis_Mozer1;~Yoshua_Bengio1;~Christopher_Pal1,5;6;4;4,4;3;3;3,Reject,0,11,0.0,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Manipal Institute of Technology;University of Montreal;University of Montreal;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Swiss Federal Institute of Technology;DeepMind;University of Colorado at Boulder;University of Montreal;Polytechnique Montreal",causal induction;model based RL,128;-1;128;128;128;-1;-1;-1;128;327,73;-1;73;73;73;-1;-1;-1;73;-1,f;m,canada,ca,n,10
7743,ICLR,2021,MSFM: Multi-Scale Fusion Module for Object Detection,Xuesong Wang;Caisheng Wang,~Xuesong_Wang2;~Caisheng_Wang1,4;3;3;3,5;4;4;5,Reject,0,4,0.0,yes,9/28/20,Wayne State University;Wayne State University,Feature Fusion;Object Detection;Multi-Scale,209;209,377;377,m;m,usa,usa,n,2
7744,ICLR,2021,Topic-aware Contextualized Transformers,Ruiying Lu;Bo Chen;Dan dan Guo;Dongsheng Wang;Mingyuan Zhou,~Ruiying_Lu1;~Bo_Chen1;~Dan_dan_Guo1;wds_dana@163.com;~Mingyuan_Zhou1,4;7;4,3;4;4,Reject,0,0,0.0,yes,9/28/20,Xidian University;Xidian University;Xidian University;;;The University of Texas at Austin,,-1;-1;-1;-1;-1;20,924;924;924;-1;-1;43,f;m,NAN,NAN,n,8;3
7745,ICLR,2021,Offline Policy Optimization with Variance Regularization,Riashat Islam;Samarth Sinha;Homanga Bharadhwaj;Samin Yeasar Arnob;Zhuoran Yang;Zhaoran Wang;Animesh Garg;Lihong Li;Doina Precup,~Riashat_Islam1;~Samarth_Sinha1;~Homanga_Bharadhwaj1;~Samin_Yeasar_Arnob1;~Zhuoran_Yang1;~Zhaoran_Wang1;~Animesh_Garg1;~Lihong_Li1;~Doina_Precup1,3;4;4,5;4;3,Reject,0,7,0.0,yes,9/28/20,"McGill University;University of Toronto, Toronto University;School of Computer Science, Carnegie Mellon University;McGill University;University of California Berkeley;Northwestern University;University of Toronto;Amazon;DeepMind",reinforcement learning;offline batch RL;off-policy;policy optimization;variance regularization,99;18;1;99;-1;46;18;-1;-1,40;18;28;40;7;24;18;-1;-1,m;f,NAN,NAN,y,1
7746,ICLR,2021,Synthetic Petri Dish: A Novel Surrogate Model for Rapid Architecture Search,Aditya Rawal;Joel Lehman;Felipe Petroski Such;Jeff Clune;Kenneth Stanley,~Aditya_Rawal1;~Joel_Lehman1;~Felipe_Petroski_Such1;~Jeff_Clune1;~Kenneth_Stanley1,4;6;6;6,4;3;1;3,Reject,0,6,0.0,yes,9/28/20,Amazon;Uber AI Labs;Uber;;University of Wyoming;University of Central Florida,Neural Architecture Search;AutoML;Meta-learning,-1;-1;-1;-1;327;71,-1;-1;1302;-1;-1;633,m;m,usa,usa,n,
7747,ICLR,2021,Prior Knowledge Representation for Self-Attention Networks,Kehai Chen;Rui Wang;Masao Utiyama;Eiichiro Sumita,~Kehai_Chen2;~Rui_Wang10;~Masao_Utiyama2;~Eiichiro_Sumita1,3;5;4,5;4;4,Reject,0,1,0.0,yes,9/28/20,National Institute of Information and Communications Technology (NICT);Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT)  National Institute of Advanced Industrial Science and Technology,Prior Knowledge;Universal Representation;Self-Attention Networks;Neural Machine Translation,-1;29;-1,-1;100;-1,m;m,NAN,NAN,n,8;3
7748,ICLR,2021,Searching for Convolutions and a More Ambitious NAS,Nicholas Carl Roberts;Mikhail Khodak;Tri Dao;Liam Li;Nina Balcan;Christopher Re;Ameet Talwalkar,~Nicholas_Carl_Roberts1;~Mikhail_Khodak1;~Tri_Dao1;~Liam_Li1;~Nina_Balcan1;~Christopher_Re1;~Ameet_Talwalkar1,5;4;5;5,4;4;5;4,Reject,0,7,0.0,yes,9/28/20,"University of Wisconsin, Madison;Carnegie Mellon University;Stanford University;Carnegie Mellon University;Carnegie-Mellon University;University of Wisconsin-Madison;University of California-Los Angeles",neural architecture search;automated machine learning;convolutional neural networks,18;1;5;1;1;18;-1,49;28;2;28;28;49;15,m;m,usa,usa,y,2
7749,ICLR,2021,On the Robustness of Sentiment Analysis for Stock Price Forecasting,Gabriel Deza;Colin Rowat;Nicolas Papernot,~Gabriel_Deza1;c.rowat@bham.ac.uk;~Nicolas_Papernot1,5;5;4;7,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,Toronto University;Birmingham University;University of Toronto,adversarial machine learning;adversarial examples;stock price forecasting;finance,-1;-1;18,-1;-1;18,m;m,canada,ca,n,2;4
7750,ICLR,2021,XMixup: Efficient Transfer Learning with Auxiliary Samples by Cross-Domain Mixup,Xingjian Li;Haoyi Xiong;Haozhe An;Cheng-zhong Xu;Dejing Dou,~Xingjian_Li1;~Haoyi_Xiong1;~Haozhe_An1;~Cheng-zhong_Xu1;~Dejing_Dou1,5;4;4;4,4;5;4;5,Reject,0,4,0.0,yes,9/28/20,"Baidu;Baidu;University of Maryland, College Park;University of Macau;University of Oregon Eugene",transfer learning;deep learning,-1;-1;12;-1;209,-1;-1;90;305;346,m;m,NAN,NAN,n,6
7751,ICLR,2021,On the Neural Tangent Kernel of Equilibrium Models,Zhili Feng;J Zico Kolter,~Zhili_Feng1;~J_Zico_Kolter1,6;4;3;4,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,"CMU, Carnegie Mellon University;Carnegie Mellon University",deel learning;equilibrium model;neural tangent kernel,1;1,28;28,m;m,usa,usa,n,
7752,ICLR,2021,Nonconvex Continual Learning with Episodic Memory,Sungyeob Han;Yeongmo Kim;Jungwoo Lee,~Sungyeob_Han1;~Yeongmo_Kim1;~Jungwoo_Lee1,4;5;3;4,5;4;3;4,Reject,0,5,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University,continual learning;nonconvex optimization,37;37;37,60;60;60,m;m,asia,kr,y,1;9
7753,ICLR,2021,Variational saliency maps for explaining model's behavior,Jae Myung Kim;Eunji Kim;Seokhyeon Ha;Sungroh Yoon;Jungwoo Lee,~Jae_Myung_Kim1;~Eunji_Kim2;~Seokhyeon_Ha1;~Sungroh_Yoon1;~Jungwoo_Lee1,4;4;5,3;3;4,Reject,0,4,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University;Seoul National University,Interpretability;XAI;Variational Inference,37;37;37;37;37,60;60;60;60;60,m;m,asia,kr,n,
7754,ICLR,2021,Exploiting Verified Neural Networks via Floating Point Numerical Error,Kai Jia;Martin Rinard,~Kai_Jia2;~Martin_Rinard1,8;4;4;3,5;5;3;5,Reject,0,9,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology,,5;5,4;4,m;m,usa,usa,n,8;4
7755,ICLR,2021,Hidden Markov models are recurrent neural networks: A disease progression modeling application,Matthew Baucum;Anahita Khojandi;Theodore Papamarkou,~Matthew_Baucum1;~Anahita_Khojandi1;~Theodore_Papamarkou1,5;5;3;4,4;3;5;4,Reject,0,0,0.0,yes,9/28/20,"University of Tennessee, Knoxville;University of Tennessee, Knoxville;University of Manchester",hidden markov models;recurrent neural networks;disease progression,209;209;263,-1;-1;51,m;m,europe,uk,y,1
7756,ICLR,2021,VideoFlow: A Framework for Building Visual Analysis Pipelines,Yue Wu;Jianqiang Huang;Jiangjie Zhen;Guokun Wang;Chen Shen;Chang Zhou;Xian-Sheng Hua,~Yue_Wu18;jianqiang.hjq@alibaba-inc.com;moevis.zjj@alibaba-inc.com;guokun.wgk@alibaba-inc.com;jason.sc@alibaba-inc.com;zhouchang.zc@alibaba-inc.com;xiansheng.hxs@alibaba-inc.com,3;3;4;3;3,4;4;3;4;4,Reject,0,0,0.0,yes,9/28/20,University of Science and Technology of China  Tsinghua University;;;;;;;;;;;Alibaba DAMO Academy,Computation graph;Resource;Computer vision;Deep learning;Framework;Software,4;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,20;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7757,ICLR,2021,Solving Min-Max Optimization with Hidden Structure via Gradient Descent Ascent,Emmanouil-Vasileios Vlatakis-Gkaragkounis;Lampros Flokas;Georgios Piliouras,~Emmanouil-Vasileios_Vlatakis-Gkaragkounis1;~Lampros_Flokas1;~Georgios_Piliouras1,5;4;6;5,4;3;4;4,Reject,0,21,0.0,yes,9/28/20,Columbia University;Columbia University;Singapore University of Technology and Design,Min-max optimization;Lyapunov functions;Stability Analysis;Generative Adversarial Networks;Non-convex optimization,23;23;-1,17;17;-1,m;m,NAN,NAN,y,1;5;4
7758,ICLR,2021,Analysis of Alignment Phenomenon in Simple Teacher-student Networks with Finite Width,Hanlin Zhu;Chengyang Ying;Song Zuo,~Hanlin_Zhu2;~Chengyang_Ying2;~Song_Zuo1,3;5;4;4,4;3;4;4,Reject,0,5,0.0,yes,9/28/20,"Tsinghua University;Tsinghua University, Tsinghua University;Google",alignment;finite width network;teacher student model;angular distance function,4;4;-1,20;20;-1,m;m,NAN,NAN,y,1
7759,ICLR,2021,Interpretable Meta-Reinforcement Learning with Actor-Critic Method,Xingyuan Liang;Xu-Ying Liu,~Xingyuan_Liang1;liuxy@seu.edu.cn,4;3;4;2;3,3;4;4;5;3,Reject,0,0,0.0,yes,9/28/20,Southeast University  Tsinghua University;Southeast University,meta-reinforcement learning;actor-critic;deep learning;interpretable,4;-1,20;509,u;f,NAN,NAN,n,6
7760,ICLR,2021,Semi-supervised learning by selective training with pseudo labels via confidence estimation,Masato Ishii,~Masato_Ishii1,4;5;5;6,3;2;4;3,Reject,0,0,0.0,yes,9/28/20,Sony,semi-supervised learning;confidence estimation,-1,-1,m,asia,cn,n,
7761,ICLR,2021,Searching towards Class-Aware Generators for Conditional Generative Adversarial Networks,Peng Zhou;Lingxi Xie;XIAOPENG ZHANG;Bingbing Ni;Qi Tian,~Peng_Zhou2;~Lingxi_Xie1;~XIAOPENG_ZHANG7;~Bingbing_Ni3;~Qi_Tian3,5;5;5;5;5,4;4;4;3;3,Reject,0,8,0.0,yes,9/28/20,Shanghai Jiao Tong University;Huawei Technologies Ltd.;National University of Singapore;Shanghai Jiao Tong University;Huawei Technologies Ltd.,NAS;cGAN,29;-1;17;29;-1,100;-1;25;100;-1,m;m,NAN,NAN,n,5;4
7762,ICLR,2021,Ensembles of Generative Adversarial Networks for Disconnected Data,Lorenzo Luzi;Randall Balestriero;Richard Baraniuk,~Lorenzo_Luzi1;~Randall_Balestriero1;~Richard_Baraniuk1,4;5;7;4,3;3;4;4,Reject,0,0,0.0,yes,9/28/20,Rice University;Rice University;William Marsh Rice University,GANs;ensembles;disconnected data,92;92;92,124;124;124,m;m,NAN,NAN,y,2;1;5
7763,ICLR,2021,It's Hard for Neural Networks to Learn the Game of Life,Jacob M. Springer;Garrett T. Kenyon,~Jacob_M._Springer1;~Garrett_T._Kenyon1,6;5;3;5,4;3;5;4,Reject,0,0,0.0,yes,9/28/20,Los Alamos National Laboratory;Los Alamos National Laboratory,Deep Learning;Game of Life,-1;-1,-1;-1,m;m,NAN,NAN,n,
7764,ICLR,2021,Anti-Distillation: Improving Reproducibility of Deep Networks,Gil I Shamir;Lorenzo Coviello,gshamir@google.com;~Lorenzo_Coviello1,3;3;3;3,3;3;4;4,Reject,0,0,0.0,yes,9/28/20,Google;Google,Deep networks;ensembles;reproducibility,-1;-1,-1;-1,m;m,NAN,NAN,n,
7765,ICLR,2021,Evaluating representations by the complexity of learning low-loss predictors,William F Whitney;Min Jae Song;David Brandfonbrener;Jaan Altosaar;Kyunghyun Cho,~William_F_Whitney1;~Min_Jae_Song1;~David_Brandfonbrener1;~Jaan_Altosaar1;~Kyunghyun_Cho1,7;4;4,4;3;3,Reject,0,3,0.0,yes,9/28/20,New York University;New York University;New York University;Columbia University;New York University,representation learning;representation evaluation;unsupervised learning;self-supervised learning,23;23;23;23;23,26;26;26;17;26,m;m,usa,usa,n,
7766,ICLR,2021,Dynamic Graph Representation Learning with Fourier Temporal State Embedding,Yihan He;Wei Cao;Shun Zheng;Zhifeng Gao;Jiang Bian,~Yihan_He1;~Wei_Cao1;~Shun_Zheng1;~Zhifeng_Gao1;~Jiang_Bian1,5;4;4;5,4;4;5;5,Reject,0,5,0.0,yes,9/28/20,"New York University;Tsinghua University, Tsinghua University;Microsoft;Peking University;Microsoft",Graph Neural Networks;Dynamic Graph;Signal Processing,23;4;-1;14;-1,26;20;-1;23;-1,f;m,NAN,NAN,n,10
7767,ICLR,2021,Meta Gradient Boosting Neural Networks,Manqing Dong;Lina Yao;Xianzhi Wang;Xiwei Xu;Liming Zhu,~Manqing_Dong1;~Lina_Yao2;xianzhi.wang@uts.edu.au;xiwei.xu@data61.csiro.au;liming.zhu@data61.csiro.au,4;4;6;5,5;4;3;4,Reject,0,4,0.0,yes,9/28/20,University of New South Wales;University of New South Wales;University of Technology Sydney;;;CSIRO,meta learning;deep learning,-1;-1;71;-1;-1;-1,-1;-1;160;-1;-1;-1,f;m,asia,in,n,6
7768,ICLR,2021,Multi-agent Policy Optimization with Approximatively Synchronous Advantage Estimation,Lipeng Wan;Xuwei Song;Xuguang Lan;Nanning Zheng,~Lipeng_Wan1;songxw17@stu.xjtu.edu.cn;~Xuguang_Lan2;~Nanning_Zheng1,5;5;3;4,2;4;4;4,Reject,0,0,0.0,yes,9/28/20,Xi'an Jiaotong University;;;Xi'an Jiaotong University,multi-agent reinforcement learning;policy optimization;advantage estimation;credit assignment,-1;-1;-1;-1,445;-1;-1;445,m;m,NAN,NAN,n,
7769,ICLR,2021,Mitigating Deep Double Descent by Concatenating Inputs,John Chen;Qihan Wang;Anastasios Kyrillidis,~John_Chen3;~Qihan_Wang1;~Anastasios_Kyrillidis2,4;3;5;2,3;3;4;4,Reject,0,0,0.0,yes,9/28/20,Rice University;Rice University;Rice University,deep double descent;feedforward neural network;image classificaiton,92;92;92,124;124;124,m;m,australasia,au,n,
7770,ICLR,2021,Certified Robustness of Nearest Neighbors against Data Poisoning Attacks,Jinyuan Jia;Xiaoyu Cao;Neil Zhenqiang Gong,~Jinyuan_Jia2;~Xiaoyu_Cao1;~Neil_Zhenqiang_Gong1,4;3;5;5;4,3;4;4;2;4,Reject,0,0,0.0,yes,9/28/20,Duke University;Duke University;Duke University,,46;46;46,20;20;20,m;m,europe,se,y,4
7771,ICLR,2021,R-LAtte: Attention Module for Visual Control via Reinforcement Learning,Mandi Zhao;Qiyang Li;Aravind Srinivas;Ignasi Clavera;Kimin Lee;Pieter Abbeel,~Mandi_Zhao1;~Qiyang_Li1;~Aravind_Srinivas1;~Ignasi_Clavera1;~Kimin_Lee1;~Pieter_Abbeel2,4;4;5,4;5;3,Reject,0,4,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Covariant,,-1;-1;-1;-1;-1;-1,7;7;7;7;7;-1,f;m,NAN,NAN,n,8;5
7772,ICLR,2021,Success-Rate Targeted Reinforcement Learning by Disorientation Penalty,Haichuan Gao;Zhile Yang;Tian Tan;Feng Chen,~Haichuan_Gao1;~Zhile_Yang1;~Tian_Tan1;~Feng_Chen1,2;3;4;4,5;4;4;4,Reject,0,5,0.0,yes,9/28/20,Tsinghua University  Tsinghua University;Tsinghua University  Tsinghua University;Stanford University; Tsinghua University  Tsinghua University,reinforcement learning;undiscounted return;success rate,4;4;5;4,20;20;2;20,m;m,NAN,NAN,n,
7773,ICLR,2021,Decorrelated Double Q-learning,GANG CHEN,~GANG_CHEN1,4;3;5;3,3;3;4;4,Reject,0,0,0.0,yes,9/28/20,"State University of New York, Buffalo",q-learning;control variates;reinforcement learning,-1,-1,u,NAN,NAN,n,
7774,ICLR,2021,The Quenching-Activation Behavior of the Gradient Descent Dynamics for Two-layer Neural Network Models,Chao Ma;Lei Wu;Weinan E,~Chao_Ma8;~Lei_Wu1;~Weinan_E1,5;5;5;5,4;4;4;4,Reject,0,0,0.0,yes,9/28/20,Stanford University;;Princeton University,Gradient descent;neural networks;implicit regularization;quenching-activation,5;-1;29,2;-1;9,m;m,usa,usa,y,
7775,ICLR,2021,Multi-Representation Ensemble in Few-Shot Learning,Qing Chen;Jian Zhang,~Qing_Chen4;~Jian_Zhang5,4;4;4;5,4;4;5;3,Reject,0,0,0.0,yes,9/28/20,Louisiana State University;Louisiana State University,Ensemble learning;Few shot learning;Multi-representaion,453;453,596;596,m;m,usa,usa,n,6
7776,ICLR,2021,Compositional Models: Multi-Task Learning and Knowledge Transfer with Modular Networks,Andrey Zhmoginov;Dina Bashkirova;Mark Sandler,~Andrey_Zhmoginov1;~Dina_Bashkirova1;~Mark_Sandler1,4;5;4;4,4;4;4;4,Reject,0,4,0.0,yes,9/28/20,University of California Berkeley;Boston University;Google,modular networks;transfer learning;domain adaptation;self-organization,-1;79;-1,7;54;-1,m;m,NAN,NAN,n,6
7777,ICLR,2021,EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets,Xiaohan Chen;Yu Cheng;Shuohang Wang;Zhe Gan;Zhangyang Wang;Jingjing Liu,~Xiaohan_Chen1;~Yu_Cheng1;~Shuohang_Wang1;~Zhe_Gan1;~Zhangyang_Wang1;~Jingjing_Liu2,5;6;7;5;3,4;4;3;3;4,Reject,0,12,0.0,yes,9/28/20,"University of Texas, Austin;Microsoft Research;Microsoft;Microsoft;University of Texas, Austin;Microsoft",Natural Language Processing;Lottery Tickets Hypothesis;Efficient Training,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,2;3
7778,ICLR,2021,Pretrain Knowledge-Aware Language Models,Corbin L Rosset;Chenyan Xiong;Minh Phan;Xia Song;Paul N. Bennett;saurabh tiwary,~Corbin_L_Rosset1;~Chenyan_Xiong1;phan.minh@microsoft.com;~Xia_Song1;~Paul_N._Bennett1;~saurabh_tiwary1,5;7;4;6,2;3;4;2,Reject,0,4,0.0,yes,9/28/20,Johns Hopkins University;Microsoft Research;Nanyang Technological University;Microsoft;Microsoft;Microsoft,Pretraining;Natural Language Generation;GPT-2;QA;Knowledge Graph,71;-1;44;-1;-1;-1,12;-1;47;-1;-1;-1,m;m,NAN,NAN,n,6;8;3
7779,ICLR,2021,Why Convolutional Networks Learn Oriented Bandpass Filters: Theory and Empirical Support,Isma Hadji;Richard Wildes,~Isma_Hadji2;~Richard_Wildes1,3;6;5;3,5;4;4;5,Reject,0,0,0.0,yes,9/28/20,Samsung;York University,,-1;209,-1;452,f;m,asia,kr,n,
7780,ICLR,2021,Human-interpretable model explainability on high-dimensional data,Damien de Mijolla;Christopher Frye;Markus Kunesch;John Mansir;Ilya Feige,damiendemijolla@gmail.com;~Christopher_Frye1;m.kunesch@cantab.net;john.m@faculty.ai;~Ilya_Feige1,5;3;4;7,4;4;3;3,Reject,0,4,0.0,yes,9/28/20,University College London;Faculty;;;;;University College London,,53;-1;-1;-1;-1;-1;53,-1;-1;-1;-1;-1;-1;-1,m;m,europe,uk,n,
7781,ICLR,2021,Network Architecture Search for Domain Adaptation,Yichen Li;Xingchao Peng,~Yichen_Li2;~Xingchao_Peng1,4;4;6;4,4;5;3;5,Reject,0,0,0.0,yes,9/28/20,Stanford University;Boston University,,5;79,2;54,f;m,europe,it,n,4
7782,ICLR,2021,PolyRetro: Few-shot Polymer Retrosynthesis via Domain Adaptation,Binghong Chen;Chengtao Li;Hanjun Dai;Rampi Ramprasad;Le Song,~Binghong_Chen1;~Chengtao_Li1;~Hanjun_Dai1;rrampi790@gmail.com;~Le_Song1,5;7;6;6,3;3;3;3,Reject,0,11,0.0,yes,9/28/20,"Georgia Institute of Technology;Massachusetts Institute of Technology;Google Research;;;College of Computing, Georgia Institute of Technology",ML for Chemistry;Polymer Retrosynthesis;Few-show Learning;Domain Adaptation,12;5;-1;-1;-1;12,38;4;-1;-1;-1;38,m;m,NAN,NAN,n,
7783,ICLR,2021,Consistent Instance Classification for Unsupervised Representation Learning,Depu Meng;Zigang Geng;Zhirong Wu;Bin Xiao;Houqiang Li;Jingdong Wang,~Depu_Meng1;~Zigang_Geng1;~Zhirong_Wu1;~Bin_Xiao2;~Houqiang_Li1;~Jingdong_Wang1,5;5;5,3;4;4,Reject,0,3,0.0,yes,9/28/20,University of Science and Technology of China;Microsoft;Microsoft;South China University of Technology;University of Science and Technology of China;Microsoft Research,,-1;-1;-1;-1;-1;-1,87;-1;-1;411;87;-1,m;m,NAN,NAN,n,2
7784,ICLR,2021,Enhanced First and Zeroth Order Variance Reduced Algorithms for Min-Max Optimization,Tengyu Xu;Zhe Wang;Yingbin Liang;H. Vincent Poor,~Tengyu_Xu1;~Zhe_Wang4;~Yingbin_Liang1;~H._Vincent_Poor1,4;6;5;6,5;5;3;3,Reject,0,0,0.0,yes,9/28/20,Ohio State University;JD company;The Ohio State University;Princeton University,minimax optimization;nonconvex;variance reduction,58;-1;58;29,78;-1;-1;9,m;m,usa,usa,y,4
7785,ICLR,2021,Efficient Competitive Self-Play Policy Optimization,Yuanyi Zhong;Yuan Zhou;Jian Peng,~Yuanyi_Zhong1;~Yuan_Zhou1;~Jian_Peng1,7;5;3;5,3;3;4;4,Reject,0,0,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Univ. of Illinois at Urbana-Champaign",self-play;policy optimization;two-player zero-sum game;multiagent,-1;-1;2,-1;-1;-1,m;m,NAN,NAN,y,1;4
7786,ICLR,2021,Learning to Infer Run-Time Invariants from Source code,Vincent Josua Hellendoorn;Premkumar Devanbu;Alex Polozov;Mark Marron,~Vincent_Josua_Hellendoorn1;~Premkumar_Devanbu1;~Alex_Polozov1;marron@microsoft.com,5;5;5;3,5;3;4;4,Reject,0,1,0.0,yes,9/28/20,Carnegie Mellon University;University of California-Davis;Microsoft Research; Microsoft Research,Invariants;Software Engineering;Programming Languages,1;-1;-1;-1,28;64;-1;-1,m;m,NAN,NAN,n,3
7787,ICLR,2021,Natural Compression  for Distributed Deep Learning,Samuel Horv√°th;Chen-Yu Ho;Ludovit Horv√°th;Atal Narayan Sahu;Marco Canini;Peter Richtarik,~Samuel_Horv√°th1;chenyu.ho@kaust.edu.sa;ludovit.horvath.94@gmail.com;atal.sahu@kaust.edu.sa;~Marco_Canini1;~Peter_Richtarik1,5;5;5;6,5;3;4;4,Reject,0,6,0.0,yes,9/28/20,KAUST;KAUST;Comenius University Slovakia;KAUST;KAUST;KAUST,,110;110;-1;110;110;110,-1;-1;-1;-1;-1;-1,m;m,europe,gr,y,1
7788,ICLR,2021,Demystifying Loss Functions for Classification,Simon Kornblith;Honglak Lee;Ting Chen;Mohammad Norouzi,~Simon_Kornblith1;~Honglak_Lee2;~Ting_Chen1;~Mohammad_Norouzi1,5;3;6;4,3;5;4;4,Reject,0,6,0.0,yes,9/28/20,Google;LG AI Research;Google;Google Brain,softmax;classification;representational similarity;transfer learning;label smoothing;dropout,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
7789,ICLR,2021,Measuring and mitigating interference in reinforcement learning,Vincent Liu;Adam M White;Hengshuai Yao;Martha White,~Vincent_Liu3;~Adam_M_White1;~Hengshuai_Yao2;~Martha_White1,5;5;6;4,4;4;2;3,Reject,0,7,0.0,yes,9/28/20,University of Alberta;University of Alberta;University of Alberta;University of Alberta,Reinforcement Learning;Representation Learning,110;110;110;110,131;131;131;131,m;f,canada,ca,n,
7790,ICLR,2021,Expectigrad: Fast Stochastic Optimization with Robust Convergence Properties,Brett Daley;Christopher Amato,~Brett_Daley1;~Christopher_Amato1,5;3;4;5,5;4;3;3,Reject,0,4,0.0,yes,9/28/20,Northeastern University;Northeastern University,deep learning;gradient descent;optimization,16;16,895;895,m;m,usa,usa,y,1;9
7791,ICLR,2021,Unsupervised Anomaly Detection by Robust Collaborative Autoencoders,Boyang Liu;Ding Wang;Kaixiang Lin;Pang-Ning Tan;Jiayu Zhou,~Boyang_Liu1;wangdin1@msu.edu;~Kaixiang_Lin1;~Pang-Ning_Tan1;~Jiayu_Zhou1,3;3;4;4,3;4;3;4,Reject,0,6,0.0,yes,9/28/20,Michigan State University;Michigan State University;Amazon;Michigan State University;Michigan State University,Anomaly Detection;Robustness,110;110;-1;110;110,105;105;-1;105;105,m;m,usa,usa,y,
7792,ICLR,2021,Neural Bayes: A Generic Parameterization Method for Unsupervised Learning,Devansh Arpit;Huan Wang;Caiming Xiong;richard socher;Yoshua Bengio,~Devansh_Arpit2;~Huan_Wang1;~Caiming_Xiong1;~richard_socher1;~Yoshua_Bengio1,4;5;4;5,3;4;4;5,Reject,0,0,0.0,yes,9/28/20,Salesforce Research;Yale University;Salesforce Research;SalesForce.com;University of Montreal,unsupervised learning;clustering;manifold separation;representation learning;Bayes rule,-1;71;-1;-1;128,-1;8;-1;-1;73,m;m,canada,ca,y,
7793,ICLR,2021,Momentum Contrastive Autoencoder,Devansh Arpit;Aadyot Bhatnagar;Huan Wang;Caiming Xiong,~Devansh_Arpit2;abhatnagar@salesforce.com;~Huan_Wang1;~Caiming_Xiong1,4;4;5;3,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,Salesforce Research;SalesForce.com;Yale University;Salesforce Research,generative model;contrastive learning;autoencoder;Wasserstein autoencoder,-1;-1;71;-1,-1;-1;8;-1,m;m,NAN,NAN,y,5
7794,ICLR,2021,Bayesian Meta-Learning for Few-Shot 3D Shape Completion ,Masanori Koyama;Toshiki Nakanishi;Shin-ichi Maeda;Vitor Campagnolo Guizilini;Adrien Gaidon,~Masanori_Koyama1;~Toshiki_Nakanishi1;~Shin-ichi_Maeda2;~Vitor_Campagnolo_Guizilini2;~Adrien_Gaidon1,4;7;5,4;4;4,Reject,0,6,0.0,yes,9/28/20,"Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.;Toyota Research Institute;Toyota Research Institute (TRI)",shape completion;Meta-learning;Few-shot;3D reconstruction,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;11
7795,ICLR,2021,"Convolutional Neural Networks are not invariant to translation, but they can learn to be",Valerio Biscione;Jeffrey Bowers,~Valerio_Biscione1;~Jeffrey_Bowers1,5;4;4,5;3;4,Reject,0,0,0.0,yes,9/28/20,University of Bristol;University of Bristol,Invariance;Convolutional Networks;Translation;Internal Representations,110;110,91;91,m;m,europe,uk,n,1
7796,ICLR,2021,Learning Axioms to Compute Verifiable Symbolic Expression Equivalence Proofs Using Graph-to-Sequence Networks,Steven James Kommrusch;Louis-Noel Pouchet;Theo Barolett,~Steven_James_Kommrusch1;~Louis-Noel_Pouchet2;theo.barolett@inria.fr,4;4;5;6,4;3;5;3,Reject,0,0,0.0,yes,9/28/20,Colorado State University;Colorado State University;Institut national de recherche en sciences et technologies du num‚àö¬©rique,Graph Neural Network;Symbolic Proofs;Graph-to-Sequence,453;453;-1,411;411;-1,m;m,NAN,NAN,n,1;10
7797,ICLR,2021,Deep Ensembles with Hierarchical Diversity Pruning,Yanzhao Wu;Ling Liu,~Yanzhao_Wu1;~Ling_Liu3,4;3;3;4,4;4;5;4,Reject,0,0,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Tech Research Corporation,Ensemble;Diversity Metrics;Hierarchical Pruning;Ensemble Accuracy;Deep Neural Networks,12;-1,38;-1,m;f,NAN,NAN,n,1
7798,ICLR,2021,Computing Preimages of Deep Neural Networks with Applications to Safety,Kyle Matoba;Fran√ßois Fleuret,~Kyle_Matoba1;~Fran√ßois_Fleuret2,3;4;3;2,4;3;4;5,Reject,0,6,0.0,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;University of Geneva,Deep neural networks;verification;interpretation;AI safety;ACAS,-1;-1,-1;149,m;m,NAN,NAN,y,
7799,ICLR,2021,Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning,Varun Badrinath Krishna,~Varun_Badrinath_Krishna1,4;4;4,5;5;3,Reject,0,0,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign",ballroom;sequence;deep;learning;machine;markov;prior,-1,-1,m,usa,usa,n,
7800,ICLR,2021,Adversarial and Natural Perturbations for General Robustness,Sadaf Gulshad;Jan Hendrik Metzen;Arnold W.M. Smeulders,~Sadaf_Gulshad1;~Jan_Hendrik_Metzen1;~Arnold_W.M._Smeulders1,4;4;4,5;4;4,Reject,0,0,0.0,yes,9/28/20,University of Amsterdam;Bosch Center Artificial Intelligence;;University of Amsterdam,Robustness;Adversarial Examples;Natural Perturbations;General Robustness,128;-1;-1;128,66;-1;-1;66,m;m,europe,nl,n,4
7801,ICLR,2021,Optimal allocation of data across training tasks in meta-learning,Georgios Batzolis;Alberto Bernacchia;Da-shan Shiu;Michael Bromberg;Alexandru Cioba,g.batz97@gmail.com;~Alberto_Bernacchia1;ds.shiu@mtkresearch.com;michael.bromberg@mtkresearch.com;alexandru.cioba@mtkresearch.com,6;4;4;4,4;3;3;4,Reject,0,4,0.0,yes,9/28/20,University of Cambridge;MedaiTek Research;University of California Berkeley;Mediatek Research;University of Cambridge,,79;-1;-1;-1;79,6;-1;7;-1;6,m;m,europe,uk,n,6;1
7802,ICLR,2021,Model agnostic meta-learning on trees,Jezabel Garcia;Federica Freddi;Jamie McGowan;Tim Nieradzik;Da-shan Shiu;Ye Tian;Alberto Bernacchia,jezabel.garcia@mtkresearch.com;federica.freddi@mtkresearch.com;j.mcgowan.18@ucl.ac.uk;tim@nieradzik.me;ds.shiu@mtkresearch.com;tiany.03@gmail.com;~Alberto_Bernacchia1,3;5;4;3,3;3;4;5,Reject,0,5,0.0,yes,9/28/20,Max Planck for Physics;;;University College London;;;University of California Berkeley;;;MedaiTek Research,Meta-learning;hierarchical data;clustering,-1;-1;-1;53;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;7;-1;-1;-1,f;m,NAN,NAN,n,6
7803,ICLR,2021,Provable Fictitious Play for General Mean-Field Games,Qiaomin Xie;Zhuoran Yang;Zhaoran Wang;Andreea Minca,~Qiaomin_Xie1;~Zhuoran_Yang1;~Zhaoran_Wang1;~Andreea_Minca1,5;5;3;5,3;3;5;5,Reject,0,5,0.0,yes,9/28/20,Cornell University;University of California Berkeley;Northwestern University;Cornell University,Mean-field games;Fictitious play;Entropy regularization;Nash equilibrium,7;-1;46;7,19;7;24;19,f;f,usa,usa,y,1
7804,ICLR,2021,On Representing (Anti)Symmetric Functions,Marcus Hutter,~Marcus_Hutter1,4;4;6;4,4;4;3;4,Reject,0,4,0.0,yes,9/28/20,DeepMind,Neural network;approximation;universality;Slater determinant;Vandermonde matrix;equivariance;symmetry;anti-symmetry;symmetric polynomials;polarized basis;multilayer perceptron;continuity;smoothness,-1,-1,m,NAN,NAN,y,2
7805,ICLR,2021,Anomaly detection in dynamical systems from measured time series,Andrei Ivanov;Anna Golovkina,~Andrei_Ivanov1;a.golovkina@spbu.ru,4;5;4,4;4;5,Reject,0,0,0.0,yes,9/28/20,DESY;St. Petersburg State University,dynamical systems;polynomial neural networks;anomaly detection,-1;-1,-1;-1,m;f,NAN,NAN,n,1
7806,ICLR,2021,Learning to Dynamically Select Between Reward Shaping Signals,Alexander Politowicz;Bing Liu,~Alexander_Politowicz1;~Bing_Liu1,5;2;4;4,3;5;4;4,Reject,0,0,0.0,yes,9/28/20,"University of Illinois, Chicago;University of Illinois at Chicago",selection;automatic;reward;shaping;reinforcement learning,-1;53,-1;276,m;m,usa,usa,n,
7807,ICLR,2021,Reinforcement Learning Based Asymmetrical DNN Modularization for Optimal Loading,Brijraj Singh;Yash Jain;Mayukh Das;Praveen Doreswamy Naidu,~Brijraj_Singh1;ya.jain@samsung.com;~Mayukh_Das1;praveen.dn@samsung.com,3;2;3;4,4;5;3;4,Reject,0,0,0.0,yes,9/28/20,Samsung;;;Samsung,DNN Compression;Loading time,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
7808,ICLR,2021,How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds,Prithviraj Ammanabrolu;Ethan Tien;Matthew Hausknecht;Mark Riedl,~Prithviraj_Ammanabrolu1;~Ethan_Tien1;~Matthew_Hausknecht1;~Mark_Riedl1,4;6;7;5,4;2;4;4,Reject,0,4,0.0,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology;Microsoft;Georgia Tech Research Corporation,text-based games;reinforcement learning;exploration;intrinsic motivation;knowledge graphs;question answering;natural language processing,12;12;-1;-1,38;38;-1;-1,m;m,NAN,NAN,n,3;10
7809,ICLR,2021,Revisiting Graph Neural Networks for Link Prediction,Muhan Zhang;Pan Li;Yinglong Xia;Kai Wang;Long Jin,~Muhan_Zhang1;~Pan_Li2;yxia@fb.com;wangkai@fb.com;longjin@fb.com,3;5;4;3,4;4;3;5,Reject,0,11,0.0,yes,9/28/20,Peking University;Purdue University;University of Southern California;;;Facebook,Graph Neural Networks;Link Prediction,14;23;37;-1;-1;-1,23;94;53;-1;-1;-1,m;m,NAN,NAN,y,10
7810,ICLR,2021,DarKnight: A Data Privacy Scheme for Training and Inference of Deep Neural Networks,Hanieh Hashemi;Yongqin Wang;Murali Annavaram,~Hanieh_Hashemi1;yongqin@usc.edu;~Murali_Annavaram1,4;5;5;3,4;4;3;3,Reject,0,5,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,Data Privacy;Information-theoretic Privacy;DNN Privacy;Trusted Execution Environment;Intel SGX,37;37;37,53;53;53,f;m,usa,usa,y,1
7811,ICLR,2021,Deep Convolution for Irregularly Sampled Temporal Point Clouds,Erich Merrill III;Stefan Lee;Li Fuxin;Thomas G Dietterich;Alan Fern,~Erich_Merrill_III1;~Stefan_Lee1;~Li_Fuxin1;~Thomas_G_Dietterich1;~Alan_Fern1,5;5;5;4,4;4;3;3,Reject,0,0,0.0,yes,9/28/20,Oregon State University;Oregon State University;Oregon State University;Oregon State University;Oregon State University,point cloud;convolution;irregular sampling;starcraft;nowcasting,79;79;79;79;79,424;424;424;424;424,m;m,usa,usa,n,
7812,ICLR,2021,Visualizing High-Dimensional Trajectories on the Loss-Landscape of ANNs,Stefan Horoi;Jessie Huang;Guy Wolf;Smita Krishnaswamy,~Stefan_Horoi1;jiexi.huang@yale.edu;~Guy_Wolf1;~Smita_Krishnaswamy1,6;4;5;5,5;4;4;4,Reject,0,4,0.0,yes,9/28/20,University of Montreal;Yale University;University of Montreal;Yale University,,128;71;128;71,73;8;73;8,m;f,europe,fi,n,1
7813,ICLR,2021,Fundamental Limits and Tradeoffs in Invariant Representation Learning,Han Zhao;Chen Dan;Bryon Aragam;Tommi S. Jaakkola;Geoff Gordon;Pradeep Kumar Ravikumar,~Han_Zhao1;~Chen_Dan1;~Bryon_Aragam1;~Tommi_S._Jaakkola1;~Geoff_Gordon2;~Pradeep_Kumar_Ravikumar1,5;5;5,1;3;2,Reject,0,6,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Carnegie Mellon University;University of Chicago;Massachusetts Institute of Technology;Microsoft;Carnegie Mellon University",Representation learning,-1;1;46;5;-1;1,-1;28;10;4;-1;28,m;m,usa,usa,y,1;7;4
7814,ICLR,2021,LINGUINE: LearnIng to pruNe on subGraph convolUtIon NEtworks,Yihan He;Wei Cao;Shun Zheng;Zhifeng Gao;Jiang Bian,~Yihan_He1;~Wei_Cao1;~Shun_Zheng1;~Zhifeng_Gao1;~Jiang_Bian1,3;3;4;5,3;4;5;3,Reject,0,4,0.0,yes,9/28/20,"New York University;Tsinghua University, Tsinghua University;Microsoft;Peking University;Microsoft",Graph Neural Networks;Meta-Learning;Pruning,23;4;-1;14;-1,26;20;-1;23;-1,f;m,NAN,NAN,n,10
7815,ICLR,2021,Improving Mutual Information based Feature Selection by Boosting Unique Relevance,Shiyu Liu;Mehul Motani,~Shiyu_Liu1;~Mehul_Motani1,2;4;4;8,5;5;5;3,Reject,0,6,0.0,yes,9/28/20,National University of Singapore;National University of Singapore,Feature Selection;Mutual Information;Unique Relevance,17;17,25;25,m;m,asia,sg,n,
7816,ICLR,2021,Using Synthetic Data to Improve the Long-range Forecasting of Time Series Data,Shiyu Liu;Mehul Motani,~Shiyu_Liu1;~Mehul_Motani1,5;5;6,4;3;4,Reject,0,5,0.0,yes,9/28/20,National University of Singapore;National University of Singapore,long-range time series data prediction;Generative Adversarial Network;Long Short-term Memory,17;17,25;25,m;m,asia,sg,n,5
7817,ICLR,2021,An Adversarial Attack via Feature Contributive Regions,Yaguan Qian;Jiamin Wang;Xiang Ling;Zhaoquan Gu;Bin Wang;Chunming Wu,qianyaguan@zust.edu.cn;~Jiamin_Wang1;~Xiang_Ling1;~Zhaoquan_Gu2;wbin2006@gmail.com;wuchunming@zju.edu.cn,3;5;3,4;4;2,Reject,0,0,0.0,yes,9/28/20,Zhejiang University of Science and Technology;;Zhejiang University;Guangzhou University  China  Tsinghua University;;Zhejiang University,Adversarial example;Feature contributive regions;Local attack,42;-1;42;4;-1;42,94;-1;94;20;-1;94,m;m,asia,cn,n,4
7818,ICLR,2021,"On Dropout, Overfitting, and Interaction Effects in Deep Neural Networks",Ben Lengerich;Eric Xing;Rich Caruana,~Ben_Lengerich1;~Eric_Xing1;~Rich_Caruana1,7;4;4,5;4;3,Reject,0,3,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University",Dropout;Interaction Effects;Neural Networks;Functional ANOVA,5;1;1,4;28;28,m;m,NAN,NAN,y,1
7819,ICLR,2021,Generalizing Tree Models for Improving Prediction Accuracy,Jaemin Yoo;Lee Sael,~Jaemin_Yoo1;sael@ajou.ac.kr,3;4;4;6,4;4;3;4,Reject,0,5,0.0,yes,9/28/20,Seoul National University;Ajou University,,37;-1,60;720,m;m,europe,tr,y,8
7820,ICLR,2021,Intervention Generative Adversarial Nets,Jiadong Liang;Liangyu Zhang;Cheng Zhang;Zhihua Zhang,~Jiadong_Liang1;~Liangyu_Zhang2;~Cheng_Zhang3;~Zhihua_Zhang1,3;6;2;7,5;3;5;4,Reject,0,0,0.0,yes,9/28/20,"Peking University;Center for Data Science, Peking University;Peking University;Shanghai Jiao Tong University",,14;14;14;29,23;23;23;100,m;m,asia,cn,y,5;4
7821,ICLR,2021,Why Does Decentralized Training Outperform Synchronous Training In The Large Batch Setting?,Wei Zhang;Mingrui Liu;Yu Feng;Brian Kingsbury;Yuhai Tu,~Wei_Zhang33;~Mingrui_Liu2;~Yu_Feng3;~Brian_Kingsbury1;~Yuhai_Tu1,5;3;3;6,4;5;4;3,Reject,0,6,0.0,yes,9/28/20,IBM  International Business Machines;Boston University;Duke University;IBM;IBM,Decentralized;Distributed Deep Learning;Large Batch,-1;79;46;453;453,-1;54;20;-1;-1,m;m,asia,in,n,2;1;9
7822,ICLR,2021,PGPS : Coupling Policy Gradient with Population-based Search,Namyong Kim;Hyunsuk Baek;Hayong Shin,~Namyong_Kim1;hisuk31@kaist.ac.kr;~Hayong_Shin1,5;5;3;5,4;3;4;4,Reject,0,0,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Arizona State University;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Population-based Search;Policy Gradient;Combining PG with PS,-1;85;-1,96;182;96,m;f,NAN,NAN,y,
7823,ICLR,2021,Imagine That! Leveraging Emergent Affordances for 3D Tool Synthesis,Yizhe Wu;Sudhanshu Kasewa;Oliver Groth;Sasha Salter;Kevin Li Sun;Oiwi Parker Jones;Ingmar Posner,~Yizhe_Wu1;~Sudhanshu_Kasewa1;~Oliver_Groth1;~Sasha_Salter1;~Kevin_Li_Sun1;~Oiwi_Parker_Jones1;~Ingmar_Posner1,5;4;4;4,3;3;5;5,Reject,0,2,0.0,yes,9/28/20,University of Oxford;University of Oxford;Google (DeepMind);University of Oxford;University of Sheffield;University of Oxford;University of Oxford,Affordance Learning;Imagination;Generative Models;Activation Maximisation,46;46;-1;46;209;46;46,1;1;-1;1;121;1;1,m;m,europe,uk,n,5
7824,ICLR,2021,Distributed Training of Graph Convolutional Networks using Subgraph Approximation,Alexandra Angerd;Keshav Balasubramanian;Murali Annavaram,~Alexandra_Angerd1;keshavba@usc.edu;~Murali_Annavaram1,5;4;5;4,4;5;4;4,Reject,0,0,0.0,yes,9/28/20,Chalmers University;University of Southern California;University of Southern California,,-1;37;37,235;53;53,f;m,usa,usa,n,10
7825,ICLR,2021,Translation Memory Guided Neural Machine Translation,Shaohui Kuang;Heng Yu;Weihua Luo;Qiang Wang,~Shaohui_Kuang1;~Heng_Yu1;weihua.luowh@alibaba-inc.com;~Qiang_Wang8,4;2;4;4,5;5;4;4,Reject,0,0,0.0,yes,9/28/20,"Alibaba Group;, Chinese Academy of Sciences;;Alibaba Group",neural machine translation;translation memory;pre-train language model,-1;34;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3
7826,ICLR,2021,3D Scene Compression through Entropy  Penalized Neural Representation Functions,Thomas Bird;Johannes Ball√©;Saurabh Singh;Philip Chou,~Thomas_Bird1;~Johannes_Ball√©1;~Saurabh_Singh1;~Philip_Chou1,5;5;4;4,4;2;3;5,Reject,0,6,0.0,yes,9/28/20,University College London;Google;Google;Stanford University,scene representation;compression;neural rendering;entropy coding,53;-1;-1;5,-1;-1;-1;2,m;m,usa,usa,n,
7827,ICLR,2021,Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion,Maria Schmidt;Alexander Bronstein,~Maria_Schmidt1;~Alexander_Bronstein1,3;3;4;3,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,"Technion, Technion;Technion",Deep learning;Non-Euclidean data completion;Sparse matrices;Recommender systems;Recommendation systems;Sparse representations,29;29,-1;408,f;m,europe,il,n,1;10
7828,ICLR,2021,Optimizing Large-Scale Hyperparameters via Automated Learning Algorithm,Bin Gu;Guodong Liu;Yanfu Zhang;Xiang Geng;Heng Huang,~Bin_Gu1;~Guodong_Liu2;~Yanfu_Zhang1;~Xiang_Geng1;~Heng_Huang1,4;5;4;3,4;4;4;5,Reject,0,4,0.0,yes,9/28/20,"University of Texas, Arlington;University of Pittsburgh;University of Pittsburgh;nanjing university;University of Pittsburgh",,-1;79;79;52;79,-1;133;133;111;133,m;m,usa,usa,y,
7829,ICLR,2021,Regularization Shortcomings for Continual Learning,Timothee LESORT;Andrei Stoian,~Timothee_LESORT1;andrei.stoian@thalesgroup.com,4;5;3;5,4;2;5;4,Reject,0,0,0.0,yes,9/28/20,Montreal Institute for Learning Algorithms  University of Montreal  University of Montreal; Thales,Continual Learning;Regularization,128;-1,73;-1,m;m,NAN,NAN,y,1
7830,ICLR,2021,Central Server Free Federated Learning over Single-sided Trust Social Networks,Chaoyang He;Conghui Tan;Hanlin Tang;Shuang Qiu;Ji Liu,~Chaoyang_He1;~Conghui_Tan1;htang14@ur.rochester.edu;~Shuang_Qiu2;~Ji_Liu1,4;4;5;8,3;4;3;5,Reject,0,5,0.0,yes,9/28/20,"University of Southern California;WeBank Co., Ltd.;;;University of Michigan;Kwai Inc.",,37;-1;-1;-1;7;-1,53;-1;-1;-1;22;-1,m;m,NAN,NAN,y,1
7831,ICLR,2021,Fair Differential Privacy Can Mitigate the Disparate Impact on Model Accuracy,Wenyan Liu;Xiangfeng Wang;Xingjian Lu;Junhong Cheng;Bo Jin;Xiaoling Wang;Hongyuan Zha,~Wenyan_Liu1;~Xiangfeng_Wang1;xjlu@cs.ecnu.edu.cn;jhcheng@stu.ecnu.edu.cn;~Bo_Jin1;xlwang@cs.ecnu.edu.cn;~Hongyuan_Zha1,4;4;4;5,3;4;4;3,Reject,0,5,0.0,yes,9/28/20,"East China Normal University;East China Normal University;;;;;East China Normal University;;;The Chinese University of Hong Kong, Shenzhen",,-1;-1;-1;-1;-1;-1;-1;-1;-1;46,387;387;-1;-1;-1;-1;387;-1;-1;39,f;m,NAN,NAN,n,1;7
7832,ICLR,2021,"MixSize: Training Convnets With Mixed Image Sizes for Improved Accuracy, Speed and Scale Resiliency",Elad Hoffer;Berry Weinstein;Itay Hubara;Tal Ben-Nun;Torsten Hoefler;Daniel Soudry,~Elad_Hoffer1;~Berry_Weinstein1;~Itay_Hubara1;~Tal_Ben-Nun1;htor@inf.ethz.ch;~Daniel_Soudry1,5;5;5;5,3;5;4;5,Reject,0,6,0.0,yes,9/28/20,"Habana Labs (Intel);interdisciplinary center herzliya;Technion, Technion;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Technion - Israel Institute of Technology",,-1;-1;29;-1;-1;29,-1;-1;-1;-1;-1;408,m;m,NAN,NAN,n,
7833,ICLR,2021,Structure Controllable Text Generation,Liming DENG;Long WANG;Binzhu WANG;Jiang Qian;Bojin Zhuang;Shaojun Wang;Jing Xiao,~Liming_DENG1;wanglong137@pingan.com.cn;wangbinzhu86@gmail.com;~Jiang_Qian1;~Bojin_Zhuang2;~Shaojun_Wang1;~Jing_Xiao3,3;2;2;5,4;5;5;4,Reject,0,0,0.0,yes,9/28/20,Pingan Technology;;;University of Edinburgh;Pingan Technology;tes;PAII Inc.;Pingan Group,Natural language generation;structure representation;structure controlling;conditional language model;structure aware transformer,-1;-1;-1;29;-1;-1;-1;-1,-1;-1;-1;30;-1;318;-1;-1,f;f,NAN,NAN,n,8
7834,ICLR,2021,MCM-aware Twin-least-square GAN for Hyperspectral Anomaly Detection,Jiaping Zhong;Weiying Xie;Jie Lei;Yunsong Li;Zan Li,jpzhong@stu.xidian.edu.cn;~Weiying_Xie1;jielei@mail.xidian.edu.cn;~Yunsong_Li1;zanli@xidian.edu.cn,4;5;5,4;4;4,Reject,0,0,0.0,yes,9/28/20,Xidian University;Xidian University;;;Xidian University,Multiscale covariance map (MCM);least square loss;hyperspectral anomaly detection;generative adversarial network (GAN),-1;-1;-1;-1;-1,924;924;-1;-1;924,f;m,asia,cn,n,8;5;4
7835,ICLR,2021,Deep Networks from the Principle of Rate Reduction,Kwan Ho Ryan Chan;Yaodong Yu;Chong You;Haozhi Qi;John Wright;Yi Ma,ryanchankh@berkeley.edu;~Yaodong_Yu4;~Chong_You2;~Haozhi_Qi1;~John_Wright1;~Yi_Ma4,4;6;9;6;6,3;3;3;2;4,Reject,0,9,0.0,yes,9/28/20,"Lawrence Livermore National Labs;Electrical Engineering & Computer Science Department, University of California Berkeley;Google;University of California Berkeley;Columbia University;University of California Berkeley",,-1;-1;-1;-1;23;-1,-1;-1;-1;7;17;7,m;m,usa,usa,n,1
7836,ICLR,2021,Learning Robust Models by Countering Spurious Correlations,Haohan Wang;Zeyi Huang;Eric Xing,~Haohan_Wang1;~Zeyi_Huang3;~Eric_Xing1,3;5;6;4,4;3;4;2,Reject,0,1,0.0,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,robustness;domain adaptation;spurious correlation;dataset bias,1;1;1,28;28;28,m;m,usa,usa,y,1
7837,ICLR,2021,On the Consistency Loss for Leveraging Augmented Data to Learn Robust and Invariant Representations,Haohan Wang;Zeyi Huang;Xindi Wu;Eric Xing,~Haohan_Wang1;~Zeyi_Huang3;~Xindi_Wu1;~Eric_Xing1,6;4;6,3;3;4,Reject,0,5,0.0,yes,9/28/20,"Carnegie Mellon University;Carnegie Mellon University;CMU, Carnegie Mellon University;Carnegie Mellon University",robustness;invariance;data augmentation;consistency loss,1;1;1;1,28;28;28;28,m;m,usa,usa,y,
7838,ICLR,2021,Natural World Distribution via Adaptive Confusion Energy Regularization,Yen-Chi Hsu;Cheng-Yao Hong;Wan-Cyuan Fan;Ding-Jie Chen;Ming-Sui Lee;davi geiger;Tyng-Luh Liu,~Yen-Chi_Hsu1;~Cheng-Yao_Hong2;~Wan-Cyuan_Fan1;~Ding-Jie_Chen1;~Ming-Sui_Lee1;~davi_geiger1;~Tyng-Luh_Liu1,4;5;4;5,3;4;5;5,Reject,0,4,0.0,yes,9/28/20,"Department of computer science and informational engineering, National Taiwan University;Academia Sinica;National Taiwan University;Academia Sinica;Department of computer science and informational engineering, National Taiwan University;New York University;IIS/Academia Sinica",Fine-Grained Visual Classification;long-tailed distribution;confusion energy,99;-1;99;-1;99;23;-1,-1;-1;97;-1;-1;26;-1,m;m,NAN,NAN,n,8
7839,ICLR,2021,Oblivious Sketching-based Central Path Method for Solving Linear Programming Problems,Zhao Song;Zheng Yu,~Zhao_Song3;~Zheng_Yu1,7;4;4;5,3;3;4;3,Reject,0,6,0.0,yes,9/28/20,Institue for Advanced Study;Princeton University,optimization;sketching;linear programming;central path method;running time complexity,-1;29,-1;9,m;m,usa,usa,y,9
7840,ICLR,2021,Empirical Sufficiency Featuring Reward Delay Calibration,Yixuan Liu;Hu Wang;Xiaowei Wang;Xiaoyue Sun;Liuyue Jiang;Minhui Xue,~Yixuan_Liu1;~Hu_Wang1;xiaowei.wang01@student.adelaide.edu.au;a1782027@student.adelaide.edu.au;liuyue.jiang@adelaide.edu.au;jason.xue@adelaide.edu.au,5;4;4;4,3;4;3;3,Reject,0,4,0.0,yes,9/28/20,The University of Adelaide;The University of Adelaide;The University of Adelaide;;;;;The University of Adelaide,Deep Reinforcement Learning;Reward Calibration;Empirical Sufficiency;Overfitting.,110;110;110;-1;-1;-1;-1;110,118;118;118;-1;-1;-1;-1;118,f;m,NAN,NAN,n,
7841,ICLR,2021,KETG: A Knowledge Enhanced Text Generation Framework,Yan Cui;Xi Chen;Jiang Qian;Bojin Zhuang;Shaojun Wang;Jing Xiao,~Yan_Cui3;chx_1988@163.com;~Jiang_Qian1;~Bojin_Zhuang2;~Shaojun_Wang1;~Jing_Xiao3,2;3;2;2,4;4;5;4,Reject,0,0,0.0,yes,9/28/20,Beijing Institute of Technology;;;Pingan Technology;tes;PAII Inc.;Pingan Group,text generation;knowledge graph,-1;-1;-1;-1;-1;-1;-1,584;-1;-1;-1;318;-1;-1,u;f,NAN,NAN,n,8;3;10
7842,ICLR,2021,Multi-Source Unsupervised Hyperparameter Optimization,Masahiro Nomura;Yuta Saito,~Masahiro_Nomura1;~Yuta_Saito1,6;5;6;3,3;4;4;3,Reject,0,7,0.0,yes,9/28/20,"CyberAgent, Inc.;Cornell University",Hyperparameter Optimization,-1;7,-1;19,m;m,usa,usa,y,
7843,ICLR,2021,Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations,Weihao Gao;Xiangjun Fan;Jiankai Sun;Kai Jia;Wenzhi Xiao;Chong Wang;Xiaobing Liu,~Weihao_Gao1;xiangjun.fan@bytedance.com;jiankai.sun@bytedance.com;jiakai@bytedance.com;xiaowenzhi@bytedance.com;~Chong_Wang8;~Xiaobing_Liu1,3;5;4;4,5;3;3;4,Reject,0,0,0.0,yes,9/28/20,University of Illinois  Urbana Champaign;;;;;;ByteDance Inc,Large-scale recommendation system;End-to-end training,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7844,ICLR,2021,ROGA: Random Over-sampling Based on Genetic Algorithm,ZONGDA HAN;XIUQUAN QIAO;SHUBO ZHAN,~ZONGDA_HAN1;qiaoxq@bupt.edu.cn;zhanshubo@cincc.cn,3;5;3;4,5;4;4;3,Reject,0,0,0.0,yes,9/28/20,Beijing University of Post and Telecommunication  Tsinghua University;;Tsingua University,class imbalance;over-sampling;genetic algorithm,4;-1;4,20;-1;20,m;m,asia,cn,n,
7845,ICLR,2021,Streaming Probabilistic Deep Tensor Factorization,shikai fang;Zheng Wang;Zhimeng pan;Ji Liu;Shandian Zhe,~shikai_fang1;~Zheng_Wang2;z.pan@utah.edu;~Ji_Liu1;~Shandian_Zhe1,6;5;6;5,3;3;2;4,Reject,0,4,0.0,yes,9/28/20,University of Utah;University of Utah;University of Utah;Kwai Inc.;University of Utah,Probabilistic Methods;online learing;tensor factorization,58;58;58;-1;58,239;239;239;-1;239,m;m,europe,uk,n,11
7846,ICLR,2021,Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness,Ke Sun;Mingjie Li;Zhouchen Lin,~Ke_Sun3;~Mingjie_Li1;~Zhouchen_Lin1,5;3;6,3;4;4,Reject,0,3,0.0,yes,9/28/20,University of Alberta;Peking University;Peking University,,110;14;14,131;23;23,m;m,asia,cn,y,1;4
7847,ICLR,2021,BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network,Zhixian Chen;Tengfei Ma;Zhihua Jin;Yangqiu Song;Yang Wang,~Zhixian_Chen1;~Tengfei_Ma1;~Zhihua_Jin1;~Yangqiu_Song1;yangwang@ust.hk,5;4;6;5,3;5;3;3,Reject,0,4,0.0,yes,9/28/20,The Hong Kong University of Science and Technology;International Business Machines;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Graph convolutional networks;graph filtering;Laplacian smooth;ADMM,-1;-1;-1;-1;-1,56;-1;56;56;56,f;m,NAN,NAN,n,10
7848,ICLR,2021,Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data,Bing Yu;Ke Sun;He Wang;Zhouchen Lin;Zhanxing Zhu,~Bing_Yu1;~Ke_Sun3;~He_Wang6;~Zhouchen_Lin1;~Zhanxing_Zhu1,5;6;6,3;4;4,Reject,0,3,0.0,yes,9/28/20,Peking University;University of Alberta;University of Leeds;Peking University;Peking University,,14;110;209;14;14,23;131;160;23;23,m;m,asia,cn,y,5;4
7849,ICLR,2021,Entropic Risk-Sensitive Reinforcement Learning: A Meta Regret Framework with Function Approximation,Yingjie Fei;Zhuoran Yang;Zhaoran Wang,~Yingjie_Fei1;~Zhuoran_Yang1;~Zhaoran_Wang1,6;5;4;5,3;3;4;2,Reject,0,4,0.0,yes,9/28/20,Cornell University;University of California Berkeley;Northwestern University,,7;-1;46,19;7;24,m;m,usa,usa,y,
7850,ICLR,2021,SEMANTIC APPROACH TO AGENT ROUTING USING A HYBRID ATTRIBUTE-BASED RECOMMENDER SYSTEM,Anwitha Paruchuri,~Anwitha_Paruchuri1,2;2;3,5;5;5,Reject,0,0,0.0,yes,9/28/20,Cornell University,Hybrid Recommendation;Customer Relationship Management;Semantic Embedding;Approximate Nearest Neighbor,7,19,f,usa,usa,n,
7851,ICLR,2021,"Deep Learning is Singular, and That's Good",Daniel Murfet;Susan Wei;Mingming Gong;Hui Li;Jesse Gell-Redman;Thomas Quella,~Daniel_Murfet1;~Susan_Wei1;~Mingming_Gong1;huli2@student.unimelb.edu.au;j.gell@unimelb.edu.au;thomas.quella@unimelb.edu.au,4;4;4;5,1;3;5;3,Reject,0,4,0.0,yes,9/28/20,The University of Melbourne;The University of Melbourne;The University of Melbourne;;;;;The University of Melbourne,deep learning theory;effective degrees of freedom;generalisation;posterior predictive distribution;real log canonical threshold;singular learning theory,85;85;85;-1;-1;-1;-1;85,31;31;31;-1;-1;-1;-1;31,m;m,NAN,NAN,y,1
7852,ICLR,2021,Better Together: Resnet-50 accuracy with $13 \times $ fewer parameters and at $3 \times $ speed,Utkarsh Nath;Shrinu Kushagra,un270@nyu.edu;~Shrinu_Kushagra1,4;6;4;5;5,4;3;4;3;4,Reject,0,5,0.0,yes,9/28/20,New York University;University of Waterloo,Deep neural networks;Theory of deep networks;deep regularization;Neural network compression,23;34,26;232,m;m,canada,ca,n,1
7853,ICLR,2021,Semi-Supervised Audio Representation Learning for Modeling Beehive Strengths,Tony Zhang;Szymon Zmyslony;Sergei Nozdrenkov;Matthew Smith;Brandon Kingsley Hopkins,~Tony_Zhang2;szymek@google.com;nsv@google.com;matthsmith@google.com;bhopkins@wsu.edu,4;3;5,5;4;3,Reject,0,1,0.0,yes,9/28/20,California Institute of Technology;;;;Washington State University,bee;beehive;audio;sound;computational ethology;deep learning;representation learning;semi-supervised learning;modeling;population;disease,150;-1;-1;-1;174,4;-1;-1;-1;323,m;m,usa,usa,n,
7854,ICLR,2021,Decoupled Greedy Learning of Graph Neural Networks,YEWEN WANG;Jian Tang;Yizhou Sun;Guy Wolf,~YEWEN_WANG1;~Jian_Tang1;~Yizhou_Sun1;~Guy_Wolf1,6;4;4,5;4;4,Reject,0,3,0.0,yes,9/28/20,"University of California, Los Angeles;HEC Montreal;University of California, Los Angeles;University of Montreal",,-1;-1;-1;128,15;-1;15;73,f;m,canada,ca,n,10
7855,ICLR,2021,Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object Detection,Yurong You;Carlos Andres Diaz-Ruiz;Yan Wang;Wei-Lun Chao;Bharath Hariharan;Mark Campbell;Kilian Q Weinberger,~Yurong_You1;~Carlos_Andres_Diaz-Ruiz1;~Yan_Wang10;~Wei-Lun_Chao1;~Bharath_Hariharan3;~Mark_Campbell1;~Kilian_Q_Weinberger1,6;6;6;4,5;3;4;4,Reject,0,5,0.0,yes,9/28/20,Cornell University;Cornell University;Cornell University;Ohio State University;Cornell University;Cornell University;Cornell University,Unsupervised domain adaptation;3D vision;object detection;autonomous driving,7;7;7;58;7;7;7,19;19;19;78;19;19;19,m;m,usa,usa,n,
7856,ICLR,2021,Real-Time AutoML,Iddo Drori;Brandon Kates;Anant Kharkar;Lu Liu;Qiang Ma;Jonah Deykin;Nihar Sidhu;Madeleine Udell,~Iddo_Drori1;bjk224@cornell.edu;agk2151@columbia.edu;ll3252@columbia.edu;~Qiang_Ma3;jd3599@columbia.edu;ns625@cornell.edu;~Madeleine_Udell1,4;4;2;4;4,5;4;5;4;4,Reject,0,1,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Department of Computer Science, Cornell University;Columbia University;Columbia University;Columbia University;;;;;Cornell University",Automated machine learning;zero-shot learning;graph neural networks;transformers,5;7;23;23;23;-1;-1;-1;-1;7,4;19;17;17;17;-1;-1;-1;-1;19,m;f,usa,usa,n,6;8;3;10
7857,ICLR,2021,Channel-Directed Gradients for Optimization of Convolutional Neural Networks,Dong Lao;Peihao Zhu;Peter Wonka;Ganesh Sundaramoorthi,~Dong_Lao1;~Peihao_Zhu1;~Peter_Wonka2;~Ganesh_Sundaramoorthi1,6;5;6;4;6,1;5;3;3;2,Reject,0,6,0.0,yes,9/28/20,KAUST;KAUST;KAUST;KAUST,stochastic optimization;Riemannian geometry;Riemannian gradient flows;convolutional neural nets,110;110;110;110,-1;-1;-1;-1,m;m,europe,gr,n,1
7858,ICLR,2021,A Lazy Approach to Long-Horizon Gradient-Based Meta-Learning,Muhammad Abdullah Jamal;Liqiang Wang;Boqing Gong,~Muhammad_Abdullah_Jamal2;~Liqiang_Wang1;~Boqing_Gong1,5;7;5;4,4;3;4;4,Reject,0,4,0.0,yes,9/28/20,University of Central Florida;University of Central Florida;International Computer Science Institute,meta-learning;learning to learn,71;71;-1,633;633;-1,m;m,NAN,NAN,n,6;10;4
7859,ICLR,2021,Predicting Video with VQVAE,Jacob C Walker;Ali Razavi;Aaron van den Oord,~Jacob_C_Walker1;~Ali_Razavi1;~Aaron_van_den_Oord2,4;4;3;4,3;4;5;4,Reject,0,5,0.0,yes,9/28/20,Carnegie Mellon University;Deepmind;Google,Generative Models;Video Generation;Video Forecasting;Autoregressive Models;VQVAE;Computer Vision,1;-1;-1,28;-1;-1,m;m,NAN,NAN,n,8;5
7860,ICLR,2021,Delay-Tolerant Local SGD for Efficient Distributed Training,An Xu;Xiao Yan;Hongchang Gao;Heng Huang,~An_Xu1;~Xiao_Yan2;~Hongchang_Gao1;~Heng_Huang1,5;4;5;5,4;4;3;4,Reject,0,0,0.0,yes,9/28/20,"University of Pittsburgh;Department of Computer Science and Engineering, Southern University of Science and Technology;University of Pittsburgh;University of Pittsburgh",Delay-tolerant;communication-efficient;distributed learning,79;-1;79;79,133;-1;133;133,m;m,usa,usa,y,9
7861,ICLR,2021,WAFFLe: Weight Anonymized Factorization for Federated Learning,Weituo Hao;Nikhil Mehta;Kevin J Liang;Pengyu Cheng;Mostafa El-Khamy;Lawrence Carin,~Weituo_Hao1;~Nikhil_Mehta1;~Kevin_J_Liang1;~Pengyu_Cheng1;~Mostafa_El-Khamy1;~Lawrence_Carin2,5;4;6,5;4;3,Reject,0,3,0.0,yes,9/28/20,Duke University;Duke University;Facebook;Duke University;;Duke University,Federated Learning;Fairness;Privacy,46;46;-1;46;-1;46,20;20;-1;20;-1;20,m;m,europe,se,n,7;4
7862,ICLR,2021,Empirically Verifying Hypotheses Using Reinforcement Learning,Kenneth Marino;Rob Fergus;Arthur Szlam;Abhinav Gupta,~Kenneth_Marino1;~Rob_Fergus1;~Arthur_Szlam1;~Abhinav_Gupta1,3;3;5;4,4;3;3;4,Reject,0,4,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;New York University;CUNY City College;Facebook",,1;23;263;-1,28;26;-1;-1,m;m,NAN,NAN,n,
7863,ICLR,2021,TraDE: A Simple Self-Attention-Based Density Estimator,Rasool Fakoor;Pratik Anil Chaudhari;Jonas Mueller;Alex Smola,~Rasool_Fakoor1;~Pratik_Anil_Chaudhari1;~Jonas_Mueller1;~Alex_Smola1,3;4;5,5;4;4,Reject,0,5,0.0,yes,9/28/20,"Amazon;School of Engineering and Applied Science, University of Pennsylvania;Amazon;Carnegie-Mellon University",density estimation;self-attention,-1;20;-1;1,-1;13;-1;28,m;m,usa,usa,n,8;10
7864,ICLR,2021,Trojans and Adversarial Examples: A Lethal Combination,Guanxiong Liu;Issa Khalil;Abdallah Khreishah;Hai Phan,~Guanxiong_Liu1;ikhalil@hbku.edu.qa;~Abdallah_Khreishah1;~Hai_Phan1,7;5;6;4,4;4;5;5,Reject,0,7,0.0,yes,9/28/20,New Jersey Institute of Technology;Hamad Bin Khalifa University;New Jersey Institute of Technology;New Jersey Institute of Technology,,-1;-1;-1;-1,570;389;570;570,m;m,NAN,NAN,n,4
7865,ICLR,2021,Analogical Reasoning for Visually Grounded Compositional Generalization,Bo Wu;Haoyu Qin;Alireza Zareian;Carl Vondrick;Shih-Fu Chang,~Bo_Wu6;~Haoyu_Qin1;~Alireza_Zareian2;~Carl_Vondrick2;~Shih-Fu_Chang3,3;5;7,3;4;4,Reject,0,9,0.0,yes,9/28/20,MIT-IBM Watson AI Lab;Columbia University;Columbia University;Columbia University;Amazon,,-1;23;23;23;-1,-1;17;17;17;-1,m;m,NAN,NAN,n,8;1
7866,ICLR,2021,Guiding Representation Learning in Deep Generative Models with Policy Gradients,Luca Lach;Timo Korthals;Malte Schilling;Helge Ritter,~Luca_Lach1;~Timo_Korthals1;~Malte_Schilling1;~Helge_Ritter1,2;4;3;1,4;4;5;5,Reject,0,0,0.0,yes,9/28/20,"Bielefeld University;Bielefeld University, CITEC;;Bielefeld University",VAE;RL;PPO,327;327;-1;327,158;158;-1;158,m;m,europe,de,n,5
7867,ICLR,2021,Predicting What You Already Know Helps: Provable Self-Supervised Learning,Jason D. Lee;Qi Lei;Nikunj Saunshi;Jiacheng Zhuo,~Jason_D._Lee1;~Qi_Lei1;~Nikunj_Saunshi1;~Jiacheng_Zhuo1,6;6;6;6;6,3;3;5;3;3,Reject,0,8,0.0,yes,9/28/20,"Princeton University;Princeton University;Princeton University;University of Texas, Austin",theory;self-supervised learning;representation learning;unsupervised learning;conditional independence,29;29;29;-1,9;9;9;-1,m;m,usa,usa,y,
7868,ICLR,2021,Discrete Predictive Representation for Long-horizon Planning,Thanard Kurutach;Julia Peng;Yang Gao;Stuart Russell;Pieter Abbeel,~Thanard_Kurutach1;~Julia_Peng1;~Yang_Gao1;~Stuart_Russell1;~Pieter_Abbeel2,4;4;4;4,4;4;4;4,Reject,0,0,0.0,yes,9/28/20,"University of California Berkeley;University of California Berkeley;Tsinghua University, Tsinghua University;University of California - Berkeley;Covariant",Discrete Representation;Learning and Planning;Model-based RL;Hierarchical RL,-1;-1;4;-1;-1,7;7;20;7;-1,m;m,NAN,NAN,n,
7869,ICLR,2021,Non-Local Graph Neural Networks,Meng Liu;Zhengyang Wang;Shuiwang Ji,~Meng_Liu3;~Zhengyang_Wang1;~Shuiwang_Ji1,6;7;4;7,5;2;4;5,Reject,0,10,0.0,yes,9/28/20,Texas A&M;Amazon;Texas A&M University,Graph Neural Networks;Non-Local Aggregation;Attention;Disassortative Graph,46;-1;46,195;-1;195,f;m,usa,usa,n,8;10
7870,ICLR,2021,EMTL: A Generative Domain Adaptation Approach,Jianfeng Zhang;Illyyne Saffar;Aladin Virmaux;Bal√°zs K√©gl,~Jianfeng_Zhang2;~Illyyne_Saffar1;~Aladin_Virmaux1;~Bal√°zs_K√©gl2,3;4;5;3,5;3;4;5,Reject,0,5,0.0,yes,9/28/20,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei France,unsupervised domain adaptation;EM;generative model;density estimation;deep learning;transfer learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,5
7871,ICLR,2021,DynamicVAE: Decoupling Reconstruction Error and Disentangled Representation Learning,Huajie Shao;Haohong Lin;Qinmin Yang;Shuochao Yao;Han Zhao;Tarek Abdelzaher,~Huajie_Shao1;lhh2017@zju.edu.cn;qmyang@zju.edu.cn;~Shuochao_Yao1;~Han_Zhao1;~Tarek_Abdelzaher1,4;4;4;4,4;5;4;5,Reject,0,0,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Zhejiang University, Tsinghua University;;;George Mason University;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",disentangled representation learning;dynamic learning;Variational Autoencoder;PID contoller,-1;4;-1;-1;85;-1;-1,-1;20;-1;-1;267;-1;-1,m;m,usa,usa,y,1;5
7872,ICLR,2021,MULTI-SPAN QUESTION ANSWERING USING SPAN-IMAGE NETWORK,Tarik Arici;Hayreddin Ceker;Ismail Baha Tutar,aricit@amazon.com;~Hayreddin_Ceker1;ismailt@amazon.com,5;4;1;3,3;4;5;4,Reject,0,0,0.0,yes,9/28/20,Amazon;;Amazon,BERT;deep learning;multi-span answer;question-answering;SQuAD;transformers,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,3
7873,ICLR,2021,Learning Discrete Adaptive Receptive Fields for Graph Convolutional Networks,Xiaojun Ma;Ziyao Li;Lingjun Xu;Guojie Song;Yi Li;Chuan Shi,mxj@pku.edu.cn;~Ziyao_Li1;xlj_rk@pku.edu.cn;~Guojie_Song1;liyi2015@pku.edu.cn;shichuan@bupt.edu.cn,5;5;5;5,5;4;2;4,Reject,0,6,0.0,yes,9/28/20,Peking University;;;;; Beijing University of Posts and Telecommunications,Graph Neural Networks;Reinforcement Learning;Attention Mechanism;Adaptive Receptive Fields,14;-1;-1;-1;-1;-1,23;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,8;1;10
7874,ICLR,2021,PanRep: Universal node embeddings for heterogeneous graphs,Vassilis N. Ioannidis;Da Zheng;George Karypis,~Vassilis_N._Ioannidis1;dzzhen@amazon.com;~George_Karypis1,6;5;4;5,3;4;5;4,Reject,0,0,0.0,yes,9/28/20,"University of Minnesota, Minneapolis;;;University of Minnesota-Twin Cities",Graph neural networks;universal node embeddings;node classification;link prediction;unsupervised learning,71;-1;-1;71,85;-1;-1;85,m;m,NAN,NAN,n,10
7875,ICLR,2021,Discriminative Cross-Modal Data Augmentation for Medical Imaging Applications,Yue Yang;Pengtao Xie,~Yue_Yang2;~Pengtao_Xie3,5;4;5;6,4;4;4;5,Reject,0,0,0.0,yes,9/28/20,"Northeastern University;University of California, San Diego",Deep learning;Medical imaging;Cross-Modal Learning,16;-1,895;33,m;m,usa,usa,n,
7876,ICLR,2021,Adversarial Attacks on Binary Image Recognition Systems,Eric Balkanski;Harrison Chase;Kojin Oshiba;Alexander Rilee;Yaron Singer;Richard Wang,~Eric_Balkanski2;harrison@robustintelligence.com;kojin@robustintelligence.com;rilee@robustintelligence.com;yaron@robustintelligence.com;richard@robustintelligence.com,5;5;5;7,3;3;2;3,Reject,0,4,0.0,yes,9/28/20,Columbia University;;;;;;;;;Robust Intelligence,Adversarial attacks;Binary images;Image Recognition;Check processing systems,23;-1;-1;-1;-1;-1;-1;-1;-1;-1,17;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,4
7877,ICLR,2021,News-Driven Stock Prediction Using Noisy Equity State Representation,Xiao Liu;Heyan Huang;Yue Zhang,~Xiao_Liu14;hhy63@bit.edu.cn;yue.zhang@wias.org.cn,5;5;6,4;4;4,Reject,0,0,0.0,yes,9/28/20,Beijing Institute of Technology;;Westlake Institute for Advanced Study,news-driven stock prediction;equity state representation;recurrent state transition,-1;-1;-1,584;-1;-1,m;m,NAN,NAN,n,
7878,ICLR,2021,Abductive Knowledge Induction from Raw Data,Wang-Zhou Dai;Stephen Muggleton,~Wang-Zhou_Dai2;~Stephen_Muggleton1,5;3;4;4,4;4;5;4,Reject,0,12,0.0,yes,9/28/20,Imperial College London;Imperial College London,Neural-Symbolic Model;Inductive Logic Programming;Abduction,53;53,11;11,m;m,europe,uk,n,
7879,ICLR,2021,Signed Graph Diffusion Network,Jinhong Jung;Jaemin Yoo;U Kang,~Jinhong_Jung1;~Jaemin_Yoo1;~U_Kang1,4;6;4;7,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,Chonbuk National University;Seoul National University;Seoul National University,graph neural network;signed graph analysis;representation learning;graph diffusion;random walk;link sign prediction,-1;37;37,1037;60;60,m;m,asia,kr,y,8;10
7880,ICLR,2021,Can We Use Gradient Norm as a Measure of Generalization Error for Model Selection in Practice?,Haozhe An;Haoyi Xiong;Xuhong Li;Xingjian Li;Dejing Dou;Zhanxing Zhu,~Haozhe_An1;~Haoyi_Xiong1;~Xuhong_Li3;~Xingjian_Li1;~Dejing_Dou1;~Zhanxing_Zhu1,4;4;6;4,4;4;3;3,Reject,0,6,0.0,yes,9/28/20,"University of Maryland, College Park;Baidu;Baidu;Baidu;University of Oregon Eugene;Peking University",,12;-1;-1;-1;209;14,90;-1;-1;-1;346;23,m;m,asia,cn,n,1
7881,ICLR,2021,Einstein VI:   General and Integrated Stein Variational Inference in NumPyro,Ahmad Salim Al-Sibahi;Ola R√∏nning;Christophe Ley;Thomas Wim Hamelryck,~Ahmad_Salim_Al-Sibahi1;ola@di.ku.dk;christophe.ley@ugent.be;thamelry@binf.ku.dk,3;4;5;5,4;4;4;3,Reject,0,7,0.0,yes,9/28/20,University of Copenhagen;;;University of Copenhagen,Stein variational inference;variational inference;probabilistic programming;Pyro;deep probabilistic programming;deep learning,92;-1;-1;92,84;-1;-1;84,m;m,europe,dk,n,11
7882,ICLR,2021,Implicit Regularization Effects of Unbiased Random Label Noises with SGD,Haoyi Xiong;Xuhong Li;Boyang Yu;Dejing Dou;Dongrui Wu;Zhanxing Zhu,~Haoyi_Xiong1;~Xuhong_Li3;~Boyang_Yu1;~Dejing_Dou1;~Dongrui_Wu1;~Zhanxing_Zhu1,3;4;2;3,3;4;5;4,Reject,0,1,0.0,yes,9/28/20,"Baidu;Baidu;Jilin University;University of Oregon Eugene;Huazhong University of Science and Technology, Tsinghua University;Peking University",,-1;-1;-1;209;4;14,-1;-1;998;346;20;23,m;m,asia,cn,y,1
7883,ICLR,2021,Suppressing Outlier Reconstruction in Autoencoders for Out-of-Distribution Detection,Sangwoong Yoon;Yung-Kyun Noh;Frank C. Park,~Sangwoong_Yoon1;~Yung-Kyun_Noh1;~Frank_C._Park1,4;5;5;4,5;4;4;4,Reject,0,0,0.0,yes,9/28/20,Seoul National University;Hanyang University;;Seoul National University,autoencoder;outlier detection;novelty detection;energy-based model,37;209;-1;37,60;380;-1;60,m;m,asia,kr,n,5
7884,ICLR,2021,Neighborhood-Aware Neural Architecture Search,Xiaofang Wang;Shengcao Cao;Mengtian Li;Kris M. Kitani,~Xiaofang_Wang1;~Shengcao_Cao1;~Mengtian_Li1;~Kris_M._Kitani1,6;6;4;5,4;4;5;3,Reject,0,5,0.0,yes,9/28/20,"Carnegie Mellon University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University",Neural architecture search;Flat minima,1;1;1;1,28;28;28;28,m;m,usa,usa,n,1
7885,ICLR,2021,ForceNet: A Graph Neural Network for Large-Scale Quantum Chemistry Simulation,Weihua Hu;Muhammed Shuaibi;Abhishek Das;Siddharth Goyal;Anuroop Sriram;Jure Leskovec;Devi Parikh;Larry Zitnick,~Weihua_Hu1;~Muhammed_Shuaibi1;~Abhishek_Das1;~Siddharth_Goyal2;~Anuroop_Sriram1;~Jure_Leskovec1;~Devi_Parikh1;~Larry_Zitnick1,6;7;5;7,4;4;5;5,Reject,0,5,0.0,yes,9/28/20,Stanford University;Carnegie Mellon University;Facebook AI Research;Carnegie Mellon University;Facebook;Stanford University;Georgia Institute of Technology;Facebook,Graph Neural Networks;Physical simulation;Quantum chemistry;Catalysis,5;1;-1;1;-1;5;12;-1,2;28;-1;28;-1;2;38;-1,m;m,NAN,NAN,n,10
7886,ICLR,2021,CAFE: Catastrophic Data Leakage in Federated Learning,Xiao Jin;Ruijie Du;Pin-Yu Chen;Tianyi Chen,jinxiao96@gmail.com;du461007169@gmail.com;~Pin-Yu_Chen1;~Tianyi_Chen1,4;4;3;4,4;3;5;2,Reject,0,5,0.0,yes,9/28/20,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute;International Business Machines;Rensselaer Polytechnic Institute,,263;263;-1;263,527;527;-1;527,m;m,usa,usa,n,4
7887,ICLR,2021,FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification,Gongpei Zhao;Tao Wang;Yidong Li;Yi Jin,~Gongpei_Zhao1;~Tao_Wang1;~Yidong_Li1;~Yi_Jin2,3;4;4;4,5;4;4;5,Reject,0,0,0.0,yes,9/28/20,Beijing jiaotong univercity;Beijing Jiaotong University;Beijing Jiaotong University;Beijing Jiaotong University,,-1;-1;-1;-1,978;978;978;978,m;f,NAN,NAN,n,10
7888,ICLR,2021,Intrinsically Guided Exploration in Meta Reinforcement Learning,Jin Zhang;Jianhao Wang;Hao Hu;Tong Chen;Yingfeng Chen;Changjie Fan;Chongjie Zhang,~Jin_Zhang6;~Jianhao_Wang1;~Hao_Hu3;~Tong_Chen3;~Yingfeng_Chen1;~Changjie_Fan1;~Chongjie_Zhang1,4;4;4;4,3;3;5;4,Reject,0,6,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Institute for Interdisciplinary Information Sciences, Tsinghua University;;University of Science and Technology of China;Tsinghua University",Meta reinforcement learning;Exploration;Information gain,4;4;4;4;-1;-1;4,20;20;20;20;-1;87;20,f;m,asia,cn,n,
7889,ICLR,2021,Rewriter-Evaluator Framework for Neural Machine Translation,Yangming Li;Kaisheng Yao,~Yangming_Li1;~Kaisheng_Yao2,4;4;6;7,5;4;3;4,Reject,0,7,0.0,yes,9/28/20,Tencent AI Lab;Ant Group,Neural Machine Translation;Post-editing mechanism;Polish Mechanism;Proper Termination Policy,-1;-1,-1;-1,m;m,NAN,NAN,n,8;3
7890,ICLR,2021,"Weak and Strong Gradient Directions: Explaining Memorization, Generalization, and Hardness of Examples at Scale",Piotr Zielinski;Shankar Krishnan;Satrajit Chatterjee,zielinski@google.com;~Shankar_Krishnan1;~Satrajit_Chatterjee1,4;4;4;5,5;3;4;5,Reject,0,0,0.0,yes,9/28/20,Google;Google;Google,generalization;deep learning;hardness of examples,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
7891,ICLR,2021,Scalable Graph Neural Networks for Heterogeneous Graphs,Lingfan Yu;Jiajun Shen;Jinyang Li;Adam Lerer,~Lingfan_Yu1;~Jiajun_Shen1;~Jinyang_Li1;~Adam_Lerer1,5;5;3;6,5;5;5;4,Reject,0,7,0.0,yes,9/28/20,New York University;Facebook;New York University;Facebook,Graph Neural Networks;Large Graphs;Heterogeneous Graphs,23;-1;23;-1,26;-1;26;-1,m;m,NAN,NAN,n,10
7892,ICLR,2021,Physics Informed Deep Kernel Learning,Zheng Wang;Wei Xing;Robert Kirby;Shandian Zhe,~Zheng_Wang2;wxing@sci.utah.edu;~Robert_Kirby1;~Shandian_Zhe1,5;7;5;8,4;3;4;4,Reject,0,14,0.0,yes,9/28/20,University of Utah;;;University of Utah;University of Utah,Deep Kernel;Bayesian Learning,58;-1;-1;58;58,239;-1;-1;239;239,m;m,europe,uk,n,11;1;5
7893,ICLR,2021,Towards Robustness against Unsuspicious Adversarial Examples,Liang Tong;Minzhe Guo;Atul Prakash;Yevgeniy Vorobeychik,~Liang_Tong1;guominzhe@wustl.edu;~Atul_Prakash1;~Yevgeniy_Vorobeychik1,4;6;4;3,4;4;4;5,Reject,0,5,0.0,yes,9/28/20,"Washington University, St. Louis;;;University of Michigan;Washington University, St. Louis",,-1;-1;-1;7;-1,-1;-1;-1;22;-1,m;m,usa,usa,n,4
7894,ICLR,2021,Clearing the Path for Truly Semantic Representation Learning,Dominik Zietlow;Michal Rolinek;Georg Martius,~Dominik_Zietlow1;~Michal_Rolinek2;~Georg_Martius1,5;5;3;4,2;4;2;5,Reject,0,1,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems",Representation Learning;Disentanglement;Unsupervised Learning;Semantic Representations;VAE;Causal Representations;PCA,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,5
7895,ICLR,2021,Neighbourhood Distillation: On the benefits of non end-to-end distillation,La√´titia Shao;Elad Eban;Yair Movshovitz-Attias,~La√´titia_Shao1;~Elad_Eban1;~Yair_Movshovitz-Attias1,5;4;5,4;4;4,Reject,0,3,0.0,yes,9/28/20,Google;Google;Google Research,distillation;deep learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,
7896,ICLR,2021,Failure Modes of Variational Autoencoders and Their Effects on Downstream Tasks,Yaniv Yacoby;Weiwei Pan;Finale Doshi-Velez,~Yaniv_Yacoby1;~Weiwei_Pan1;~Finale_Doshi-Velez1,4;5;5;5,5;3;3;3,Reject,0,6,0.0,yes,9/28/20,Harvard University;Harvard University;Harvard University,Variational Autoencoders;Variational Inference;VAE;Approximate Inference;Semi-Supervision,53;53;53,3;3;3,m;f,usa,usa,y,5;4
7897,ICLR,2021,Constraining Latent Space to Improve Deep Self-Supervised e-Commerce Products Embeddings for Downstream Tasks,Cristian Cardellino;Rafael Carrascosa,~Cristian_Cardellino1;rafael.carrascosa@mercadolibre.com,3;3;5;4,4;4;3;4,Reject,0,0,0.0,yes,9/28/20,Universidad Nacional de C‚àö‚â•rdoba;Mercado Libre,representation learning;deep learning;self-supervised learning,327;-1,-1;-1,m;m,NAN,NAN,n,6
7898,ICLR,2021,"Adversarial Data Generation of Multi-category Marked Temporal Point Processes with Sparse, Incomplete, and Small Training Samples",Shashika Ranga Muramudalige;Anura Jayasumana;Haonan Wang,~Shashika_Ranga_Muramudalige1;~Anura_Jayasumana1;~Haonan_Wang2,5;5;3,4;4;4,Reject,0,5,0.0,yes,9/28/20,Colorado State University;;Colorado State University,Marked temporal point process;Stochastic process;Adversarial autoencoder;Incomplete data generation,453;-1;453,411;-1;411,m;m,usa,usa,n,4
7899,ICLR,2021,Hyperrealistic neural decoding: Reconstruction of face stimuli from fMRI measurements via the GAN latent space,Thirza Dado;Yaƒümur G√º√ßl√ºt√ºrk;Luca Ambrogioni;Gabrielle Ras;Sander E. Bosch;Marcel van Gerven;Umut G√º√ßl√º,~Thirza_Dado1;~Yaƒümur_G√º√ßl√ºt√ºrk1;~Luca_Ambrogioni1;~Gabrielle_Ras1;s.bosch@donders.ru.nl;~Marcel_van_Gerven1;~Umut_G√º√ßl√º1,4;5;7;5;2,3;4;5;4;5,Reject,0,0,0.0,yes,9/28/20,"Radboud University Nijmegen;Radboud University Nijmegen;Radboud University Nijmegen;Radboud University Nijmegen;;;Donders Institute for Brain, Cognition and Behaviour;Radboud University Nijmegen",Deep learning;Face perception;fMRI;Generative Adversarial Networks;Neural decoding,209;209;209;209;-1;-1;-1;209,136;136;136;136;-1;-1;-1;136,f;m,NAN,NAN,n,5;4
7900,ICLR,2021,Adaptive N-step Bootstrapping with Off-policy Data,Guan Wang;Dong Yan;Hang Su;Jun Zhu,wangguan19@mails.tsinghua.edu.cn;~Dong_Yan1;~Hang_Su3;~Jun_Zhu2,4;4;3;5,5;4;4;4,Reject,0,0,0.0,yes,9/28/20,Tsinghua University;;;Tsinghua University,reinforcement learning;policy evaluation,4;-1;-1;4,20;-1;-1;20,m;m,asia,cn,n,
7901,ICLR,2021,Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization,Qi Zhu;Yidan Xu;Haonan Wang;Chao Zhang;Jiawei Han;Carl Yang,~Qi_Zhu7;~Yidan_Xu1;~Haonan_Wang1;~Chao_Zhang9;~Jiawei_Han1;~Carl_Yang1,4;6;6;7,5;4;3;3,Reject,0,5,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Washington, Seattle;University of Illinois, Urbana Champaign;;University of Illinois, Urbana-Champaign;Emory University",Transfer learning;graph neural networks,-1;11;-1;-1;-1;174,-1;29;-1;-1;-1;85,m;m,canada,ca,y,6;1;10
7902,ICLR,2021,Guiding Neural Network Initialization via Marginal Likelihood Maximization,Anthony Tai;Chunfeng Huang,~Anthony_Tai1;~Chunfeng_Huang1,3;4;4;4,3;4;4;5,Reject,0,5,0.0,yes,9/28/20,"Indiana University, Bloomington;Indiana University",Neural networks;Gaussian processes;model initialization;marginal likelihood,64;64,140;140,m;m,usa,usa,n,
7903,ICLR,2021,Reviving Autoencoder Pretraining,You Xie;Nils Thuerey,~You_Xie1;~Nils_Thuerey1,5;4;3;9,4;4;3;3,Reject,0,5,0.0,yes,9/28/20,Technical University Munich;Technical University Munich,unsupervised pretraining;greedy layer-wise pretraining;transfer learning;orthogonality,-1;-1,-1;-1,m;m,NAN,NAN,n,5
7904,ICLR,2021,Regularized Mutual Information Neural Estimation,Kwanghee Choi;Siyeong Lee,~Kwanghee_Choi1;~Siyeong_Lee1,5;3;7;6,4;5;2;3,Reject,0,6,0.0,yes,9/28/20,Sogang University;Naver Labs,Information Theory;Regularization,-1;-1,929;-1,m;f,NAN,NAN,n,1
7905,ICLR,2021,Class-Weighted Evaluation Metrics for Imbalanced Data Classification,Akhilesh Gupta;Nesime Tatbul;Ryan Marcus;Shengtian Zhou;Insup Lee;Justin Gottschlich,akhileshgupta@alumni.upenn.edu;~Nesime_Tatbul1;~Ryan_Marcus1;~Shengtian_Zhou1;~Insup_Lee1;~Justin_Gottschlich1,6;3;3;4,4;5;4;4,Reject,0,0,0.0,yes,9/28/20,"University of Pennsylvania;Intel Labs;Computer Science and Artificial Intelligence Laboratory, Electrical Engineering & Computer Science;Intel;University of Pennsylvania;Intel Labs",Imbalanced data classification;Evaluation metrics;Log parsing;Sentiment analysis,20;-1;-1;-1;20;-1,13;-1;-1;-1;13;-1,m;m,NAN,NAN,n,
7906,ICLR,2021,Neurally Guided Genetic Programming for Turing Complete Programming by Example,Alexander Newton Wild;Barry Porter,~Alexander_Newton_Wild1;~Barry_Porter1,4;5;5,4;4;5,Reject,0,5,0.0,yes,9/28/20,Lancaster University;Lancaster University,Code Synthesis;Neural Code Synthesis;Genetic Programming;Programming By Example,209;209,136;136,m;m,europe,uk,n,
7907,ICLR,2021,DHOG: Deep Hierarchical Object Grouping,Luke Nicholas Darlow;Amos Storkey,~Luke_Nicholas_Darlow1;~Amos_Storkey1,4;6;3;4,2;4;4;4,Reject,0,5,0.0,yes,9/28/20,University of Edinburgh;University of Edinburgh,Unsupervised learning;Deep neural networks;clustering,29;29,30;30,m;m,europe,uk,n,
7908,ICLR,2021,Do Transformers Understand Polynomial Simplification? ,Vishesh Agarwal;Somak Aditya;Navin Goyal,t-viaga@microsoft.com;~Somak_Aditya1;~Navin_Goyal1,4;6;6;4,4;4;4;4,Reject,0,11,0.0,yes,9/28/20,"Indian Institute of Technology Kharagpur, Dhirubhai Ambani Institute Of Information and Communication Technology;Microsoft;Microsoft",,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;1
7909,ICLR,2021,Stochastic Optimization with Non-stationary Noise: The Power of Moment Estimation,Jingzhao Zhang;Hongzhou Lin;Subhro Das;Suvrit Sra;Ali Jadbabaie,~Jingzhao_Zhang2;~Hongzhou_Lin1;~Subhro_Das1;~Suvrit_Sra1;~Ali_Jadbabaie1,3;5;4;3,5;4;4;5,Reject,0,9,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Amazon;MIT-IBM Watson AI Lab, IBM Research;Massachusetts Institute of Technology;Massachusetts Institute of Technology",Stochastic optimization,5;-1;-1;5;5,4;-1;-1;4;4,m;m,usa,usa,y,1;9
7910,ICLR,2021,Adaptive norms for deep learning with regularized Newton methods,Jonas K Kohler;Leonard Adolphs;Aurelien Lucchi,~Jonas_K_Kohler1;~Leonard_Adolphs1;~Aurelien_Lucchi1,5;4;6;4,3;4;2;4,Reject,0,5,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Stochastic Optimization;Non-convex Optimization;Deep Learning;Adaptive methods;Newton methods;Second-order optimization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
7911,ICLR,2021,DyHCN: Dynamic Hypergraph Convolutional Networks,Nan Yin;zhigang luo;wenjie wang;Fuli Feng;Xiang Zhang,~Nan_Yin1;zgluo@nudt.edu.cn;wenjiewang96@gmail.com;~Fuli_Feng1;~Xiang_Zhang7,4;6;6;5,4;4;3;3,Reject,0,6,0.0,yes,9/28/20,"National University of Defense Technology;National University of Defense Technology, Tsinghua University;National University of Singapore;National University of Singapore;National University of Defense Technology",,-1;4;17;17;-1,-1;20;25;25;-1,f;m,NAN,NAN,n,8
7912,ICLR,2021,OFFER PERSONALIZATION USING TEMPORAL CONVOLUTION NETWORK AND OPTIMIZATION,Ankur Verma,~Ankur_Verma1,4;5;3,2;4;4,Reject,0,0,0.0,yes,9/28/20,Samya,Machine Learning;Deep Learning;Optimization;Time-Series;Offer Personalization,-1,-1,m,NAN,NAN,n,
7913,ICLR,2021,Manifold-aware Training: Increase Adversarial Robustness with Feature Clustering,Ting-An Yen;Chun-Shien Lu;Pau-Choo Chung,~Ting-An_Yen1;~Chun-Shien_Lu1;~Pau-Choo_Chung1,4;5;7;1;5,3;5;3;5;3,Reject,0,0,0.0,yes,9/28/20,National Cheng Kung University;Academia Sinica;National Cheng Kung University,Adversarial Attacks;Adversarial Defense;Robustness;Convolutional Neural Network;Feature Compactness,327;-1;327,599;-1;599,f;f,asia,tw,n,8;4
7914,ICLR,2021,Sensory Resilience based on Synesthesia,Eric Platon;Tom Sonoda,~Eric_Platon1;~Tom_Sonoda1,3;2;5,4;5;4,Reject,0,3,0.0,yes,9/28/20,ART;Waseda University,perception;resilience;robotics;synesthesia,-1;327,100;867,m;m,asia,jp,n,
7915,ICLR,2021,Transformer-QL: A Step Towards Making Transformer Network Quadratically Large,Suvadeep Hajra,~Suvadeep_Hajra1,4;5;5;7,4;3;4;4,Reject,0,0,0.0,yes,9/28/20,Indian Institute of Technology Bombay,deep learning;language model;transformer network;multi-scale transformer network;natural language processing;transformer-xl,-1,-1,m,NAN,NAN,n,8;3
7916,ICLR,2021,Embedding a random graph via GNN: mean-field inference theory and RL applications to NP-Hard multi-robot/machine scheduling,HYUNWOOK KANG;SEUNGWOO SCHIN;James Morrison;Jinkyoo Park,~HYUNWOOK_KANG1;seungwooschin@gmail.com;james.morrison@kaist.edu;~Jinkyoo_Park1,5;6;7;7,3;4;3;2,Reject,0,4,0.0,yes,9/28/20,Texas A&M;;;;;Korea Advanced Institute of Science and Technology,Graph neural network;graph embedding;multi-robot/machine scheduling;Reinforcement learning;Mean-field inference,46;-1;-1;-1;-1;-1,195;-1;-1;-1;-1;96,m;m,NAN,NAN,y,1;10
7917,ICLR,2021,Semi-Supervised Learning via Clustering Representation Space,Yen-Chieh Huang;Yuh-Jye Lee;Chih-Chi Wu;Yi-Wei Chiu;Yong-Xiang Lin;CHENG-YING LI;Po-Hung Ko,jeffpapapa@gmail.com;~Yuh-Jye_Lee1;~Chih-Chi_Wu1;~Yi-Wei_Chiu1;george851101@gmail.com;chuck30621@gmail.com;kphong19.iie08g@nctu.edu.tw,4;2;4;4,5;5;4;5,Reject,0,0,0.0,yes,9/28/20,National Chiao Tung University;;;;;;National Chiao Tung University,semi-supervised learning;deep learning;clustering;embedding latent space,128;-1;-1;-1;-1;-1;128,564;-1;-1;-1;-1;-1;564,m;m,asia,tw,n,
7918,ICLR,2021,A General Computational Framework to Measure the Expressiveness of Complex Networks using a Tight Upper Bound of Linear Regions,Yutong Xie;Gaoxiang Chen;Quanzheng Li,~Yutong_Xie1;gaoxiangchen@pku.edu.cn;~Quanzheng_Li2,4;4;3;4,3;2;4;2,Reject,0,0,0.0,yes,9/28/20,Peking University;;Harvard,,14;-1;53,23;-1;3,f;m,NAN,NAN,y,1
7919,ICLR,2021,Neural Time-Dependent Partial Differential Equation,Yihao Hu;Tong Zhao;Zhiliang Xu;Lizhen Lin,~Yihao_Hu1;~Tong_Zhao3;~Zhiliang_Xu1;~Lizhen_Lin1,3;5;4;5,4;5;4;5,Reject,0,0,0.0,yes,9/28/20,University of Notre Dame;University of Notre Dame;University of Notre Dame;University of Notre Dame,Numerical analysis;Deep learning;Partial differential equation;Machine learning;Predictive modeling,128;128;128;128,170;170;170;170,m;f,usa,usa,n,
7920,ICLR,2021,Finding Patient Zero: Learning Contagion Source with Graph Neural Networks,Chintan Shah;Nima Dehmamy;Nicola Perra;Matteo Chinazzi;Albert-Laszlo Barabasi;Alessandro Vespignani;Rose Yu,~Chintan_Shah2;~Nima_Dehmamy1;nicolaperra@gmail.com;~Matteo_Chinazzi1;~Albert-Laszlo_Barabasi1;~Alessandro_Vespignani1;~Rose_Yu1,3;5;7;3,3;4;4;5,Reject,0,0,0.0,yes,9/28/20,"Northeastern University;Northwestern University;;;Northeastern University;Northeastern University;Northeastern University;University of California, San Diego",contagion dynamics;theory of graph neural networks;epidemic modeling,16;46;-1;-1;16;16;16;-1,895;24;-1;-1;895;895;895;33,m;f,usa,usa,y,1;10
7921,ICLR,2021,Neural Subgraph Matching,Zhitao Ying;Andrew Wang;Jiaxuan You;Chengtao Wen;Arquimedes Canedo;Jure Leskovec,~Zhitao_Ying1;anwang@cs.stanford.edu;~Jiaxuan_You2;chengtao.wen@siemens.com;arquimedes.canedo@siemens.com;~Jure_Leskovec1,5;5;3;6,3;3;5;5,Reject,0,4,0.0,yes,9/28/20,"Stanford University;Stanford University;Computer Science Department, Stanford University;;;;;Stanford University",Graph neural networks;Subgraph matching;Order Embedding,5;5;5;-1;-1;-1;-1;5,2;2;2;-1;-1;-1;-1;2,m;m,usa,usa,pdf miss,10
7922,ICLR,2021,Dataset Curation Beyond Accuracy,Johan Bjorck;Carla P Gomes,~Johan_Bjorck2;~Carla_P_Gomes1,4;4;4;6,4;3;4;3,Reject,0,1,0.0,yes,9/28/20,Cornell University;Cornell University,crowd-sourcing;calibration;dataset;uncertainty,7;7,19;19,m;f,usa,usa,y,
7923,ICLR,2021,NAHAS: Neural Architecture and Hardware Accelerator Search,Yanqi Zhou;Xuanyi Dong;Daiyi Peng;Ethan Zhu;Amir Yazdanbakhsh;Berkin Akin;Mingxing Tan;James Laudon,~Yanqi_Zhou1;~Xuanyi_Dong1;~Daiyi_Peng1;ethanzhu@google.com;~Amir_Yazdanbakhsh1;~Berkin_Akin1;~Mingxing_Tan3;~James_Laudon1,4;5;5;6,4;2;3;4,Reject,0,1,0.0,yes,9/28/20,"Google Brain;University of Technology Sydney;;University of California, Santa Cruz;Georgia Institute of Technology;Google;Google;Stanford University",neural architecture search;systems;hardware,-1;71;-1;-1;12;-1;-1;5,-1;160;-1;207;38;-1;-1;2,f;m,usa,usa,n,
7924,ICLR,2021,Certified Watermarks for Neural Networks,Arpit Amit Bansal;Ping-yeh Chiang;Michael Curry;Hossein Souri;Rama Chellappa;John P Dickerson;Rajiv Jain;Tom Goldstein,~Arpit_Amit_Bansal1;~Ping-yeh_Chiang1;~Michael_Curry2;~Hossein_Souri1;~Rama_Chellappa1;~John_P_Dickerson1;~Rajiv_Jain1;~Tom_Goldstein1,4;4;6;5,4;4;4;4,Reject,0,7,0.0,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Johns Hopkins University;Johns Hopkins University;Arthur AI;Adobe Systems;University of Maryland, College Park",certified defense;watermarking;backdoor attack,12;12;12;71;71;-1;-1;12,90;90;90;12;12;-1;-1;90,m;m,usa,usa,y,4
7925,ICLR,2021,FORK: A FORward-looKing Actor for Model-Free Reinforcement Learning,Honghao Wei;Lei Ying,~Honghao_Wei2;~Lei_Ying1,5;3;5;3,4;5;4;5,Reject,0,0,0.0,yes,9/28/20,"University of Michigan;University of Michigan, Ann Arbor",Reinforcement Learning;Actor Critic;Policy Gradient;Model Free,7;7,22;22,m;m,NAN,NAN,n,
7926,ICLR,2021,Uncertainty-Based Adaptive Learning for Reading Comprehension,Jing Wang;Jie Shen;Xiaofei Ma;Andrew Arnold,~Jing_Wang14;~Jie_Shen6;~Xiaofei_Ma1;anarnld@amazon.com,4;3;4;5,4;3;5;4,Reject,0,4,0.0,yes,9/28/20,Amazon;Stevens Institute of Technology;Amazon;Amazon,machine reading comprehension;uncertainty-based sampling;adaptive loss minimization,-1;150;-1;-1,-1;567;-1;-1,f;m,NAN,NAN,n,
7927,ICLR,2021,Graph Pooling by Edge Cut,Alexis Galland;marc lelarge,~Alexis_Galland1;~marc_lelarge1,4;3;3;5,4;5;5;3,Reject,0,0,0.0,yes,9/28/20,INRIA;inria,graph;deep;learning;pooling,-1;-1,-1;-1,m;m,NAN,NAN,n,10
7928,ICLR,2021,Fast MNAS: Uncertainty-aware Neural Architecture Search with Lifelong Learning,Jihao Liu;Yangting Sun;Ming Zhang;Boxiao Liu;Yu Liu,~Jihao_Liu3;~Yangting_Sun1;~Ming_Zhang10;~Boxiao_Liu1;~Yu_Liu2,5;5;6;6,5;3;3;4,Reject,0,4,0.0,yes,9/28/20,"Shanghai University;SenseTime LTD;;State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences;The Chinese University of Hong Kong",Neural Architecture Search;AutoML;Reinforcement Learning (RL),-1;-1;-1;34;327,818;-1;-1;-1;39,m;m,NAN,NAN,n,7
7929,ICLR,2021,Learning Spatiotemporal Features via Video and Text Pair Discrimination,Tianhao Li;Limin Wang,~Tianhao_Li1;~Limin_Wang1,6;4;5;4,3;4;5;5,Reject,0,4,0.0,yes,9/28/20,Nanjing University;Nanjing University,Spatiotemporal Feature Learning;Video and Text Pair Discrimination;Self-/Weakly Supervised Learning,52;52,111;111,m;m,asia,kr,n,
7930,ICLR,2021,Data Transfer Approaches to Improve Seq-to-Seq Retrosynthesis,Katsuhiko Ishiguro;Kazuya Ujihara;Ryohto Sawada;Hirotaka Akita;Masaaki Kotera,~Katsuhiko_Ishiguro1;ujihara@preferred.jp;rsawada@preferred.jp;~Hirotaka_Akita1;kotera@preferred.jp,4;4;4;4,5;4;4;5,Reject,0,1,0.0,yes,9/28/20,Preferred Networks  Inc.;;;;Tokyo Institute of Technology,retrosynthesis;data transfer;transfer learninig;pre-training;fine-tuning;self-training,-1;-1;-1;-1;174,-1;-1;-1;-1;312,m;m,asia,jp,n,8;5
7931,ICLR,2021,Towards Powerful Graph Neural Networks: Diversity Matters,Xu Bingbing;Huawei Shen;Qi Cao;Yuanhao Liu;Keting Cen;Xueqi Cheng,~Xu_Bingbing1;~Huawei_Shen1;~Qi_Cao1;liuyuanhao20z@ict.ac.cn;cenketing@ict.ac.cn;~Xueqi_Cheng1,3;4;4;4;4,3;5;4;4;5,Reject,0,1,0.0,yes,9/28/20,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences, China;, Chinese Academy of Sciences;, Chinese Academy of Sciences;, Chinese Academy of Sciences",GNNs;Expressive power;Diverse sampling;Injective,34;34;34;34;34;34,-1;-1;-1;-1;-1;-1,m;m,asia,cn,n,10
7932,ICLR,2021,On the Landscape of Sparse Linear Networks,Dachao Lin;Ruoyu Sun;Zhihua Zhang,~Dachao_Lin1;~Ruoyu_Sun1;~Zhihua_Zhang1,4;4;7;5,4;4;5;4,Reject,0,0,0.0,yes,9/28/20,"Peking University;University of Illinois, Urbana-Champaign;Shanghai Jiao Tong University",theory;sparse network;landscape,14;-1;29,23;-1;100,m;m,asia,cn,y,
7933,ICLR,2021,Bayesian neural network parameters provide insights into the earthquake rupture physics.,Sabber Ahamed,~Sabber_Ahamed1,6;4;4;4,4;5;4;3,Reject,0,0,0.0,yes,9/28/20,Asurion,Bayesian neural network;earthquake rupture;simulation;Explainable neural network,-1,-1,m,NAN,NAN,n,11
7934,ICLR,2021,Unsupervised Cross-lingual Representation Learning for Speech Recognition,Alexis Conneau;Alexei Baevski;Ronan Collobert;Abdelrahman Mohamed;Michael Auli,~Alexis_Conneau1;~Alexei_Baevski1;~Ronan_Collobert1;~Abdelrahman_Mohamed2;~Michael_Auli1,6;4;6;5,3;5;4;5,Reject,0,0,0.0,yes,9/28/20,Facebook;Facebook;Facebook;Facebook;Facebook,Deep learning;speech processing;multilingual modeling;cross-lingual,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
7935,ICLR,2021,Preventing Value Function Collapse in Ensemble  Q-Learning by Maximizing Representation Diversity,Hassam Sheikh;Ladislau Boloni,~Hassam_Sheikh1;~Ladislau_Boloni1,4;5;5;6,1;4;4;3,Reject,0,2,0.0,yes,9/28/20,University of Central Florida;University of Central Florida,Ensemble Q-Learning;Representation Diversity;Reinforcement Learning,71;71,633;633,m;m,usa,usa,n,1
7936,ICLR,2021,MVP-BERT: Redesigning Vocabularies for Chinese BERT and Multi-Vocab Pretraining,Wei Zhu,~Wei_Zhu5,4;2;5;3,3;5;4;4,Reject,0,0,0.0,yes,9/28/20,East China Normal University,pretrained language models;multi-vocab pretraining;Chinese BERT,-1,387,m,NAN,NAN,n,2;3
7937,ICLR,2021,Fast Binarized Neural Network Training with Partial Pre-training,Alex Renda;Joshua Wolff Fromm,~Alex_Renda2;~Joshua_Wolff_Fromm1,4;4;4;5,5;5;3;4,Reject,0,17,0.0,yes,9/28/20,Massachusetts Institute of Technology;OctoML,binarized neural network;binary;quantized;1-bit;low precision,5;-1,4;-1,m;m,NAN,NAN,n,
7938,ICLR,2021,TopoTER: Unsupervised Learning of Topology Transformation Equivariant Representations,Xiang Gao;Wei Hu;Guo-Jun Qi,~Xiang_Gao2;~Wei_Hu6;~Guo-Jun_Qi1,5;7;6;6,4;3;2;4,Reject,0,5,0.0,yes,9/28/20,Peking University;Peking University;University of Central Florida,Unsupervised learning;node representations;mutual information,14;14;71,23;23;633,m;m,usa,usa,y,10
7939,ICLR,2021,Dream and Search to Control: Latent Space Planning for Continuous Control,Anurag Koul;Varun Kumar Vijay;Alan Fern;Somdeb Majumdar,~Anurag_Koul1;~Varun_Kumar_Vijay1;~Alan_Fern1;~Somdeb_Majumdar1,5;4;6;4,4;4;4;5,Reject,0,5,0.0,yes,9/28/20,Oregon State University;Intel;Oregon State University;Intel,Reinforcement Learning;Model Based RL;Continuous Control;Search;Planning;MCTS,79;-1;79;-1,424;-1;424;-1,m;m,NAN,NAN,n,
7940,ICLR,2021,Learning Intrinsic Symbolic Rewards in Reinforcement Learning,Hassam Sheikh;Shauharda Khadka;Santiago Miret;Somdeb Majumdar,~Hassam_Sheikh1;~Shauharda_Khadka1;~Santiago_Miret1;~Somdeb_Majumdar1,5;4;5,4;4;4,Reject,0,5,0.0,yes,9/28/20,University of Central Florida;Microsoft;Intel;Intel,Reinforcement Learning;Intrinsic Rewards;Symbolic Regression,71;-1;-1;-1,633;-1;-1;-1,m;m,NAN,NAN,n,
7941,ICLR,2021,Understanding Classifiers with Generative Models,La√´titia Shao;Yang Song;Stefano Ermon,~La√´titia_Shao1;~Yang_Song1;~Stefano_Ermon1,4;5;6;5,4;4;4;4,Reject,0,3,0.0,yes,9/28/20,Google;Stanford University;Stanford University,OOD detection;adversarial samples detection;deep learning;classification,-1;5;5,-1;2;2,f;m,usa,usa,n,1;5;4
7942,ICLR,2021,Frequency Decomposition in Neural Processes,Jens Petersen;Paul F Jaeger;Gregor Koehler;David Zimmerer;Fabian Isensee;Klaus Maier-Hein,~Jens_Petersen2;~Paul_F_Jaeger1;~Gregor_Koehler1;~David_Zimmerer1;~Fabian_Isensee1;~Klaus_Maier-Hein1,4;3;5;6,3;4;3;2,Reject,0,14,0.0,yes,9/28/20,German Cancer Research Center (DKFZ);German Cancer Research Center;German Cancer Research Center (DKFZ);German Cancer Research Center;German Cancer Research Center;German Cancer Research Center,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
7943,ICLR,2021,Contrasting distinct structured views to learn sentence embeddings,Antoine Simoulin;Benoit Crabb√©,~Antoine_Simoulin1;benoit.crabbe@gmail.com,5;3;4,4;4;4,Reject,0,1,0.0,yes,9/28/20,Laboratoire de Linguistique Formelle;Paris Diderot University,Sentence;Embeddings;Structure;Contrastive;Multi-views,-1;-1,-1;-1,m;m,NAN,NAN,n,
7944,ICLR,2021, Towards Understanding the Cause of Error in Few-Shot Learning,Liang Song;Jinlu Liu;Yongqiang Qin,~Liang_Song1;~Jinlu_Liu1;~Yongqiang_Qin1,4;4;6;5,5;4;5;4,Reject,0,5,0.0,yes,9/28/20,"University of Science and Technology of China;Renmin University of China;Tsinghua University, Tsinghua University",upper bound of error;feature separability;classifier discrepancy;few-shot learning,-1;85;4,87;517;20,m;m,NAN,NAN,y,6;1
7945,ICLR,2021,Learning from Demonstrations with Energy based Generative Adversarial Imitation Learning,Kaifeng Zhang,~Kaifeng_Zhang1,5;4;5;4,3;2;4;5,Reject,0,4,0.0,yes,9/28/20,Independent Researcher,Learning from Demonstrations;Energy based Models;Inverse Reinforcement Learning;Imitation Learning,-1,-1,m,NAN,NAN,y,5;4
7946,ICLR,2021,Learn Robust Features via Orthogonal Multi-Path,Kun Fang;Xiaolin Huang;Yingwen Wu;Tao Li;Jie Yang,~Kun_Fang1;~Xiaolin_Huang1;~Yingwen_Wu1;~Tao_Li12;jieyang@sjtu.edu.cn,5;5;4;5,3;3;5;3,Reject,0,4,0.0,yes,9/28/20,"Shanghai Jiao Tong University;Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University",adversarial robustness;orthogonal multi-path,29;4;29;29;29,100;20;100;100;100,m;m,asia,cn,n,1;4
7947,ICLR,2021,CURI: A Benchmark for Productive Concept Learning Under Uncertainty,Shanmukha Ramakrishna Vedantam;Arthur Szlam;Maximilian Nickel;Ari S. Morcos;Brenden M. Lake,~Shanmukha_Ramakrishna_Vedantam1;~Arthur_Szlam1;~Maximilian_Nickel1;~Ari_S._Morcos1;~Brenden_M._Lake1,6;6;5,3;3;4,Reject,0,5,0.0,yes,9/28/20,Facebook;CUNY City College;Facebook;Facebook AI Research (FAIR);Facebook,compositional learning;meta-learning;systematicity;reasoning,-1;263;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;1
7948,ICLR,2021,Model-based Navigation in Environments with Novel Layouts Using Abstract $2$-D Maps,Linfeng Zhao;Lawson L. S. Wong,~Linfeng_Zhao1;~Lawson_L._S._Wong1,6;4;4;3,4;4;4;4,Reject,0,5,0.0,yes,9/28/20,Northeastern University;Northeastern University,,16;16,895;895,m;m,usa,usa,n,6
7949,ICLR,2021,Contrastive Video Textures,Medhini Narasimhan;Shiry Ginosar;Andrew Owens;Alexei A Efros;Trevor Darrell,~Medhini_Narasimhan1;~Shiry_Ginosar1;~Andrew_Owens1;~Alexei_A_Efros1;~Trevor_Darrell2,6;4;5,3;5;5,Reject,0,3,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of Michigan;University of California Berkeley;Electrical Engineering & Computer Science Department,Video Textures;Audio Conditioned Video Synthesis;Self-Supervised learning;Contrastive Learning,-1;-1;7;-1;-1,7;7;22;7;-1,f;m,NAN,NAN,n,10
7950,ICLR,2021,"Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data",Alexander Robey;Hamed Hassani;George J. Pappas,~Alexander_Robey1;~Hamed_Hassani2;~George_J._Pappas1,5;5;5;5,4;2;3;3,Reject,0,11,0.0,yes,9/28/20,"School of Engineering and Applied Science, University of Pennsylvania;University of Pennsylvania;School of Engineering and Applied Science, University of Pennsylvania",robustness;out-of-distribution generalization;natural variation;deep learning,20;20;20,13;13;13,m;m,NAN,NAN,n,4
7951,ICLR,2021,Teleport Graph Convolutional Networks,Hongyang Gao;Shuiwang Ji,~Hongyang_Gao1;~Shuiwang_Ji1,5;5;3;5,4;4;3;5,Reject,0,0,0.0,yes,9/28/20,Iowa State University;Texas A&M University,over-smoothing,209;46,427;195,m;m,usa,usa,n,10
7952,ICLR,2021,Weighted Line Graph Convolutional Networks,Hongyang Gao;Shuiwang Ji,~Hongyang_Gao1;~Shuiwang_Ji1,5;6;4;6;5,4;4;3;4;4,Reject,0,5,0.0,yes,9/28/20,Iowa State University;Texas A&M University,Line graph,209;46,427;195,m;m,usa,usa,y,10
7953,ICLR,2021,No Spurious Local Minima: on the Optimization Landscapes of Wide and Deep Neural Networks,Johannes Lederer,~Johannes_Lederer1,4;5;4;4;6,4;4;3;4;3,Reject,0,0,0.0,yes,9/28/20,Ruhr-Universt√§t Bochum,,-1,-1,m,NAN,NAN,y,1
7954,ICLR,2021,Dimension reduction as an optimization problem over a set of generalized functions,Rustem Takhanov,~Rustem_Takhanov1,5;7;4,2;3;4,Reject,0,1,0.0,yes,9/28/20,Nazarbayev University,Unsupervised dimension reduction;sufficient dimension reduction;alternating scheme;Fourier transform;maximum mean discrepancy;Wasserstein distance;positive definite functions;Bochner‚Äôs theorem,-1,-1,m,NAN,NAN,y,
7955,ICLR,2021,"Slice, Dice, and Optimize: Measuring the Dimension of Neural Network Class Manifolds",Stanislav Fort;Ekin Dogus Cubuk;Surya Ganguli;Samuel Stern Schoenholz,~Stanislav_Fort1;~Ekin_Dogus_Cubuk1;~Surya_Ganguli1;~Samuel_Stern_Schoenholz1,4;5;4;6,4;4;4;3,Reject,0,16,0.0,yes,9/28/20,Stanford University;Google;Stanford University;Google,input space;random hyperplane;optimization;robustness;dimension;codimension;manifold,5;-1;5;-1,2;-1;2;-1,m;m,NAN,NAN,n,1
7956,ICLR,2021,A Benchmark for Voice-Face Cross-Modal Matching and  Retrieval,Chuyuan Xiong;Deyuan Zhang;Tao Liu;Xiaoyong Du;Jiankun Tian;Songyan Xue,~Chuyuan_Xiong1;~Deyuan_Zhang1;~Tao_Liu1;~Xiaoyong_Du1;~Jiankun_Tian1;~Songyan_Xue1,3;3;4,5;5;4,Reject,0,0,0.0,yes,9/28/20,"Renmin University of China;Shenyang Aerospace University;Renmin University of China;Renmin University of China;Dalian University of Technology;Renmin University of China, Tsinghua University",Cross-Modal Learning;Voice-Face Matching;Voice-Face Retrieval,85;-1;85;85;-1;4,517;-1;517;517;694;20,m;m,NAN,NAN,n,8
7957,ICLR,2021,Effective Subspace Indexing via Interpolation on Stiefel and Grassmann manifolds,Wenqing Hu;Tiefeng Jiang;Zhu Li,~Wenqing_Hu1;~Tiefeng_Jiang1;~Zhu_Li2,4;5;3;4,3;4;2;5,Reject,0,0,0.0,yes,9/28/20,Missouri University of Science and Technology;University of Minnesota-Twin Cities;University of Missouri-Kansas City,subspace indexing;locality preserving projection;Stiefel and Grassmann manifolds,-1;71;327,440;85;-1,m;m,usa,usa,y,
7958,ICLR,2021,Improved Uncertainty Post-Calibration via Rank Preserving Transforms,Yu Bai;Tengyu Ma;Huan Wang;Caiming Xiong,~Yu_Bai1;~Tengyu_Ma1;~Huan_Wang1;~Caiming_Xiong1,4;5;7;2,3;4;4;5,Reject,0,4,0.0,yes,9/28/20,Salesforce Research;Stanford University;Yale University;Salesforce Research,uncertainty quantification;calibration;temperature scaling,-1;5;71;-1,-1;2;8;-1,m;m,NAN,NAN,n,
7959,ICLR,2021,USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE,Ahmad Melhem Hammoud;Ahmad Rabih Ghandour,~Ahmad_Melhem_Hammoud1;arg06@mail.aub.edu,3;2;3;5,4;5;5;5,Reject,0,0,0.0,yes,9/28/20,Global University;American University of Beirut,Machine Learning;Computer Vision;Data Augmentation;Background Removal,-1;327,-1;328,m;m,asia,lb,n,
7960,ICLR,2021,Robust Learning for Congestion-Aware Routing,Sreenivas Gollapudi;Kostas Kollias;Benjamin Plaut;Ameya Velingker,~Sreenivas_Gollapudi2;kostaskollias@google.com;~Benjamin_Plaut2;~Ameya_Velingker1,5;8;7;3,4;4;3;4,Reject,0,12,0.0,yes,9/28/20,Google;Google;Stanford University;Google,routing algorithms;adversarial learning;congestion functions,-1;-1;5;-1,-1;-1;2;-1,m;m,NAN,NAN,y,10;4
7961,ICLR,2021,Layer-wise Adversarial Defense: An ODE Perspective,Zonghan Yang;Yang Liu;Chenglong Bao;Zuoqiang Shi,~Zonghan_Yang1;liuyang2011@tsinghua.edu.cn;~Chenglong_Bao3;~Zuoqiang_Shi1,5;5;5;4,4;4;3;4,Reject,0,0,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",adversarial training;robustness;ODE,4;4;4;4,20;20;20;20,m;m,NAN,NAN,y,8;1;4
7962,ICLR,2021,Towards Counteracting Adversarial Perturbations to Resist Adversarial Examples,Haimin ZHANG;Min Xu,~Haimin_ZHANG1;~Min_Xu5,3;2;2;1,5;5;5;5,Reject,0,0,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney,adversarial robustness;resisting adversarial examples,71;71,160;160,m;f,australasia,au,n,4
7963,ICLR,2021,One Reflection Suffice,Alexander Mathiasen;Frederik Hvilsh√∏j,~Alexander_Mathiasen2;fhvilshoj@gmail.com,4;6;4;4,5;2;2;2,Reject,0,13,0.0,yes,9/28/20,Aarhus University;Aarhus University,Orthogonal Weights Householder Reflections Normalizing Flows,92;92,106;106,m;m,europe,dk,y,
7964,ICLR,2021,Out-of-Distribution Generalization via Risk Extrapolation (REx),David Krueger;Ethan Caballero;Joern-Henrik Jacobsen;Amy Zhang;Jonathan Binas;R√©mi LE PRIOL;Dinghuai Zhang;Aaron Courville,~David_Krueger1;~Ethan_Caballero1;~Joern-Henrik_Jacobsen1;~Amy_Zhang1;~Jonathan_Binas1;~R√©mi_LE_PRIOL1;~Dinghuai_Zhang1;~Aaron_Courville3,6;6;5;4,2;4;4;5,Reject,0,16,0.0,yes,9/28/20,"University of Montreal;University of Montreal;Vector Institute;University of California Berkeley;Montreal Institute for Learning Algorithms, University of Montreal;University of Montreal;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;University of Montreal",out of distribution;domain generalization;invariant risk minimization;robust optimization;invariant causal prediction;spurious features;generalization,128;128;-1;-1;128;128;128;128,73;73;-1;7;73;73;73;73,m;m,canada,ca,y,1
7965,ICLR,2021,DeeperGCN: Training Deeper GCNs with Generalized Aggregation Functions,Guohao Li;Chenxin Xiong;Ali Thabet;Bernard Ghanem,~Guohao_Li1;chenxin.xiong@kaust.edu.sa;~Ali_Thabet1;~Bernard_Ghanem1,4;5;6;4,3;5;5;5,Reject,0,4,0.0,yes,9/28/20,KAUST;KAUST;KAUST;KAUST,Graph Neural Networks;Graph Representation Learning,110;110;110;110,-1;-1;-1;-1,m;m,europe,gr,y,8;2;10
7966,ICLR,2021,DiffAutoML: Differentiable Joint Optimization for Efficient End-to-End Automated Machine Learning,Kaichen Zhou;Lanqing HONG;Fengwei Zhou;Binxin Ru;Zhenguo Li;Trigoni Niki;Jiashi Feng,~Kaichen_Zhou1;~Lanqing_HONG1;~Fengwei_Zhou1;~Binxin_Ru1;~Zhenguo_Li1;niki.trigoni@cs.ox.ac.uk;~Jiashi_Feng1,5;4;4;6,3;4;4;3,Reject,0,5,0.0,yes,9/28/20,"Department of Computer Science, University of Oxford;Huawei Technologies Ltd.;Huawei Technologies Ltd.;University of Oxford;Huawei;;;National University of Singapore",Differentiable;Automated machine learning;Neural Architecture Search;Data Augment;Hyperparameter Optimization,46;-1;-1;46;-1;-1;-1;17,1;-1;-1;1;-1;-1;-1;25,m;m,asia,sg,n,
7967,ICLR,2021,Vision at A Glance: Interplay between Fine and Coarse Information Processing Pathways,Zilong Ji;Xiaolong Zou;Tiejun Huang;Si Wu,~Zilong_Ji1;~Xiaolong_Zou1;~Tiejun_Huang1;~Si_Wu1,3;3;6,4;4;4,Reject,0,3,0.0,yes,9/28/20,"State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University;Peking University;Peking University;Peking University",Fast pathway;Slow pathway;Interplay;Robustness;Visual backward masking;Biological visual systems;Biological inspried model,-1;14;14;14,307;23;23;23,m;m,asia,cn,n,
7968,ICLR,2021,Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning,Xue Bin Peng;Aviral Kumar;Grace Zhang;Sergey Levine,~Xue_Bin_Peng1;~Aviral_Kumar2;grace.zhang@berkeley.edu;~Sergey_Levine1,6;3;4;3,3;4;4;3,Reject,0,8,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;;;University of Washington,reinforcement learning;policy search;offline RL;control,-1;-1;-1;-1;11,7;7;-1;-1;29,m;m,usa,usa,n,
7969,ICLR,2021,Deep Evolutionary Learning for Molecular Design,Yifeng Li;Hsu Kiang Ooi;Alain Tchagang,~Yifeng_Li1;~Hsu_Kiang_Ooi1;alain.tchagang@nrc-cnrc.gc.ca,4;4;4;4,3;4;3;4,Reject,0,4,0.0,yes,9/28/20,Brock University;National Research Council Canada;National Research Council Canada,Deep Evolutionary Learning;Fragment-Based Drug Design;Deep Generative Model;Drug Design;Multi-objective Optimization,85;-1;-1,61;-1;-1,m;m,NAN,NAN,n,11;5
7970,ICLR,2021,Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing,Jinghan Yang;Adith Boloor;Ayan Chakrabarti;Xuan Zhang;Yevgeniy Vorobeychik,jinghan.yang@wustl.edu;adith@wustl.edu;~Ayan_Chakrabarti1;~Xuan_Zhang1;~Yevgeniy_Vorobeychik1,6;6;5;5,4;4;4;2,Reject,0,4,0.0,yes,9/28/20,"Washington University, St. Louis;Washington University, St. Louis;Google;Washington University, St. Louis;Washington University, St. Louis",Adversarial examples;autonomous driving,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,usa,usa,n,11;4
7971,ICLR,2021,Semantically-Adaptive Upsampling for Layout-to-Image Translation,Hao Tang;Nicu Sebe,~Hao_Tang6;~Nicu_Sebe1,4;5;6;5,5;5;5;4,Reject,0,0,0.0,yes,9/28/20,University of Trento;University of Trento,Feature upsampling;semantically-adaptive;layout-to-image translation,150;150,343;343,m;m,europe,gr,n,8
7972,ICLR,2021,Transferability of Compositionality,Yuanpeng Li;Liang Zhao;Joel Hestness;Ka Yee Lun;Kenneth Church;Mohamed Elhoseiny,~Yuanpeng_Li2;~Liang_Zhao2;~Joel_Hestness2;kayeelun@gmail.com;~Kenneth_Church1;~Mohamed_Elhoseiny1,3;4;3;2,5;3;3;5,Reject,0,6,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Samsung Research America;Cerebras Systems, Inc;;;Baidu;KAUST",Compositionality,4;-1;-1;-1;-1;-1;110,20;-1;-1;-1;-1;-1;-1,m;m,europe,gr,n,1
7973,ICLR,2021,SVMax: A Feature Embedding Regularizer,Ahmed Taha;Alex Hanson;Abhinav Shrivastava;Larry S. Davis,~Ahmed_Taha1;~Alex_Hanson1;~Abhinav_Shrivastava2;~Larry_S._Davis1,5;6;6;4,5;3;5;3,Reject,0,4,0.0,yes,9/28/20,"Honda Research Institute US;Department of Computer Science, University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park;Amazon",metric learning;model collapse;feature embedding;neural network regularizer,-1;-1;-1;-1,-1;90;90;-1,m;m,NAN,NAN,n,5;4
7974,ICLR,2021,On the Marginal Regret Bound Minimization of Adaptive Methods,Wenjie Li;Guang Cheng,~Wenjie_Li2;~Guang_Cheng1,8;5;4;5;3,3;3;4;3;4,Reject,0,5,0.0,yes,9/28/20,Purdue University;Purdue University,Optimization Algorithm;Adaptive algorithms;Online Learning;Regret Minimization,23;23,94;94,m;m,usa,usa,y,1;9
7975,ICLR,2021,Self-Pretraining for Small Datasets by Exploiting Patch Information,Zhang Chunyang,~Zhang_Chunyang1,4;2;4,4;5;5,Reject,0,0,0.0,yes,9/28/20,Huazhong University of Science and Technology,Learning with Small Datasets;Self-Pretraining,-1,312,m,NAN,NAN,n,
7976,ICLR,2021,Graph View-Consistent Learning Network,Zhuolin Liao;Kun Zhan,liaozl20@lzu.edu.cn;~Kun_Zhan1,3;3;4;4;5,4;4;4;5;5,Reject,0,5,0.0,yes,9/28/20,Lanzhou University;Lanzhou University,,-1;-1,862;862,f;m,NAN,NAN,n,10
7977,ICLR,2021,Non-Inherent Feature Compatible Learning,Yantao Shen;Fanzi Wu;Ying Shan,~Yantao_Shen2;~Fanzi_Wu1;~Ying_Shan2,5;5;2;6,3;4;4;3,Reject,0,4,0.0,yes,9/28/20,Tencent Applied Research Center;The Chinese University of Hong Kong;Tencent,Deep Learning;Feature Learning;Compatible Learning,-1;327;-1,-1;39;-1,m;m,NAN,NAN,n,
7978,ICLR,2021,FLAG: Adversarial Data Augmentation for Graph Neural Networks,Kezhi Kong;Guohao Li;Mucong Ding;Zuxuan Wu;Chen Zhu;Bernard Ghanem;Gavin Taylor;Tom Goldstein,~Kezhi_Kong1;~Guohao_Li1;~Mucong_Ding1;~Zuxuan_Wu1;~Chen_Zhu2;~Bernard_Ghanem1;~Gavin_Taylor1;~Tom_Goldstein1,6;5;6;7,3;4;3;5,Reject,0,5,0.0,yes,9/28/20,"University of Maryland, College Park;KAUST;Department of Computer Science, University of Maryland, College Park;Fudan University;Department of Computer Science, University of Maryland, College Park;KAUST;US Naval Academy;University of Maryland, College Park",Graph Neural Networks;Data Augmentation;Adversarial Training,12;110;-1;71;-1;110;-1;12,90;-1;90;70;90;-1;-1;90,u;m,usa,usa,n,10;4
7979,ICLR,2021,Secure Network Release with Link Privacy,Carl Yang;Haonan Wang;Ke ZHANG;Lichao Sun,~Carl_Yang1;~Haonan_Wang1;~Ke_ZHANG7;~Lichao_Sun1,6;3;5;6,4;5;2;3,Reject,0,9,0.0,yes,9/28/20,"Emory University;University of Illinois, Urbana Champaign;The University of Hong Kong;Lehigh University",generative model;graph neural network;data release,174;-1;99;263,85;-1;39;613,m;m,usa,usa,y,1;10
7980,ICLR,2021,Grounded Compositional Generalization with Environment Interactions,Yuanpeng Li,~Yuanpeng_Li2,4;3;5;5,3;3;4;3,Reject,0,6,0.0,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University",compositional generalization;grounding,4,20,m,NAN,NAN,n,1
7981,ICLR,2021,Patch-level Neighborhood Interpolation:  A General and Effective Graph-based Regularization Strategy,Ke Sun;Bing Yu;Zhouchen Lin;Zhanxing Zhu,~Ke_Sun3;~Bing_Yu1;~Zhouchen_Lin1;~Zhanxing_Zhu1,5;5;6;6,4;3;2;1,Reject,0,4,0.0,yes,9/28/20,University of Alberta;Peking University;Peking University;Peking University,Deep Learning;Regularization;Graph-based Representation,110;14;14;14,131;23;23;23,m;m,asia,cn,n,10;4
7982,ICLR,2021,Continuous Transfer Learning,Jun Wu;Jingrui He,~Jun_Wu3;~Jingrui_He1,6;5;6,4;4;4,Reject,0,4,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1,-1;-1,m;f,usa,usa,y,6;1;4
7983,ICLR,2021,Hierarchical Meta Reinforcement Learning for Multi-Task Environments,Dongyang Zhao;Yue Huang;Changnan Xiao;Yue Li;Shihong Deng,~Dongyang_Zhao1;~Yue_Huang5;~Changnan_Xiao1;~Yue_Li5;~Shihong_Deng1,3;3;4;3,5;4;4;3,Reject,0,0,0.0,yes,9/28/20,Peking University;The Chinese University of Hong Kong;New York University;Shandong University of Science and Technology;Bytedance,Reinforcement Learning;Multi-task;Hierarchical;Meta Learning,14;327;23;150;-1,23;39;26;627;-1,m;m,NAN,NAN,n,
7984,ICLR,2021,GN-Transformer: Fusing AST and Source Code information in Graph Networks,Junyan Cheng;Iordanis Fostiropoulos;Barry Boehm,~Junyan_Cheng1;fostirop@usc.edu;~Barry_Boehm1,3;5;5;5,4;3;4;4,Reject,0,0,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,,37;37;37,53;53;53,m;m,usa,usa,n,8;3;10
7985,ICLR,2021,Stochastic Inverse Reinforcement Learning ,Ce Ju,~Ce_Ju1,2;2;4;3;3,5;5;2;3;4,Reject,0,0,0.0,yes,9/28/20,"WeBank Co., Ltd. AI Department",Inverse Reinforcement Learning;Stochastic Methods;MCEM,-1,-1,u,NAN,NAN,n,
7986,ICLR,2021,Transformers satisfy,Feng Shi;CHEN LI;Shijie Bian;Yiqiao Jin;Ziheng Xu;Tian Han;Song-Chun Zhu,~Feng_Shi1;~CHEN_LI14;~Shijie_Bian1;~Yiqiao_Jin1;~Ziheng_Xu1;~Tian_Han1;~Song-Chun_Zhu1,4;4;3;4,4;3;5;4,Reject,0,0,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;Stevens Institute of Technology;University of California-Los Angeles",constraint satisfaction problem;graph attention;transformers,-1;-1;-1;-1;-1;150;-1,15;15;15;15;15;567;15,m;m,usa,usa,n,8;10
7987,ICLR,2021,Meta-k: Towards Unsupervised Prediction of Number of Clusters,Azade Farshad;Samin Hamidi;Nassir Navab,~Azade_Farshad1;hamidi.1732304@studenti.uniroma1.it;~Nassir_Navab1,3;4;4,5;3;4,Reject,0,0,0.0,yes,9/28/20,Technical University Munich;Sapienza University of Rome;TU Munich,Clustering;Self-supervised learning;Meta-learning,-1;99;58,-1;216;32,f;m,europe,de,n,2
7988,ICLR,2021,Proper Measure for Adversarial Robustness,Hyeongji Kim;Ketil Malde,~Hyeongji_Kim1;ketil@malde.org,3;3;3;3,5;4;5;4,Reject,0,2,0.0,yes,9/28/20,Institute of Marine Research;Institute of Marine Research  University of Bergen,adversarial examples;adversarial robustness;adversarial accuracy;nearest neighbor classifiers,-1;263,-1;219,f;m,NAN,NAN,y,1;4
7989,ICLR,2021,THE EFFICACY OF L1 REGULARIZATION IN NEURAL NETWORKS,Gen Li;Yuantao Gu;Jie Ding,g-li16@mails.tsinghua.edu.cn;~Yuantao_Gu1;~Jie_Ding2,5;4;5,4;4;3,Reject,0,3,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;;Tsinghua University;University of Minnesota, Minneapolis",Model selection;Neural Network;Regularization,4;-1;4;71,20;-1;20;85,m;m,NAN,NAN,y,1
7990,ICLR,2021,Mixture of Step Returns in Bootstrapped DQN,PoHan Chiang;Hsuan-Kung Yang;Zhang-Wei Hong;Chun-Yi Lee,~PoHan_Chiang2;~Hsuan-Kung_Yang1;~Zhang-Wei_Hong1;~Chun-Yi_Lee1,4;5;4;7;5,4;5;4;3;4,Reject,0,21,0.0,yes,9/28/20,National Tsing Hua University;National Tsing Hua University;Massachusetts Institute of Technology;National Tsing Hua University,Reinforcement Learning,209;209;5;209,365;365;4;365,m;m,asia,tw,n,
7991,ICLR,2021,Segmenting Natural Language Sentences via Lexical Unit Analysis,Yangming Li;lemao liu;Shuming Shi,~Yangming_Li1;~lemao_liu1;~Shuming_Shi1,7;5;6,5;3;5,Reject,0,3,0.0,yes,9/28/20,Tencent AI Lab;Tencent AI Lab;Tencent AI Lab,Neural Sequence Labeling;Neural Sequence Segmentation;Dynamic Programming,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2;3
7992,ICLR,2021,Truthful Self-Play,Shohei Ohsawa,~Shohei_Ohsawa1,6;5;5;4,2;3;4;4,Reject,0,0,0.0,yes,9/28/20,The University of Tokyo,Comm-POSG;Imaginary Rewards,71,36,m,NAN,NAN,y,1
7993,ICLR,2021,Transforming Recurrent Neural Networks with Attention and Fixed-point Equations,Zhaobin Xu;Baotian Hu;Buzhou Tang,~Zhaobin_Xu2;~Baotian_Hu1;~Buzhou_Tang1,4;3;4;5,4;4;4;4,Reject,0,0,0.0,yes,9/28/20,Harbin Institute of Technology  Shenzhen;Harbin Institute of Technology  Shenzhen;Harbin Institute of Technology  Shenzhen,Fixed-point;Attention;Feed Forward Network;Transformer;Recurrent Neural Network;Deep Learning,150;150;150,416;416;416,m;m,NAN,NAN,n,3;8;1
7994,ICLR,2021,Unified Principles For Multi-Source Transfer Learning Under Label Shifts,changjian shui;Zijian Li;jiaqi li;Christian Gagn√©;Charles Ling;Boyu Wang,~changjian_shui1;~Zijian_Li1;lijiaqi.victor@gmail.com;~Christian_Gagn√©1;~Charles_Ling1;~Boyu_Wang3,7;6;7;4,4;5;3;4,Reject,0,12,0.0,yes,9/28/20,Laval university;Guangdong University of Technology;University of Western Ontario;Universit√© Laval;University of Western Ontario;University of Western Ontario,,-1;-1;-1;-1;-1;-1,-1;740;-1;257;-1;-1,m;m,NAN,NAN,y,6
7995,ICLR,2021,Towards Adversarial Robustness of Bayesian Neural Network through Hierarchical Variational Inference,Byung-Kwan Lee;Youngjoon Yu;Yong Man Ro,~Byung-Kwan_Lee1;~Youngjoon_Yu1;~Yong_Man_Ro1,6;5;6;5,4;4;3;4,Reject,0,6,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,11;1;4
7996,ICLR,2021,Demystifying Learning of Unsupervised Neural Machine Translation,Guanlin Li;lemao liu;Taro Watanabe;Conghui Zhu;Tiejun Zhao,~Guanlin_Li1;~lemao_liu1;~Taro_Watanabe1;~Conghui_Zhu2;~Tiejun_Zhao1,5;6;4;5,3;3;3;4,Reject,0,4,0.0,yes,9/28/20,"Harbin Institute of Technology;Tencent AI Lab;Nara Institute of Science and Technology, Japan;Harbin Institute of Technonolgy;Harbin Institute of Technology",Unsupervised Neural Machine Translation;Marginal Likelihood Maximization;Mutual Information,150;-1;-1;150;150,416;-1;-1;416;416,m;m,asia,cn,n,3;8;1
7997,ICLR,2021,Toward Trainability of Quantum Neural Networks,Kaining Zhang;Min-Hsiu Hsieh;Liu Liu;Dacheng Tao,~Kaining_Zhang1;min-hsiu.hsieh@uts.edu.au;~Liu_Liu8;~Dacheng_Tao1,5;6;5,4;4;3,Reject,0,4,0.0,yes,9/28/20,University of Sydney;;;University of Sydney;JD.com,Near-term Quantum Algorithm;Quantum Neural Network;Trainability;Hierarchical Structure,71;-1;-1;71;-1,51;-1;-1;51;-1,m;m,NAN,NAN,y,1
7998,ICLR,2021,EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS,Like Hui;Mikhail Belkin,~Like_Hui1;mbelkin@ucsd.edu,8;6;7;7,5;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"University of California, San Diego;University of California, San Diego",large scale learning;square loss vs cross-entropy;classification;experimental evaluation,-1;-1,33;33,f;m,usa,usa,n,2;3
7999,ICLR,2021,Domain Generalization with MixStyle,Kaiyang Zhou;Yongxin Yang;Yu Qiao;Tao Xiang,~Kaiyang_Zhou1;~Yongxin_Yang1;~Yu_Qiao1;~Tao_Xiang1,6;7;7,4;4;4,Accept (Poster),0,3,0.0,yes,9/28/20,"University of Surrey;University of Surrey;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences;University of Surrey",Domain Generalization;Style Mixing,150;150;34;150,260;260;-1;260,m;m,europe,uk,n,1
8000,ICLR,2021,Learning to Generate 3D Shapes with Generative Cellular Automata,Dongsu Zhang;Changwoon Choi;Jeonghwan Kim;Young Min Kim,~Dongsu_Zhang1;~Changwoon_Choi1;whitealex95@snu.ac.kr;~Young_Min_Kim1,7;8;6,3;5;5,Accept (Poster),0,8,0.0,yes,9/28/20,Seoul National University;Seoul National University;;Seoul National University;Seoul National University,3D generation;generative models,37;37;-1;37;37,60;60;-1;60;60,m;m,asia,kr,y,5
8001,ICLR,2021,Semi-supervised Keypoint Localization,Olga Moskvyak;Frederic Maire;Feras Dayoub;Mahsa Baktashmotlagh,~Olga_Moskvyak1;~Frederic_Maire1;~Feras_Dayoub1;~Mahsa_Baktashmotlagh1,6;7;6;5,3;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,Queensland University of Technology;Queensland University of Technology;Queensland University of Technology;University of Queensland,semi-supervised learning;keypoint localization;limited data;unsupervised loss,-1;-1;-1;209,185;185;185;62,f;f,australasia,au,n,
8002,ICLR,2021,Learning Structural Edits via Incremental Tree Transformations,Ziyu Yao;Frank F. Xu;Pengcheng Yin;Huan Sun;Graham Neubig,~Ziyu_Yao1;~Frank_F._Xu1;~Pengcheng_Yin1;~Huan_Sun1;~Graham_Neubig1,7;7;8;5,4;4;4;4,Accept (Poster),0,26,0.0,yes,9/28/20,"Ohio State University;Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Ohio State University;Carnegie Mellon University",Tree-structured Data;Edit;Incremental Tree Transformations;Representation Learning;Imitation Learning;Source Code,58;1;1;58;1,78;28;28;78;28,f;m,usa,usa,n,5
8003,ICLR,2021,Aligning AI With Shared Human Values,Dan Hendrycks;Collin Burns;Steven Basart;Andrew Critch;Jerry Li;Dawn Song;Jacob Steinhardt,~Dan_Hendrycks1;collin.burns@columbia.edu;~Steven_Basart1;~Andrew_Critch1;~Jerry_Li1;~Dawn_Song1;~Jacob_Steinhardt1,6;7;6;6,4;4;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,UC Berkeley;University of California Berkeley;University of Chicago;University of California Berkeley;Massachusetts Institute of Technology;University of California Berkeley;University of California Berkeley,value learning;human preferences;alignment,-1;-1;46;-1;5;-1;-1,-1;7;10;7;4;7;7,m;m,usa,usa,n,3;7
8004,ICLR,2021,Selectivity considered harmful: evaluating the causal impact of class selectivity in DNNs,Matthew L Leavitt;Ari S. Morcos,~Matthew_L_Leavitt1;~Ari_S._Morcos1,6;7;6,4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,Facebook;Facebook AI Research (FAIR),interpretability;explainability;empirical analysis;deep learning;selectivity,-1;-1,-1;-1,m;m,NAN,NAN,n,
8005,ICLR,2021,Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms,Maruan Al-Shedivat;Jennifer Gillenwater;Eric Xing;Afshin Rostamizadeh,~Maruan_Al-Shedivat1;~Jennifer_Gillenwater1;~Eric_Xing1;~Afshin_Rostamizadeh1,7;6;6,3;4;2,Accept (Poster),0,5,0.0,yes,9/28/20,Carnegie Mellon University;Google;Carnegie Mellon University;Google,federated learning;posterior inference;MCMC,1;-1;1;-1,28;-1;28;-1,m;m,NAN,NAN,y,
8006,ICLR,2021,AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition,Yue Meng;Rameswar Panda;Chung-Ching Lin;Prasanna Sattigeri;Leonid Karlinsky;Kate Saenko;Aude Oliva;Rogerio Feris,~Yue_Meng1;~Rameswar_Panda1;~Chung-Ching_Lin2;~Prasanna_Sattigeri1;~Leonid_Karlinsky3;~Kate_Saenko1;~Aude_Oliva1;~Rogerio_Feris1,7;6;5;7,4;4;4;5,Accept (Poster),0,11,0.0,yes,9/28/20,"Massachusetts Institute of Technology;MIT-IBM Watson AI Lab, IBM Research;Microsoft;IBM Research;IBM Research AI;Boston University;Massachusetts Institute of Technology;International Business Machines",,5;-1;-1;-1;-1;79;5;-1,4;-1;-1;-1;-1;54;4;-1,m;m,NAN,NAN,n,
8007,ICLR,2021,Noise against noise: stochastic label noise helps combat inherent label noise,Pengfei Chen;Guangyong Chen;Junjie Ye;jingwei zhao;Pheng-Ann Heng,~Pengfei_Chen1;gy.chen@siat.ac.cn;kourenmu@gmail.com;~jingwei_zhao1;~Pheng-Ann_Heng1,7;7;5;6,3;4;4;5,Accept (Spotlight),0,11,0.0,yes,9/28/20,"The Chinese University of Hong Kong;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences;The Chinese University of Hong Kong;Tsinghua University, Tsinghua University;The Chinese University of Hong Kong",Noisy Labels;Robust Learning;SGD noise;Regularization,327;34;327;4;327,39;-1;39;20;39,m;m,NAN,NAN,y,1
8008,ICLR,2021,Private Image Reconstruction from System Side Channels Using Generative Models,Yuanyuan Yuan;Shuai Wang;Junping Zhang,~Yuanyuan_Yuan1;~Shuai_Wang7;~Junping_Zhang2,5;7;7;8,3;4;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Fudan University",side channel analysis,-1;-1;71,56;56;70,f;m,asia,cn,n,5;4
8009,ICLR,2021,FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,Yi Ren;Chenxu Hu;Xu Tan;Tao Qin;Sheng Zhao;Zhou Zhao;Tie-Yan Liu,~Yi_Ren2;~Chenxu_Hu1;~Xu_Tan1;~Tao_Qin1;sheng.zhao@microsoft.com;~Zhou_Zhao2;~Tie-Yan_Liu1,7;7;8;7;5,4;5;4;5;5,Accept (Poster),0,6,0.0,yes,9/28/20,Zhejiang University;Zhejiang University;Microsoft;Tsinghua University;;;Zhejiang University;Microsoft,text to speech;speech synthesis;non-autoregressive generation;one-to-many mapping;end-to-end,42;42;-1;4;-1;-1;42;-1,94;94;-1;20;-1;-1;94;-1,m;m,NAN,NAN,n,
8010,ICLR,2021,MALI: A memory efficient and reverse accurate integrator for Neural ODEs,Juntang Zhuang;Nicha C Dvornek;sekhar tatikonda;James s Duncan,~Juntang_Zhuang1;~Nicha_C_Dvornek1;~sekhar_tatikonda1;~James_s_Duncan1,7;7;6;7,3;4;2;2,Accept (Poster),0,9,0.0,yes,9/28/20,Yale University;Yale University;Yale University;Yale University,neural ode;memory efficient;reverse accuracy;gradient estimation,71;71;71;71,8;8;8;8,m;m,europe,fi,y,5
8011,ICLR,2021,DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation,Alexandre Rame;Matthieu Cord,~Alexandre_Rame1;~Matthieu_Cord1,6;8;7;6,3;4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,LIP6;Sorbonne University,Deep Learning;Deep Ensembles;Information Theory;Information Bottleneck;Adversarial Learning,453;-1,-1;87,m;m,NAN,NAN,n,1;4
8012,ICLR,2021,The inductive bias of ReLU networks on orthogonally separable data,Mary Phuong;Christoph H Lampert,~Mary_Phuong1;~Christoph_H_Lampert1,7;8;5;8,4;4;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,IST Austria;Institute of Science and Technology Austria,inductive bias;implicit bias;gradient descent;ReLU networks;max-margin;extremal sector,110;-1,-1;-1,f;m,NAN,NAN,y,1
8013,ICLR,2021,Locally Free Weight Sharing for Network Width Search,Xiu Su;Shan You;Tao Huang;Fei Wang;Chen Qian;Changshui Zhang;Chang Xu,~Xiu_Su1;~Shan_You3;~Tao_Huang5;~Fei_Wang9;~Chen_Qian1;~Changshui_Zhang1;~Chang_Xu4,8;6;8;7,4;5;4;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,University of Sydney;Tsinghua University;SenseTime;Sensetime;The SenseTime Research;Tsinghua University;University of Sydney,,71;4;-1;-1;-1;4;71,51;20;-1;-1;-1;20;51,u;m,europe,uk,pdf miss,
8014,ICLR,2021,Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability,Suraj Srinivas;Francois Fleuret,~Suraj_Srinivas1;francois.fleuret@unige.ch,5;7;9;9,4;4;4;4,Accept (Oral),0,10,0.0,yes,9/28/20,Idiap Research Institute & EPFL;University of Geneva,Interpretability;saliency maps;score-matching,23;-1,-1;149,m;m,NAN,NAN,n,5
8015,ICLR,2021,BOIL: Towards Representation Change for Few-shot Learning,Jaehoon Oh;Hyungjun Yoo;ChangHwan Kim;Se-Young Yun,~Jaehoon_Oh1;~Hyungjun_Yoo1;~ChangHwan_Kim2;~Se-Young_Yun1,7;7;7,4;5;4,Accept (Poster),0,10,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,,-1;-1;-1;15,96;96;96;96,m;m,asia,in,n,6
8016,ICLR,2021,Removing Undesirable Feature Contributions Using Out-of-Distribution Data,Saehyung Lee;Changhwa Park;Hyungyu Lee;Jihun Yi;Jonghyun Lee;Sungroh Yoon,~Saehyung_Lee1;~Changhwa_Park1;~Hyungyu_Lee2;~Jihun_Yi1;~Jonghyun_Lee1;~Sungroh_Yoon1,6;7;6;7,1;4;4;5,Accept (Poster),0,8,0.0,yes,9/28/20,Seoul National University;Hyundai Motor Company;Seoul National University;Seoul National University;Seoul National University;Seoul National University,adversarial training;adversarial robustness;generalization;out-of-distribution,37;-1;37;37;37;37,60;-1;60;60;60;60,m;m,asia,kr,y,1;4
8017,ICLR,2021,IOT: Instance-wise Layer Reordering for Transformer Structures,Jinhua Zhu;Lijun Wu;Yingce Xia;Shufang Xie;Tao Qin;Wengang Zhou;Houqiang Li;Tie-Yan Liu,~Jinhua_Zhu1;~Lijun_Wu1;~Yingce_Xia1;~Shufang_Xie1;~Tao_Qin1;~Wengang_Zhou1;~Houqiang_Li1;~Tie-Yan_Liu1,7;5;7;5,4;5;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,University of Science and Technology of China;Microsoft Research;Microsoft;Microsoft Research Asia;Tsinghua University;University of Science and Technology of China;University of Science and Technology of China;Microsoft,Layer order;Transformers;Instance-wise Learning,-1;-1;-1;-1;4;-1;-1;-1,87;-1;-1;-1;20;87;87;-1,m;m,NAN,NAN,n,8;3
8018,ICLR,2021,Text Generation by Learning from Demonstrations,Richard Yuanzhe Pang;He He,~Richard_Yuanzhe_Pang1;~He_He2,5;7;7;7;7,4;4;4;4;3,Accept (Poster),0,12,0.0,yes,9/28/20,New York University;New York University,text generation;learning from demonstrations;nlp,23;23,26;26,m;f,usa,usa,n,3
8019,ICLR,2021,How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks,Keyulu Xu;Mozhi Zhang;Jingling Li;Simon Shaolei Du;Ken-Ichi Kawarabayashi;Stefanie Jegelka,~Keyulu_Xu1;~Mozhi_Zhang1;~Jingling_Li1;~Simon_Shaolei_Du1;~Ken-Ichi_Kawarabayashi1;~Stefanie_Jegelka3,9;8;9;9,3;4;4;4,Accept (Oral),0,8,0.0,yes,9/28/20,"Massachusetts Institute of Technology;University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park;Facebook;;Massachusetts Institute of Technology",extrapolation;deep learning;out-of-distribution;graph neural networks;deep learning theory,5;12;-1;-1;-1;5,4;90;90;-1;-1;4,m;f,usa,usa,y,1;10
8020,ICLR,2021,Large Associative Memory Problem in Neurobiology and Machine Learning,Dmitry Krotov;John J. Hopfield,~Dmitry_Krotov2;~John_J._Hopfield1,6;8;7;7,4;3;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,"Institue for Advanced Study, Princeton;;Princeton University",associative memory;Hopfield networks;modern Hopfield networks;neuroscience,-1;-1;29,-1;-1;9,m;m,usa,usa,n,1
8021,ICLR,2021,Adaptive Universal Generalized PageRank Graph Neural Network,Eli Chien;Jianhao Peng;Pan Li;Olgica Milenkovic,~Eli_Chien1;~Jianhao_Peng1;~Pan_Li2;~Olgica_Milenkovic1,4;6;9;7,4;2;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Illinois, Urbana-Champaign;University of Illinois, Urbana Champaign;Purdue University;University of Illinois, Urbana Champaign",Graph Neural Networks;Generalized PageRank;Heterophily;Homophily;Over-smoothing,-1;-1;23;-1,-1;-1;94;-1,m;f,usa,usa,y,10
8022,ICLR,2021,UMEC: Unified model and embedding compression for efficient recommendation systems,Jiayi Shen;Haotao Wang;Shupeng Gui;Jianchao Tan;Zhangyang Wang;Ji Liu,~Jiayi_Shen1;~Haotao_Wang1;~Shupeng_Gui1;~Jianchao_Tan1;~Zhangyang_Wang1;~Ji_Liu1,7;6;7;7,3;5;4;5,Accept (Poster),0,8,0.0,yes,9/28/20,"Texas A&M;University of Texas, Austin;University of Rochester;Kwai Inc.;University of Texas, Austin;Kwai Inc.",recommendation system;model compression;ADMM;resource constrained,46;-1;110;-1;-1;-1,195;-1;147;-1;-1;-1,f;m,NAN,NAN,n,
8023,ICLR,2021,"Learning Incompressible Fluid Dynamics from Scratch - Towards Fast, Differentiable Fluid Models that Generalize",Nils Wandel;Michael Weinmann;Reinhard Klein,~Nils_Wandel2;~Michael_Weinmann1;~Reinhard_Klein1,7;7;7;7,3;5;5;3,Accept (Spotlight),0,7,0.0,yes,9/28/20,University of Bonn;University of Bonn;;University of Bonn,Unsupervised Learning;Fluid Dynamics;U-Net,128;128;-1;128,114;114;-1;114,m;m,europe,uk,n,1
8024,ICLR,2021,Fooling a Complete Neural Network Verifier,D√°niel Zombori;Bal√°zs B√°nhelyi;Tibor Csendes;Istv√°n Megyeri;M√°rk Jelasity,zomborid@inf.u-szeged.hu;banhelyi@inf.u-szeged.hu;csendes@inf.u-szeged.hu;imegyeri@inf.u-szeged.hu;~M√°rk_Jelasity1,6;6;7;6,5;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,University of Szeged;;;University of Szeged;University of Szeged;University of Szeged,adversarial examples;complete verifiers;numerical errors,453;-1;-1;453;453;453,876;-1;-1;876;876;876,m;m,europe,de,n,4
8025,ICLR,2021,Deep Neural Network Fingerprinting by Conferrable Adversarial Examples,Nils Lukas;Yuxuan Zhang;Florian Kerschbaum,~Nils_Lukas1;~Yuxuan_Zhang1;~Florian_Kerschbaum1,6;7;6;6,3;3;2;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,University of Waterloo;University of Waterloo;University of Waterloo,Fingerprinting;Adversarial Examples;Transferability;Conferrability,34;34;34,232;232;232,m;m,canada,ca,n,6;4
8026,ICLR,2021,Wasserstein Embedding for Graph Learning,Soheil Kolouri;Navid Naderializadeh;Gustavo K. Rohde;Heiko Hoffmann,~Soheil_Kolouri1;nnaderializadeh@hrl.com;~Gustavo_K._Rohde1;hhoffmann@hrl.com,7;6;8;6,4;3;5;4,Accept (Poster),0,9,0.0,yes,9/28/20,"Vanderbilt University;HRL Laboratories;;HRL Laboratories, LLC",Wasserstein;graph embedding;graph-level prediction,263;-1;-1;-1,111;-1;-1;-1,m;m,NAN,NAN,y,10
8027,ICLR,2021,On Position Embeddings in BERT,Benyou Wang;Lifeng Shang;Christina Lioma;Xin Jiang;Hao Yang;Qun Liu;Jakob Grue Simonsen,~Benyou_Wang2;~Lifeng_Shang1;~Christina_Lioma1;~Xin_Jiang1;~Hao_Yang7;~Qun_Liu1;~Jakob_Grue_Simonsen1,6;6;8;7,4;5;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Universita' degli studi di Padova;Huawei Technologies Ltd.;University of Copenhagen;Noah‚Äôs Ark Lab, Huawei Technologies;Beijing University of Post and Telecommunication, Tsinghua University;Noah's Ark Lab, Huawei Technologies Ltd.;University of Copenhagen",Position Embedding;BERT;pretrained language model.,-1;-1;92;-1;4;-1;92,-1;-1;84;-1;20;-1;84,m;m,europe,dk,n,8
8028,ICLR,2021,Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis,Bingchen Liu;Yizhe Zhu;Kunpeng Song;Ahmed Elgammal,~Bingchen_Liu2;~Yizhe_Zhu2;~Kunpeng_Song1;~Ahmed_Elgammal1,7;7;7;7,4;5;4;3,Accept (Poster),0,18,0.0,yes,9/28/20,Rutgers University;Rutgers University;Rutgers University;Rutgers University New Brunswick,deep learning;generative model;image synthesis;few-shot learning;generative adversarial network;self-supervised learning;unsupervised learning,29;29;29;29,-1;-1;-1;-1,m;m,NAN,NAN,n,6;5;4
8029,ICLR,2021,AdaSpeech: Adaptive Text to Speech for Custom Voice,Mingjian Chen;Xu Tan;Bohan Li;Yanqing Liu;Tao Qin;sheng zhao;Tie-Yan Liu,t-miche@microsoft.com;~Xu_Tan1;bohan.li@microsoft.com;yanqliu@microsoft.com;~Tao_Qin1;~sheng_zhao1;~Tie-Yan_Liu1,4;7;6;8,5;5;2;5,Accept (Poster),0,10,0.0,yes,9/28/20,Microsoft;;;;;;Microsoft,Text to speech;adaptation;fine-tuning;custom voice;acoustic condition modeling;conditional layer normalization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
8030,ICLR,2021,Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching,Jonas Geiping;Liam H Fowl;W. Ronny Huang;Wojciech Czaja;Gavin Taylor;Michael Moeller;Tom Goldstein,~Jonas_Geiping1;~Liam_H_Fowl1;~W._Ronny_Huang1;~Wojciech_Czaja1;~Gavin_Taylor1;~Michael_Moeller1;~Tom_Goldstein1,7;5;7;6,3;5;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,"University of Siegen;University of Maryland, College Park;Google;;US Naval Academy;University of Siegen;University of Maryland, College Park",Data Poisoning;ImageNet;Large-scale;Gradient Alignment;Security;Backdoor Attacks;from-scratch;clean-label,327;12;-1;-1;-1;327;12,717;90;-1;-1;-1;717;90,m;m,usa,usa,y,4
8031,ICLR,2021,Conformation-Guided Molecular Representation with Hamiltonian Neural Networks,Ziyao Li;Shuwen Yang;Guojie Song;Lingsheng Cai,~Ziyao_Li1;swyang@pku.edu.cn;~Guojie_Song1;cailingsheng@pku.edu.cn,5;7;7,4;3;5,Accept (Poster),0,3,0.0,yes,9/28/20,Peking University;Peking University;Peking University;Peking University,Molecular Representation;Neural Physics Engines;Molecular Dynamics;Graph Neural Networks,14;14;14;14,23;23;23;23,m;m,asia,cn,n,
8032,ICLR,2021,Free Lunch for Few-shot Learning:  Distribution Calibration,Shuo Yang;Lu Liu;Min Xu,~Shuo_Yang5;~Lu_Liu7;~Min_Xu5,7;7;7,5;4;4,Accept (Oral),0,5,0.0,yes,9/28/20,"University of Technology Sydney, Australia;University of Technology Sydney;University of Technology Sydney",few-shot learning;image classification;distribution estimation,71;71;71,160;160;160,m;f,australasia,au,n,
8033,ICLR,2021,Learning Reasoning Paths over Semantic Graphs for Video-grounded Dialogues,Hung Le;Nancy F. Chen;Steven Hoi,~Hung_Le2;~Nancy_F._Chen1;~Steven_Hoi2,7;6;6,4;5;4,Accept (Poster),0,3,0.0,yes,9/28/20,Singapore Management University;;Salesforce Research Asia,video-grounded dialogues;reasoning paths;semantic graphs,79;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,10
8034,ICLR,2021,Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency,Qiang Zhang;Tete Xiao;Alexei A Efros;Lerrel Pinto;Xiaolong Wang,~Qiang_Zhang5;~Tete_Xiao1;~Alexei_A_Efros1;~Lerrel_Pinto1;~Xiaolong_Wang3,10;7;8;6,4;3;3;2,Accept (Oral),0,4,0.0,yes,9/28/20,"Shanghai Jiao Tong University;University of California Berkeley;University of California Berkeley;New York University;University of California, San Diego",self-supervised learning;robotics,29;-1;-1;23;-1,100;7;7;26;33,m;m,usa,usa,n,6
8035,ICLR,2021,Graph-Based Continual Learning,Binh Tang;David S. Matteson,~Binh_Tang1;~David_S._Matteson1,8;7;7;6,4;3;4;4,Accept (Spotlight),0,4,0.0,yes,9/28/20,Cornell University;Cornell University,,7;7,19;19,m;m,usa,usa,n,10
8036,ICLR,2021,Fully Unsupervised Diversity Denoising with Convolutional Variational Autoencoders,Mangal Prakash;Alexander Krull;Florian Jug,~Mangal_Prakash1;~Alexander_Krull3;~Florian_Jug1,7;6;6;7,3;3;5;4,Accept (Poster),0,8,0.0,yes,9/28/20,Max-Planck Institute;Birmingham University;Fondation Human Technopole,Diversity denoising;Unsupervised denoising;Variational Autoencoders;Noise model,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2;5
8037,ICLR,2021,IEPT: Instance-Level and Episode-Level Pretext Tasks for Few-Shot Learning,Manli Zhang;Jianhong Zhang;Zhiwu Lu;Tao Xiang;Mingyu Ding;Songfang Huang,~Manli_Zhang1;~Jianhong_Zhang1;~Zhiwu_Lu1;~Tao_Xiang1;~Mingyu_Ding1;~Songfang_Huang1,6;5;8;7;5,4;4;4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,Renmin University of China;Renmin University of China;Renmin University of China;University of Surrey;The University of Hong Kong;Alibaba Group,few-shot learning;self-supervised learning;episode-level pretext task,85;85;85;150;99;-1,517;517;517;260;39;-1,f;m,NAN,NAN,n,6
8038,ICLR,2021,MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning,Nanyi Fei;Zhiwu Lu;Tao Xiang;Songfang Huang,~Nanyi_Fei1;~Zhiwu_Lu1;~Tao_Xiang1;~Songfang_Huang1,7;6;6;7,4;5;3;5,Accept (Poster),0,14,0.0,yes,9/28/20,Renmin University of China;Renmin University of China;University of Surrey;Alibaba Group,few-shot learning;episodic training;cross-episode attention,85;85;150;-1,517;517;260;-1,u;m,NAN,NAN,n,6;8
8039,ICLR,2021,Correcting experience replay for multi-agent communication,Sanjeevan Ahilan;Peter Dayan,~Sanjeevan_Ahilan1;~Peter_Dayan1,7;7;8;8,4;2;3;3,Accept (Spotlight),0,11,0.0,yes,9/28/20,University College London;Max-Planck Institute,multi-agent reinforcement learning;experience replay;communication;relabelling,53;-1,-1;-1,m;m,NAN,NAN,n,
8040,ICLR,2021,Representation Learning for Sequence Data with Deep Autoencoding Predictive Components,Junwen Bai;Weiran Wang;Yingbo Zhou;Caiming Xiong,~Junwen_Bai1;~Weiran_Wang1;~Yingbo_Zhou1;~Caiming_Xiong1,5;6;5;7,4;4;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,Cornell University;Google;Salesforce Research;Salesforce Research,Mutual Information;Unsupervised Learning;Sequence Data;Masked Reconstruction,7;-1;-1;-1,19;-1;-1;-1,m;m,NAN,NAN,n,1
8041,ICLR,2021,BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction,Yuhang Li;Ruihao Gong;Xu Tan;Yang Yang;Peng Hu;Qi Zhang;Fengwei Yu;Wei Wang;Shi Gu,~Yuhang_Li1;~Ruihao_Gong1;~Xu_Tan3;~Yang_Yang22;~Peng_Hu3;~Qi_Zhang15;~Fengwei_Yu1;~Wei_Wang3;~Shi_Gu1,6;7;8;7,4;4;4;1,Accept (Poster),0,8,0.0,yes,9/28/20,"Yale University;Beihang University;Institute of Computing Technology, Chinese Academy of Sciences;Sensetime;Beihang University, Tsinghua University;Beihang University;Beihang University;National University of Singapore;University of Electronic Science and Technology of China, Tsinghua University",Post Training Quantization;Mixed Precision;Second-order analysis,71;99;34;-1;4;99;99;17;4,8;567;-1;-1;20;567;567;25;20,f;m,NAN,NAN,y,2;1
8042,ICLR,2021,Exploring Balanced Feature Spaces for Representation Learning,Bingyi Kang;Yu Li;Sa Xie;Zehuan Yuan;Jiashi Feng,~Bingyi_Kang1;~Yu_Li7;~Sa_Xie1;~Zehuan_Yuan1;~Jiashi_Feng1,5;5;6,5;5;5,Accept (Poster),0,8,0.0,yes,9/28/20,"National University of Singapore;Institute of Computing Technology, Chinese Academy of Sciences;Open Review;Nanjing University;National University of Singapore",Representation Learning;Contrastive Learning;Long-Tailed Recognition,17;34;-1;52;17,25;-1;-1;111;25,m;m,asia,sg,n,
8043,ICLR,2021,CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation,Xin Ding;Yongwei Wang;Zuheng Xu;William J Welch;Z. Jane Wang,~Xin_Ding2;~Yongwei_Wang1;~Zuheng_Xu1;~William_J_Welch1;~Z._Jane_Wang1,7;6;5;6,4;3;3;3,Accept (Poster),0,10,0.0,yes,9/28/20,University of British Columbia;University of British Columbia;University of British Columbia;University of British Columbia;University of British Columbia,Conditional generative adversarial networks;image generation;continuous and scalar conditions,58;58;58;58;58,34;34;34;34;34,m;f,canada,ca,y,5;4
8044,ICLR,2021,Effective and Efficient Vote Attack on Capsule Networks,Jindong Gu;Baoyuan Wu;Volker Tresp,~Jindong_Gu1;~Baoyuan_Wu1;~Volker_Tresp1,6;5;8;6,3;3;2;4,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Munich;The Chinese University of Hong Kong, Shenzhen;Ludwig Maximilian University of Munich",Capsule Networks;Adversarial Attacks;Adversarial Example Detection,128;46;-1,41;39;-1,m;m,NAN,NAN,n,4
8045,ICLR,2021,Sparse Quantized Spectral Clustering,Zhenyu Liao;Romain Couillet;Michael W. Mahoney,~Zhenyu_Liao1;~Romain_Couillet1;~Michael_W._Mahoney1,7;7;7;6,4;2;3;3,Accept (Spotlight),0,4,0.0,yes,9/28/20,Huazhong University of Science and Technology;;University of California Berkeley,Eigenspectrum;high-dimensional statistic;random matrix theory;spectral clustering,-1;-1;-1,312;-1;7,m;m,usa,usa,y,1
8046,ICLR,2021,Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks,Yige Li;Xixiang Lyu;Nodens Koren;Lingjuan Lyu;Bo Li;Xingjun Ma,~Yige_Li1;xxlv@mail.xidian.edu.cn;~Nodens_Koren1;~Lingjuan_Lyu1;~Bo_Li19;~Xingjun_Ma1,7;6;7;7,4;4;4;5,Accept (Poster),0,9,0.0,yes,9/28/20,"Xidian University;;;The University of Melbourne;the University of Melbourne;University of Illinois, Urbana Champaign;Deakin University",Backdoor Defense;Deep Neural Networks;Neural Attention Distillation,-1;-1;-1;85;85;-1;-1,924;-1;-1;31;31;-1;295,m;m,asia,cn,n,8;4
8047,ICLR,2021,You Only Need Adversarial Supervision for Semantic Image Synthesis,Edgar Sch√∂nfeld;Vadim Sushko;Dan Zhang;Juergen Gall;Bernt Schiele;Anna Khoreva,~Edgar_Sch√∂nfeld1;~Vadim_Sushko1;~Dan_Zhang1;~Juergen_Gall1;~Bernt_Schiele1;~Anna_Khoreva1,7;7;6,5;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Bosch;Robert Bosch GmbH, Bosch;Bosch center for artificial intelligence;University of Bonn;Max Planck Institute for Informatics, Saarland Informatics Campus;Bosch Center for Artificial Intelligence",Semantic Image Synthesis;GANs;Image Generation;Deep Learning,-1;-1;-1;128;-1;-1,285;-1;-1;114;-1;-1,m;f,NAN,NAN,n,2;5;4
8048,ICLR,2021,GANs Can Play Lottery Tickets Too,Xuxi Chen;Zhenyu Zhang;Yongduo Sui;Tianlong Chen,~Xuxi_Chen1;~Zhenyu_Zhang4;~Yongduo_Sui1;~Tianlong_Chen1,6;6;8;6,4;4;3;3,Accept (Poster),0,9,0.0,yes,9/28/20,"University of Texas, Austin;University of Science and Technology of China;University of Science and Technology of China;University of Texas, Austin",lottery tickets;GAN compression;generative adversarial networks,-1;-1;-1;-1,-1;87;87;-1,m;m,usa,usa,n,5;4
8049,ICLR,2021,Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers,Kaidi Xu;Huan Zhang;Shiqi Wang;Yihan Wang;Suman Jana;Xue Lin;Cho-Jui Hsieh,~Kaidi_Xu1;~Huan_Zhang1;~Shiqi_Wang2;~Yihan_Wang2;~Suman_Jana1;~Xue_Lin1;~Cho-Jui_Hsieh1,7;5;5;5,4;2;1;2,Accept (Poster),0,12,0.0,yes,9/28/20,"Northeastern University;Carnegie Mellon University;Columbia University;University of California, Los Angeles;Columbia University;Northeastern University;Amazon",neural network verification;branch and bound,16;1;23;-1;23;16;-1,895;28;17;15;17;895;-1,m;m,NAN,NAN,y,1
8050,ICLR,2021,Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning,Haibo Yang;Minghong Fang;Jia Liu,~Haibo_Yang1;myfang@iastate.edu;~Jia_Liu1,7;6;7,4;5;5,Accept (Poster),0,6,0.0,yes,9/28/20,Ohio State University;The Ohio State University;The Ohio State University,Federated Learning;Linear Speedup;Partial Worker Participation,58;58;58,78;-1;-1,m;m,NAN,NAN,y,8;9
8051,ICLR,2021,"A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference",Sanghyun Hong;Yigitcan Kaya;Ionu»õ-Vlad Modoranu;Tudor Dumitras,~Sanghyun_Hong1;~Yigitcan_Kaya1;modoranu.ionut.vlad@hotmail.com;~Tudor_Dumitras1,3;6;8;7,3;3;5;4,Accept (Spotlight),0,7,0.0,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;University of Maryland, College Park;University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park;University of Maryland, College Park",Slowdown attacks;efficient inference;input-adaptive multi-exit neural networks;adversarial examples,-1;12;-1;12,90;90;90;90,m;m,usa,usa,n,4
8052,ICLR,2021,Explainable Deep One-Class Classification,Philipp Liznerski;Lukas Ruff;Robert A. Vandermeulen;Billy Joe Franks;Marius Kloft;Klaus Robert Muller,~Philipp_Liznerski1;~Lukas_Ruff1;~Robert_A._Vandermeulen2;b_franks12@cs.uni-kl.de;~Marius_Kloft1;~Klaus_Robert_Muller1,7;8;4,4;4;1,Accept (Poster),0,4,0.0,yes,9/28/20,Technische Universit√§t Kaiserslautern;Aignostics GmbH;TU Berlin;;;TU Kaiserslautern;TU Berlin,anomaly-detection;deep-learning;explanations;interpretability;xai;one-class-classification;deep-anomaly-detection;novelty-detection;outlier-detection,-1;-1;128;-1;-1;174;128,-1;-1;-1;-1;-1;-1;-1,m;m,europe,de,n,
8053,ICLR,2021,Do not Let Privacy Overbill Utility:  Gradient Embedding Perturbation for Private Learning,Da Yu;Huishuai Zhang;Wei Chen;Tie-Yan Liu,~Da_Yu1;~Huishuai_Zhang3;~Wei_Chen1;~Tie-Yan_Liu1,6;7;5;9,4;3;5;4,Accept (Poster),0,13,0.0,yes,9/28/20,SUN YAT-SEN UNIVERSITY;Microsoft Research Asia;Microsoft;Microsoft,privacy preserving machine learning;differentially private deep learning;gradient redundancy,-1;-1;-1;-1,293;-1;-1;-1,m;m,NAN,NAN,y,1
8054,ICLR,2021,Learning Accurate Entropy Model with Global Reference for Image Compression,Yichen Qian;Zhiyu Tan;Xiuyu Sun;Ming Lin;Dongyang Li;Zhenhong Sun;Li Hao;Rong Jin,~Yichen_Qian1;zhiyu.tzy@alibaba-inc.com;~Xiuyu_Sun1;~Ming_Lin4;yingtian.ldy@alibaba-inc.com;zhenhong.szh@alibaba-inc.com;~Li_Hao1;~Rong_Jin1,6;5;6;7,4;5;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"Beijing University of Post and Telecommunication, Tsinghua University;Tianjin University;Alibaba Group;Alibaba Group;;;;;Alibaba Group;Alibaba Group",Image compression;Entropy Model;Global Reference,4;-1;-1;-1;-1;-1;-1;-1;-1;-1,20;496;-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n,
8055,ICLR,2021,Robust Overfitting may be mitigated by properly learned smoothening,Tianlong Chen;Zhenyu Zhang;Sijia Liu;Shiyu Chang;Zhangyang Wang,~Tianlong_Chen1;~Zhenyu_Zhang4;~Sijia_Liu1;~Shiyu_Chang2;~Zhangyang_Wang1,6;7;7,3;4;5,Accept (Poster),0,12,0.0,yes,9/28/20,"University of Texas, Austin;University of Science and Technology of China;Michigan State University;UC Santa Barbara;University of Texas, Austin",Robust Overfitting;Adversarial Training;Adversarial Robustness,-1;-1;110;-1;-1,-1;87;105;-1;-1,m;m,usa,usa,n,4
8056,ICLR,2021,Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning,Tianlong Chen;Zhenyu Zhang;Sijia Liu;Shiyu Chang;Zhangyang Wang,~Tianlong_Chen1;~Zhenyu_Zhang4;~Sijia_Liu1;~Shiyu_Chang2;~Zhangyang_Wang1,8;7;5,3;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Texas, Austin;University of Science and Technology of China;Michigan State University;UC Santa Barbara;University of Texas, Austin",lottery tickets;winning tickets;lifelong learning,-1;-1;110;-1;-1,-1;87;105;-1;-1,m;m,usa,usa,n,
8057,ICLR,2021,Unlearnable Examples: Making Personal Data Unexploitable,Hanxun Huang;Xingjun Ma;Sarah Monazam Erfani;James Bailey;Yisen Wang,~Hanxun_Huang1;~Xingjun_Ma1;~Sarah_Monazam_Erfani1;~James_Bailey1;~Yisen_Wang1,7;7;8;7,4;3;4;4,Accept (Spotlight),0,9,0.0,yes,9/28/20,The University of Melbourne;Deakin University;;University of Melbourne;The University of Melbourne;Peking University,Unlearnable Examples;Data Protection;Adversarial Machine Learning,85;-1;-1;85;85;14,31;295;-1;31;31;23,m;m,asia,cn,n,2
8058,ICLR,2021,Distributional Sliced-Wasserstein and Applications to Generative Modeling,Khai Nguyen;Nhat Ho;Tung Pham;Hung Bui,~Khai_Nguyen1;~Nhat_Ho1;v.tungph4@vinai.io;~Hung_Bui1,7;7;9,5;4;5,Accept (Spotlight),0,7,0.0,yes,9/28/20,"VinAI Research, Vietnam;University of Texas, Austin;Vietnam National University;Google DeepMind",Deep generative models;Sliced Wasserstein;Optimal Transport,-1;-1;-1;-1,-1;-1;924;-1,m;m,NAN,NAN,y,1;5
8059,ICLR,2021,Efficient Continual Learning with Modular Networks and Task-Driven Priors,Tom Veniat;Ludovic Denoyer;MarcAurelio Ranzato,~Tom_Veniat1;~Ludovic_Denoyer1;~MarcAurelio_Ranzato1,6;6;7;7,4;4;3;3,Accept (Poster),0,12,0.0,yes,9/28/20,"ISIR, UMR 7222;Criteo;Facebook",Continual learning;Lifelong learning;Benchmark;Modular network;Neural Network,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
8060,ICLR,2021,Intraclass clustering: an implicit learning ability that regularizes DNNs,Simon Carbonnelle;Christophe De Vleeschouwer,~Simon_Carbonnelle1;~Christophe_De_Vleeschouwer1,6;6;7;8,4;4;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,Universit√© catholique de Louvain;Universit√© catholique de Louvain,deep learning;generalization;implicit regularization,-1;-1,164;164,m;m,NAN,NAN,n,1
8061,ICLR,2021,Learning Better Structured Representations Using Low-rank Adaptive Label Smoothing,Asish Ghoshal;Xilun Chen;Sonal Gupta;Luke Zettlemoyer;Yashar Mehdad,~Asish_Ghoshal2;~Xilun_Chen1;sonalgupta@fb.com;~Luke_Zettlemoyer1;~Yashar_Mehdad2,6;7;6;6,2;4;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,Facebook AI;Facebook;Facebook;Facebook;Facebook,label smoothing;calibration;semantic parsing;structured prediction,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,3;11;1
8062,ICLR,2021,Creative Sketch Generation,Songwei Ge;Vedanuj Goswami;Larry Zitnick;Devi Parikh,~Songwei_Ge2;~Vedanuj_Goswami1;~Larry_Zitnick1;~Devi_Parikh1,6;7;7;7,4;4;3;4,Accept (Poster),0,8,0.0,yes,9/28/20,"University of Maryland, College Park;Georgia Institute of Technology;Facebook;Georgia Institute of Technology",creativity;sketches;part-based;GAN;dataset;generative art,12;12;-1;12,90;38;-1;38,m;f,usa,usa,n,5;4
8063,ICLR,2021,Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control,Zhuang Liu;Xuanlin Li;Bingyi Kang;Trevor Darrell,~Zhuang_Liu1;~Xuanlin_Li1;~Bingyi_Kang1;~Trevor_Darrell2,6;7;7;7,4;5;4;3,Accept (Spotlight),0,16,0.0,yes,9/28/20,"University of California Berkeley;University of California, San Diego;National University of Singapore;Electrical Engineering & Computer Science Department",Policy Optimization;Regularization;Continuous Control;Deep Reinforcement Learning,-1;-1;17;-1,7;33;25;-1,m;m,NAN,NAN,n,8;1
8064,ICLR,2021,Learning with AMIGo: Adversarially Motivated Intrinsic Goals,Andres Campero;Roberta Raileanu;Heinrich Kuttler;Joshua B. Tenenbaum;Tim Rockt√§schel;Edward Grefenstette,~Andres_Campero1;~Roberta_Raileanu2;~Heinrich_Kuttler1;~Joshua_B._Tenenbaum1;~Tim_Rockt√§schel1;~Edward_Grefenstette1,7;7;6;6,3;4;4;4,Accept (Poster),0,20,0.0,yes,9/28/20,Massachusetts Institute of Technology;New York University;Facebook;Massachusetts Institute of Technology;Facebook AI Research;Facebook,reinforcement learning;exploration;meta-learning,5;23;-1;5;-1;-1,4;26;-1;4;-1;-1,m;m,NAN,NAN,n,6;4
8065,ICLR,2021,Projected Latent Markov Chain Monte Carlo: Conditional Sampling of Normalizing Flows,Chris Cannella;Mohammadreza Soltani;Vahid Tarokh,~Chris_Cannella1;~Mohammadreza_Soltani1;~Vahid_Tarokh1,6;7;6,3;4;4,Accept (Poster),0,3,0.0,yes,9/28/20,Duke University;Duke University;Duke University,Conditional Sampling;Normalizing Flows;Markov Chain Monte Carlo;Missing Data Inference,46;46;46,20;20;20,m;m,europe,se,n,
8066,ICLR,2021,LiftPool: Bidirectional ConvNet Pooling,Jiaojiao Zhao;Cees G. M. Snoek,~Jiaojiao_Zhao2;~Cees_G._M._Snoek1,7;8;5;7,4;4;4;5,Accept (Poster),0,8,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam,bidirectional;pooling,128;128,66;66,f;m,europe,nl,n,2
8067,ICLR,2021,Unbiased Teacher for Semi-Supervised Object Detection,Yen-Cheng Liu;Chih-Yao Ma;Zijian He;Chia-Wen Kuo;Kan Chen;Peizhao Zhang;Bichen Wu;Zsolt Kira;Peter Vajda,~Yen-Cheng_Liu1;~Chih-Yao_Ma1;zijian@fb.com;~Chia-Wen_Kuo1;~Kan_Chen1;~Peizhao_Zhang1;~Bichen_Wu1;~Zsolt_Kira1;~Peter_Vajda1,7;7;9;6,5;4;4;3,Accept (Poster),0,7,0.0,yes,9/28/20,"Georgia Institute of Technology;Facebook;, University of California, Los Angeles;Georgia Institute of Technology;Facebook;Facebook;Facebook;Georgia Institute of Technology;Stanford University",Object Detection,12;-1;-1;12;-1;-1;-1;12;5,38;-1;15;38;-1;-1;-1;38;2,m;m,usa,usa,n,2
8068,ICLR,2021,Shapley explainability on the data manifold,Christopher Frye;Damien de Mijolla;Tom Begley;Laurence Cowton;Megan Stanley;Ilya Feige,~Christopher_Frye1;damiendemijolla@gmail.com;~Tom_Begley1;laurence.c@faculty.ai;t-mestan@microsoft.com;~Ilya_Feige1,7;7;6;8,4;5;3;3,Accept (Poster),0,7,0.0,yes,9/28/20,Faculty;University College London;Faculty;University of Cambridge;;;University College London,,-1;53;-1;79;-1;-1;53,-1;-1;-1;6;-1;-1;-1,m;m,europe,uk,n,5
8069,ICLR,2021,Deciphering and Optimizing Multi-Task Learning: a Random Matrix Approach,Malik Tiomoko;Hafiz Tiomoko Ali;Romain Couillet,~Malik_Tiomoko1;~Hafiz_Tiomoko_Ali1;~Romain_Couillet1,6;7;6;7,3;3;3;3,Accept (Spotlight),0,5,0.0,yes,9/28/20,UPSud/INRIA University Paris-Saclay;Huawei Technologies Ltd.;UPSud/INRIA University Paris-Saclay,Transfer Learning;Multi Task Learning;Random Matrix Theory,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,6;1
8070,ICLR,2021,Set Prediction without Imposing Structure as Conditional Density Estimation,David W Zhang;Gertjan J. Burghouts;Cees G. M. Snoek,~David_W_Zhang1;gertjan.burghouts@tno.nl;~Cees_G._M._Snoek1,7;6;7;6,3;2;3;3,Accept (Poster),0,4,0.0,yes,9/28/20,University of Amsterdam;TNO;University of Amsterdam,set prediction;energy based models,128;263;128,66;-1;66,m;m,europe,nl,n,
8071,ICLR,2021,Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits,Jiawang Bai;Baoyuan Wu;Yong Zhang;Yiming Li;Zhifeng Li;Shu-Tao Xia,~Jiawang_Bai2;~Baoyuan_Wu1;~Yong_Zhang6;~Yiming_Li1;~Zhifeng_Li5;~Shu-Tao_Xia1,6;5;6;7,4;4;3;2,Accept (Poster),0,7,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;The Chinese University of Hong Kong, Shenzhen;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tsinghua University;Tencent;Graduate School at Shenzhen, Tsinghua University",targeted attack;bit-flip;weight attack,4;46;34;4;-1;4,20;39;-1;20;-1;20,m;m,NAN,NAN,n,4
8072,ICLR,2021,Effective Distributed Learning with Random Features: Improved Bounds and Algorithms,Yong Liu;Jiankun Liu;Shuqiang Wang,liuyonggsai@ruc.edu.cn;liujiankun@iie.ac.cn;sq.wang@siat.ac.cn,6;4;6,3;4;3,Accept (Poster),0,5,0.0,yes,9/28/20,"Renmin University of China;Institute of Information Engineering, CAS;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences",Risk bound;statistical learning theory;kernel methods,85;-1;34,517;-1;-1,m;m,NAN,NAN,y,1
8073,ICLR,2021,Large-width functional asymptotics for deep Gaussian neural networks,Daniele Bracale;Stefano Favaro;Sandra Fortini;Stefano Peluchetti,daniele.bracale@edu.unito.it;~Stefano_Favaro1;sandra.fortini@unibocconi.it;~Stefano_Peluchetti1,7;6;4;7,3;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,Unito;University of Torino;;;The university of Warwick,deep learning theory;infinitely wide neural network;Gaussian process;stochastic process,-1;18;-1;-1;-1,-1;18;-1;-1;77,m;m,NAN,NAN,y,
8074,ICLR,2021,Return-Based Contrastive Representation Learning for Reinforcement  Learning,Guoqing Liu;Chuheng Zhang;Li Zhao;Tao Qin;Jinhua Zhu;Li Jian;Nenghai Yu;Tie-Yan Liu,~Guoqing_Liu3;~Chuheng_Zhang1;~Li_Zhao1;~Tao_Qin1;~Jinhua_Zhu1;~Li_Jian1;~Nenghai_Yu1;~Tie-Yan_Liu1,7;6;7;6,3;4;4;3,Accept (Poster),0,15,0.0,yes,9/28/20,"University of Science and Technology of China;IIIS, Tsinghua University;Tsinghua University;Tsinghua University;University of Science and Technology of China;University of Maryland, College Park;University of Science and Technology of China;Microsoft",reinforcement learning;auxiliary task;representation learning;contrastive learning,-1;4;4;4;-1;12;-1;-1,87;20;20;20;87;90;87;-1,m;m,NAN,NAN,y,
8075,ICLR,2021,Universal approximation power of deep residual neural networks via nonlinear control theory,Paulo Tabuada;Bahman Gharesifard,~Paulo_Tabuada1;bahman.gharesifard@queensu.ca,6;6;6;7,3;4;4;3,Accept (Poster),0,0,0.0,yes,9/28/20,"University of California, Los Angeles;Queens University",Deep residual neural networks;universal approximation;nonlinear control theory,-1;263,15;273,m;m,canada,ca,y,
8076,ICLR,2021,Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option Framework for Task-oriented Dialogue System,Jianhong Wang;Yuan Zhang;Tae-Kyun Kim;Yunjie Gu,~Jianhong_Wang1;~Yuan_Zhang7;~Tae-Kyun_Kim2;yunjie.gu@imperial.ac.uk,6;6;6;7,4;4;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,Imperial College London;University College London;Imperial College London;Imperial College London,Task-oriented Dialogue System;Natural Language Processing;Hierarchical Reinforcement Learning;Policy Optimization,53;53;53;53,11;-1;11;11,m;m,europe,uk,y,3
8077,ICLR,2021,Discovering a set of policies for the worst case reward,Tom Zahavy;Andre Barreto;Daniel J Mankowitz;Shaobo Hou;Brendan O'Donoghue;Iurii Kemaev;Satinder Singh,~Tom_Zahavy2;~Andre_Barreto1;~Daniel_J_Mankowitz2;~Shaobo_Hou1;~Brendan_O'Donoghue1;iukemaev@google.com;~Satinder_Singh2,7;7;6;8,4;4;4;3,Accept (Spotlight),0,16,0.0,yes,9/28/20,DeepMind;DeepMind;Google;DeepMind;DeepMind;DeepMind;University of Michigan,,-1;-1;-1;-1;-1;-1;7,-1;-1;-1;-1;-1;-1;22,m;m,usa,usa,y,
8078,ICLR,2021,Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels,Binxin Ru;Xingchen Wan;Xiaowen Dong;Michael Osborne,~Binxin_Ru1;~Xingchen_Wan1;~Xiaowen_Dong1;~Michael_Osborne1,5;9;7;7,2;4;4;3,Accept (Poster),0,17,0.0,yes,9/28/20,"University of Oxford;University of Oxford, University of Oxford;University of Oxford;University of Oxford",,46;46;46;46,1;1;1;1,m;m,europe,uk,n,11;10
8079,ICLR,2021,HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients,Enmao Diao;Jie Ding;Vahid Tarokh,~Enmao_Diao1;~Jie_Ding2;~Vahid_Tarokh1,6;7;7;6,5;4;5;3,Accept (Poster),0,14,0.0,yes,9/28/20,"Duke University;University of Minnesota, Minneapolis;Duke University",Federated Learning;Internet of Things;Heterogeneity,46;71;46,20;85;20,m;m,europe,se,n,
8080,ICLR,2021,On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers,Kenji Kawaguchi,~Kenji_Kawaguchi1,8;7;7;7,3;3;3;3,Accept (Spotlight),0,9,0.0,yes,9/28/20,Harvard University,Implicit Deep Learning;Deep Equilibrium Models;Gradient Descent;Learning Theory;Non-Convex Optimization,53,3,m,usa,usa,y,1
8081,ICLR,2021,Optimism in Reinforcement Learning with Generalized Linear Function Approximation,Yining Wang;Ruosong Wang;Simon Shaolei Du;Akshay Krishnamurthy,~Yining_Wang1;~Ruosong_Wang1;~Simon_Shaolei_Du1;~Akshay_Krishnamurthy1,5;6;7;6,3;4;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;Carnegie Mellon University;Facebook;Microsoft Research",reinforcement learning;optimism;exploration;function approximation;theory;regret analysis;provable sample efficiency,1;1;-1;-1,28;28;-1;-1,m;m,NAN,NAN,y,1
8082,ICLR,2021,Property Controllable Variational Autoencoder via Invertible Mutual Dependence,Xiaojie Guo;Yuanqi Du;Liang Zhao,~Xiaojie_Guo1;~Yuanqi_Du1;~Liang_Zhao1,6;6;6;6,4;3;4;3,Accept (Poster),0,16,0.0,yes,9/28/20,George Mason University;George Mason University;Emory University,deep generative models;interpretable latent representation;disentangled representation learning,85;85;174,267;267;85,f;m,canada,ca,n,8;11;5
8083,ICLR,2021,Differentially Private Learning Needs Better Features (or Much More Data),Florian Tramer;Dan Boneh,~Florian_Tramer1;~Dan_Boneh1,6;7;7;7,5;3;4;2,Accept (Spotlight),0,11,0.0,yes,9/28/20,Stanford University;Stanford University,Differential Privacy;Privacy;Deep Learning,5;5,2;2,m;m,usa,usa,n,
8084,ICLR,2021,Proximal Gradient Descent-Ascent: Variable Convergence under K≈Å Geometry,Ziyi Chen;Yi Zhou;Tengyu Xu;Yingbin Liang,~Ziyi_Chen2;~Yi_Zhou2;~Tengyu_Xu1;~Yingbin_Liang1,5;8;8;7,4;4;5;3,Accept (Poster),0,5,0.0,yes,9/28/20,University of Utah;University of Utah;Ohio State University;The Ohio State University,Kurdyka-≈Åojasiewicz geometry;minimax;nonconvex;proximal gradient descent-ascent;variable convergence,58;58;58;58,239;239;78;-1,m;f,NAN,NAN,y,9
8085,ICLR,2021,Adversarially Guided Actor-Critic,Yannis Flet-Berliac;Johan Ferret;Olivier Pietquin;Philippe Preux;Matthieu Geist,~Yannis_Flet-Berliac1;~Johan_Ferret1;~Olivier_Pietquin1;~Philippe_Preux1;~Matthieu_Geist1,7;5;7,2;3;2,Accept (Poster),0,4,0.0,yes,9/28/20,Inria (SequeL team) / Univ. Lille;Google;Google Brain;Universit√© de Lille;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,4
8086,ICLR,2021,Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments,Daochen Zha;Wenye Ma;Lei Yuan;Xia Hu;Ji Liu,~Daochen_Zha1;mawenye@gmail.com;~Lei_Yuan1;~Xia_Hu4;~Ji_Liu1,7;6;7;7,3;3;4;3,Accept (Poster),0,11,0.0,yes,9/28/20,Texas A&M;;;;Arizona State University;Texas A&M;Kwai Inc.,Reinforcement Learning;Exploration;Generalization of Reinforcement Learning;Self-Imitation,46;-1;-1;-1;85;46;-1,195;-1;-1;-1;182;195;-1,m;m,NAN,NAN,n,
8087,ICLR,2021,Zero-shot Synthesis with Group-Supervised Learning,Yunhao Ge;Sami Abu-El-Haija;Gan Xin;Laurent Itti,~Yunhao_Ge1;~Sami_Abu-El-Haija1;~Gan_Xin1;~Laurent_Itti1,7;6;7;8,3;4;4;3,Accept (Poster),0,11,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California;;University of Southern California;University of Southern California,Disentangled representation learning;Group-supervised learning;Zero-shot synthesis;Knowledge factorization,37;37;37;-1;37;37,53;53;53;-1;53;53,m;m,usa,usa,n,6
8088,ICLR,2021,Improving Relational Regularized Autoencoders with Spherical Sliced Fused Gromov Wasserstein,Khai Nguyen;Son Nguyen;Nhat Ho;Tung Pham;Hung Bui,~Khai_Nguyen1;v.sonnv27@vinai.io;~Nhat_Ho1;v.tungph4@vinai.io;~Hung_Bui1,6;6;7,3;4;5,Accept (Poster),0,9,0.0,yes,9/28/20,"VinAI Research, Vietnam;VinAI Research Viet Nam;University of Texas, Austin;Vietnam National University;Google DeepMind",Relational regularized autoencoder;deep generative model;sliced fused Gromov Wasserstein;spherical distributions,-1;-1;-1;-1;-1,-1;-1;-1;924;-1,m;m,NAN,NAN,y,
8089,ICLR,2021,VA-RED$^2$: Video Adaptive Redundancy Reduction,Bowen Pan;Rameswar Panda;Camilo Luciano Fosco;Chung-Ching Lin;Alex J Andonian;Yue Meng;Kate Saenko;Aude Oliva;Rogerio Feris,~Bowen_Pan2;~Rameswar_Panda1;~Camilo_Luciano_Fosco1;~Chung-Ching_Lin2;~Alex_J_Andonian1;~Yue_Meng1;~Kate_Saenko1;~Aude_Oliva1;~Rogerio_Feris1,6;6;6,4;1;4,Accept (Poster),0,4,0.0,yes,9/28/20,"Massachusetts Institute of Technology;MIT-IBM Watson AI Lab, IBM Research;Massachusetts Institute of Technology;Microsoft;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Boston University;Massachusetts Institute of Technology;International Business Machines",,5;-1;5;-1;5;5;79;5;-1,4;-1;4;-1;4;4;54;4;-1,m;m,NAN,NAN,n,
8090,ICLR,2021,Directed Acyclic Graph Neural Networks,Veronika Thost;Jie Chen,~Veronika_Thost1;~Jie_Chen1,7;7;6,3;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,International Business Machines;International Business Machines,Graph Neural Networks;Graph Representation Learning;Directed Acyclic Graphs;DAG;Inductive Bias,-1;-1,-1;-1,f;m,NAN,NAN,y,10
8091,ICLR,2021,BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization,Huanrui Yang;Lin Duan;Yiran Chen;Hai Li,~Huanrui_Yang1;ld213@duke.edu;~Yiran_Chen1;~Hai_Li1,6;6;6;7,4;3;4;4,Accept (Poster),0,12,0.0,yes,9/28/20,NVIDIA;;;Duke University;Duke University,Mixed-precision quantization;bit-level sparsity;DNN compression,-1;-1;-1;46;46,-1;-1;-1;20;20,m;f,europe,se,n,
8092,ICLR,2021,Training with Quantization Noise for Extreme Model Compression,Pierre Stock;Angela Fan;Benjamin Graham;Edouard Grave;R√©mi Gribonval;Herve Jegou;Armand Joulin,~Pierre_Stock1;~Angela_Fan2;~Benjamin_Graham1;~Edouard_Grave1;~R√©mi_Gribonval1;~Herve_Jegou1;~Armand_Joulin1,4;4;6;10;5,4;4;3;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,Facebook;Facebook;Facebook;Facebook;INRIA;Facebook;Facebook,Compression;Efficiency;Product Quantization,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
8093,ICLR,2021,Greedy-GQ with Variance Reduction: Finite-time Analysis and Improved Complexity,Shaocong Ma;Ziyi Chen;Yi Zhou;Shaofeng Zou,~Shaocong_Ma1;~Ziyi_Chen2;~Yi_Zhou2;~Shaofeng_Zou1,5;6;3;8;8,3;4;5;3;5,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Utah;University of Utah;University of Utah;State University of New York, Buffalo",Optimization;Reinforcement Learning;Machine Learning,58;58;58;-1,239;239;239;-1,m;m,NAN,NAN,y,1;9
8094,ICLR,2021,MODALS: Modality-agnostic Automated Data Augmentation in the Latent Space,Tsz-Him Cheung;Dit-Yan Yeung,~Tsz-Him_Cheung1;~Dit-Yan_Yeung2,6;6;7;6,4;3;5;4,Accept (Poster),0,4,0.0,yes,9/28/20,The Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,deep learning;data augmentation;automated data augmentation;latent space,-1;-1,56;56,m;m,NAN,NAN,n,1;10
8095,ICLR,2021,Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning,Enrico Marchesini;Davide Corsi;Alessandro Farinelli,~Enrico_Marchesini1;davide.corsi@univr.it;~Alessandro_Farinelli1,6;7;6,3;4;4,Accept (Poster),0,13,0.0,yes,9/28/20,Universit√† degli Studi di Verona;Universit√† degli Studi di Verona;Universit√† degli Studi di Verona,Deep Reinforcement Learning;Evolutionary Algorithms;Formal Verification;Machine Learning for Robotics,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
8096,ICLR,2021,Fidelity-based Deep Adiabatic Scheduling,Eli Ovits;Lior Wolf,eliovify@gmail.com;~Lior_Wolf1,6;6;8;9,4;4;4;5,Accept (Spotlight),0,5,0.0,yes,9/28/20,Tel Aviv University;Tel Aviv University,,34;34,190;190,m;m,europe,il,n,
8097,ICLR,2021,ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations,Rishabh Tiwari;Udbhav Bamba;Arnav Chavan;Deepak Gupta,~Rishabh_Tiwari1;~Udbhav_Bamba1;~Arnav_Chavan1;~Deepak_Gupta2,6;6;7;7,4;3;3;4,Accept (Poster),0,7,0.0,yes,9/28/20,"Indian Institute of Technology (ISM) Dhanbad;Indian Institute of Technology (ISM) Dhanbad;Indian Institute of Technology (Indian School of Mines), Dhanbad;Transmute AI Research",Structured Pruning;Budget-Aware Pruning;Budget constraints;Sparsity Learning,-1;-1;-1;-1,-1;-1;919;-1,m;m,NAN,NAN,n,
8098,ICLR,2021,Taming GANs with Lookahead-Minmax,Tatjana Chavdarova;Matteo Pagliardini;Sebastian U Stich;Fran√ßois Fleuret;Martin Jaggi,~Tatjana_Chavdarova2;~Matteo_Pagliardini1;~Sebastian_U_Stich1;~Fran√ßois_Fleuret2;~Martin_Jaggi1,7;6;4;7,5;3;4;2,Accept (Poster),0,8,0.0,yes,9/28/20,"Electrical Engineering & Computer Science Department, University of California Berkeley;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;University of Geneva;EPFL",Minmax;Generative Adversarial Networks,-1;-1;-1;-1;23,-1;-1;-1;149;-1,f;m,europe,ch,y,5;4
8099,ICLR,2021,Rethinking Soft Labels for Knowledge Distillation: A Bias‚ÄìVariance Tradeoff Perspective,Helong Zhou;Liangchen Song;Jiajie Chen;Ye Zhou;Guoli Wang;Junsong Yuan;Qian Zhang,~Helong_Zhou1;~Liangchen_Song1;~Jiajie_Chen1;~Ye_Zhou2;~Guoli_Wang2;~Junsong_Yuan2;~Qian_Zhang7,7;4;7;6,3;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Horizon Robotics;State University of New York, Buffalo;Horizon Robotics;Horizon Robotics;Tsinghua University, Tsinghua University;State University of New York, Buffalo;Horizon Robotics",Knowledge distillation;soft labels;teacher-student model,-1;-1;-1;-1;4;-1;-1,-1;-1;-1;-1;20;-1;-1,m;m,NAN,NAN,n,
8100,ICLR,2021,When does preconditioning help or hurt generalization?,Shun-ichi Amari;Jimmy Ba;Roger Baker Grosse;Xuechen Li;Atsushi Nitanda;Taiji Suzuki;Denny Wu;Ji Xu,~Shun-ichi_Amari1;~Jimmy_Ba1;~Roger_Baker_Grosse1;~Xuechen_Li1;~Atsushi_Nitanda1;~Taiji_Suzuki1;~Denny_Wu2;~Ji_Xu1,8;7;6,4;3;3,Accept (Poster),0,9,0.0,yes,9/28/20,The University of Tokyo;Department of Computer Science  University of Toronto;Department of Computer Science  University of Toronto;Stanford University;Kyushu Institute of Technology;The University of Tokyo;University of Toronto;Columbia University,generalization;second-order optimization;natural gradient descent;high-dimensional asymptotics,71;18;18;5;-1;71;18;23,36;18;18;2;1152;36;18;17,m;m,usa,usa,y,1
8101,ICLR,2021,Learning Robust State Abstractions for Hidden-Parameter Block MDPs,Amy Zhang;Shagun Sodhani;Khimya Khetarpal;Joelle Pineau,~Amy_Zhang1;~Shagun_Sodhani1;~Khimya_Khetarpal1;~Joelle_Pineau1,7;7;6;7,3;4;2;3,Accept (Poster),0,8,0.0,yes,9/28/20,University of California Berkeley;Facebook;McGill University;Facebook,multi-task reinforcement learning;bisimulation;hidden-parameter mdp;block mdp,-1;-1;99;-1,7;-1;40;-1,f;f,NAN,NAN,y,1
8102,ICLR,2021,On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning,Ren Wang;Kaidi Xu;Sijia Liu;Pin-Yu Chen;Tsui-Wei Weng;Chuang Gan;Meng Wang,~Ren_Wang1;~Kaidi_Xu1;~Sijia_Liu1;~Pin-Yu_Chen1;~Tsui-Wei_Weng1;~Chuang_Gan1;~Meng_Wang4,6;6;6;6,4;2;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Michigan;Northeastern University;Michigan State University;International Business Machines;University of California, San Diego;MIT-IBM Watson AI Lab;Rensselaer Polytechnic Institute",,7;16;110;-1;-1;-1;263,22;895;105;-1;33;-1;527,m;f,usa,usa,n,6;1;4
8103,ICLR,2021,DeLighT: Deep and Light-weight Transformer,Sachin Mehta;Marjan Ghazvininejad;Srinivasan Iyer;Luke Zettlemoyer;Hannaneh Hajishirzi,~Sachin_Mehta1;~Marjan_Ghazvininejad1;sviyer@fb.com;~Luke_Zettlemoyer1;~Hannaneh_Hajishirzi1,6;6;6;7,4;4;4;4,Accept (Poster),0,30,0.0,yes,9/28/20,"University of Washington, Seattle;Facebook AI Research;University of Washington, Seattle;Facebook;University of Washington",Transformers;Sequence Modeling;Machine Translation;Language Modeling;Representation learning;Efficient Networks,11;-1;11;-1;11,29;-1;29;-1;29,m;f,usa,usa,n,8;3
8104,ICLR,2021,Learning to Set Waypoints for Audio-Visual Navigation,Changan Chen;Sagnik Majumder;Ziad Al-Halah;Ruohan Gao;Santhosh Kumar Ramakrishnan;Kristen Grauman,~Changan_Chen2;~Sagnik_Majumder1;~Ziad_Al-Halah2;~Ruohan_Gao2;~Santhosh_Kumar_Ramakrishnan1;~Kristen_Grauman1,7;7;7;6,3;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Texas, Austin;University of Texas, Austin;University of Texas at Austin;Stanford University;University of Texas, Austin;Facebook",visual navigation;audio visual learning;embodied vision,-1;-1;20;5;-1;-1,-1;-1;43;2;-1;-1,m;f,NAN,NAN,n,
8105,ICLR,2021,Incremental few-shot learning via vector quantization in deep embedded space,Kuilin Chen;Chi-Guhn Lee,~Kuilin_Chen1;~Chi-Guhn_Lee1,5;6;6;5,4;4;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,"University of Toronto;Department of Mechanical and Industrial Engineering, University of Toronto, Toronto University",incremental learning;few-shot;vector quantization,18;18,18;18,m;m,NAN,NAN,n,6
8106,ICLR,2021,Uncertainty Estimation in Autoregressive Structured Prediction,Andrey Malinin;Mark Gales,~Andrey_Malinin1;~Mark_Gales1,6;7;7,4;4;3,Accept (Poster),0,15,0.0,yes,9/28/20,Yandex;University of Cambridge,ensembles;structures prediction;uncertainty estimation;knowledge uncertainty;autoregressive models;information theory;machine translation;speech recognition.,-1;79,-1;6,m;m,europe,uk,n,
8107,ICLR,2021,Emergent Road Rules In Multi-Agent Driving Environments,Avik Pal;Jonah Philion;Yuan-Hong Liao;Sanja Fidler,~Avik_Pal1;~Jonah_Philion1;~Yuan-Hong_Liao2;~Sanja_Fidler1,6;5;7;5,3;2;3;2,Accept (Poster),0,8,0.0,yes,9/28/20,"IIT Kanpur;Toronto University;University of Toronto;Department of Computer Science, University of Toronto",,128;-1;18;18,-1;-1;18;18,m;f,NAN,NAN,n,
8108,ICLR,2021,Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors,Yu Sun;Jiaming Liu;Yiran Sun;Brendt Wohlberg;Ulugbek Kamilov,~Yu_Sun11;jiaming.liu@wustl.edu;yiran.s@wustl.edu;~Brendt_Wohlberg2;~Ulugbek_Kamilov1,7;7;6;8,5;3;2;2,Accept (Spotlight),0,6,0.0,yes,9/28/20,"Washington University, St. Louis;Washington University, St. Louis;Washington University, St. Louis;Los Alamos National Laboratory;Washington University, St. Louis",Regularization by denoising;Computational imaging;asynchronous parallel algorithm;Deep denoising priors,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n,
8109,ICLR,2021,Anytime Sampling for Autoregressive Models via Ordered Autoencoding,Yilun Xu;Yang Song;Sahaj Garg;Linyuan Gong;Rui Shu;Aditya Grover;Stefano Ermon,~Yilun_Xu1;~Yang_Song1;~Sahaj_Garg1;gonglinyuan@hotmail.com;~Rui_Shu1;~Aditya_Grover1;~Stefano_Ermon1,6;6;7;6,4;3;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Massachusetts Institute of Technology;Stanford University;Stanford University;University of California Berkeley;Stanford University;Computer Science Department, Stanford University;Stanford University",,5;5;5;-1;5;5;5,4;2;2;7;2;2;2,m;m,usa,usa,n,
8110,ICLR,2021,Saliency is a Possible Red Herring When Diagnosing Poor Generalization,Joseph D Viviano;Becks Simpson;Francis Dutil;Yoshua Bengio;Joseph Paul Cohen,~Joseph_D_Viviano1;~Becks_Simpson1;~Francis_Dutil1;~Yoshua_Bengio1;~Joseph_Paul_Cohen1,7;7;7;6,4;5;3;4,Accept (Poster),0,17,0.0,yes,9/28/20,University of Montreal;University of Queensland;;University of Montreal;Stanford University,Feature Attribution;Generalization;Saliency,128;209;-1;128;5,73;62;-1;73;2,m;m,usa,usa,n,1
8111,ICLR,2021,Risk-Averse Offline Reinforcement Learning,N√∫ria Armengol Urp√≠;Sebastian Curi;Andreas Krause,~N√∫ria_Armengol_Urp√≠1;~Sebastian_Curi1;~Andreas_Krause1,6;8;5;6;7,4;3;4;3;3,Accept (Poster),0,7,0.0,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,offline;reinforcement learning;risk-averse;risk sensitive;robust;safety;safe,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y,
8112,ICLR,2021,CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers,SHIYANG LI;Semih Yavuz;Kazuma Hashimoto;Jia Li;Tong Niu;Nazneen Rajani;Xifeng Yan;Yingbo Zhou;Caiming Xiong,~SHIYANG_LI2;~Semih_Yavuz1;~Kazuma_Hashimoto1;~Jia_Li8;tniu@salesforce.com;~Nazneen_Rajani1;~Xifeng_Yan1;~Yingbo_Zhou1;~Caiming_Xiong1,6;4;7,3;5;4,Accept (Poster),0,3,0.0,yes,9/28/20,"UC Santa Barbara;SalesForce.com;SalesForce.com;Salesforce Research;Duke University;University of Texas, Austin;UC Santa Barbara;Salesforce Research;Salesforce Research",task-oriented dialogue;dialogue state tracking;robustness;dst;evaluation,-1;-1;-1;-1;46;-1;-1;-1;-1,-1;-1;-1;-1;20;-1;-1;-1;-1,m;m,NAN,NAN,n,1
8113,ICLR,2021,Open Question Answering over Tables and Text,Wenhu Chen;Ming-Wei Chang;Eva Schlinger;William Yang Wang;William W. Cohen,~Wenhu_Chen3;~Ming-Wei_Chang3;~Eva_Schlinger2;~William_Yang_Wang2;~William_W._Cohen2,7;6;6;7,4;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,UC Santa Barbara;Google;Google;UC Santa Barbara;Google,Question Answering;Tabular Data;Open-domain;Retrieval,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;10
8114,ICLR,2021,Learning Manifold Patch-Based Representations of Man-Made Shapes,Dmitriy Smirnov;Mikhail Bessmeltsev;Justin Solomon,~Dmitriy_Smirnov1;~Mikhail_Bessmeltsev1;~Justin_Solomon1,6;7;7;4,4;3;5;5,Accept (Poster),0,13,0.0,yes,9/28/20,Massachusetts Institute of Technology;University of Montreal;Massachusetts Institute of Technology,3D shape representations;CAD modeling;sketch-based modeling;computer graphics;computer vision;deep learning,5;128;5,4;73;4,m;m,usa,usa,n,
8115,ICLR,2021,Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective,Muhammet Balcilar;Guillaume Renton;Pierre H√©roux;Benoit Ga√ºz√®re;S√©bastien Adam;Paul Honeine,~Muhammet_Balcilar1;guillaume.renton@gmail.com;pierre.heroux@univ-rouen.fr;benoit.gauzere@insa-rouen.fr;~S√©bastien_Adam1;~Paul_Honeine1,6;6;8;8,4;2;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Universit√© de Rouen;;;;;;;Universit√© de Rouen;LITIS, Universit√© de Rouen Normandie, France",Graph Neural Networks;Spectral Graph Filter;Spectral Analysis,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,10
8116,ICLR,2021,Score-Based Generative Modeling through Stochastic Differential Equations,Yang Song;Jascha Sohl-Dickstein;Diederik P Kingma;Abhishek Kumar;Stefano Ermon;Ben Poole,~Yang_Song1;~Jascha_Sohl-Dickstein2;~Diederik_P_Kingma1;~Abhishek_Kumar1;~Stefano_Ermon1;~Ben_Poole1,8;9;7;8,4;4;3;3,Accept (Oral),0,7,0.0,yes,9/28/20,Stanford University;Google;Google;Google Brain;Stanford University;Google,generative models;score-based generative models;stochastic differential equations;score matching;diffusion,5;-1;-1;-1;5;-1,2;-1;-1;-1;2;-1,m;m,NAN,NAN,n,5
8117,ICLR,2021,MoPro: Webly Supervised Learning with Momentum Prototypes,Junnan Li;Caiming Xiong;Steven Hoi,~Junnan_Li2;~Caiming_Xiong1;~Steven_Hoi2,6;7;6;7,4;4;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,Salesforce Research Asia;Salesforce Research;Salesforce Research Asia,webly-supervised learning;weakly-supervised learning;contrastive learning;representation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
8118,ICLR,2021,Prototypical Contrastive Learning of Unsupervised Representations,Junnan Li;Pan Zhou;Caiming Xiong;Steven Hoi,~Junnan_Li2;~Pan_Zhou3;~Caiming_Xiong1;~Steven_Hoi2,7;6;5;7,4;5;4;3,Accept (Poster),0,4,0.0,yes,9/28/20,Salesforce Research Asia;Sea Group;Salesforce Research;Salesforce Research Asia,self-supervised learning;unsupervised learning;representation learning;contrastive learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6
8119,ICLR,2021,Spatio-Temporal Graph Scattering Transform,Chao Pan;Siheng Chen;Antonio Ortega,~Chao_Pan2;~Siheng_Chen1;~Antonio_Ortega1,6;7;9;6,5;3;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Carnegie Mellon University;University of Southern California",scattering transform;spatio-temporal graph;graph neural networks;skeleton-based action recognition,-1;1;37,-1;28;53,m;m,usa,usa,y,10
8120,ICLR,2021,Graph Traversal with Tensor Functionals: A Meta-Algorithm for Scalable Learning,Elan Sopher Markowitz;Keshav Balasubramanian;Mehrnoosh Mirtaheri;Sami Abu-El-Haija;Bryan Perozzi;Greg Ver Steeg;Aram Galstyan,~Elan_Sopher_Markowitz2;keshavba@usc.edu;mehrnoom@usc.edu;~Sami_Abu-El-Haija1;~Bryan_Perozzi1;~Greg_Ver_Steeg1;~Aram_Galstyan1,7;7;7;7,3;2;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California;University of Southern California;Google;USC/ISI;Information Sciences Institute,Graph;Learning;Algorithm;Scale;Message Passing;Node Embeddings,37;37;37;37;-1;-1;-1,53;53;53;53;-1;-1;-1,m;m,NAN,NAN,y,10
8121,ICLR,2021,Effective Abstract Reasoning with Dual-Contrast Network,Tao Zhuo;Mohan Kankanhalli,~Tao_Zhuo3;~Mohan_Kankanhalli1,7;5;8;7,3;4;4;3,Accept (Poster),0,8,0.0,yes,9/28/20,National University of Singapore;National University of Singapore,abstract reasoning;raven's progressive matrices;deep learning,17;17,25;25,m;m,asia,sg,n,1
8122,ICLR,2021,Meta-Learning with Neural Tangent Kernels,Yufan Zhou;Zhenyi Wang;Jiayi Xian;Changyou Chen;Jinhui Xu,~Yufan_Zhou1;~Zhenyi_Wang1;jxian@buffalo.edu;~Changyou_Chen1;~Jinhui_Xu1,7;7;7;5,4;5;2;4,Accept (Poster),0,6,0.0,yes,9/28/20,"State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo",meta-learning;neural tangent kernel,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,6;1;4
8123,ICLR,2021,Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy,Zuyue Fu;Zhuoran Yang;Zhaoran Wang,~Zuyue_Fu1;~Zhuoran_Yang1;~Zhaoran_Wang1,7;8;8;5,4;3;1;4,Accept (Poster),0,8,0.0,yes,9/28/20,"Northwestern University, Northwestern University;University of California Berkeley;Northwestern University",,46;-1;46,24;7;24,m;m,usa,usa,y,1;9
8124,ICLR,2021,UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers,Siyi Hu;Fengda Zhu;Xiaojun Chang;Xiaodan Liang,~Siyi_Hu1;~Fengda_Zhu1;~Xiaojun_Chang3;~Xiaodan_Liang2,7;6;9,4;4;4,Accept (Spotlight),0,5,0.0,yes,9/28/20,Monash University;Monash University;Monash University;SUN YAT-SEN UNIVERSITY,Multi-agent Reinforcement Learning;Transfer Learning,92;92;92;-1,64;64;64;293,f;f,NAN,NAN,n,8;1
8125,ICLR,2021,Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy,Akinori F Ebihara;Taiki Miyagawa;Kazuyuki Sakurai;Hitoshi Imaoka,~Akinori_F_Ebihara1;miyagawataik@nec.com;k-sakurai-bq@nec.com;h-imaoka_cb@nec.com,7;8;9;7;6,3;4;4;3;4,Accept (Spotlight),0,17,0.0,yes,9/28/20,NEC Corporation;RIKEN;;NEC Corporation,Sequential probability ratio test;Early classification;Density ratio estimation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
8126,ICLR,2021,"Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU",Patrick Kidger;Terry Lyons,~Patrick_Kidger1;tlyons@maths.ox.ac.uk,6;8;7;7,3;3;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,University of Oxford;Alan Turing Institute,signature;logsignature;gpu;library;open source,46;-1,1;-1,m;m,NAN,NAN,y,
8127,ICLR,2021,Sparse encoding for more-interpretable feature-selecting representations in probabilistic matrix factorization,Joshua C Chang;Patrick Fletcher;Jungmin Han;Ted L Chang;Shashaank Vattikuti;Bart Desmet;Ayah Zirikly;Carson C Chow,~Joshua_C_Chang1;patrick@mederrata.com;jungmin@mederrata.com;ted@mederrata.com;shashaank@mederrata.com;bart.desmet@gmail.com;ayah.zirikly@gmail.com;carsonc@niddk.nih.gov,7;6;6,4;4;4,Accept (Poster),0,14,0.0,yes,9/28/20,National Institutes of Health;;;;;;;National Institutes of Health,poisson matrix factorization;generalized additive model;probabilistic matrix factorization;bayesian;sparse coding;interpretability;factor analysis,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5
8128,ICLR,2021,"Heating up decision boundaries: isocapacitory saturation, adversarial scenarios and generalization bounds",Bogdan Georgiev;Lukas Franken;Mayukh Mukherjee,~Bogdan_Georgiev1;~Lukas_Franken1;~Mayukh_Mukherjee1,7;6;8;5,3;3;3;3,Accept (Poster),0,6,0.0,yes,9/28/20,"Fraunhofer IAIS;Fraunhofer Institute IAIS, Fraunhofer IAIS;Indian Institute of Technology Bombay",Brownian motion;deep learning theory;decision boundary geometry;curvature estimates;generalization bounds;adversarial attacks/defenses,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1;4
8129,ICLR,2021,Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity,JangHyun Kim;Wonho Choo;Hosan Jeong;Hyun Oh Song,~JangHyun_Kim1;~Wonho_Choo1;~Hosan_Jeong1;~Hyun_Oh_Song1,7;7;7,3;3;4,Accept (Oral),0,5,0.0,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Data Augmentation;Deep Learning;Supervised Learning;Discrete Optimization,37;37;37;37,60;60;60;60,m;m,asia,kr,y,1
8130,ICLR,2021,Neural representation and generation for RNA secondary structures,Zichao Yan;William L. Hamilton;Mathieu Blanchette,~Zichao_Yan1;~William_L._Hamilton1;~Mathieu_Blanchette1,6;6;6;7,4;3;4;2,Accept (Poster),0,7,0.0,yes,9/28/20,McGill University;McGill University;McGill University,Graph neural network;Deep generative modeling;Machine learning;Drug discovery;RNA structure;RNA structure embedding;RNA-protein interaction prediction,99;99;99,40;40;40,m;m,canada,ca,n,10;5
8131,ICLR,2021,Learning Hyperbolic Representations of Topological Features,Panagiotis Kyriakis;Iordanis Fostiropoulos;Paul Bogdan,~Panagiotis_Kyriakis1;~Iordanis_Fostiropoulos1;~Paul_Bogdan1,6;6;6;7,4;3;4;5,Accept (Poster),0,11,0.0,yes,9/28/20,University of Southern California;University of Southern California;University of Southern California,representation learning;hyperbolic deep learning;persistent homology;persistence diagrams,37;37;37,53;53;53,m;m,usa,usa,y,10
8132,ICLR,2021,On the Origin of Implicit Regularization in Stochastic Gradient Descent,Samuel L Smith;Benoit Dherin;David Barrett;Soham De,~Samuel_L_Smith1;~Benoit_Dherin1;~David_Barrett1;~Soham_De2,7;7;7;8,3;4;3;3,Accept (Poster),0,13,0.0,yes,9/28/20,Google DeepMind;Google;Google;DeepMind,SGD;learning rate;batch size;optimization;generalization;implicit regularization;backward error analysis;SDE;stochastic differential equation;ODE;ordinary differential equation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,1
8133,ICLR,2021,What Makes Instance Discrimination Good for Transfer Learning?,Nanxuan Zhao;Zhirong Wu;Rynson W. H. Lau;Stephen Lin,~Nanxuan_Zhao1;~Zhirong_Wu1;~Rynson_W._H._Lau1;~Stephen_Lin1,8;5;7;7,4;4;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,City University of Hong Kong;Microsoft;City University of Hong Kong;Microsoft Research Asia,Transfer Learning;Unsupervised Learning;Self-supervised Learning,128;-1;128;-1,126;-1;126;-1,f;m,NAN,NAN,n,6;2
8134,ICLR,2021,Learning continuous-time PDEs from sparse data with graph neural networks,Valerii Iakovlev;Markus Heinonen;Harri L√§hdesm√§ki,~Valerii_Iakovlev1;~Markus_Heinonen1;~Harri_L√§hdesm√§ki1,6;7;7;6,3;4;4;3,Accept (Poster),0,9,0.0,yes,9/28/20,Aalto University;Aalto University;Aalto University,dynamical systems;partial differential equations;PDEs;graph neural networks;continuous time,128;128;128,220;220;220,m;m,europe,dk,n,10
8135,ICLR,2021,NBDT: Neural-Backed Decision Tree,Alvin Wan;Lisa Dunlap;Daniel Ho;Jihan Yin;Scott Lee;Suzanne Petryk;Sarah Adel Bargal;Joseph E. Gonzalez,~Alvin_Wan1;~Lisa_Dunlap1;~Daniel_Ho2;~Jihan_Yin1;~Scott_Lee2;~Suzanne_Petryk1;~Sarah_Adel_Bargal1;~Joseph_E._Gonzalez1,7;6;8;6;6,4;4;3;5;2,Accept (Poster),0,17,0.0,yes,9/28/20,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Boston University;University of California - Berkeley,explainability;computer vision;interpretability,-1;-1;-1;-1;-1;-1;79;-1,7;7;7;7;7;7;54;7,m;m,usa,usa,n,
8136,ICLR,2021,On Self-Supervised Image Representations for GAN Evaluation,Stanislav Morozov;Andrey Voynov;Artem Babenko,~Stanislav_Morozov1;~Andrey_Voynov1;~Artem_Babenko1,7;7;7;7,4;4;4;4,Accept (Spotlight),0,6,0.0,yes,9/28/20,Yandex;Yandex;Yandex,GAN;evaluation;embedding,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,5
8137,ICLR,2021,Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling,Jiahui Yu;Wei Han;Anmol Gulati;Chung-Cheng Chiu;Bo Li;Tara N Sainath;Yonghui Wu;Ruoming Pang,~Jiahui_Yu1;~Wei_Han3;~Anmol_Gulati1;~Chung-Cheng_Chiu1;~Bo_Li1;~Tara_N_Sainath1;~Yonghui_Wu1;~Ruoming_Pang1,7;6;7;7,5;5;4;5,Accept (Poster),0,5,0.0,yes,9/28/20,Google Brain;Google;Google;Google;Google;Google;;Google Brain,Speech Recognition;Streaming ASR;Low-latency ASR;Dual-mode ASR,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8
8138,ICLR,2021,Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval,Wenhan Xiong;Xiang Li;Srini Iyer;Jingfei Du;Patrick Lewis;William Yang Wang;Yashar Mehdad;Scott Yih;Sebastian Riedel;Douwe Kiela;Barlas Oguz,~Wenhan_Xiong1;~Xiang_Li2;~Srini_Iyer1;~Jingfei_Du1;~Patrick_Lewis2;~William_Yang_Wang2;mehdad@fb.com;~Scott_Yih1;~Sebastian_Riedel1;~Douwe_Kiela1;~Barlas_Oguz1,7;6;5;9,4;5;3;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Facebook;Department of Computer Science, University of Massachusetts, Amherst;University of Washington, Seattle;Facebook;University College London;UC Santa Barbara;Facebook;Facebook AI Research;Facebook;Facebook AI Research;Facebook AI",multi-hop question answering;recursive dense retrieval;open domain complex question answering,-1;-1;11;-1;53;-1;-1;-1;-1;-1;-1,-1;210;29;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
8139,ICLR,2021,Revisiting Locally Supervised Learning: an Alternative to End-to-end Training,Yulin Wang;Zanlin Ni;Shiji Song;Le Yang;Gao Huang,~Yulin_Wang1;~Zanlin_Ni1;~Shiji_Song1;~Le_Yang2;~Gao_Huang1,6;7;7;6,3;3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Locally supervised training;Deep learning,4;4;4;4;4,20;20;20;20;20,m;m,NAN,NAN,y,1
8140,ICLR,2021,C-Learning: Horizon-Aware Cumulative Accessibility Estimation,Panteha Naderian;Gabriel Loaiza-Ganem;Harry J. Braviner;Anthony L. Caterini;Jesse C. Cresswell;Tong Li;Animesh Garg,panteha@layer6.ai;~Gabriel_Loaiza-Ganem1;harry@layer6.ai;~Anthony_L._Caterini1;jesse@layer6.ai;tong@layer6.ai;~Animesh_Garg1,6;6;5;6,3;4;3;4,Accept (Poster),0,14,0.0,yes,9/28/20,Layer 6 AI;;;;;;University of Toronto,reinforcement learning;goal reaching;Q-learning,-1;-1;-1;-1;-1;-1;18,-1;-1;-1;-1;-1;-1;18,f;m,canada,ca,n,1
8141,ICLR,2021,Adversarial score matching and improved sampling for image generation,Alexia Jolicoeur-Martineau;R√©mi Pich√©-Taillefer;Ioannis Mitliagkas;Remi Tachet des Combes,~Alexia_Jolicoeur-Martineau1;remi.piche-taillefer@umontreal.ca;~Ioannis_Mitliagkas1;~Remi_Tachet_des_Combes1,7;7;6;7,3;2;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,University of Montreal;University of Montreal;University of Montreal;Microsoft Research,adversarial;score matching;Langevin dynamics;GAN;generative model,128;128;128;-1,73;73;73;-1,f;m,NAN,NAN,y,5;4
8142,ICLR,2021,Single-Photon Image Classification,Thomas Fischbacher;Luciano Sbaiz,~Thomas_Fischbacher1;~Luciano_Sbaiz1,7;6;3;8,3;3;1;3,Accept (Poster),0,9,0.0,yes,9/28/20,Google Research;Google,quantum mechanics;image classification;quantum machine learning;theoretical limits,-1;-1,-1;-1,m;m,NAN,NAN,n,1
8143,ICLR,2021,Denoising Diffusion Implicit Models,Jiaming Song;Chenlin Meng;Stefano Ermon,~Jiaming_Song1;chenlin@stanford.edu;~Stefano_Ermon1,6;8;7,3;4;4,Accept (Poster),0,6,0.0,yes,9/28/20,"Computer Science Department, Stanford University;Stanford University;Stanford University",generative models;variational autoencoders;denoising score matching;variational inference,5;5;5,2;2;2,m;m,usa,usa,y,5;4
8144,ICLR,2021,Meta Back-Translation,Hieu Pham;Xinyi Wang;Yiming Yang;Graham Neubig,~Hieu_Pham1;~Xinyi_Wang1;~Yiming_Yang1;~Graham_Neubig1,7;6;7;6,4;4;5;4,Accept (Poster),0,11,0.0,yes,9/28/20,"Google Brain;School of Computer Science, Carnegie Mellon University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University",meta learning;machine translation;back translation,-1;1;1;1,-1;28;28;28,m;m,usa,usa,n,6;3
8145,ICLR,2021,Scaling the Convex Barrier with Active Sets,Alessandro De Palma;Harkirat Behl;Rudy R Bunel;Philip Torr;M. Pawan Kumar,~Alessandro_De_Palma1;~Harkirat_Behl1;~Rudy_R_Bunel1;~Philip_Torr1;~M._Pawan_Kumar1,7;6;6;7;8;5,4;1;2;2;5;3,Accept (Poster),0,7,0.0,yes,9/28/20,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Neural Network Verification;Neural Network Bounding;Optimisation for Deep Learning,46;46;46;46;46,1;1;1;1;1,m;m,europe,uk,n,
8146,ICLR,2021,Measuring Massive Multitask Language Understanding,Dan Hendrycks;Collin Burns;Steven Basart;Andy Zou;Mantas Mazeika;Dawn Song;Jacob Steinhardt,~Dan_Hendrycks1;collin.burns@columbia.edu;~Steven_Basart1;andyzou_jiaming@berkeley.edu;~Mantas_Mazeika3;~Dawn_Song1;~Jacob_Steinhardt1,6;6;5;8,3;4;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,"UC Berkeley;University of California Berkeley;University of Chicago;University of California Berkeley;University of Illinois, Urbana-Champaign;University of California Berkeley;University of California Berkeley",multitask;few-shot,-1;-1;46;-1;-1;-1;-1,-1;7;10;7;-1;7;7,m;m,usa,usa,n,
8147,ICLR,2021,How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision,Dongkwan Kim;Alice Oh,~Dongkwan_Kim1;~Alice_Oh1,7;5;8;4,3;4;5;4,Accept (Poster),0,6,0.0,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Graph Neural Network;Attention Mechanism;Self-supervised Learning,-1;-1,96;96,m;f,NAN,NAN,y,8;10
8148,ICLR,2021,MIROSTAT: A NEURAL TEXT DECODING ALGORITHM THAT DIRECTLY CONTROLS PERPLEXITY,Sourya Basu;Govardana Sachitanandam Ramachandran;Nitish Shirish Keskar;Lav R. Varshney,~Sourya_Basu1;gramachandran@salesforce.com;~Nitish_Shirish_Keskar1;~Lav_R._Varshney1,7;6;6,4;5;3,Accept (Poster),0,7,0.0,yes,9/28/20,"University of Illinois, Urbana Champaign;Stanford University;SalesForce.com;University of Illinois at Urbana-Champaign",Neural text decoding;sampling algorithms;cross-entropy;repetitions;incoherence,-1;5;-1;-1,-1;2;-1;48,m;m,NAN,NAN,n,3
8149,ICLR,2021,Evaluating the Disentanglement of Deep Generative Models through Manifold Topology,Sharon Zhou;Eric Zelikman;Fred Lu;Andrew Y. Ng;Gunnar E. Carlsson;Stefano Ermon,~Sharon_Zhou1;~Eric_Zelikman1;fredlu@stanford.edu;~Andrew_Y._Ng1;~Gunnar_E._Carlsson1;~Stefano_Ermon1,7;5;8;5;6,3;5;4;2;1,Accept (Poster),0,10,0.0,yes,9/28/20,Stanford University;Stanford University;;;Stanford University;;Stanford University,generative models;evaluation;disentanglement,5;5;-1;-1;5;-1;5,2;2;-1;-1;2;-1;2,f;m,usa,usa,n,1;5
8150,ICLR,2021,Counterfactual Generative Networks,Axel Sauer;Andreas Geiger,~Axel_Sauer1;~Andreas_Geiger3,5;5;7;8,5;3;3;4,Accept (Poster),0,15,0.0,yes,9/28/20,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;University of Tuebingen",Causality;Counterfactuals;Generative Models;Robustness;Image Classification;Data Augmentation,-1;128,-1;78,m;m,europe,de,n,5
8151,ICLR,2021,Local Search Algorithms for Rank-Constrained Convex Optimization,Kyriakos Axiotis;Maxim Sviridenko,~Kyriakos_Axiotis1;sviri@verizonmedia.com,6;6;7;7,3;3;3;5,Accept (Poster),0,8,0.0,yes,9/28/20,Massachusetts Institute of Technology;Yahoo,low rank;rank-constrained convex optimization;matrix completion,5;-1,4;-1,m;m,NAN,NAN,y,9
8152,ICLR,2021,Differentiable Segmentation of Sequences,Erik Scharw√§chter;Jonathan Lennartz;Emmanuel M√ºller,~Erik_Scharw√§chter1;jlen@uni-bonn.de;emmanuel.mueller@cs.tu-dortmund.de,6;7;7,3;3;3,Accept (Poster),0,5,0.0,yes,9/28/20,TU Dortmund;;TU Dortmund,segmented models;segmentation;change point detection;concept drift;warping functions;gradient descent,263;-1;263,404;-1;404,m;m,europe,de,n,2
8153,ICLR,2021,The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels Methods,Louis THIRY;Michael Arbel;Eugene Belilovsky;Edouard Oyallon,~Louis_THIRY1;~Michael_Arbel1;~Eugene_Belilovsky1;~Edouard_Oyallon1,6;6;7;6,3;2;5;2,Accept (Poster),0,5,0.0,yes,9/28/20,ENS Paris;University College London;University of Montreal;CNRS/LIP6,convolutional kernel methods;image classification,-1;53;128;-1,-1;-1;73;-1,m;m,NAN,NAN,n,
8154,ICLR,2021,On Data-Augmentation and Consistency-Based Semi-Supervised Learning,Atin Ghosh;Alexandre H. Thiery,~Atin_Ghosh1;~Alexandre_H._Thiery1,6;6;6,3;4;2,Accept (Poster),0,3,0.0,yes,9/28/20,National University of Singapore;National University of Singapore,Semi-Supervised Learning;Regularization;Data augmentation,17;17,25;25,m;m,asia,sg,y,4
8155,ICLR,2021,Efficient Conformal Prediction via Cascaded Inference with Expanded Admission,Adam Fisch;Tal Schuster;Tommi S. Jaakkola;Regina Barzilay,~Adam_Fisch2;~Tal_Schuster1;~Tommi_S._Jaakkola1;~Regina_Barzilay1,6;6;8,3;3;3,Accept (Poster),0,8,0.0,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,conformal prediction;uncertainty estimation;efficient inference methods;natural language processing;chemistry,5;5;5;5,4;4;4;4,m;f,usa,usa,y,3
8156,ICLR,2021,Interpretable Models for Granger Causality Using Self-explaining Neural Networks,Riƒçards Marcinkeviƒçs;Julia E Vogt,~Riƒçards_Marcinkeviƒçs1;~Julia_E_Vogt1,6;4;8;6,4;4;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,"Department of Computer Science, Swiss Federal Institute of Technology;Memorial Sloan Kettering Cancer Center",time series;Granger causality;interpretability;inference;neural networks,-1;-1,-1;-1,m;f,NAN,NAN,n,
8157,ICLR,2021,Few-Shot Bayesian Optimization with Deep Kernel Surrogates,Martin Wistuba;Josif Grabocka,~Martin_Wistuba1;~Josif_Grabocka1,6;6;5;4,3;4;4;5,Accept (Poster),0,7,0.0,yes,9/28/20,International Business Machines;Universit√§t Freiburg,bayesian optimization;metalearning;few-shot learning;automl,-1;-1,-1;-1,m;m,NAN,NAN,n,6;11
8158,ICLR,2021,Monotonic Kronecker-Factored Lattice,William Taylor Bakst;Nobuyuki Morioka;Erez Louidor,~William_Taylor_Bakst1;~Nobuyuki_Morioka1;~Erez_Louidor1,6;6;6;7,2;3;1;3,Accept (Poster),0,7,0.0,yes,9/28/20,Google;Google;Google,Theory;Regularization;Algorithms;Classification;Regression;Matrix and Tensor Factorization;Fairness;Evaluation;Efficiency;Machine Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
8159,ICLR,2021,Robust Reinforcement Learning on State Observations with Learned Optimal Adversary,Huan Zhang;Hongge Chen;Duane S Boning;Cho-Jui Hsieh,~Huan_Zhang1;~Hongge_Chen1;~Duane_S_Boning1;~Cho-Jui_Hsieh1,6;7;7;7,5;5;3;2,Accept (Poster),0,6,0.0,yes,9/28/20,Carnegie Mellon University;Google;Massachusetts Institute of Technology;Amazon,reinforcement learning;robustness;adversarial attacks;adversarial defense,1;-1;5;-1,28;-1;4;-1,m;m,NAN,NAN,y,4
8160,ICLR,2021,A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels,Leon Lang;Maurice Weiler,~Leon_Lang1;~Maurice_Weiler1,8;6;8;6,4;3;4;1,Accept (Poster),0,5,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam,Group Equivariant Convolution;Steerable Kernel;Quantum Mechanics;Wigner-Eckart Theorem;Representation Theory;Harmonic Analysis;Peter-Weyl Theorem,128;128,66;66,m;m,europe,nl,y,1
8161,ICLR,2021,Overfitting for Fun and Profit: Instance-Adaptive Data Compression,Ties van Rozendaal;Iris AM Huijben;Taco Cohen,~Ties_van_Rozendaal1;ihuijben@qti.qualcomm.com;~Taco_Cohen1,6;7;6;7,3;4;4;4,Accept (Poster),0,15,0.0,yes,9/28/20,University of Amsterdam;;;University of Amsterdam,Neural data compression;Learned compression;Generative modeling;Overfitting;Finetuning;Instance learning;Instance adaptation;Variational autoencoders;Rate-distortion optimization;Model compression;Weight quantization,128;-1;-1;128,66;-1;-1;66,m;m,europe,nl,n,1
8162,ICLR,2021,Categorical Normalizing Flows via Continuous Transformations,Phillip Lippe;Efstratios Gavves,~Phillip_Lippe1;~Efstratios_Gavves1,7;6;7;7,3;3;4;4,Accept (Poster),0,7,0.0,yes,9/28/20,University of Amsterdam;University of Amsterdam,Normalizing Flows;Density Estimation;Graph Generation,128;128,66;66,m;m,europe,nl,n,10;5
8163,ICLR,2021,Learning Mesh-Based Simulation with Graph Networks,Tobias Pfaff;Meire Fortunato;Alvaro Sanchez-Gonzalez;Peter Battaglia,~Tobias_Pfaff1;~Meire_Fortunato1;~Alvaro_Sanchez-Gonzalez1;~Peter_Battaglia1,10;6;6;9,4;4;4;4,Accept (Spotlight),0,8,0.0,yes,9/28/20,Deepmind;DeepMind;DeepMind;DeepMind,graph networks;simulation;mesh;physics,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,10
8164,ICLR,2021,On the Impossibility of Global Convergence in Multi-Loss Optimization,Alistair Letcher,~Alistair_Letcher1,6;8;7;4,4;5;4;4,Accept (Poster),0,5,0.0,yes,9/28/20,University of Oxford,impossibility;global;convergence;optimization;multi-loss;multi-player;multi-agent;gradient;descent,46,1,m,europe,uk,y,1;5
8165,ICLR,2021,Learning Task-General Representations with Generative Neuro-Symbolic Modeling,Reuben Feinman;Brenden M. Lake,~Reuben_Feinman1;~Brenden_M._Lake1,6;7;7;6,4;4;3;4,Accept (Poster),0,11,0.0,yes,9/28/20,New York University;Facebook,few-shot concept learning;neuro-symbolic models;probabilistic programs;generative models,23;-1,26;-1,m;m,NAN,NAN,n,1;5
8166,ICLR,2021,Disambiguating Symbolic Expressions in Informal Documents,Dennis M√ºller;Cezary Kaliszyk,~Dennis_M√ºller1;~Cezary_Kaliszyk1,6;4;7;8,3;3;4;4,Accept (Poster),0,4,0.0,yes,9/28/20,Friedrich-Alexander University Erlangen-N√ºrnberg;University of Innsbruck,,-1;-1,-1;398,m;m,NAN,NAN,n,8;3
8167,ICLR,2021,Grounding Language to Autonomously-Acquired Skills via Goal Generation,Ahmed Akakzia;C√©dric Colas;Pierre-Yves Oudeyer;Mohamed CHETOUANI;Olivier Sigaud,~Ahmed_Akakzia1;~C√©dric_Colas1;~Pierre-Yves_Oudeyer1;~Mohamed_CHETOUANI2;~Olivier_Sigaud1,6;6;7;4,5;3;3;3,Accept (Poster),0,13,0.0,yes,9/28/20,"ISIR, UMR 7222;INRIA;Inria;ISIR, UMR 7222;Sorbonne Universit√©",Deep reinforcement learning;intrinsic motivations;symbolic representations;autonomous learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;87,m;m,NAN,NAN,n,
8168,ICLR,2021,Perceptual Adversarial Robustness: Defense Against Unseen Threat Models,Cassidy Laidlaw;Sahil Singla;Soheil Feizi,~Cassidy_Laidlaw1;~Sahil_Singla1;~Soheil_Feizi2,7;7;6;7,3;5;4;4,Accept (Poster),0,11,0.0,yes,9/28/20,"University of California Berkeley;University of Maryland, College Park;University of Maryland, College Park",,-1;12;12,7;90;90,m;m,usa,usa,n,1;4
8169,ICLR,2021,Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling,Benedikt Boecking;Willie Neiswanger;Eric Xing;Artur Dubrawski,~Benedikt_Boecking1;~Willie_Neiswanger2;~Eric_Xing1;~Artur_Dubrawski2,6;6;6;8,3;4;4;4,Accept (Poster),0,10,0.0,yes,9/28/20,Carnegie Mellon University;Stanford University;Carnegie Mellon University;Carnegie-Mellon University,weak supervision;data programming;data labeling;active learning,1;5;1;1,28;2;28;28,m;m,usa,usa,n,
8170,ICLR,2021,Learning to Generate the Unknowns for Open-set Domain Adaptation,Mahsa Baktashmotlagh;Tianle Chen;Mathieu Salzmann,~Mahsa_Baktashmotlagh1;tianle.chen@uq.edu.au;~Mathieu_Salzmann1,5;5;5,4;5;3,Withdrawn,0,0,,yes,9/28/20,University of Queensland;University of Queensland;Swiss Federal Institute of Technology Lausanne,Open-set domain adaptation;Unknown sample generation;Distribution Alignment;,209;209;-1,62;62;-1,f;m,NAN,NAN,pdf miss,5
8171,ICLR,2021,Depth Completion using Plane-Residual Representation,Byeong-Uk Lee;Kyunghyun Lee;In So Kweon,~Byeong-Uk_Lee1;~Kyunghyun_Lee2;~In_So_Kweon2,4;5;5;5,5;5;5;5,Withdrawn,0,0,,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,
8172,ICLR,2021,Illuminating Dark Knowledge via Random Matrix Ensembles,Anthony Ndirango,~Anthony_Ndirango1,2;1;4;2,4;4;3;3,Withdrawn,0,0,,yes,9/28/20,University of California Berkeley,,-1,7,m,usa,usa,n,1
8173,ICLR,2021,A Unified Framework to Analyze and Design the Nonlocal Blocks for Neural Networks,Lei Zhu;Qi She;Changhu Wang,~Lei_Zhu10;~Qi_She1;~Changhu_Wang3,6;5;5;5,4;4;5;4,Withdrawn,0,0,,yes,9/28/20,Peking University;Bytedance AI Lab;ByteDance AI Lab,Nonlocal Block;Image Classification;Action Recognition;Graph Neural Network;,14;-1;-1,23;-1;-1,m;m,NAN,NAN,n,8;2;10
8174,ICLR,2021,Causal Future Prediction in a Minkowski Space-Time,Athanasios Vlontzos;Henrique Bergallo Rocha;Daniel Rueckert;Bernhard Kainz,~Athanasios_Vlontzos1;h.b.rocha@ed.ac.uk;~Daniel_Rueckert2;~Bernhard_Kainz1,3;4;3;2;3,4;3;3;5;3,Withdrawn,0,0,,yes,9/28/20,Imperial College London;;;Imperial College London;Imperial College London,Causal Discovery;Future Prediction;,53;-1;-1;53;53,11;-1;-1;11;11,m;m,europe,uk,n,
8175,ICLR,2021,Improve Novel Class Generalization By Adaptive Feature Distribution for Few-Shot Learning,Ran Tao;Marios Savvides,~Ran_Tao2;~Marios_Savvides1,4;2;3;4,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University,Novel Class Generalization;Finetuning One Scale Vector;Adaptive Feature Distribution;Cross-Domain;,1;1,28;28,f;m,usa,usa,n,6;1
8176,ICLR,2021,Pathological Visual Question Answering,Xuehai He;Zhuo Cai;Wenlan Wei;Yichen Zhang;Luntian Mou;Eric Xing;Pengtao Xie,~Xuehai_He1;~Zhuo_Cai2;~Wenlan_Wei2;~Yichen_Zhang1;~Luntian_Mou1;~Eric_Xing1;~Pengtao_Xie3,4;4;5;3,4;3;4;4,Withdrawn,0,0,,yes,9/28/20,"University of California, San Diego;Tsinghua University, Tsinghua University;Wuhan University;University of California, San Diego;Beijing University of Technology;Carnegie Mellon University;University of California, San Diego",Pathology Visual Question Answering;Healthcare;Learning to Ignore;Self-supervised Learning;,-1;4;209;-1;-1;1;-1,33;20;323;33;1093;28;33,m;m,usa,usa,n,
8177,ICLR,2021,Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation,Xiaogang Xu;Hengshuang Zhao;Jiaya Jia,~Xiaogang_Xu2;~Hengshuang_Zhao2;~Jiaya_Jia1,3;6;5;5,4;3;4;2,Withdrawn,0,0,,yes,9/28/20,The Chinese University of Hong Kong;University of Oxford;The Chinese University of Hong Kong,adversarial defense;semantic segmentation;robustness;,327;46;327,39;1;39,m;m,NAN,NAN,n,2;4
8178,ICLR,2021,General Adversarial Defense via Pixel Level and Feature Level Distribution Alignment,Xiaogang Xu;Hengshuang Zhao;Philip Torr;Jiaya Jia,~Xiaogang_Xu2;~Hengshuang_Zhao2;~Philip_Torr1;~Jiaya_Jia1,6;4;3;5,4;4;5;5,Withdrawn,0,0,,yes,9/28/20,The Chinese University of Hong Kong;University of Oxford;University of Oxford;The Chinese University of Hong Kong,adversarial defense;distribution alignment;high-level computer vision task;,327;46;46;327,39;1;1;39,m;m,NAN,NAN,n,2;5;4
8179,ICLR,2021,Meta-Aggregating Networks for Class-Incremental Learning,Yaoyao Liu;Bernt Schiele;Qianru Sun,~Yaoyao_Liu1;~Bernt_Schiele1;~Qianru_Sun2,5;5;4;5,4;4;4;5,Withdrawn,0,0,,yes,9/28/20,"Max Planck Institute for Informatics;Max Planck Institute for Informatics, Saarland Informatics Campus;Singapore Management University",incremental learning;continual learning;class-incremental learning;meta learning;,-1;-1;79,-1;-1;-1,m;f,asia,sg,n,
8180,ICLR,2021,Uncertain Out-of-Domain Generalization,Fengchun Qiao;Xi Peng,~Fengchun_Qiao1;~Xi_Peng1,5;6;3;6,4;3;4;3,Withdrawn,0,0,,yes,9/28/20,University of Delaware;University of Delaware,domain generalization;uncertainty assessment;data augmentation;Bayesian meta-learning;,209;209,312;312,m;m,usa,usa,n,6;11;1
8181,ICLR,2021,Non-maximum Suppression Also Closes the Variational Approximation Gap of Multi-object Variational Autoencoders,Li Nanbo;Robert Burns Fisher,nanbo.li@ed.ac.uk;~Robert_Burns_Fisher1,1;6;4,5;4;4,Withdrawn,0,0,,yes,9/28/20,University of Edinburgh;Univ of Edinburgh,Object-centric Visual Representation Learning;Deep Generative Models;Computer Vision;,29;-1,30;-1,m;m,NAN,NAN,n,
8182,ICLR,2021,Buffer Zone based Defense against Adversarial Examples in Image Classification,Kaleel Mahmood;Phuong Ha Nguyen;Lam M. Nguyen;Thanh V Nguyen;Marten van Dijk,~Kaleel_Mahmood1;~Phuong_Ha_Nguyen1;~Lam_M._Nguyen1;~Thanh_V_Nguyen1;~Marten_van_Dijk1,2;4;5;5,5;3;4;4,Withdrawn,0,0,,yes,9/28/20,"University of Connecticut;University of Connecticut;IBM Research, Thomas J. Watson Research Center;Amazon;University of Connecticut",,174;174;-1;-1;174,440;440;-1;-1;440,m;m,usa,usa,n,4
8183,ICLR,2021,Width transfer: on the (in)variance of width optimization,Rudy Chin;Diana Marculescu;Ari S. Morcos,~Rudy_Chin2;~Diana_Marculescu4;~Ari_S._Morcos1,3;5;4;4,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,"Carnegie Mellon University;University of Texas, Austin;Facebook AI Research (FAIR)",Channel Optimization;Channel Pruning;Neural Architecture Search;Convolutional Neural Network;Image Classification;,1;-1;-1,28;-1;-1,m;m,NAN,NAN,n,
8184,ICLR,2021,In the Wild: From ML Models to Pragmatic ML Systems,Matthew Wallingford;Aditya Kusupati;Keivan Alizadeh-Vahid;Aaron Walsman;Aniruddha Kembhavi;Ali Farhadi,mcw244@cs.washington.edu;~Aditya_Kusupati1;~Keivan_Alizadeh-Vahid1;~Aaron_Walsman1;~Aniruddha_Kembhavi1;~Ali_Farhadi3,3;4;4;5,3;4;4;4,Withdrawn,0,0,,yes,9/28/20,"University of Washington;Department of Computer Science, University of Washington;University of Washington, Seattle;Department of Computer Science, University of Washington;Allen Institute for Artificial Intelligence;University of Washington",Benchmark;Real-world;Framework;Few-shot Learning;Sequential Learning;Continual Learning;Long tail;Open-world;Deep Learning;,11;11;11;11;-1;11,29;29;29;29;-1;29,m;m,usa,usa,n,6
8185,ICLR,2021,Revisiting Parameter Sharing in Multi-Agent Deep Reinforcement Learning,Justin K Terry;Nathaniel Grammel;Ananth Hari;Luis Santos;Benjamin Black,~Justin_K_Terry1;ngrammel@umd.edu;ahari1@umd.edu;luis.santos@swarmlabs.com;benjamin.black@swarmlabs.com,3;3;5;7,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;;;University of Maryland, College Park",Reinforcement Learning;Multi-agent Reinforcement Learning;,12;12;12;-1;-1;12,90;90;90;-1;-1;90,m;m,usa,usa,y,1
8186,ICLR,2021,Mirror Sample Based Distribution Alignment for Unsupervised Domain Adaption,Yin Zhao;Minquan Wang;Longjun Cai,~Yin_Zhao1;~Minquan_Wang1;~Longjun_Cai1,4;4;4;5,5;5;5;5,Withdrawn,0,0,,yes,9/28/20,Alibaba Group;Alibaba Group;Alibaba Group,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,1
8187,ICLR,2021,Logit As Auxiliary Weak-supervision for More Reliable and Accurate Prediction,Duhyeon Bang;Yunho Jeon;Jin-Hwa Kim;Jiwon Kim;Hyunjung Shim,~Duhyeon_Bang1;~Yunho_Jeon1;~Jin-Hwa_Kim1;~Jiwon_Kim3;~Hyunjung_Shim1,3;7;4;5,4;2;4;4,Withdrawn,0,0,,yes,9/28/20,Yonsei university;SK T-Brain;SK Telecom;SK T-Brain;Yonsei University,Inter-class correlation;Human cognitive system;Weak supervision;Calibration;Regularization;,150;-1;-1;-1;150,186;-1;-1;-1;186,f;f,asia,cn,n,
8188,ICLR,2021,Pareto-Frontier-aware Neural Architecture Search,Yong Guo;Yaofo Chen;Yin Zheng;Peilin Zhao;Jian Chen;Junzhou Huang;Mingkui Tan,~Yong_Guo1;chenyaofo@gmail.com;~Yin_Zheng1;~Peilin_Zhao2;ellachen@scut.edu.cn;~Junzhou_Huang2;~Mingkui_Tan2,6;4;5;5,5;3;5;5,Withdrawn,0,0,,yes,9/28/20,"South China University of Technology;South China University of Technology;Weixin Group, Tencent;Tencent AI Lab;South China University of Technology;University of Texas, Arlington;South China University of Technology",Neural Architecture Search;Pareto Frontier Learning;Resource Constraint;,-1;-1;-1;-1;-1;-1;-1,411;411;-1;-1;411;-1;411,m;m,NAN,NAN,n,
8189,ICLR,2021,Sparse Coding-inspired GAN for Weakly Supervised Hyperspectral Anomaly Detection,Tao Jiang;Weiying Xie;Jie Lei;Yunsong Li;Zan Li,tjiang_2@stu.xidian.edu.cn;~Weiying_Xie1;jielei@mail.xidian.edu.cn;~Yunsong_Li1;zanli@xidian.edu.cn,4;3;3,4;4;3,Withdrawn,0,0,,yes,9/28/20,Xidian University;;;;Xidian University,Anomaly detection (AD);weakly supervised learning (WSL);sparse coding (SC);generative adversarial network (GAN);hyperspectral image (HSI);,-1;-1;-1;-1;-1,924;-1;-1;-1;924,m;f,asia,cn,n,5;4
8190,ICLR,2021,QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings,Dai Quoc Nguyen;Thanh Vu;Tu Dinh Nguyen;Dinh Phung,~Dai_Quoc_Nguyen1;thanh.v.vu@oracle.com;~Tu_Dinh_Nguyen1;~Dinh_Phung2,4;2;5;5,5;5;4;4,Withdrawn,0,0,,yes,9/28/20,Monash University;;;Deakin University;Monash University,Knowledge graph embeddings;Quaternion;Hamilton product;,92;-1;-1;-1;92,64;-1;-1;295;64,m;m,australasia,au,n,10
8191,ICLR,2021,Optimizing Information Bottleneck in Reinforcement Learning: A Stein Variational Approach,Pei Yingjun;Hou Xinwen;Li Jian;Lei Wang,~Pei_Yingjun1;xwhou@nlpr.ia.ac.cn;~Li_Jian1;~Lei_Wang22,6;4;5;5,5;4;4;3,Withdrawn,0,0,,yes,9/28/20,"Beijing University of Post and Telecommunication;;;University of Maryland, College Park;Tsinghua University",Information Bottleneck;Reinforcement Learning;Stein Variational Gradient;,-1;-1;-1;12;4,-1;-1;-1;90;20,u;f,asia,cn,y,1
8192,ICLR,2021,Hypersphere Face Uncertainty Learning,Shen Li;Jianqing Xu;Xiaqing Xu;Pengcheng Shen;Shaoxin Li;Bryan Hooi,~Shen_Li2;~Jianqing_Xu1;~Xiaqing_Xu1;~Pengcheng_Shen1;~Shaoxin_Li2;~Bryan_Hooi1,6;3;4,4;4;5,Withdrawn,0,0,,yes,9/28/20,"national university of singaore, National University of Singapore;HIT;Chinese Academy of Sciences;Tencent Youtu Lab;Youtu Lab, Tencent;National University of Singapore",,17;209;34;-1;-1;17,25;-1;-1;-1;-1;25,m;m,asia,sg,y,2;1
8193,ICLR,2021,Misclassification Detection via Class Augmentation,Fei Zhu;Xu-yao Zhang;Chuang Wang;Cheng-lin Liu,~Fei_Zhu1;~Xu-yao_Zhang1;~Chuang_Wang2;~Cheng-lin_Liu1,5;7;5;3,4;3;3;4,Withdrawn,0,0,,yes,9/28/20,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",misclassification detection;augmentation;uncertainty;confidence;,34;34;34;34,-1;-1;-1;-1,m;m,NAN,NAN,n,6
8194,ICLR,2021,Token-Level Contrast for Video and Language Alignment,Jianwei Yang;Yonatan Bisk;Jianfeng Gao,~Jianwei_Yang1;~Yonatan_Bisk1;~Jianfeng_Gao1,4;5;4;6,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Microsoft;Carnegie Mellon University;Microsoft Research,token-level contrastive loss;video and language alignment;video retrieval;multi-modal representation learning;,-1;1;-1,-1;28;-1,m;m,NAN,NAN,n,8
8195,ICLR,2021,$Graph Embedding via Topology and Functional Analysis$,Phani raj Chinnalingu,~Phani_raj_Chinnalingu1,2;3;2;2,5;3;5;5,Withdrawn,0,0,,yes,9/28/20,"Indian Institute of Science, Dhirubhai Ambani Institute Of Information and Communication Technology",Graph embedding;Theory;Topology;Functional analysis;,-1,323,m,NAN,NAN,n,1;10
8196,ICLR,2021,Rethinking the Trigger of Backdoor Attack,Yiming Li;Tongqing Zhai;Baoyuan Wu;Yong Jiang;Zhifeng Li;Shu-Tao Xia,~Yiming_Li1;~Tongqing_Zhai1;~Baoyuan_Wu1;~Yong_Jiang3;~Zhifeng_Li5;~Shu-Tao_Xia1,5;5;5,3;4;4,Withdrawn,0,0,,yes,9/28/20,"Tsinghua University;Tsinghua University, Tsinghua University;The Chinese University of Hong Kong, Shenzhen;;Tencent;Graduate School at Shenzhen, Tsinghua University",Backdoor Attack;Backdoor Defense;Security;Deep Learning;,4;4;46;-1;-1;4,20;20;39;-1;-1;20,f;m,NAN,NAN,n,4
8197,ICLR,2021,Contextual Graph Reasoning Networks,Zhaoqing Wang;Jiaming Liu;Yangyuxuan Kang;Mingming Gong;Chuang Zhang;Ming Lu;Ming Wu,~Zhaoqing_Wang1;~Jiaming_Liu2;~Yangyuxuan_Kang1;~Mingming_Gong1;~Chuang_Zhang1;~Ming_Lu2;~Ming_Wu2,5;4;5,4;4;4,Withdrawn,0,0,,yes,9/28/20,"The University of Sydney, University of Sydney;Beijing University of Post and Telecommunication;Chinese Academy of Sciences, Chinese Academy of Sciences;The University of Melbourne;;Beijing University of Posts and Telecommunications;Intel Labs China;Beijing University of Post and Telecommunication",graph reasoning;context-aware representation;long-range dependencies;semantic segmentation;,71;-1;34;85;-1;-1;-1;-1,51;-1;-1;31;-1;-1;-1;-1,m;f,NAN,NAN,n,8;2;1;10
8198,ICLR,2021,Batch Normalization Embeddings for Deep Domain Generalization,Mattia Seg√π;Alessio Tonioni;Federico Tombari,~Mattia_Seg√π1;~Alessio_Tonioni1;~Federico_Tombari1,4;5;6;4,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,Swiss Federal Institute of Technology;Google;Google,Domain Generalization;Domain Representation;Multi-source Domain Generalization;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,1
8199,ICLR,2021,BalaGAN: Image Translation Between Imbalanced Domains via Cross-Modal Transfer,Or Patashnik;Dov Danon;Hao Zhang;Daniel Cohen-or,~Or_Patashnik1;~Dov_Danon1;~Hao_Zhang25;~Daniel_Cohen-or2,4;3;5;4,4;5;4;4,Withdrawn,0,4,,yes,9/28/20,"Tel Aviv University;Tel Aviv University;Simon Fraser University;Tel Aviv University, Technion",,34;34;58;29,190;190;271;190,f;m,NAN,NAN,n,
8200,ICLR,2021,Erasure for Advancing: Dynamic Self-Supervised Learning for Commonsense Reasoning,Fuyu Wang;Pan Zhou;Xiaodan Liang;Liang Lin,~Fuyu_Wang1;~Pan_Zhou3;~Xiaodan_Liang2;~Liang_Lin1,4;5;3;4,3;3;4;3,Withdrawn,0,0,,yes,9/28/20,"SUN YAT-SEN UNIVERSITY, Tsinghua University;Sea Group;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY",Dynamic Self-Supervised Learning;Commonsense Reasoning;,4;-1;-1;-1,20;-1;293;293,m;m,NAN,NAN,n,8;3
8201,ICLR,2021,CNN Based Analysis of the Luria‚Äôs Alternating Series Test for Parkinson‚Äôs Disease Diagnostics,Sergei Zarembo;Sven Nomm;Kadri Medijainen;Pille Taba;Aaro Toomela,sezare@taltech.ee;~Sven_Nomm1;kadri.medijainen@ut.ee;pille.taba@kliinikum.ee;aaro.toomela@tlu.ee,4;2;5;5,4;5;2;5,Withdrawn,0,0,,yes,9/28/20,TalTech;;;;Tallinn University,Parkinson's disease;drawing tests;data augmentation;CNN;diagnostics support;,-1;-1;-1;-1;-1,-1;-1;-1;-1;983,m;m,NAN,NAN,n,
8202,ICLR,2021,A Deep Graph Neural Networks Architecture Design: From Global Pyramid-like Shrinkage Skeleton to Local Link Rewiring,Gege Zhang;Gangwei Li;Weining Shen;Huixin Zhang;Weidong Zhang,~Gege_Zhang2;vili@nvidia.com;~Weining_Shen1;hxzhang2013@sjtu.edu.cn;wdzhang@sjtu.edu.cn,5;4;5,2;4;3,Withdrawn,0,0,,yes,9/28/20,Xidian University;;;;Shanghai Jiao Tong University,graph neural networks;architecture design;convergence;errorneous weight links;,-1;-1;-1;-1;29,924;-1;-1;-1;100,u;m,asia,cn,n,
8203,ICLR,2021,Essentials for Class Incremental Learning,Sudhanshu Mittal;Silvio Galesso;Thomas Brox,~Sudhanshu_Mittal2;~Silvio_Galesso1;~Thomas_Brox1,4;5;7;4,5;5;5;3,Withdrawn,0,0,,yes,9/28/20,Universit√§t Freiburg;Universit√§t Freiburg;University of Freiburg,class-incremental learning;catastrophic forgetting;,-1;-1;150,-1;-1;83,m;m,europe,de,n,
8204,ICLR,2021,HYPE-C: Evaluating Image Completion Models Through Standardized Crowdsourcing,Emily Walters;Weifeng Chen;Jia Deng,~Emily_Walters1;~Weifeng_Chen4;~Jia_Deng1,4;4;3;4,5;4;5;4,Withdrawn,0,0,,yes,9/28/20,Princeton University;Amazon;Princeton University,evaluation methods;image completion;image inpainting;evaluation;generative adversarial model;GAN;autoregressive generative model;,29;-1;29,9;-1;9,f;m,usa,usa,n,5
8205,ICLR,2021,Uncertainty Quantification for Bayesian Optimization,Rui Tuo;Wenjia Wang,~Rui_Tuo1;~Wenjia_Wang2,5;5;4;5,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,Texas A&M Engineering Experiment Station;The Hong Kong University of Science and Technology,Bayesian optimization;uncertainty quantification;Gaussian process;,-1;-1,-1;56,m;f,NAN,NAN,y,11;1
8206,ICLR,2021,Single Pair Cross-Modality Super Resolution,Guy Shacht;Sharon Fogel;Dov Danon;Ilya Leizerson;Daniel Cohen-or,~Guy_Shacht1;sharonbenzvi@gmail.com;~Dov_Danon1;ilya.leizerson@elbitsystems.com;~Daniel_Cohen-or2,6;5;4;3,4;5;4;5,Withdrawn,0,4,,yes,9/28/20,"Tel Aviv University, Technion;;;Tel Aviv University;;;Tel Aviv University, Technion",Super Resolution;Cross Modality;Misalignment;Deep Learning;CNN;Unsupervised;Optimization;,29;-1;-1;34;-1;-1;29,190;-1;-1;190;-1;-1;190,m;m,NAN,NAN,n,8
8207,ICLR,2021,A-FMI: Learning Attributions from Deep Networks via Feature Map Importance,An Zhang;Xiang Wang;Chengfang Fang;Jie Shi;Xiangnan He;Tat-seng Chua;Zehua Chen,~An_Zhang2;~Xiang_Wang6;fang.chengfang@huawei.com;shi.jie1@huawei.com;~Xiangnan_He1;~Tat-seng_Chua1;stachenz@nus.edu.sg,6;6;6;3,3;3;2;4,Withdrawn,0,0,,yes,9/28/20,National University of Singapore;National University of Singapore;National University of Singapore;Huawei International.;University of Science and Technology of China;National University of Singapore;National University of Singapore,Feature Attribution;Convolutional Neural Networks;Explanation Methods;,17;17;17;-1;-1;17;17,25;25;25;-1;87;25;25,f;m,asia,sg,n,
8208,ICLR,2021,Highway-Connection Classifier Networks for Plastic yet Stable Continual Learning,Nicholas I-Hsien Kuo;Mehrtash Harandi;Nicolas Fourrier;Christian Walder;Gabriela Ferraro;Hanna Suominen,~Nicholas_I-Hsien_Kuo1;~Mehrtash_Harandi2;~Nicolas_Fourrier1;~Christian_Walder1;gabriela.ferraro@data61.csiro.aut;~Hanna_Suominen2,4;4;3;4,4;3;5;4,Withdrawn,0,0,,yes,9/28/20,Australian National University;Monash University;;Ecole Superieur d'Ingenieurs Leonard de Vinci;Australian National University;;;Australian National University,,99;92;-1;-1;99;-1;-1;99,59;64;-1;-1;59;-1;-1;59,m;f,australasia,au,pdf miss,
8209,ICLR,2021,LayoutTransformer: Relation-Aware Scene Layout Generation,Cheng-Fu Yang;Wan-Cyuan Fan;Fu-En Yang;Yu-Chiang Frank Wang,~Cheng-Fu_Yang1;~Wan-Cyuan_Fan1;~Fu-En_Yang1;~Yu-Chiang_Frank_Wang2,4;4;4;4,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,National Taiwan University;National Taiwan University;National Taiwan University;National Taiwan University,Text-to-Image;Text-to-Layout;Layout generation;,99;99;99;99,97;97;97;97,m;m,asia,tw,n,8;2;5
8210,ICLR,2021,AFINets: Attentive Feature Integration Networks for Image Classification,Xinglin Pan;Jing Xu;Yu Pan;WenXiang Lin;Liangjian Wen;Zenglin Xu,~Xinglin_Pan1;~Jing_Xu1;~Yu_Pan1;~WenXiang_Lin1;~Liangjian_Wen1;~Zenglin_Xu1,6;3;4;6,2;3;5;4,Withdrawn,0,0,,yes,9/28/20,"University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Harbin Institute of Technology, Shenzhen;Beijing Institute of Technology;Huawei Technologies Ltd.;Harbin Institute of Technology, Shenzhen",Image Classification;Convolutional Neural Network;Attention Mechanisms;Feature Reuse;,-1;-1;150;-1;-1;150,553;553;416;584;-1;416,u;m,NAN,NAN,n,
8211,ICLR,2021,Toward Understanding Supervised Representation Learning with RKHS and GAN,Xu Liao;Jin Liu;Tianwen Wen;Yuling Jiao;Jian Huang,liaoxu@u.duke.nus.edu;~Jin_Liu5;weitianwen@xiaomi.com;yulingjiaomath@whu.edu.cn;~Jian_Huang5,4;3;5;3,4;4;3;3,Withdrawn,0,0,,yes,9/28/20,Duke University;National University of Singapore;;;Wuhan University;University of Iowa,Reproducing kernel Hilbert space;GAN;neural network;statistical guarantee;,46;17;-1;-1;209;174,20;25;-1;-1;323;245,m;m,europe,de,y,1;5;4
8212,ICLR,2021,Practical Order Attack in Deep Ranking,Mo Zhou;Le Wang;Zhenxing Niu;Qilin Zhang;Xu Yinghui;Nanning Zheng;Gang Hua,~Mo_Zhou1;~Le_Wang1;~Zhenxing_Niu1;~Qilin_Zhang2;~Xu_Yinghui1;~Nanning_Zheng1;~Gang_Hua3,3;6;5;5,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,Xi'an Jiaotong University;Xi'an Jiaotong University;Alibaba Group;HERE North America LLC;;;Wormpex AI Research,Adversarial Attack;Deep Ranking;Relative Order;Black-Box Attack;,-1;-1;-1;-1;-1;-1;-1,445;445;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,4
8213,ICLR,2021,MoCo-Pretraining Improves Representations and Transferability of Chest X-ray Models,Hari Sowrirajan;Jing Bo Yang;Andrew Y. Ng;Pranav Rajpurkar,~Hari_Sowrirajan1;~Jing_Bo_Yang1;~Andrew_Y._Ng1;~Pranav_Rajpurkar1,3;5;2;6,4;4;5;3,Withdrawn,0,0,,yes,9/28/20,"Stanford University;Stanford University;Stanford University;Computer Science Department, Stanford University",self-supervised learning;medical imaging;transfer learning;chest X-rays;deep learning;,5;5;5;5,2;2;2;2,m;m,NAN,NAN,n,6
8214,ICLR,2021,Why is Attention Not So Interpretable?,Bing Bai;Jian Liang;Guanhua Zhang;Hao Li;Kun Bai;Fei Wang,~Bing_Bai2;~Jian_Liang3;~Guanhua_Zhang1;~Hao_Li15;~Kun_Bai1;~Fei_Wang3,5;7;4;3,4;4;3;5,Withdrawn,0,0,,yes,9/28/20,"Tencent;Alibaba Group;Harbin Institute of Technology;Tencent;Tencent;Tsinghua University, Tsinghua University",model interpretation;attention mechanism;causal effect estimation;,-1;-1;150;-1;-1;4,-1;-1;416;-1;-1;20,f;m,NAN,NAN,n,8
8215,ICLR,2021,Semantic Inference Network for Few-shot Streaming Label Learning,Zhen Wang;Liu Liu;Yiqun Duan;Dacheng Tao,~Zhen_Wang9;~Liu_Liu8;~Yiqun_Duan1;~Dacheng_Tao1,8;4;5;4,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,University of Sydney;University of Sydney;University of Technology Sydney;JD.com,streaming label learning;multi-label learning;smenatci inference;few-shot learning;,71;71;71;-1,51;51;160;-1,m;m,NAN,NAN,y,6
8216,ICLR,2021,Fewmatch: Dynamic Prototype Refinement for Semi-Supervised Few-Shot Learning,Xu Lan;Steven McDonagh;Shaogang Gong;Jiali Wang;Zhenguo Li;Sarah Parisot,~Xu_Lan2;~Steven_McDonagh1;~Shaogang_Gong2;jiali.wang@qmul.ac.uk;~Zhenguo_Li1;~Sarah_Parisot1,4;3;5;5,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Queen Mary University London;Huawei Technologies Ltd.;Queen Mary University London;;;Huawei;Huawei Technologies Ltd.,Few shot learning;Semi-supervised Learning;,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n,6
8217,ICLR,2021,Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation,Elad Richardson;Yuval Alaluf;Or Patashnik;Yotam Nitzan;Yaniv Azar;Stav Shapiro;Daniel Cohen-or,~Elad_Richardson2;yuvalalaluf@gmail.com;orpatashnik@gmail.com;yotam.nitzan@gmail.com;azaryaniv@gmail.com;~Stav_Shapiro1;~Daniel_Cohen-or2,4;6;6,5;4;5,Withdrawn,0,4,,yes,9/28/20,"Technion, Technion;IDC Herzliya;Tel Aviv University;Tel Aviv University;;;Technion, Technion;Tel Aviv University, Technion",,29;-1;34;34;-1;-1;29;29,-1;771;190;190;-1;-1;-1;190,m;m,NAN,NAN,n,2
8218,ICLR,2021,Bigeminal Priors Variational Auto-encoder,Xuming Ran;Mingkun Xu;Qi Xu;Huihui Zhou;Quanying Liu,~Xuming_Ran1;~Mingkun_Xu1;~Qi_Xu1;~Huihui_Zhou1;~Quanying_Liu1,4;3;4;3,3;4;4;5,Withdrawn,0,0,,yes,9/28/20,"Southern University of Science and Technology;Tsinghua University, Center for Brain Inspired Computing Research (CBICR);Zhejiang University;Pengcheng Lab;Southern University of Science and Technology",Variational Auto-encoder   Out-of-distribution Detection   Deep Generative Model    Unsupervised Learning;,-1;4;42;-1;-1,252;20;94;-1;252,m;f,NAN,NAN,n,1;5
8219,ICLR,2021,Improved knowledge distillation by utilizing backward pass knowledge in neural networks,Aref Jafari;Mehdi Rezagholizadeh;Ali Ghodsi,~Aref_Jafari1;~Mehdi_Rezagholizadeh1;~Ali_Ghodsi1,3;6;4;5,5;4;4;3,Withdrawn,0,0,,yes,9/28/20,University of Waterloo;McGill University;University of Waterloo,Deep Neural Networks;Knowledge Distillation;Natural Language Processing;,34;99;34,232;40;232,m;m,canada,ca,n,3
8220,ICLR,2021,Gradient flow encoding with distance optimization adaptive step size,Kyriakos Flouris;Anna Volokitin;Gustav Bredell;Ender Konukoglu,~Kyriakos_Flouris1;~Anna_Volokitin1;gustav.bredell@vision.ee.ethz.ch;~Ender_Konukoglu1,3;3;2;4,3;5;4;4,Withdrawn,0,0,,yes,9/28/20,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;INRIA Sophia Antipolis,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
8221,ICLR,2021,Searching for Robustness: Loss Learning for Noisy Classification Tasks,Boyan Gao;Henry Gouk;Timothy Hospedales,~Boyan_Gao1;~Henry_Gouk1;~Timothy_Hospedales1,4;5;5;4;5,4;4;2;3;4,Withdrawn,0,0,,yes,9/28/20,"University of Edinburgh;Edinburgh University, University of Edinburgh;University of Edinburgh",meta-learning;loss function learning;,29;29;29,30;30;30,m;m,europe,uk,n,
8222,ICLR,2021,Generative modeling with one recursive network,Benjamin Lincoln Brimacombe,~Benjamin_Lincoln_Brimacombe1,4;4;2;2,3;4;5;4,Withdrawn,0,1,,yes,9/28/20,Columbia University,Generative model;GAN;VAE;Recursive Neural Network;self-play;,23,17,m,usa,usa,n,5;4
8223,ICLR,2021,Out-of-Distribution Classification and Clustering,Gabriele Prato;Sarath Chandar,~Gabriele_Prato1;~Sarath_Chandar1,5;4;5;4,4;4;4;4,Withdrawn,0,1,,yes,9/28/20,"Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;Polytechnique Montreal",Out-of-Distribution Generalization;Out-of-Distribution Classification;Out-of-Distribution Clustering;Class Overfitting;,128;327,73;-1,m;m,canada,ca,n,1
8224,ICLR,2021,On the relationship between topology and gradient propagation in deep networks,Kartikeya Bhardwaj;Guihong Li;Radu Marculescu,~Kartikeya_Bhardwaj1;~Guihong_Li1;~Radu_Marculescu2,3;6;2,3;4;4,Withdrawn,0,0,,yes,9/28/20,"Arm;University of Texas, Austin;University of Texas, Austin",Dynamical Isometry;Gradient Propagation;Deep Learning;Small-world Networks;Efficient Inference;,-1;-1;-1,302;-1;-1,m;m,usa,usa,y,
8225,ICLR,2021,Joint Descent: Training and Tuning Simultaneously,Qiuyi Zhang,~Qiuyi_Zhang1,5;6;4;4,4;2;3;5,Withdrawn,0,0,,yes,9/28/20,Google,First Order Optimization;Zeroth Order Optimization;,-1,-1,m,NAN,NAN,y,1;9
8226,ICLR,2021,Efficient Model Performance Estimation via Feature Histories,Shengcao Cao;Xiaofang Wang;Kris M. Kitani,~Shengcao_Cao1;~Xiaofang_Wang1;~Kris_M._Kitani1,4;6;4;5,5;2;4;4,Withdrawn,0,0,,yes,9/28/20,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Hyperparameter Optimization;Neural Architecture Search;,1;1;1,28;28;28,m;m,usa,usa,n,
8227,ICLR,2021,Meta-Learned Confidence for Transductive Few-shot Learning,Seong Min Kye;Hae Beom Lee;Hoirin Kim;Sung Ju Hwang,~Seong_Min_Kye1;~Hae_Beom_Lee1;hoirkim@kaist.ac.kr;~Sung_Ju_Hwang1,4;5;5;5,3;4;5;5,Withdrawn,0,0,,yes,9/28/20,Hyperconnect;Korea Advanced Institute of Science and Technology;;;Korea Advanced Institute of Science and Technology,Meta-learning;Few-shot learning;Transductive learning;Semi-supervised learning;,-1;-1;-1;-1;-1,-1;96;-1;-1;96,m;m,NAN,NAN,n,6
8228,ICLR,2021,A StyleMap-Based Generator for Real-Time Image Projection and Local Editing,Hyunsu Kim;Yunjey Choi;Junho Kim;Sungjoo Yoo;Youngjung Uh,~Hyunsu_Kim1;~Yunjey_Choi3;~Junho_Kim3;~Sungjoo_Yoo1;~Youngjung_Uh2,3;5;5;6,5;4;3;5,Withdrawn,0,0,,yes,9/28/20,Seoul National University;NAVER;NAVER;Seoul National University;Yonsei University,Generative Adversarial Network;Real-time Image Projection;Image Manipulation;Local Editing;Deep Learning;,37;-1;-1;37;150,60;-1;-1;60;186,m;m,asia,cn,n,5;4
8229,ICLR,2021,Understanding Knowledge Distillation,Taehyeon Kim;Jaehoon Oh;Nakyil Kim;Sangwook Cho;Se-Young Yun,~Taehyeon_Kim1;~Jaehoon_Oh1;~Nakyil_Kim1;~Sangwook_Cho1;~Se-Young_Yun1,6;4;4,5;5;3,Withdrawn,0,1,,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,knowledge distillation;,-1;-1;-1;-1;15,96;96;96;96;96,m;m,asia,in,y,1
8230,ICLR,2021,Domain Adaptation with Morphologic Segmentation,Jonathan Klein;Soren Pirk;Dominik Michels,~Jonathan_Klein1;~Soren_Pirk2;~Dominik_Michels1,4;4;3;3;5,5;5;5;5;5,Withdrawn,0,0,,yes,9/28/20,University of Bonn;Google Inc;KAUST,Domain Adaptation;Morphologic Segmentation;Image-to-image Translation;,128;-1;110,114;-1;-1,m;m,europe,gr,n,2
8231,ICLR,2021,Detecting Adversarial Examples by Additional Evidence from Noise Domain,Song Gao;Shui Yu;Shaowen Yao,~Song_Gao2;~Shui_Yu1;yaosw@ynu.edu.cn,4;3;4;4,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Yunnan University;;Yunnan University,,209;-1;209,421;-1;421,m;m,asia,cn,n,1;4
8232,ICLR,2021,Everybody's Talkin': Let Me Talk as You Want,Linsen Song;Wayne Wu;Chen Qian;Ran He;Chen Change Loy,~Linsen_Song1;~Wayne_Wu1;~Chen_Qian1;~Ran_He1;~Chen_Change_Loy2,4;5;6;5,5;4;4;4,Withdrawn,0,0,,yes,9/28/20,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tsinghua University;The SenseTime Research;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Nanyang Technological University",,34;4;-1;34;44,-1;20;-1;-1;47,f;m,asia,sg,n,
8233,ICLR,2021,Playing Atari with Capsule Networks: A systematic comparison of CNN and CapsNets-based agents.,Akash Singh;Kevin Mets;Jose Oramas;Steven Latr√©,~Akash_Singh3;~Kevin_Mets1;~Jose_Oramas1;steven.latre@uantwerpen.be,2;4;5;4,2;4;4;3,Withdrawn,0,1,,yes,9/28/20,University of Antwerpen;University of Antwerp;University of Antwerpen;University of Antwerp,,-1;-1;-1;-1,173;173;173;173,m;m,NAN,NAN,n,
8234,ICLR,2021,What can we learn from gradients?,Jia Qian;Lars Kai Hansen,~Jia_Qian1;~Lars_Kai_Hansen1,4;4;6;7,3;4;3;3,Withdrawn,0,0,,yes,9/28/20,Technical University of Denmark;Technical University of Denmark,Privacy;Security;Reconstruction Attack;Federated Learning;,-1;-1,186;186,f;m,NAN,NAN,y,
8235,ICLR,2021,Towards Good Practices in Self-Supervised Representation Learning,srikar appalaraju;Yi Zhu;Yusheng Xie;Istvan Fehervari,~srikar_appalaraju1;~Yi_Zhu1;~Yusheng_Xie1;~Istvan_Fehervari1,4;4;4;5,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Amazon;Amazon;Amazon;Amazon,self-supervised learning;unsupervised learning;deep learning;neural networks;good practices;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,2
8236,ICLR,2021,Neural Disjunctive Normal Form: Vertically Integrating Logic With Deep Learning For Classification,Jialin Lu;Martin Ester,~Jialin_Lu1;~Martin_Ester1,6;5;4;4,2;3;3;5,Withdrawn,0,5,,yes,9/28/20,Simon Fraser University;Simon Fraser University,neuro-symbolic;hybrid;interpretability;,58;58,271;271,m;m,canada,ca,n,
8237,ICLR,2021,Auto-view contrastive learning for few-shot image recognition,Xu Luo;Yuxuan Chen;Liangjian Wen;Lili Pan;Zenglin Xu,~Xu_Luo1;~Yuxuan_Chen2;~Liangjian_Wen1;~Lili_Pan2;~Zenglin_Xu1,4;4;5;7,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,"University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Huawei Technologies Ltd.;University of Electronic Science and Technology of China;Harbin Institute of Technology, Shenzhen",Few-shot learning;Contrastive learning;Metric-based meta learning;,-1;-1;-1;-1;150,553;553;-1;553;416,m;m,NAN,NAN,n,6;1
8238,ICLR,2021,Embedding Transfer via Smooth Contrastive Loss,Sungyeon Kim;Dongwon Kim;Minsu Cho;Suha Kwak,~Sungyeon_Kim1;~Dongwon_Kim1;~Minsu_Cho1;~Suha_Kwak3,4;5;6;6;5;5,4;4;4;3;5;4,Withdrawn,0,1,,yes,9/28/20,POSTECH;POSTECH;POSTECH;POSTECH,embedding transfer;knowledge distillation;deep metric learning;representation learning;,128;128;128;128,151;151;151;151,m;m,asia,kr,n,
8239,ICLR,2021,Pair-based Self-Distillation for Semi-supervised Domain Adaptation,Jeongbeen Yoon;Dahyun Kang;Minsu Cho,~Jeongbeen_Yoon1;~Dahyun_Kang1;~Minsu_Cho1,4;3;5,5;5;5,Withdrawn,0,1,,yes,9/28/20,POSTECH;POSTECH;POSTECH,Semi-supervised Domain Adaptation;Self-Distillation;,128;128;128,151;151;151,f;m,asia,kr,n,
8240,ICLR,2021,Deep Manifold Computing and Visualization Using Elastic Locally Isometric Smoothness,Stan Z. Li;Zelin Zang;Lirong Wu,~Stan_Z._Li2;~Zelin_Zang2;~Lirong_Wu1,4;3;5;5,4;5;3;3,Withdrawn,0,1,,yes,9/28/20,Westlake University;Westlake University;Westlake University,manifold learning;dimensionality reduction;visualization;data generation;,263;263;263,-1;-1;-1,m;m,asia,cn,n,
8241,ICLR,2021,IF-Defense: 3D Adversarial Point Cloud Defense via Implicit Function based Restoration,Ziyi Wu;Yueqi Duan;He Wang;Qingnan Fan;Leonidas Guibas,~Ziyi_Wu1;~Yueqi_Duan1;~He_Wang5;~Qingnan_Fan2;~Leonidas_Guibas1,4;6;6;5,3;4;3;5,Withdrawn,0,0,,yes,9/28/20,"Tsinghua University, Tsinghua University;Stanford University;Peking University;Tencent AI Lab;Stanford University",Point cloud;adversarial defense;implicit function;,4;5;14;-1;5,20;2;23;-1;2,m;m,usa,usa,n,4
8242,ICLR,2021,DOTS: Decoupling Operation and Topology in Differentiable Architecture Search,Yuchao Gu;Yun Liu;Yi Yang;Yu-Huan Wu;Shao-Ping Lu;Ming-Ming Cheng,~Yuchao_Gu1;~Yun_Liu1;~Yi_Yang4;~Yu-Huan_Wu1;~Shao-Ping_Lu1;~Ming-Ming_Cheng3,5;4;6;6,5;5;5;4,Withdrawn,0,0,,yes,9/28/20,"Nankai University;Swiss Federal Institute of Technology;Zhejiang University;Nankai University;Nankai University;Nankai University, Tsinghua University",Neural architecture search;differentiable architecture search;topology search;,-1;-1;42;-1;-1;4,358;-1;94;358;358;20,m;m,NAN,NAN,n,8
8243,ICLR,2021,Graph-Based Neural Network Models with Multiple Self-Supervised Auxiliary Tasks,Franco Manessi;Alessandro Rozza,franco.manessi.86@gmail.com;~Alessandro_Rozza2,4;4;4;5,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,lastminute.com group;lastminute.com group,Graph Neural Networks;Self-supervised learning;Multi-task learning;Graph Convolutional Networks;Semi-supervised learning;,-1;-1,-1;-1,m;m,NAN,NAN,n,8;10
8244,ICLR,2021,Derivative Manipulation for General Example Weighting,Xinshao Wang;Elyor Kodirov;Yang Hua;Neil M. Robertson,~Xinshao_Wang1;~Elyor_Kodirov1;~Yang_Hua2;~Neil_M._Robertson1,4;5;3;5,4;5;4;3,Withdrawn,0,0,,yes,9/28/20,University of Oxford;Anyvision;Queen's University Belfast;Queen's University Belfast,loss function;gradient descent;roubst deep learning;example weighting;regularization;label noise;sample imbalance;,46;-1;263;263,1;-1;199;199,m;m,europe,uk,n,1
8245,ICLR,2021,ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks,Xinshao Wang;Yang Hua;Elyor Kodirov;David A. Clifton;Neil M. Robertson,~Xinshao_Wang1;~Yang_Hua2;~Elyor_Kodirov1;~David_A._Clifton1;~Neil_M._Robertson1,4;4;5;5,4;4;3;4,Withdrawn,0,2,,yes,9/28/20,University of Oxford;Queen's University Belfast;Anyvision;University of Oxford;Queen's University Belfast,label correction;entropy minimisation;maximum entropy;confidence penalty;knowledge distillation;regularization;label noise;,46;263;-1;46;263,1;199;-1;1;199,m;m,europe,uk,n,1
8246,ICLR,2021,LEARNING BILATERAL CLIPPING PARAMETRIC ACTIVATION FUNCTION FOR LOW-BIT NEURAL NETWORKS,Yunlong Ding;Rui Wu;Dirong Chen,~Yunlong_Ding1;rui.wu@horizon.ai;~Dirong_Chen1,4;3;4;5,4;3;3;4,Withdrawn,0,0,,yes,9/28/20,Beihang University;Horizon Robotics;Beihang University,quantization;activation function;unbounded;full-precision;,99;-1;99,567;-1;567,m;f,asia,cn,y,1
8247,ICLR,2021,PLM: Partial Label Masking for Imbalanced Multi-label Classification,Kevin Duarte;Yogesh S Rawat;Mubarak Shah,~Kevin_Duarte1;~Yogesh_S_Rawat1;~Mubarak_Shah3,6;4;5,3;4;3,Withdrawn,0,1,,yes,9/28/20,University of Central Florida;University of Central Florida;University of Central Florida,Deep Learning;Imbalance;Multilabel;Classification;,71;71;71,633;633;633,m;m,usa,usa,n,
8248,ICLR,2021,Max-Affine Spline Insights Into Deep Network Pruning,Randall Balestriero;Haoran You;Zhihan Lu;Yutong Kou;Yingyan Lin;Richard Baraniuk,~Randall_Balestriero1;~Haoran_You1;~Zhihan_Lu1;~Yutong_Kou1;~Yingyan_Lin1;~Richard_Baraniuk1,2;4;5;4,4;4;5;5,Withdrawn,0,0,,yes,9/28/20,Rice University;Rice University;Rice University;Huazhong University of Science and Technology;Rice University;William Marsh Rice University,Network pruning;Spline theory;,92;92;92;-1;92;92,124;124;124;312;124;124,m;m,NAN,NAN,n,
8249,ICLR,2021,MCMC-Interactive Variational Inference,Quan Zhang;Huangjie Zheng;Mingyuan Zhou,~Quan_Zhang1;~Huangjie_Zheng1;~Mingyuan_Zhou1,4;4;4;5,3;3;3;3,Withdrawn,0,1,,yes,9/28/20,"Michigan State University;University of Texas, Austin;The University of Texas at Austin",Gibbs sampling;stochastic gradient Langevin dynamics;design of MCMC;Bayesian bridge regression;variational autoencoders;,110;-1;20,105;-1;43,m;m,NAN,NAN,y,1
8250,ICLR,2021,Domain Knowledge in Exploration Noise in AlphaZero,Eric Weiner;George D Monta√±ez;Aaron Trujillo;Abtin Molavi,~Eric_Weiner1;gmontanez@hmc.edu;atrujillo@hmc.edu;amolavi@hmc.edu,3;4;4;4,5;4;4;5,Withdrawn,0,1,,yes,9/28/20,Harvey Mudd College;;;Harvey Mudd College,Machine Learning;AlphaZero;Information Theory;Inductive Bias;MCTS;Monte Carlo Tree Search;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,
8251,ICLR,2021,FOC OSOD: Focus on Classification One-Shot Object Detection,Hanqing Yang;Huaijin Pi;SABA GHORBANI BARZEGAR;Yu Zhang,~Hanqing_Yang1;~Huaijin_Pi1;~SABA_GHORBANI_BARZEGAR1;~Yu_Zhang31,5;4;4,3;4;5,Withdrawn,0,0,,yes,9/28/20,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,one-shot object detection;false positives;focus on classification;,42;42;42;42,94;94;94;94,m;m,asia,cn,n,2
8252,ICLR,2021,Self-supervised Temporal Learning,Hao Shao;Yu Liu;Hongsheng Li,~Hao_Shao1;~Yu_Liu2;~Hongsheng_Li3,6;4;4;5,5;5;4;4,Withdrawn,0,0,,yes,9/28/20,"Tsinghua University, Tsinghua University;The Chinese University of Hong Kong;The Chinese University of Hong Kong",,4;327;327,20;39;39,m;m,NAN,NAN,n,
8253,ICLR,2021,Efficiently labelling sequences using semi-supervised active learning,Harshil Shah;David Barber,~Harshil_Shah1;~David_Barber1,4;3;5;5,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,University College London;University College London,,53;53,-1;-1,m;m,europe,uk,n,3
8254,ICLR,2021,Differentiable Programming for Piecewise Polynomial Functions,Minsu Cho;Ameya Joshi;Xian Yeow Lee;Aditya Balu;Adarsh Krishnamurthy;Baskar Ganapathysubramanian;Soumik Sarkar;Chinmay Hegde,~Minsu_Cho2;~Ameya_Joshi2;~Xian_Yeow_Lee1;~Aditya_Balu1;~Adarsh_Krishnamurthy1;~Baskar_Ganapathysubramanian1;~Soumik_Sarkar1;~Chinmay_Hegde1,4;4;5;3,3;3;4;3,Withdrawn,0,0,,yes,9/28/20,New York University;New York University;Iowa State University;Iowa State University;Iowa State University;Iowa State University;Iowa State University;New York University,Differentiable Programming;piecewise polynomial regression;generative models;segmentation;,23;23;209;209;209;209;209;23,26;26;427;427;427;427;427;26,m;m,usa,usa,y,2;5
8255,ICLR,2021,Sequential Normalization: an improvement over Ghost Normalization,Neofytos Dimitriou;Ognjen Arandjelovic,~Neofytos_Dimitriou1;~Ognjen_Arandjelovic2,3;4;4;4,4;5;5;4,Withdrawn,0,0,,yes,9/28/20,University of St Andrews;University of St Andrews,,327;327,239;239,m;m,europe,uk,n,
8256,ICLR,2021,Robust Ensembles of Neural Networks using It√¥ Processes,Sumit Kumar Jha;Susmit Jha;Rickard Ewetz;Alvaro Velasquez,~Sumit_Kumar_Jha2;~Susmit_Jha1;~Rickard_Ewetz1;alvarovelasquezucf@gmail.com,1;7;6;5,5;2;2;3,Withdrawn,0,15,,yes,9/28/20,"University of Texas, San Antonio;SRI International;University of Central Florida;Air Force Research Laboratory",Robustness;Ito Process;Stochastic;,-1;-1;71;-1,-1;-1;633;-1,m;m,NAN,NAN,n,1;4
8257,ICLR,2021,Exploring representation learning for flexible few-shot tasks,Mengye Ren;Eleni Triantafillou;Kuan-Chieh Wang;James Lucas;Jake Snell;Xaq Pitkow;Andreas S. Tolias;Richard Zemel,~Mengye_Ren1;~Eleni_Triantafillou1;~Kuan-Chieh_Wang1;~James_Lucas1;~Jake_Snell1;~Xaq_Pitkow1;~Andreas_S._Tolias1;~Richard_Zemel1,4;5;4;8,4;5;4;3,Withdrawn,0,0,,yes,9/28/20,"University of Toronto;University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Baylor College of Medicine;Baylor College of Medicine;University of Toronto",Few-shot learning;representation learning;,18;18;18;18;18;-1;-1;18,18;18;18;18;18;-1;-1;18,m;m,canada,ca,n,6
8258,ICLR,2021,Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations,Jinyuan Jia;Binghui Wang;Xiaoyu Cao;Hongbin Liu;Neil Zhenqiang Gong,~Jinyuan_Jia2;~Binghui_Wang2;~Xiaoyu_Cao1;hongbin.liu@duke.edu;~Neil_Zhenqiang_Gong1,6;5;5;5,3;4;2;4,Withdrawn,0,0,,yes,9/28/20,Duke University;Duke University;Duke University;Duke University;Duke University,Certified robustness;adversarial perturbation;,46;46;46;46;46,20;20;20;20;20,m;m,europe,se,y,4
8259,ICLR,2021,Deep Active Learning for Object Detection with Mixture Density Networks,Jiwoong Choi;Ismail Elezi;Hyuk-Jae Lee;Clement Farabet;Jose M. Alvarez,~Jiwoong_Choi1;~Ismail_Elezi1;~Hyuk-Jae_Lee1;~Clement_Farabet1;~Jose_M._Alvarez2,5;5;6;3,5;3;2;4,Withdrawn,0,0,,yes,9/28/20,Seoul National University;University Ca' Foscari of Venice;Seoul National University;;NVIDIA,Active Learning;Object Detection;,37;-1;37;-1;-1,60;-1;60;-1;-1,m;m,NAN,NAN,n,2
8260,ICLR,2021,Spectrally Similar Graph Pooling,Kyoung-Woon On;Eun-Sol Kim;Il-Jae Kwon;Sangwoong Yoon;Byoung-Tak Zhang,~Kyoung-Woon_On1;~Eun-Sol_Kim1;~Il-Jae_Kwon1;~Sangwoong_Yoon1;~Byoung-Tak_Zhang1,5;7;4;7,3;3;4;3,Withdrawn,0,0,,yes,9/28/20,Seoul National University;Kakao Brain;Seoul National University;Seoul National University;Seoul National University,Graph Neural Networks;Graph Pooling;Spectral Similarity on Graph;,37;-1;37;37;37,60;-1;60;60;60,m;m,asia,kr,y,10
8261,ICLR,2021,No Feature Is An Island: Adaptive Collaborations Between Features Improve Adversarial Robustness,Yufeng Zhang;Yunan Zhang;ChengXiang Zhai,zhangyufeng.96@bytedance.com;~Yunan_Zhang1;~ChengXiang_Zhai1,4;5;4,4;3;3,Withdrawn,0,0,,yes,9/28/20,ByteDance Inc;University of Illinois  Urbana Champaign;University of Illinois  Urbana Champaign,robustness;adversarial attack;defense;representation learning;cooperative game;feature selection;adversarial robustness;reliable machine learning;,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n,1;4
8262,ICLR,2021,Temporal Difference Networks for Action Recognition,Limin Wang;Bin Ji;Zhan Tong;Gangshan Wu,~Limin_Wang1;~Bin_Ji2;~Zhan_Tong1;~Gangshan_Wu1,5;6;4,4;5;5,Withdrawn,0,0,,yes,9/28/20,Nanjing University;;Nanjing University;Nanjing University,action recognition;video understanding;temporal modeling;,52;-1;52;52,111;-1;111;111,m;m,asia,kr,n,
8263,ICLR,2021,Orthogonal Over-Parameterized Training,Weiyang Liu;Rongmei Lin;Zhen Liu;James Matthew Rehg;Li Xiong;Adrian Weller;Le Song,~Weiyang_Liu1;~Rongmei_Lin1;~Zhen_Liu6;~James_Matthew_Rehg1;~Li_Xiong1;~Adrian_Weller1;~Le_Song1,3;5;6,4;2;3,Withdrawn,0,5,,yes,9/28/20,"University of Cambridge;Emory University;University of Montreal;Georgia Institute of Technology;Emory University;Alan Turing Institute;College of Computing, Georgia Institute of Technology",Neural Network;Hyperspherical Energy;Inductive Bias;Orthogonality;,79;174;128;12;174;-1;12,6;85;73;38;85;-1;38,m;m,NAN,NAN,n,1
8264,ICLR,2021,The Card Shuffling Hypotheses: Building a Time and Memory Efficient Graph Convolutional Network,Yawei Li;He Chen;Zhaopeng Cui;Radu Timofte;Marc Pollefeys;Gregory Chirikjian;Luc Van Gool,~Yawei_Li1;~He_Chen1;~Zhaopeng_Cui1;~Radu_Timofte1;~Marc_Pollefeys2;~Gregory_Chirikjian1;~Luc_Van_Gool1,4;4;3;4,5;5;4;3,Withdrawn,0,0,,yes,9/28/20,Swiss Federal Institute of Technology;Johns Hopkins University;Swiss Federal Institute of Technology;ETH Zurich;Microsoft;Johns Hopkins University;KTH,graph convolutional network;network compression;model acceleration;k-nearest nearst neighbor;card shuffling;3D deep learning;,-1;71;-1;9;-1;71;174,-1;12;-1;14;-1;12;239,m;m,asia,in,y,2;10
8265,ICLR,2021,Faster and Smarter AutoAugment: Augmentation Policy Search Based on Dynamic Data-Clustering,Jonghyun Bae;Ji-Hoon Kim,~Jonghyun_Bae1;~Ji-Hoon_Kim2,4;3;4;5,5;4;5;3,Withdrawn,0,0,,yes,9/28/20,Seoul National University;NAVER,Data augmentation;Image recognition;Computer vision;,37;-1,60;-1,m;m,europe,gr,n,3;2;1
8266,ICLR,2021,Is Retriever Merely an Approximator of Reader?,Sohee Yang;Minjoon Seo,~Sohee_Yang1;~Minjoon_Seo1,2;4;5;8;3,4;5;5;4;4,Withdrawn,0,1,,yes,9/28/20,"Clova AI, NAVER Corp.;Korea Advanced Institute of Science and Technology",NLP;Open-Domain QA;Open-Domain Question Answering;Document Retrieval;,-1;-1,-1;96,f;m,NAN,NAN,n,
8267,ICLR,2021,MOFA: Modular Factorial Design for Hyperparameter Optimization,Bo Xiong;Yimin Huang;Steffen Staab;Zhenguo Li,~Bo_Xiong3;~Yimin_Huang2;~Steffen_Staab2;~Zhenguo_Li1,4;3;4;5,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,University of Stuttgart;Huawei Technologies Ltd.;University of Stuttgart;Huawei,Automated Hyperparameter Optimization;Factorial Analysis;Model-Free;Sample Efficiency;Orthogonal Latin Hypercubes;,110;-1;110;-1,354;-1;354;-1,m;m,NAN,NAN,n,8
8268,ICLR,2021,Polar Embedding,Ran Iwamoto;Ryosuke Kohita;Akifumi Wachi,~Ran_Iwamoto1;~Ryosuke_Kohita1;~Akifumi_Wachi2,3;4;3;4,5;4;5;3,Withdrawn,0,1,,yes,9/28/20,Keio University;International Business Machines;International Business Machines,natural language processing;word embedding;hierarchical representations;polar coordinates;,263;-1;-1,730;-1;-1,f;m,NAN,NAN,n,3
8269,ICLR,2021,Training Data Generating Networks: Linking 3D Shapes and Few-Shot Classification,Biao Zhang;Peter Wonka,~Biao_Zhang5;~Peter_Wonka1,5;4;6;3,4;4;4;4,Withdrawn,0,4,,yes,9/28/20,KAUST;KAUST,shape representation;single image 3d reconstruction;few-shot learning;meta learning;,110;110,-1;-1,m;m,europe,gr,n,6
8270,ICLR,2021,Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition,Ionut Cosmin Duta;Li Liu;Fan Zhu;Ling Shao,~Ionut_Cosmin_Duta2;~Li_Liu12;~Fan_Zhu5;~Ling_Shao1,5;5;6;3,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,IIAI;IIAI;Inception Institute of Artificial Intelligence;Inception Institute of Artificial Intelligence,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,2
8271,ICLR,2021,Point Cloud Instance Segmentation using Probabilistic Embeddings,Biao Zhang;Peter Wonka,~Biao_Zhang5;~Peter_Wonka1,5;5;7;4,4;4;4;4,Withdrawn,0,4,,yes,9/28/20,KAUST;KAUST,point clouds;instance segmentation;uncertainty estimation;probabilistic embedding;,110;110,-1;-1,m;m,europe,gr,n,2
8272,ICLR,2021,Heterogeneous Model Transfer between Different Neural Networks,Guangcong Wang;Jianhuang Lai;Wenqi Liang;Guangrun Wang,~Guangcong_Wang1;~Jianhuang_Lai1;liangwq8@mail2.sysu.edu.cn;~Guangrun_Wang1,4;3;5;5,4;5;5;5,Withdrawn,0,0,,yes,9/28/20,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;;;University of Oxford,Heterogeneous model transfer;pretraining-finetuning;,-1;-1;-1;-1;46,293;293;-1;-1;1,m;m,europe,uk,n,
8273,ICLR,2021,A 3D Convolutional Neural Network for Predicting Wildfire Profiles,Samuel Sung;Yuping Li;Leonard Ortolano,~Samuel_Sung1;yupingli@stanford.edu;ortolano@stanford.edu,2;3;3;3;3,5;5;4;5;4,Withdrawn,0,0,,yes,9/28/20,Stanford University;;Stanford University,AI application in Earth Science;Convolutional Neural Network;3D;Wildfire Spread Model;,5;-1;5,2;-1;2,m;m,usa,usa,n,
8274,ICLR,2021,Connection-Adaptive Meta-Learning,Yadong Ding;Yu Wu;Chengyue Huang;Siliang Tang;Yi Yang;Yueting Zhuang,~Yadong_Ding1;~Yu_Wu3;~Chengyue_Huang1;~Siliang_Tang1;~Yi_Yang4;~Yueting_Zhuang1,5;4;3;5,4;4;5;4,Withdrawn,0,4,,yes,9/28/20,Zhejiang University;University of Technology Sydney;Zhejiang University;Zhejiang University;Zhejiang University;;Zhejiang University;Zhejiang University,Meta learning;NAS;Fast adaptation;,42;71;42;42;42;-1;42;42,94;160;94;94;94;-1;94;94,m;m,asia,cn,n,6
8275,ICLR,2021,ImCLR: Implicit Contrastive Learning for Image Classification,John Chen;Samarth Sinha;Anastasios Kyrillidis,~John_Chen3;~Samarth_Sinha1;~Anastasios_Kyrillidis2,4;5;4;5,4;3;4;4,Withdrawn,0,4,,yes,9/28/20,"Rice University;University of Toronto, Toronto University;Rice University",Image classification;supervised learning;contrastive learning;,92;18;92,124;18;124,m;m,australasia,au,n,
8276,ICLR,2021,Semi-supervised Domain Adaptation with Prototypical Alignment and Consistency Learning,Kai Li;Chang Liu;Handong Zhao;Yulun Zhang;Yun Fu,~Kai_Li3;~Chang_Liu13;~Handong_Zhao3;~Yulun_Zhang1;~Yun_Fu1,4;6;6;5;5,5;4;5;4;5,Withdrawn,0,0,,yes,9/28/20,Northeastern University;Northeastern University;Adobe Systems;Northeastern University;Northeastern University,,16;16;-1;16;16,895;895;-1;895;895,m;m,usa,usa,n,
8277,ICLR,2021,Generalization and Stability of GANs: A theory and promise from data augmentation,Khoat Than;Nghia Vu,~Khoat_Than1;vutrungnghiahust99@gmail.com,4;3;4;3,4;4;4;2,Withdrawn,0,0,,yes,9/28/20,Hanoi University of Science and Technology;Hanoi University of Science and Technology,generative adversarial networks;generalization;stability;data augmentation;,-1;-1,1158;1158,m;m,NAN,NAN,y,1;5;4
8278,ICLR,2021,Blank,Moitreya Chatterjee;Anoop Cherian;Narendra Ahuja,~Moitreya_Chatterjee1;~Anoop_Cherian1;~Narendra_Ahuja1,6;5;5;4,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,"University of Illinois, Urbana Champaign;Australian National University;University of Illinois at Urbana-Champaign",Blank;,-1;99;-1,-1;59;48,m;m,NAN,NAN,pdf miss,
8279,ICLR,2021,Enabling Efficient On-Device Self-supervised Contrastive Learning by Data Selection,Yawen Wu;Zhepeng Wang;Dewen Zeng;Yiyu Shi;Jingtong Hu,~Yawen_Wu1;zhw82@pitt.edu;~Dewen_Zeng1;~Yiyu_Shi1;~Jingtong_Hu1,4;5;4,4;3;3,Withdrawn,0,0,,yes,9/28/20,University of Pittsburgh;University of Pittsburgh;University of Notre Dame;University of Notre Dame;University of Pittsburgh,Contrastive Learning;On-device Training;Data Selection;,79;79;128;128;79,133;133;170;170;133,m;m,usa,usa,n,
8280,ICLR,2021,On Sparse Critical Paths of Neural Response,Ashkan Khakzar;Soroosh Baselizadeh;Saurabh Khanduja;Christian Rupprecht;Seong Tae Kim;Nassir Navab,~Ashkan_Khakzar1;~Soroosh_Baselizadeh1;~Saurabh_Khanduja1;~Christian_Rupprecht1;~Seong_Tae_Kim1;~Nassir_Navab1,4;6;4,3;5;2,Withdrawn,0,1,,yes,9/28/20,Technical University Munich;Sharif University of Technology;Technical University Munich;University of Oxford;Kyung Hee University;TU Munich,Interpretability;Feature Attribution;Neural Network Pruning;Critical Paths;,-1;327;-1;46;453;58,-1;475;-1;1;265;32,m;m,europe,de,y,
8281,ICLR,2021,Image Animation with Refined Masking,yoav shalev;Lior Wolf,~yoav_shalev1;~Lior_Wolf1,5;4;5,4;5;4,Withdrawn,0,4,,yes,9/28/20,Tel Aviv University;Tel Aviv University,,34;34,190;190,m;m,europe,il,n,
8282,ICLR,2021,ACDC: Weight Sharing in Atom-Coefficient Decomposed Convolution,Ze Wang;Xiuyuan Cheng;Guillermo Sapiro;Qiang Qiu,~Ze_Wang3;~Xiuyuan_Cheng1;~Guillermo_Sapiro1;~Qiang_Qiu1,5;4;6;5,4;3;4;4,Withdrawn,0,5,,yes,9/28/20,Purdue University;Duke University;Duke University;Purdue University,,23;46;46;23,94;20;20;94,m;m,usa,usa,n,6
8283,ICLR,2021,Learning Semantic Similarities for Prototypical Classifiers,Joao Monteiro;Isabela Albuquerque;Jahangir Alam;Tiago Falk,~Joao_Monteiro1;~Isabela_Albuquerque1;~Jahangir_Alam1;~Tiago_Falk1,4;4;4;4,5;4;3;4,Withdrawn,0,0,,yes,9/28/20,Institut national de la recherche scientifique;Institut national de la recherche scientifique;Computer Research Institute of Montreal (CRIM);‚àö√¢nergie Mat‚àö¬©riaux T‚àö¬©l‚àö¬©communications Research Centre,Semantic similarities;metric learning;prototypical classifiers;adversarial robustness;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,6;4
8284,ICLR,2021,SHOT IN THE DARK: FEW-SHOT LEARNING WITH NO BASE-CLASS LABELS,Zitian Chen;Subhransu Maji;Erik Learned-Miller,~Zitian_Chen1;~Subhransu_Maji1;~Erik_Learned-Miller2,6;5;4;4,4;4;3;5,Withdrawn,0,4,,yes,9/28/20,"University of Massachusetts, Amherst;Department of Computer Science, University of Massachusetts, Amherst;Department of Computer Science, University of Massachusetts, Amherst",Few-shot learning;transductive learning;unsupervised learning;self-supervised learning;,23;-1;-1,210;210;210,m;m,NAN,NAN,n,6
8285,ICLR,2021,FGNAS: FPGA-Aware Graph Neural Architecture Search,Qing Lu;Weiwen Jiang;Meng Jiang;Jingtong Hu;Sakyasingha Dasgupta;Yiyu Shi,~Qing_Lu2;~Weiwen_Jiang1;~Meng_Jiang3;~Jingtong_Hu1;~Sakyasingha_Dasgupta1;~Yiyu_Shi1,5;5;4;3,4;4;5;5,Withdrawn,0,0,,yes,9/28/20,University of Notre Dame;University of Notre Dame;University of Notre Dame;University of Pittsburgh;International Business Machines Research;University of Notre Dame,graph neural network;NAS;FPGA;,128;128;128;79;-1;128,170;170;170;133;-1;170,m;m,usa,usa,n,10
8286,ICLR,2021,AutoHAS: Efficient Hyperparameter and Architecture Search,Xuanyi Dong;Mingxing Tan;Adams Wei Yu;Daiyi Peng;Bogdan Gabrys;Quoc V Le,~Xuanyi_Dong1;~Mingxing_Tan3;~Adams_Wei_Yu1;~Daiyi_Peng1;~Bogdan_Gabrys1;~Quoc_V_Le1,5;5;6;4,5;4;2;5,Withdrawn,0,3,,yes,9/28/20,University of Technology Sydney;Google;Google Brain;;University of Technology Sydney;Google,HPO;NAS;AutoML;,71;-1;-1;-1;71;-1,160;-1;-1;-1;160;-1,m;m,NAN,NAN,n,11;1
8287,ICLR,2021,Neural Cellular Automata Manifold,Alejandro Hernandez Ruiz;Armand Vilalta;Francesc Moreno-Noguer,~Alejandro_Hernandez_Ruiz1;~Armand_Vilalta1;~Francesc_Moreno-Noguer1,5;7;4;4,4;1;2;4,Withdrawn,0,0,,yes,9/28/20,Institut de Rob√≤tica i Inform√†tica Industrial;;Universitat Politecnica de Catalunya,Cellular Automata;Manifold;Embedding;,-1;-1;-1,-1;-1;700,m;m,NAN,NAN,n,1
8288,ICLR,2021,Dual Averaging is Surprisingly Effective for Deep Learning Optimization,Samy Jelassi;Aaron Defazio,~Samy_Jelassi1;~Aaron_Defazio1,4;4;3;6,3;4;5;4,Withdrawn,0,0,,yes,9/28/20,Princeton University;Facebook,,29;-1,9;-1,m;m,NAN,NAN,y,8;2;3
8289,ICLR,2021,Multi-level Graph Matching Networks for Deep and Robust Graph Similarity Learning,Xiang Ling;Lingfei Wu;Saizhuo Wang;Tengfei Ma;Fangli Xu;Alex X. Liu;Chunming Wu;Shouling Ji,~Xiang_Ling1;~Lingfei_Wu1;~Saizhuo_Wang1;~Tengfei_Ma1;~Fangli_Xu2;alexliu@antfin.com;wuchunming@zju.edu.cn;~Shouling_Ji1,5;4;4;5;5,4;4;5;4;4,Withdrawn,0,0,,yes,9/28/20,Zhejiang University;JD.COM Silicon Valley Research Center;The Hong Kong University of Science and Technology;International Business Machines;Squirrel AI Learning;;;;;Zhejiang University,Semi-supervised Learning;Graph Neural Network;Graph Similarity Learning;,42;-1;-1;-1;-1;-1;-1;-1;-1;42,94;-1;56;-1;-1;-1;-1;-1;-1;94,u;m,asia,cn,n,10
8290,ICLR,2021,Training-Free Uncertainty Estimation for Dense Regression: Sensitivity as a Surrogate,Lu Mi;Hao Wang;Yonglong Tian;Nir Shavit,~Lu_Mi1;~Hao_Wang3;~Yonglong_Tian1;~Nir_Shavit1,6;3;4,4;5;3,Withdrawn,0,0,,yes,9/28/20,Massachusetts Institute of Technology;Rutgers University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,training-free;uncertainty estimation;dense regression;super resolution;depth estimation;deep learning;,5;29;5;5,4;-1;4;4,f;m,usa,usa,y,2;11
8291,ICLR,2021,Optimal Designs of Gaussian Processes with Budgets for Hyperparameter Optimization,Yimin Huang;Yujun Li;Zhenguo Li;Zhihua Zhang,~Yimin_Huang2;~Yujun_Li1;~Zhenguo_Li1;~Zhihua_Zhang1,3;4;4,4;4;3,Withdrawn,0,0,,yes,9/28/20,Huawei Technologies Ltd.;Shanghai Jiao Tong University;Huawei;Shanghai Jiao Tong University,Automated Hyperparameter Optimization;Budgets;Efficiency;Optimal Initial Design;Robustness;,-1;29;-1;29,-1;100;-1;100,f;m,asia,cn,y,11;1
8292,ICLR,2021,Ranking Neural Checkpoints,YANDONG LI;Xuhui Jia;Ruoxin Sang;Yukun Zhu;Bradley Green;Liqiang Wang;Boqing Gong,~YANDONG_LI1;~Xuhui_Jia1;rxsang@google.com;~Yukun_Zhu1;~Bradley_Green3;~Liqiang_Wang1;~Boqing_Gong1,6;4;5;5,4;3;5;4,Withdrawn,0,0,,yes,9/28/20,University of Central Florida;The University of Hong Kong;Google;Google;Google Research;University of Central Florida;International Computer Science Institute,checkpoint selection;transfer learning;task transferability;network generalization prediction;,71;99;-1;-1;-1;71;-1,633;39;-1;-1;-1;633;-1,m;m,NAN,NAN,n,6
8293,ICLR,2021,Quantum and Translation Embedding for Knowledge Graph Completion,Panfeng Chen;Yisong Wang;Renyan Feng;Xiaomin Yu;Quan Yu,~Panfeng_Chen1;yswang@gzu.edu.cn;renyan_feng@163.com;musexiaoyu521@outlook.com;yuquanlogic@126.com,4;4;3;4,4;4;5;4,Withdrawn,0,0,,yes,9/28/20,Guizhou University;;;;Sun Yat-Sen University,quantum embedding;knowledge graph embedding;knowledge graph completion;logical rules mining;knowledge base;,-1;-1;-1;-1;128,831;-1;-1;-1;293,m;m,asia,cn,n,10
8294,ICLR,2021,SAD: Saliency Adversarial Defense without Adversarial Training,Yao Zhu;Jiacheng Sun;Zewei Chen;Zhenguo Li,~Yao_Zhu2;~Jiacheng_Sun1;~Zewei_Chen1;~Zhenguo_Li1,5;4;4,5;5;5,Withdrawn,0,0,,yes,9/28/20,Zhejiang University;Peking University;The Hong Kong University of Science and Technology;Huawei,Adversarial Robustness;Saliency Maps;Interpretability;,42;14;-1;-1,94;23;56;-1,m;m,NAN,NAN,n,4
8295,ICLR,2021,Dense Global Context Aware RCNN for Object Detection,Wenchao Zhang;Haoyu Xie;Mai Zhu;Chong Fu,~Wenchao_Zhang1;~Haoyu_Xie2;~Mai_Zhu1;~Chong_Fu1,3;5;5;4,5;4;5;5,Withdrawn,0,1,,yes,9/28/20,Northeastern University;Northeastern University;SCHOOL OF COMPUTER SCIENCE AND ENGINEERING;Northeastern University,Object DetectionÔºåDense ConnectionÔºåContext AwareÔºåAttention Mechanism;,16;16;-1;16,895;895;-1;895,m;m,usa,usa,n,8;2
8296,ICLR,2021,Asymptotic Optimality of Self-Representative Low-Rank Approximation and Its Applications,Saeed Vahidian;mohsen Joneidi;Ashkan Esmaeili;Siavash Khodadadeh;Sharare zehtabian;Ladislau Boloni;Nazanin Rahnavard;Bill Lin;Mubarak Shah,~Saeed_Vahidian1;joneidi@knights.ucf.edu;ashkan.esmaeili@ucf.edu;~Siavash_Khodadadeh1;sharare.zehtabian@knights.ucf.edu;~Ladislau_Boloni1;~Nazanin_Rahnavard1;~Bill_Lin1;~Mubarak_Shah3,3;4;4;4,3;3;4;4,Withdrawn,0,0,,yes,9/28/20,"University of California, San Diego;University of Central Florida;University of Central Florida;University of Central Florida;University of Central Florida;University of Central Florida;University of Central Florida;University of California, San Diego;University of Central Florida",data selection;low rank approximation;column subset selection;,-1;71;71;71;71;71;71;-1;71,33;633;633;633;633;633;633;33;633,m;m,usa,usa,n,1;10
8297,ICLR,2021,Reinforcement Learning for Flexibility Design Problems,Yehua Wei;Lei Zhang;Ruiyi Zhang;Shijing Si;Hao Zhang;Lawrence Carin,~Yehua_Wei2;lei.zhang3@fmr.com;~Ruiyi_Zhang3;shijing.si@duke.edu;haz4007@med.cornell.edu;~Lawrence_Carin2,5;4;4;4,4;5;5;4,Withdrawn,0,0,,yes,9/28/20,"Duke University;;;Duke University;Duke University;Weill Cornell Medicine, Cornell University;Duke University",reinforcement learning;flexibility design;policy gradient;combinatorial optimization;,46;-1;-1;46;46;7;46,20;-1;-1;20;20;19;20,m;m,europe,se,n,
8298,ICLR,2021,Density-Based Object Detection: Learning Bounding Boxes without Ground Truth Assignment,Jaeyoung Yoo;Hojun Lee;Inseop Chung;Geonseok Seo;Nojun Kwak,~Jaeyoung_Yoo2;~Hojun_Lee2;~Inseop_Chung1;~Geonseok_Seo2;~Nojun_Kwak1,3;4;7,5;5;5,Withdrawn,0,4,,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University;Seoul National University;Seoul National University,Multi-Object Detection;Density Estimation;Mixture Model;Ground Truth Assignment;,37;37;37;37;37,60;60;60;60;60,m;m,asia,kr,n,2
8299,ICLR,2021,FAST DIFFERENTIALLY PRIVATE-SGD VIA JL PROJECTIONS,Zhiqi Bu;Sivakanth Gopi;Janardhan Kulkarni;Yin Tat Lee;Uthaipon Tantipongpipat,~Zhiqi_Bu1;sigopi@microsoft.com;~Janardhan_Kulkarni2;~Yin_Tat_Lee1;~Uthaipon_Tantipongpipat1,7;4;7,2;3;3,Withdrawn,0,0,,yes,9/28/20,University of Pennsylvania;Microsoft Research;Microsoft;University of Washington;Twitter,Deep Learning;Differential Privacy;Optimization Algorithms;,20;-1;-1;11;-1,13;-1;-1;29;-1,m;m,NAN,NAN,y,
8300,ICLR,2021,A Point Cloud Generative Model Based on Nonequilibrium Thermodynamics,Shitong Luo;Wei Hu,~Shitong_Luo1;~Wei_Hu6,7;6;4,3;5;5,Withdrawn,0,0,,yes,9/28/20,Peking University;Peking University,Point cloud;Generation;Generative model;,14;14,23;23,m;m,asia,cn,n,1
8301,ICLR,2021,Mobile Construction Benchmark,Wenyu Han;Chen Feng;Haoran Wu;Alexander Gao;Armand Jordana;Dongdong Liu;Lerrel Pinto;Ludovic Righetti,wenyuhan@nyu.edu;~Chen_Feng2;haoran.wu@nyu.edu;alexandergao@nyu.edu;aj2988@nyu.edu;~Dongdong_Liu1;~Lerrel_Pinto1;~Ludovic_Righetti1,5;4;4;4,3;5;5;4,Withdrawn,0,0,,yes,9/28/20,New York University;New York University;New York University;;;New York University;New York University;New York University;New York University,localization;dynamic environment;deep reinforcement learning;benchmark;,23;23;23;-1;-1;23;23;23;23,26;26;26;-1;-1;26;26;26;26,m;m,usa,usa,n,
8302,ICLR,2021,The Effectiveness of Memory Replay in Large Scale Continual Learning,Yogesh Balaji;Mehrdad Farajtabar;Dong Yin;Alex Mott;Ang Li,~Yogesh_Balaji1;~Mehrdad_Farajtabar1;~Dong_Yin1;~Alex_Mott1;~Ang_Li1,4;3;5;5,5;4;4;4,Withdrawn,0,5,,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;Google;DeepMind;DeepMind;Google DeepMind",Continual learning;memory replay;regularization;lifelong learning;multi-task learning;,-1;-1;-1;-1;-1,90;-1;-1;-1;-1,m;m,NAN,NAN,n,
8303,ICLR,2021,Smooth Adversarial Training,cihang xie;Mingxing Tan;Boqing Gong;Alan Yuille;Quoc V Le,~cihang_xie1;~Mingxing_Tan3;~Boqing_Gong1;~Alan_Yuille1;~Quoc_V_Le1,6;7;4;4,4;4;5;4,Withdrawn,0,7,,yes,9/28/20,"University of California, Santa Cruz;Google;International Computer Science Institute;Johns Hopkins University;Google",adversarial defense;adversarial machine learning;activation function;adversarial training;neural network architecture;,-1;-1;-1;71;-1,207;-1;-1;12;-1,m;m,NAN,NAN,n,4
8304,ICLR,2021,A Stochastic Gradient Langevin Dynamics Algorithm For Noise Intrinsic Federated Learning,Yan Shen;Jian Du;Chunwei Ma;Mingchen Gao;Benyu Zhang,~Yan_Shen1;~Jian_Du3;~Chunwei_Ma1;~Mingchen_Gao1;~Benyu_Zhang1,2;3;3;3,4;5;3;4,Withdrawn,0,0,,yes,9/28/20,"State University of New York, Buffalo;Ant Group;SEU;University at Buffalo, SUNY;Peking Univ",,-1;-1;263;64;14,-1;-1;-1;273;23,u;m,NAN,NAN,y,1
8305,ICLR,2021,Learning Image Labels On-the-fly for Training Robust Classification Models,Xiaosong Wang;Ziyue Xu;Dong Yang;Leo K Tam;Holger R Roth;Daguang Xu,~Xiaosong_Wang1;~Ziyue_Xu1;~Dong_Yang1;~Leo_K_Tam1;~Holger_R_Roth1;~Daguang_Xu2,5;7;4,4;3;2,Withdrawn,0,3,,yes,9/28/20,NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA,Attention-on-label;meta training;noisy data;multi-observer;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y,3;8;1
8306,ICLR,2021,TransNAS-Bench-101: Improving Transferrability and Generalizability of Cross-Task Neural Architecture Search,Yawen Duan;Xin Chen;Hang Xu;Zewei Chen;Xiaodan Liang;Tong Zhang;Zhenguo Li,~Yawen_Duan1;~Xin_Chen15;~Hang_Xu1;~Zewei_Chen1;~Xiaodan_Liang2;~Tong_Zhang2;~Zhenguo_Li1,6;5;5;5,5;4;5;3,Withdrawn,0,0,,yes,9/28/20,The University of Hong Kong;The University of Hong Kong;Huawei Noah‚Äòs Ark Lab;The Hong Kong University of Science and Technology;SUN YAT-SEN UNIVERSITY;Google;Huawei,,99;99;-1;-1;-1;-1;-1,39;39;-1;56;293;-1;-1,f;m,NAN,NAN,n,6
8307,ICLR,2021,Sparta: Spatially Attentive and Adversarially Robust Activations,Qing Guo;Felix Juefei-Xu;Changqing Zhou;Lei Ma;Xiaofei Xie;Wei Feng;Yang Liu,~Qing_Guo3;~Felix_Juefei-Xu2;zhou0365@e.ntu.edu.sg;~Lei_Ma1;~Xiaofei_Xie1;~Wei_Feng1;~Yang_Liu36,6;4;4;5,4;3;4;4,Withdrawn,0,0,,yes,9/28/20,"Nanyang Technological University;Alibaba Group, USA;Nanyang Technological University;University of Alberta;Kyushu University;Tianjin University;Nanyang Technological University",adversarial training;activation function;spatially attentive activation;,44;-1;44;110;-1;-1;44,47;-1;47;131;452;496;47,m;m,asia,sg,n,8;4
8308,ICLR,2021,Sample Balancing for Improving Generalization under Distribution Shifts,Xingxuan Zhang;Peng Cui;Renzhe Xu;Yue He;Linjun Zhou;Zheyan Shen,~Xingxuan_Zhang1;~Peng_Cui1;~Renzhe_Xu1;~Yue_He2;~Linjun_Zhou1;~Zheyan_Shen1,4;3;3;6,5;5;5;3,Withdrawn,0,1,,yes,9/28/20,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",Image classification;distribution shift;,4;4;4;4;4;4,20;20;20;20;20;20,m;m,asia,cn,n,1
8309,ICLR,2021,On the Benefits of Early Fusion in Multimodal Representation Learning,Sabera J Talukder;George Barnum;Yisong Yue,~Sabera_J_Talukder1;~George_Barnum1;~Yisong_Yue1,4;4;3;4,4;4;5;3,Withdrawn,0,1,,yes,9/28/20,California Institute of Technology;California Institute of Technology;California Institute of Technology,Multimodal Learning;Representations;Noise;Audio;Visual;Fusion;Biologically Inspired;,150;150;150,4;4;4,f;m,usa,usa,n,
8310,ICLR,2021,Robustness via Probabilistic Cross-Task Ensembles,Teresa Yeo;Oguzhan Fatih Kar;Amir Zamir,~Teresa_Yeo1;~Oguzhan_Fatih_Kar1;~Amir_Zamir1,3;3;9;5,5;4;4;2,Withdrawn,0,0,,yes,9/28/20,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Robustness;distribution shift;ensembling;uncertainty estimation;,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n,
8311,ICLR,2021,Improved Techniques for Model Inversion Attacks,Si Chen;Ruoxi Jia;Guo-Jun Qi,~Si_Chen5;~Ruoxi_Jia1;~Guo-Jun_Qi1,4;4;5;6,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,Virginia Tech;Virginia Tech;University of Central Florida,,64;64;71,-1;-1;633,f;m,usa,usa,n,5;4
8312,ICLR,2021,Incremental Learning on Growing Graphs,Yutong Feng;Jianwen Jiang;Yue Gao,~Yutong_Feng2;~Jianwen_Jiang2;~Yue_Gao4,4;5;7;3,3;3;4;5,Withdrawn,0,0,,yes,9/28/20,"Tsinghua University, Tsinghua University;Alibaba Group;Tsinghua University, Tsinghua University",Graph Learning;Incremental Learning;Growing Graph;Dynamic Graph;,4;-1;4,20;-1;20,m;m,NAN,NAN,y,8;10
8313,ICLR,2021,Contrast to Divide: self-supervised pre-training for learning with noisy labels,Evgenii Zheltonozhskii;Chaim Baskin;Avi Mendelson;Alex M. Bronstein;Or Litany,~Evgenii_Zheltonozhskii1;~Chaim_Baskin1;~Avi_Mendelson1;~Alex_M._Bronstein1;~Or_Litany1,4;4;5;5,3;4;4;4,Withdrawn,0,0,,yes,9/28/20,"Technion;Technion, Technion;;;NVIDIA",noisy labels;self-supervised learning;semi-supervised learning;label noise;,29;29;-1;-1;-1,408;-1;-1;-1;-1,m;m,NAN,NAN,n,
8314,ICLR,2021,Dual Adversarial Training for Unsupervised Domain Adaptation,Yuan Wu;Diana Inkpen;Ahmed El-Roby,~Yuan_Wu2;~Diana_Inkpen1;~Ahmed_El-Roby1,3;2;5;3,5;5;5;5,Withdrawn,0,9,,yes,9/28/20,Carleton University;University of Ottawa;Carleton University,Domain Adaptation;Class-Invariant Features;Adversarial Learning;,209;263;209,588;145;588,m;m,canada,ca,n,4
8315,ICLR,2021,AETree: Areal Spatial Data Generation,Congcong Wen;Wenyu Han;Hang Zhao;Chen Feng,cw3437@nyu.edu;wenyuhan@nyu.edu;~Hang_Zhao1;~Chen_Feng2,3;5;5;2,5;4;3;5,Withdrawn,0,0,,yes,9/28/20,"Chinese Academy of Sciences;New York University;Tsinghua University, Tsinghua University;New York University",content generation;spatial data representation;tree-based network;,34;23;4;23,-1;26;20;26,m;m,usa,usa,n,
8316,ICLR,2021,HyperReal:  Complex-Valued Layer Functions For Complex-Valued Scaling Invariance,Utkarsh Singhal;Yifei Xing;Stella Yu,~Utkarsh_Singhal1;xingyifei2016@berkley.edu;~Stella_Yu2,5;5;5,3;4;3,Withdrawn,0,0,,yes,9/28/20,University of California Berkeley;;;University of California Berkeley,Complex Deep Learning;Invariance;Equivariance;Manifold;SAR Imaging;,-1;-1;-1;-1,7;-1;-1;7,m;f,usa,usa,y,1
8317,ICLR,2021,Generating universal language adversarial examples by understanding and enhancing the transferability across neural models,Liping Yuan;Xiaoqing Zheng;Yi Zhou;Cho-Jui Hsieh;Kai-Wei Chang;Xuanjing Huang,~Liping_Yuan1;~Xiaoqing_Zheng1;~Yi_Zhou11;~Cho-Jui_Hsieh1;~Kai-Wei_Chang1;~Xuanjing_Huang1,3;4;5;3,3;5;2;3,Withdrawn,0,0,,yes,9/28/20,Fudan University;;Fudan University;Fudan University;Amazon;University of California-Los Angeles;Fudan University,,71;-1;71;71;-1;-1;71,70;-1;70;70;-1;15;70,m;u,asia,cn,n,4
8318,ICLR,2021,Dual Contradistinctive Generative Autoencoder,Gaurav Parmar;Dacheng Li;Kwonjoon Lee;Zhuowen Tu,~Gaurav_Parmar1;~Dacheng_Li1;~Kwonjoon_Lee1;~Zhuowen_Tu1,3;5;6;5,4;5;4;4,Withdrawn,0,4,,yes,9/28/20,"Carnegie Mellon University;University of California, San Diego;University of California, San Diego;University of California, San Diego",,1;-1;-1;-1,28;33;33;33,m;m,usa,usa,y,2;5;4
8319,ICLR,2021,Noisy Differentiable Architecture Search,Xiangxiang Chu;Bo Zhang,~Xiangxiang_Chu1;~Bo_Zhang7,5;5;5;2,4;4;3;5,Withdrawn,0,4,,yes,9/28/20,MeiTuan;Meituan Inc.,neural architecture search;stabilize DARTS;noise injection;,-1;-1,-1;-1,m;m,NAN,NAN,n,1
8320,ICLR,2021,Batch Normalization Increases Adversarial Vulnerability: Disentangling Usefulness and Robustness of Model Features,Philipp Benz;Chaoning Zhang;In So Kweon,~Philipp_Benz1;~Chaoning_Zhang1;~In_So_Kweon2,4;4;5;6,4;4;5;4,Withdrawn,0,0,,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,batch normalization;adversarial robustness;feature perspective;,-1;-1;-1,96;96;96,m;m,NAN,NAN,n,4
8321,ICLR,2021,ADD-Defense: Towards Defending Widespread Adversarial Examples via Perturbation-Invariant Representation,Dawei Zhou;Tongliang Liu;Bo Han;Nannan Wang;Xinbo Gao,~Dawei_Zhou3;~Tongliang_Liu1;~Bo_Han1;~Nannan_Wang1;~Xinbo_Gao3,7;2;3;6,5;5;5;4,Withdrawn,0,0,,yes,9/28/20,Xidian University;University of Sydney;HKBU;Xidian University;Xidian University,defense framework;widespread adversarial examples;perturbation-invariant representation;adversarial learning;,-1;71;-1;-1;-1,924;51;-1;924;924,m;m,asia,cn,y,4
8322,ICLR,2021,PANDA - Adapting Pretrained Features for Anomaly Detection,Tal Reiss;Niv Cohen;Liron Bergman;Yedid Hoshen,tal.reiss@mail.huji.ac.il;~Niv_Cohen1;~Liron_Bergman1;~Yedid_Hoshen3,7;4;5;4,4;4;3;3,Withdrawn,0,5,,yes,9/28/20,"Hebrew University of Jerusalem;Hebrew University of Jerusalem, Technion;Hebrew University of Jerusalem;Hebrew University of Jerusalem",anomaly detection;,85;29;85;85,235;235;235;235,m;m,europe,il,n,
8323,ICLR,2021,Rethinking Graph Neural Networks for Graph Coloring,Wei Li;Ruxuan Li;Yuzhe Ma;Siu On Chan;Bei Yu,~Wei_Li35;1155124615@link.cuhk.edu.hk;~Yuzhe_Ma2;~Siu_On_Chan1;~Bei_Yu2,5;6;3;2,3;3;4;5,Withdrawn,0,0,,yes,9/28/20,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;Chinese University of Hong Kong;The Chinese University of Hong Kong,graph neural networks;graph coloring;combinational problem;,327;327;327;46;327,39;39;39;56;39,f;m,NAN,NAN,y,1;10
8324,ICLR,2021,Toward Synergism in Macro Action Ensembles,Yu Ming Chen;Kuan-Yu Chang;Chien Liu;Tsu-Ching Hsiao;Zhang-Wei Hong;Chun-Yi Lee,~Yu_Ming_Chen1;~Kuan-Yu_Chang1;~Chien_Liu1;~Tsu-Ching_Hsiao1;~Zhang-Wei_Hong1;~Chun-Yi_Lee1,4;4;4;4,4;5;5;4,Withdrawn,0,0,,yes,9/28/20,"National Tsing Hua University;Department of Computer Science, National Tsing Hua University, National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Massachusetts Institute of Technology;National Tsing Hua University",Automated machine Learning;Reinforcement learning;Macro action ensemble;,209;209;209;209;5;209,365;365;365;365;4;365,m;m,asia,tw,n,
8325,ICLR,2021,Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER,Markus Holzleitner;Lukas Gruber;Jose Arjona-Medina;Johannes Brandstetter;Sepp Hochreiter,~Markus_Holzleitner1;~Lukas_Gruber2;~Jose_Arjona-Medina1;~Johannes_Brandstetter1;~Sepp_Hochreiter1,5;4;4;4,4;3;3;4,Withdrawn,0,1,,yes,9/28/20,Johannes Kepler University Linz;Johannes Kepler University Linz;Institute for Machine Learning;Johannes Kepler University Linz;Johannes Kepler University Linz,reinforcement learning;actor critic algorithms;policy gradient methods;stochastic approximation;PPO;RUDDER;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y,1
8326,ICLR,2021,Generating Unobserved Alternatives: A Case Study through Super-Resolution and Decompression,Shichong Peng;Ke Li,~Shichong_Peng1;~Ke_Li1,4;5;4,3;4;4,Withdrawn,0,6,,yes,9/28/20,Simon Fraser University;Simon Fraser University,one-to-many prediction;generative models;,58;58,271;271,m;m,canada,ca,n,5
8327,ICLR,2021,EnTranNAS: Towards Closing the Gap between the Architectures in Search and Evaluation,Yibo Yang;Shan You;Hongyang Li;Fei Wang;Chen Qian;Zhouchen Lin,~Yibo_Yang2;~Shan_You3;~Hongyang_Li2;~Fei_Wang9;~Chen_Qian1;~Zhouchen_Lin1,4;4;6;7,5;5;4;4,Withdrawn,0,7,,yes,9/28/20,Peking University;Tsinghua University;Peking University;Sensetime;The SenseTime Research;Peking University,,14;4;14;-1;-1;14,23;20;23;-1;-1;23,m;m,asia,cn,n,
8328,ICLR,2021,"Understanding, Analyzing, and Optimizing the Complexity of Deep Models",Jie Ren;Mingjie Li;Meng Zhou;Shih-Han Chan;Zexu Liu;Quanshi Zhang,~Jie_Ren1;~Mingjie_Li3;~Meng_Zhou2;~Shih-Han_Chan1;~Zexu_Liu2;~Quanshi_Zhang1,4;5;8;5,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,,29;29;29;29;29;29,100;100;100;100;100;100,f;m,asia,cn,y,1
8329,ICLR,2021,"Disentanglement, Visualization and Analysis of Complex Features in DNNs",Jie Ren;Mingjie Li;Zexu Liu;Quanshi Zhang,~Jie_Ren1;~Mingjie_Li3;~Zexu_Liu2;~Quanshi_Zhang1,4;3;6;3,4;3;4;2,Withdrawn,0,0,,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Interpretability;,29;29;29;29,100;100;100;100,f;m,asia,cn,n,
8330,ICLR,2021,BLANK,Soumya Banerjee;Vinay P Namboodiri,~Soumya_Banerjee1;~Vinay_P_Namboodiri1,3;3;7;3,5;5;4;4,Withdrawn,0,0,,yes,9/28/20,"IIT Kanpur, IIT Kanpur;IIT Kanpur,",BLANK;,128;128,-1;-1,m;m,asia,in,pdf miss,
8331,ICLR,2021,Improving Calibration for Long-Tailed Recognition,Zhisheng Zhong;Jiequan Cui;Shu Liu;Jiaya Jia,~Zhisheng_Zhong1;~Jiequan_Cui1;~Shu_Liu4;~Jiaya_Jia1,6;4;6,3;4;4,Withdrawn,0,3,,yes,9/28/20,Peking University;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,long tailed recognition;network calibration;label-aware smoothing;mixup;dataset bias;,14;327;327;327,23;39;39;39,m;m,NAN,NAN,n,
8332,ICLR,2021,Boltzman Tuning of Generative Models,Victor Berger;Michele Sebag,~Victor_Berger1;~Michele_Sebag1,4;3;4,4;3;4,Withdrawn,0,1,,yes,9/28/20,"INRIA;CNRS, Universit√© Paris-Saclay",generative models;variational inference;,-1;-1,-1;-1,m;f,NAN,NAN,n,5
8333,ICLR,2021,Embedding semantic relationships in hidden representations via label smoothing,Michael Marino;Pascal Nieters;Gunther Heidemann;Joachim Hertzberg,~Michael_Marino1;pnieters@uos.de;gunther.heidemann@uos.de;~Joachim_Hertzberg1,4;2;3;5,2;5;5;4,Withdrawn,0,0,,yes,9/28/20,Universit√§t Osnabr√ºck;University of Osnabr√ºck;;;University of Osnabr√ºck,deep learning;hierarchical modeling;neural network analysis;,-1;327;-1;-1;327,-1;-1;-1;-1;-1,m;m,europe,de,n,2
8334,ICLR,2021,Deep Denoising for Scientific Discovery: A Case Study in Electron Microscopy,Sreyas Mohan;Ram√≥n Manzorro;Joshua Vincent;Binh Tang;Dev Yashpal Sheth;Eero Peter Simoncelli;David S. Matteson;Peter Crozier;Carlos Fernandez-Granda,~Sreyas_Mohan1;ramon.manzorro@uca.es;joshua.vincent@asu.edu;~Binh_Tang1;cs17b106@cse.iitm.ac.in;~Eero_Peter_Simoncelli1;~David_S._Matteson1;~Peter_Crozier1;~Carlos_Fernandez-Granda1,2;4;5;3,3;4;4;5,Withdrawn,0,0,,yes,9/28/20,New York University;;;Arizona State University;Cornell University;Indian Institute of Technology Madras;New York University;Cornell University;Arizona State University;New York University,denoising;image processing;deep learning;applications;scientific discovery;microscopy;material science;,23;-1;-1;85;7;-1;23;7;85;23,26;-1;-1;182;19;-1;26;19;182;26,m;m,usa,usa,n,1
8335,ICLR,2021,Learning to Recover from Failures using Memory,Tao Chen;Pulkit Agrawal,~Tao_Chen1;~Pulkit_Agrawal1,4;4;4;4,3;4;4;3,Withdrawn,0,0,,yes,9/28/20,Massachusetts Institute of Technology;Massachusetts Institute of Technology,memory;meta learning;learn from failures;,5;5,4;4,m;m,usa,usa,n,6
8336,ICLR,2021,Novelty Detection with Rotated Contrastive Predictive Coding,Dong Huk Park;Trevor Darrell,~Dong_Huk_Park2;~Trevor_Darrell2,4;3;6,4;5;4,Withdrawn,0,0,,yes,9/28/20,University of California Berkeley;Electrical Engineering & Computer Science Department,,-1;-1,7;-1,m;m,NAN,NAN,n,
8337,ICLR,2021,OT-LLP: Optimal Transport for Learning from Label Proportions,Jiabin Liu;Hanyuan Hang;Bo Wang;Xin Shen;Zhouchen Lin,~Jiabin_Liu1;~Hanyuan_Hang1;~Bo_Wang14;~Xin_Shen2;~Zhouchen_Lin1,5;5;4;5,4;3;3;3,Withdrawn,0,1,,yes,9/28/20,Samsung;University of Twente;University of International Business and Economics;The Chinese University of Hong Kong;Peking University,Learning from label proportions;Optimal transport;Weakly supervised learning;Classification;,-1;150;-1;327;14,-1;242;730;39;23,m;m,asia,cn,y,
8338,ICLR,2021,Using MMD GANs to correct physics models and improve Bayesian parameter estimation,Jonathan Doucette;Christian Kames;Alexander Rauscher,~Jonathan_Doucette1;~Christian_Kames1;~Alexander_Rauscher1,4;3;4;4,4;3;3;3,Withdrawn,0,0,,yes,9/28/20,University of British Columbia;University of British Columbia;University of British Columbia,deep learning;GANs;MMD GANs;bayesian learning;bayesian inference;,58;58;58,34;34;34,m;m,canada,ca,n,11;5;4
8339,ICLR,2021,Rapid Neural Pruning for Novel Datasets with Set-based Task-Adaptive Meta-Pruning,Minyoung Song;Jaehong Yoon;Eunho Yang;Sung Ju Hwang,~Minyoung_Song1;~Jaehong_Yoon1;~Eunho_Yang1;~Sung_Ju_Hwang1,5;4;5,4;4;2,Withdrawn,0,3,,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science and Technology,Network pruning;meta learning;set representation;,-1;-1;-1;-1,96;96;-1;96,f;m,NAN,NAN,n,
8340,ICLR,2021,Refine and Imitate: Reducing Repetition and Inconsistency in Dialogue Generation via Reinforcement Learning and Human Demonstration,Weiyan Shi;Yu Li;Saurav Sahay;Zhou Yu,~Weiyan_Shi2;~Yu_Li6;~Saurav_Sahay1;~Zhou_Yu1,3;6;4,4;4;4,Withdrawn,0,1,,yes,9/28/20,"Columbia University;University of California, Davis;Intel;University of California, Davis",Dialogue System;Persuasion;Conversation;,23;-1;-1;-1,17;64;-1;64,f;f,usa,usa,n,3
8341,ICLR,2021,Exploring Sub-Pseudo Labels for Learning from Weakly-Labeled Web Videos,Kunpeng Li;Zizhao Zhang;Guanhang Wu;Xuehan Xiong;Chen-Yu Lee;Yun Fu;Tomas Pfister,~Kunpeng_Li1;~Zizhao_Zhang3;~Guanhang_Wu1;~Xuehan_Xiong1;~Chen-Yu_Lee2;~Yun_Fu1;~Tomas_Pfister1,5;4;5,4;4;5,Withdrawn,0,3,,yes,9/28/20,Northeastern University;Google;;Google;Google;Northeastern University;Google,Learning from web data;video action recognition;network pre-training;,16;-1;-1;-1;-1;16;-1,895;-1;-1;-1;-1;895;-1,m;m,NAN,NAN,n,1
8342,ICLR,2021,MASP: Model-Agnostic Sample Propagation for Few-shot learning,Lu Liu;Tianyi Zhou;Guodong Long;Jing Jiang;Xuanyi Dong;Chengqi Zhang,~Lu_Liu7;~Tianyi_Zhou1;~Guodong_Long2;~Jing_Jiang6;~Xuanyi_Dong1;~Chengqi_Zhang1,3;4;5;3,5;5;4;4,Withdrawn,0,4,,yes,9/28/20,University of Technology Sydney;University of Washington;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,few-shot learning;sample propagation;feature calibration;outlier removal;noisy label;,71;11;71;71;71;71,160;29;160;160;160;160,f;m,australasia,au,n,6;8;10
8343,ICLR,2021,Self-supervised Bayesian Deep Learning for Image Denoising,Tongyao Pang;Yuhui Quan;Hui Ji,~Tongyao_Pang1;~Yuhui_Quan5;~Hui_Ji1,6;6;6;3,5;3;5;5,Withdrawn,0,0,,yes,9/28/20,National University of Singapore;South China University of Technology;National University of Singapore,Self-supervised Learning;Bayesian Inference;Image Denoising;,17;-1;17,25;411;25,u;m,asia,sg,n,11
8344,ICLR,2021,Representation Quality Of Neural Networks Links To Adversarial Attacks and Defences,Shashank Kotyan;Moe Matsuki;Danilo Vasconcellos Vargas,~Shashank_Kotyan1;matsuki.sousisu@gmail.com;~Danilo_Vasconcellos_Vargas1,4;4;3;4,3;3;4;4,Withdrawn,0,1,,yes,9/28/20,Kyushu University;;;Kyushu University,Understanding Neural Networks;Representation Metrics;Adversarial Machine Learning;Adversarial Attacks;Adversarial Defences;,-1;-1;-1;-1,452;-1;-1;452,m;m,NAN,NAN,n,6;4
8345,ICLR,2021,Explicit Learning Topology for Differentiable Neural Architecture Search,Tao Huang;Shan You;Yibo Yang;Zhuozhuo Tu;Fei Wang;Chen Qian;Changshui Zhang,~Tao_Huang5;~Shan_You3;~Yibo_Yang2;~Zhuozhuo_Tu1;~Fei_Wang9;~Chen_Qian1;~Changshui_Zhang1,4;4;5;5,5;5;4;3,Withdrawn,0,4,,yes,9/28/20,SenseTime;Tsinghua University;Peking University;The University of Sydney;Sensetime;The SenseTime Research;Tsinghua University,,-1;4;14;71;-1;-1;4,-1;20;23;51;-1;-1;20,m;m,asia,cn,n,
8346,ICLR,2021,Stabilizing DARTS with Amended Gradient Estimation on Architectural Parameters,Kaifeng Bi;Lingxi Xie;Changping Hu;Xin Chen;Longhui Wei;Qi Tian,bikaifeng1@huawei.com;~Lingxi_Xie1;hcp06@mails.tsinghua.edu.cn;chenxin180@huawei.com;~Longhui_Wei1;~Qi_Tian3,6;4;5;4,4;4;3;5,Withdrawn,0,0,,yes,9/28/20,Huawei Technologies Ltd.;;;;;Huawei Technologies Ltd.,Neural Architecture Search;DARTS;Gradient Estimation;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,
8347,ICLR,2021,"GOLD-NAS: Gradual, One-Level, Differentiable",Kaifeng Bi;Lingxi Xie;Xin Chen;Longhui Wei;Qi Tian,bikaifeng1@huawei.com;~Lingxi_Xie1;chenxin180@huawei.com;~Longhui_Wei1;~Qi_Tian3,5;4;5;6,5;4;5;4,Withdrawn,0,0,,yes,9/28/20,Huawei Technologies Ltd.;;;;Huawei Technologies Ltd.,Neural Architecture Search;GOLD-NAS;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,1
8348,ICLR,2021,A Simple Framework for Uncertainty in Contrastive Learning,Mike Wu;Noah Goodman,~Mike_Wu1;~Noah_Goodman1,4;5;3;5,4;3;3;5,Withdrawn,0,0,,yes,9/28/20,Stanford University;Stanford University,uncertainty;contrastive learning;unsupervised learning;anomaly detection;out of distribution;corruption;,5;5,2;2,m;m,usa,usa,n,5
8349,ICLR,2021,Learning Task-Relevant Features via Contrastive Input Morphing,Saeid Asgari;Kristy Choi;Amir Hosein Khasahmadi;Anirudh Goyal,~Saeid_Asgari1;~Kristy_Choi1;~Amir_Hosein_Khasahmadi1;~Anirudh_Goyal1,5;5;4;4,4;5;4;5,Withdrawn,0,1,,yes,9/28/20,"Autodesk;Computer Science Department, Stanford University;Autodesk;University of Montreal",representation learning;spurious correlations;deep learning;,-1;5;-1;128,-1;2;-1;73,m;m,canada,ca,n,
8350,ICLR,2021,Text as Neural Operator: Image Manipulation by Text Instruction,Tianhao Zhang;Hung-Yu Tseng;Lu Jiang;Honglak Lee;Irfan Essa;Weilong Yang,~Tianhao_Zhang2;~Hung-Yu_Tseng2;~Lu_Jiang1;~Honglak_Lee2;~Irfan_Essa1;~Weilong_Yang1,6;6;4,4;4;5,Withdrawn,0,0,,yes,9/28/20,"Nanjing University;University of California, Merced;Carnegie Mellon University;LG AI Research;Georgia Institute of Technology;Google",Image Manipulation;Generative Adversarial Networks;,52;-1;1;-1;12;-1,111;336;28;-1;38;-1,m;m,NAN,NAN,n,8;3;5
8351,ICLR,2021,Weakly-Supervised Amodal Instance Segmentation with Compositional Priors,Yihong Sun;Adam Kortylewski;Alan Yuille,~Yihong_Sun1;~Adam_Kortylewski1;~Alan_Yuille1,4;5;5;6;5,4;3;4;2;4,Withdrawn,0,0,,yes,9/28/20,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,Amodal perception;deep learning;segmentation;partial occlusion;,71;71;71,12;12;12,m;m,usa,usa,n,2
8352,ICLR,2021,Big GANs Are Watching You: Towards Unsupervised Object Segmentation with Off-the-Shelf Generative Models,Andrey Voynov;Stanislav Morozov;Artem Babenko,~Andrey_Voynov1;~Stanislav_Morozov1;~Artem_Babenko1,5;5;6;4,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Yandex;Yandex;Yandex,GAN;segmentation;unsupervised;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,2;5
8353,ICLR,2021,Lightweight Long-Range Generative Adversarial Networks,Bowen Li;Thomas Lukasiewicz,~Bowen_Li2;~Thomas_Lukasiewicz2,3;5;6;4;5,5;4;3;4;5,Withdrawn,0,5,,yes,9/28/20,"Department of Computer Science, University of Oxford;Department of Computer Science, University of Oxford",Generative Adversarial Networks;Lightweight;Long-Range Dependency;,46;46,1;1,m;m,NAN,NAN,n,5;4
8354,ICLR,2021,Improving Machine Translation by Searching Skip Connections Efficiently,Chen Yang;Houfeng Wang,~Chen_Yang2;~Houfeng_Wang1,4;3;6;7,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,"Peking University, Tsinghua University;Peking University",network morphism;machine translation;neural architecture search;,4;14,20;23,m;m,asia,cn,n,8;3
8355,ICLR,2021,About contrastive unsupervised representation learning for classification and its convergence,Ibrahim Merad;Yiyang Yu;Emmanuel Bacry;St√©phane Ga√Øffas,~Ibrahim_Merad1;~Yiyang_Yu1;~Emmanuel_Bacry1;~St√©phane_Ga√Øffas1,6;4;5;3,2;3;3;5,Withdrawn,0,0,,yes,9/28/20,"Universit√© de Paris;LPSM, Universit√© de Paris;Univerist√© Paris-Dauphine;Ecole normale sup√©rieure",Theoretical guarantees;Unsupervised learning;Contrastive learning;Overparametrized models;,-1;-1;-1;-1,136;136;-1;-1,m;f,NAN,NAN,y,
8356,ICLR,2021,Lyapunov Barrier Policy Optimization,Harshit Sikchi;Wenxuan Zhou;David Held,~Harshit_Sikchi1;~Wenxuan_Zhou1;~David_Held1,4;6;4;4,4;3;4;5,Withdrawn,0,0,,yes,9/28/20,"School of Computer Science, Carnegie Mellon University;DeepMind;Carnegie Mellon University",Safe Reinforcement Learning;Deep Reinforcement Learning;,1;-1;1,28;-1;28,m;m,usa,usa,n,
8357,ICLR,2021,Analysing Features Learned Using Unsupervised Models on Program Embeddings,Martina Saletta;Claudio Ferretti,~Martina_Saletta1;claudio.ferretti@unimib.it,5;2;4;3,3;4;5;4,Withdrawn,0,1,,yes,9/28/20,University of Milan-Bicocca;University of Milan-Bicocca,Source code embedding;Unsupervised learning;,-1;-1,396;396,f;m,NAN,NAN,n,
8358,ICLR,2021,An Automated Domain Understanding Technique for Knowledge Graph Generation,Dimitrios Christofidellis;Matteo Manica;Leonidas Georgopoulos;Hans Vandierendonck,~Dimitrios_Christofidellis1;~Matteo_Manica1;leg@zurich.ibm.com;h.vandierendonck@qub.ac.uk,3;4;3,4;3;4,Withdrawn,0,0,,yes,9/28/20,Queen's University Belfast;;;Queen's University Belfast,Knowledge Graphs;Graph Inference;Transformers;NLP;Wisdom of Crowds;Attention Mechanism;,263;-1;-1;263,199;-1;-1;199,m;m,europe,uk,n,8;10
8359,ICLR,2021,Artificial GAN Fingerprints: Rooting Deepfake Attribution in Training Data,Ning Yu;Vladislav Skripniuk;Sahar Abdelnabi;Mario Fritz,~Ning_Yu2;vladislav@mpi-inf.mpg.de;~Sahar_Abdelnabi1;~Mario_Fritz1,4;3;6,3;4;4,Withdrawn,0,0,,yes,9/28/20,"Saarland Informatics Campus, Max-Planck Institute;Saarland Informatics Campus, Max-Planck Institute;CISPA, saarland university, saarland informatics campus;CISPA Helmholtz Center for Information Security",,-1;-1;-1;99,-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
8360,ICLR,2021,Semi-Supervised Speech-Language Joint Pre-Training for Spoken Language Understanding,Yu-An Chung;Chenguang Zhu;Michael Zeng,~Yu-An_Chung1;~Chenguang_Zhu1;~Michael_Zeng1,4;5;5,4;4;3,Withdrawn,0,0,,yes,9/28/20,Massachusetts Institute of Technology;;Microsoft,joint pre-training;multimodal representation learning;spoken language understanding;speech representation learning;,5;-1;-1,4;-1;-1,m;m,NAN,NAN,n,3
8361,ICLR,2021,AggMask: Exploring locally aggregated learning of mask representations for instance segmentation,Tao Wang;Jun Hao Liew;Yu Li;Yunpeng Chen;Jiashi Feng,~Tao_Wang3;~Jun_Hao_Liew1;~Yu_Li7;~Yunpeng_Chen1;~Jiashi_Feng1,4;4;6;6,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,"National University of Singapore;ByteDance;Institute of Computing Technology, Chinese Academy of Sciences;YiTu Technology co. ltd;National University of Singapore",,17;-1;34;-1;17,25;-1;-1;-1;25,m;m,asia,sg,n,2
8362,ICLR,2021,Learning Invariant Representations and Risks for Semi-supervised Domain Adaptation,Bo Li;Yezhen Wang;Shanghang Zhang;Dongsheng Li;Trevor Darrell;Kurt Keutzer;Han Zhao,~Bo_Li23;~Yezhen_Wang1;~Shanghang_Zhang4;~Dongsheng_Li2;~Trevor_Darrell2;~Kurt_Keutzer2;~Han_Zhao1,4;5;4;4,4;4;5;5,Withdrawn,0,7,,yes,9/28/20,"University of California Berkeley;University of California, San Diego;University of California Berkeley;Microsoft Research Asia;Electrical Engineering & Computer Science Department;University of California-Berkeley;University of Illinois, Urbana Champaign",Semi-supervised Domain Adaptation;,-1;-1;-1;-1;-1;-1;-1,7;33;7;-1;-1;7;-1,f;m,usa,usa,n,1
8363,ICLR,2021,Effective Training of Sparse Neural Networks under Global Sparsity Constraint,Xiao Zhou;Weizhong Zhang;Tong Zhang,~Xiao_Zhou4;~Weizhong_Zhang1;~Tong_Zhang2,4;5;5;5,5;4;5;4,Withdrawn,0,5,,yes,9/28/20,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Google,,-1;-1;-1,56;56;-1,m;m,NAN,NAN,y,
8364,ICLR,2021,RoeNets: Predicting Discontinuity of Hyperbolic Systems from Continuous Data,Shiying Xiong;Xingzhe He;Shuqi Yang;Yunjin Tong;Runze Liu;Bo Zhu,~Shiying_Xiong1;~Xingzhe_He1;~Shuqi_Yang2;yunjin.tong.22@dartmouth.edu;runze.liu.20@dartmouth.edu;~Bo_Zhu2,4;5;3,4;2;2,Withdrawn,0,0,,yes,9/28/20,Dartmouth College;University of British Columbia;Dartmouth College;Dartmouth College;;;Dartmouth College,Data-driving modeling;neural PDE;hyperbolic dynamic system;,174;58;174;174;-1;-1;174,100;34;100;100;-1;-1;100,m;m,usa,usa,n,
8365,ICLR,2021,VortexNet: Learning Complex Dynamic Systems with Physics-Embedded Networks,Shiying Xiong;Xingzhe He;Yunjin Tong;Yitong Deng;Bo Zhu,~Shiying_Xiong1;~Xingzhe_He1;yunjin.tong.22@dartmouth.edu;yitong.deng.gr@dartmouth.edu;~Bo_Zhu2,5;4;4;4,3;5;4;3,Withdrawn,0,0,,yes,9/28/20,Dartmouth College;University of British Columbia;Dartmouth College;;;Dartmouth College,,174;58;174;-1;-1;174,100;34;100;-1;-1;100,m;m,usa,usa,n,
8366,ICLR,2021,Out-of-Distribution Generalization with Maximal Invariant Predictor,Masanori Koyama;Shoichiro Yamaguchi,~Masanori_Koyama1;~Shoichiro_Yamaguchi1,5;3;4;5,3;4;3;2,Withdrawn,0,1,,yes,9/28/20,"Preferred Networks, Inc.;Preferred Networks, Inc.",out-of-distribution generalization;extrapolation;,-1;-1,-1;-1,m;m,NAN,NAN,n,1
8367,ICLR,2021,Adaptive Gradient Method with Resilience and Momentum,Jie Liu;Chen Lin;Chuming Li;Lu Sheng;Ming Sun;Junjie Yan;Wanli Ouyang,~Jie_Liu13;~Chen_Lin2;~Chuming_Li1;~Lu_Sheng1;~Ming_Sun4;~Junjie_Yan4;~Wanli_Ouyang1,5;4;4;5;5,3;2;4;3;5,Withdrawn,0,0,,yes,9/28/20,"Beihang University;University of Oxford, University of Oxford;University of Electronic Science and Technology of China;Beihang University;Nankai University;SenseTime Group Limited;University of Sydney",,99;46;-1;99;-1;-1;71,567;1;553;567;358;-1;51,f;m,europe,uk,y,1
8368,ICLR,2021,Exploring Target Driven Image Classification,Aditya Singh;Alessandro Bay;Andrea Mirabile,~Aditya_Singh3;~Alessandro_Bay1;andrea.mirabile@zebra.com,5;2;5;4;4,4;4;4;3;4,Withdrawn,0,7,,yes,9/28/20,Zebra Technologies;Zebra Technologies;Zebra technologies,Image classification;computer vision;deep learning;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
8369,ICLR,2021,Fast and Differentiable Matrix Inverse and Its Extension to SVD,Xingyu Xie;Hao Kong;Jianlong Wu;Guangcan Liu;Zhouchen Lin,~Xingyu_Xie1;konghao@pku.edu.cn;~Jianlong_Wu1;~Guangcan_Liu3;~Zhouchen_Lin1,5;3;6;5,3;4;3;3,Withdrawn,0,0,,yes,9/28/20,"Peking University;Peking University, Tsinghua University;Shandong University;;Peking University",learning-based optimization;learning-based iterative method;differentiable matrix inverse;differentiable singular value decomposition;convergence;generalization;,14;4;150;-1;14,23;20;627;-1;23,m;m,asia,cn,y,1
8370,ICLR,2021,Perceptual Deep Neural Networks: Adversarial Robustness Through Input Recreation,Danilo Vasconcellos Vargas;Bingli Liao;Takahiro Kanzaki,~Danilo_Vasconcellos_Vargas1;liao.bingli.734@s.kyushu-u.ac.jp;kanzaki.takahiro.491@s.kyushu-u.ac.jp,5;6;5,4;5;3,Withdrawn,0,6,,yes,9/28/20,"Kyushu University;Kyushu University, Tokyo Institute of Technology;Kyushu University",Adversarial Machine Learning;Perception;Adversarial Training;Bioinspired Architectures;Filling-in;Blind-spot;Deep Neural Networks;Robust Deep Neural Networks;,-1;174;-1,452;312;452,m;m,NAN,NAN,n,5;4
8371,ICLR,2021,Meta-Semi: A Meta-learning Approach for Semi-supervised Learning,Yulin Wang;Jiayi Guo;Shiji Song;Gao Huang,~Yulin_Wang1;~Jiayi_Guo2;~Shiji_Song1;~Gao_Huang1,4;5;5,4;3;3,Withdrawn,0,0,,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Semi-supervised learning;Meta-learning;,4;4;4;4,20;20;20;20,m;m,NAN,NAN,y,6;9
8372,ICLR,2021,Unsupervised Learning of Slow Features for Data Efficient Regression,Oliver Struckmeier;Kshitij Tiwari;Ville Kyrki,~Oliver_Struckmeier1;kshitij.tiwari@oulu.fi;ville.kyrki@aalto.fi,5;4;4;3,4;4;4;4,Withdrawn,0,6,,yes,9/28/20,Aalto University;University of Oulu;Aalto University,Representation Learning;Semi-supervised Learning;Data Efficiency;Slowness Principle;,128;-1;128,220;312;220,m;m,europe,dk,n,5
8373,ICLR,2021,A first look into the carbon footprint of federated learning,Xinchi Qiu;Titouan Parcollet;daniel j Beutel;Taner Topal;Akhil Mathur;Nicholas Donald Lane,~Xinchi_Qiu1;~Titouan_Parcollet1;daniel@adap.com;taner@adap.com;~Akhil_Mathur1;~Nicholas_Donald_Lane1,3;3;6;4,4;3;4;5,Withdrawn,0,0,,yes,9/28/20,"University of Cambridge;Avignon University;;;;;University College London;Department of Computer Science, University of Oxford",Federated Learning;carbon footprint;,79;-1;-1;-1;-1;-1;53;46,6;-1;-1;-1;-1;-1;-1;1,f;m,NAN,NAN,n,1
8374,ICLR,2021,Asynchronous Edge Learning using Cloned Knowledge Distillation,Sangho Lee;KiYoon Yoo;Nojun Kwak,~Sangho_Lee3;961230@snu.ac.kr;~Nojun_Kwak1,8;4;3,1;4;4,Withdrawn,0,0,,yes,9/28/20,Seoul National University;Seoul National University;Seoul National University,Knowledge distillation;Federated learning;,37;37;37,60;60;60,m;m,asia,kr,n,
8375,ICLR,2021,Unsupervised Word Translation Pairing using Refinement based Point Set Registration,Silviu Oprea;Sourav Dutta;Haytham Assem,silviu.oprea@ed.ac.uk;~Sourav_Dutta1;haytham.assem@huawei.com,4;4;3,5;4;5,Withdrawn,0,0,,yes,9/28/20,University of Edinburgh;;Huawei Research Center,,29;-1;-1,30;-1;-1,m;m,NAN,NAN,n,3;4
8376,ICLR,2021,Demon: Momentum Decay for Improved Neural Network Training,John Chen;Cameron Wolfe;Zhao Li;Anastasios Kyrillidis,~John_Chen3;wolfe.cameron@rice.edu;zhao.li@uth.tmc.edu;~Anastasios_Kyrillidis2,5;6;5;5,2;4;4;5,Withdrawn,0,11,,yes,9/28/20,Rice University;Rice University;UTHealth;Rice University,deep learning;large scale learning;neural networks;sgd;,92;92;-1;92,124;124;-1;124,m;m,australasia,au,n,3;5
8377,ICLR,2021,Learning to Learn with Smooth Regularization,Yuanhao Xiong;Cho-Jui Hsieh,~Yuanhao_Xiong1;~Cho-Jui_Hsieh1,4;5;6;5,4;4;1;3,Withdrawn,0,0,,yes,9/28/20,"University of California, Los Angeles;Amazon",learning to learn;neural optimizer;,-1;-1,15;-1,m;m,NAN,NAN,n,6
8378,ICLR,2021,Domain Adaptation via Anaomaly Detection,Vivek Madan;Ashish Khetan;Zohar Karnin,~Vivek_Madan2;~Ashish_Khetan1;~Zohar_Karnin1,4;5;4;4,4;3;4;5,Withdrawn,0,0,,yes,9/28/20,Georgia Institute of Technology;Amazon;Amazon,Domain Adaptation;Data Selection;,12;-1;-1,38;-1;-1,m;m,NAN,NAN,n,3
8379,ICLR,2021,"Inverse Problems, Deep Learning, and Symmetry Breaking",Kshitij Tayal;Chieh-Hsin Lai;Raunak Manekar;Zhong Zhuang;Vipin Kumar;Ju Sun,~Kshitij_Tayal1;~Chieh-Hsin_Lai1;~Raunak_Manekar1;~Zhong_Zhuang1;~Vipin_Kumar1;~Ju_Sun2,5;4;3;4,3;4;5;3,Withdrawn,0,0,,yes,9/28/20,"University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Minnesota;University of Minnesota, Twin Cities",Phase Retrieval;inverse problems;Symmetry;Deep Learning;,71;71;71;71;71;71,85;85;85;85;85;85,m;m,NAN,NAN,y,
8380,ICLR,2021,Leveraging the Variance of Return Sequences for Exploration Policy,Zerong Xi;Gita Sukthankar,~Zerong_Xi1;~Gita_Sukthankar1,2;4;5;5,5;4;4;3,Withdrawn,0,4,,yes,9/28/20,"University of Central Florida;Computer Science Department, University of Central Florida",Reinforcement Learning;Deep Reinforcement Learning;Exploration;Temporal Difference Error;Variance;,71;71,633;633,f;f,NAN,NAN,n,1
8381,ICLR,2021,Improved generalization by noise enhancement,Takashi Mori;Masahito Ueda,~Takashi_Mori1;ueda@phys.s.u-tokyo.ac.jp,4;3;4;4,5;5;4;5,Withdrawn,0,1,,yes,9/28/20,RIKEN;The University of Tokyo,deep learning;generalization;stochastic gradient descent;large-batch training;,-1;71,-1;36,m;m,NAN,NAN,n,1
8382,ICLR,2021,Example-Driven Intent Prediction with Observers,Shikib Mehri;Mihail Eric;Dilek Hakkani-Tur,~Shikib_Mehri1;~Mihail_Eric2;~Dilek_Hakkani-Tur1,5;3;5;4,4;5;3;3,Withdrawn,0,0,,yes,9/28/20,Carnegie Mellon University;Amazon;Amazon Alexa AI,dialog;intent prediction;pre-training;,1;-1;-1,28;-1;-1,m;f,NAN,NAN,n,6;8
8383,ICLR,2021,Robust Offline Reinforcement Learning from Low-Quality Data,Wenjie Shi;Tianchi Cai;Shiji Song;Lihong Gu;Jinjie Gu;Gao Huang,~Wenjie_Shi1;~Tianchi_Cai1;~Shiji_Song1;lihong.glh@antgroup.com;jinjie.gujj@antgroup.com;~Gao_Huang1,5;4;6;6;2,4;3;4;4;5,Withdrawn,0,1,,yes,9/28/20,"Electronic Engineering, Tsinghua University, Tsinghua University;Ant Group;Tsinghua University, Tsinghua University;;;Nanjing University;Tsinghua University, Tsinghua University",Offline reinforcement learning;,4;-1;4;-1;-1;52;4,20;-1;20;-1;-1;111;20,m;m,NAN,NAN,y,1
8384,ICLR,2021,Self-supervised representation learning via adaptive hard-positive mining,Shaofeng Zhang;Junchi Yan;Xiaokang Yang,~Shaofeng_Zhang1;~Junchi_Yan2;~Xiaokang_Yang1,6;7;7;7,3;4;3;4,Withdrawn,0,8,,yes,9/28/20,"Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University, China",self-supervised learning;contrastive learning;unsupervised classification;,29;29;29,100;100;100,m;m,NAN,NAN,n,8;1
8385,ICLR,2021,SemVLP: Vision-Language Pre-training by Aligning Semantics at Multiple Levels,Chenliang Li;Ming Yan;Haiyang Xu;Fuli Luo;Wei Wang;Bin Bi;Songfang Huang,~Chenliang_Li2;~Ming_Yan2;~Haiyang_Xu1;~Fuli_Luo1;~Wei_Wang41;~Bin_Bi1;~Songfang_Huang1,5;4;5;4,3;3;4;4,Withdrawn,0,0,,yes,9/28/20,"Beijing University of Post and Telecommunication, Tsinghua University;Alibaba Group;Southeast University, Tsinghua University;Alibaba Group;Alibaba Group;University of California, Los Angeles;Alibaba Group",vision-language pre-training;cross-modal representation;semantic gap;,4;-1;4;-1;-1;-1;-1,20;-1;20;-1;-1;15;-1,m;m,NAN,NAN,n,8
8386,ICLR,2021,Catching the Long Tail in Deep Neural Networks,Julio Hurtado;Alain Raymond;Alvaro Soto,~Julio_Hurtado1;~Alain_Raymond1;~Alvaro_Soto1,5;4;5,3;4;4,Withdrawn,0,0,,yes,9/28/20,Pontificia Universidad Cat√≥lica;Pontificia Universidad Cat√≥lica;Universidad Cat√≥lica de Chile,Deep Learning;Memorization;Long Tail;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,
8387,ICLR,2021,Neural Networks Preserve Invertibility Across Iterations: A Possible Source of Implicit Data Augmentation,Arushi Gupta,~Arushi_Gupta1,5;4;2;4,3;4;4;4,Withdrawn,0,0,,yes,9/28/20,"Department of Computer Science, Princeton University",,29,9,f,NAN,NAN,n,1
8388,ICLR,2021,Self-Supervised Continuous Control without Policy Gradient,Hao Sun;Ziping Xu;Meng Fang;Yuhang Song;Jiechao Xiong;Bo Dai;Zhengyou Zhang;Bolei Zhou,~Hao_Sun3;zipingxu@umich.edu;~Meng_Fang1;~Yuhang_Song1;~Jiechao_Xiong1;~Bo_Dai2;~Zhengyou_Zhang2;~Bolei_Zhou5,3;4;4;4,4;4;3;3,Withdrawn,0,0,,yes,9/28/20,"The Chinese University of Hong Kong;University of Michigan;Eindhoven University of Technology;University of Oxford;AI Lab, Tencent;Nanyang Technological University;Tencent AI Lab;The Chinese University of Hong Kong",Self-Supervised Reinforcement Learning;Continuous Control;Zeroth-Order Optimization;,327;7;-1;46;-1;44;-1;327,39;22;186;1;-1;47;-1;39,m;m,NAN,NAN,y,
8389,ICLR,2021,Leveraged Weighted Loss For Partial Label Learning,Hongwei Wen;Hanyuan Hang;Jiabin Liu;Zhouchen Lin,~Hongwei_Wen1;~Hanyuan_Hang1;~Jiabin_Liu1;~Zhouchen_Lin1,4;7;3;6,2;4;4;3,Withdrawn,0,0,,yes,9/28/20,Renmin University of China;University of Twente;Samsung;Peking University,weakly supervised learning;loss function;risk consistency;,85;150;-1;14,517;242;-1;23,m;m,asia,cn,y,1
8390,ICLR,2021,Complex neural networks have no spurious local minima,Xingtu Liu,~Xingtu_Liu1,4;4;4,4;2;3,Withdrawn,0,8,,yes,9/28/20,University of Waterloo,Deep learning;Non-convex optimization;Complex-valued neural networks;Optimization landscape;Wirtinger calculus;,34,232,m,canada,ca,y,1
8391,ICLR,2021,Dynamically locating multiple speakers based on the time-frequency domain,Hodaya Hammer;Shlomo Chazan;Jacob Goldberger;Sharon Gannot,hodib91@gmail.com;~Shlomo_Chazan1;~Jacob_Goldberger1;~Sharon_Gannot1,6;4;5;4,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,Bar Ilan University  Technion;;;Bar Ilan University  Technion,speaker localisation;microphone array;U-Net;,29;-1;-1;29,-1;-1;-1;-1,f;m,NAN,NAN,n,
8392,ICLR,2021,Learning to Disentangle Textual Representations and Attributes via Mutual Information,Pierre Colombo;Chlo√© Clavel;Pablo Piantanida,~Pierre_Colombo2;~Chlo√©_Clavel1;~Pablo_Piantanida1,4;4;4,3;3;2,Withdrawn,0,1,,yes,9/28/20,T√©l√©com ParisTech;T√©l√©com ParisTech;CNRS Universit√© Paris Saclay,NLP;Textual Style Transfer;Fair Classification;Representation Learning;,-1;-1;-1,209;209;-1,m;m,NAN,NAN,pdf miss,3;1;4
8393,ICLR,2021,Mixup Training as the Complexity Reduction,Masanari Kimura,~Masanari_Kimura2,6;4;4;6,3;4;4;3,Withdrawn,0,3,,yes,9/28/20,"SOKENDAI, Graduate University for Advanced Studies",machine learning;data augmentation;,-1,-1,m,NAN,NAN,y,1
8394,ICLR,2021,DACT-BERT: Increasing the efficiency and interpretability of BERT by using adaptive computation time.,Cristobal Eyzaguirre;Felipe del Rio;Vladimir Araujo;Alvaro Soto,~Cristobal_Eyzaguirre1;~Felipe_del_Rio1;vgaraujo@uc.cl;~Alvaro_Soto1,5;3;3,3;5;4,Withdrawn,0,0,,yes,9/28/20,Pontificia Universidad Cat√≥lica;Millennium Institute Foundational Research on Data;;;Universidad Cat√≥lica de Chile,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n,8;3
8395,ICLR,2021,Learning to Explore with Pleasure,Yean Hoon Ong;Jun Wang,~Yean_Hoon_Ong1;~Jun_Wang2,4;4;5;5,3;3;2;4,Withdrawn,0,0,,yes,9/28/20,"Department of Computer Science, University College London;University College London",exploration;curiosity-driven reinforcement learning;Bayesian optimisation;,53;53,-1;-1,f;m,europe,uk,n,11
8396,ICLR,2021,Faster Federated Learning with Decaying Number of Local SGD Steps,Jed Mills;Jia Hu;Geyong Min,~Jed_Mills1;j.hu@exeter.ac.uk;g.min@exeter.ac.uk,4;4;5,5;4;4,Withdrawn,0,0,,yes,9/28/20,University of Exeter;;University of Exeter,Distributed Machine Learning;Federated Learning;,327;-1;327,173;-1;173,m;m,europe,gr,y,1
8397,ICLR,2021,Resurrecting Submodularity for Neural Text Generation,SIMENG HAN;Xiang Lin;Shafiq Joty,~SIMENG_HAN1;~Xiang_Lin2;~Shafiq_Joty1,6;4;3;6,3;4;4;3,Withdrawn,0,0,,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;SalesForce.com,submodularity;text generation;attention;,44;44;-1,47;47;-1,f;m,NAN,NAN,n,8;1
8398,ICLR,2021,Efficient Learning of Less Biased Models with Transfer Learning,Xisen Jin;Francesco Barbieri;Leonardo Neves;Xiang Ren,~Xisen_Jin3;~Francesco_Barbieri1;~Leonardo_Neves1;~Xiang_Ren1,3;4;3;5,5;4;4;3,Withdrawn,0,1,,yes,9/28/20,University of Southern California;Snap Inc.;Carnegie Mellon University;University of Southern California,Prediction bias;bias mitigation;transfer learning;natural language processing;,37;-1;1;37,53;-1;28;53,m;m,usa,usa,n,6;8
8399,ICLR,2021,CoNES: Convex Natural Evolutionary Strategies,Sushant Veer;Anirudha Majumdar,~Sushant_Veer1;~Anirudha_Majumdar1,6;2;3,4;5;5,Withdrawn,0,7,,yes,9/28/20,Princeton University;Google,blackbox optimization;evolutionary strategies;,29;-1,9;-1,m;m,NAN,NAN,y,9
8400,ICLR,2021,Adversarial Attacks on Machine Learning Systems for High-Frequency Trading,Micah Goldblum;Avi Schwarzschild;Ankit Patel;Tom Goldstein,~Micah_Goldblum1;~Avi_Schwarzschild1;~Ankit_Patel1;~Tom_Goldstein1,3;3;4,4;4;4,Withdrawn,0,0,,yes,9/28/20,"University of Maryland, College Park;University of Maryland, College Park;Baylor College of Medicine;University of Maryland, College Park",Adversarial;robustness;trading;finance;security;,12;12;-1;12,90;90;-1;90,m;m,usa,usa,n,8;4
8401,ICLR,2021,Indirect Supervision to Mitigate Perturbations,Mayank Kumar Kundalwal;Azad Singh;Deepak Mishra,~Mayank_Kumar_Kundalwal1;singh.63@iitj.ac.in;~Deepak_Mishra5,2;4;4;3,4;4;5;4,Withdrawn,0,0,,yes,9/28/20,"Indian Institute of Technology Jodhpur, India, Dhirubhai Ambani Institute Of Information and Communication Technology;Indian Institute of Technology Jodhpur, India, Dhirubhai Ambani Institute Of Information and Communication Technology;Indian Institute of Technology Jodhpur, India",Indirect supervision;Perturbation;Downstream models;Image enhancement;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n,8;2;1;5
8402,ICLR,2021,AE-SMOTE: A Multi-Modal Minority Oversampling Framework,Sajad Darabi;Yotam Elor,~Sajad_Darabi1;yotam.elor@gmail.com,4;4;3,5;3;4,Withdrawn,0,0,,yes,9/28/20,"University of California, Los Angeles;Technion, Technion",Data Augmentation;Binary Classification;Autoencoder;Tabular Data;Imbalanced Data;,-1;29,15;-1,m;m,NAN,NAN,n,
8403,ICLR,2021,Deep Learning Proteins using a Triplet-BERT network,Mark Lennox;Neil M. Robertson;Barry Devereux,~Mark_Lennox1;~Neil_M._Robertson1;~Barry_Devereux1,3;3;3;3,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,Queen's University Belfast;Queen's University Belfast;Queen's University Belfast,Deep Learning;Transformers;Metric Learning;Proteomics;,263;263;263,199;199;199,m;m,europe,uk,n,
8404,ICLR,2021,Modelling Drug-Target Binding Affinity using a BERT based Graph Neural network,Mark Lennox;Neil M. Robertson;Barry Devereux,~Mark_Lennox1;~Neil_M._Robertson1;~Barry_Devereux1,4;4;4;3,3;4;4;4,Withdrawn,0,0,,yes,9/28/20,Queen's University Belfast;Queen's University Belfast;Queen's University Belfast,Deep Learning;Drug-Target Binding Affinity;Transformers;Graph Neural networks;,263;263;263,199;199;199,m;m,europe,uk,n,3;10
8405,ICLR,2021,Multi-Faceted Trust Based Recommendation System,Ramamoorthy Srinath;Shruthi Gopinath;Vaani Sundaresh;Varsha Venkatasubramanian,ramamoorthysrinath@gmail.com;shruthigopinath2@gmail.com;~Vaani_Sundaresh1;varshav0119@gmail.com,3;4;4;4,5;4;4;5,Withdrawn,0,0,,yes,9/28/20,PESIT;;;University of California  Berkeley,recommendation;implicit trust;explicit trust;collaborative filtering;multi-faceted;trust;trust metrics;similarity;recommender;,-1;-1;-1;-1,-1;-1;-1;7,m;f,usa,usa,n,
8406,ICLR,2021,Visible and Invisible: Causal Variable Learning and its Application in a Cancer Study,Jiqing Wu;Inti Zlobec;Viktor K√∂lzer,~Jiqing_Wu1;inti.zlobec@pathology.unibe.ch;viktor.koelzer@usz.ch,3;3;7,2;4;2,Withdrawn,0,0,,yes,9/28/20,University Hospital Zurich;;University Hospital Zurich,visible and invisible;causal discovery;invariant causal prediction;colorectal cancer;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y,
8407,ICLR,2021,Structural Knowledge Distillation,Xinyu Wang;Yong Jiang;Zhaohui Yan;Zixia Jia;Nguyen Bach;Tao Wang;Zhongqiang Huang;Fei Huang;Kewei Tu,~Xinyu_Wang3;~Yong_Jiang1;~Zhaohui_Yan1;~Zixia_Jia1;~Nguyen_Bach1;~Tao_Wang4;~Zhongqiang_Huang1;~Fei_Huang2;~Kewei_Tu1,4;5;4;5,3;4;4;4,Withdrawn,0,0,,yes,9/28/20,ShanghaiTech University;ShanghaiTech University;Shanghaitech University;ShanghaiTech University;Alibaba Group;Huazhong University of Science and Technology;Alibaba Group;Alibaba Group;ShanghaiTech University,,327;327;327;327;-1;-1;-1;-1;327,-1;-1;-1;-1;-1;312;-1;-1;-1,m;m,asia,cn,n,
8408,ICLR,2021,Self-supervised Disentangled Representation Learning,Xiaojiang Yang;Yitong Sun;Junchi Yan,~Xiaojiang_Yang1;~Yitong_Sun1;~Junchi_Yan2,4;4;5;5,4;4;3;3,Withdrawn,0,0,,yes,9/28/20,Shanghai Jiao Tong University;University of Michigan;Shanghai Jiao Tong University,Disentanglement;Identifiability;Nonlinear ICA;Self-supervised Learning;,29;7;29,100;22;100,m;m,asia,cn,y,1
8409,ICLR,2021,InvertGAN: Reducing mode collapse with multi-dimensional Gaussian Inversion,Liangliang Shi;Yang Li;Junchi Yan,~Liangliang_Shi1;~Yang_Li32;~Junchi_Yan2,6;5;4;3,3;4;4;3,Withdrawn,0,0,,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Generative Adversarial Networks;Mode Collapses;Image Diversity;,29;29;29,100;100;100,m;m,asia,cn,y,1;5;4
8410,ICLR,2021,GSdyn: Learning training dynamics via online Gaussian optimization with gradient states,Haoran Liao;Junchi Yan;Zimin Feng,~Haoran_Liao1;~Junchi_Yan2;zimingfzm@cmbchina.com,3;5;6;6,4;3;3;3,Withdrawn,0,1,,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;China Merchants Bank",,4;29;-1,20;100;-1,m;m,NAN,NAN,n,8;11
8411,ICLR,2021,Don't Trigger Me! A Triggerless Backdoor Attack Against Deep Neural Networks,Ahmed Salem;Michael Backes;Yang Zhang,~Ahmed_Salem2;~Michael_Backes1;~Yang_Zhang15,5;3;3,4;4;4,Withdrawn,0,1,,yes,9/28/20,The CISPA Helmholtz Center for Information Security;;CISPA Helmholtz Center for Information Security,Backdoor attack;Machine learning security;,99;-1;99,-1;-1;-1,m;m,NAN,NAN,n,4
8412,ICLR,2021,Exploiting Weight Redundancy in CNNs: Beyond Pruning and Quantization,Yuan Wen;David Gregg,~Yuan_Wen1;david.gregg@cs.tcd.ie,3;4;4;5;3,4;4;3;5;4,Withdrawn,0,0,,yes,9/28/20,Trinity College  Dublin;Trinity College  Dublin,Sparse tensor;tensor compaction;beyond pruning and quantization;,-1;-1,155;155,m;m,NAN,NAN,n,
8413,ICLR,2021,How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds,Prithviraj Ammanabrolu;Jack Urbanek;Margaret Li;Arthur Szlam;Tim Rockt√§schel;Jason E Weston,~Prithviraj_Ammanabrolu1;~Jack_Urbanek1;~Margaret_Li1;~Arthur_Szlam1;~Tim_Rockt√§schel1;~Jason_E_Weston1,7;4;4;4,2;3;3;3,Withdrawn,0,0,,yes,9/28/20,Georgia Institute of Technology;Facebook;Facebook;CUNY City College;Facebook AI Research;Facebook,reinforcement learning;text-based games;goal-driven dialogue;natural language processing;,12;-1;-1;263;-1;-1,38;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,6;3
8414,ICLR,2021,PHEW: Paths with Higher Edge-Weights give ''winning tickets'' without training data,Shreyas Malakarjun Patil;Constantine Dovrolis,~Shreyas_Malakarjun_Patil1;~Constantine_Dovrolis1,7;5;3;5;5,4;5;4;5;5,Withdrawn,0,0,,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology,Sparse Neural Networks;Pruning;,12;12,38;38,m;m,usa,usa,n,
8415,ICLR,2021,NASLib: A Modular and Flexible Neural Architecture Search Library,Michael Ruchte;Arber Zela;Julien Niklas Siems;Josif Grabocka;Frank Hutter,~Michael_Ruchte1;~Arber_Zela1;~Julien_Niklas_Siems1;~Josif_Grabocka1;~Frank_Hutter1,3;4;5;4,4;5;3;4,Withdrawn,0,5,,yes,9/28/20,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;University of Freiburg & Bosch,Neural Architecture Search;Automated Machine Learning;Deep Learning;Open-Source;Software;Python;PyTorch;,-1;-1;-1;-1;150,-1;-1;-1;-1;83,m;m,NAN,NAN,n,
8416,ICLR,2021,SEMI: Self-supervised Exploration via Multisensory Incongruity,Jianren Wang;Ziwen Zhuang;Hang Zhao,~Jianren_Wang2;~Ziwen_Zhuang1;~Hang_Zhao1,7;4;4;5,3;4;2;4,Withdrawn,0,1,,yes,9/28/20,"Carnegie Mellon University;ShanghaiTech University;Tsinghua University, Tsinghua University",Self-supervised Exploration;Multimodal Machine Learning;,1;327;4,28;-1;20,m;m,NAN,NAN,n,
8417,ICLR,2021,Measuring GAN Training in Real Time,Yuexiang Zhai;Bai Jiang;Yi Ma;Hao Chen,~Yuexiang_Zhai1;bai.jiang@bytedance.com;~Yi_Ma4;~Hao_Chen5,3;5;4;2,4;4;5;5,Withdrawn,0,0,,yes,9/28/20,University of California Berkeley;;;University of California Berkeley;University of California-Davis,Generative adversarial networks;Evaluation;,-1;-1;-1;-1;-1,7;-1;-1;7;64,m;m,usa,usa,n,5;4
8418,ICLR,2021,Probabilistic Multimodal Representation Learning,Leila Pishdad;Ran Zhang;Afsaneh Fazly;Allan Jepson,~Leila_Pishdad1;ran.zhang@samsung.com;a.fazly@samsung.com;allan.jepson@samsung.com,3;3;4;4,4;5;4;4,Withdrawn,0,4,,yes,9/28/20,"Samsung;Department of Computer Science, University of Toronto;Samsung;University of Toronto",multimodal representation learning;Probabilistic representation;image caption retrieval;,-1;18;-1;18,-1;18;-1;18,f;m,canada,ca,n,
8419,ICLR,2021,Motion Representations for Articulated Animation,Aliaksandr Siarohin;Oliver J. Woodford;Jian Ren;Menglei Chai;Sergey Tulyakov,~Aliaksandr_Siarohin1;~Oliver_J._Woodford1;~Jian_Ren2;~Menglei_Chai1;~Sergey_Tulyakov1,5;4;4;4,2;3;3;5,Withdrawn,0,5,,yes,9/28/20,Snap Inc.;University of Oxford;Snap Inc.;Snap Inc.;Snap Inc.,deep learning;imaga animation;generative modeling;,-1;46;-1;-1;-1,-1;1;-1;-1;-1,m;m,NAN,NAN,n,
8420,ICLR,2021,Understanding How Over-Parametrization Leads to Acceleration: A case of learning a single teacher neuron,Jun-Kun Wang;Jacob Abernethy,~Jun-Kun_Wang1;~Jacob_Abernethy1,3;4;4;5;5,5;3;5;4;4,Withdrawn,0,0,,yes,9/28/20,Georgia Institute of Technology;Georgia Tech Research Corporation,,12;-1,38;-1,m;m,NAN,NAN,y,1
8421,ICLR,2021,CLARE-GAN: GENERATION OF CLASS-SPECIFIC TIME SERIES,Hiba Arnout;Johanna Bronner;Thomas Runkler,~Hiba_Arnout1;johanna.bronner@siemens.com;~Thomas_Runkler1,3;4;4;3,5;3;4;5,Withdrawn,0,0,,yes,9/28/20,Technical University Munich;;;TU Munich,Generative Adversarial Networks;Time Series;,-1;-1;-1;58,-1;-1;-1;32,u;m,europe,de,n,1;5
8422,ICLR,2021,BAAAN: Backdoor Attacks Against Auto-encoder and GAN-Based Machine Learning Models,Ahmed Salem;Yannick Sautter;Michael Backes;Mathias Humbert;Yang Zhang,~Ahmed_Salem2;yannicksautter@gmail.com;~Michael_Backes1;mathias.humbert@armasuisse.ch;~Yang_Zhang15,4;3;5;4,4;5;5;4,Withdrawn,0,2,,yes,9/28/20,The CISPA Helmholtz Center for Information Security;Saarland University;;;;CISPA Helmholtz Center for Information Security,Backdoor attack;Autoencoders;Generative Adversarial Networks;,99;92;-1;-1;-1;99,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,5;4
8423,ICLR,2021,Mem2Mem: Learning to Summarize Long Texts with Memory Compression and Transfer,Jonathan Pilault;Jaehong Park;Christopher Pal,~Jonathan_Pilault1;~Jaehong_Park2;~Christopher_Pal1,5;4;5,3;5;4,Withdrawn,0,4,,yes,9/28/20,Polytechnique Montreal;Element AI;Polytechnique Montreal,Natural Language Processing;Summarization;Abstractive Summarization;Memory Compression;Hierarchical models;,327;-1;327,-1;-1;-1,m;m,canada,ca,n,8
8424,ICLR,2021,DAG-GPs: Learning Directed Acyclic Graph Structure For Multi-Output Gaussian Processes,Benjamin J. Ayton;Brian Williams,~Benjamin_J._Ayton1;~Brian_Williams1,4;5;5;5,4;2;3;4,Withdrawn,0,0,,yes,9/28/20,Massachusetts Institute of Technology;Randall Davis,multi-output gaussian processes;exact inference;directed acyclic graphs;conditional independence;structure learning;negative transfer;,5;-1,4;-1,m;m,NAN,NAN,y,10
8425,ICLR,2021,Unsupervised Disentanglement Learning by intervention,Weishen Pan;Sen Cui;Changshui Zhang,~Weishen_Pan1;cuis19@mails.tsinghua.edu.cn;~Changshui_Zhang2,5;5;2,5;3;4,Withdrawn,0,0,,yes,9/28/20,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",Disentanglement;Intervention;,4;4;4,20;20;20,m;m,asia,cn,y,1;5
8426,ICLR,2021,A Simple and General Strategy for Referential Problem in Low-Resource Neural Machine Translation,Yatu Ji;Nier Wu;Hongxu Hou,~Yatu_Ji1;~Nier_Wu1;~Hongxu_Hou1,2;4;3;4,5;4;3;3,Withdrawn,0,0,,yes,9/28/20,Inner Mongolia University;inner mongolia university;;Inner Mongolia University,machine translation;Referential Problem;low-resource;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n,3;4
8427,ICLR,2021,Re-examining Routing Networks for Multi-task Learning,Limeng Cui;Aaron Jaech,~Limeng_Cui1;ajaech@fb.com,3;3;6;5,3;3;2;4,Withdrawn,0,0,,yes,9/28/20,Pennsylvania State University;University of Washington,Routing Networks;Multi-task Learning;Reinforcement Learning;,44;11,-1;29,f;m,usa,usa,n,
8428,ICLR,2021,Robust Multi-view Representation Learning,Sibi Venkatesan;Kyle Miller;Artur Dubrawski,~Sibi_Venkatesan1;~Kyle_Miller1;~Artur_Dubrawski2,3;3;3;3,5;5;4;5,Withdrawn,0,0,,yes,9/28/20,"Carnegie Mellon University;CMU, Carnegie Mellon University;Carnegie-Mellon University",Multimodal Machine Learning;Representation Learning;AutoEncoders;,1;1;1,28;28;28,m;m,usa,usa,n,5
8429,ICLR,2021,GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training,Tianle Cai;Shengjie Luo;Keyulu Xu;Di He;Tie-Yan Liu;Liwei Wang,~Tianle_Cai1;~Shengjie_Luo1;~Keyulu_Xu1;~Di_He1;~Tie-Yan_Liu1;~Liwei_Wang1,4;4;6;5,4;4;3;4,Withdrawn,0,1,,yes,9/28/20,Peking University;Peking University;Massachusetts Institute of Technology;Microsoft;Microsoft;Peking University,Graph Neural Network;Normalization;,14;14;5;-1;-1;14,23;23;4;-1;-1;23,m;m,asia,cn,y,3;2;1;10
8430,ICLR,2021,Fairness guarantee in analysis of incomplete data,Yiliang Zhang;Qi Long,~Yiliang_Zhang1;qlong@upenn.edu,6;4;5;4;5,3;4;4;3;2,Withdrawn,0,8,,yes,9/28/20,University of Pennsylvania;University of Pennsylvania,Algorithmic fairness;missing data analysis;domain adaptation;,20;20,13;13,m;m,usa,usa,y,7
8431,ICLR,2021,Reflective Decoding: Unsupervised Paraphrasing and Abductive Reasoning,Peter West;Ximing Lu;Ari Holtzman;Chandra Bhagavatula;Jena Hwang;Yejin Choi,~Peter_West1;ximinglu@allenai.org;~Ari_Holtzman1;~Chandra_Bhagavatula1;jenah@allenai.org;~Yejin_Choi1,5;6;5,3;5;4,Withdrawn,0,6,,yes,9/28/20,"University of Washington, Seattle;;;Department of Computer Science, University of Washington;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Department of Computer Science, University of Washington",nlg;paraphrasing;unsupervised;decoding;language modeling;generation;,11;-1;-1;11;-1;-1;11,29;-1;-1;29;-1;-1;29,m;f,NAN,NAN,n,3
8432,ICLR,2021,Adaptive Dataset Sampling by Deep Policy Gradient,Jaerin Lee;Kyoung Mu Lee,~Jaerin_Lee1;~Kyoung_Mu_Lee2,5;3;5,4;5;4,Withdrawn,0,0,,yes,9/28/20,Seoul National University;Seoul National University,dataset sampling;batch selection;mini-batch SGD;reinforcement learning;policy gradient;optimal sample sequence;,37;37,60;60,m;m,asia,kr,n,
8433,ICLR,2021,Greedy Multi-Step Off-Policy Reinforcement Learning,Yuhui Wang;Xiaoyang Tan,~Yuhui_Wang1;~Xiaoyang_Tan2,2;4;4;5,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,Nanjing University of Aeronautics and Astronautics;Nanjing University of Aeronautics and Astronautics,off-policy learning;multi-step reinforcement learning;Q learning;,52;52,1076;1076,m;m,NAN,NAN,y,
8434,ICLR,2021,Syntactic Relevance XLNet Word Embedding Generation in Low-Resource Machine Translation,Nier Wu;Yatu Ji;Hongxu Hou,~Nier_Wu1;~Yatu_Ji1;~Hongxu_Hou1,3;3;3;5,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,inner mongolia university;Inner Mongolia University;;Inner Mongolia University,XLNet;Word Embedding;Machine Translation;Low resource;,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n,3;1
8435,ICLR,2021,Knapsack Pruning with Inner Distillation,Yonathan Aflalo;Itamar Friedman;Asaf Noy;Lihi Zelnik-Manor;Ming Lin,~Yonathan_Aflalo2;itamar.friedman@alibaba-inc.com;asaf.noy@alibaba-inc.com;~Lihi_Zelnik-Manor1;~Ming_Lin4,4;4;5;4,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,"Technion, Technion;;;;Technion;Alibaba Group",,29;-1;-1;-1;29;-1,-1;-1;-1;-1;408;-1,m;m,NAN,NAN,n,
8436,ICLR,2021,Discrete Word Embedding for Logical Natural Language Understanding,Zilu Tang;Masataro Asai,~Zilu_Tang1;~Masataro_Asai1,5;4;5;3,3;2;3;3,Withdrawn,0,6,,yes,9/28/20,International Business Machines;IBM Research / MIT-IBM Watson AI Lab,NLP;word embedding;discrete VAE;classical planning;neural symbolic;,-1;-1,-1;-1,m;m,NAN,NAN,y,
8437,ICLR,2021,Scalable Transformers for Neural Machine Translation,Gao Peng;Shijie Geng;Xiaogang Wang;Jifeng Dai;Hongsheng Li,~Gao_Peng1;~Shijie_Geng1;~Xiaogang_Wang2;~Jifeng_Dai1;~Hongsheng_Li3,4;4;5;6,5;4;3;5,Withdrawn,0,0,,yes,9/28/20,The Chinese University of Hong Kong;Rutgers University;Chinese University of Hong Kong;SenseTime Group Ltd;The Chinese University of Hong Kong,Scalable Transformers;Neural Machine Translation;Parameter Sharing;Self-distillation;,327;29;46;-1;327,39;-1;56;-1;39,m;m,NAN,NAN,n,8;3
8438,ICLR,2021,Inhibition-augmented ConvNets,Nicola Strisciuglio;George Azzopardi;Nicolai Petkov,~Nicola_Strisciuglio2;~George_Azzopardi2;~Nicolai_Petkov1,4;4;3;5,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,University of Twente;University of Groningen;;University of Groningen,ConvNet robustness;data corruption;inhibition;push-pull;,150;327;-1;327,242;81;-1;81,m;m,europe,nl,n,1
8439,ICLR,2021,NODE-SELECT: A FLEXIBLE GRAPH NEURAL NETWORK BASED ON REALISTIC PROPAGATION SCHEME,Steph-Yves Louis;Alireza Nasiri;Fatima Christina Rolland;Cameron Mitro;Jianjun Hu,~Steph-Yves_Louis1;~Alireza_Nasiri1;fr92@drexel.edu;cameron.mitro@atriumhealth.org;~Jianjun_Hu1,3;4;4,4;3;5,Withdrawn,0,1,,yes,9/28/20,University of South Carolina-Columbia;University of South Carolina;;;University of South Carolina-Columbia;University of South Carolina,Node selection;Realistic Propagation;Graph neural networks;,209;209;-1;-1;209;209,424;424;-1;-1;424;424,m;m,usa,usa,n,1;10
8440,ICLR,2021,Difference-in-Differences: Bridging Normalization and Disentanglement in PG-GAN,Xiao Liu;Jiajie Zhang;Siting Li;Zuotong Wu;Yang Yu,~Xiao_Liu15;jiajie-z19@mails.tsinghua.edu.cn;li-st19@mails.tsinghua.edu.cn;wuzt19@mails.tsinghua.edu.cn;yangyu1@tsinghua.edu.cn,5;3;4,3;4;4,Withdrawn,0,0,,yes,9/28/20,Tsinghua University;;;;Tsinghua University,,4;-1;-1;-1;4,20;-1;-1;-1;20,f;m,asia,cn,n,8;5
8441,ICLR,2021,Deep Reinforcement Learning for Optimal Stopping with Application in Financial Engineering,Abderrahim Fathan;Erick Delage,abderrahim.fathan@gmail.com;~Erick_Delage2,2;4;4;5,4;4;4;4,Withdrawn,0,0,,yes,9/28/20,"Concordia University, Montreal;HEC Montreal",Reinforcement learning;deep learning;financial engineering;optimal stopping.;,327;-1,631;-1,m;m,canada,ca,n,
8442,ICLR,2021,Spatially Decomposed Hinge Adversarial Loss by Local Gradient Amplifier,Sanghun Kim;Seungkyu Lee,kei97103@khu.ac.kr;~Seungkyu_Lee1,7;3;5;3,4;5;2;4,Withdrawn,0,0,,yes,9/28/20,Kyung Hee University;Kyung Hee University,,453;453,265;265,m;m,asia,kr,n,8;5;4
8443,ICLR,2021,Multi-view Arbitrary Style Transfer,Taekyung Kim;Changick Kim,~Taekyung_Kim3;~Changick_Kim1,4;6;3;5,5;4;5;3,Withdrawn,0,1,,yes,9/28/20,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,style transfer;multi-view vision;,-1;-1,96;96,m;m,NAN,NAN,n,
8444,ICLR,2021,Azimuthal Rotational Equivariance in Spherical CNNs,Carl Toft;Georg B√∂kman;Fredrik Kahl,~Carl_Toft1;bokman@chalmers.se;~Fredrik_Kahl3,5;6;3,4;4;4,Withdrawn,0,0,,yes,9/28/20,Chalmers University of Technology;Chalmers University;Chalmers University,,-1;-1;-1,235;235;235,m;m,europe,cz,y,
8445,ICLR,2021,Consensus Driven Learning,Kyle Crandall;Dustin Webb,~Kyle_Crandall1;dustin@aiinflux.com,2;3;1;3,4;4;5;5,Withdrawn,0,0,,yes,9/28/20,US Naval Research Lab;University of Utah,Distributed Machine Learning;Federated Learning;Distributed Averaging Consensus;,-1;58,-1;239,m;m,europe,uk,n,
8446,ICLR,2021,Learning to Represent Programs with Heterogeneous Graphs,Wenhan Wang;Kechi Zhang;Ge Li;Zhi Jin,~Wenhan_Wang2;1700012886@pku.edu.cn;lige@pku.edu.cn;~Zhi_Jin1,2;5;5;4,5;5;5;4,Withdrawn,0,0,,yes,9/28/20,Peking University;Peking University;;;Peking University,graph neural networks;heterogeneous graphs;code summarization;,14;14;-1;-1;14,23;23;-1;-1;23,m;f,asia,cn,n,10
8447,ICLR,2021,Gradient penalty from a maximum margin perspective,Alexia Jolicoeur-Martineau;Ioannis Mitliagkas,~Alexia_Jolicoeur-Martineau1;~Ioannis_Mitliagkas1,5;4;5;6,3;4;2;4,Withdrawn,0,0,,yes,9/28/20,University of Montreal;University of Montreal,GAN;large margin;SVM;,128;128,73;73,f;m,canada,ca,n,5;4
8448,ICLR,2021,Neural Text Classification by Jointly Learning to Cluster and Align,Yekun Chai;Haidong Zhang;Shuo Jin,~Yekun_Chai1;haidong_zhang14@yahoo.com;shj42@pitt.edu,5;4;5;3,2;3;3;4,Withdrawn,0,0,,yes,9/28/20,Institute of automation  Chinese academy of sciences;Institute of Automation   Chinese Academy of Sciences;University of Pittsburgh,text clustering;text classification;latent variable model;,-1;34;79,-1;-1;133,m;m,usa,usa,n,3
8449,ICLR,2021,Alpha-DAG: a reinforcement learning based algorithm to learn Directed Acyclic Graphs,Fan Zhou;Yifeng Pan;Shenghua Zhu;Xin HE,~Fan_Zhou7;~Yifeng_Pan3;~Shenghua_Zhu1;~Xin_HE6,4;5;4;4,4;4;4;3,Withdrawn,0,0,,yes,9/28/20,Shanghai University of Finance and Economics;Shanghai University of Finance and Economics;Shanghai University of Finance and Economics;Shanghai University of Finance and Economics,Directed acyclic graph;reinforcement learning;Q Learning;Graph Auto-Encoder;,-1;-1;-1;-1,818;818;818;818,m;m,NAN,NAN,n,10
8450,ICLR,2021,An Euler-based GAN for time series,Carl Remlinger;Joseph Mickael;Romuald Elie,~Carl_Remlinger1;joseph.mikael@edf.fr;~Romuald_Elie1,3;3;3;5;5,4;3;5;4;3,Withdrawn,0,0,,yes,9/28/20,Universit√© Gustave Eiffel;edf;Universit√© Gustave Eiffel,Euler GAN;GAN;time series;Wasserstein;Sinkhorn divergence;transfer learning;,-1;-1;-1,-1;975;-1,m;m,NAN,NAN,n,6;5;4
8451,ICLR,2021,Improving Zero-Shot Neural Architecture Search with Parameters Scoring,Luca Celotti;Ismael Balafrej;Emmanuel Calvet,~Luca_Celotti1;ismael.balafrej@usherbrooke.ca;emmanuel.calvet@usherbrooke.ca,3;5;4;5,4;2;4;4,Withdrawn,0,4,,yes,9/28/20,Universit‚àö¬© de Sherbrooke;Universit‚àö¬© de Sherbrooke;Universit‚àö¬© de Sherbrooke,,327;327;327,-1;-1;-1,m;m,NAN,NAN,n,6
8452,ICLR,2021,Transferred Discrepancy: Quantifying the Difference Between Representations,Yunzhen Feng;Runtian Zhai;Di He;Liwei Wang;Bin Dong,~Yunzhen_Feng1;~Runtian_Zhai1;~Di_He1;~Liwei_Wang1;~Bin_Dong1,3;5;5;4,3;4;4;5,Withdrawn,0,4,,yes,9/28/20,Peking University;Carnegie Mellon University;Microsoft;Peking University;Peking University,,14;1;-1;14;14,23;28;-1;23;23,m;m,asia,cn,y,1
8453,ICLR,2021,Learning to Control on the Fly,Zhanzhan Zhao,~Zhanzhan_Zhao1,3;4;4;3,3;5;4;5,Withdrawn,0,0,,yes,9/28/20,Georgia Institute of Technology,online decision making;convergence;regret bound;bounded random noise;,12,38,f,usa,usa,y,1
8454,ICLR,2021,Symmetry-Augmented Representation for Time Series,Amine Mohamed Aboussalah;Chi-Guhn Lee,~Amine_Mohamed_Aboussalah1;~Chi-Guhn_Lee1,4;4;4;6,3;2;3;1,Withdrawn,0,0,,yes,9/28/20,"Toronto University;Department of Mechanical and Industrial Engineering, University of Toronto, Toronto University",Time Series;Symmetry;Homology;Augmentation;Machine Learning;Reinforcement Learning;,-1;18,-1;18,m;m,NAN,NAN,n,1
8455,ICLR,2021,Learned residual Gerchberg-Saxton network for computer generated holography,Lennart Schlieder;Heiner Kremer;Valentin Volchkov;Kai Melde;Peer Fischer;Bernhard Sch√∂lkopf,~Lennart_Schlieder1;hkremer@tuebingen.mpg.de;valentin.volchkov@tuebinge.mpg.de;melde@is.mpg.de;fischer@is.mpg.de;~Bernhard_Sch√∂lkopf1,3;4;3;5,5;4;4;2,Withdrawn,0,0,,yes,9/28/20,"Max-Planck-Institute for Intelligent Systems, Max-Planck Institute;;;;;;;;;Max Planck Institute for Intelligent Systems, Max-Planck Institute",computer generated holography;inverse problems;deep learning;,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,9
8456,ICLR,2021,"The Scattering Compositional Learner: Discovering Objects, Attributes, Relationships in Analogical Reasoning",Yuhuai Wu;Honghua Dong;Roger Baker Grosse;Jimmy Ba,~Yuhuai_Wu1;~Honghua_Dong1;~Roger_Baker_Grosse1;~Jimmy_Ba1,5;4;5,4;5;5,Withdrawn,0,1,,yes,9/28/20,"Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",Raven's Progressive Matrices;visual analogical reasoning.;,18;18;18;18,18;18;18;18,m;m,NAN,NAN,n,6;1
8457,ICLR,2021,Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in First-person Simulated 3D Environments,Wilka Torrico Carvalho;Anthony Liang;Kimin Lee;Sungryull Sohn;Honglak Lee;Richard Lewis;Satinder Singh,~Wilka_Torrico_Carvalho1;aliangdw@umich.edu;~Kimin_Lee1;~Sungryull_Sohn1;~Honglak_Lee2;~Richard_Lewis1;~Satinder_Singh2,3;4;4;6,4;3;4;3,Withdrawn,0,7,,yes,9/28/20,DeepMind;;;University of California Berkeley;University of Michigan;LG AI Research;Carnegie Mellon University;University of Michigan,object-centric;representation learning;reinforcement learning;sparse reward;,-1;-1;-1;-1;7;-1;1;7,-1;-1;-1;7;22;-1;28;22,m;m,usa,usa,n,
8458,ICLR,2021,Hybrid Quantum-Classical Stochastic Networks with Boltzmann Layers,Jonathan H Warrell;Prashant Emani;Mark Gerstein,~Jonathan_H_Warrell1;prashant.emani@yale.edu;~Mark_Gerstein1,3;4;5;3,3;3;4;5,Withdrawn,0,0,,yes,9/28/20,Yale University;;;Yale University,Quantum Machine Learning;Hierarchical Models;Variational Inference;Model Interpretation;Computational Biology;,71;-1;-1;71,8;-1;-1;8,m;m,europe,fi,n,5
8459,ICLR,2021,Data Augmentation for Meta-Learning,Renkun Ni;Micah Goldblum;Amr Sharaf;Kezhi Kong;Tom Goldstein,~Renkun_Ni1;~Micah_Goldblum1;~Amr_Sharaf1;~Kezhi_Kong1;~Tom_Goldstein1,3;6;5;5,4;4;4;4,Withdrawn,0,1,,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;University of Maryland, College Park;Microsoft;University of Maryland, College Park;University of Maryland, College Park",meta-learning;few-shot classification;data augmentation;transfer learning;,-1;12;-1;12;12,90;90;-1;90;90,m;m,usa,usa,n,6
8460,ICLR,2021,Solving Non-Stationary Bandit Problems with an RNN and an Energy Minimization Loss,Michael Rotman;Lior Wolf,~Michael_Rotman1;~Lior_Wolf1,2;4;3;5,5;3;4;3,Withdrawn,0,1,,yes,9/28/20,Tel Aviv University;Tel Aviv University,Recurrent Neural Networks;Mutli Arm-Bandits;,34;34,190;190,m;m,europe,il,n,
8461,ICLR,2021,Graph-Graph Similarity Network,Han Yue;Pengyu Hong;Hongfu Liu,~Han_Yue2;~Pengyu_Hong1;~Hongfu_Liu2,5;4;5;2,5;4;4;5,Withdrawn,0,1,,yes,9/28/20,Brandeis University;Brandeis University;Brandeis University,Machine Learning;Graph Classification;,263;263;263,242;242;242,u;m,usa,usa,n,10;4
8462,ICLR,2021,Neural Bootstrapper,Minsuk Shin;Hyungjoo Cho;Sungbin Lim,mshin@mailbox.sc.edu;~Hyungjoo_Cho1;~Sungbin_Lim1,5;5;3;5,3;3;5;4,Withdrawn,0,1,,yes,9/28/20,University of South Carolina;Seoul National University;Ulsan National Institute of Science and Technology,Bootstrapping;Uncertainty Estimation;Deep Learning;,209;37;-1,424;60;176,m;m,NAN,NAN,y,
8463,ICLR,2021,Modeling Human Development: Effects of Blurred Vision on Category Learning in CNNs,William Charles;Daniel Leeds,~William_Charles1;dleeds@fordham.edu,4;5;4,4;3;4,Withdrawn,0,0,,yes,9/28/20,Georgetown University;Fordham University,CNNs;computer vision;,209;-1,120;-1,m;m,europe,uk,n,2
8464,ICLR,2021,Hokey Pokey Causal Discovery: Using Deep Learning Model Errors to Learn Causal Structure,Emily Saldanha;Dustin Arendt;Svitlana Volkova,~Emily_Saldanha1;dustin.arendt@pnnl.gov;~Svitlana_Volkova1,4;4;5;4,4;4;3;5,Withdrawn,0,1,,yes,9/28/20,Pacific Northwest National Laboratory;;;Pacific Northwest National Laboratory,causal discovery;,-1;-1;-1;-1,-1;-1;-1;-1,f;f,NAN,NAN,n,1
8465,ICLR,2021,Temporal Attention Modules for Memory-Augmented Neural Networks,Rodolfo Palma;Alvaro Soto;Luis Mart√≠;Nayat Sanchez-pi,~Rodolfo_Palma1;~Alvaro_Soto1;~Luis_Mart√≠1;~Nayat_Sanchez-pi1,3;4;5;3,4;3;3;4,Withdrawn,0,0,,yes,9/28/20,Pontificia Universidad Cat‚àö‚â•lica;Universidad Cat‚àö‚â•lica de Chile;Inria Chile Research Center;Instituto de Matem‚àö¬∞tica e Estat‚àö‚â†stica,multitasking;attention;deep learning;natural language processing;,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n,8;3
8466,ICLR,2021,Invariant Batch Normalization for Multi-source Domain Generalization,Qing LIAN;LIN Yong;Tong Zhang,~Qing_LIAN3;~LIN_Yong1;~Tong_Zhang2,4;4;5;5,4;4;4;5,Withdrawn,0,1,,yes,9/28/20,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Google,Domain generalization;Invariant learning;Batch Normalization;,-1;-1;-1,56;56;-1,m;m,NAN,NAN,n,1
8467,ICLR,2021,Few-shot Adaptation of Generative Adversarial Networks,Esther Robb;Wen-Sheng Chu;Abhishek Kumar;Jia-Bin Huang,~Esther_Robb1;~Wen-Sheng_Chu1;~Abhishek_Kumar1;~Jia-Bin_Huang1,5;7;4;3,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,Virginia Tech;Google Research;Google Brain;Virginia Tech,GAN;Few-shot;SVD;PCA;,64;-1;-1;64,-1;-1;-1;-1,f;m,usa,usa,n,6;5
8468,ICLR,2021,Optimizing Over All Sequences of Orthogonal Polynomials,Shiva Kaul,~Shiva_Kaul1,6;4;4,4;3;4,Withdrawn,0,4,,yes,9/28/20,Carnegie Mellon University,orthogonal polynomials;differentiation;compression;nonconvex optimization;,1,28,m,usa,usa,n,
8469,ICLR,2021,Understanding Adversarial Attacks on Autoencoders,Elsa Riachi;Frank Rudzicz,~Elsa_Riachi1;~Frank_Rudzicz2,4;5;3;7,4;2;4;3,Withdrawn,0,1,,yes,9/28/20,Toronto University;University of Toronto,,-1;18,-1;18,f;m,canada,ca,n,1;4
8470,ICLR,2021,Continual Learning Without Knowing Task Identities: Do Simple Models Work?,Tiffany Tuor;Shiqiang Wang;Kin Leung,tiffany.tuor14@imperial.ac.uk;~Shiqiang_Wang1;~Kin_Leung1,5;5;5;3,5;4;5;4,Withdrawn,0,0,,yes,9/28/20,"Imperial College London;IBM, International Business Machines;Imperial College London",continual learning;catastrophic forgetting;Bayesian neural network;,53;-1;53,11;-1;11,f;m,europe,uk,n,11
8471,ICLR,2021,The Foes of Neural Network‚Äôs Data Efficiency Among Unnecessary Input Dimensions,Vanessa D'Amario;Sanjana Srivastava;Tomotake Sasaki;Xavier Boix,~Vanessa_D'Amario1;~Sanjana_Srivastava2;~Tomotake_Sasaki1;~Xavier_Boix1,3;5;5;4,3;3;4;4,Withdrawn,0,0,,yes,9/28/20,Massachusetts Institute of Technology;Stanford University;Fujitsu Limited;Massachusetts Institute of Technology,Data Efficiency;Small Sample Size;Data Dimensionality;Image Background;,5;5;-1;5,4;2;-1;4,f;m,usa,usa,n,1
8472,ICLR,2021,Dynamic Probabilistic Pruning: Training sparse networks based on stochastic and dynamic masking,Lizeth Gonzalez Carabarin;Iris A.M. Huijben;Bastiaan S. Veeling;Alexandre Schmid;Ruud Van Sloun,~Lizeth_Gonzalez_Carabarin1;~Iris_A.M._Huijben1;~Bastiaan_S._Veeling1;alexandre.schmid@epfl.ch;~Ruud_Van_Sloun1,2;5;4;5,5;3;4;4,Withdrawn,0,10,,yes,9/28/20,Eindhoven University of Technology;Eindhoven University of Technology;Google;;;Eindhoven University of Technology,deep probabilistic subsampling;sparse deep learning;structured pruning;hardware-oriented pruning;,-1;-1;-1;-1;-1;-1,186;186;-1;-1;-1;186,f;m,NAN,NAN,n,
8473,ICLR,2021,A Unified Framework for Proximal Methods,Jihun Yun;Aurelie Lozano;Eunho Yang,~Jihun_Yun2;~Aurelie_Lozano1;~Eunho_Yang1,4;5;6;5,5;4;4;4,Withdrawn,0,6,,yes,9/28/20,Korea Advanced Institute of Science and Technology;IBM Research;Korea Advanced Institute of Science & Technology,Stochastic Optimization;Deep Learning;Proximal Gradient Descent;,-1;-1;-1,96;-1;-1,m;m,NAN,NAN,y,
8474,ICLR,2021,Out-of-Core Training for Extremely Large-Scale Neural Networks with Adaptive Window-Based Scheduling,Akio Hayakawa;Takuya Narihira,~Akio_Hayakawa1;~Takuya_Narihira2,4;4;4;4,3;4;4;4,Withdrawn,0,1,,yes,9/28/20,Sony;Sony,Deep Learning;Neural Networks;Out-of-Core Execution;,-1;-1,-1;-1,m;m,asia,cn,n,1
8475,ICLR,2021,PAC-Bayesian Randomized Value Function with Informative Prior,Yuankun Jiang;Chenglin Li;Junni Zou;Wenrui Dai;Hongkai Xiong,~Yuankun_Jiang1;~Chenglin_Li2;~Junni_Zou1;~Wenrui_Dai1;~Hongkai_Xiong1,7;3;5;4;5,3;4;3;2;4,Withdrawn,0,0,,yes,9/28/20,"Shanghai Jiao Tong University, Tsinghua University;Shanghai Jiao Tong University;;Shanghai Jiaotong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Reinforcement learning;,4;29;-1;29;29;29,20;100;-1;100;100;100,m;m,asia,cn,y,11;1
8476,ICLR,2021,cross-modal knowledge enhancement mechanism for few-shot learning,Haiyang Zhang;Jiaming Duan;liang liu,zhhy@bupt.edu.cn;~Jiaming_Duan1;liangliu@bupt.edu.cn,4;4;5;3,5;5;4;5,Withdrawn,0,0,,yes,9/28/20,Beijing University of Posts and Telecommunications;Beijing University of Post and Telecommunications;Beijing University of Posts and Telecommunications,few-shot learning;cross-modal;image classification;,-1;-1;-1,-1;-1;-1,u;m,NAN,NAN,n,6;10
8477,ICLR,2021,Category Disentangled Context: Turning Category-irrelevant Features  Into Treasures,Keke Tang;Guodong Wei;Jie Zhu;Yuexin Ma;Runnan Chen;Zhaoquan Gu;Wenping Wang,~Keke_Tang2;~Guodong_Wei1;~Jie_Zhu2;~Yuexin_Ma2;~Runnan_Chen1;~Zhaoquan_Gu2;~Wenping_Wang1,4;5;6;5,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,"Guangzhou University;The University of Hong Kong;The University of Hong Kong;Hong Kong Baptist University;The University of Hong Kong;Guangzhou University, China, Tsinghua University;HKU",,-1;99;99;209;99;4;37,983;39;39;377;39;20;-1,m;m,asia,in,n,8;2;4
8478,ICLR,2021,Mathematical Word Problem Generation from Commonsense Knowledge Graph and Equations,Tianqiao Liu;Qiang Fang;Wenbiao Ding;Zhongqin Wu;Zitao Liu,~Tianqiao_Liu1;fangqiang@tal.com;dingwenbiao@tal.com;wuzhongqin@tal.com;~Zitao_Liu1,3;5;5;5,5;4;5;4,Withdrawn,0,0,,yes,9/28/20,Purdue University;;;TAL Education Group;TAL;TAL Education Group,mathematical word problem;natural language generation;graph neural network;,23;-1;-1;-1;-1;-1,94;-1;-1;-1;16;-1,m;m,NAN,NAN,n,10
8479,ICLR,2021,On the Discovery of Feature Importance Distribution: An Overlooked Area,Yuxiao Huang,~Yuxiao_Huang1,4;5;3,5;3;3,Withdrawn,0,0,,yes,9/28/20,George Washington University,,209,186,m,usa,usa,n,
8480,ICLR,2021,Feedforward Legendre Memory Unit,Narsimha Reddy Chilkuri;Chris Eliasmith,~Narsimha_Reddy_Chilkuri1;~Chris_Eliasmith1,4;4;5;4,5;3;3;3,Withdrawn,0,0,,yes,9/28/20,University of Waterloo;University of Waterloo,LMU;LSTM;RNN;NLP;Transformers;Feedforward Training;,34;34,232;232,m;m,canada,ca,n,8;3
8481,ICLR,2021,Interpretable Reinforcement Learning With Neural Symbolic Logic,Zhihao Ma;Yuzheng Zhuang;Paul Weng;Dong Li;Kun Shao;Wulong Liu;Hankz Hankui Zhuo;Jianye HAO,~Zhihao_Ma1;~Yuzheng_Zhuang1;~Paul_Weng1;~Dong_Li10;~Kun_Shao1;~Wulong_Liu1;~Hankz_Hankui_Zhuo2;~Jianye_HAO1,4;5;4;5,4;4;2;4,Withdrawn,0,4,,yes,9/28/20,"SUN YAT-SEN UNIVERSITY;Huawei Technologies Ltd.;Shanghai Jiaotong University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Huawei Noah's Ark Lab;Huawei Noah's Ark Lab;SUN YAT-SEN UNIVERSITY;Tianjin University",Interpretable Reinforcement Learning;Neural Symbolic Logic;,-1;-1;29;34;-1;-1;-1;-1,293;-1;100;-1;-1;-1;293;496,m;m,asia,cn,n,
8482,ICLR,2021,FixNorm: Dissecting Weight Decay for Training Deep Neural Networks,Yucong Zhou;Yunxiao Sun;Jian Zhang;Zhao Zhong,~Yucong_Zhou2;~Yunxiao_Sun1;~Jian_Zhang18;~Zhao_Zhong1,4;5;4;4,4;3;4;4,Withdrawn,0,0,,yes,9/28/20,Huawei Technologies Ltd.;Beijing Institute of Technology;Peking University;Huawei,weight decay;effective learning rate;cross-boundary risk;hyperparameter tuning;,-1;-1;14;-1,-1;584;23;-1,m;m,NAN,NAN,n,11;1
8483,ICLR,2021,Cost-efficient SVRG with Arbitrary Sampling,Hossein S. Ghadikolaei;Thomas Ohlson Timoudas;Carlo Fischione,~Hossein_S._Ghadikolaei1;ttohlson@kth.se;~Carlo_Fischione1,4;4;4;4;3,4;4;5;5;3,Withdrawn,0,0,,yes,9/28/20,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;;KTH Royal Institute of Technology;KTH Royal Institute of Technology",Distributed optimization;communication efficiency;SVRG;importance sampling;Internet-of-Things;,174;174;-1;174;174,239;239;-1;239;239,m;m,europe,se,y,9
8484,ICLR,2021,Adaptive Learning Rates with Maximum Variation Averaging,Chen Zhu;Yu Cheng;Zhe Gan;Furong Huang;Jingjing Liu;Tom Goldstein,~Chen_Zhu2;~Yu_Cheng1;~Zhe_Gan1;~Furong_Huang1;~Jingjing_Liu2;~Tom_Goldstein1,4;3;4;4,4;4;4;5,Withdrawn,0,5,,yes,9/28/20,"Department of Computer Science, University of Maryland, College Park;Microsoft Research;Microsoft;Department of Computer Science, University of Maryland;Microsoft;University of Maryland, College Park",Adaptive Step Size;Large Batch Optimization;Transformers;,-1;-1;-1;-1;-1;12,90;-1;-1;-1;-1;90,m;m,usa,usa,y,3;8;1
8485,ICLR,2021,Paired Examples as Indirect Supervision in Latent Decision Models,Nitish Gupta;Sameer Singh;Matt Gardner;Dan Roth,~Nitish_Gupta1;~Sameer_Singh1;~Matt_Gardner1;~Dan_Roth3,6;4;5;4,2;4;3;4,Withdrawn,0,4,,yes,9/28/20,"University of Pennsylvania;University of California, Irvine;Allen Institute for Artificial Intelligence;University of Illinois at Urbana-Champaign",indirect supervision;compositional model;question answering;neural module networks;,20;-1;-1;-1,13;98;-1;48,m;m,NAN,NAN,n,1
8486,ICLR,2021,NeuralLog: a Neural Logic Language,Victor Guimar√£es;Vitor Santos Costa,~Victor_Guimar√£es1;~Vitor_Santos_Costa1,5;6;5;3,5;5;4;5,Withdrawn,0,6,,yes,9/28/20,University of Porto;University of Porto,Deep learning;logic programming;neural network;relational learning;,-1;-1,452;452,m;m,europe,ee,n,1
8487,ICLR,2021,Meta-Continual Learning Via Dynamic Programming,Krishnan Raghavan;Prasanna Balaprakash,~Krishnan_Raghavan1;~Prasanna_Balaprakash1,6;4;4;4,4;3;3;3,Withdrawn,0,6,,yes,9/28/20,Argonne National Laboratory;Argonne National Laboratory,Meta Continual Learning;Supervised Learning;Dynamic Programming;Catastrophic Forgetting;Generalization;,-1;-1,-1;-1,m;m,NAN,NAN,y,1
8488,ICLR,2021,Distribution Based MIL Pooling Filters are Superior to Point Estimate Based Counterparts,Mustafa Umit Oner;Jared Marc Song;Hwee Kuan Lee;Wing-Kin Sung,~Mustafa_Umit_Oner1;~Jared_Marc_Song1;~Hwee_Kuan_Lee1;~Wing-Kin_Sung1,4;4;5,4;5;3,Withdrawn,0,8,,yes,9/28/20,National University of Singapore;Singapore Institute of Technology;BII;National University of Singapore,multiple instance learning;mil;mil pooling filters;distribution pooling;point estimate based pooling;,17;-1;209;17,25;-1;-1;25,m;m,asia,sg,y,8
8489,ICLR,2021,Graph Adversarial Networks: Protecting Information against Adversarial Attacks,Peiyuan Liao;Han Zhao;Keyulu Xu;Tommi S. Jaakkola;Geoff Gordon;Stefanie Jegelka;Ruslan Salakhutdinov,~Peiyuan_Liao1;~Han_Zhao1;~Keyulu_Xu1;~Tommi_S._Jaakkola1;~Geoff_Gordon2;~Stefanie_Jegelka3;~Ruslan_Salakhutdinov1,5;5;4;5,4;4;4;3,Withdrawn,0,10,,yes,9/28/20,"CMU, Carnegie Mellon University;University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Microsoft;Massachusetts Institute of Technology;Carnegie-Mellon University",graph neural networks;deep learning;adversarial learning;theory;,1;-1;5;5;-1;5;1,28;-1;4;4;-1;4;28,m;m,usa,usa,y,10;4
8490,ICLR,2021,Intragroup sparsity for efficient inference,Zilin Yu;Chao Wang;Xin Wang;Yong Zhao;Xundong Wu,~Zilin_Yu1;~Chao_Wang1;~Xin_Wang2;~Yong_Zhao4;~Xundong_Wu3,6;4;5;4,3;5;3;4,Withdrawn,0,0,,yes,9/28/20,"Baidu;Peking University;Cerebras Systems, Inc;Peking University Shenzhen Graduate School;Hangzhou Dianzi University",Deep Learning;Model compression;Neural Network Pruning;High Performance Computation;,-1;14;-1;14;-1,-1;23;-1;23;-1,m;m,NAN,NAN,n,
8491,ICLR,2021,Semantic Segmentation Based Unsupervised Domain Adaptation via Pseudo-Label Fusion,Chen-Hao Chao;Bo-Wun Cheng;Chien Feng;Chun-Yi Lee,~Chen-Hao_Chao2;~Bo-Wun_Cheng1;~Chien_Feng1;~Chun-Yi_Lee1,5;6;4;5,4;4;4;4,Withdrawn,0,8,,yes,9/28/20,"Department of Computer Science, National Tsing Hua University, National Tsing Hua University;National Tsing Hua University;;National Tsing Hua University",Semantic Segmentation;Unsupervised Domain Adaptation;Knowledge Distillation;Pseudo Labeling;,209;209;-1;209,365;365;-1;365,m;m,asia,tw,n,2
8492,ICLR,2021,Withdraw,Matthew Thorpe;Bao Wang,matthew.thorpe-2@manchester.ac.uk;~Bao_Wang1,5;4;4;5,3;4;3;2,Withdrawn,0,1,,yes,9/28/20,University of Manchester;University of Utah,,263;58,51;239,m;m,europe,uk,pdf miss,
8493,ICLR,2021,Backdoor Attacks to Graph Neural Networks,Zaixi Zhang;Jinyuan Jia;Binghui Wang;Neil Zhenqiang Gong,zaixi.zhang@duke.edu;~Jinyuan_Jia2;~Binghui_Wang2;~Neil_Zhenqiang_Gong1,5;5;5;4,5;4;3;4,Withdrawn,0,0,,yes,9/28/20,Duke University;Duke University;Duke University;Duke University,,46;46;46;46,20;20;20;20,m;m,europe,se,n,10;4
8494,ICLR,2021,Knowledge Distillation based Ensemble Learning for Neural Machine Translation,Chenze Shao;Meng Sun;Yang Feng;Zhongjun He;hua wu;Haifeng Wang,~Chenze_Shao1;sunmeng09@baidu.com;~Yang_Feng4;hezhongjun@baidu.com;~hua_wu1;wanghaifeng@baidu.com,6;4;6;4,4;4;4;4,Withdrawn,0,5,,yes,9/28/20,Chinese Academy of Sciences;;;;;Baidu Inc.,Knowledge Distillation;Ensemble Learning;Neural Machine Translation;,34;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,3
8495,ICLR,2021,Unsupervised Simultaneous Depth-from-defocus and Depth-from-focus,Yawen Lu;Guoyu Lu,~Yawen_Lu1;~Guoyu_Lu3,4;4;3;6,4;5;5;3,Withdrawn,0,4,,yes,9/28/20,Rochester Institute of Technology;Rochester Institute of Technology,Depth-from-defocus;Depth-from-focus;Unsupervised learning;,110;110,891;891,m;m,usa,usa,n,
8496,ICLR,2021,Max-Affine Spline Insights Into Deep Generative Networks,Randall Balestriero;Sebastien Paris;Richard Baraniuk,~Randall_Balestriero1;sebastien.paris@lis-lab.fr;~Richard_Baraniuk1,4;8;2;4,2;2;4;3,Withdrawn,0,6,,yes,9/28/20,Rice University;;;William Marsh Rice University,max affine spline;generative networks;manifold smoothing;dropout;dropconnect;inverse problems;GAN;VAE;multimodal density estimation;elbow method;,92;-1;-1;92,124;-1;-1;124,m;m,NAN,NAN,y,5
8497,ICLR,2021,Interpretable Super-Resolution via a Learned Time-Series Representation,Randall Balestriero;Herv√© Glotin;Richard Baraniuk,~Randall_Balestriero1;~Herv√©_Glotin1;~Richard_Baraniuk1,6;4;6;4,4;2;4;5,Withdrawn,0,2,,yes,9/28/20,Rice University;CNRS university Toulon;William Marsh Rice University,time frequency representation;time series;wigner ville;cohen class;wavelet transform;scalogram;bird;speech;,92;-1;92,124;-1;124,m;m,NAN,NAN,y,
8498,ICLR,2021,Practical Phase Retrieval: Low-Photon Holography with Untrained Priors,Hannah Lawrence;David Barmherzig;Henry Li;Michael Eickenberg;Marylou Gabri√©,hanlaw@mit.edu;dbarmherzig@flatironinstitute.org;~Henry_Li2;~Michael_Eickenberg3;~Marylou_Gabri√©1,5;7;4;3,4;3;1;5,Withdrawn,0,8,,yes,9/28/20,Massachusetts Institute of Technology;Flatiron Institute;Yale University;Flatiron Institute;New York University,inverse problems;phase retrieval;generative priors;holography;coherent diffraction imaging;,5;-1;71;-1;23,4;-1;8;-1;26,f;f,usa,usa,n,
8499,ICLR,2021,Transferable Feature Learning on Graphs Across Visual Domains,Ronghang Zhu;Xiaodong Jiang;Jiasen Lu;Sheng Li,~Ronghang_Zhu2;~Xiaodong_Jiang1;~Jiasen_Lu2;~Sheng_Li3,5;4;3;4,4;2;5;5,Withdrawn,0,5,,yes,9/28/20,University of Georgia;Facebook;Georgia Institute of Technology;University of Georgia,,263;-1;12;263,411;-1;38;411,m;m,usa,usa,n,8;10;4
8500,ICLR,2021,Good for Misconceived Reasons: Revisiting Neural Multimodal Machine Translation,Zhiyong Wu;Lingpeng Kong;Ben Kao,~Zhiyong_Wu3;~Lingpeng_Kong1;~Ben_Kao1,6;5;5;4,3;5;4;5,Withdrawn,0,7,,yes,9/28/20,"The University of Hong Kong;Department of Computer Science, The University of Hong Kong;;University of Hong Kong",multimodal machine translation;interpretability;,99;99;-1;99,39;39;-1;39,m;m,asia,hk,n,3
8501,ICLR,2021,Towards Generalized Artificial Intelligence by Assessment Aggregation with Applications to Standard and Extreme Classifications,Abdourrahmane M ATTO,~Abdourrahmane_M_ATTO1,5;2;3,2;4;2,Withdrawn,0,1,,yes,9/28/20,USMB,Artificial Intelligence;Convolutional Neural Network;Extreme Classifications;,99,-1,m,europe,gr,n,1
8502,ICLR,2021,Unified analytic forms for Convolutional Neural Networks and Wavelet Filter Banks,Abdourrahmane M ATTO,~Abdourrahmane_M_ATTO1,4;5;4;2,3;5;2;4,Withdrawn,0,5,,yes,9/28/20,USMB,Convolutional neural network;Multiserial convolution filter bank;Analytic expressions;,99,-1,m,europe,gr,n,
8503,ICLR,2021,A Spectral Perspective of Neural Networks Robustness to Label Noise,Oshrat Bar;Amnon Drory;Raja Giryes,~Oshrat_Bar1;~Amnon_Drory1;~Raja_Giryes1,3;5;3;4,4;4;4;4,Withdrawn,0,4,,yes,9/28/20,Tel Aviv University;Tel Aviv University;Tel Aviv University,Label noise;Neural network robustness;Regularization methods;Spectral normalization;Fourier analysis;,34;34;34,190;190;190,f;m,europe,il,y,
8504,ICLR,2021,Spatial Frequency Bias in Convolutional Generative Adversarial Networks,Mahyar Khayatkhoei;Ahmed Elgammal,~Mahyar_Khayatkhoei1;~Ahmed_Elgammal1,3;3;4;5,4;4;4;3,Withdrawn,0,6,,yes,9/28/20,Rutgers University;Rutgers University New Brunswick,GANs;Spectral Bias;Convolutional Neural Networks;,29;29,-1;-1,m;m,NAN,NAN,y,5;4
8505,ICLR,2021,Convolutional Complex Knowledge Graph Embeddings,Caglar Demir;Axel Ngonga,~Caglar_Demir1;~Axel_Ngonga1,4;4;4;5,5;5;5;3,Withdrawn,0,0,,yes,9/28/20,eim;Universit√§t Paderborn,complex knowledge graph embeddings;convolutions;,263;-1,140;-1,m;m,NAN,NAN,n,10
8506,ICLR,2021,EMPIRICAL UPPER BOUND IN OBJECT DETECTION,ali borji,~ali_borji1,4;5;4;3,5;4;3;4,Withdrawn,0,0,,yes,9/28/20,HCL America,object detection;object recognition;deep learning;,-1,-1,m,NAN,NAN,n,2;1
8507,ICLR,2021,Cross-lingual Transfer Learning for Pre-trained Contextualized Language Models,Zuchao Li;Kevin Barry Parnow;hai zhao;Zhuosheng Zhang;Rui Wang;Masao Utiyama;Eiichiro Sumita,~Zuchao_Li1;~Kevin_Barry_Parnow1;~hai_zhao1;~Zhuosheng_Zhang1;~Rui_Wang10;~Masao_Utiyama2;~Eiichiro_Sumita1,4;4;4;4,4;4;4;3,Withdrawn,0,15,,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT)  National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT),transfer learning;pre-trained language models;contextualized language models;,29;29;29;29;29;-1;-1,100;100;100;100;100;-1;-1,m;m,NAN,NAN,n,6;3;4
8508,ICLR,2021,FSPN: A New Class of Probabilistic Graphical Model,Ziniu Wu;Rong Zhu;Andreas Pfadler;Yuxing Han;Jiangneng Li;Zhengping Qian;Kai Zeng;Jingren Zhou,~Ziniu_Wu1;~Rong_Zhu2;~Andreas_Pfadler1;~Yuxing_Han3;~Jiangneng_Li1;zhengping.qzp@alibaba-inc.com;zengkai.zk@alibaba-inc.com;~Jingren_Zhou1,4;5;7;4,5;4;5;5,Withdrawn,0,17,,yes,9/28/20,University of Oxford;;;;;;;Alibaba,FSPN;Probabilistic Graphical Model;Bayesian Network;Sum-Product Network;,46;-1;-1;-1;-1;-1;-1;-1,1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n,11;10
8509,ICLR,2021,S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric Learning,Karsten Roth;Timo Milbich;Bj√∂rn Ommer;Joseph Paul Cohen;Marzyeh Ghassemi,~Karsten_Roth1;~Timo_Milbich2;~Bj√∂rn_Ommer2;~Joseph_Paul_Cohen1;~Marzyeh_Ghassemi1,4;6;7;4,4;4;5;5,Withdrawn,0,12,,yes,9/28/20,University of Tuebingen;Heidelberg University;Heidelberg University;Stanford University;University of Toronto,Deep Metric Learning;Representation Learning;,128;209;209;5;18,78;42;42;2;18,m;f,canada,ca,n,6;1
8510,ICLR,2021,Graph Convolutional Value Decomposition in Multi-Agent Reinforcement Learning,Navid Naderializadeh;Fan H. Hung;Sean Soleyman;Deepak Khosla,~Navid_Naderializadeh1;fhhung.ven@hrl.com;ssoleyman@hrl.com;dkhosla@hrl.com,5;3;4;4,5;4;4;4,Withdrawn,0,0,,yes,9/28/20,"HRL Laboratories;;;HRL Laboratories, LLC;University of Southern California",multi-agent deep reinforcement learning;graph neural networks;value function factorization;attention mechanisms;,-1;-1;-1;-1;37,-1;-1;-1;-1;53,m;m,usa,usa,n,8;10
8511,ICLR,2021,Fast Estimation for Privacy and Utility in Differentially Private Machine Learning,Yuzhe Li;Yong Liu;Weipinng Wang;Bo Li;Nan Liu,~Yuzhe_Li1;~Yong_Liu7;~Weipinng_Wang1;~Bo_Li22;liunan@iie.ac.cn,4;5;3;5,5;3;4;5,Withdrawn,0,30,,yes,9/28/20,Institute of Information Engineering  Chinese Academy of Sciences;;;;Institute of Information Engineering  Chinese Academy of Sciences,machine learning;privacy;parameter selection;,34;-1;-1;-1;34,-1;-1;-1;-1;-1,m;f,NAN,NAN,y,1
8512,ICLR,2021,Robust Memory Augmentation by Constrained Latent Imagination,Yao Mu;Yuzheng Zhuang;Bin Wang;Wulong Liu;Shengbo Eben Li;Jianye HAO,~Yao_Mu1;~Yuzheng_Zhuang1;~Bin_Wang12;~Wulong_Liu1;~Shengbo_Eben_Li1;~Jianye_HAO1,3;7;4;5,4;3;3;5,Withdrawn,0,10,,yes,9/28/20,"Tsinghua University, Tsinghua University;Huawei Technologies Ltd.;Huawei Noah's Ark Lab;Huawei Noah's Ark Lab;Tsinghua University, Tsinghua University;Tianjin University",Memory Augmentation;Model-based reinforcement learning;Latent imagination;,4;-1;-1;-1;4;-1,20;-1;-1;-1;20;496,m;m,asia,cn,y,1
8513,ICLR,2021,BURT: BERT-inspired Universal Representation from Learning Meaningful Segment,Yian Li;hai zhao,~Yian_Li1;~hai_zhao1,4;6;3;4;3,3;4;4;4;4,Withdrawn,0,6,,yes,9/28/20,Shanghai Jiao Tong University;Shanghai Jiao Tong University,language modeling;,29;29,100;100,f;m,asia,cn,n,3
8514,ICLR,2021,Subformer: A Parameter Reduced Transformer,Machel Reid;Edison Marrese-Taylor;Yutaka Matsuo,~Machel_Reid1;~Edison_Marrese-Taylor2;~Yutaka_Matsuo1,6;4;4,5;4;4,Withdrawn,1,13,,yes,9/28/20,"The University of Tokyo;AIST, National Institute of Advanced Industrial Science and Technology;The University of Tokyo",transformers;sequence modeling;machine translation;efficiency;,71;-1;71,36;-1;36,m;m,NAN,NAN,n,8;3
8515,ICLR,2021,Recurrently Controlling a Recurrent Network with Recurrent Networks Controlled by More Recurrent Networks,Yi Tay;Yikang Shen;Alvin Chan;Aston Zhang;Shuai Zhang,~Yi_Tay1;~Yikang_Shen1;~Alvin_Chan1;~Aston_Zhang2;~Shuai_Zhang7,4;3;6;5,3;5;4;4,Withdrawn,0,0,,yes,9/28/20,Google;University of Montreal;Nanyang Technological University;AWS;Swiss Federal Institute of Technology,Deep Learning;Recurrent Neural Networks;,-1;128;44;209;-1,-1;73;47;-1;-1,m;m,NAN,NAN,n,3
8516,ICLR,2021,Information-theoretic Vocabularization via Optimal Transport for Machine Translation,Jingjing Xu;Hao Zhou;Chun Gan;Zaixiang Zheng;Lei Li,~Jingjing_Xu1;zhouhao.nlp@bytedance.com;ganchun@bytedance.com;~Zaixiang_Zheng2;~Lei_Li11,4;3;3;4,5;4;5;2,Withdrawn,0,5,,yes,9/28/20,Peking University;Bytedance;;Nanjing University;ByteDance AI Lab,Vocabulary Construction;NLP;,14;-1;-1;52;-1,23;-1;-1;111;-1,f;m,NAN,NAN,n,3
8517,ICLR,2021,Accurate Word Representations with Universal Visual Guidance,Haojie Yu;Zhuosheng Zhang;hai zhao;Rui Wang;Masao Utiyama,hudiefeiafei@sjtu.edu.cn;~Zhuosheng_Zhang1;~hai_zhao1;~Rui_Wang10;~Masao_Utiyama2,4;4;4;3,4;5;4;4,Withdrawn,0,7,,yes,9/28/20,"Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology",Natural Language Processing;Visual Representation;Multimodal Language Representation;Natural Language Understanding;,29;29;29;29;-1,100;100;100;100;-1,m;m,NAN,NAN,n,3;8;1
8518,ICLR,2021,Generating Landmark Navigation Instructions from Maps as a Graph-to-Text Problem,Raphael Schumann;Stefan Riezler,~Raphael_Schumann2;~Stefan_Riezler1,4;6;5;5,5;3;4;4,Withdrawn,0,7,,yes,9/28/20,"Heidelberg University;Heidelberg University, Germany",natural language processing;graph neural network;graph-to-text;geographical navigation;,209;209,42;42,m;m,NAN,NAN,n,3;10
8519,ICLR,2021,Model-Free Energy Distance for Pruning DNNs,Mohammadreza Soltani;Suya Wu;Yuerong Li;Jie Ding;Vahid Tarokh,~Mohammadreza_Soltani1;~Suya_Wu1;yuerong.li@duke.edu;~Jie_Ding2;~Vahid_Tarokh1,3;5;5;5,5;3;4;4,Withdrawn,0,4,,yes,9/28/20,"Duke University;Duke University;Duke University;University of Minnesota, Minneapolis;Duke University",Pruning;Residual Networks;Structured Method;Energy Distance;,46;46;46;71;46,20;20;20;85;20,m;m,europe,se,n,
8520,ICLR,2021,Hierarchical Binding in Convolutional Neural Networks Confers Adversarial Robustness,Niels Leadholm;Simon Stringer,~Niels_Leadholm1;simon.stringer@psy.ox.ac.uk,3;4;5;5,3;4;3;3,Withdrawn,0,8,,yes,9/28/20,University of Oxford;University of Oxford,adversarial examples;robust representations;feature binding;,46;46,1;1,m;m,europe,uk,n,4
8521,ICLR,2021,RNA Alternative Splicing Prediction with Discrete Compositional Energy Network,Alvin Chan;Anna Korsakova;Yew-Soon Ong;Fernaldo Richtia Winnerdy;Kah Wai Lim;Anh Tuan Phan,~Alvin_Chan1;kors0001@e.ntu.edu.sg;~Yew-Soon_Ong1;fernaldo.winnerdy@ntu.edu.sg;kwlim@ntu.edu.sg;phantuan@ntu.edu.sg,3;4;4;4,4;5;4;5,Withdrawn,0,0,,yes,9/28/20,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;;Nanyang Technological University,RNA splicing;Computational Biology;RNA;,44;44;44;44;-1;44,47;47;47;47;-1;47,m;m,asia,sg,y,
8522,ICLR,2021,Provable Acceleration of Wide Neural Net Training via Polyak's Momentum,Jun-Kun Wang;Jacob Abernethy,~Jun-Kun_Wang1;~Jacob_Abernethy1,7;5;4;6,2;3;4;2,Withdrawn,0,12,,yes,9/28/20,Georgia Institute of Technology;Georgia Tech Research Corporation,,12;-1,38;-1,m;m,NAN,NAN,y,1
8523,ICLR,2021,Scaling Unsupervised Domain Adaptation through Optimal Collaborator Selection and Lazy Discriminator Synchronization,Akhil Mathur;Shaoduo Gan;Anton Isopoussu;Fahim Kawsar;Nadia Berthouze;Nicholas Donald Lane,~Akhil_Mathur1;~Shaoduo_Gan1;~Anton_Isopoussu1;fahim.kawsar@nokia-bell-labs.com;~Nadia_Berthouze1;~Nicholas_Donald_Lane1,6;6;2,3;5;4,Withdrawn,0,1,,yes,9/28/20,"University College London;Swiss Federal Institute of Technology;;;;University College London;Department of Computer Science, University of Oxford",unsupervised domain adaptation;systems for machine learning;,53;-1;-1;-1;-1;53;46,-1;-1;-1;-1;-1;-1;1,m;m,NAN,NAN,y,8;4
8524,ICLR,2021,Diversity Augmented Conditional Generative Adversarial Network for Enhanced Multimodal Image-to-Image Translation,Yunlong MENG;Lin Xu,~Yunlong_MENG1;~Lin_Xu2,5;5;5;4,4;4;3;4,Withdrawn,0,0,,yes,9/28/20,"Em-Data Technology;the Institute of Artificial Intelligence, Shanghai Em-Data Technology Co., Ltd.",Conditional Generative Adversarial Network;Multimodal Image-to-Image Translation;,-1;-1,-1;-1,m;m,NAN,NAN,n,5;4
8525,ICLR,2021,Unsupervised Word Alignment via Cross-Lingual  Contrastive Learning,Di Wu;Liang Ding;Shuo Yang;Dacheng Tao,~Di_Wu8;~Liang_Ding3;~Shuo_Yang7;~Dacheng_Tao1,5;4;6;5,5;4;4;4,Withdrawn,0,8,,yes,9/28/20,"Peking University;University of Sydney;The University of Sydney, University of Sydney;JD.com",,14;71;71;-1,23;51;51;-1,m;m,NAN,NAN,y,8
8526,ICLR,2021,Non-Asymptotic PAC-Bayes Bounds on Generalisation Error,Arijit Das,~Arijit_Das2,4;4;5;4;5,2;2;3;4;3,Withdrawn,0,5,,yes,9/28/20,University of Cologne,PAC-Bayes Bounds;Large Deviation Theory;Concentration Inequalities;Generalisation Error;,-1,145,m,NAN,NAN,n,1
8527,ICLR,2021,AdaS: Adaptive Scheduling of Stochastic Gradients,Mahdi S. Hosseini;Konstantinos N Plataniotis,~Mahdi_S._Hosseini1;~Konstantinos_N_Plataniotis1,4;5;4;3,3;3;4;5,Withdrawn,0,9,,yes,9/28/20,University of New Brunswick;Toronto University,Adaptive Stochastic Optimization;Deep Convolution Neural Network;Low-Rank Factorization;,453;-1,849;-1,m;m,NAN,NAN,y,1
8528,ICLR,2021,Towards Robust Textual Representations with Disentangled Contrastive Learning,Ningyu Zhang;Xiang Chen;Xin Xie;Shumin Deng;Yantao Jia;Zonggang Yuan;Huajun Chen,~Ningyu_Zhang1;~Xiang_Chen5;~Xin_Xie2;~Shumin_Deng1;~Yantao_Jia1;~Zonggang_Yuan1;~Huajun_Chen1,4;3;5;3,4;3;4;4,Withdrawn,0,0,,yes,9/28/20,"Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Institute of Computing Technology, Chinese Academy of Sciences;Southeast University,;;Zhejiang University;Zhejiang University",Robustness;Contrastive Learning;Textual Representation Learning;Natural Language Processing;,42;42;42;42;34;-1;-1;42;42,94;94;94;94;-1;509;-1;94;94,m;m,asia,cn,n,8;3;4
8529,ICLR,2021,DeepLTRS: A Deep Latent Recommender System based on User Ratings and Reviews,Dingge LIANG;Marco Corneli;pierre Latouche;Charles Bouveyron,~Dingge_LIANG1;~Marco_Corneli1;pierre.latouche@parisdescartes.fr;~Charles_Bouveyron2,5;3;5;4,3;3;5;4,Withdrawn,0,0,,yes,9/28/20,universite cote d'azur;Universit√© Cote d'Azur;;;Universit√© C√¥te d'Azur,representation learning for recommender system;optimization for representation learning;variational auto-encoder;topic modeling;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n,5
8530,ICLR,2021,HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis,Jiawei Chen;Xu Tan;Jian luan;Tao Qin;Tie-Yan Liu,~Jiawei_Chen4;~Xu_Tan1;jianluan@microsoft.com;~Tao_Qin1;~Tie-Yan_Liu1,3;3;6;5,5;4;5;5,Withdrawn,0,0,,yes,9/28/20,"South China University of Technology, Tsinghua University;Microsoft;;;Tsinghua University;Microsoft",singing voice synthesis;high-fidelity;adversarial training;high sampling rate;,4;-1;-1;-1;4;-1,20;-1;-1;-1;20;-1,m;m,NAN,NAN,n,5;4
8531,ICLR,2021,MAS-GAN: Adversarial Calibration of Multi-Agent Market Simulators.,Victor Storchan;Svitlana Vyetrenko;Tucker Balch,victor.storchan@jpmchase.com;~Svitlana_Vyetrenko1;~Tucker_Balch2,5;3;7,5;4;4,Reject,0,4,0.0,yes,9/28/20,Stanford University;J.P. Morgan Chase;Georgia Institute of Technology,Generative adversarial networks;multi-agent systems.;,5;-1;12,2;-1;38,m;m,usa,usa,n,8;5
8532,ICLR,2021,On the Capability of CNNs to Generalize to Unseen Category-Viewpoint Combinations,Spandan Madan;Timothy Henry;Jamell Arthur Dozier;Helen Ho;Nishchal Bhandari;Tomotake Sasaki;Fredo Durand;Hanspeter Pfister;Xavier Boix,~Spandan_Madan1;timhenry@mit.edu;~Jamell_Arthur_Dozier1;helenwh@mit.edu;nishchalb@alum.mit.edu;~Tomotake_Sasaki1;~Fredo_Durand1;~Hanspeter_Pfister1;~Xavier_Boix1,6;6;4;7,3;3;4;5,Reject,0,5,0.0,yes,9/28/20,Harvard University;;;Massachusetts Institute of Technology;;;;;Fujitsu Limited;Massachusetts Institute of Technology;Harvard University;Massachusetts Institute of Technology,systematic generalization;category-viewpoint classification;multi-task learning;,53;-1;-1;5;-1;-1;-1;-1;-1;5;53;5,3;-1;-1;4;-1;-1;-1;-1;-1;4;3;4,m;m,usa,usa,n,1
8533,ICLR,2021,Collaborative Normalization for Unsupervised Domain Adaptation,Haifeng Xia;TAOTAO JING;Zhengming Ding,~Haifeng_Xia2;~TAOTAO_JING1;~Zhengming_Ding4,4;6;5,5;4;4,Reject,0,0,0.0,yes,9/28/20,"Tulane University;Tulane University;Indiana University, Bloomington",,209;209;64,302;302;140,m;m,NAN,NAN,n,9
8534,ICLR,2021,On Effective Parallelization of Monte Carlo Tree Search,Anji Liu;Yitao Liang;Ji Liu;Guy Van den Broeck;Jianshu Chen,~Anji_Liu1;~Yitao_Liang1;~Ji_Liu1;~Guy_Van_den_Broeck1;~Jianshu_Chen1,6;6;7;7,3;4;3;1,Reject,0,5,0.0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;Kwai Inc.;University of California, Los Angeles;Tencent AI Lab",parallel Monte Carlo Tree Search (MCTS);Upper Confidence bound for Trees (UCT);Reinforcement Learning (RL);,-1;-1;-1;-1;-1,15;15;-1;15;-1,m;m,NAN,NAN,y,
8535,ICLR,2021,Temperature Regret Matching for Imperfect-Information Games,Enmin Zhao;Kai Li;Junliang Xing,zhaoenmin2018@ia.ac.cn;~Kai_Li2;~Junliang_Xing1,3;2;6,3;5;3,Reject,0,0,0.0,yes,9/28/20,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences",regret matching;counterfactual regret minimization;imperfect-information games;regret updating;,34;34;34;34,-1;-1;-1;-1,u;m,asia,cn,n,
8536,ICLR,2021,Conditioning Trick for Training Stable GANs,MOHAMMAD ESMAEILPOUR;Raymel Alfonso Sallo;Olivier St-Georges;Patrick Cardinal;Alessandro Lameiras Koerich,~MOHAMMAD_ESMAEILPOUR1;raymel.alfonso-sallo.1@ens.etsmtl.ca;olivier.st-georges.1@ens.etsmtl.ca;~Patrick_Cardinal1;alessandro.lameiraskoerich@etsmtl.ca,4;3;5;3,3;5;3;2,Reject,0,4,0.0,yes,9/28/20,√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;University of Montreal;√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure,Generative Adversarial Network;Departure From Normality;Schur Decomposition;Spectrogram Synthesis;,-1;-1;128;-1;-1,-1;-1;73;-1;-1,m;m,NAN,NAN,n,5
8537,ICLR,2021,Wasserstein Distributionally Robust Optimization: A Three-Player Game Framework,Zhuozhuo Tu;Shan You;Tao Huang;Dacheng Tao,~Zhuozhuo_Tu1;~Shan_You3;~Tao_Huang5;~Dacheng_Tao1,5;5;4;5;6,3;4;3;3;3,Reject,0,6,0.0,yes,9/28/20,The University of Sydney;Tsinghua University;SenseTime;JD.com,,71;4;-1;-1,51;20;-1;-1,u;m,NAN,NAN,y,8;1
8538,ICLR,2021,The Skill-Action Architecture: Learning Abstract Action Embeddings for Reinforcement Learning,Chang Li;Dongjin Song;Dacheng Tao,~Chang_Li5;~Dongjin_Song2;~Dacheng_Tao1,5;4;5,4;4;3,Reject,0,4,0.0,yes,9/28/20,University of Sydney;University of Connecticut;JD.com,Hierarchical Reinforcement Learning;Reinforcement Learning;,71;174;-1,51;440;-1,u;m,NAN,NAN,y,6;8
8539,ICLR,2021,Information-Theoretic Odometry Learning,Sen Zhang;Jing Zhang;Dacheng Tao,~Sen_Zhang3;~Jing_Zhang17;~Dacheng_Tao1,6;5;5,3;2;3,Reject,0,4,0.0,yes,9/28/20,"The University of Sydney, University of Sydney;University of Sydney;JD.com",Odometry Learning;Information Bottleneck;Generalization Bound;,71;71;-1,51;51;-1,m;m,NAN,NAN,y,1
8540,ICLR,2021,GenAD: General Representations of Multivariate Time Series for Anomaly Detection,Xiaolei Hua;Su Wang;Lin Zhu;Dong Zhou;Junlan Feng;Yiting Wang;Chao Deng;Shuo Wang;Mingtao Mei,~Xiaolei_Hua1;~Su_Wang1;~Lin_Zhu6;~Dong_Zhou1;~Junlan_Feng2;~Yiting_Wang1;~Chao_Deng3;~Shuo_Wang12;~Mingtao_Mei1,3;5;4,4;4;3,Reject,0,3,0.0,yes,9/28/20,Beijing University of Chemical Technology;Beijing University of Post and Telecommunication;China Mobile research institute;Beijing University of Post and Telecommunication;;University of Manchester;;Beijing University of Posts and Telecommunications;China Mobile,Anomaly Detection;Multivariate Time Series;General Representations;,-1;-1;-1;-1;-1;263;-1;-1;-1,588;-1;-1;-1;-1;51;-1;-1;-1,u;u,NAN,NAN,n,8
8541,ICLR,2021,Streamlining EM into Auto-Encoder Networks,Yuangang Pan;Ivor Tsang,~Yuangang_Pan2;~Ivor_Tsang1,7;6;5;6,4;5;5;4,Reject,0,8,0.0,yes,9/28/20,University of Technology Sydney;University of Technology Sydney,Deep Clustering;Differentiable EM;,71;71,160;160,m;m,australasia,au,n,
8542,ICLR,2021,RETHINKING LOCAL LOW RANK MATRIX DETECTION:A MULTIPLE-FILTER BASED NEURAL NETWORK FRAMEWORK,Pengtao Dang;Wennan Chang;Haiqi Zhu;Changlin Wan;Tong Zhao;Tingbo Guo;Paul Salama;Sha Cao;Chi Zhang,~Pengtao_Dang1;chang534@purdue.edu;haiqzhu@iu.edu;~Changlin_Wan1;zhaoton@amazon.com;guotingbo.tbg@foxmail.com;~Paul_Salama1;robincaosha@gmail.com;czhang87@iu.edu,5;3;4,5;3;3,Reject,0,5,0.0,yes,9/28/20,"Purdue University;Purdue University;Purdue University;Purdue University;Amazon;;;Indiana University/Purdue University at Indianapolis;Indiana University, School of Medicine;Indiana University, Bloomington",Matrix decomposition;Local Low Rank matrix detection;Representation learning;Subspace learning;,23;23;23;23;-1;-1;-1;23;64;64,94;94;94;94;-1;-1;-1;140;140;140,m;m,NAN,NAN,y,2
8543,ICLR,2021,Optimizing Quantized Neural Networks in a Weak Curvature Manifold,Jun Chen;Hanwen Chen;Jiangning Zhang;Wenzhou Chen;Yong Liu;Yunliang Jiang,~Jun_Chen9;chenhanwen@zju.edu.cn;~Jiangning_Zhang1;wenzhouchen@zju.edu.cn;~Yong_Liu11;~Yunliang_Jiang2,5;3;5;3,4;4;3;5,Reject,0,4,0.0,yes,9/28/20,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Huzhou University,Deep learning;Neural network quantization;Information geometry;,42;42;42;42;42;-1,94;94;94;94;94;831,m;m,NAN,NAN,n,
8544,ICLR,2021,A New Variant of Stochastic Heavy ball Optimization Method for Deep Learning,Zhou Shao;Tong Lin,~Zhou_Shao1;~Tong_Lin1,6;3;4,3;4;4,Reject,0,0,0.0,yes,9/28/20,Peking University;Peking University,,14;14,23;23,u;m,asia,cn,y,1;9
8545,ICLR,2021,Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution,Zhaoyang Zhang;Wenqi Shao;Jinwei Gu;Xiaogang Wang;Ping Luo,~Zhaoyang_Zhang1;~Wenqi_Shao2;~Jinwei_Gu1;~Xiaogang_Wang2;~Ping_Luo2,6;4;6;5,4;5;5;4,Reject,0,0,0.0,yes,9/28/20,The Chinese University of Hong Kong;The Chinese University of Hong Kong;Columbia University;Chinese University of Hong Kong;The University of Hong Kong,,327;327;23;46;99,39;39;17;56;39,m;m,NAN,NAN,n,
8546,ICLR,2021,The 3TConv: An Intrinsic Approach to Explainable 3D CNNs,Gabrielle Ras;Luca Ambrogioni;Pim Haselager;Marcel van Gerven;Umut G√º√ßl√º,~Gabrielle_Ras1;~Luca_Ambrogioni1;w.haselager@donders.ru.nl;~Marcel_van_Gerven1;~Umut_G√º√ßl√º1,3;6;3;5,3;4;4;4,Reject,0,1,0.0,yes,9/28/20,"Radboud University Nijmegen;Radboud University Nijmegen;;;Donders Institute for Brain, Cognition and Behaviour;Radboud University Nijmegen",3dconv;convolution;neural network;explainability;interpretability;,209;209;-1;-1;-1;209,136;136;-1;-1;-1;136,f;m,NAN,NAN,n,
8547,ICLR,2021,Inner Ensemble Networks: Average Ensemble as an Effective Regularizer,Abduallah Mohamed;Muhammed Mohaimin Sadiq;Ehab AlBadawy;Mohamed Elhoseiny;Christian Claudel,~Abduallah_Mohamed1;m.mohaiminsadiq@utexas.edu;ealbadawy@albany.edu;~Mohamed_Elhoseiny1;~Christian_Claudel1,7;4;5;3,4;4;4;3,Reject,0,9,0.0,yes,9/28/20,"Facebook;University of Texas, Austin;State University of New York, Albany;KAUST;University of Texas at Austin",Regularize;ensemble;variance;reduction;,-1;-1;-1;110;20,-1;-1;-1;-1;43,m;m,usa,usa,n,
8548,ICLR,2021,Quantifying Uncertainty in Deep Spatiotemporal Forecasting,Dongxia Wu;Liyao Gao;Xinyue Xiong;Matteo Chinazzi;Alessandro Vespignani;Yian Ma;Rose Yu,~Dongxia_Wu1;~Liyao_Gao2;xiong.xin@northeastern.edu;~Matteo_Chinazzi1;~Alessandro_Vespignani1;~Yian_Ma1;~Rose_Yu1,5;4;4,4;5;5,Reject,0,4,0.0,yes,9/28/20,"University of California, San Diego;University of Washington, Seattle;Northeastern University;Northeastern University;Northeastern University;University of California, San Diego;University of California, San Diego",uncertainty quantification;deep learning;deep sequence models;spatiotemporal forecasting;bayesian uncertainty estimation;frequentist uncertainty estimation;traffic;COVID-19;,-1;11;16;16;16;-1;-1,33;29;895;895;895;33;33,m;f,usa,usa,y,11;1
8549,ICLR,2021,Recurrent Exploration Networks for Recommender Systems,Hao Wang;Yifei Ma;Hao Ding;Bernie Wang,~Hao_Wang3;~Yifei_Ma1;haodin@amazon.com;~Bernie_Wang1,5;5;4;4,3;4;3;3,Reject,0,7,0.0,yes,9/28/20,Rutgers University;Amazon;Amazon;AWS AI Labs,Recommender Systems;Recurrent Neural Networks;Deep Learning;,29;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y,
8550,ICLR,2021,Unsupervised Domain Adaptation via Minimized Joint Error,Dexuan Zhang;Tatsuya Harada,~Dexuan_Zhang1;~Tatsuya_Harada1,4;7;6;5,5;3;4;4,Reject,0,7,0.0,yes,9/28/20,"The University of Tokyo, Tokyo Institute of Technology;RIKEN",,71;-1,36;-1,m;m,NAN,NAN,pdf miss,1;4
8551,ICLR,2021,The Unreasonable Effectiveness of the Class-reversed Sampling in Tail Sample Memorization,Benyi Hu;Chi Zhang;Yuehu Liu;Le Wang;Li Liu,~Benyi_Hu1;colorzc@stu.xjtu.edu.cn;~Yuehu_Liu1;~Le_Wang1;~Li_Liu12,5;5;2;6,5;4;5;3,Reject,0,13,0.0,yes,9/28/20,"Xi'an Jiaotong University;Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University,;;Xi'an Jiaotong University;IIAI",long-tailed learning;re-sampling;sample memorization;,-1;-1;-1;-1;-1,445;-1;-1;445;-1,u;m,asia,in,n,1
8552,ICLR,2021,Withdraw,Zihao WANG;Xu Zhao;Tam Le;Hao Wu;Yong Zhang;Makoto Yamada,~Zihao_WANG6;zhaoxu18@mails.tsinghua.edu.cn;~Tam_Le2;hwu@tsinghua.edu.cn;zhangyong05@tsinghua.edu.cn;~Makoto_Yamada3,4;4;5;4,4;5;4;4,Withdrawn,0,0,,yes,9/28/20,The Hong Kong University of Science and Technology;Kyoto University,,263;58,51;239,m;m,europe,uk,pdf miss,
