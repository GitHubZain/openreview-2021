ICLR,2020,Policy path programming,Daniel McNamee,daniel.c.mcnamee@gmail.com,3;3;3;1,,Reject,0,1,0,yes,9/25/19,causaLens,markov decision process;planning;hierarchical;reinforcement learning,-1,-1,m;m,NAN,NAN,n
ICLR,2020,Meta-Learning Deep Energy-Based Memory Models,Sergey Bartunov;Jack Rae;Simon Osindero;Timothy Lillicrap,bartunov@google.com;jwrae@google.com;osindero@google.com;countzero@google.com,6;6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Google;Google;Google;Google,associative memory;energy-based memory;meta-learning;compressive memory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories,Tiange Luo;Kaichun Mo;Zhiao Huang;Jiarui Xu;Siyu Hu;Liwei Wang;Hao Su,luotg@pku.edu.cn;kaichun@cs.stanford.edu;z2huang@eng.ucsd.edu;jxuat@connect.ust.hk;sy89128@mail.ustc.edu.cn;wanglw@cis.pku.edu.cn;haosu@eng.ucsd.edu,8;6;3,,Accept (Poster),1,5,0,yes,9/25/19,"Peking University;Stanford University;University of California, San Diego;The Hong Kong University of Science and Technology;University of Science and Technology of China;Peking University;University of California, San Diego",Shape Segmentation;Zero-Shot Learning;Learning Representations,14;5;-1;-1;-1;14;-1,24;4;31;47;80;24;31,m;m,usa,usa,n
ICLR,2020,VL-BERT: Pre-training of Generic Visual-Linguistic Representations,Weijie Su;Xizhou Zhu;Yue Cao;Bin Li;Lewei Lu;Furu Wei;Jifeng Dai,jackroos@mail.ustc.edu.cn;ezra0408@mail.ustc.edu.cn;yuecao@microsoft.com;binli@ustc.edu.cn;lewlu@microsoft.com;fuwei@microsoft.com;jifdai@microsoft.com,3;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;Microsoft;University of Science and Technology of China;Microsoft;Microsoft;Microsoft,Visual-Linguistic;Generic Representation;Pre-training,-1;-1;-1;-1;-1;-1;-1,80;80;-1;80;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Episodic Reinforcement Learning with Associative Memory,Guangxiang Zhu*;Zichuan Lin*;Guangwen Yang;Chongjie Zhang,guangxiangzhu@outlook.com;linzc16@mails.tsinghua.edu.cn;ygw@tsinghua.edu.cn;chongjie@tsinghua.edu.cn,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Deep Reinforcement Learning;Episodic Control;Episodic Memory;Associative Memory;Non-Parametric Method;Sample Efficiency,-1;4;4;4,-1;23;23;23,m;m,NAN,NAN,n
ICLR,2020,Independence-aware Advantage Estimation,Pushi Zhang;Li Zhao;Guoqing Liu;Jiang Bian;Minglie Huang;Tao Qin;Tie-Yan Liu,zpschang@gmail.com;lizo@microsoft.com;lgq1001@mail.ustc.edu.cn;jiang.bian@microsoft.com;aihuang@mails.tsinghua.edu.cn;taoqin@microsoft.com;tie-yan.liu@microsoft.com,6;6;3,,Reject,0,7,0,yes,9/25/19,"Tsinghua University;Microsoft;University of Science and Technology of China;Microsoft;Tsinghua University, Tsinghua University;Microsoft;Microsoft",Reinforcement Learning;Advantage Estimation,-1;-1;-1;-1;4;-1;-1,-1;-1;80;-1;23;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets,Mingrui Liu;Youssef Mroueh;Jerret Ross;Wei Zhang;Xiaodong Cui;Payel Das;Tianbao Yang,mingrui-liu@uiowa.edu;mroueh@us.ibm.com;rossja@us.ibm.com;weiz@us.ibm.com;cuix@us.ibm.com;daspa@us.ibm.com;tianbao-yang@uiowa.edu,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Iowa;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Iowa,Generative Adversarial Nets;Adaptive Gradient Algorithms,168;-1;-1;-1;-1;-1;168,227;-1;-1;-1;-1;-1;227,m;m,europe,de,y
ICLR,2020,Understanding Attention Mechanisms,Bingyuan Liu;Yogesh Balaji;Lingzhou Xue;Martin Renqiang Min,bul37@psu.edu;yogesh@cs.umd.edu;lzxue@psu.edu;renqiang@nec-labs.com,6;3;3,,Reject,0,5,0,yes,9/25/19,"Pennsylvania State University;University of Maryland, College Park;Pennsylvania State University;NEC-Labs",Attention;deep learning;sample complexity;self-attention,43;12;43;-1,-1;91;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Defending Against Adversarial Examples by Regularized Deep Embedding,Yao Li;Martin Renqiang Min;Wenchao Yu;Cho-Jui Hsieh;Thomas Lee;Erik Kruus,yaoli@ucdavis.edu;renqiang@nec-labs.com;yuwenchao@ucla.edu;chohsieh@cs.ucla.edu;tcmlee@ucdavis.edu;kruus@nec-labs.com,3;1;6,,Reject,2,11,0,yes,9/25/19,"University of California, Davis;NEC-Labs;University of California, Los Angeles;University of California, Los Angeles;University of California, Davis;NEC-Labs",,-1;-1;-1;-1;-1;-1,55;-1;17;17;55;-1,f;m,NAN,NAN,y
ICLR,2020,A Learning-based Iterative Method for Solving Vehicle Routing Problems,Hao Lu;Xingwen Zhang;Shuang Yang,haolu@princeton.edu;xingwen.zhang@antfin.com;shuang.yang@antfin.com,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Princeton University;Antfin;Antfin,vehicle routing;reinforcement learning;optimization;heuristics,30;-1;-1,6;-1;-1,m;m,NAN,NAN,n
ICLR,2020,GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations,Martin Engelcke;Adam R. Kosiorek;Oiwi Parker Jones;Ingmar Posner,martin@robots.ox.ac.uk;adamk@robots.ox.ac.uk;oiwi@robots.ox.ac.uk;ingmar@robots.ox.ac.uk,8;6;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Generative modelling;object-centric representations;scene generation;variational inference,46;46;46;46,1;1;1;1,m;m,europe,uk,n
ICLR,2020,Robust training with ensemble consensus,Jisoo Lee;Sae-Young Chung,jisoolee@kaist.ac.kr;schung@kaist.ac.kr,3;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Annotation noise;Noisy label;Robustness;Ensemble;Perturbation,-1;-1,110;110,f;m,NAN,NAN,n
ICLR,2020,Selection via Proxy: Efficient Data Selection for Deep Learning,Cody Coleman;Christopher Yeh;Stephen Mussmann;Baharan Mirzasoleiman;Peter Bailis;Percy Liang;Jure Leskovec;Matei Zaharia,cody@cs.stanford.edu;chrisyeh@stanford.edu;mussmann@stanford.edu;baharanm@stanford.edu;pbailis@cs.stanford.edu;pliang@cs.stanford.edu;jure@cs.stanford.edu;matei@cs.stanford.edu,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,data selection;active-learning;core-set selection;deep learning;uncertainty sampling,5;5;5;5;5;5;5;5,4;4;4;4;4;4;4;4,m;m,usa,usa,n
ICLR,2020,Estimating Gradients for Discrete Random Variables by Sampling without Replacement,Wouter Kool;Herke van Hoof;Max Welling,w.w.m.kool@uva.nl;h.c.vanhoof@uva.nl;m.welling@uva.nl,6;8;6,,Accept (Spotlight),0,6,0,yes,9/25/19,University of Amsterdam;University of Amsterdam;University of Amsterdam,gradient;estimator;discrete;categorical;sampling;without replacement;reinforce;baseline;variance;gumbel;vae;structured prediction,143;143;143,62;62;62,m;m,europe,nl,y
ICLR,2020,Graph Neural Networks Exponentially Lose Expressive Power for Node Classification,Kenta Oono;Taiji Suzuki,kenta_oono@mist.i.u-tokyo.ac.jp;taiji@mist.i.u-tokyo.ac.jp,8;6;8,,Accept (Spotlight),1,3,2,yes,9/25/19,The University of Tokyo;The University of Tokyo,Graph Neural Network;Deep Learning;Expressive Power,64;64,36;36,m;m,NAN,NAN,y
ICLR,2020,Accelerating SGD with momentum for over-parameterized learning,Chaoyue Liu;Mikhail Belkin,liu.2656@buckeyemail.osu.edu;mbelkin@cse.ohio-state.edu,3;8;8,,Accept (Poster),0,3,0,yes,9/25/19,"Ohio State University;University of California, San Diego",SGD;acceleration;momentum;stochastic;over-parameterized;Nesterov,59;-1,70;31,u;m,usa,usa,y
ICLR,2020,On the Equivalence between Positional Node Embeddings and Structural Graph Representations,Balasubramaniam Srinivasan;Bruno Ribeiro,bsriniv@purdue.edu;ribeiro@cs.purdue.edu,8;8;6,,Accept (Poster),0,8,3,yes,9/25/19,Purdue University;Purdue University,Graph Neural Networks;Structural Graph Representations;Node Embeddings;Relational Learning;Invariant Theory;Theory;Deep Learning;Representational Power;Graph Isomorphism,24;24,88;88,m;m,usa,usa,y
ICLR,2020,Robustness Verification for Transformers,Zhouxing Shi;Huan Zhang;Kai-Wei Chang;Minlie Huang;Cho-Jui Hsieh,zhouxingshichn@gmail.com;huan@huan-zhang.com;kw@kwchang.net;aihuang@tsinghua.edu.cn;chohsieh@cs.ucla.edu,3;6;6,,Accept (Poster),0,4,0,yes,9/25/19,"University of California, Los Angeles;Carnegie Mellon University;University of California-Los Angeles;Tsinghua University, Tsinghua University;University of California, Los Angeles",Robustness;Verification;Transformers,-1;1;-1;4;-1,17;27;17;23;17,m;m,usa,usa,n
ICLR,2020,DDSP: Differentiable Digital Signal Processing,Jesse Engel;Lamtharn (Hanoi) Hantrakul;Chenjie Gu;Adam Roberts,jesseengel@google.com;hanoih@google.com;gcj@google.com;adarob@google.com,6;8;8,,Accept (Spotlight),0,9,4,yes,9/25/19,Google;Google;Google;Google,dsp;audio;music;nsynth;wavenet;wavernn;vocoder;synthesizer;sound;signal;processing;tensorflow;autoencoder;disentanglement,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning,Weihao Yu;Zihang Jiang;Yanfei Dong;Jiashi Feng,weihaoyu6@gmail.com;jzihang@u.nus.edu;yanfei.dong43@gmail.com;elefjia@nus.edu.sg,6;8;6,,Accept (Poster),0,5,0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;National University of Singapore,reading comprehension;logical reasoning;natural language processing,17;17;17;17,25;25;25;25,m;m,asia,sg,n
ICLR,2020,Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks,Haoran You;Chaojian Li;Pengfei Xu;Yonggan Fu;Yue Wang;Xiaohan Chen;Richard G. Baraniuk;Zhangyang Wang;Yingyan Lin,hy34@rice.edu;cl114@rice.edu;px5@rice.edu;yf22@rice.edu;yw68@rice.edu;chernxh@tamu.edu;richb@rice.edu;atlaswang@tamu.edu;yingyan.lin@rice.edu,8;6;6,,Accept (Spotlight),0,6,0,yes,9/25/19,Rice University;Rice University;Rice University;Rice University;Rice University;Texas A&M;Rice University;Texas A&M;Rice University,,92;92;92;92;92;46;92;46;92,105;105;105;105;105;177;105;177;105,m;f,australasia,au,n
ICLR,2020,Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning,Arsenii Ashukha;Alexander Lyzhov;Dmitry Molchanov;Dmitry Vetrov,ars.ashuha@gmail.com;alex.grig.lyzhov@gmail.com;dmolch111@gmail.com;vetrovd@yandex.ru,6;8;6,,Accept (Poster),0,6,1,yes,9/25/19,Samsung;Center for Long-Term Risk;Samsung;Higher School of Economics,uncertainty;in-domain uncertainty;deep ensembles;ensemble learning;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Theory of Usable Information under Computational Constraints,Yilun Xu;Shengjia Zhao;Jiaming Song;Russell Stewart;Stefano Ermon,xuyilun@pku.edu.cn;sjzhao@stanford.edu;tsong@cs.stanford.edu;russell.sb.nebel@gmail.com;ermon@cs.stanford.edu,8;8,,Accept (Talk),0,3,0,yes,9/25/19,Peking University;Stanford University;Stanford University;;Stanford University,,14;5;5;-1;5,24;4;4;-1;4,m;m,usa,usa,y
ICLR,2020,An Inductive Bias for Distances: Neural Nets that Respect the Triangle Inequality,Silviu Pitis;Harris Chan;Kiarash Jamali;Jimmy Ba,spitis@cs.toronto.edu;hchan@cs.toronto.edu;kiarash.jamali@mail.utoronto.ca;jba@cs.toronto.edu,8;3;8;8,,Accept (Poster),0,6,0,yes,9/25/19,University of Toronto;University of Toronto;Toronto University;University of Toronto,metric learning;deep metric learning;neural network architectures;triangle inequality;graph distances,18;18;-1;18,18;18;-1;18,m;m,canada,ca,y
ICLR,2020,Stochastic AUC Maximization with Deep Neural Networks,Mingrui Liu;Zhuoning Yuan;Yiming Ying;Tianbao Yang,mingrui-liu@uiowa.edu;zhuoning-yuan@uiowa.edu;yying@albany.edu;tianbao-yang@uiowa.edu,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,"University of Iowa;University of Iowa;State University of New York, Albany;University of Iowa",Stochastic AUC Maximization;Deep Neural Networks,168;168;-1;168,227;227;350;227,m;m,europe,de,y
ICLR,2020,Convolutional Conditional Neural Processes,Jonathan Gordon;Wessel P. Bruinsma;Andrew Y. K. Foong;James Requeima;Yann Dubois;Richard E. Turner,jg801@cam.ac.uk;wpb23@cam.ac.uk;ykf21@cam.ac.uk;jrr41@cam.ac.uk;yanndubois96@gmail.com;ret26@cam.ac.uk,8;8;6,,Accept (Talk),0,7,0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge;University of Toronto;University of Cambridge,Neural Processes;Deep Sets;Translation Equivariance,79;79;79;79;18;79,3;3;3;3;18;3,m;m,europe,uk,y
ICLR,2020,On the interaction between supervision and self-play in emergent communication,Ryan Lowe*;Abhinav Gupta*;Jakob Foerster;Douwe Kiela;Joelle Pineau,rlowe1@cs.mcgill.ca;abhinav.gupta@umontreal.ca;jakobfoerster@gmail.com;dkiela@fb.com;jpineau@cs.mcgill.ca,6;8;6,,Accept (Poster),0,5,0,yes,9/25/19,McGill University;University of Montreal;;Facebook;McGill University,multi-agent communication;self-play;emergent languages,102;118;-1;-1;102,42;85;-1;-1;42,m;f,canada,ca,n
ICLR,2020,TabFact: A Large-scale Dataset for Table-based Fact Verification,Wenhu Chen;Hongmin Wang;Jianshu Chen;Yunkai Zhang;Hong Wang;Shiyang Li;Xiyou Zhou;William Yang Wang,wenhuchen@ucsb.edu;hongmin@ucsb.edu;chenjianshu@gmail.com;yunkai_zhang@ucsb.edu;hongwang600@ucsb.edu;shiyangli@ucsb.edu;xiyou@ucsb.edu;william@cs.ucsb.edu,6;6;8,,Accept (Poster),0,6,1,yes,9/25/19,UC Santa Barbara;UC Santa Barbara;Tencent AI Lab;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara;UC Santa Barbara,Fact Verification;Tabular Data;Symbolic Reasoning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning,Noah Siegel;Jost Tobias Springenberg;Felix Berkenkamp;Abbas Abdolmaleki;Michael Neunert;Thomas Lampe;Roland Hafner;Nicolas Heess;Martin Riedmiller,siegeln@google.com;springenberg@google.com;befelix@inf.ethz.ch;aabdolmaleki@google.com;neunertm@google.com;thomaslampe@google.com;rhafner@google.com;heess@google.com;riedmiller@google.com,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Swiss Federal Institute of Technology;Google;Google;Google;Google;Google;Google,Reinforcement Learning;Off-policy;Multitask;Continuous Control,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Scale-Equivariant Steerable Networks,Ivan Sosnovik;Micha≈Ç Szmaja;Arnold Smeulders,sosnovikivan@gmail.com;szmajamichal@gmail.com;a.w.m.smeulders@uva.nl,8;6;6,,Accept (Poster),0,5,0,yes,9/25/19,University of Amsterdam;;University of Amsterdam,Scale Equivariance;Steerable Filters,143;-1;143,62;-1;62,m;m,europe,nl,n
ICLR,2020,Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech,David Harwath*;Wei-Ning Hsu*;James Glass,dharwath@csail.mit.edu;wnhsu@mit.edu;glass@mit.edu,8;8;6,,Accept (Talk),0,6,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,visually-grounded speech;self-supervised learning;discrete representation learning;vision and language;vision and speech;hierarchical representation learning,5;5;5,5;5;5,m;m,usa,usa,n
ICLR,2020,Inductive and Unsupervised Representation Learning on Graph Structured Objects,Lichen Wang;Bo Zong;Qianqian Ma;Wei Cheng;Jingchao Ni;Wenchao Yu;Yanchi Liu;Dongjin Song;Haifeng Chen;Yun Fu,wanglichenxj@gmail.com;bzong@nec-labs.com;maqq@bu.edu;weicheng@nec-labs.com;jni@nec-labs.com;wyu@nec-labs.com;yanchi@nec-labs.com;dsong@nec-labs.com;haifeng@nec-labs.com;yunfu@ece.neu.edu,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Northeastern University;NEC-Labs;Boston University;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;Northeastern University,Graph representation learning;Graph isomorphism;Graph similarity learning,-1;-1;79;-1;-1;-1;-1;-1;-1;16,-1;-1;61;-1;-1;-1;-1;-1;-1;906,m;m,usa,usa,y
ICLR,2020,Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach,Kimon Antonakopoulos;E. Veronica Belmega;Panayotis Mertikopoulos,kimon.antonakopoulos@inria.fr;veronica.belmega@ensea.fr;panayotis.mertikopoulos@imag.fr,8;6;8,,Accept (Spotlight),0,3,0,yes,9/25/19,INRIA;ETIS;French National Center for Scientific Research,Online optimization;stochastic optimization;Poisson inverse problems,-1;-1;-1,-1;-1;-1,u;u,NAN,NAN,y
ICLR,2020,HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS,Elizabeth Dinella;Hanjun Dai;Ziyang Li;Mayur Naik;Le Song;Ke Wang,edinella@seas.upenn.edu;hadai@google.com;liby99@seas.upenn.edu;mhnaik@cis.upenn.edu;lsong@cc.gatech.edu;kewang@visa.com,6;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,University of Pennsylvania;Google;University of Pennsylvania;University of Pennsylvania;Georgia Institute of Technology;Visa Research,Bug Detection;Program Repair;Graph Neural Network;Graph Transformation,20;-1;20;20;13;-1,11;-1;11;11;38;-1,f;m,NAN,NAN,n
ICLR,2020,Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering,Akari Asai;Kazuma Hashimoto;Hannaneh Hajishirzi;Richard Socher;Caiming Xiong,akari@cs.washington.edu;k.hashimoto@salesforce.com;hannaneh@washington.edu;richard@socher.org;cxiong@salesforce.com,6;8;6,,Accept (Poster),1,8,3,yes,9/25/19,University of Washington;SalesForce.com;University of Washington;SalesForce.com;SalesForce.com,Multi-hop Open-domain Question Answering;Graph-based Retrieval;Multi-step Retrieval,11;-1;11;-1;-1,26;-1;26;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Learning from Rules Generalizing Labeled Exemplars,Abhijeet Awasthi;Sabyasachi Ghosh;Rasna Goyal;Sunita Sarawagi,awasthi@cse.iitb.ac.in;sghosh@cse.iitb.ac.in;rasna.goyal66@gmail.com;sunita@iitb.ac.in,6;8;6,,Accept (Spotlight),1,5,0,yes,9/25/19,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;;Indian Institute of Technology Bombay,Learning from Rules;Learning from limited labeled data;Weakly Supervised Learning,-1;-1;-1;-1,480;480;-1;480,m;f,NAN,NAN,n
ICLR,2020,Mirror-Generative Neural Machine Translation,Zaixiang Zheng;Hao Zhou;Shujian Huang;Lei Li;Xin-Yu Dai;Jiajun Chen,zhengzx.142857@gmail.com;zhouhao.nlp@bytedance.com;huangsj@nju.edu.cn;lilei.02@bytedance.com;daixinyu@nju.edu.cn;chenjj@nju.edu.cn,8;8;8,,Accept (Talk),0,7,1,yes,9/25/19,Zhejiang University;ByteDance;Zhejiang University;ByteDance;Zhejiang University;Zhejiang University,neural machine translation;generative model;mirror,39;-1;39;-1;39;39,107;-1;107;-1;107;107,u;u,asia,cn,n
ICLR,2020,Phase Transitions for the Information Bottleneck in Representation Learning,Tailin Wu;Ian Fischer,tailin@cs.stanford.edu;iansf@google.com,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,Stanford University;Google,Information Theory;Representation Learning;Phase Transition,5;-1,4;-1,m;m,NAN,NAN,y
ICLR,2020,Model-based reinforcement learning for biological sequence design,Christof Angermueller;David Dohan;David Belanger;Ramya Deshpande;Kevin Murphy;Lucy Colwell,christofa@google.com;ddohan@google.com;dbelanger@google.com;ramyadeshpande@google.com;lcolwell@google.com;kpmurphy@google.com,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,reinforcement learning;blackbox optimization;molecule design,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification,Xuwang Yin;Soheil Kolouri;Gustavo K Rohde,xy4cm@virginia.edu;skolouri@hrl.com;gustavo@virginia.edu,6;6;6,,Accept (Poster),1,5,0,yes,9/25/19,"University of Virginia;HRL Laboratories, LLC;University of Virginia",adversarial example detection;adversarial examples classification;robust optimization;ML security;generative modeling;generative classification,52;-1;52,107;-1;107,m;m,usa,usa,n
ICLR,2020,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding,Wei Wang;Bin Bi;Ming Yan;Chen Wu;Jiangnan Xia;Zuyi Bao;Liwei Peng;Luo Si,hebian.ww@alibaba-inc.com;b.bi@alibaba-inc.com;ym119608@alibaba-inc.com;wuchen.wc@alibaba-inc.com;jiangnan.xjn@alibaba-inc.com;zuyi.bzy@alibaba-inc.com;liwei.peng@alibaba-inc.com;luo.si@alibaba-inc.com,3;8;6,,Accept (Poster),0,3,0,yes,9/25/19,Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Restricting the Flow: Information Bottlenecks for Attribution,Karl Schulz;Leon Sixt;Federico Tombari;Tim Landgraf,karl.schulz@tum.de;leon.sixt@fu-berlin.de;tombari@in.tum.de;tim.landgraf@fu-berlin.de,8;8;8,,Accept (Talk),1,4,2,yes,9/25/19,Technical University Munich;Freie Universit√§t Berlin;Technical University Munich;Freie Universit√§t Berlin,Attribution;Informational Bottleneck;Interpretable Machine Learning;Explainable AI,-1;316;-1;316,-1;-1;-1;-1,m;m,europe,de,n
ICLR,2020,Oblique Decision Trees from Derivatives of ReLU Networks,Guang-He Lee;Tommi S. Jaakkola,guanghe@csail.mit.edu;tommi@csail.mit.edu,3;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,oblique decision trees;ReLU networks,5;5,5;5,m;m,usa,usa,y
ICLR,2020,DBA: Distributed Backdoor Attacks against Federated Learning,Chulin Xie;Keli Huang;Pin-Yu Chen;Bo Li,chulinxie@zju.edu.cn;nick_cooper@sjtu.edu.cn;pin-yu.chen@ibm.com;lbo@illinois.edu,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,"Zhejiang University;Shanghai Jiao Tong University;International Business Machines;University of Illinois, Urbana Champaign",distributed backdoor attack;federated learning,39;30;-1;-1,107;157;-1;-1,f;f,usa,usa,n
ICLR,2020,Understanding and Improving Information Transfer in Multi-Task Learning,Sen Wu;Hongyang R. Zhang;Christopher R√©,senwu@cs.stanford.edu;hongyang@cs.stanford.edu;chrismre@stanford.edu,6;6;8,,Accept (Poster),0,6,0,yes,9/25/19,Stanford University;Stanford University;Stanford University,Multi-Task Learning,5;5;5,4;4;4,m;m,usa,usa,y
ICLR,2020,FSPool: Learning Set Representations with Featurewise Sort Pooling,Yan Zhang;Jonathon Hare;Adam Pr√ºgel-Bennett,yz5n12@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,6;8;8,,Accept (Poster),0,5,0,yes,9/25/19,University of Southampton;University of Southampton;University of Southampton,set auto-encoder;set encoder;pooling,194;194;194,122;122;122,u;m,europe,uk,n
ICLR,2020,Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning,Ruqi Zhang;Chunyuan Li;Jianyi Zhang;Changyou Chen;Andrew Gordon Wilson,rz297@cornell.edu;chunyuan.li@duke.edu;jz318@duke.edu;cchangyou@gmail.com;andrewgw@cims.nyu.edu,8;8;6,,Accept (Talk),0,5,0,yes,9/25/19,"Cornell University;Duke University;Duke University;State University of New York, Buffalo;New York University",,7;46;46;-1;22,19;20;20;-1;29,f;m,usa,usa,y
ICLR,2020,RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments,Roberta Raileanu;Tim Rockt√§schel,raileanu@cs.nyu.edu;tim.rocktaeschel@gmail.com,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,New York University;Facebook AI Research,reinforcement learning;exploration;curiosity,22;-1,29;-1,f;m,NAN,NAN,n
ICLR,2020,Counterfactuals uncover the modular structure of deep generative models,Michel Besserve;Arash Mehrjou;R√©my Sun;Bernhard Sch√∂lkopf,michel.besserve@tuebingen.mpg.de;mehrjou.arash@gmail.com;remy.sun@ens-rennes.fr;bs@tuebingen.mpg.de,8;8;3,,Accept (Poster),0,3,0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Ecole Normale Superieure de Rennes;Max-Planck Institute,generative models;causality;counterfactuals;representation learning;disentanglement;generalization;unsupervised learning,-1;-1;445;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Neural Machine Translation with Universal Visual Representation,Zhuosheng Zhang;Kehai Chen;Rui Wang;Masao Utiyama;Eiichiro Sumita;Zuchao Li;Hai Zhao,zhangzs@sjtu.edu.cn;khchen@nict.go.jp;wangrui@nict.go.jp;mutiyama@nict.go.jp;eiichiro.sumita@nict.go.jp;charlee@sjtu.edu.cn;zhaohai@cs.sjtu.edu.cn,6;8;6,,Accept (Spotlight),1,4,0,yes,9/25/19,"Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Neural Machine Translation;Visual Representation;Multimodal Machine Translation;Language Representation,30;-1;-1;-1;-1;30;30,157;-1;-1;-1;-1;157;157,m;m,asia,cn,n
ICLR,2020,Once-for-All: Train One Network and Specialize it for Efficient Deployment,Han Cai;Chuang Gan;Tianzhe Wang;Zhekai Zhang;Song Han,hancai@mit.edu;ganchuang1990@gmail.com;usedtobe@mit.edu;zhangzk@mit.edu;songhan@mit.edu,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Efficient Deep Learning;Specialized Neural Network Architecture;AutoML,5;-1;5;5;5,5;-1;5;5;5,m;m,usa,usa,n
ICLR,2020,Learning Nearly Decomposable Value Functions Via Communication Minimization,Tonghan Wang*;Jianhao Wang*;Chongyi Zheng;Chongjie Zhang,tonghanwang1996@gmail.com;1040594377@qq.com;chongyeezheng@gmail.com;chongjie@tsinghua.edu.cn,3;6;6,,Accept (Poster),0,6,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Carnegie Mellon University;Tsinghua University, Tsinghua University",Multi-agent reinforcement learning;Nearly decomposable value function;Minimized communication;Multi-agent systems,4;4;1;4,23;23;27;23,m;m,NAN,NAN,n
ICLR,2020,Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,Pu Zhao;Pin-Yu Chen;Payel Das;Karthikeyan Natesan Ramamurthy;Xue Lin,zhao.pu@husky.neu.edu;pin-yu.chen@ibm.com;daspa@us.ibm.com;knatesa@us.ibm.com;xue.lin@northeastern.edu,8;6;3,,Accept (Poster),0,3,0,yes,9/25/19,Northeastern University;International Business Machines;International Business Machines;International Business Machines;Northeastern University,mode connectivity;adversarial robustness;backdoor attack;error-injection attack;evasion attacks;loss landscapes,16;-1;-1;-1;16,906;-1;-1;-1;906,m;f,usa,usa,y
ICLR,2020,The Break-Even Point on Optimization Trajectories of Deep Neural Networks,Stanislaw Jastrzebski;Maciej Szymczak;Stanislav Fort;Devansh Arpit;Jacek Tabor;Kyunghyun Cho*;Krzysztof Geras*,staszek.jastrzebski@gmail.com;msz93@o2.pl;stanislav.fort@gmail.com;devansharpit@gmail.com;jcktbr@gmail.com;kyunghyun.cho@nyu.edu;k.j.geras@nyu.edu,6;8;6,,Accept (Spotlight),1,7,0,yes,9/25/19,Jagiellonian University;Jagiellonian University;Stanford University;SalesForce.com;Jagiellonian University;New York University;New York University,generalization;sgd;learning rate;batch size;hessian;curvature;trajectory;optimization,-1;-1;5;-1;-1;22;22,610;610;4;-1;610;29;29,m;m,usa,usa,y
ICLR,2020,Empirical Studies on the Properties of Linear Regions in Deep Neural Networks,Xiao Zhang;Dongrui Wu,xiao_zhang@hust.edu.cn;drwu@hust.edu.cn,6;3;8,,Accept (Poster),2,6,0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,deep learning;linear region;optimization,-1;-1,47;47,m;m,NAN,NAN,n
ICLR,2020,Learning Compositional Koopman Operators for Model-Based Control,Yunzhu Li;Hao He;Jiajun Wu;Dina Katabi;Antonio Torralba,liyunzhu@mit.edu;haohe@mit.edu;jiajunwu.cs@gmail.com;dina@csail.mit.edu;torralba@csail.mit.edu,6;8;6;6,,Accept (Spotlight),0,7,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Stanford University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Koopman operators;graph neural networks;compositionality,5;5;5;5;5,5;5;4;5;5,m;m,usa,usa,n
ICLR,2020,Meta-Learning without Memorization,Mingzhang Yin;George Tucker;Mingyuan Zhou;Sergey Levine;Chelsea Finn,mzyin@utexas.edu;gjt@google.com;mingyuan.zhou@mccombs.utexas.edu;svlevine@eecs.berkeley.edu;cbfinn@cs.stanford.edu,6;8;8,,Accept (Spotlight),0,5,1,yes,9/25/19,"University of Texas, Austin;Google;University of Texas, Austin;University of California Berkeley;Stanford University",meta-learning;memorization;regularization;overfitting;mutually-exclusive,-1;-1;-1;-1;5,-1;-1;-1;13;4,m;f,usa,usa,y
ICLR,2020,Guiding Program Synthesis by Learning to Generate Examples,Larissa Laich;Pavol Bielik;Martin Vechev,llaich@ethz.ch;pavol.bielik@inf.ethz.ch;martin.vechev@inf.ethz.ch,8;3;8,,Accept (Poster),0,9,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,program synthesis;programming by examples,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Truth or backpropaganda? An empirical investigation of deep learning theory,Micah Goldblum;Jonas Geiping;Avi Schwarzschild;Michael Moeller;Tom Goldstein,goldblumcello@gmail.com;jonas.geiping@uni-siegen.de;avi1@umd.edu;michael.moeller@uni-siegen.de;tomg@cs.umd.edu,8;8;6,,Accept (Spotlight),3,4,0,yes,9/25/19,"University of Maryland, College Park;University of Siegen;University of Maryland, College Park;University of Siegen;University of Maryland, College Park",Deep learning;generalization;loss landscape;robustness,-1;316;12;316;12,-1;570;91;570;91,m;m,usa,usa,y
ICLR,2020,What Can Neural Networks Reason About?,Keyulu Xu;Jingling Li;Mozhi Zhang;Simon S. Du;Ken-ichi Kawarabayashi;Stefanie Jegelka,keyulu@mit.edu;jingling@cs.umd.edu;mozhi@cs.umd.edu;ssdu@ias.edu;k_keniti@nii.ac.jp;stefje@mit.edu,8;8;6,,Accept (Spotlight),0,10,0,yes,9/25/19,"Massachusetts Institute of Technology;University of Maryland, College Park;University of Maryland, College Park;Institue for Advanced Study, Princeton;National Institute of Informatics;Massachusetts Institute of Technology",reasoning;deep learning theory;algorithmic alignment;graph neural networks,5;12;12;-1;-1;5,5;91;91;-1;-1;5,f;f,usa,usa,y
ICLR,2020,U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation,Junho Kim;Minjae Kim;Hyeonwoo Kang;Kwang Hee Lee,takis0112@gmail.com;minjaekim@ncsoft.com;hwkang0131@ncsoft.com;lkwanghee@gmail.com,8;6;6,,Accept (Poster),0,3,0,yes,9/25/19,NAVER;NCSOFT;NCSOFT;Boeing Korea Engineering and Technology Center,Image-to-Image Translation;Generative Attentional Networks;Adaptive Layer-Instance Normalization,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Learn by Zeroth-Order Oracle,Yangjun Ruan;Yuanhao Xiong;Sashank Reddi;Sanjiv Kumar;Cho-Jui Hsieh,ruanyj3107@zju.edu.cn;yhxiong@cs.ucla.edu;sashank@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,"Zhejiang University;University of California, Los Angeles;Google;Google;University of California, Los Angeles",learning to learn;zeroth-order optimization;black-box adversarial attack,39;-1;-1;-1;-1,107;17;-1;-1;17,m;m,usa,usa,n
ICLR,2020,Lite Transformer with Long-Short Range Attention,Zhanghao Wu*;Zhijian Liu*;Ji Lin;Yujun Lin;Song Han,zhanghao.wu@outlook.com;zhijian@mit.edu;jilin@mit.edu;yujunlin@mit.edu;songhan@mit.edu,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,University of California Berkeley;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,efficient model;transformer,-1;5;5;5;5,13;5;5;5;5,m;m,usa,usa,n
ICLR,2020,Regularizing activations in neural networks via distribution matching with the Wasserstein metric,Taejong Joo;Donggu Kang;Byunghoon Kim,tjoo@estsoft.com;emppunity@gmail.com;byungkim@hanyang.ac.kr,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,ESTsoft;;Hanyang University,regularization;Wasserstein metric;deep learning,-1;-1;194,-1;-1;393,m;u,asia,kr,n
ICLR,2020,The Ingredients of Real World Robotic Reinforcement Learning,Henry Zhu;Justin Yu;Abhishek Gupta;Dhruv Shah;Kristian Hartikainen;Avi Singh;Vikash Kumar;Sergey Levine,henryzhu@berkeley.edu;justinvyu@berkeley.edu;abhigupta@berkeley.edu;shah@eecs.berkeley.edu;kristian.hartikainen@gmail.com;avisingh@cs.berkeley.edu;vikashplus@gmail.com;svlevine@eecs.berkeley.edu,8;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Oxford;University of California Berkeley;Facebook;University of California Berkeley,Reinforcement Learning;Robotics,-1;-1;-1;-1;46;-1;-1;-1,13;13;13;13;1;13;-1;13,m;m,usa,usa,n
ICLR,2020,Relational State-Space Model for Stochastic Multi-Object Systems,Fan Yang;Ling Chen;Fan Zhou;Yusong Gao;Wei Cao,fanyang01@zju.edu.cn;lingchen@cs.zju.edu.cn;fanzhou@zju.edu.cn;jianchuan.gys@alibaba-inc.com;mingsong.cw@alibaba-inc.com,6;3;6,,Accept (Poster),0,7,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Alibaba Group;Alibaba Group,state-space model;time series;deep sequential model;graph neural network,39;39;39;-1;-1,107;107;107;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Empirical Bayes Transductive Meta-Learning with Synthetic Gradients,Shell Xu Hu;Pablo Garcia Moreno;Yang Xiao;Xi Shen;Guillaume Obozinski;Neil Lawrence;Andreas Damianou,dom343@gmail.com;morepabl@amazon.com;yang.xiao@enpc.fr;xi.shen@enpc.fr;guillaume.obozinski@epfl.ch;n.lawrence@sheffield.ac.uk;damianou@amazon.com,6;6;6,,Accept (Poster),0,5,1,yes,9/25/19,Ecole des Ponts ParisTech;Amazon;ENPC;ENPC;Swiss Federal Institute of Technology Lausanne;University of Sheffield;Amazon,Meta-learning;Empirical Bayes;Synthetic Gradient;Information Bottleneck,-1;-1;-1;-1;-1;194;-1,-1;-1;-1;-1;-1;117;-1,m;m,NAN,NAN,y
ICLR,2020,Implicit Bias of Gradient Descent based Adversarial Training on Separable Data,Yan Li;Ethan X.Fang;Huan Xu;Tuo Zhao,yli939@gatech.edu;xxf13@psu.edu;huan.xu@isye.gatech.edu;tourzhao@gatech.edu,3;8;6,,Accept (Poster),0,4,0,yes,9/25/19,Georgia Institute of Technology;Pennsylvania State University;Georgia Institute of Technology;Georgia Institute of Technology,implicit bias;adversarial training;robustness;gradient descent,13;43;13;13,38;-1;38;38,u;m,usa,usa,y
ICLR,2020,word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement,Aliakbar Panahi;Seyran Saeedi;Tom Arodz,panahia@vcu.edu;saeedis@vcu.edu;tarodz@vcu.edu,8;8;3,,Accept (Spotlight),0,3,0,yes,9/25/19,Virginia Commonwealth University;Virginia Commonwealth University;Virginia Commonwealth University,word embeddings;natural language processing;model reduction,248;248;248,-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Towards Fast Adaptation of Neural Architectures with Meta Learning,Dongze Lian;Yin Zheng;Yintao Xu;Yanxiong Lu;Leyu Lin;Peilin Zhao;Junzhou Huang;Shenghua Gao,liandz@shanghaitech.edu.cn;yzheng3xg@gmail.com;xuyt@shanghaitech.edu.cn;alanlu@tencent.com;goshawklin@tencent.com;masonzhao@tencent.com;jzhuang@uta.edu;gaoshh@shanghaitech.edu.cn,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,"ShanghaiTech University;Tencent AI Lab;ShanghaiTech University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;University of Texas, Arlington;ShanghaiTech University",Fast adaptation;Meta learning;NAS,316;-1;316;-1;-1;-1;-1;316,-1;-1;-1;-1;-1;-1;-1;-1,m;m,asia,cn,n
ICLR,2020,Hamiltonian Generative Networks,Peter Toth;Danilo J. Rezende;Andrew Jaegle;S√©bastien Racani√®re;Aleksandar Botev;Irina Higgins,petertoth@google.com;danilor@google.com;drewjaegle@google.com;sracaniere@google.com;botev@google.com;irinah@google.com,6;6;8,,Accept (Spotlight),0,9,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Hamiltonian dynamics;normalising flows;generative model;physics,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Residual Energy-Based Models for Text Generation,Yuntian Deng;Anton Bakhtin;Myle Ott;Arthur Szlam;Marc'Aurelio Ranzato,dengyuntian@seas.harvard.edu;yolo@fb.com;aszlam@fb.com;ranzato@fb.com,6;6;6,,Accept (Poster),0,3,1,yes,9/25/19,Harvard University;Facebook;Facebook;Facebook,energy-based models;text generation,52;-1;-1;-1,7;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Plug and Play Language Models: A Simple Approach to Controlled Text Generation,Sumanth Dathathri;Andrea Madotto;Janice Lan;Jane Hung;Eric Frank;Piero Molino;Jason Yosinski;Rosanne Liu,dathathris@gmail.com;amadotto@connect.ust.hk;lan.janice.j@gmail.com;jane.hung@uber.com;mysterefrank@uber.com;piero@uber.com;yosinski@uber.com;rosanne@uber.com,6;3;6,,Accept (Poster),6,7,1,yes,9/25/19,California Institute of Technology;The Hong Kong University of Science and Technology;Facebook;Uber;Uber;Uber;Uber;Uber,controlled text generation;generative models;conditional generative models;language modeling;transformer,-1;-1;-1;-1;-1;-1;-1;-1,-1;47;-1;-1;-1;-1;-1;-1,m;f,southamerica,br,n
ICLR,2020,"Deep 3D Pan via local adaptive t-shaped"" convolutions with global and local adaptive dilations""",Juan Luis Gonzalez Bello;Munchurl Kim,juanluisgb@kaist.ac.kr;mkimee@kaist.ac.kr,6;6;3,,Accept (Poster),0,3,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Deep learning;Stereoscopic view synthesis;Monocular depth;Deep 3D Pan,-1;-1,110;110,m;m,NAN,NAN,n
ICLR,2020,Conservative Uncertainty Estimation By Fitting  Prior Networks,Kamil Ciosek;Vincent Fortuin;Ryota Tomioka;Katja Hofmann;Richard Turner,kamil.ciosek@microsoft.com;fortuin@inf.ethz.ch;ryoto@microsoft.com;katja.hofmann@microsoft.com;ret26@cam.ac.uk,6;6;6,,Accept (Poster),2,13,0,yes,9/25/19,Microsoft;Swiss Federal Institute of Technology;Microsoft;Microsoft;University of Cambridge,uncertainty quantification;deep learning;Gaussian process;epistemic uncertainty;random network;prior;Bayesian inference,-1;-1;-1;-1;79,-1;-1;-1;-1;3,m;m,europe,uk,y
ICLR,2020,Dynamics-Aware Unsupervised Discovery of Skills,Archit Sharma;Shixiang Gu;Sergey Levine;Vikash Kumar;Karol Hausman,architsh@google.com;shanegu@google.com;slevine@google.com;vikashplus@google.com;karolhausman@google.com,8;8;8,,Accept (Talk),0,3,0,yes,9/25/19,Google;Google;Google;Google;Google,reinforcement learning;unsupervised learning;model-based learning;deep learning;hierarchical reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Implementation Matters in Deep RL: A Case Study on PPO and TRPO,Logan Engstrom;Andrew Ilyas;Shibani Santurkar;Dimitris Tsipras;Firdaus Janoos;Larry Rudolph;Aleksander Madry,ailyas@mit.edu;engstrom@mit.edu;shibani@mit.edu;tsipras@mit.edu;firdaus.janoos@twosigma.com;rudolph@csail.mit.edu;madry@mit.edu,8;8;8,,Accept (Talk),0,10,2,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Two Sigma;Massachusetts Institute of Technology;Massachusetts Institute of Technology,deep policy gradient methods;deep reinforcement learning;trpo;ppo,5;5;5;5;-1;5;5,5;5;5;5;-1;5;5,m;m,usa,usa,n
ICLR,2020,Mutual Information Gradient Estimation for  Representation Learning,Liangjian Wen;Yiji Zhou;Lirong He;Mingyuan Zhou;Zenglin Xu,wlj6816@gmail.com;zhouyiji@outlook.com;ronghe1217@gmail.com;mingyuan.zhou@mccombs.utexas.edu;zenglin@gmail.com,8;6;3;6,,Accept (Poster),0,14,0,yes,9/25/19,"Huawei Technologies Ltd.;;University of Electronic Science and Technology of China;University of Texas, Austin;Harbin Institute of Technology",Mutual Information;Score Estimation;Representation Learning;Information Bottleneck,-1;-1;-1;-1;168,-1;-1;628;-1;424,u;m,asia,cn,n
ICLR,2020,Minimizing FLOPs to Learn Efficient Sparse Representations,Biswajit Paria;Chih-Kuan Yeh;Ian E.H. Yen;Ning Xu;Pradeep Ravikumar;Barnab√°s P√≥czos,bparia@cs.cmu.edu;cjyeh@cs.cmu.edu;a061105@gmail.com;ningxu01@gmail.com;pradeepr@cs.cmu.edu;bapoczos@cs.cmu.edu,8;3;8,,Accept (Poster),0,7,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;;Amazon;Carnegie Mellon University;Carnegie Mellon University,sparse embeddings;deep representations;metric learning;regularization,1;1;-1;-1;1;1,27;27;-1;-1;27;27,m;m,usa,usa,y
ICLR,2020,Data-Independent Neural Pruning via Coresets,Ben Mussay;Margarita Osadchy;Vladimir Braverman;Samson Zhou;Dan Feldman,bengordoncshaifa@gmail.com;rita@cs.haifa.ac.il;vova@cs.jhu.edu;samsonzhou@gmail.com;dannyf.post@gmail.co,8;3;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Haifa;University of Haifa;Johns Hopkins University;Carnegie Mellon University;Massachusetts Institute of Technology,coresets;neural pruning;network compression,-1;194;73;1;-1,-1;544;12;27;-1,m;m,asia,in,y
ICLR,2020,LEARNED STEP SIZE QUANTIZATION,Steven K. Esser;Jeffrey L. McKinstry;Deepika Bablani;Rathinakumar Appuswamy;Dharmendra S. Modha,sesser@us.ibm.com;jlmckins@us.ibm.com;deepika.bablani@ibm.com;rappusw@us.ibm.com;dmodha@us.ibm.com,6;8;6,,Accept (Poster),0,4,1,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,deep learning;low precision;classification;quantization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning To Explore Using Active Neural SLAM,Devendra Singh Chaplot;Dhiraj Gandhi;Saurabh Gupta;Abhinav Gupta;Ruslan Salakhutdinov,chaplot@cs.cmu.edu;dhirajgandhi@fb.com;saurabhg@illinois.edu;abhinavg@cs.cmu.edu;rsalakhu@cs.cmu.edu,6;3;8,,Accept (Poster),0,5,0,yes,9/25/19,"Carnegie Mellon University;Facebook;University of Illinois, Urbana Champaign;Carnegie Mellon University;Carnegie Mellon University",Navigation;Exploration,1;-1;-1;1;1,27;-1;-1;27;27,m;m,usa,usa,n
ICLR,2020,Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization,Junjie Yan;Ruosi Wan;Xiangyu Zhang;Wei Zhang;Yichen Wei;Jian Sun,jjyan17@fudan.edu.cn;wanruosi@megvii.com;zhangxiangyu@megvii.com;weizh@fudan.edu.cn;weiyichen@megvii.com;sunjian@megvii.com,6;6;8,,Accept (Poster),0,3,1,yes,9/25/19,Fudan University;Megvii Technology Inc.;Megvii Technology Inc.;Fudan University;Megvii Technology Inc.;Megvii Technology Inc.,batch normalization;small batch size;backward propagation,73;-1;-1;73;-1;-1,109;-1;-1;109;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Tensor Decompositions for Temporal Knowledge Base Completion,Timoth√©e Lacroix;Guillaume Obozinski;Nicolas Usunier,timothee.lax@gmail.com;guillaume.obozinski@epfl.ch;usunier@fb.com,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Facebook;Swiss Federal Institute of Technology Lausanne;Facebook,knowledge base completion;temporal embeddings,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Generalization bounds for deep convolutional neural networks,Philip M. Long;Hanie Sedghi,plong@google.com;hsedghi@google.com,6;3;3,,Accept (Poster),0,8,0,yes,9/25/19,Google;Google,generalization;convolutional networks;statistical learning theory,-1;-1,-1;-1,m;f,NAN,NAN,y
ICLR,2020,Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples,Eleni Triantafillou;Tyler Zhu;Vincent Dumoulin;Pascal Lamblin;Utku Evci;Kelvin Xu;Ross Goroshin;Carles Gelada;Kevin Swersky;Pierre-Antoine Manzagol;Hugo Larochelle,eleni@cs.toronto.edu;tylerzhu@google.com;vdumoulin@google.com;lamblinp@google.com;evcu@google.com;kelvinxu@berkeley.edu;goroshin@google.com;cgel@google.com;kswersky@google.com;manzagop@google.com;hugolarochelle@google.com,3;8;6,,Accept (Poster),0,6,0,yes,9/25/19,University of Toronto;Google;Google;Google;Google;University of California Berkeley;Google;Google;Google;Google;Google,few-shot learning;meta-learning;few-shot classification,18;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,18;-1;-1;-1;-1;13;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings,Shweta Mahajan;Iryna Gurevych;Stefan Roth,mahajan@aiphes.tu-darmstadt.de;gurevych@ukp.informatik.tu-darmstadt.de;stefan.roth@visinf.tu-darmstadt.de,8;8;6,,Accept (Poster),0,6,0,yes,9/25/19,TU Darmstadt;TU Darmstadt;TU Darmstadt,,59;59;59,-1;-1;-1,f;m,europe,de,n
ICLR,2020,Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution,Nikaash Puri;Sukriti Verma;Piyush Gupta;Dhruv Kayastha;Shripad Deshmukh;Balaji Krishnamurthy;Sameer Singh,nikpuri@adobe.com;dce.sukriti@gmail.com;piygupta@adobe.com;dhruvkayastha@iitkgp.ac.in;shripad@smail.iitm.ac.in;kbalaji@adobe.com;sameer@uci.edu,8;6;8,,Accept (Poster),0,11,1,yes,9/25/19,"Adobe Systems;Adobe Systems;Adobe Systems;Indian Institute of Technology Kharagpur;Indian Institute of Technology Madras;Adobe Systems;University of California, Irvine",Deep Reinforcement Learning;Saliency maps;Chess;Go;Atari;Interpretable AI;Explainable AI,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;476;641;-1;96,m;m,usa,usa,n
ICLR,2020,AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing     ,Xingzhe He;Helen Lu Cao;Bo Zhu,xingzhe.he95@gmail.com;helen.l.cao.22@dartmouth.edu;bo.zhu@dartmouth.edu,6;6;6,,Accept (Poster),0,1,1,yes,9/25/19,University of British Columbia;Dartmouth College;Dartmouth College,Point Cloud Processing;Physical Reservoir Learning;Eulerian-Lagrangian Method;PIC/FLIP,-1;168;168,-1;94;94,m;m,usa,usa,n
ICLR,2020,Batch-shaping for learning conditional channel gated networks,Babak Ehteshami Bejnordi;Tijmen Blankevoort;Max Welling,behtesha@qti.qualcomm.com;tijmen@qti.qualcomm.com;mwelling@qti.qualcomm.com,8;6;6,,Accept (Poster),1,3,0,yes,9/25/19,"Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",Conditional computation;channel gated networks;gating;Batch-shaping;distribution matching;image classification;semantic segmentation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Closer Look at Deep Policy Gradients,Andrew Ilyas;Logan Engstrom;Shibani Santurkar;Dimitris Tsipras;Firdaus Janoos;Larry Rudolph;Aleksander Madry,ailyas@mit.edu;engstrom@mit.edu;shibani@mit.edu;tsipras@mit.edu;firdaus.janoos@twosigma.com;rudolph@csail.mit.edu;madry@mit.edu,8;6;8,,Accept (Talk),0,3,1,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Two Sigma;Massachusetts Institute of Technology;Massachusetts Institute of Technology,deep policy gradient methods;deep reinforcement learning;trpo;ppo,5;5;5;5;-1;5;5,5;5;5;5;-1;5;5,m;m,usa,usa,n
ICLR,2020,Provable robustness against all adversarial $l_p$-perturbations for $p\geq 1$,Francesco Croce;Matthias Hein,francesco91.croce@gmail.com;matthias.hein@uni-tuebingen.de,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,University of Tuebingen;University of Tuebingen,adversarial robustness;provable guarantees,143;143,91;91,m;m,europe,de,y
ICLR,2020,Distributionally Robust Neural Networks,Shiori Sagawa*;Pang Wei Koh*;Tatsunori B. Hashimoto;Percy Liang,ssagawa@cs.stanford.edu;koh.pangwei@gmail.com;thashim@stanford.edu;pliang@cs.stanford.edu,8;3;6,,Accept (Poster),0,4,0,yes,9/25/19,Stanford University;;Stanford University;Stanford University,distributionally robust optimization;deep learning;robustness;generalization;regularization,5;-1;5;5,4;-1;4;4,f;m,usa,usa,y
ICLR,2020,Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks,Jiadong Lin;Chuanbiao Song;Kun He;Liwei Wang;John E. Hopcroft,jdlin@hust.edu.cn;cbsong@hust.edu.cn;brooklet60@hust.edu.cn;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Peking University;Cornell University,adversarial examples;adversarial attack;transferability;Nesterov accelerated gradient;scale invariance,-1;-1;-1;14;7,47;47;47;24;19,m;m,usa,usa,n
ICLR,2020,Fast Neural Network Adaptation via Parameter Remapping and Architecture Search,Jiemin Fang*;Yuzhu Sun*;Kangjian Peng*;Qian Zhang;Yuan Li;Wenyu Liu;Xinggang Wang,jaminfong@hust.edu.cn;yzsun@hust.edu.cn;kangjian.peng@horizon.ai;qian01.zhang@horizon.ai;yuan.li@horizon.ai;liuwy@hust.edu.cn;xgwang@hust.edu.cn,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Horizon Robotics;Horizon Robotics;Horizon Robotics;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,,-1;-1;-1;-1;-1;-1;-1,47;47;-1;-1;-1;47;47,m;m,NAN,NAN,n
ICLR,2020,Understanding Generalization in Recurrent Neural Networks,Zhuozhuo Tu;Fengxiang He;Dacheng Tao,zhtu3055@uni.sydney.edu.au;fengxiang.he@sydney.edu.au;dacheng.tao@sydney.edu.au,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney,generalization;recurrent neural networks;learning theory,64;64;64,60;60;60,u;m,europe,uk,y
ICLR,2020,Piecewise linear activations substantially shape the loss surfaces of neural networks,Fengxiang He;Bohan Wang;Dacheng Tao,fengxiang.he@sydney.edu.au;bhwangfy@gmail.com;dacheng.tao@sydney.edu.au,6;6;3,,Accept (Poster),0,19,0,yes,9/25/19,University of Sydney;Microsoft;University of Sydney,neural network;nonlinear activation;loss surface;spurious local minimum,64;-1;64,60;-1;60,m;m,europe,uk,y
ICLR,2020,Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,Samuel Humeau;Kurt Shuster;Marie-Anne Lachaux;Jason Weston,samuelhumeau@fb.com;kshuster@fb.com;malachaux@fb.com;jaseweston@gmail.com,8;8;6,,Accept (Poster),0,1,0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Understanding the Limitations of Variational Mutual Information Estimators,Jiaming Song;Stefano Ermon,jiaming.tsong@gmail.com;ermon@cs.stanford.edu,6;6;6,,Accept (Poster),0,0,0,yes,9/25/19,Stanford University;Stanford University,,5;5,4;4,m;m,usa,usa,y
ICLR,2020,A Baseline for Few-Shot Image Classification,Guneet Singh Dhillon;Pratik Chaudhari;Avinash Ravichandran;Stefano Soatto,guneetdhillon@utexas.edu;pratikac@seas.upenn.edu;avinash.a.ravichandran@gmail.com;soattos@amazon.com,6;6;6,,Accept (Poster),0,5,2,yes,9/25/19,"University of Texas, Austin;University of Pennsylvania;Amazon;Amazon",few-shot learning;transductive learning;fine-tuning;baseline;meta-learning,-1;20;-1;-1,-1;11;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation,Suraj Nair;Chelsea Finn,surajn@stanford.edu;chelseaf@google.com,6;6,,Accept (Poster),1,2,0,yes,9/25/19,Stanford University;Google,video prediction;reinforcement learning;planning,5;-1,4;-1,m;f,NAN,NAN,n
ICLR,2020,Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving,Yurong You;Yan Wang;Wei-Lun Chao;Divyansh Garg;Geoff Pleiss;Bharath Hariharan;Mark Campbell;Kilian Q. Weinberger,yy785@cornell.edu;yw763@cornell.edu;weilunchao760414@gmail.com;dg595@cornell.edu;gp346@cornell.edu;bharathh@cs.cornell.edu;mc288@cornell.edu;kqw4@cornell.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Cornell University;Cornell University;Ohio State University;Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,pseudo-LiDAR;3D-object detection;stereo depth estimation;autonomous driving,7;7;59;7;7;7;7;7,19;19;70;19;19;19;19;19,m;m,usa,usa,n
ICLR,2020,V4D: 4D Convolutional Neural Networks for Video-level Representation Learning,Shiwen Zhang;Sheng Guo;Weilin Huang;Matthew R. Scott;Limin Wang,shizhang@malong.com;sheng@malong.com;whuang@malong.com;mscott@malong.com;07wanglimin@gmail.com,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,Malong Technologies;Malong Technologies;Malong Technologies;Malong Technologies;Zhejiang University,video-level representation learning;video action recognition;4D CNNs,-1;-1;-1;-1;39,-1;-1;-1;-1;107,u;m,asia,cn,n
ICLR,2020,Certified Defenses for Adversarial Patches,Ping-yeh Chiang*;Renkun Ni*;Ahmed Abdelkader;Chen Zhu;Christoph Studor;Tom Goldstein,pchiang@cs.umd.edu;rn9zm@cs.umd.edu;akader@cs.umd.edu;chenzhu@cs.umd.edu;studer@cornell.edu;tomg@cs.umd.edu,6;6;6,,Accept (Poster),0,9,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Cornell University;University of Maryland, College Park",certified defenses;patch attack;adversarial robustness;sparse defense,12;12;12;12;7;12,91;91;91;91;19;91,m;m,usa,usa,n
ICLR,2020,Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation,Byung Hoon Ahn;Prannoy Pilligundla;Amir Yazdanbakhsh;Hadi Esmaeilzadeh,bhahn@eng.ucsd.edu;ppilligu@eng.ucsd.edu;ayazdan@google.com;hadi@eng.ucsd.edu,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;Google;University of California, San Diego",Reinforcement Learning;Learning to Optimize;Combinatorial Optimization;Compilers;Code Optimization;Neural Networks;ML for Systems;Learning for Systems,-1;-1;-1;-1,31;31;-1;31,m;m,usa,usa,n
ICLR,2020,Semantically-Guided Representation Learning for Self-Supervised Monocular Depth,Vitor Guizilini;Rui Hou;Jie Li;Rares Ambrus;Adrien Gaidon,vitor.guizilini@tri.global;rayhou@umich.edu;jie.li@tri.global;rares.ambrus@tri.global;adrien.gaidon@tri.global,6;6;3,,Accept (Poster),0,8,0,yes,9/25/19,Toyota Research Institute;University of Michigan;Toyota Research Institute;Toyota Research Institute;Toyota Research Institute,computer vision;machine learning;deep learning;monocular depth estimation;self-supervised learning,-1;7;-1;-1;-1,-1;21;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Target-Embedding Autoencoders for Supervised Representation Learning,Daniel Jarrett;Mihaela van der Schaar,daniel.jarrett@eng.ox.ac.uk;mv472@damtp.cam.ac.uk,8;6;6;8,,Accept (Talk),0,19,0,yes,9/25/19,University of Oxford;University of Cambridge,autoencoders;supervised learning;representation learning;target-embedding;label-embedding,46;79,1;3,m;f,europe,uk,y
ICLR,2020,MetaPix: Few-Shot Video Retargeting,Jessica Lee;Deva Ramanan;Rohit Girdhar,jl5@cs.cmu.edu;deva@cs.cmu.edu;rgirdhar@cs.cmu.edu,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Meta-learning;Few-shot Learning;Generative Adversarial Networks;Video Retargeting,1;1;1,27;27;27,f;m,usa,usa,n
ICLR,2020,Lazy-CFR: fast and near-optimal regret minimization for extensive games with imperfect information,Yichi Zhou;Tongzheng Ren;Jialian Li;Dong Yan;Jun Zhu,vofhqn@gmail.com;rtz19970824@gmail.com;lijialia16@mails.tsinghua.edu.cn;sproblvem@gmail.com;dcszj@mail.tsinghua.edu.cn,8;8;3,,Accept (Poster),0,5,0,yes,9/25/19,"Tsinghua University;;Tsinghua University, Tsinghua University;;Tsinghua University",,-1;-1;4;-1;4,-1;-1;23;-1;23,m;m,NAN,NAN,y
ICLR,2020,Neural Module Networks for Reasoning over Text,Nitish Gupta;Kevin Lin;Dan Roth;Sameer Singh;Matt Gardner,gnnitish@gmail.com;kevinlin@eecs.berkeley.edu;danroth@seas.upenn.edu;sameer@uci.edu;mattg@allenai.org,6;6;8,,Accept (Poster),0,4,1,yes,9/25/19,"University of Pennsylvania;University of California Berkeley;University of Pennsylvania;University of California, Irvine;Allen Institute for Artificial Intelligence",question answering;compositionality;neural module networks;multi-step reasoning;reading comprehension,-1;-1;20;-1;-1,-1;13;11;96;-1,m;m,NAN,NAN,n
ICLR,2020,Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks,Leopold Cambier;Anahita Bhiwandiwalla;Ting Gong;Oguz H. Elibol;Mehran Nekuii;Hanlin Tang,lcambier@stanford.edu;anahita.bhiwandiwalla@intel.com;ting.gong@intel.com;oguz.h.elibol@intel.com;mehran.nekuii@intel.com;hanlin.tang@intel.com,6;6;1;8,,Accept (Poster),0,4,0,yes,9/25/19,Stanford University;Intel;Intel;Intel;Intel;Intel,Low-precision training;numerics;deep learning,5;-1;-1;-1;-1;-1,4;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ProxSGD: Training Structured Neural Networks under Regularization and Constraints,Yang Yang;Yaxiong Yuan;Avraam Chatzimichailidis;Ruud JG van Sloun;Lei Lei;Symeon Chatzinotas,yang.yang@itwm.fraunhofer.de;yaxiong.yuan@uni.lu;avraam.chatzimichailidis@itwm.fraunhofer.de;r.j.g.v.sloun@tue.nl;lei.lei@uni.lu;symeon.chatzinotas@uni.lu,3;6;6,,Accept (Poster),0,4,1,yes,9/25/19,"Fraunhofer IIS;Interdisciplinary Centre for Security, Reliability and Trust (SnT);Fraunhofer IIS;Eindhoven University of Technology;Interdisciplinary Centre for Security, Reliability and Trust (SnT);Interdisciplinary Centre for Security, Reliability and Trust (SnT)",stochastic gradient descent;regularization;constrained optimization;nonsmooth optimization,-1;-1;-1;-1;-1;-1,-1;-1;-1;185;-1;-1,m;m,NAN,NAN,y
ICLR,2020,BayesOpt Adversarial Attack,Binxin Ru;Adam Cobb;Arno Blaas;Yarin Gal,robin@robots.ox.ac.uk;adam.cobb@worc.ox.ac.uk;arno@robots.ox.ac.uk;yarin@cs.ox.ac.uk,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Black-box Adversarial Attack;Bayesian Optimisation;Gaussian Process,46;46;46;46,1;1;1;1,m;m,europe,uk,n
ICLR,2020,Distance-Based Learning from Errors for Confidence Calibration,Chen Xing;Sercan Arik;Zizhao Zhang;Tomas Pfister,xingchen1113@gmail.com;soarik@google.com;zizhaoz@google.com;tpfister@google.com,6;6;6,,Accept (Poster),0,3,1,yes,9/25/19,SalesForce.com;Google;Google;Google,Confidence Calibration;Uncertainty Estimation;Prototypical Learning,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Compressive Transformers for Long-Range Sequence Modelling,Jack W. Rae;Anna Potapenko;Siddhant M. Jayakumar;Chloe Hillier;Timothy P. Lillicrap,jwrae@google.com;apotapenko@google.com;sidmj@google.com;chillier@google.com;countzero@google.com,8;8;6,,Accept (Poster),0,8,1,yes,9/25/19,Google;Google;Google;Google;Google,memory;language modeling;transformer;compression,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Symplectic Recurrent Neural Networks,Zhengdao Chen;Jianyu Zhang;Martin Arjovsky;L√©on Bottou,zc1216@nyu.edu;edzhang@tju.edu.cn;martinarjovsky@gmail.com;leonb@fb.com,8;8;6,,Accept (Spotlight),0,4,1,yes,9/25/19,New York University;Zhejiang University;;Facebook,Hamiltonian systems;learning physical laws;symplectic integrators;recurrent neural networks;inverse problems,22;39;-1;-1,29;107;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Coordinate Manipulation Skills via Skill Behavior Diversification,Youngwoon Lee;Jingyun Yang;Joseph J. Lim,lee504@usc.edu;jingyuny@usc.edu;limjj@usc.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,reinforcement learning;hierarchical reinforcement learning;modular framework;skill coordination;bimanual manipulation,36;36;36,62;62;62,m;m,usa,usa,n
ICLR,2020,Learning Expensive Coordination: An Event-Based Deep RL Approach,Zhenyu Shi*;Runsheng Yu*;Xinrun Wang*;Rundong Wang;Youzhi Zhang;Hanjiang Lai;Bo An,shizhy6@mail2.sysu.edu.cn;runsheng.yu@ntu.edu.sg;xwang033@e.ntu.edu.sg;rundong001@e.ntu.edu.sg;yzhang137@e.ntu.edu.sg;laihanj3@mail.sysu.edu.cn;boan@ntu.edu.sg,6;8;6,,Accept (Poster),0,5,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;SUN YAT-SEN UNIVERSITY;Nanyang Technological University,Multi-Agent Deep Reinforcement Learning;Deep Reinforcement Learning;Leader‚ÄìFollower Markov Game;Expensive Coordination,-1;43;43;43;43;-1;43,299;49;49;49;49;299;49,m;m,asia,sg,y
ICLR,2020,Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML,Aniruddh Raghu;Maithra Raghu;Samy Bengio;Oriol Vinyals,aniruddhraghu@gmail.com;maithrar@gmail.com;bengio@google.com;vinyals@google.com,3;8;8,,Accept (Poster),0,5,0,yes,9/25/19,Massachusetts Institute of Technology;Cornell University;Google;Google,deep learning analysis;representation learning;meta-learning;few-shot learning,-1;7;-1;-1,-1;19;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Iterative energy-based projection on a normal data manifold for anomaly localization,David Dehaene;Oriel Frigo;S√©bastien Combrexelle;Pierre Eline,david@anotherbrain.ai;oriel@anotherbrain.ai;sebastien@anotherbrain.ai;pierre@anotherbrain.ai,3;6;8,,Accept (Poster),0,4,0,yes,9/25/19,AnotherBrain;AnotherBrain;AnotherBrain;AnotherBrain,deep learning;visual inspection;unsupervised anomaly detection;anomaly localization;autoencoder;variational autoencoder;gradient descent;inpainting,-1;-1;-1;-1,-1;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,Harnessing Structures for Value-Based Planning and Reinforcement Learning,Yuzhe Yang;Guo Zhang;Zhi Xu;Dina Katabi,yuzhe@mit.edu;guozhang@mit.edu;zhixu@mit.edu;dina@csail.mit.edu,8;6;8,,Accept (Talk),0,8,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Deep reinforcement learning;value-based reinforcement learning,5;5;5;5,5;5;5;5,m;f,usa,usa,n
ICLR,2020,A closer look at the approximation capabilities of neural networks,Kai Fong Ernest Chong,ernest_chong@sutd.edu.sg,8;6;6;6,,Accept (Poster),0,3,1,yes,9/25/19,Singapore University of Technology and Design,deep learning;approximation;universal approximation theorem,-1,-1,m,NAN,NAN,y
ICLR,2020,Spectral  Embedding of Regularized Block Models,Nathan De Lara;Thomas Bonald,ndelara@enst.fr;bonald@enst.fr,6;8,,Accept (Spotlight),0,1,0,yes,9/25/19,T√©l√©com ParisTech;T√©l√©com ParisTech,Spectral embedding;regularization;block models;clustering,-1;-1,187;187,u;m,NAN,NAN,y
ICLR,2020,MMA Training: Direct Input Space Margin Maximization through Adversarial Training,Gavin Weiguang Ding;Yash Sharma;Kry Yik Chau Lui;Ruitong Huang,gavin.w.ding@gmail.com;yash.sharma@bethgelab.org;yikchau.y.lui@borealisai.com;ruitong.huang@borealisai.com,3;6;6,,Accept (Poster),1,10,0,yes,9/25/19,"Borealis AI;Centre for Integrative Neuroscience, AG Bethge;Borealis AI;Borealis AI",adversarial robustness;perturbation;margin maximization;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Monotonic Multihead Attention,Xutai Ma;Juan Miguel Pino;James Cross;Liezl Puzon;Jiatao Gu,xutai_ma@jhu.edu;juancarabina@fb.com;jcross@fb.com;lie@fb.com;jgu@fb.com,6;6;8,,Accept (Poster),0,9,0,yes,9/25/19,Johns Hopkins University;Facebook;Facebook;Facebook;Facebook,Simultaneous Translation;Transformer;Monotonic Attention,73;-1;-1;-1;-1,12;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning representations for binary-classification without backpropagation,Mathias Lechner,mathias.lechner@ist.ac.at,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Institute of Science and Technology Austria,feedback alignment;alternatives to backpropagation;biologically motivated learning algorithms,-1,-1,m,NAN,NAN,y
ICLR,2020,Action Semantics Network: Considering the Effects of Actions in Multiagent Systems,Weixun Wang;Tianpei Yang;Yong Liu;Jianye Hao;Xiaotian Hao;Yujing Hu;Yingfeng Chen;Changjie Fan;Yang Gao,wxwang@tju.edu.cn;tpyang@tju.edu.cn;lucasliunju@gmail.com;jianye.hao@tju.edu.cn;xiaotianhao@tju.edu.cn;huyujing@corp.netease.com;chenyingfeng1@corp.netease.com;fanchangjie@corp.netease.com;gaoy@nju.edu.cn,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Zhejiang University;Zhejiang University;;Zhejiang University;Zhejiang University;Fuxi AI Lab in Netease;Fuxi AI Lab in Netease;Fuxi AI Lab in Netease;Zhejiang University,multiagent coordination;multiagent learning,39;39;-1;39;39;-1;-1;-1;39,107;107;-1;107;107;-1;-1;-1;107,u;m,asia,cn,n
ICLR,2020,Finite Depth and Width Corrections to the Neural Tangent Kernel,Boris Hanin;Mihai Nica,bhanin@math.tamu.edu;mnica@math.utoronto.ca,6;8;8,,Accept (Spotlight),0,3,0,yes,9/25/19,Texas A&M;Toronto University,Neural Tangent Kernel;Finite Width Corrections;Random ReLU Net;Wide Networks;Deep Networks,46;-1,177;-1,m;m,NAN,NAN,y
ICLR,2020,What graph neural networks cannot learn: depth vs width,Andreas Loukas,andreas.loukas@epfl.ch,6;8;8,,Accept (Poster),0,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne,graph neural networks;capacity;impossibility results;lower bounds;expressive power,-1,-1,m,NAN,NAN,y
ICLR,2020,Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data,Sergei Popov;Stanislav Morozov;Artem Babenko,sapopov@yandex-team.ru;stanis-morozov@yandex.ru;artem.babenko@phystech.edu,6;8;3,,Accept (Poster),0,3,0,yes,9/25/19,Yandex;Yandex;Moscow Institute of Physics and Technology,tabular data;architectures;DNN,-1;-1;-1,-1;-1;234,m;m,NAN,NAN,n
ICLR,2020,Gradient $\ell_1$ Regularization for Quantization Robustness,Milad Alizadeh;Arash Behboodi;Mart van Baalen;Christos Louizos;Tijmen Blankevoort;Max Welling,milada@qti.qualcomm.com;behboodi@qti.qualcomm.com;mart@qti.qualcomm.com;clouizos@qti.qualcomm.com;tijmen@qti.qualcomm.com;mwelling@qti.qualcomm.com,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,"Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",quantization;regularization;robustness;gradient regularization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PairNorm: Tackling Oversmoothing in GNNs,Lingxiao Zhao;Leman Akoglu,lingxiao@cmu.edu;lakoglu@andrew.cmu.edu,8;3,,Accept (Poster),0,2,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Graph Neural Network;oversmoothing;normalization,1;1,27;27,m;f,usa,usa,n
ICLR,2020,Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework,Zirui Wang*;Jiateng Xie*;Ruochen Xu;Yiming Yang;Graham Neubig;Jaime G. Carbonell,ziruiw@cs.cmu.edu;jiatengx@cs.cmu.edu;ruochenx@cs.cmu.edu;yiming@cs.cmu.edu;gneubig@cs.cmu.edu;jgc@cs.cmu.edu,8;8;6,,Accept (Poster),2,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Cross-lingual Representation,1;1;1;1;1;1,27;27;27;27;27;27,m;m,usa,usa,n
ICLR,2020,Generalization of Two-layer Neural Networks: An Asymptotic Viewpoint,Jimmy Ba;Murat Erdogdu;Taiji Suzuki;Denny Wu;Tianzong Zhang,jba@cs.toronto.edu;erdogdu@cs.toronto.edu;taiji@mist.i.u-tokyo.ac.jp;dennywu@cs.toronto.edu;ztz16@mails.tsinghua.edu.cn,8;6;8,,Accept (Spotlight),0,3,0,yes,9/25/19,"University of Toronto;University of Toronto;The University of Tokyo;University of Toronto;Tsinghua University, Tsinghua University",Neural Networks;Generalization;High-dimensional Statistics,18;18;64;18;4,18;18;36;18;23,m;m,NAN,NAN,y
ICLR,2020,LAMOL: LAnguage MOdeling for Lifelong Language Learning,Fan-Keng Sun*;Cheng-Hao Ho*;Hung-Yi Lee,fankeng@mit.edu;jojotenya@gmail.com;hungyilee@ntu.edu.tw,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,Massachusetts Institute of Technology;;Nanyang Technological University,NLP;Deep Learning;Lifelong Learning,5;-1;43,5;-1;49,m;m,asia,sg,n
ICLR,2020,Neural Stored-program Memory,Hung Le;Truyen Tran;Svetha Venkatesh,lethai@deakin.edu.au;truyen.tran@deakin.edu.au;svetha.venkatesh@deakin.edu.au,8;6;3,,Accept (Poster),0,8,0,yes,9/25/19,Deakin University;Deakin University;Deakin University,Memory Augmented Neural Networks;Universal Turing Machine;fast-weight,-1;-1;-1,332;332;332,m;f,asia,cn,n
ICLR,2020,BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning,Yeming Wen;Dustin Tran;Jimmy Ba,ywen@cs.toronto.edu;trandustin@google.com;jba@cs.toronto.edu,6;3;6,,Accept (Poster),0,9,1,yes,9/25/19,University of Toronto;Google;University of Toronto,deep learning;ensembles,18;-1;18,18;-1;18,m;m,canada,ca,n
ICLR,2020,Neural Arithmetic Units,Andreas Madsen;Alexander Rosenberg Johansen,amwebdk@gmail.com;alexander@herhjemme.dk,6;8;6;3,,Accept (Spotlight),0,11,0,yes,9/25/19,Technical University of Denmark;Technical University of Denmark,,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,"To Relieve Your Headache of Training an MRF, Take AdVIL",Chongxuan Li;Chao Du;Kun Xu;Max Welling;Jun Zhu;Bo Zhang,chongxuanli1991@gmail.com;duchao0726@gmail.com;kunxu.thu@gmail.com;m.welling@uva.nl;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Tsinghua University;;;University of Amsterdam;Tsinghua University;Tsinghua University,Markov Random Fields;Undirected Graphical Models;Variational Inference;Black-box Infernece,-1;-1;-1;143;4;4,-1;-1;-1;62;23;23,m;m,NAN,NAN,y
ICLR,2020,State Alignment-based Imitation Learning,Fangchen Liu;Zhan Ling;Tongzhou Mu;Hao Su,fliu@eng.ucsd.edu;z6ling@eng.ucsd.edu;t3mu@eng.ucsd.edu;haosu@eng.ucsd.edu,6;3;8,,Accept (Poster),0,12,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",Imitation learning;Reinforcement Learning,-1;-1;-1;-1,31;31;31;31,f;m,usa,usa,n
ICLR,2020,Influence-Based Multi-Agent Exploration,Tonghan Wang*;Jianhao Wang*;Yi Wu;Chongjie Zhang,tonghanwang1996@gmail.com;1040594377@qq.com;jxwuyi@openai.com;chongjie@tsinghua.edu.cn,6;8;6,,Accept (Spotlight),3,4,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;OpenAI;Tsinghua University, Tsinghua University",Multi-agent reinforcement learning;Exploration,4;4;-1;4,23;23;-1;23,m;m,NAN,NAN,y
ICLR,2020,AE-OT: A NEW GENERATIVE MODEL BASED ON EXTENDED SEMI-DISCRETE OPTIMAL TRANSPORT,Dongsheng An;Yang Guo;Na Lei;Zhongxuan Luo;Shing-Tung Yau;Xianfeng Gu,doan@cs.stonybrook.edu;yangguo@cs.stonybrook.edu;nalei@dlut.edu.cn;zxluo@dlut.edu.cn;yau@math.harvard.edu;gu@cs.stonybrook.edu,3;3;8,,Accept (Poster),0,6,0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;South China University of Technology;South China University of Technology;Harvard University;State University of New York, Stony Brook",Generative model;auto-encoder;optimal transport;mode collapse;regularity,-1;-1;-1;-1;52;-1,-1;-1;501;501;7;-1,m;m,NAN,NAN,n
ICLR,2020,CoPhy: Counterfactual Learning of Physical Dynamics,Fabien Baradel;Natalia Neverova;Julien Mille;Greg Mori;Christian Wolf,fabien.baradel@insa-lyon.fr;nneverova@fb.com;julien.mille@insa-cvl.fr;mori@cs.sfu.ca;christian.wolf@insa-lyon.fr,6;6;6,,Accept (Spotlight),0,6,0,yes,9/25/19,INSA de Lyon;Facebook;;Simon Fraser University;INSA de Lyon,intuitive physics;visual reasoning,-1;-1;-1;52;-1,-1;-1;-1;272;-1,m;m,NAN,NAN,n
ICLR,2020,Disentangling Factors of Variations Using Few Labels,Francesco Locatello;Michael Tschannen;Stefan Bauer;Gunnar R√§tsch;Bernhard Sch√∂lkopf;Olivier Bachem,flocatello@tuebingen.mpg.de;tschannen@google.com;stefan.bauer@tuebingen.mpg.de;raetsch@inf.ethz.ch;bs@tuebingen.mpg.de;bachem@google.com,1;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Max-Planck Institute;Google;Max-Planck Institute;Swiss Federal Institute of Technology;Max-Planck Institute;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Uncertainty-guided Continual Learning with Bayesian Neural Networks,Sayna Ebrahimi;Mohamed Elhoseiny;Trevor Darrell;Marcus Rohrbach,sayna@berkeley.edu;mohamed.elhoseiny@gmail.com;trevor@eecs.berkeley.edu;maroffm@gmail.com,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,University of California Berkeley;KAUST;University of California Berkeley;Facebook,continual learning;catastrophic forgetting,-1;102;-1;-1,13;-1;13;-1,f;m,NAN,NAN,n
ICLR,2020,Composing Task-Agnostic Policies with Deep Reinforcement Learning,Ahmed H. Qureshi;Jacob J. Johnson;Yuzhe Qin;Taylor Henderson;Byron Boots;Michael C. Yip,a1qureshi@ucsd.edu;jjj025@eng.ucsd.edu;y1qin@eng.ucsd.edu;tjwest@ucsd.edu;bboots@cs.washington.edu;yip@ucsd.edu,6;6;6,,Accept (Poster),0,13,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego;University of Washington;University of California, San Diego",composition;transfer learning;deep reinforcement learning,-1;-1;-1;-1;11;-1,31;31;31;31;26;31,m;m,usa,usa,n
ICLR,2020,Making Sense of Reinforcement Learning and Probabilistic Inference,Brendan O'Donoghue;Ian Osband;Catalin Ionescu,bodonoghue85@gmail.com;iosband@google.com;cdi@google.com,6;8;6,,Accept (Spotlight),0,5,1,yes,9/25/19,DeepMind;Google;Google,Reinforcement learning;Bayesian inference;Exploration,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,The Logical Expressiveness of Graph Neural Networks,Pablo Barcel√≥;Egor V. Kostylev;Mikael Monet;Jorge P√©rez;Juan Reutter;Juan Pablo Silva,pbarcelo@gmail.com;egor.kostylev@cs.ox.ac.uk;mikael.monet@imfd.cl;jorge.perez.rojas@gmail.com;juan.reutter@gmail.com;jpsilvapena@gmail.com,8;8;8,,Accept (Spotlight),0,4,0,yes,9/25/19,Pontificia Universidad Cat√≥lica;University of Oxford;Instituto Milenio Fundamentos de los Datos;Universidad de Chile;Pontificia Universidad Cat√≥lica;Universidad de Chile,Graph Neural Networks;First Order Logic;Expressiveness,-1;46;-1;316;-1;316,-1;1;-1;-1;-1;-1,m;m,southamerica,cl,y
ICLR,2020,Language GANs Falling Short,Massimo Caccia;Lucas Caccia;William Fedus;Hugo Larochelle;Joelle Pineau;Laurent Charlin,massimo.p.caccia@gmail.com;lucas.page-caccia@mail.mcgill.ca;liam.fedus@gmail.com;hugolarochelle@google.com;jpineau@cs.mcgill.ca;lcharlin@gmail.com,6;8,,Accept (Poster),0,10,1,yes,9/25/19,University of Montreal;McGill University;;Google;McGill University;HEC Montreal,NLP;GAN;MLE;adversarial;text generation;temperature,118;102;-1;-1;102;-1,85;42;-1;-1;42;-1,m;m,canada,ca,n
ICLR,2020,Directional Message Passing for Molecular Graphs,Johannes Klicpera;Janek Gro√ü;Stephan G√ºnnemann,klicpera@in.tum.de;grossja@in.tum.de;guennemann@in.tum.de,8;8;6,,Accept (Spotlight),0,3,0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,GNN;Graph neural network;message passing;graphs;equivariance;molecules,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning,Shahbaz Rezaei;Xin Liu,srezaei@ucdavis.edu;xinliu@ucdavis.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,"University of California, Davis;University of California, Davis",Machine learning security;Transfer learning;deep learning security;Softmax Vulnerability;Transfer learning Security,-1;-1,55;55,m;f,usa,usa,n
ICLR,2020,At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima Selection in Asynchronous Training of Neural Networks?,Niv Giladi;Mor Shpigel Nacson;Elad Hoffer;Daniel Soudry,giladiniv@gmail.com;mor.shpigel@gmail.com;elad.hoffer@gmail.com;daniel.soudry@gmail.com,6;8;8,,Accept (Spotlight),0,3,0,yes,9/25/19,"Technion, Technion;Technion, Technion;Habana Labs (Intel);Technion, Technion",implicit bias;stability;neural networks;generalization gap;asynchronous SGD,27;27;-1;27,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Smoothness and Stability in GANs,Casey Chu;Kentaro Minami;Kenji Fukumizu,caseychu@stanford.edu;minami@preferred.jp;fukumizu@ism.ac.jp,8;6;1,,Accept (Poster),0,5,0,yes,9/25/19,"Stanford University;Preferred Networks, Inc.;The Institute of Statistical Mathematics, Japan",generative adversarial networks;stability;smoothness;convex conjugate,5;-1;-1,4;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Infinite-Horizon Differentiable Model Predictive Control,Sebastian East;Marco Gallieri;Jonathan Masci;Jan Koutnik;Mark Cannon,sebastian.east@bath.edu;marco@nnaisense.com;jonathan@nnaisense.com;jan@nnaisense.com;mark.cannon@eng.ox.ac.uk,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Oxford;NNAISENSE;NNAISENSE;NNAISENSE;University of Oxford,Model Predictive Control;Riccati Equation;Imitation Learning;Safe Learning,46;-1;-1;-1;46,1;-1;-1;-1;1,m;m,europe,uk,y
ICLR,2020,Observational Overfitting in Reinforcement Learning,Xingyou Song;Yiding Jiang;Stephen Tu;Yilun Du;Behnam Neyshabur,xsong@berkeley.edu;ydjiang@google.com;stephentu@google.com;yilundu@mit.edu;neyshabur@google.com,6;8;8,,Accept (Poster),0,6,0,yes,9/25/19,University of California Berkeley;Google;Google;Massachusetts Institute of Technology;Google,observational;overfitting;reinforcement;learning;generalization;implicit;regularization;overparametrization,-1;-1;-1;5;-1,13;-1;-1;5;-1,m;m,NAN,NAN,y
ICLR,2020,Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin,Colin Wei;Tengyu Ma,colinwei@stanford.edu;tengyuma@cs.stanford.edu,3;8;8;6,,Accept (Poster),0,7,0,yes,9/25/19,Stanford University;Stanford University,deep learning theory;generalization bounds;adversarially robust generalization;data-dependent generalization bounds,5;5,4;4,m;m,usa,usa,y
ICLR,2020,SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards,Siddharth Reddy;Anca D. Dragan;Sergey Levine,sgr@berkeley.edu;anca@berkeley.edu;svlevine@eecs.berkeley.edu,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Imitation Learning;Reinforcement Learning,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection,Michael Tsang;Dehua Cheng;Hanpeng Liu;Xue Feng;Eric Zhou;Yan Liu,tsangm@usc.edu;dehuacheng@fb.com;hanpengl@usc.edu;xfeng@fb.com;hanningz@fb.com;yanliu.cs@usc.edu,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Southern California;Facebook;University of Southern California;Facebook;Facebook;University of Southern California,Feature Interaction;Interpretability;Black Box;AutoML,36;-1;36;-1;-1;36,62;-1;62;-1;-1;62,m;f,usa,usa,n
ICLR,2020,Your classifier is secretly an energy based model and you should treat it like one,Will Grathwohl;Kuan-Chieh Wang;Joern-Henrik Jacobsen;David Duvenaud;Mohammad Norouzi;Kevin Swersky,wgrathwohl@cs.toronto.edu;wangkua1@cs.toronto.edu;j.jacobsen@vectorinstitute.ai;duvenaud@cs.toronto.edu;mnorouzi@google.com;kswersky@google.com,6;8;8,,Accept (Talk),0,10,3,yes,9/25/19,University of Toronto;University of Toronto;Vector Institute;University of Toronto;Google;Google,energy based models;adversarial robustness;generative models;out of distribution detection;outlier detection;hybrid models;robustness;calibration,18;18;-1;18;-1;-1,18;18;-1;18;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Pad√© Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks,Alejandro Molina;Patrick Schramowski;Kristian Kersting,molina@cs.tu-darmstadt.de;schramowski@cs.tu-darmstadt.de;kersting@cs.tu-darmstadt.de,6;6;8,,Accept (Poster),0,7,0,yes,9/25/19,TU Darmstadt;TU Darmstadt;TU Darmstadt,,59;59;59,-1;-1;-1,m;m,europe,de,y
ICLR,2020,Lipschitz constant estimation of Neural Networks via sparse polynomial optimization,Fabian Latorre;Paul Rolland;Volkan Cevher,fabian.latorre@epfl.ch;paul.rolland@epfl.ch;volkan.cevher@epfl.ch,8;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,robust networks;Lipschitz constant;polynomial optimization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,AMRL: Aggregated Memory For Reinforcement Learning,Jacob Beck;Kamil Ciosek;Sam Devlin;Sebastian Tschiatschek;Cheng Zhang;Katja Hofmann,jacob_beck@alumni.brown.edu;kamil.ciosek@microsoft.com;sam.devlin@microsoft.com;sebastian.tschiatschek@microsoft.com;cheng.zhang@microsoft.com;katja.hofmann@microsoft.com,6;8;6,,Accept (Poster),0,5,0,yes,9/25/19,Brown University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,deep learning;reinforcement learning;rl;memory;noise;machine learning,85;-1;-1;-1;-1;-1,53;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Memory-Based Graph Networks,Amir Hosein Khasahmadi;Kaveh Hassani;Parsa Moradi;Leo Lee;Quaid Morris,amirhosein.khasahmadi@mail.utoronto.ca;kaveh.hassani@autodesk.com;parsa.moradi73@gmail.com;ljlee@psi.toronto.edu;quaid.morris@utoronto.ca,6;6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Toronto University;Autodesk;;University of Toronto;Toronto University,Graph Neural Networks;Memory Networks;Hierarchial Graph Representation Learning,-1;-1;-1;18;-1,-1;-1;-1;18;-1,m;m,NAN,NAN,n
ICLR,2020,One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation,Shunshi Zhang;Bradly C. Stadie,matthew.zhang@mail.utoronto.ca;bstadie@berkeley.edu,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Toronto University;University of California Berkeley,Pruning;RNNs;Sparsity,-1;-1,-1;13,m;m,usa,usa,n
ICLR,2020,Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning,Kimin Lee;Kibok Lee;Jinwoo Shin;Honglak Lee,kiminlee@kaist.ac.kr;kibok@umich.edu;jinwoos@kaist.ac.kr;honglak@eecs.umich.edu,6;3;8,,Accept (Poster),0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;University of Michigan;Korea Advanced Institute of Science and Technology;University of Michigan,Deep reinforcement learning;Generalization in visual domains,-1;7;-1;7,110;21;110;21,m;m,usa,usa,n
ICLR,2020,On Mutual Information Maximization for Representation Learning,Michael Tschannen;Josip Djolonga;Paul K. Rubenstein;Sylvain Gelly;Mario Lucic,mi.tschannen@gmail.com;josip@djolonga.com;paruby@gmail.com;sylvaingelly@google.com;lucic@google.com,6;8;8,,Accept (Poster),0,3,0,yes,9/25/19,Apple;Google;;Google;Google,mutual information;representation learning;unsupervised learning;self-supervised learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Hypermodels for Exploration,Vikranth Dwaracherla;Xiuyuan Lu;Morteza Ibrahimi;Ian Osband;Zheng Wen;Benjamin Van Roy,vikranthd@google.com;lxlu@google.com;mibrahimi@google.com;iosband@google.com;zhengwen@google.com;benvanroy@google.com,6;8;3,,Accept (Poster),0,7,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,exploration;hypermodel;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,GraphSAINT: Graph Sampling Based Inductive Learning Method,Hanqing Zeng;Hongkuan Zhou;Ajitesh Srivastava;Rajgopal Kannan;Viktor Prasanna,zengh@usc.edu;hongkuaz@usc.edu;ajiteshs@usc.edu;rajgopal.kannan.civ@mail.mil;prasanna@usc.edu,6;6;6,,Accept (Poster),1,5,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;Army Reserach laboratory;University of Southern California,Graph Convolutional Networks;Graph sampling;Network embedding,36;36;36;-1;36,62;62;62;-1;62,m;m,usa,usa,y
ICLR,2020,Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks,Ziwei Ji;Matus Telgarsky,ziweiji2@illinois.edu;mjt@illinois.edu,6;8;8,,Accept (Poster),0,13,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",neural tangent kernel;polylogarithmic width;test error;gradient descent;classification,-1;-1,-1;-1,m;m,usa,usa,y
ICLR,2020,Cross-Lingual Ability of Multilingual BERT: An Empirical Study,Karthikeyan K;Zihan Wang;Stephen Mayhew;Dan Roth,kkarthi@seas.upenn.edu;zihanw2@illinois.edu;mayhew@seas.upenn.edu;danroth@seas.upenn.edu,3;6;6,,Accept (Poster),0,5,0,yes,9/25/19,"University of Pennsylvania;University of Illinois, Urbana Champaign;University of Pennsylvania;University of Pennsylvania",Cross-Lingual Learning;Multilingual BERT,20;-1;20;20,11;-1;11;11,m;m,usa,usa,n
ICLR,2020,Model Based Reinforcement Learning for Atari,≈Åukasz Kaiser;Mohammad Babaeizadeh;Piotr Mi≈Ços;B≈Ça≈ºej Osi≈Ñski;Roy H Campbell;Konrad Czechowski;Dumitru Erhan;Chelsea Finn;Piotr Kozakowski;Sergey Levine;Afroz Mohiuddin;Ryan Sepassi;George Tucker;Henryk Michalewski,lukaszkaiser@google.com;mbz@google.com;pmilos@mimuw.edu.pl;blazej.osinski@gmail.com;rhc@illinois.edu;konrad.czechowski@gmail.com;dumitru@google.com;chelseaf@google.com;kozak000@gmail.com;slevine@google.com;afrozm@google.com;rsepassi@google.com;gjt@google.com;henrykmichalewski@gmail.com,6;8;6,,Accept (Spotlight),0,4,0,yes,9/25/19,"Google;Google;University of Washington, Seattle;Lyft Inc.;University of Illinois, Urbana Champaign;University of Washington, Seattle;Google;Google;;Google;Google;Google;Google;Google",reinforcement learning;model based rl;video prediction model;atari,-1;-1;11;-1;-1;11;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;26;-1;-1;26;-1;-1;-1;-1;-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization,Fan-Yun Sun;Jordan Hoffman;Vikas Verma;Jian Tang,sunfanyun@gmail.com;jhoffmann@g.harvard.edu;vikasverma.iitm@gmail.com;jian.tang@hec.ca,6;6;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Stanford University;Harvard University;Aalto University;HEC Montreal,graph-level representation learning;mutual information maximization,5;52;118;-1,4;7;182;-1,m;m,canada,ca,n
ICLR,2020,Black-Box Adversarial Attack with Transferable Model-based Embedding,Zhichao Huang;Tong Zhang,zhuangbx@connect.ust.hk;tongzhang@tongzhang-ml.org,6;8;6,,Accept (Poster),0,3,0,yes,9/25/19,The Hong Kong University of Science and Technology;Google,adversarial examples;black-box attack;embedding,-1;-1,47;-1,m;m,NAN,NAN,n
ICLR,2020,Inductive Matrix Completion Based on Graph Neural Networks,Muhan Zhang;Yixin Chen,muhan@wustl.edu;chen@cse.wustl.edu,6;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,"Washington University, St. Louis;Washington University, St. Louis",matrix completion;graph neural network,-1;-1,-1;-1,m;m,usa,usa,n
ICLR,2020,Probability Calibration for Knowledge Graph Embedding Models,Pedro Tabacof;Luca Costabello,tabacof@gmail.com;luca.costabello@accenture.com,6;8;6;3,,Accept (Poster),0,5,0,yes,9/25/19,University of Campinas;Accenture,knowledge graph embeddings;probability calibration;calibration;graph representation learning;knowledge graphs,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Intensity-Free Learning of Temporal Point Processes,Oleksandr Shchur;Marin Bilo≈°;Stephan G√ºnnemann,shchur@in.tum.de;bilos@in.tum.de;guennemann@in.tum.de,8;6;8,,Accept (Spotlight),0,5,4,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,Temporal point process;neural density estimation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing,Jinyuan Jia;Xiaoyu Cao;Binghui Wang;Neil Zhenqiang Gong,jinyuan.jia@duke.edu;xiaoyu.cao@duke.edu;binghui.wang@duke.edu;neil.gong@duke.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,Certified Adversarial Robustness;Randomized Smoothing;Adversarial Examples,46;46;46;46,20;20;20;20,m;m,europe,se,y
ICLR,2020,Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee,Wei Hu;Zhiyuan Li;Dingli Yu,huwei@cs.princeton.edu;zhiyuanli@cs.princeton.edu;dingliy@cs.princeton.edu,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Princeton University;Princeton University;Princeton University,deep learning theory;regularization;noisy labels,30;30;30,6;6;6,m;m,usa,usa,y
ICLR,2020,"Understanding l4-based Dictionary Learning: Interpretation, Stability, and Robustness",Yuexiang Zhai;Hermish Mehta;Zhengyuan Zhou;Yi Ma,ysz@berkeley.edu;hermish@berkeley.edu;zyzhou@stanford.edu;yima@eecs.berkeley.edu,8;6,,Accept (Poster),0,2,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,L4-norm Maximization;Robust Dictionary Learning,-1;-1;5;-1,13;13;4;13,m;m,usa,usa,y
ICLR,2020,RGBD-GAN: Unsupervised 3D Representation Learning From Natural Image Datasets via RGBD Image Synthesis,Atsuhiro Noguchi;Tatsuya Harada,noguchi@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,The University of Tokyo;The University of Tokyo,image generation;3D vision;unsupervised representation learning,64;64,36;36,u;m,NAN,NAN,n
ICLR,2020,Estimating counterfactual treatment outcomes over time through adversarially balanced representations,Ioana Bica;Ahmed M Alaa;James Jordon;Mihaela van der Schaar,ioana.bica@eng.ox.ac.uk;a7med3laa@hotmail.com;james.jordon@wolfson.ox.ac.uk;mschaar@turing.ac.uk,6;6;8,,Accept (Spotlight),0,5,0,yes,9/25/19,University of Oxford;;University of Oxford;Alan Turing Institute,treatment effects over time;causal inference;counterfactual estimation,46;-1;46;-1,1;-1;1;-1,f;f,NAN,NAN,y
ICLR,2020,Exploring Model-based Planning with Policy Networks,Tingwu Wang;Jimmy Ba,tingwuwang@cs.toronto.edu;jba@cs.toronto.edu,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Toronto;University of Toronto,reinforcement learning;model-based reinforcement learning;planning,18;18,18;18,m;m,canada,ca,n
ICLR,2020,LambdaNet: Probabilistic Type Inference using Graph Neural Networks,Jiayi Wei;Maruth Goyal;Greg Durrett;Isil Dillig,jiayi@cs.utexas.edu;maruth@utexas.edu;gdurrett@cs.utexas.edu;isil@cs.utexas.edu,6;8;8,,Accept (Poster),0,8,0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",Type inference;Graph neural network;Programming languages;Pointer network,-1;-1;-1;-1,-1;-1;-1;-1,m;f,usa,usa,n
ICLR,2020,Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations,Yichi Zhang;Ritchie Zhao;Weizhe Hua;Nayun Xu;G. Edward Suh;Zhiru Zhang,yz2499@cornell.edu;rz252@cornell.edu;wh399@cornell.edu;nx38@cornell.edu;edward.suh@cornell.edu;zhiruz@cornell.edu,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Cornell University;Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,deep learning;neural network;dynamic quantization;dual precision;efficient gating,7;7;7;7;7;7,19;19;19;19;19;19,m;m,usa,usa,n
ICLR,2020,Variational Template Machine for Data-to-Text Generation,Rong Ye;Wenxian Shi;Hao Zhou;Zhongyu Wei;Lei Li,rye18@fudan.edu.cn;shiwenxian@bytedance.com;zhouhao.nlp@bytedance.com;zywei@fudan.edu.cn;lileilab@bytedance.com,8;3;8,,Accept (Poster),0,4,0,yes,9/25/19,Fudan University;ByteDance;ByteDance;Fudan University;ByteDance,,73;-1;-1;73;-1,109;-1;-1;109;-1,u;m,NAN,NAN,n
ICLR,2020,On Universal Equivariant Set Networks,Nimrod Segol;Yaron Lipman,nimrod.segol@weizmann.ac.il;yaron.lipman@weizmann.ac.il,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Weizmann Institute;Weizmann Institute,deep learning;universality;set functions;equivariance,118;118,-1;-1,m;m,NAN,NAN,y
ICLR,2020,The Gambler's Problem and Beyond,Baoxiang Wang;Shuai Li;Jiajin Li;Siu On Chan,bxwang@cse.cuhk.edu.hk;shuaili8@sjtu.edu.cn;jjli@se.cuhk.edu.hk;siuon@cse.cuhk.edu.hk,6;6;6,,Accept (Poster),0,9,0,yes,9/25/19,"Department of Computer Science and Engineering, The Chinese University of Hong Kong;Shanghai Jiao Tong University;The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong",the gambler's problem;reinforcement learning;fractal;self-similarity;Bellman equation,46;30;316;46,35;157;35;35,m;m,NAN,NAN,y
ICLR,2020,Learning to Represent Programs with Property Signatures,Augustus Odena;Charles Sutton,augustusodena@google.com;csutton@inf.ed.ac.uk,6;6;1,,Accept (Poster),0,8,0,yes,9/25/19,Google;University of Edinburgh,Program Synthesis,-1;36,-1;30,m;m,europe,uk,n
ICLR,2020,Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks,Hae Beom Lee;Hayeon Lee;Donghyun Na;Saehoon Kim;Minseop Park;Eunho Yang;Sung Ju Hwang,haebeom.lee@kaist.ac.kr;hayeon926@kaist.ac.kr;donghyun.na@kaist.ac.kr;shkim@aitrics.com;mike_seop@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,8;8;8,,Accept (Talk),0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;AITRICS;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,meta-learning;few-shot learning;Bayesian neural network;variational inference;learning to learn;imbalanced and out-of-distribution tasks for few-shot learning,-1;-1;-1;-1;-1;-1;-1,110;110;110;-1;-1;110;110,m;m,NAN,NAN,n
ICLR,2020,Smooth markets: A basic mechanism for organizing gradient-based learners,David Balduzzi;Wojciech M. Czarnecki;Tom Anthony;Ian Gemp;Edward Hughes;Joel Leibo;Georgios Piliouras;Thore Graepel,dbalduzzi@google.com;lejlot@google.com;edwardhughes@google.com;jzl@google.com;imgemp@google.com;twa@google.com;georgios.piliouras@gmail.com;thore@google.com,8;8,,Accept (Poster),0,2,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Singapore University of Technology and Design;Google,game theory;optimization;gradient descent;adversarial learning,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Thinking While Moving: Deep Reinforcement Learning with Concurrent Control,Ted Xiao;Eric Jang;Dmitry Kalashnikov;Sergey Levine;Julian Ibarz;Karol Hausman;Alexander Herzog,tedxiao@google.com;ejang@google.com;dkalashnikov@google.com;slevine@google.com;julianibarz@google.com;karolhausman@google.com;alexherzog@google.com,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,deep reinforcement learning;continuous-time;robotics,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Demystifying Inter-Class Disentanglement,Aviv Gabbay;Yedid Hoshen,avivga@gmail.com;yedid@cs.huji.ac.il,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,disentanglement;latent optimization;domain translation,-1;85,-1;216,m;m,europe,il,n
ICLR,2020,Self-Supervised Learning of Appliance Usage,Chen-Yu Hsu;Abbas Zeitoun;Guang-He Lee;Dina Katabi;Tommi Jaakkola,cyhsu@mit.edu;zeitoun@mit.edu;guanghe@csail.mit.edu;dina@csail.mit.edu;tommi@csail.mit.edu,6;3;8,,Accept (Poster),0,6,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Appliance usage;self-supervised learning;multi-modal learning;unsupervised learning,5;5;5;5;5,5;5;5;5;5,m;m,usa,usa,n
ICLR,2020,Higher-Order Function Networks for Learning Composable 3D Object Representations,Eric Mitchell;Selim Engin;Volkan Isler;Daniel D Lee,eric.anthony.mitchell95@gmail.com;engin003@umn.edu;isler@umn.edu;ddlee@seas.upenn.edu,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,"Stanford University;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Pennsylvania",computer vision;3d reconstruction;deep learning;representation learning,-1;73;73;20,-1;79;79;11,m;m,usa,usa,n
ICLR,2020,Learning to solve the credit assignment problem,Benjamin James Lansdell;Prashanth Ravi Prakash;Konrad Paul Kording,ben.lansdell@gmail.com;prprak@seas.upenn.edu;koerding@gmail.com,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,biologically plausible deep learning;node perturbation;REINFORCE;synthetic gradients;feedback alignment,-1;20;20,-1;11;11,m;m,usa,usa,y
ICLR,2020,Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks,Tribhuvanesh Orekondy;Bernt Schiele;Mario Fritz,orekondy@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de;fritz@cispa.saarland,8;3;6,,Accept (Poster),0,6,1,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;CISPA Helmholtz Center for Information Security,model functionality stealing;adversarial machine learning,-1;-1;92,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Difference-Seeking Generative Adversarial Network--Unseen Sample Generation,Yi Lin Sung;Sung-Hsien Hsieh;Soo-Chang Pei;Chun-Shien Lu,r06942076@ntu.edu.tw;parvaty316@hotmail.com;peisc@ntu.edu.tw;lcs@iis.sinica.edu.tw,6;3;6,,Accept (Poster),0,5,0,yes,9/25/19,Nanyang Technological University;;Nanyang Technological University;Academia Sinica,generative adversarial network;semi-supervised learning;novelty detection,43;-1;43;-1,49;-1;49;-1,m;m,NAN,NAN,y
ICLR,2020,Reducing Transformer Depth on Demand with Structured Dropout,Angela Fan;Edouard Grave;Armand Joulin,angelafan@fb.com;egrave@fb.com;ajoulin@fb.com,8;6;6,,Accept (Poster),1,10,0,yes,9/25/19,Facebook;Facebook;Facebook,reduction;regularization;pruning;dropout;transformer,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games,Zuyue Fu;Zhuoran Yang;Yongxin Chen;Zhaoran Wang,zuyuefu2022@u.northwestern.edu;zy6@princeton.edu;yongchen@gatech.edu;zhaoranwang@gmail.com,8;6;6,,Accept (Poster),0,16,0,yes,9/25/19,Northwestern University;Princeton University;Georgia Institute of Technology;Northwestern University,,46;30;13;46,22;6;38;22,m;m,usa,usa,y
ICLR,2020,Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations,Pawel Korus;Nasir Memon,pkorus@nyu.edu;memon@nyu.edu,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,New York University;New York University,image forensics;photo manipulation detection;learned compression;lossy compression;image compression;entropy estimation,22;22,29;29,m;m,usa,usa,n
ICLR,2020,Multi-agent Reinforcement Learning for Networked System Control,Tianshu Chu;Sandeep Chinchali;Sachin Katti,cts198859@hotmail.com;csandeep@stanford.edu;skatti@stanford.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,VMware Research;Stanford University;Stanford University,deep reinforcement learning;multi-agent reinforcement learning;decision and control,-1;5;5,-1;4;4,m;m,usa,usa,y
ICLR,2020,Learning Space Partitions for Nearest Neighbor Search,Yihe Dong;Piotr Indyk;Ilya Razenshteyn;Tal Wagner,yihedong@gmail.com;indyk@mit.edu;ilyaraz@microsoft.com;tal.wagner@gmail.com,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,Microsoft;Massachusetts Institute of Technology;Microsoft;Microsoft,space partition;lsh;locality sensitive hashing;nearest neighbor search,-1;5;-1;-1,-1;5;-1;-1,m;m,NAN,NAN,n
ICLR,2020,On Computation and Generalization of Generative Adversarial Imitation Learning,Minshuo Chen;Yizhou Wang;Tianyi Liu;Zhuoran Yang;Xingguo Li;Zhaoran Wang;Tuo Zhao,mchen393@gatech.edu;wyzjack990122@gmail.com;tianyiliu@gatech.edu;zy6@princeton.edu;xingguol@princeton.edu;zhaoran.wang@northwestern.edu;tourzhao@gatech.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Georgia Institute of Technology;Northeastern University;Georgia Institute of Technology;Princeton University;Princeton University;Northwestern University;Georgia Institute of Technology,,13;16;13;30;30;46;13,38;906;38;6;6;22;38,m;m,usa,usa,y
ICLR,2020,Evaluating The Search Phase of Neural Architecture Search,Kaicheng Yu;Christian Sciuto;Martin Jaggi;Claudiu Musat;Mathieu Salzmann,kaicheng.yu@epfl.ch;sciutochristian@gmail.com;martin.jaggi@epfl.ch;claudiu.musat@swisscom.com;mathieu.salzmann@epfl.ch,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;;Swiss Federal Institute of Technology Lausanne;Swisscom;Swiss Federal Institute of Technology Lausanne,Neural architecture search;parameter sharing;random search;evaluation framework,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Critical initialisation in continuous approximations of binary neural networks,George Stamatescu;Federica Gerace;Carlo Lucibello;Ian Fuss;Langford White,george.stamatescu@gmail.com;federicagerace91@gmail.com;carlo.lucibello@gmail.com;ian.fuss@adelaide.edu.au;lang.white@adelaide.edu.au,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,The University of Adelaide;Swiss Federal Institute of Technology Lausanne;Bocconi University;The University of Adelaide;The University of Adelaide,,102;-1;316;102;102,120;-1;-1;120;120,m;m,NAN,NAN,n
ICLR,2020,Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning,Qian Long*;Zihan Zhou*;Abhinav Gupta;Fei Fang;Yi Wu‚Ä†;Xiaolong Wang‚Ä†,qianlong@cs.cmu.edu;footoredo@sjtu.edu.cn;abhinavg@cs.cmu.edu;feif@cs.cmu.edu;jxwuyi@gmail.com;dragonwxl123@gmail.com,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,"Carnegie Mellon University;Shanghai Jiao Tong University;Carnegie Mellon University;Carnegie Mellon University;Tsinghua University, Tsinghua University;University of California, San Diego",multi-agent reinforcement learning;evolutionary learning;curriculum learning,1;30;1;1;4;-1,27;157;27;27;23;31,f;m,usa,usa,n
ICLR,2020,Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks,Xin Xing;Long Sha;Pengyu Hong;Zuofeng Shang;Jun S. Liu,xin_xing@fas.harvard.edu;longsha@brandeis.edu;hongpeng@brandeis.edu;zuofeng.shang@njit.edu;jliu@stat.harvard.edu,6;6;6,,Accept (Poster),0,10,0,yes,9/25/19,Harvard University;Brandeis University;Brandeis University;New Jersey Institute of Technology;Harvard University,,52;248;248;-1;52,7;244;244;564;7,m;m,usa,usa,y
ICLR,2020,Picking Winning Tickets Before Training by Preserving Gradient Flow,Chaoqi Wang;Guodong Zhang;Roger Grosse,cqwang@cs.toronto.edu;gdzhang@cs.toronto.edu;rgrosse@cs.toronto.edu,6;6;6,,Accept (Poster),0,12,0,yes,9/25/19,University of Toronto;University of Toronto;University of Toronto,neural network;pruning before training;weight pruning,18;18;18,18;18;18,m;m,canada,ca,n
ICLR,2020,CAQL: Continuous Action Q-Learning,Moonkyung Ryu;Yinlam Chow;Ross Anderson;Christian Tjandraatmadja;Craig Boutilier,mkryu@google.com;yinlamchow@google.com;rander@google.com;ctjandra@google.com;cboutilier@google.com,6;6,,Accept (Poster),1,2,0,yes,9/25/19,Google;Google;Google;Google;Google,Reinforcement learning (RL);DQN;Continuous control;Mixed-Integer Programming (MIP),-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Stable Rank Normalization for Improved Generalization in Neural Networks and GANs,Amartya Sanyal;Philip H. Torr;Puneet K. Dokania,amartya.sanyal@cs.ox.ac.uk;philip.torr@eng.ox.ac.uk;puneet@robots.ox.ac.uk,6;8;8,,Accept (Spotlight),0,9,1,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,Generelization;regularization;empirical lipschitz,46;46;46,1;1;1,m;m,europe,uk,y
ICLR,2020,Dynamic Model Pruning with Feedback,Tao Lin;Sebastian U. Stich;Luis Barba;Daniil Dmitriev;Martin Jaggi,tao.lin@epfl.ch;sebastian.stich@epfl.ch;luis.barba@inf.ethz.ch;daniil.dmitriev@epfl.ch;martin.jaggi@epfl.ch,6;6;6,,Accept (Poster),2,5,1,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,network pruning;dynamic reparameterization;model compression,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Emergent Tool Use From Multi-Agent Autocurricula,Bowen Baker;Ingmar Kanitscheider;Todor Markov;Yi Wu;Glenn Powell;Bob McGrew;Igor Mordatch,bowen@openai.com;ingmar@openai.com;todor@openai.com;jxwuyi@openai.com;glenn@openai.com;bmcgrew@openai.com;imordatch@google.com,6;8;3,,Accept (Spotlight),1,5,0,yes,9/25/19,OpenAI;OpenAI;OpenAI;OpenAI;OpenAI;OpenAI;Google,,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Conditional Learning of Fair Representations,Han Zhao;Amanda Coston;Tameem Adel;Geoffrey J. Gordon,han.zhao@cs.cmu.edu;acoston@cs.cmu.edu;tah47@cam.ac.uk;ggordon@cs.cmu.edu,6;6;6,,Accept (Spotlight),0,6,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;University of Cambridge;Carnegie Mellon University,algorithmic fairness;representation learning,1;1;79;1,27;27;3;27,m;m,usa,usa,y
ICLR,2020,You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings,Daniel Ruffinelli;Samuel Broscheit;Rainer Gemulla,daniel@informatik.uni-mannheim.de;broscheit@informatik.uni-mannheim.de;rgemulla@uni-mannheim.de,6;6;8,,Accept (Poster),6,4,0,yes,9/25/19,University of Mannheim;University of Mannheim;University of Mannheim,knowledge graph embeddings;hyperparameter optimization,248;248;248,157;157;157,m;m,europe,de,n
ICLR,2020,Disagreement-Regularized Imitation Learning,Kiante Brantley;Wen Sun;Mikael Henaff,kdbrant@cs.umd.edu;wen.sun@microsoft.com;mihenaff@microsoft.com,8;8;6,,Accept (Spotlight),1,4,1,yes,9/25/19,"University of Maryland, College Park;Microsoft;Microsoft",imitation learning;reinforcement learning;uncertainty,12;-1;-1,91;-1;-1,m;u,NAN,NAN,y
ICLR,2020,Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video,Miguel Jaques;Michael Burke;Timothy Hospedales,m.a.m.jaques@sms.ed.ac.uk;michael.burke@ed.ac.uk;t.hospedales@ed.ac.uk,6;6;6,,Accept (Poster),0,9,0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh,,36;36;36,30;30;30,m;m,europe,uk,n
ICLR,2020,Model-Augmented Actor-Critic: Backpropagating through Paths,Ignasi Clavera;Yao Fu;Pieter Abbeel,iclavera@berkeley.edu;violetfuyao@berkeley.edu;pabbeel@cs.berkeley.edu,3;8;6,,Accept (Poster),0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;model-based;actor-critic;pathwise,-1;-1;-1,13;13;13,m;m,usa,usa,y
ICLR,2020,Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN),Peter Sorrenson;Carsten Rother;Ullrich K√∂the,peter.sorrenson@gmail.com;carsten.rother@iwr.uni-heidelberg.de;ullrich.koethe@iwr.uni-heidelberg.de,6;6;8,,Accept (Spotlight),0,5,0,yes,9/25/19,Heidelberg University;Heidelberg University;Heidelberg University,disentanglement;nonlinear ICA;representation learning;feature discovery;theoretical justification,194;194;194,44;44;44,m;m,europe,de,n
ICLR,2020,Generative Ratio Matching Networks,Akash Srivastava;Kai Xu;Michael U. Gutmann;Charles Sutton,akash.srivastava@me.com;kai.xu@ed.ac.uk;michael.gutmann@ed.ac.uk;charlessutton@google.com,6;6;6,,Accept (Poster),0,10,0,yes,9/25/19,Massachusetts Institute of Technology;University of Edinburgh;University of Edinburgh;Google,deep generative model;deep learning;maximum mean discrepancy;density ratio estimation,5;36;36;-1,5;30;30;-1,m;m,NAN,NAN,y
ICLR,2020,CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning,Jiachen Yang;Alireza Nakhaei;David Isele;Kikuo Fujimura;Hongyuan Zha,yjiachen@gmail.com;anakhaei@honda-ri.com;disele@honda-ri.com;kfujimura@honda-ri.com;zha@cc.gatech.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Georgia Institute of Technology;Honda Research Institute;Honda Research Institute;Honda Research Institute;Georgia Institute of Technology,multi-agent reinforcement learning,13;-1;-1;-1;13,38;-1;-1;-1;38,m;m,usa,usa,y
ICLR,2020,Order Learning and Its Application to Age Estimation,Kyungsun Lim;Nyeong-Ho Shin;Young-Yoon Lee;Chang-Su Kim,kslim@mcl.korea.ac.kr;nhshin@mcl.korea.ac.kr;yy77lee@gmail.com;changsukim@korea.ac.kr,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,Korea University;Korea University;;Korea University,Order learning;age estimation;aesthetic assessment,168;168;-1;168,179;179;-1;179,u;m,asia,kr,n
ICLR,2020,Learning to Link,Maria-Florina Balcan;Travis Dick;Manuel Lang,ninamf@cs.cmu.edu;tdick@ttic.edu;manuel.lang@student.kit.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Carnegie Mellon University;Toyota Technological Institute at Chicago;Karlsruhe Institute of Technology,Data-driven Algorithm Configuration;Metric Learning;Linkage Clustering;Learning Algorithms,1;-1;168,27;-1;174,f;m,europe,de,y
ICLR,2020,DiffTaichi: Differentiable Programming for Physical Simulation,Yuanming Hu;Luke Anderson;Tzu-Mao Li;Qi Sun;Nathan Carr;Jonathan Ragan-Kelley;Fredo Durand,yuanmhu@gmail.com;lukea@mit.edu;tzumao@berkeley.edu;qisu@adobe.com;ncarr@adobe.com;jrk@berkeley.edu;fredo@mit.edu,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley;Adobe Systems;Adobe Systems;University of California Berkeley;Massachusetts Institute of Technology,Differentiable programming;robotics;optimal control;physical simulation;machine learning system,5;5;-1;-1;-1;-1;5,5;5;13;-1;-1;13;5,m;m,usa,usa,n
ICLR,2020,Adaptive Structural Fingerprints for Graph Attention Networks,Kai Zhang;Yaokang Zhu;Jun Wang;Jie Zhang,kzhang980@gmail.com;52184501026@stu.ecnu.edu.cn;wongjun@gmail.com;jzhang080@gmail.com,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Temple University;East China Normal University;;Fudan University,Graph attention networks;graph neural networks;node classification,-1;-1;-1;73,-1;544;-1;109,m;m,asia,cn,n
ICLR,2020,Kernelized Wasserstein Natural Gradient,M Arbel;A Gretton;W Li;G Montufar,michael.n.arbel@gmail.com;arthur.gretton@gmail.com;wcli@math.ucla.edu;guidomontufar@gmail.com,8;6;6,,Accept (Spotlight),0,6,1,yes,9/25/19,"University College London;;University of California, Los Angeles;Max Planck Institute MIS",kernel methods;natural gradient;information geometry;Wasserstein metric,52;-1;-1;-1,-1;-1;17;-1,m;m,NAN,NAN,y
ICLR,2020,DeepV2D: Video to Depth with Differentiable Structure from Motion,Zachary Teed;Jia Deng,zteed@princeton.edu;jiadeng@princeton.edu,8;6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Princeton University;Princeton University,Structure-from-Motion;Video to Depth;Dense Depth Estimation,30;30,6;6,m;m,usa,usa,n
ICLR,2020,Measuring the Reliability of Reinforcement Learning Algorithms,Stephanie C.Y. Chan;Samuel Fishman;Anoop Korattikara;John Canny;Sergio Guadarrama,scychan@google.com;sfishman@google.com;kbanoop@google.com;canny@google.com;sguada@google.com,8;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Google;Google;Google;Google;Google,reinforcement learning;metrics;statistics;reliability,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,SELF: Learning to Filter Noisy Labels with Self-Ensembling,Duc Tam Nguyen;Chaithanya Kumar Mummadi;Thi Phuong Nhung Ngo;Thi Hoai Phuong Nguyen;Laura Beggel;Thomas Brox,ductam.nguyen08@gmail.com;chaithanyakumar.mummadi@de.bosch.com;thiphuongnhung.ngo@de.bosch.com;hoai.phuong.nguyen198@gmail.com;laura.beggel@de.bosch.com;brox@cs.uni-freiburg.de,6;8;3,,Accept (Poster),0,6,1,yes,9/25/19,University of Freiburg;Bosch;Bosch;;Bosch;University of Freiburg,Ensemble Learning;Robust Learning;Noisy Labels;Labels Filtering,-1;-1;-1;-1;-1;-1,-1;297;297;-1;297;-1,m;m,NAN,NAN,n
ICLR,2020,Incorporating BERT into Neural Machine Translation,Jinhua Zhu;Yingce Xia;Lijun Wu;Di He;Tao Qin;Wengang Zhou;Houqiang Li;Tieyan Liu,teslazhu@mail.ustc.edu.cn;yingce.xia@gmail.com;wulijun3@mail2.sysu.edu.cn;di_he@pku.edu.cn;taoqin@microsoft.com;zhwg@ustc.edu.cn;lihq@ustc.edu.cn;tyliu@microsoft.com,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Science and Technology of China;Microsoft;SUN YAT-SEN UNIVERSITY;Peking University;Microsoft;University of Science and Technology of China;University of Science and Technology of China;Microsoft,BERT;Neural Machine Translation,-1;-1;-1;14;-1;-1;-1;-1,80;-1;299;24;-1;80;80;-1,u;m,NAN,NAN,n
ICLR,2020,Mogrifier LSTM,G√°bor Melis;Tom√°≈° Koƒçisk√Ω;Phil Blunsom,melisgl@google.com;tkocisky@google.com;pblunsom@google.com,6;8;8,,Accept (Talk),0,3,0,yes,9/25/19,Google;Google;Google,lstm;language modelling,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Transferring Optimality Across Data Distributions via Homotopy Methods,Matilde Gargiani;Andrea Zanelli;Quoc Tran Dinh;Moritz Diehl;Frank Hutter,gargiani@informatik.uni-freiburg.de;andrea.zanelli@imtek.uni-freiburg.de;quoctd@email.unc.edu;moritz.diehl@imtek.uni-freiburg.de;fh@cs.uni-freiburg.de,3;6;8,,Accept (Poster),0,4,0,yes,9/25/19,"Universit√§t Freiburg;Universit√§t Freiburg;University of North Carolina, Chapel Hill;Universit√§t Freiburg;Universit√§t Freiburg",deep learning;numerical optimization;transfer learning,-1;-1;64;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Quantum Algorithms for Deep Convolutional Neural Networks,Iordanis Kerenidis;Jonas Landman;Anupam Prakash,jkeren@gmail.com;landman@irif.fr;anupamprakash1@gmail.com,6;8;8;6,,Accept (Poster),0,6,0,yes,9/25/19,Universite Paris Diderot;Universite Paris Diderot;Universite Paris Diderot,quantum computing;quantum machine learning;convolutional neural network;theory;algorithm,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Unrestricted Adversarial Examples via Semantic Manipulation,Anand Bhattad;Min Jin Chong;Kaizhao Liang;Bo Li;D. A. Forsyth,bhattad2@illinois.edu;mchong6@illinois.edu;kl2@illinois.edu;lbo@illinois.edu;daf@illinois.edu,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Adversarial Examples;Semantic Manipulation;Image Colorization;Texture Transfer,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n
ICLR,2020,A Stochastic Derivative Free Optimization Method with Momentum,Eduard Gorbunov;Adel Bibi;Ozan Sener;El Houcine Bergou;Peter Richtarik,eduard.gorbunov@phystech.edu;adel.bibi@kaust.edu.sa;ozan.sener@intel.com;houcine.bergou@kaust.edu.sa;peter.richtarik@kaust.edu.sa,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Moscow Institute of Physics and Technology;KAUST;Intel;KAUST;KAUST,derivative-free optimization;stochastic optimization;heavy ball momentum;importance sampling,-1;102;-1;102;102,234;-1;-1;-1;-1,m;m,europe,gr,y
ICLR,2020,Learning The Difference That Makes A Difference With Counterfactually-Augmented Data,Divyansh Kaushik;Eduard Hovy;Zachary Lipton,dkaushik@cs.cmu.edu;hovy@cmu.edu;zlipton@cmu.edu,8;8;1;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,humans in the loop;annotation artifacts;text classification;sentiment analysis;natural language inference,1;1;1,27;27;27,m;m,usa,usa,n
ICLR,2020,Fast is better than free: Revisiting adversarial training,Eric Wong;Leslie Rice;J. Zico Kolter,ericwong@cs.cmu.edu;larice@cs.cmu.edu;zkolter@cs.cmu.edu,6;6;8,,Accept (Poster),10,11,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,adversarial examples;adversarial training;fast gradient sign method,1;1;1,27;27;27,m;m,usa,usa,n
ICLR,2020,Disentangling neural mechanisms for perceptual grouping,Junkyung Kim*;Drew Linsley*;Kalpit Thakkar;Thomas Serre,junkyung_kim@brown.edu;drew_linsley@brown.edu;kalpit_thakkar@brown.edu;thomas_serre@brown.edu,8;6;8,,Accept (Spotlight),0,5,0,yes,9/25/19,Brown University;Brown University;Brown University;Brown University,Perceptual grouping;visual cortex;recurrent feedback;horizontal connections;top-down connections,85;85;85;85,53;53;53;53,m;m,usa,usa,n
ICLR,2020,How to 0wn the NAS in Your Spare Time,Sanghyun Hong;Michael Davinroy;Yi«ßitcan Kaya;Dana Dachman-Soled;Tudor Dumitra≈ü,shhong@cs.umd.edu;michael.davinroy@gmail.com;cankaya@umiacs.umd.edu;danadach@ece.umd.edu;tdumitra@umiacs.umd.edu,6;6;3,,Accept (Poster),0,6,0,yes,9/25/19,"University of Maryland, College Park;;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",Reconstructing Novel Deep Learning Systems,12;-1;12;12;12,91;-1;91;91;91,m;m,usa,usa,n
ICLR,2020,Option Discovery using Deep Skill Chaining,Akhil Bagaria;George Konidaris,akhil_bagaria@brown.edu;gdk@cs.brown.edu,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Brown University;Brown University,Hierarchical Reinforcement Learning;Reinforcement Learning;Skill Discovery;Deep Learning;Deep Reinforcement Learning,85;85,53;53,m;m,usa,usa,n
ICLR,2020,Optimal Strategies Against Generative Attacks,Roy Mor;Erez Peterfreund;Matan Gavish;Amir Globerson,roy16mor@gmail.com;erezpeter@cs.huji.ac.il;matan.gavish@mail.huji.ac.il;amir.globerson@gmail.com,8;8;8;8,,Accept (Talk),0,4,0,yes,9/25/19,Tel Aviv University;Hebrew University of Jerusalem;Hebrew University of Jerusalem;Tel Aviv University,,-1;85;85;30,-1;216;216;188,m;m,europe,il,y
ICLR,2020,Massively Multilingual Sparse Word Representations,G√°bor Berend,berendg@inf.u-szeged.hu,8;8;6,,Accept (Poster),0,5,0,yes,9/25/19,University of Szeged,sparse word representations;multilinguality;sparse coding,445,874,m,europe,de,n
ICLR,2020,RaPP: Novelty Detection with Reconstruction along Projection Pathway,Ki Hyun Kim;Sangwoo Shim;Yongsub Lim;Jongseob Jeon;Jeongwoo Choi;Byungchan Kim;Andre S. Yoon,khkim@makinarocks.ai;sangwoo@makinarocks.ai;yongsub@makinarocks.ai;jongseob.jeon@makinarocks.ai;jeongwoo@makinarocks.ai;kbc8894@makinarocks.ai;andre@makinarocks.ai,6;6;6,,Accept (Poster),0,8,1,yes,9/25/19,MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks;MakinaRocks,Novelty Detection;Anomaly Detection;Outlier Detection;Semi-supervised Learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Domain Adaptive Multibranch Networks,R√≥ger Berm√∫dez-Chac√≥n;Mathieu Salzmann;Pascal Fua,roger.bermudez@epfl.ch;mathieu.salzmann@epfl.ch;pascal.fua@epfl.ch,6;3;8,,Accept (Poster),0,3,1,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Domain Adaptation;Computer Vision,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Continual learning with hypernetworks,Johannes von Oswald;Christian Henning;Jo√£o Sacramento;Benjamin F. Grewe,voswaldj@ethz.ch;henningc@ethz.ch;sacramento@ini.ethz.ch;bgrewe@ethz.ch,6;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Continual Learning;Catastrophic Forgetting;Meta Model;Hypernetwork,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Distributed Bandit Learning: Near-Optimal Regret with Efficient Communication,Yuanhao Wang;Jiachen Hu;Xiaoyu Chen;Liwei Wang,yuanhao-16@mails.tsinghua.edu.cn;nickh@pku.edu.cn;cxy30@pku.edu.cn;wanglw@cis.pku.edu.cn,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Peking University;Peking University;Peking University",Theory;Bandit Algorithms;Communication Efficiency,4;14;14;14,23;24;24;24,m;m,asia,cn,y
ICLR,2020,SVQN: Sequential Variational Soft Q-Learning Networks,Shiyu Huang;Hang Su;Jun Zhu;Ting Chen,huangsy1314@163.com;suhangss@mail.tsinghua.edu.cn;dcszj@tsinghua.edu.cn;tingchen@tsinghua.edu.cn,8;3,,Accept (Poster),0,2,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",reinforcement learning;POMDP;variational inference;generative model,4;4;4;4,23;23;23;23,m;m,NAN,NAN,n
ICLR,2020,PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS,Zhiyuan Li;Jaideep Vitthal Murkute;Prashnna Kumar Gyawali;Linwei Wang,zl7904@rit.edu;jvm6526@rit.edu;pkg2182@rit.edu;linwei.wang@rit.edu,8;6;8,,Accept (Spotlight),0,6,0,yes,9/25/19,Rochester Institute of Technology;Rochester Institute of Technology;Rochester Institute of Technology;Rochester Institute of Technology,generative model;disentanglement;progressive learning;VAE,118;118;118;118,843;843;843;843,m;f,usa,usa,n
ICLR,2020,Learning transport cost from subset correspondence,Ruishan Liu;Akshay Balsubramani;James Zou,ruishan@stanford.edu;akshay7@gmail.com;jamesyzou@gmail.com,3;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Stanford University;;Stanford University,,5;-1;-1,4;-1;-1,f;m,asia,in,y
ICLR,2020,Meta Dropout: Learning to Perturb Latent Features for Generalization,Hae Beom Lee;Taewook Nam;Eunho Yang;Sung Ju Hwang,haebeom.lee@kaist.ac.kr;namsan@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,8;3;6,,Accept (Poster),0,6,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,On Robustness of Neural Ordinary Differential Equations,Hanshu YAN;Jiawei DU;Vincent TAN;Jiashi FENG,hanshu.yan@u.nus.edu;dujiawei@u.nus.edu;vtan@nus.edu.sg;elefjia@nus.edu.sg,6;8;6,,Accept (Spotlight),0,11,1,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;National University of Singapore,Neural ODE,17;17;17;17,25;25;25;25,m;m,asia,sg,y
ICLR,2020,Towards neural networks that provably know when they don't know,Alexander Meinke;Matthias Hein,alexander.meinke@uni-tuebingen.de;matthias.hein@uni-tuebingen.de,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Tuebingen;University of Tuebingen,,143;143,91;91,m;m,europe,de,y
ICLR,2020,Exploration in Reinforcement Learning with Deep Covering Options,Yuu Jinnai;Jee Won Park;Marlos C. Machado;George Konidaris,yuu_jinnai@brown.edu;jee_won_park@brown.edu;marlosm@google.com;gdk@cs.brown.edu,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Brown University;Brown University;Google;Brown University,Reinforcement learning;temporal abstraction;exploration,85;85;-1;85,53;53;-1;53,m;m,usa,usa,n
ICLR,2020,Mixed Precision DNNs: All you need is a good parametrization,Stefan Uhlich;Lukas Mauch;Fabien Cardinaux;Kazuki Yoshiyama;Javier Alonso Garcia;Stephen Tiedemann;Thomas Kemp;Akira Nakamura,stefan.uhlich@sony.com;lukas.mauch@sony.com;fabien.cardinaux@sony.com;kazuki.yoshiyama@sony.com;javier.alonso@sony.com;stephen.tiedemann@sony.com;thomas.kemp@sony.com;akira.b.nakamura@sony.com,6;6;6,,Accept (Poster),1,7,1,yes,9/25/19,Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation;Sony Corporation,Deep Neural Network Compression;Quantization;Straight through gradients,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Depth-Width Trade-offs for ReLU Networks via Sharkovsky's Theorem,Vaggos Chatziafratis;Sai Ganesh Nagarajan;Ioannis Panageas;Xiao Wang,vaggos@cs.stanford.edu;sai_nagarajan@mymail.sutd.edu.sg;ioannis@sutd.edu.sg;xiao_wang@sutd.edu.sg,8;8,,Accept (Spotlight),0,3,0,yes,9/25/19,Stanford University;Singapore University of Technology and Design;Singapore University of Technology and Design;Singapore University of Technology and Design,Depth-Width trade-offs;ReLU networks;chaos theory;Sharkovsky Theorem;dynamical systems,5;-1;-1;-1,4;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Learning to Move with Affordance Maps,William Qi;Ravi Teja Mullapudi;Saurabh Gupta;Deva Ramanan,wq@cs.cmu.edu;raviteja.mullapudi@gmail.com;saurabhg@illinois.edu;deva@cs.cmu.edu,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;University of Illinois, Urbana Champaign;Carnegie Mellon University",navigation;exploration,1;1;-1;1,27;27;-1;27,m;m,usa,usa,n
ICLR,2020,Data-dependent Gaussian Prior Objective for Language Generation,Zuchao Li;Rui Wang;Kehai Chen;Masso Utiyama;Eiichiro Sumita;Zhuosheng Zhang;Hai Zhao,charlee@sjtu.edu.cn;wangrui@nict.go.jp;khchen@nict.go.jp;mutiyama@nict.go.jp;eiichiro.sumita@nict.go.jp;zhangzs@sjtu.edu.cn;zhaohai@cs.sjtu.edu.cn,8;8;8,,Accept (Talk),0,8,0,yes,9/25/19,"Shanghai Jiao Tong University;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University",Gaussian Prior Objective;Language Generation,30;-1;-1;-1;-1;30;30,157;-1;-1;-1;-1;157;157,m;m,asia,cn,n
ICLR,2020,Sign Bits Are All You Need for Black-Box Attacks,Abdullah Al-Dujaili;Una-May O'Reilly,ash.aldujaili@gmail.com;unamay@csail.mit.edu,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Analog Devices;Massachusetts Institute of Technology,Black-box adversarial attack models;Deep Nets;Adversarial Examples;Black-Box Optimization;Zeroth-Order Optimization,-1;5,-1;5,m;f,usa,usa,y
ICLR,2020,Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks,Timothy Tadros;Giri Krishnan;Ramyaa Ramyaa;Maxim Bazhenov,tttadros@ucsd.edu;gkrishnan@ucsd.edu;ramyaa.ramyaa@gmail.com;mbazhenov@ucsd.edu,8;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;;University of California, San Diego",Adversarial Robustness;Generalization;Neural Computing;Deep Learning,-1;-1;-1;-1,31;31;-1;31,m;m,usa,usa,n
ICLR,2020,SNODE: Spectral Discretization of Neural ODEs for System Identification,Alessio Quaglino;Marco Gallieri;Jonathan Masci;Jan Koutn√≠k,alessio@nnaisense.com;marco@nnaisense.com;jonathan@nnaisense.com;jan@nnaisense.com,8;6;6,,Accept (Poster),0,7,0,yes,9/25/19,NNAISENSE;NNAISENSE;NNAISENSE;NNAISENSE,Recurrent neural networks;system identification;neural ODEs,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings,Hongyu Ren*;Weihua Hu*;Jure Leskovec,hyren@cs.stanford.edu;weihuahu@stanford.edu;jure@cs.stanford.edu,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Stanford University;Stanford University;Stanford University,knowledge graph embeddings;logical reasoning;query answering,5;5;5,4;4;4,m;m,usa,usa,y
ICLR,2020,Theory and Evaluation Metrics for Learning Disentangled Representations,Kien Do;Truyen Tran,dkdo@deakin.edu.au;truyen.tran@deakin.edu.au,6;6;6,,Accept (Poster),0,3,1,yes,9/25/19,Deakin University;Deakin University,disentanglement;metrics,-1;-1,332;332,m;m,asia,cn,n
ICLR,2020,Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees,Binghong Chen;Bo Dai;Qinjie Lin;Guo Ye;Han Liu;Le Song,binghong@gatech.edu;bodai@google.com;qinjielin2018@u.northwestern.edu;guoye2018@u.northwestern.edu;hanliu@northwestern.edu;lsong@cc.gatech.edu,8;6;8,,Accept (Spotlight),0,3,0,yes,9/25/19,Georgia Institute of Technology;Google;Northwestern University;Northwestern University;Northwestern University;Georgia Institute of Technology,learning to plan;representation learning;learning to design algorithm;reinforcement learning;meta learning,13;-1;46;46;46;13,38;-1;22;22;22;38,m;m,usa,usa,n
ICLR,2020,And the Bit Goes Down: Revisiting the Quantization of Neural Networks,Pierre Stock;Armand Joulin;R√©mi Gribonval;Benjamin Graham;Herv√© J√©gou,pstock@fb.com;ajoulin@fb.com;remi.gribonval@inria.fr;benjamingraham@fb.com;rvj@fb.com,6;8;6;8,,Accept (Spotlight),0,5,3,yes,9/25/19,Facebook;Facebook;INRIA;Facebook;Facebook,compression;quantization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Continual Learning with Adaptive Weights (CLAW),Tameem Adel;Han Zhao;Richard E. Turner,tah47@cam.ac.uk;han.zhao@cs.cmu.edu;ret26@cam.ac.uk,3;8;3,,Accept (Poster),0,3,1,yes,9/25/19,University of Cambridge;Carnegie Mellon University;University of Cambridge,Continual learning,79;1;79,3;27;3,m;m,europe,uk,n
ICLR,2020,Depth-Adaptive Transformer,Maha Elbayad;Jiatao Gu;Edouard Grave;Michael Auli,maha.elbayad@inria.fr;thomagram@gmail.com;egrave@fb.com;michael.auli@gmail.com,6;3;6,,Accept (Poster),0,7,1,yes,9/25/19,INRIA;Facebook;Facebook;Facebook,Deep learning;natural language processing;sequence modeling,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Robust Local Features for Improving the Generalization of Adversarial Training,Chuanbiao Song;Kun He;Jiadong Lin;Liwei Wang;John E. Hopcroft,cbsong@hust.edu.cn;brooklet60@hust.edu.cn;jdlin@hust.edu.cn;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,6;3;8,,Accept (Poster),0,7,0,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Peking University;Cornell University,adversarial robustness;adversarial training;adversarial example;deep learning,-1;-1;-1;14;7,47;47;47;24;19,m;m,usa,usa,n
ICLR,2020,Learning deep graph matching with channel-independent embedding and Hungarian attention,Tianshu Yu;Runzhong Wang;Junchi Yan;Baoxin Li,tianshuy@asu.edu;runzhong.wang@sjtu.edu.cn;yanjunchi@sjtu.edu.cn;baoxin.li@asu.edu,3;6;6,,Accept (Poster),0,3,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Shanghai Jiao Tong University;Shanghai Jiao Tong University;SUN YAT-SEN UNIVERSITY,deep graph matching;edge embedding;combinatorial problem;Hungarian loss,-1;30;30;-1,299;157;157;299,m;m,NAN,NAN,n
ICLR,2020,Large Batch Optimization for Deep Learning: Training BERT in 76 minutes,Yang You;Jing Li;Sashank Reddi;Jonathan Hseu;Sanjiv Kumar;Srinadh Bhojanapalli;Xiaodan Song;James Demmel;Kurt Keutzer;Cho-Jui Hsieh,youyang@cs.berkeley.edu;jingli@google.com;sashank@google.com;jhseu@google.com;sanjivk@google.com;bsrinadh@google.com;xiaodansong@google.com;demmel@berkeley.edu;keutzer@berkeley.edu;chohsieh@cs.ucla.edu,3;8;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of California Berkeley;Google;Google;Google;Google;Google;Google;University of California Berkeley;University of California Berkeley;University of California, Los Angeles",large-batch optimization;distributed training;fast optimizer,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,13;-1;-1;-1;-1;-1;-1;13;13;17,m;m,usa,usa,y
ICLR,2020,Reanalysis of Variance Reduced Temporal Difference Learning,Tengyu Xu;Zhe Wang;Yi Zhou;Yingbin Liang,xu.3260@osu.edu;wang.10982@osu.edu;yi.zhou@utah.edu;liang.889@osu.edu,3;8;8;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Ohio State University;Ohio State University;University of Utah;Ohio State University,Reinforcement Learning;TD learning;Markovian sample;Variance Reduction,59;59;64;59,70;70;219;70,m;f,usa,usa,y
ICLR,2020,Unsupervised Model Selection for Variational Disentangled Representation Learning,Sunny Duan;Loic Matthey;Andre Saraiva;Nick Watters;Chris Burgess;Alexander Lerchner;Irina Higgins,sunnyd@google.com;lmatthey@google.com;andresnds@google.com;nwatters@google.com;cpburgess@google.com;lerchner@google.com;irinah@google.com,6;6;6,,Accept (Poster),2,14,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,unsupervised disentanglement metric;disentangling;representation learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,On the Weaknesses of Reinforcement Learning for Neural Machine Translation,Leshem Choshen;Lior Fox;Zohar Aizenbud;Omri Abend,leshem.choshen@mail.huji.ac.il;lior.fox@mail.huji.ac.il;zohar.aizenbud@mail.huji.ac.il;oabend@cs.huji.ac.il,6;3;8,,Accept (Poster),0,5,0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Reinforcement learning;MRT;minimum risk training;reinforce;machine translation;peakkiness;generation,85;85;85;85,216;216;216;216,m;m,europe,il,n
ICLR,2020,Training binary neural networks with real-to-binary convolutions,Brais Martinez;Jing Yang;Adrian Bulat;Georgios Tzimiropoulos,brais.mart@gmail.com;psxjy3@nottingham.ac.uk;adrian@adrianbulat.com;yorgos.tzimiropoulos@nottingham.ac.uk,6;6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Samsung;University of Nottingham;Samsung;University of Nottingham,binary networks,-1;194;-1;194,-1;152;-1;152,m;m,europe,uk,n
ICLR,2020,Mixed-curvature Variational Autoencoders,Ondrej Skopek;Octavian-Eugen Ganea;Gary B√©cigneul,oskopek@oskopek.com;oct@mit.edu;garyb@mit.edu,8;8;6,,Accept (Poster),0,6,0,yes,9/25/19,Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology,variational autoencoders;riemannian manifolds;non-Euclidean geometry,-1;5;5,-1;5;5,m;m,usa,usa,y
ICLR,2020,Program Guided Agent,Shao-Hua Sun;Te-Lin Wu;Joseph J. Lim,shaohuas@usc.edu;telinwu@usc.edu;limjj@usc.edu,6;8;8,,Accept (Spotlight),0,16,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,Program Execution;Program Executor;Program Understanding;Program Guided Agent;Learning to Execute;Deep Learning,36;36;36,62;62;62,m;m,usa,usa,n
ICLR,2020,Revisiting Self-Training for Neural Sequence Generation,Junxian He;Jiatao Gu;Jiajun Shen;Marc'Aurelio Ranzato,junxianh@cs.cmu.edu;thomagram@gmail.com;jiajunshen@fb.com;ranzato@fb.com,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook,self-training;semi-supervised learning;neural sequence generatioin,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Ridge Regression: Structure, Cross-Validation, and Sketching",Sifan Liu;Edgar Dobriban,sfliu@stanford.edu;dobribanedgar@gmail.com,6;8,,Accept (Spotlight),0,2,0,yes,9/25/19,Stanford University;University of Pennsylvania,ridge regression;sketching;random matrix theory;cross-validation;high-dimensional asymptotics,5;20,4;11,f;m,usa,usa,y
ICLR,2020,Deep Network Classification by Scattering and Homotopy Dictionary Learning,John Zarka;Louis Thiry;Tomas Angles;Stephane Mallat,john.zarka@ens.fr;louis.thiry@ens.fr;tomas.angles@ens.fr;stephane.mallat@ens.fr,8;6;8,,Accept (Poster),0,4,0,yes,9/25/19,Ecole Normale Superieure;Ecole Normale Superieure;Ecole Normale Superieure;Ecole Normale Superieure,dictionary learning;scattering transform;sparse coding;imagenet,118;118;118;118,-1;-1;-1;-1,m;f,europe,fr,y
ICLR,2020,FreeLB: Enhanced Adversarial Training for Natural Language Understanding,Chen Zhu;Yu Cheng;Zhe Gan;Siqi Sun;Tom Goldstein;Jingjing Liu,chenzhu@cs.umd.edu;yu.cheng@microsoft.com;zhe.gan@microsoft.com;siqi.sun@microsoft.com;tomg@cs.umd.edu;jingjl@microsoft.com,8;8,,Accept (Spotlight),0,3,0,yes,9/25/19,"University of Maryland, College Park;Microsoft;Microsoft;Microsoft;University of Maryland, College Park;Microsoft",,12;-1;-1;-1;12;-1,91;-1;-1;-1;91;-1,m;f,NAN,NAN,n
ICLR,2020,Reinforcement Learning with Competitive  Ensembles of Information-Constrained Primitives,Anirudh Goyal;Shagun Sodhani;Jonathan Binas;Xue Bin Peng;Sergey Levine;Yoshua Bengio,anirudhgoyal9119@gmail.com;sshagunsodhani@gmail.com;jbinas@gmail.com;xbpeng@berkeley.edu;svlevine@eecs.berkeley.edu;yoshua.bengio@mila.quebec,8;6;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Montreal;Facebook;University of Montreal;University of California Berkeley;University of California Berkeley;University of Montreal,Reinforcement Learning;Variational Information Bottleneck;Learning primitives,-1;-1;118;-1;-1;143,-1;-1;85;13;13;336,m;m,NAN,NAN,n
ICLR,2020,Adversarially Robust Representations with Smooth Encoders,Taylan Cemgil;Sumedh Ghaisas;Krishnamurthy (Dj) Dvijotham;Pushmeet Kohli,taylancemgil@google.com;sumedhg@google.com;dvij@google.com;pushmeet@google.com,6;3;8,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Google;Google,Adversarial Learning;Robust Representations;Variational AutoEncoder;Wasserstein Distance;Variational Inference,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Scalable Neural Methods for Reasoning With a Symbolic Knowledge   Base,William W. Cohen;Haitian Sun;R. Alex Hofer;Matthew Siegler,wcohen@google.com;haitiansun@google.com;rofer@google.com;msiegler@google.com,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Google;Google,question-answering;knowledge base completion;neuro-symbolic reasoning;multihop reasoning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Curriculum Loss: Robust Learning and Generalization  against Label Corruption,Yueming Lyu;Ivor W. Tsang,lv_yueming@outlook.com;ivor.tsang@uts.edu.au,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney,Curriculum Learning;deep learning,73;73,193;193,m;m,australasia,au,y
ICLR,2020,Low-dimensional statistical manifold embedding of directed graphs,Thorben Funke;Tian Guo;Alen Lancic;Nino Antulov-Fantulin,fun@biba.uni-bremen.de;tian.guo0980@gmail.com;alen.lancic@math.hr;nino.antulov@gess.ethz.ch,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Universit√§t Bremen;;;Swiss Federal Institute of Technology,graph embedding;information geometry;graph representations,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation,Manoj Kumar;Mohammad Babaeizadeh;Dumitru Erhan;Chelsea Finn;Sergey Levine;Laurent Dinh;Durk Kingma,manojkumarsivaraj334@gmail.com;mb2@uiuc.edu;dumitru@google.com;cbfinn@eecs.berkeley.edu;slevine@google.com;laurentdinh@google.com;d.p.kingma@uva.nl,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,"Google;University of Illinois, Urbana-Champaign;Google;University of California Berkeley;Google;Google;University of Amsterdam",Video generation;flow-based generative models;stochastic video prediction,-1;-1;-1;-1;-1;-1;143,-1;-1;-1;13;-1;-1;62,m;m,europe,nl,n
ICLR,2020,Self-Adversarial Learning with Comparative Discrimination for Text Generation,Wangchunshu Zhou;Tao Ge;Ke Xu;Furu Wei;Ming Zhou,v-waz@microsoft.com;tage@microsoft.com;kexu@nlsde.buaa.edu.cn;fuwei@microsoft.com;mingzhou@microsoft.com,8;3;8,,Accept (Poster),0,6,0,yes,9/25/19,Microsoft;Microsoft;Beihang University;Microsoft;Microsoft,adversarial learning;text generation,-1;-1;102;-1;-1,-1;-1;594;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Deep neuroethology of a virtual rodent,Josh Merel;Diego Aldarondo;Jesse Marshall;Yuval Tassa;Greg Wayne;Bence Olveczky,jsmerel@google.com;diegoaldarondo@g.harvard.edu;jesse_d_marshall@fas.harvard.edu;tassa@google.com;gregwayne@google.com;olveczky@fas.harvard.edu,6;8;6,,Accept (Spotlight),0,4,0,yes,9/25/19,Google;Harvard University;Harvard University;Google;Google;Harvard University,computational neuroscience;motor control;deep RL,-1;52;52;-1;-1;52,-1;7;7;-1;-1;7,m;m,usa,usa,n
ICLR,2020,On the Global Convergence  of Training Deep Linear ResNets,Difan Zou;Philip M. Long;Quanquan Gu,knowzou@ucla.edu;plong@google.com;qgu@cs.ucla.edu,6;6;6,,Accept (Poster),0,9,0,yes,9/25/19,"University of California, Los Angeles;Google;University of California, Los Angeles",,-1;-1;-1,17;-1;17,m;m,usa,usa,y
ICLR,2020,Measuring and Improving the Use of Graph Information in Graph Neural Networks,Yifan Hou;Jian Zhang;James Cheng;Kaili Ma;Richard T. B. Ma;Hongzhi Chen;Ming-Chang Yang,yfhou@cse.cuhk.edu.hk;jzhang@cse.cuhk.edu.hk;jcheng@cse.cuhk.edu.hk;klma@cse.cuhk.edu.hk;tbma@comp.nus.edu.sg;hzchen@cse.cuhk.edu.hk;mcyang@cse.cuhk.edu.hk,8;3;8,,Accept (Poster),0,5,0,yes,9/25/19,"Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;National University of Singapore;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong",,46;46;46;46;17;46;46,35;35;35;35;25;35;35,m;m,NAN,NAN,y
ICLR,2020,AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures,Michael S. Ryoo;AJ Piergiovanni;Mingxing Tan;Anelia Angelova,mryoo@google.com;ajpiergi@indiana.edu;tanmingxing@google.com;anelia@google.com,8;8;6,,Accept (Poster),0,4,1,yes,9/25/19,Google;Indiana University;Google;Google,video representation learning;video understanding;activity recognition;neural architecture search,-1;64;-1;-1,-1;134;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Identity Crisis: Memorization and Generalization Under Extreme Overparameterization,Chiyuan Zhang;Samy Bengio;Moritz Hardt;Michael C. Mozer;Yoram Singer,pluskid@gmail.com;bengio@google.com;moritzhardt@gmail.com;mcmozer@google.com;y.s@cs.princeton.edu,8;6;3,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;;Google;Princeton University,Generalization;Memorization;Understanding;Inductive Bias,-1;-1;-1;-1;30,-1;-1;-1;-1;6,m;m,usa,usa,y
ICLR,2020,Spike-based causal inference for weight alignment,Jordan Guerguiev;Konrad Kording;Blake Richards,jordan.guerguiev@utoronto.ca;koerding@gmail.com;blake.richards@mcgill.ca,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,Toronto University;University of Pennsylvania;McGill University,causal;inference;weight;transport;rdd;regression;discontinuity;design;cifar10;biologically;plausible,-1;20;102,-1;11;42,m;m,canada,ca,n
ICLR,2020,VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning,Luisa Zintgraf;Kyriacos Shiarlis;Maximilian Igl;Sebastian Schulze;Yarin Gal;Katja Hofmann;Shimon Whiteson,luisa.zintgraf@cs.ox.ac.uk;kikos1988@gmail.com;maximilian.igl@gmail.com;sebastian.schulze@eng.ox.ac.uk;yarin.gal@cs.ox.ac.uk;katja.hofmann@microsoft.com;shimon.whiteson@cs.ox.ac.uk,6;8;1;8,,Accept (Poster),0,7,0,yes,9/25/19,University of Oxford;;;University of Oxford;University of Oxford;Microsoft;University of Oxford,Meta-Learning;Bayesian Reinforcement Learning;BAMDPs;Deep Reinforcement Learning,46;-1;-1;46;46;-1;46,1;-1;-1;1;1;-1;1,f;m,europe,uk,n
ICLR,2020,Expected Information Maximization: Using the I-Projection for Mixture Density Estimation,Philipp Becker;Oleg Arenz;Gerhard Neumann,philippbecker93@googlemail.com;oleg@robot-learning.de;geri@robot-learning.de,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Karlsruhe Institute of Technology;TU Darmstadt;Karlsruhe Institute of Technology,density estimation;information projection;mixture models;generative learning;multimodal modeling,168;59;168,174;-1;174,m;m,europe,de,n
ICLR,2020,Fast Task Inference with Variational Intrinsic Successor Features,Steven Hansen;Will Dabney;Andre Barreto;David Warde-Farley;Tom Van de Wiele;Volodymyr Mnih,stevenhansen@google.com;wdabney@google.com;andrebarreto@google.com;dwf@google.com;tvdwiele@gmail.com;vmnih@google.com,6;8;8,,Accept (Talk),0,4,0,yes,9/25/19,Google;Google;Google;Google;;Google,Reinforcement Learning;Variational Intrinsic Control;Successor Features,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Kernel of CycleGAN as a principal homogeneous space,Nikita Moriakov;Jonas Adler;Jonas Teuwen,nikita.moriakov@radboudumc.nl;jonasadl@kth.se;jonas.teuwen@radboudumc.nl,3;6;8,,Accept (Poster),0,3,1,yes,9/25/19,"Radboud University Medical Center;KTH Royal Institute of Technology, Stockholm, Sweden;Radboud University Medical Center",Generative models;CycleGAN,248;194;248,-1;222;-1,f;m,NAN,NAN,y
ICLR,2020,"Generative Models for Effective ML on Private, Decentralized Datasets",Sean Augenstein;H. Brendan McMahan;Daniel Ramage;Swaroop Ramaswamy;Peter Kairouz;Mingqing Chen;Rajiv Mathews;Blaise Aguera y Arcas,saugenst@google.com;mcmahan@google.com;dramage@google.com;swaroopram@google.com;kairouz@google.com;mingqing@google.com;mathews@google.com;blaisea@google.com,6;8;3,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,generative models;federated learning;decentralized learning;differential privacy;privacy;security;GAN,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Gradient-Based Neural DAG Learning,S√©bastien Lachapelle;Philippe Brouillard;Tristan Deleu;Simon Lacoste-Julien,sebastien.lachapelle@umontreal.ca;philippebrouillard@gmail.com;tristan.deleu@gmail.com;slacoste@iro.umontreal.ca,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,University of Montreal;;University of Montreal;University of Montreal,Structure Learning;Causality;Density estimation,118;-1;118;118,85;-1;85;85,m;m,canada,ca,y
ICLR,2020,DeepSphere: a graph-based spherical CNN,Micha√´l Defferrard;Martino Milani;Fr√©d√©rick Gusset;Nathana√´l Perraudin,michael.defferrard@epfl.ch;martino.milani@epfl.ch;frederick.gusset@epfl.ch;nathanael.perraudin@sdsc.ethz.ch,6;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology,spherical cnns;graph neural networks;geometric deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks,Michael Luo;Jiahao Yao;Richard Liaw;Eric Liang;Ion Stoica,michael.luo@berkeley.edu;jiahaoyao@berkeley.edu;rliaw@berkeley.edu;ekhliang@gmail.com;istoica@berkeley.edu,6;6;6;3,,Accept (Poster),0,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Reinforcement Learning;Artificial Intelligence;Distributed Computing;Neural Networks,-1;-1;-1;-1;-1,13;13;13;13;13,m;m,usa,usa,n
ICLR,2020,Improving Neural Language Generation with Spectrum Control,Lingxiao Wang;Jing Huang;Kevin Huang;Ziniu Hu;Guangtao Wang;Quanquan Gu,lingxw@cs.ucla.edu;jing.huang@jd.com;kevin.huang3@jd.com;bull@cs.ucla.edu;guangtao.wang@jd.com;qgu@cs.ucla.edu,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,"University of California, Los Angeles;JD AI Research;JD AI Research;University of California, Los Angeles;JD AI Research;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1,17;-1;-1;17;-1;17,m;m,usa,usa,y
ICLR,2020,Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks,Sanjeev Arora;Simon S. Du;Zhiyuan Li;Ruslan Salakhutdinov;Ruosong Wang;Dingli Yu,arora@cs.princeton.edu;ssdu@ias.edu;zhiyuanli@cs.princeton.edu;rsalakhu@cs.cmu.edu;ruosongw@andrew.cmu.edu;dingliy@cs.princeton.edu,8;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,"Princeton University;Institue for Advanced Study, Princeton;Princeton University;Carnegie Mellon University;Carnegie Mellon University;Princeton University",small data;neural tangent kernel;UCI database;few-shot learning;kernel SVMs;deep learning theory;kernel design,30;-1;30;1;1;30,6;-1;6;27;27;6,m;m,usa,usa,n
ICLR,2020,NAS evaluation is frustratingly hard,Antoine Yang;Pedro M. Esperan√ßa;Fabio M. Carlucci,antoineyang3@gmail.com;pedro.esperanca@huawei.com;fabiom.carlucci@gmail.com,8;1;8,,Accept (Poster),0,4,0,yes,9/25/19,ENS Paris-Saclay;Huawei Technologies Ltd.;Facebook,neural architecture search;nas;benchmark;reproducibility;harking,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Understanding and Robustifying Differentiable Architecture Search,Arber Zela;Thomas Elsken;Tonmoy Saikia;Yassine Marrakchi;Thomas Brox;Frank Hutter,zelaa@cs.uni-freiburg.de;thomas.elsken@de.bosch.com;saikiat@cs.uni-freiburg.de;marrakch@cs.uni-freiburg.de;brox@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,8;8;8,,Accept (Talk),1,5,0,yes,9/25/19,Universit√§t Freiburg;Bosch;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Neural Architecture Search;AutoML;AutoDL;Deep Learning;Computer Vision,-1;-1;-1;-1;-1;-1,-1;297;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Meta-Q-Learning,Rasool Fakoor;Pratik Chaudhari;Stefano Soatto;Alexander J. Smola,rasool.fakoor@mavs.uta.edu;pratikac@seas.upenn.edu;soatto@cs.ucla.edu;alex@smola.org,6;8;8,,Accept (Talk),0,10,0,yes,9/25/19,"University of Texas, Arlington;University of Pennsylvania;University of California, Los Angeles;Carnegie-Mellon University",meta reinforcement learning;propensity estimation;off-policy,-1;20;-1;1,-1;11;17;27,m;m,usa,usa,n
ICLR,2020,Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints,Mengtian Li;Ersin Yumer;Deva Ramanan,mtli@cs.cmu.edu;meyumer@gmail.com;deva@cs.cmu.edu,6;6;6,,Accept (Poster),0,4,1,yes,9/25/19,Carnegie Mellon University;Uber;Carnegie Mellon University,budgeted training;learning rate schedule;linear schedule;annealing;learning rate decay,1;-1;1,27;-1;27,f;m,usa,usa,n
ICLR,2020,Training individually fair ML models with sensitive subspace robustness,Mikhail Yurochkin;Amanda Bower;Yuekai Sun,mikhail.yurochkin@ibm.com;amandarg@umich.edu;yuekai@umich.edu,6;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,International Business Machines;University of Michigan;University of Michigan,fairness;adversarial robustness,-1;7;7,-1;21;21,m;m,usa,usa,y
ICLR,2020,Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation,Hang Gao;Xizhou Zhu;Stephen Lin;Jifeng Dai,hangg@berkeley.edu;ezra0408@mail.ustc.edu.cn;stevelin@microsoft.com;jifdai@microsoft.com,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of California Berkeley;University of Science and Technology of China;Microsoft;Microsoft,Effective Receptive Fields;Deformation Modeling;Dynamic Inference,-1;-1;-1;-1,13;80;-1;-1,m;m,NAN,NAN,n
ICLR,2020,From Variational to Deterministic Autoencoders,Partha Ghosh;Mehdi S. M. Sajjadi;Antonio Vergari;Michael Black;Bernhard Scholkopf,partha.ghosh@tuebingen.mpg.de;msajjadi@tue.mpg.de;antonio.vergari@tuebingen.mpg.de;black@tue.mpg.de;bs@tue.mpg.de,6;8;6,,Accept (Poster),0,11,0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,Unsupervised learning;Generative Models;Variational Autoencoders;Regularization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation,Chence Shi*;Minkai Xu*;Zhaocheng Zhu;Weinan Zhang;Ming Zhang;Jian Tang,chenceshi@pku.edu.cn;mkxu@apex.sjtu.edu.cn;zhaocheng.zhu@umontreal.ca;wnzhang@sjtu.edu.cn;mzhang_cs@pku.edu.cn;jian.tang@hec.ca,6;6;6,,Accept (Poster),0,17,1,yes,9/25/19,Peking University;Shanghai Jiao Tong University;University of Montreal;Shanghai Jiao Tong University;Peking University;HEC Montreal,Molecular graph generation;deep generative models;normalizing flows;autoregressive models,14;30;118;30;14;-1,24;157;85;157;24;-1,m;m,canada,ca,n
ICLR,2020,A Theoretical Analysis of the Number of Shots in Few-Shot Learning,Tianshi Cao;Marc T Law;Sanja Fidler,tianshi.cao@mail.utoronto.ca;law@cs.toronto.edu;fidler@cs.toronto.edu,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Toronto University;University of Toronto;University of Toronto,Few shot learning;Meta Learning;Performance Bounds,-1;18;18,-1;18;18,u;f,canada,ca,y
ICLR,2020,Deep Learning of Determinantal Point Processes via Proper Spectral Sub-gradient,Tianshu Yu;Yikang Li;Baoxin Li,tianshuy@asu.edu;yikang.li@asu.edu;baoxin.li@asu.edu,3;8;6,,Accept (Poster),0,3,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,determinantal point processes;deep learning;optimization,-1;-1;-1,299;299;299,m;m,NAN,NAN,n
ICLR,2020,Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space,AkshatKumar Nigam;Pascal Friederich;Mario Krenn;Alan Aspuru-Guzik,akshat.nigam@mail.utoronto.ca;pascal.friederich@utoronto.ca;mario.krenn@utoronto.ca;alan@aspuru.com,8;3;6,,Accept (Poster),0,7,0,yes,9/25/19,Toronto University;Toronto University;Toronto University;Toronto University,Generative model;Chemical Space;Inverse Molecular Design,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Denoising and Regularization via Exploiting the Structural Bias of Convolutional Generators,Reinhard Heckel and Mahdi Soltanolkotabi,reinhard.heckel@tum.de;msoltoon@gmail.com,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Technical University Munich;University of Southern California,theory for deep learning;convolutional network;deep image prior;deep decoder;dynamics of gradient descent;overparameterization,-1;36,-1;62,m;m,usa,usa,y
ICLR,2020,SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks,Chungkuk Yoo;Bumsoo Kang;Minsik Cho,ckyoo@ibm.com;steve.kang@kaist.ac.kr;thyeros@gmail.com,8;8;3,,Accept (Poster),0,6,0,yes,9/25/19,"International Business Machines;Korea Advanced Institute of Science and Technology;University of Texas, Austin",channel pooling;efficient training and inferencing;lifelong learning;transfer learning;multi task,-1;-1;-1,-1;110;-1,m;f,asia,in,n
ICLR,2020,A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms,Yoshua Bengio;Tristan Deleu;Nasim Rahaman;Nan Rosemary Ke;Sebastien Lachapelle;Olexa Bilaniuk;Anirudh Goyal;Christopher Pal,yoshua.bengio@mila.quebec;tristan.deleu@gmail.com;nasim.rahaman@tuebingen.mpg.de;rosemary.nan.ke@gmail.com;sebastien.lachapelle@umontreal.ca;obilaniu@gmail.com;anirudhgoyal9119@gmail.com;chris.j.pal@gmail.com,8;8;3,,Accept (Poster),0,8,0,yes,9/25/19,Mila;University of Montreal;Max-Planck Institute;;University of Montreal;;;Polytechnique Montreal,meta-learning;transfer learning;structure learning;modularity;causality,143;118;-1;-1;118;-1;-1;316,336;85;-1;-1;85;-1;-1;-1,m;m,canada,ca,y
ICLR,2020,Classification-Based Anomaly Detection for General Data,Liron Bergman;Yedid Hoshen,liron.bergman@mail.huji.ac.il;yedid@cs.huji.ac.il,6;8;8,,Accept (Poster),0,3,1,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,anomaly detection,85;85,216;216,m;m,europe,il,n
ICLR,2020,B-Spline CNNs on Lie groups,Erik J Bekkers,e.j.bekkers@tue.nl,8;3;6,,Accept (Poster),0,6,0,yes,9/25/19,Eindhoven University of Technology,equivariance;Lie groups;B-Splines;G-CNNs;deep learning;group convolution;computer vision;medical image analysis,-1,185,m,NAN,NAN,y
ICLR,2020,Global Relational Models of Source Code,Vincent J. Hellendoorn;Charles Sutton;Rishabh Singh;Petros Maniatis;David Bieber,vjhellendoorn@gmail.com;charlessutton@google.com;rising@google.com;maniatis@google.com;dbieber@google.com,6;6;3,,Accept (Poster),1,8,0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Google,Models of Source Code;Graph Neural Networks;Structured Learning,1;-1;-1;-1;-1,27;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,NeurQuRI: Neural Question Requirement Inspector for Answerability Prediction in Machine Reading Comprehension,Seohyun Back;Sai Chetan Chinthakindi;Akhil Kedia;Haejun Lee;Jaegul Choo,scv.back@samsung.com;sai.chetan@samsung.com;akhil.kedia@samsung.com;haejun82.lee@samsung.com;jchoo@korea.ac.kr,6;8;6,,Accept (Poster),0,6,0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Korea University,Question Answering;Machine Reading Comprehension;Answerability Prediction;Neural Checklist,-1;-1;-1;-1;168,-1;-1;-1;-1;179,m;m,asia,kr,n
ICLR,2020,Adjustable Real-time Style Transfer,Mohammad Babaeizadeh;Golnaz Ghiasi,mb2@uiuc.edu;golnazg@google.com,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of Illinois, Urbana-Champaign;Google",Image Style Transfer;Deep Learning,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,Ranking Policy Gradient,Kaixiang Lin;Jiayu Zhou,linkaixi@msu.edu;jiayuz@msu.edu,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,Michigan State University;Michigan State University,Sample-efficient reinforcement learning;off-policy learning.,102;102,84;84,m;m,usa,usa,y
ICLR,2020,Neural Epitome Search for Architecture-Agnostic Network Compression,Daquan Zhou;Xiaojie Jin;Qibin Hou;Kaixin Wang;Jianchao Yang;Jiashi Feng,zhoudaquan21@gmail.com;jinxiaojie@bytedance.com;andrewhoux@gmail.com;kaixin.wang@u.nus.edu;yangjianchao@bytedance.com;elefjia@nus.edu.sg,6;3;6,,Accept (Poster),0,5,0,yes,9/25/19,National University of Singapore;ByteDance;National University of Singapore;National University of Singapore;ByteDance;National University of Singapore,Network Compression;Classification;Deep Learning;Weights Sharing,-1;-1;17;17;-1;17,-1;-1;25;25;-1;25,u;m,asia,sg,n
ICLR,2020,Learning to Guide Random Search,Ozan Sener;Vladlen Koltun,ozansener@gmail.com;vkoltun@gmail.com,6;8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Intel;Intel,Random search;Derivative-free optimization;Learning continuous control,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,BERTScore: Evaluating Text Generation with BERT,Tianyi Zhang*;Varsha Kishore*;Felix Wu*;Kilian Q. Weinberger;Yoav Artzi,zty27x@gmail.com;vk352@cornell.edu;fw245@cornell.edu;kqw4@cornell.edu;yoav@cs.cornell.edu,8;3;6,,Accept (Poster),0,3,0,yes,9/25/19,Stanford University;Cornell University;Cornell University;Cornell University;Cornell University,Metric;Evaluation;Contextual Embedding;Text Generation,5;7;7;7;7,4;19;19;19;19,m;m,usa,usa,n
ICLR,2020,Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs,Aditya Paliwal;Felix Gimeno;Vinod Nair;Yujia Li;Miles Lubin;Pushmeet Kohli;Oriol Vinyals,adipal@google.com;fgimeno@google.com;vinair@google.com;yujiali@google.com;mlubin@google.com;pushmeet@google.com;vinyals@google.com,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,reinforcement learning;learning to optimize;combinatorial optimization;computation graphs;model parallelism;learning for systems,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Meta-Learning Acquisition Functions for Transfer Learning in Bayesian Optimization,Michael Volpp;Lukas P. Fr√∂hlich;Kirsten Fischer;Andreas Doerr;Stefan Falkner;Frank Hutter;Christian Daniel,mvolpp89@googlemail.com;lukas.froehlich@de.bosch.com;k.fischer-lotte@online.de;andreas.doerr3@de.bosch.com;stefan.falkner@de.bosch.com;fh@cs.uni-freiburg.de;christian.daniel@de.bosch.com,8;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Bosch;Bosch;Forschungszentrum J√ºlich;Bosch;Bosch;Universit√§t Freiburg;Bosch,Transfer Learning;Meta Learning;Bayesian Optimization;Reinforcement Learning,-1;-1;-1;-1;-1;-1;-1,297;297;-1;297;297;-1;297,m;m,NAN,NAN,n
ICLR,2020,Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation,Xinjie Fan;Yizhe Zhang;Zhendong Wang;Mingyuan Zhou,xfan@utexas.edu;yizhe.zhang@microsoft.com;zw2533@columbia.edu;mingyuan.zhou@mccombs.utexas.edu,6;8;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of Texas, Austin;Microsoft;Columbia University;University of Texas, Austin",binary softmax;discrete variables;policy gradient;pseudo actions;reinforcement learning;variance reduction,-1;-1;24;-1,-1;-1;16;-1,m;m,usa,usa,n
ICLR,2020,Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking,Yunhan Jia;Yantao Lu;Junjie Shen;Qi Alfred Chen;Hao Chen;Zhenyu Zhong;Tao Wei,jack0082010@gmail.com;ylu25@syr.edu;junjies1@uci.edu;alfchen@uci.edu;chen@ucdavis.edu;edwardzhong@baidu.com;lenx.wei@gmail.com,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,"University of Michigan;Syracuse University;University of California, Irvine;University of California, Irvine;University of California, Davis;Baidu;Peking University",Adversarial examples;object detection;object tracking;security;autonomous vehicle;deep learning,7;194;-1;-1;-1;-1;-1,21;292;96;96;55;-1;-1,m;m,asia,in,n
ICLR,2020,Pre-training Tasks for Embedding-based Large-scale Retrieval,Wei-Cheng Chang;Felix X. Yu;Yin-Wen Chang;Yiming Yang;Sanjiv Kumar,wchang2@cs.cmu.edu;felixyu@google.com;yinwen@google.com;yiming@cs.cmu.edu;sanjivk@google.com,6;6;1,,Accept (Poster),0,8,0,yes,9/25/19,Carnegie Mellon University;Google;Google;Carnegie Mellon University;Google,natural language processing;large-scale retrieval;unsupervised representation learning;paragraph-level pre-training;two-tower Transformer models,1;-1;-1;1;-1,27;-1;-1;27;-1,m;m,NAN,NAN,n
ICLR,2020,MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius,Runtian Zhai;Chen Dan;Di He;Huan Zhang;Boqing Gong;Pradeep Ravikumar;Cho-Jui Hsieh;Liwei Wang,zhairuntian@pku.edu.cn;cdan@cs.cmu.edu;dihe@microsoft.com;huan@huan-zhang.com;boqinggo@outlook.com;pradeepr@cs.cmu.edu;chohsieh@cs.ucla.edu;wanglw@cis.pku.edu.cn,8;3;6,,Accept (Poster),0,6,0,yes,9/25/19,"Peking University;Carnegie Mellon University;Microsoft;Carnegie Mellon University;International Computer Science Institute;Carnegie Mellon University;University of California, Los Angeles;Peking University",Adversarial Robustness;Provable Adversarial Defense;Randomized Smoothing;Robustness Certification,14;1;-1;1;-1;1;-1;14,24;27;-1;27;-1;27;17;24,m;m,asia,cn,y
ICLR,2020,R√©nyi Fair Inference,Sina Baharlouei;Maher Nouiehed;Ahmad Beirami;Meisam Razaviyayn,baharlou@usc.edu;nouiehed@usc.edu;beirami@mit.edu;razaviya@usc.edu,8;6;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Southern California;University of Southern California;Massachusetts Institute of Technology;University of Southern California,,36;36;5;36,62;62;5;62,m;m,usa,usa,y
ICLR,2020,An Exponential Learning Rate Schedule for Deep Learning,Zhiyuan Li;Sanjeev Arora,zhiyuanli@cs.princeton.edu;arora@cs.princeton.edu,6;8;8;6,,Accept (Spotlight),0,4,0,yes,9/25/19,Princeton University;Princeton University,batch normalization;weight decay;learning rate;deep learning theory,30;30,6;6,m;m,usa,usa,y
ICLR,2020,Graph Convolutional Reinforcement Learning,Jiechuan Jiang;Chen Dun;Tiejun Huang;Zongqing Lu,jiechuan.jiang@pku.edu.cn;cd46@rice.edu;tjhuang@pku.edu.cn;zongqing.lu@pku.edu.cn,6;6;6,,Accept (Poster),1,12,0,yes,9/25/19,Peking University;Rice University;Peking University;Peking University,,14;92;14;14,24;105;24;24,u;m,asia,cn,n
ICLR,2020,In Search for a SAT-friendly Binarized Neural Network Architecture,Nina Narodytska;Hongce Zhang;Aarti Gupta;Toby Walsh,n.narodytska@gmail.com;hongcez@princeton.edu;aartig@cs.princeton.edu;toby.walsh@data61.csiro.au,8;6;6,,Accept (Poster),0,6,0,yes,9/25/19,University of New South Wales;Princeton University;Princeton University;CSIRO,verification;Boolean satisfiability;Binarized Neural Networks,-1;30;30;-1,-1;6;6;-1,f;m,asia,in,n
ICLR,2020,A Constructive Prediction of the Generalization Error Across Scales,Jonathan S. Rosenfeld;Amir Rosenfeld;Yonatan Belinkov;Nir Shavit,jonsr@mit.edu;amir@eecs.yorku.ca;belinkov@mit.edu;shanir@csail.mit.edu,6;8;1,,Accept (Poster),0,5,0,yes,9/25/19,Massachusetts Institute of Technology;York University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,neural networks;deep learning;generalization error;scaling;scalability;vision;language,5;194;5;5,5;416;5;5,m;m,usa,usa,n
ICLR,2020,Improving Generalization in Meta Reinforcement Learning using Learned Objectives,Louis Kirsch;Sjoerd van Steenkiste;Juergen Schmidhuber,louis@idsia.ch;sjoerd@idsia.ch;juergen@idsia.ch,6;6;8,,Accept (Spotlight),0,7,1,yes,9/25/19,IDSIA;IDSIA;IDSIA,meta reinforcement learning;meta learning;reinforcement learning,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning,Akanksha Atrey;Kaleigh Clary;David Jensen,aatrey@cs.umass.edu;kclary@cs.umass.edu;jensen@cs.umass.edu,8;3;1,,Accept (Poster),0,8,0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",explainability;saliency maps;representations;deep reinforcement learning,24;24;24,209;209;209,f;m,usa,usa,n
ICLR,2020,A Generalized Training Approach for Multiagent Learning,Paul Muller;Shayegan Omidshafiei;Mark Rowland;Karl Tuyls;Julien Perolat;Siqi Liu;Daniel Hennes;Luke Marris;Marc Lanctot;Edward Hughes;Zhe Wang;Guy Lever;Nicolas Heess;Thore Graepel;Remi Munos,pmuller@google.com;somidshafiei@google.com;markrowland@google.com;karltuyls@google.com;perolat@google.com;liusiqi@google.com;hennes@google.com;marris@google.com;lanctot@google.com;edwardhughes@google.com;zhewang@google.com;guylever@google.com;heess@google.com;thore@google.com;munos@google.com,8;8;8,,Accept (Talk),0,10,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,multiagent learning;game theory;training;games,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Scalable Model Compression by Entropy Penalized Reparameterization,Deniz Oktay;Johannes Ball√©;Saurabh Singh;Abhinav Shrivastava,doktay@princeton.edu;jballe@google.com;saurabhsingh@google.com;abhinav@cs.umd.edu,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,"Princeton University;Google;Google;University of Maryland, College Park",deep learning;model compression;computer vision;information theory,30;-1;-1;12,6;-1;-1;91,m;m,usa,usa,n
ICLR,2020,Rotation-invariant clustering of neuronal responses in primary visual cortex,Ivan Ustyuzhaninov;Santiago A. Cadena;Emmanouil Froudarakis;Paul G. Fahey;Edgar Y. Walker;Erick Cobos;Jacob Reimer;Fabian H. Sinz;Andreas S. Tolias;Matthias Bethge;Alexander S. Ecker,ivan.ustyuzhaninov@bethgelab.org;santiago.cadena@bethgelab.org;froudara@bcm.edu;paul.fahey@bcm.edu;eywalker@bcm.edu;ecobos@bcm.edu;reimer@bcm.edu;fabian.sinz@bcm.edu;astolias@bcm.edu;matthias@bethgelab.org;alexander.ecker@uni-tuebingen.de,8;8;8,,Accept (Talk),0,7,0,yes,9/25/19,"Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Centre for Integrative Neuroscience, AG Bethge;University of Tuebingen",computational neuroscience;neural system identification;functional cell types;deep learning;rotational equivariance,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;143,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;91,m;m,europe,de,n
ICLR,2020,Ensemble Distribution Distillation,Andrey Malinin;Bruno Mlodozeniec;Mark Gales,am969@yandex-team.ru;bkm28@cam.ac.uk;mjfg@eng.cam.ac.uk,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Yandex;University of Cambridge;University of Cambridge,Ensemble Distillation;Knowledge Distillation;Uncertainty Estimation;Density Estimation,-1;79;79,-1;3;3,m;m,europe,uk,n
ICLR,2020,ES-MAML: Simple Hessian-Free Meta Learning,Xingyou Song;Wenbo Gao;Yuxiang Yang;Krzysztof Choromanski;Aldo Pacchiano;Yunhao Tang,xsong@berkeley.edu;wg2279@columbia.edu;yxyang@google.com;kchoro@google.com;pacchiano@berkeley.edu;yt2541@columbia.edu,8;8;1;6,,Accept (Poster),0,7,0,yes,9/25/19,University of California Berkeley;Columbia University;Google;Google;University of California Berkeley;Columbia University,ES;MAML;evolution;strategies;meta;learning;gaussian;perturbation;reinforcement;learning;adaptation,-1;24;-1;-1;-1;24,13;16;-1;-1;13;16,m;m,usa,usa,n
ICLR,2020,SAdam: A Variant of Adam for Strongly Convex Functions,Guanghui Wang;Shiyin Lu;Quan Cheng;Wei-wei Tu;Lijun Zhang,guhuwang@gmail.com;lsy1116@qq.com;chengquangm@gmail.com;tuwwcn@gmail.com;zljzju@gmail.com,8;6;3,,Accept (Poster),0,8,0,yes,9/25/19,Nanjing University;Zhejiang University;Zhejiang University;4Paradigm Inc.;Zhejiang University,Online convex optimization;Adaptive online learning;Adam,-1;39;39;-1;39,-1;107;107;-1;107,m;m,asia,cn,y
ICLR,2020,Continual Learning with Bayesian Neural Networks for Non-Stationary Data,Richard Kurle;Botond Cseke;Alexej Klushyn;Patrick van der Smagt;Stephan G√ºnnemann,richard.kurle@tum.de;botond.cseke@argmax.ai;a.klushyn@tum.de;smagt@argmax.ai;guennemann@in.tum.de,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,"Technical University Munich;Volkswagen Group, Machine Learning Research Lab (MLRL);Technical University Munich;Volkswagen Group, Machine Learning Research Lab (MLRL);Technical University Munich",Continual Learning;Online Variational Bayes;Non-Stationary Data;Bayesian Neural Networks;Variational Inference;Lifelong Learning;Concept Drift;Episodic Memory,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Automated curriculum generation through setter-solver interactions,Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Timothy Lillicrap,lampinen@stanford.edu;sracaniere@google.com;adamsantoro@google.com;reichert@google.com;vladfi@google.com;countzero@google.com,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Stanford University;Google;Google;Google;Google;Google,Deep Reinforcement Learning;Automatic Curriculum,5;-1;-1;-1;-1;-1,4;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search,Xuanyi Dong;Yi Yang,xuanyi.dxy@gmail.com;yi.yang@uts.edu.au,8;8;8,,Accept (Spotlight),0,14,2,yes,9/25/19,University of Technology Sydney;Zhejiang University,Neural Architecture Search;AutoML;Benchmark,-1;73,-1;193,m;m,australasia,au,n
ICLR,2020,Dynamic Time Lag Regression: Predicting What & When,Mandar Chandorkar;Cyril Furtlehner;Bala Poduval;Enrico Camporeale;Michele Sebag,mandar.chandorkar@cwi.nl;furtlehn@lri.fr;bala.poduval@unh.edu;e.camporeale@cwi.nl;michele.sebag@lri.fr,6;6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,"Centrum voor Wiskunde en Informatica;CNRS, Universit√© Paris-Saclay;University of New Hampshire;Centrum voor Wiskunde en Informatica;CNRS, Universit√© Paris-Saclay",Dynamic Time-Lag Regression;Time Delay;Regression;Time Series,-1;-1;248;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,y
ICLR,2020,Double Neural Counterfactual Regret Minimization,Hui Li;Kailiang Hu;Shaohua Zhang;Yuan Qi;Le Song,ken.lh@antfin.com;hkl163251@antfin.com;yaohua.zsh@antfin.com;yuan.qi@antfin.com;lsong@cc.gatech.edu,6;8,,Accept (Poster),0,2,0,yes,9/25/19,Antfin;Antfin;Antfin;Antfin;Georgia Institute of Technology,Counterfactual Regret Minimization;Imperfect Information game;Neural Strategy;Deep Learning;Robust Sampling,-1;-1;-1;-1;13,-1;-1;-1;-1;38,u;m,usa,usa,y
ICLR,2020,Robust anomaly detection and backdoor attack detection via differential privacy,Min Du;Ruoxi Jia;Dawn Song,min.du@berkeley.edu;ruoxijia@berkeley.edu;dawnsong@berkeley.edu,6;3;6,,Accept (Poster),0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,outlier detection;novelty detection;backdoor attack detection;system log anomaly detection;differential privacy,-1;-1;-1,13;13;13,f;f,usa,usa,y
ICLR,2020,Optimistic Exploration even with a Pessimistic Initialisation,Tabish Rashid;Bei Peng;Wendelin Boehmer;Shimon Whiteson,tabish.rashid@cs.ox.ac.uk;bei.peng@cs.ox.ac.uk;wendelin.boehmer@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Reinforcement Learning;Exploration;Optimistic Initialisation,46;46;46;46,1;1;1;1,m;m,europe,uk,y
ICLR,2020,Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators,Daniel Stoller;Sebastian Ewert;Simon Dixon,d.stoller@qmul.ac.uk;sewert@spotify.com;s.e.dixon@qmul.ac.uk,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Queen Mary University London;Spotify;Queen Mary University London,Adversarial Learning;Semi-supervised Learning;Image generation;Image segmentation;Missing Data,-1;-1;-1,-1;-1;-1,m;m,europe,uk,y
ICLR,2020,Mathematical Reasoning in Latent Space,Dennis Lee;Christian Szegedy;Markus Rabe;Sarah Loos;Kshitij Bansal,ldennis@google.com;szegedy@google.com;mrabe@google.com;smoos@google.com;kbk@google.com,8;8;8,,Accept (Talk),0,7,0,yes,9/25/19,Google;Google;Google;Google;Google,machine learning;formal reasoning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Deep Symbolic Superoptimization Without Human Knowledge,Hui Shi;Yang Zhang;Xinyun Chen;Yuandong Tian;Jishen Zhao,hshi@ucsd.edu;yang.zhang2@ibm.com;xinyun.chen@berkeley.edu;yuandong@fb.com;jzhao@ucsd.edu,6;6;3,,Accept (Poster),0,5,0,yes,9/25/19,"University of California, San Diego;International Business Machines;University of California Berkeley;Facebook;University of California, San Diego",,-1;-1;-1;-1;-1,31;-1;13;-1;31,f;f,usa,usa,n
ICLR,2020,Neural Execution of Graph Algorithms,Petar Veliƒçkoviƒá;Rex Ying;Matilde Padovano;Raia Hadsell;Charles Blundell,petarv@google.com;rexying@stanford.edu;mp861@cam.ac.uk;raia@google.com;cblundell@google.com,8;8;1,,Accept (Poster),0,4,0,yes,9/25/19,Google;Stanford University;University of Cambridge;Google;Google,Graph Neural Networks;Graph Algorithms;Learning to Execute;Program Synthesis;Message Passing Neural Networks;Deep Learning,-1;5;79;-1;-1,-1;4;3;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Encoding word order in complex embeddings,Benyou Wang;Donghao Zhao;Christina Lioma;Qiuchi Li;Peng Zhang;Jakob Grue Simonsen,wang@dei.unipd.it;zhaodh@tju.edu.cn;chrh@di.ku.dk;qiuchili@dei.unipd.it;pzhang@tju.edu.cn;simonsen@di.ku.dk,6;8;6;8,,Accept (Spotlight),0,9,0,yes,9/25/19,Universita' degli studi di Padova;Zhejiang University;University of Copenhagen;Universita' degli studi di Padova;Zhejiang University;University of Copenhagen,word embedding;complex-valued neural network;position embedding,-1;39;92;-1;39;92,-1;107;101;-1;107;101,m;m,europe,dk,y
ICLR,2020,Deep Double Descent: Where Bigger Models and More Data Hurt,Preetum Nakkiran;Gal Kaplun;Yamini Bansal;Tristan Yang;Boaz Barak;Ilya Sutskever,preetum@cs.harvard.edu;galkaplun@g.harvard.edu;ybansal@g.harvard.edu;tristanyang@college.harvard.edu;b@boazbarak.org;ilyasu@openai.com,8;6;6,,Accept (Poster),0,4,1,yes,9/25/19,Harvard University;Harvard University;Harvard University;Harvard University;Harvard University;OpenAI,deep learning;double descent;optimization;SGD;complexity,52;52;52;52;52;-1,7;7;7;7;7;-1,m;m,NAN,NAN,n
ICLR,2020,The Early Phase of Neural Network Training,Jonathan Frankle;David J. Schwab;Ari S. Morcos,jfrankle@mit.edu;dschwab@gc.cuny.edu;arimorcos@gmail.com,8;6;3,,Accept (Poster),0,3,0,yes,9/25/19,Massachusetts Institute of Technology;The City University of New York;Facebook,empirical;learning dynamics;lottery tickets;critical periods;early,5;-1;-1,5;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Don't Use Large Mini-batches, Use Local SGD",Tao Lin;Sebastian U. Stich;Kumar Kshitij Patel;Martin Jaggi,tao.lin@epfl.ch;sebastian.stich@epfl.ch;kumarkshitijpatel@gmail.com;martin.jaggi@epfl.ch,6;6;6,,Accept (Poster),7,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Closer Look at the Optimization Landscapes of Generative Adversarial Networks,Hugo Berard;Gauthier Gidel;Amjad Almahairi;Pascal Vincent;Simon Lacoste-Julien,berard.hugo@gmail.com;gauthier.gidel@umontreal.ca;amjadmahayri@gmail.com;vincentp@iro.umontreal.ca;slacoste@iro.umontreal.ca,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Facebook;University of Montreal;Facebook;University of Montreal;University of Montreal,Deep Learning;Generative models;GANs;Optimization;Visualization,-1;118;-1;118;118,-1;85;-1;85;85,m;m,canada,ca,y
ICLR,2020,Learning to Control PDEs with Differentiable Physics,Philipp Holl;Nils Thuerey;Vladlen Koltun,philipp.holl@tum.de;nils.thuerey@tum.de;vkoltun@gmail.com,6;8;6,,Accept (Spotlight),0,6,0,yes,9/25/19,Technical University Munich;Technical University Munich;Intel,Differentiable physics;Optimal control;Deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network,Taiji Suzuki;Hiroshi Abe;Tomoaki Nishimura,taiji@mist.i.u-tokyo.ac.jp;abe@ipride.co.jp;tomoaki.nishimura@nttdata.com,8;6;6,,Accept (Spotlight),0,8,0,yes,9/25/19,The University of Tokyo;;Nttdata,Generalization error;compression based bound;local Rademacher complexity,64;-1;-1,36;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Rethinking the Hyperparameters for Fine-tuning,Hao Li;Pratik Chaudhari;Hao Yang;Michael Lam;Avinash Ravichandran;Rahul Bhotika;Stefano Soatto,hao.li.ict@gmail.com;pratikac@seas.upenn.edu;lancelot365@gmail.com;michlam@amazon.com;avinash.a.ravichandran@gmail.com;bhotikar@amazon.com;soatto@ucla.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,"Amazon;University of Pennsylvania;Amazon;Amazon;Amazon;Amazon;University of California, Los Angeles",fine-tuning;hyperparameter search;transfer learning,-1;20;-1;-1;-1;-1;-1,-1;11;-1;-1;-1;-1;17,m;m,usa,usa,n
ICLR,2020,PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction,Sangdon Park;Osbert Bastani;Nikolai Matni;Insup Lee,sangdonp@cis.upenn.edu;obastani@seas.upenn.edu;nmatni@seas.upenn.edu;lee@cis.upenn.edu,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,PAC;confidence sets;classification;regression;reinforcement learning,20;20;20;20,11;11;11;11,m;m,usa,usa,y
ICLR,2020,Deep Semi-Supervised Anomaly Detection,Lukas Ruff;Robert A. Vandermeulen;Nico G√∂rnitz;Alexander Binder;Emmanuel M√ºller;Klaus-Robert M√ºller;Marius Kloft,contact@lukasruff.com;vandermeulen@cs.uni-kl.de;nico.goernitz@tu-berlin.de;alexander_binder@sutd.edu.sg;mueller@bit.uni-bonn.de;klaus-robert.mueller@tu-berlin.de;kloft@cs.uni-kl.de,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Aignostics GmbH;TU Kaiserslautern;TU Berlin;Singapore University of Technology and Design;University of Bonn;TU Berlin;TU Kaiserslautern,anomaly detection;deep learning;semi-supervised learning;unsupervised learning;outlier detection;one-class classification;deep anomaly detection;deep one-class classification,-1;194;118;-1;143;118;194,-1;-1;-1;-1;106;-1;-1,m;m,europe,de,n
ICLR,2020,AtomNAS: Fine-Grained End-to-End Neural Architecture Search,Jieru Mei;Yingwei Li;Xiaochen Lian;Xiaojie Jin;Linjie Yang;Alan Yuille;Jianchao Yang,meijieru@gmail.com;yingwei.li@jhu.edu;xiaochen.lian@bytedance.com;jinxiaojie@bytedance.com;linjie.yang@bytedance.com;alan.l.yuille@gmail.com;yangjianchao@bytedance.com,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;ByteDance;ByteDance;ByteDance;Johns Hopkins University;ByteDance,Neural Architecture Search;Image Classification,73;73;-1;-1;-1;73;-1,12;12;-1;-1;-1;12;-1,m;m,NAN,NAN,n
ICLR,2020,"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference",Ting-Kuei Hu;Tianlong Chen;Haotao Wang;Zhangyang Wang,tkhu@tamu.edu;wiwjp619@tamu.edu;htwang@tamu.edu;atlaswang@tamu.edu,8;8;3,,Accept (Poster),0,4,0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;Texas A&M,adversarial robustness;efficient inference,46;46;46;46,177;177;177;177,m;m,NAN,NAN,n
ICLR,2020,CLEVRER: Collision Events for Video Representation and Reasoning,Kexin Yi*;Chuang Gan*;Yunzhu Li;Pushmeet Kohli;Jiajun Wu;Antonio Torralba;Joshua B. Tenenbaum,kyi@g.harvard.edu;ganchuang1990@gmail.com;liyunzhu@mit.edu;pushmeet@google.com;jiajunwu@mit.edu;torralba@mit.edu;jbt@mit.edu,6;8;6,,Accept (Spotlight),0,4,0,yes,9/25/19,Harvard University;;Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neuro-symbolic;Reasoning,52;-1;5;-1;5;5;5,7;-1;5;-1;5;5;5,u;m,usa,usa,n
ICLR,2020,Computation Reallocation for Object Detection,Feng Liang;Chen Lin;Ronghao Guo;Ming Sun;Wei Wu;Junjie Yan;Wanli Ouyang,liangfeng@sensetime.com;linchen@sensetime.com;guoronghao@sensetime.com;sunming1@sensetime.com;wuwei@sensetime.com;yanjunjie@sensetime.com;wanli.ouyang@sydney.edu.au,3;6;6;8,,Accept (Poster),0,6,0,yes,9/25/19,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;University of Sydney,Neural Architecture Search;Object Detection,-1;-1;-1;-1;-1;-1;64,-1;-1;-1;-1;-1;-1;60,m;m,europe,uk,n
ICLR,2020,Making Efficient Use of Demonstrations to Solve Hard Exploration Problems,Caglar Gulcehre;Tom Le Paine;Bobak Shahriari;Misha Denil;Matt Hoffman;Hubert Soyer;Richard Tanburn;Steven Kapturowski;Neil Rabinowitz;Duncan Williams;Gabriel Barth-Maron;Ziyu Wang;Nando de Freitas;Worlds Team,caglarg@google.com;tpaine@google.com;bshahr@google.com;mdenil@google.com;mwhoffman@google.com;soyer@google.com;tanburn@google.com;skapturowski@google.com;ncr@google.com;duncanwilliams@google.com;gabrielbm@google.com;ziyu@google.com;nandodefreitas@google.com;deepmind-worlds-team@google.com,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,imitation learning;deep learning;reinforcement learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks,Sreyas Mohan;Zahra Kadkhodaie;Eero P. Simoncelli;Carlos Fernandez-Granda,sm7582@nyu.edu;zk388@nyu.edu;eero.simoncelli@nyu.edu;cfgranda@cims.nyu.edu,6;6;6,,Accept (Poster),0,4,1,yes,9/25/19,New York University;New York University;New York University;New York University,denoising;overfitting;generalization;robustness;interpretability;analysis of neural networks,22;22;22;22,29;29;29;29,m;m,usa,usa,y
ICLR,2020,Permutation Equivariant Models for Compositional Generalization in Language,Jonathan Gordon;David Lopez-Paz;Marco Baroni;Diane Bouchacourt,jg801@cam.ac.uk;dlp@fb.com;mbaroni@fb.com;dianeb@fb.com,8;6;6,,Accept (Poster),0,5,0,yes,9/25/19,University of Cambridge;Facebook;Facebook;Facebook,Compositionality;Permutation Equivariance;Language Processing,79;-1;-1;-1,3;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Automated Relational Meta-learning,Huaxiu Yao;Xian Wu;Zhiqiang Tao;Yaliang Li;Bolin Ding;Ruirui Li;Zhenhui Li,huaxiuyao@psu.edu;xwu9@nd.edu;zqtao@ece.neu.edu;yaliangl.ub@gmail.com;bolin.ding@alibaba-inc.com;rrli@cs.ucla.edu;jessieli@ist.psu.edu,8;8;3,,Accept (Poster),0,5,0,yes,9/25/19,"Pennsylvania State University;University of Notre Dame;Northeastern University;Alibaba Group;Alibaba Group;University of California, Los Angeles;Pennsylvania State University",meta-learning;task heterogeneity;meta-knowledge graph,43;118;16;-1;-1;-1;43,-1;157;906;-1;-1;17;-1,m;f,usa,usa,n
ICLR,2020,A Probabilistic Formulation of Unsupervised Text Style Transfer,Junxian He;Xinyi Wang;Graham Neubig;Taylor Berg-Kirkpatrick,junxianh@cs.cmu.edu;xinyiw1@cs.cmu.edu;gneubig@cs.cmu.edu;tberg@eng.ucsd.edu,6;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;University of California, San Diego",unsupervised text style transfer;deep latent sequence model,1;1;1;-1,27;27;27;31,m;m,usa,usa,n
ICLR,2020,Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth,Igor Lovchinsky;Alon Daks;Israel Malkin;Pouya Samangouei;Ardavan Saeedi;Yang Liu;Swami Sankaranarayanan;Tomer Gafner;Ben Sternlieb;Patrick Maher;Nathan Silberman,ilovchinsky@butterflynetwork.com;adaks@butterflynetwork.com;imalkin@butterflynetwork.com;psamangouei@butterflynetwork.com;asaeedi@butterflynetwork.com;yliu@butterflynetwork.com;ssankaranarayanan@butterflynetwork.com;tgafner@butterflynetwork.com;bsternlieb@butterflynetwork.com;pmaher@butterflynetwork.com;nsilberman@butterflynetwork.com,8;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc;Butterfly Network Inc,Evaluation Metrics;Medical Imaging,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Combining Q-Learning and Search with Amortized Value Estimates,Jessica B. Hamrick;Victor Bapst;Alvaro Sanchez-Gonzalez;Tobias Pfaff;Theophane Weber;Lars Buesing;Peter W. Battaglia,jhamrick@google.com;vbapst@google.com;alvarosg@google.com;tpfaff@google.com;theophane@google.com;lbuesing@google.com;peterbattaglia@google.com,6;6;6,,Accept (Poster),0,10,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,model-based RL;Q-learning;MCTS;search,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Generalized Convolutional Forest Networks for Domain Generalization and Visual Recognition,Jongbin Ryu;Gitaek Kwon;Ming-Hsuan Yang;Jongwoo Lim,jongbin.ryu@gmail.com;kwongitack@gmail.com;mhyang@ucmerced.edu;jlim@hanyang.ac.kr,6;3;6,,Accept (Poster),0,3,0,yes,9/25/19,Ajou University;;University of California at Merced;Hanyang University,,-1;-1;-1;194,852;-1;-1;393,m;m,asia,kr,n
ICLR,2020,Graph Constrained Reinforcement Learning for Natural Language Action Spaces,Prithviraj Ammanabrolu;Matthew Hausknecht,raj.ammanabrolu@gatech.edu;matthew.hausknecht@microsoft.com,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Georgia Institute of Technology;Microsoft,natural language generation;deep reinforcement learning;knowledge graphs;interactive fiction,13;-1,38;-1,m;m,NAN,NAN,n
ICLR,2020,Improved memory in recurrent neural networks with sequential non-normal dynamics,Emin Orhan;Xaq Pitkow,aeminorhan@gmail.com;xaq@rice.edu,6;8;3,,Accept (Poster),0,5,0,yes,9/25/19,New York University;Rice University,recurrent neural networks;memory;non-normal dynamics,22;92,29;105,m;m,australasia,au,n
ICLR,2020,Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks,Christopher J. Cueva;Peter Y. Wang;Matthew Chin;Xue-Xin Wei,ccueva@gmail.com;peterwang724@gmail.com;mattchin35@gmail.com;weixxpku@gmail.com,6;8;6,,Accept (Spotlight),0,4,0,yes,9/25/19,Columbia University;;;Columbia University,recurrent network;head direction system;neural circuits;neural coding,24;-1;-1;-1,16;-1;-1;-1,m;m,asia,in,n
ICLR,2020,GenDICE: Generalized Offline Estimation of Stationary Values,Ruiyi Zhang*;Bo Dai*;Lihong Li;Dale Schuurmans,ryzhang@cs.duke.edu;bodai@google.com;lihongli.cs@gmail.com;schuurmans@google.com,8;8;8,,Accept (Talk),0,6,0,yes,9/25/19,Duke University;Google;Amazon;Google,Off-policy Policy Evaluation;Reinforcement Learning;Stationary Distribution Correction Estimation;Fenchel Dual,46;-1;-1;-1,20;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Adversarially robust transfer learning,Ali Shafahi;Parsa Saadatpanah;Chen Zhu;Amin Ghiasi;Christoph Studer;David Jacobs;Tom Goldstein,ashafahi@cs.umd.edu;parsa@cs.umd.edu;chenzhu@cs.umd.edu;amin@cs.umd.edu;studer@cornell.edu;djacobs@cs.umd.edu;tomg@cs.umd.edu,8;8;1,,Accept (Poster),0,6,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;Cornell University;University of Maryland, College Park;University of Maryland, College Park",,12;12;12;12;7;12;12,91;91;91;91;19;91;91,m;m,usa,usa,n
ICLR,2020,Learning from Explanations with Neural Execution Tree,Ziqi Wang*;Yujia Qin*;Wenxuan Zhou;Jun Yan;Qinyuan Ye;Leonardo Neves;Zhiyuan Liu;Xiang Ren,ziqi-wan16@mails.tsinghua.edu.cn;qinyj16@mails.tsinghua.edu.cn;zhouwenx@usc.edu;yanjun@usc.edu;qinyuany@usc.edu;lneves@snap.com;liuzy@tsinghua.edu.cn;xiangren@usc.edu,8;8;3,,Accept (Poster),0,6,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Southern California;University of Southern California;University of Southern California;Snap Inc.;Tsinghua University, Tsinghua University;University of Southern California",,4;4;36;36;36;-1;4;36,23;23;62;62;62;-1;23;62,m;m,usa,usa,n
ICLR,2020,Universal Approximation with Certified Networks,Maximilian Baader;Matthew Mirman;Martin Vechev,mbaader@inf.ethz.ch;matthew.mirman@inf.ethz.ch;martin.vechev@inf.ethz.ch,3;8;6,,Accept (Poster),1,7,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,adversarial robustness;universal approximation;certified network;interval bound propagation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Extreme Classification via Adversarial Softmax Approximation,Robert Bamler;Stephan Mandt,rbamler@uci.edu;stephan.mandt@gmail.com,6;3;8,,Accept (Poster),0,3,0,yes,9/25/19,"University of California, Irvine;University of California, Irvine",Extreme classification;negative sampling,-1;-1,96;96,m;m,usa,usa,y
ICLR,2020,Synthesizing Programmatic Policies that Inductively Generalize,Jeevana Priya Inala;Osbert Bastani;Zenna Tavares;Armando Solar-Lezama,jinala@csail.mit.edu;obastani@seas.upenn.edu;zenna@mit.edu;asolar@csail.mit.edu,8;6;6,,Accept (Poster),0,11,0,yes,9/25/19,Massachusetts Institute of Technology;University of Pennsylvania;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Program synthesis;reinforcement learning;inductive generalization,5;20;5;5,5;11;5;5,f;m,usa,usa,n
ICLR,2020,Image-guided Neural Object Rendering,Justus Thies;Michael Zollh√∂fer;Christian Theobalt;Marc Stamminger;Matthias Nie√üner,justus.thies@tum.de;michael@zollhoefer.com;marc.stamminger@fau.de;theobalt@mpi-inf.mpg.de;niessner@tum.de,6;8;3;6,,Accept (Poster),0,1,0,yes,9/25/19,Technical University Munich;Facebook;Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;Max-Planck Institute;Technical University Munich,Neural Rendering;Neural Image Synthesis,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?,Simon S. Du;Sham M. Kakade;Ruosong Wang;Lin F. Yang,ssdu@ias.edu;sham@cs.washington.edu;ruosongw@andrew.cmu.edu;linyang@ee.ucla.edu,6;8;8,,Accept (Spotlight),0,6,0,yes,9/25/19,"Institue for Advanced Study, Princeton;University of Washington;Carnegie Mellon University;University of California, Los Angeles",reinforcement learning;function approximation;lower bound;representation,-1;11;1;-1,-1;26;27;17,m;m,usa,usa,y
ICLR,2020,Interpretable Complex-Valued Neural Networks for Privacy Protection,Liyao Xiang;Hao Zhang;Haotian Ma;Yifan Zhang;Jie Ren;Quanshi Zhang,xiangliyao08@sjtu.edu.cn;1603023-zh@sjtu.edu.cn;11612807@mail.sustc.edu.cn;zhangyf_sjtu@sjtu.edu.cn;ariesrj@sjtu.edu.cn;zqs1022@sjtu.edu.cn,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Deep Learning;Privacy Protection;Complex-Valued Neural Networks,30;30;-1;30;30;30,157;157;80;157;157;157,f;m,asia,cn,n
ICLR,2020,The Shape of Data: Intrinsic Distance for Data Distributions,Anton Tsitsulin;Marina Munkhoeva;Davide Mottin;Panagiotis Karras;Alex Bronstein;Ivan Oseledets;Emmanuel Mueller,tsitsulin@bit.uni-bonn.de;marina.munkhoeva@skolkovotech.ru;davide@cs.au.dk;piekarras@gmail.com;bron@cs.technion.ac.il;i.oseledets@skoltech.ru;mueller@bit.uni-bonn.de,6;6;6,,Accept (Poster),1,4,0,yes,9/25/19,"University of Bonn;Skolkovo Institute of Science and Technology;Aarhus University;Aarhus University;Technion, Technion;Skolkovo Institute of Science and Technology;University of Bonn",Deep Learning;Generative Models;Nonlinear Dimensionality Reduction;Manifold Learning;Similarity and Distance Learning;Spectral Methods,143;-1;92;92;27;-1;143,106;-1;115;115;-1;-1;106,m;m,europe,uk,y
ICLR,2020,Dynamics-Aware Embeddings,William Whitney;Rajat Agarwal;Kyunghyun Cho;Abhinav Gupta,wfwhitney@gmail.com;ra2630@nyu.edu;kyunghyun.cho@nyu.edu;abhinavg@cs.cmu.edu,8;8;6;3,,Accept (Poster),0,8,0,yes,9/25/19,New York University;New York University;New York University;Carnegie Mellon University,representation learning;reinforcement learning;rl,22;22;22;1,29;29;29;27,m;m,usa,usa,n
ICLR,2020,Extreme Tensoring for Low-Memory Preconditioning ,Xinyi Chen;Naman Agarwal;Elad Hazan;Cyril Zhang;Yi Zhang,xinyic@google.com;namanagarwal@google.com;ehazan@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,8;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Google;Google;Princeton University;Princeton University;Princeton University,optimization;deep learning,-1;-1;30;30;30,-1;-1;6;6;6,f;m,usa,usa,y
ICLR,2020,Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue,Byeongchang Kim;Jaewoo Ahn;Gunhee Kim,byeongchang.kim@vision.snu.ac.kr;jaewoo.ahn@vision.snu.ac.kr;gunhee@snu.ac.kr,8;6;8,,Accept (Spotlight),0,3,0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University,dialogue;knowledge;language;conversation,39;39;39,64;64;64,m;m,asia,kr,n
ICLR,2020,Geom-GCN: Geometric Graph Convolutional Networks,Hongbin Pei;Bingzhe Wei;Kevin Chen-Chuan Chang;Yu Lei;Bo Yang,gspeihongbing@163.com;bwei6@illinois.edu;kcchang@illinois.edu;csylei@comp.polyu.edu.hk;ybo@jlu.edu.cn,6;8;6,,Accept (Spotlight),2,6,2,yes,9/25/19,"Xi'an Jiaotong University;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;The Hong Kong Polytechnic University;Jilin University",Deep Learning;Graph Convolutional Network;Network Geometry,-1;-1;-1;118;-1,555;-1;-1;171;952,m;m,NAN,NAN,n
ICLR,2020,Compositional languages emerge in a neural iterated learning model,Yi Ren;Shangmin Guo;Matthieu Labeau;Shay B. Cohen;Simon Kirby,y.ren-18@sms.ed.ac.uk;s.guo-16@sms.ed.ac.uk;matthieu.labeau@gmail.com;scohen@inf.ed.ac.uk;simon.kirby@ed.ac.uk,6;6;6,,Accept (Poster),0,17,0,yes,9/25/19,University of Edinburgh;University of Edinburgh;T√©l√©com ParisTech;University of Edinburgh;University of Edinburgh,Compositionality;Multi-agent;Emergent language;Iterated learning,36;36;-1;36;36,30;30;187;30;30,m;m,europe,uk,n
ICLR,2020,Knowledge Consistency between Neural Networks and Beyond,Ruofan Liang;Tianlin Li;Longfei Li;Jing Wang;Quanshi Zhang,nexuslrf@sjtu.edu.cn;litl@act.buaa.edu.cn;1776752575@sjtu.edu.cn;wangjing215@huawei.com;zqs1022@sjtu.edu.cn,8;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Shanghai Jiao Tong University;Beihang University;Shanghai Jiao Tong University;Huawei Technologies Ltd.;Shanghai Jiao Tong University,Deep Learning;Interpretability;Convolutional Neural Networks,30;102;30;-1;30,157;594;157;-1;157,m;m,asia,cn,n
ICLR,2020,Differentially Private Meta-Learning,Jeffrey Li;Mikhail Khodak;Sebastian Caldas;Ameet Talwalkar,jwl3@andrew.cmu.edu;khodak@cs.cmu.edu;scaldas@cs.cmu.edu;talwalkar@cmu.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Differential Privacy;Meta-Learning;Federated Learning,1;1;1;1,27;27;27;27,m;m,usa,usa,y
ICLR,2020,Stochastic Conditional Generative Networks with Basis Decomposition,Ze Wang;Xiuyuan Cheng;Guillermo Sapiro;Qiang Qiu,ze.w@duke.edu;xiuyuan.cheng@duke.edu;guillermo.sapiro@duke.edu;qiang.qiu@duke.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,,46;46;46;46,20;20;20;20,m;m,europe,se,y
ICLR,2020,Meta-Learning with Warped Gradient Descent,Sebastian Flennerhag;Andrei A. Rusu;Razvan Pascanu;Francesco Visin;Hujun Yin;Raia Hadsell,flennerhag@google.com;andreirusu@google.com;razp@google.com;visin@google.com;hujun.yin@manchester.ac.uk;raia@google.com,8;8;8,,Accept (Talk),2,3,0,yes,9/25/19,Google;Google;Google;Google;University of Manchester;Google,meta-learning;transfer learning,-1;-1;-1;-1;248;-1,-1;-1;-1;-1;55;-1,m;f,NAN,NAN,n
ICLR,2020,Neural Text Generation With Unlikelihood Training,Sean Welleck;Ilia Kulikov;Stephen Roller;Emily Dinan;Kyunghyun Cho;Jason Weston,wellecks@nyu.edu;kulikov@cs.nyu.edu;roller@fb.com;edinan@fb.com;kyunghyun.cho@nyu.edu;jase@fb.com,6;6;3,,Accept (Poster),0,3,0,yes,9/25/19,New York University;New York University;Facebook;Facebook;New York University;Facebook,language modeling;machine learning,22;22;-1;-1;22;-1,29;29;-1;-1;29;-1,m;m,NAN,NAN,n
ICLR,2020,Duration-of-Stay Storage Assignment under Uncertainty,Michael Lingzhi Li;Elliott Wolf;Daniel Wintz,mlli@mit.edu;ewolf@lineagelogistics.com;dwintz@lineagelogistics.com,6;3;6,,Accept (Spotlight),0,16,0,yes,9/25/19,Massachusetts Institute of Technology;Lineagelogistics;Lineagelogistics,Storage Assignment;Deep Learning;Duration-of-Stay;Application;Natural Language Processing;Parallel Network,5;-1;-1,5;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Non-Autoregressive Dialog State Tracking,Hung Le;Richard Socher;Steven C.H. Hoi,l.hung1610@gmail.com;rsocher@salesforce.com;shoi@salesforce.com,6;1;6,,Accept (Poster),1,3,0,yes,9/25/19,Singapore Management University;SalesForce.com;SalesForce.com,task-oriented;dialogues;dialogue state tracking;non-autoregressive,79;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Scalable and Order-robust Continual Learning with Additive Parameter Decomposition,Jaehong Yoon;Saehoon Kim;Eunho Yang;Sung Ju Hwang,jaehong.yoon@kaist.ac.kr;shkim@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,1;6;8,,Accept (Poster),0,16,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Continual Learning;Lifelong Learning;Catastrophic Forgetting;Deep Learning,-1;-1;-1;-1,110;-1;110;110,m;m,NAN,NAN,n
ICLR,2020,Automatically Discovering and Learning New Visual Categories with Ranking Statistics,Kai Han;Sylvestre-Alvise Rebuffi;Sebastien Ehrhardt;Andrea Vedaldi;Andrew Zisserman,khan@robots.ox.ac.uk;srebuffi@robots.ox.ac.uk;hyenal@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk;az@robots.ox.ac.uk,3;6;6,,Accept (Poster),0,5,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,deep learning;classification;novel classes;transfer learning;clustering;incremental learning,46;46;46;46;46,1;1;1;1;1,m;m,europe,uk,n
ICLR,2020,On Identifiability in Transformers,Gino Brunner;Yang Liu;Damian Pascual;Oliver Richter;Massimiliano Ciaramita;Roger Wattenhofer,brunnegi@ethz.ch;liu.yang@alumni.ethz.ch;dpascual@ethz.ch;richtero@ethz.ch;massi@google.com;wattenhofer@ethz.ch,8;6;6,,Accept (Poster),0,7,1,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Google;Swiss Federal Institute of Technology,Self-attention;interpretability;identifiability;BERT;Transformer;NLP;explanation;gradient attribution,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Robust Reinforcement Learning for Continuous Control with Model Misspecification,Daniel J. Mankowitz;Nir Levine;Rae Jeong;Abbas Abdolmaleki;Jost Tobias Springenberg;Yuanyuan Shi;Jackie Kay;Todd Hester;Timothy Mann;Martin Riedmiller,dmankowitz@google.com;nirlevine@google.com;raejeong@google.com;aabdolmaleki@google.com;springenberg@google.com;yyshi@google.com;kayj@google.com;toddhester@google.com;timothymann@google.com;riedmiller@google.com,8;6;6,,Accept (Poster),0,9,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;robustness,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Enhancing Adversarial Defense by k-Winners-Take-All,Chang Xiao;Peilin Zhong;Changxi Zheng,chang@cs.columbia.edu;pz2225@columbia.edu;cxz@cs.columbia.edu,8;8;8,,Accept (Spotlight),0,5,0,yes,9/25/19,Columbia University;Columbia University;Columbia University,adversarial defense;activation function;winner takes all,24;24;24,16;16;16,m;m,usa,usa,y
ICLR,2020,Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction,Taeuk Kim;Jihun Choi;Daniel Edmiston;Sang-goo Lee,taeuk@europa.snu.ac.kr;jhchoi@europa.snu.ac.kr;danedmiston@uchicago.edu;sglee@europa.snu.ac.kr,6;8;6,,Accept (Poster),0,6,0,yes,9/25/19,Seoul National University;Seoul National University;University of Chicago;Seoul National University,,39;39;51;39,64;64;9;64,m;m,asia,kr,n
ICLR,2020,Neural Policy Gradient Methods: Global Optimality and Rates of Convergence,Lingxiao Wang;Qi Cai;Zhuoran Yang;Zhaoran Wang,lingxiaowang2022@u.northwestern.edu;qicai2022@u.northwestern.edu;zy6@princeton.edu;zhaoranwang@gmail.com,8;6;3,,Accept (Poster),0,5,0,yes,9/25/19,Northwestern University;Northwestern University;Princeton University;Northwestern University,,46;46;30;46,22;22;6;22,f;m,usa,usa,y
ICLR,2020,Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier,Connie Kou;Hwee Kuan Lee;Ee-Chien Chang;Teck Khim Ng,conniekoukl@gmail.com;leehk@bii.a-star.edu.sg;changec@comp.nus.edu.sg;ngtk@comp.nus.edu.sg,6;6;3,,Accept (Poster),0,11,0,yes,9/25/19,National University of Singapore;A*STAR;National University of Singapore;National University of Singapore,adversarial attack;transformation defenses;distribution classifier,17;-1;17;17,25;-1;25;25,f;m,asia,sg,n
ICLR,2020,Sample Efficient Policy Gradient Methods with Recursive Variance Reduction,Pan Xu;Felicia Gao;Quanquan Gu,panxu@cs.ucla.edu;fxgao1160@engineering.ucla.edu;qgu@cs.ucla.edu,6;8;6,,Accept (Poster),0,5,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Policy Gradient;Reinforcement Learning;Sample Efficiency,-1;-1;-1,17;17;17,m;m,usa,usa,y
ICLR,2020,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,Zhenzhong Lan;Mingda Chen;Sebastian Goodman;Kevin Gimpel;Piyush Sharma;Radu Soricut,lanzhzh@google.com;mchen@ttic.edu;seabass@google.com;kgimpel@ttic.edu;piyushsharma@google.com;rsoricut@google.com,6;8;8,,Accept (Spotlight),8,8,0,yes,9/25/19,Google;Toyota Technological Institute at Chicago;Google;Toyota Technological Institute at Chicago;Google;Google,Natural Language Processing;BERT;Representation Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,State-only Imitation with Transition Dynamics Mismatch,Tanmay Gangwani;Jian Peng,gangwan2@illinois.edu;jianpeng@illinois.edu,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Imitation learning;Reinforcement Learning;Inverse Reinforcement Learning,-1;-1,-1;-1,m;m,usa,usa,y
ICLR,2020,Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search,Anji Liu;Jianshu Chen;Mingze Yu;Yu Zhai;Xuewen Zhou;Ji Liu,anjiliu219@gmail.com;chenjianshu@gmail.com;yumingze@kuaishou.com;zhaiyu@kuaishou.com;zhouxuewen@kuaishou.com;ji.liu.uwisc@gmail.com,6;8;8,,Accept (Talk),0,9,0,yes,9/25/19,"University of California, Los Angeles;Tencent AI Lab;Kuaishou Technology;Kuaishou Technology;Kuaishou Technology;Kwai Inc.",parallel Monte Carlo Tree Search (MCTS);Upper Confidence bound for Trees (UCT);Reinforcement Learning (RL),-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;m,asia,in,n
ICLR,2020,Gradientless Descent: High-Dimensional Zeroth-Order Optimization,Daniel Golovin;John Karro;Greg Kochanski;Chansoo Lee;Xingyou Song;Qiuyi Zhang,dgg@google.com;karro@google.com;gpk@google.com;chansoo@google.com;xingyousong@google.com;qiuyiz@google.com,6;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Zeroth Order Optimization,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning,Ali Mousavi;Lihong Li;Qiang Liu;Denny Zhou,ali.mousavi1988@gmail.com;lihongli.cs@gmail.com;dennyzhou@google.com;lqiang@cs.utexas.edu,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,"Apple;Amazon;Google;University of Texas, Austin",reinforcement learning;off-policy estimation;importance sampling;propensity score,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Hyper-SAGNN: a self-attention based graph neural network for hypergraphs,Ruochi Zhang;Yuesong Zou;Jian Ma,ruochiz@andrew.cmu.edu;logic.zys@gmail.com;jianma@cs.cmu.edu,8;8,,Accept (Poster),0,3,1,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University,graph neural network;hypergraph;representation learning,1;-1;1,27;-1;27,m;m,usa,usa,n
ICLR,2020,Unpaired Point Cloud Completion on Real Scans using Adversarial Training,Xuelin Chen;Baoquan Chen;Niloy J. Mitra,xuelin.chen.sdu@gmail.com;baoquan.chen@gmail.com;n.mitra@cs.ucl.ac.uk,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Shandong University;Peking University;University College London,point cloud completion;generative adversarial network;real scans,-1;14;52,-1;24;-1,m;m,europe,uk,n
ICLR,2020,The intriguing role of module criticality in the generalization of deep networks,Niladri Chatterji;Behnam Neyshabur;Hanie Sedghi,niladri.chatterji@berkeley.edu;neyshabur@google.com;hsedghi@google.com,8;6;6,,Accept (Spotlight),0,5,0,yes,9/25/19,University of California Berkeley;Google;Google,Module Criticality Phenomenon;Complexity Measure;Deep Learning,-1;-1;-1,13;-1;-1,m;f,NAN,NAN,y
ICLR,2020,SpikeGrad: An ANN-equivalent Computation Model for Implementing Backpropagation with Spikes,Johannes C. Thiele;Olivier Bichler;Antoine Dupret,johannes.thiele@cea.fr;olivier.bichler@cea.fr;antoine.dupret@cea.fr,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,CEA;CEA;CEA,spiking neural network;neuromorphic engineering;backpropagation,194;194;194,1027;1027;1027,m;m,europe,gr,n
ICLR,2020,Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics,Sungyong Seo*;Chuizheng Meng*;Yan Liu,sungyons@usc.edu;chuizhem@usc.edu;yanliu.cs@usc.edu,6;8;8,,Accept (Poster),0,4,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,physics-aware learning;spatial difference operators;sparsely-observed dynamics,36;36;36,62;62;62,m;f,usa,usa,n
ICLR,2020,Neural Network Branching for Neural Network Verification ,Jingyue Lu;M. Pawan Kumar,jingyue.lu@spc.ox.ac.uk;pawan@robots.ox.ac.uk,6;8;8,,Accept (Talk),0,7,0,yes,9/25/19,University of Oxford;University of Oxford,Neural Network Verification;Branch and Bound;Graph Neural Network;Learning to branch,46;46,1;1,f;m,europe,uk,n
ICLR,2020,DivideMix: Learning with Noisy Labels as Semi-supervised Learning,Junnan Li;Richard Socher;Steven C.H. Hoi,junnan.li@salesforce.com;rsocher@salesforce.com;shoi@salesforce.com,6;6;6,,Accept (Poster),1,4,1,yes,9/25/19,SalesForce.com;SalesForce.com;SalesForce.com,label noise;semi-supervised learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,6;6;8,,Accept (Poster),0,6,1,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,deep learning;reinforcement learning;graph neural networks;natural language processing;question generation,248;194;248,438;-1;438,f;m,usa,usa,n
ICLR,2020,Bayesian Meta Sampling for Fast Uncertainty Adaptation,Zhenyi Wang;Yang Zhao;Ping Yu;Ruiyi Zhang;Changyou Chen,zhenyiwa@buffalo.edu;yzhao63@buffalo.edu;pingyu@buffalo.edu;ryzhang@cs.duke.edu;changyou@buffalo.edu,6;6;3,,Accept (Poster),0,6,0,yes,9/25/19,"State University of New York, Buffalo;State University of New York, Buffalo;State University of New York, Buffalo;Duke University;State University of New York, Buffalo",Bayesian Sampling;Uncertainty Adaptation;Meta Learning;Variational Inference,-1;-1;-1;46;-1,-1;-1;-1;20;-1,u;m,NAN,NAN,y
ICLR,2020,BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES,Amin Ghiasi;Ali Shafahi;Tom Goldstein,amin@cs.umd.edu;ashafahi@cs.umd.edu;tomg@cs.umd.edu,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",,12;12;12,91;91;91,m;m,usa,usa,n
ICLR,2020,Progressive Memory Banks for Incremental Domain Adaptation,Nabiha Asghar;Lili Mou;Kira A. Selby;Kevin D. Pantasdo;Pascal Poupart;Xin Jiang,nasghar@uwaterloo.ca;doublepower.mou@gmail.com;kaselby@uwaterloo.ca;kevin.pantasdo@uwaterloo.ca;ppoupart@uwaterloo.ca;jiang.xin@huawei.com,6;6;6,,Accept (Poster),0,0,0,yes,9/25/19,University of Waterloo;University of Alberta;University of Waterloo;University of Waterloo;University of Waterloo;Huawei Technologies Ltd.,natural language processing;domain adaptation,30;102;30;30;30;-1,235;136;235;235;235;-1,f;m,NAN,NAN,y
ICLR,2020,Deep Learning For Symbolic Mathematics,Guillaume Lample;Fran√ßois Charton,guillaume.lample@gmail.com;fcharton@fb.com,8;6;8,,Accept (Spotlight),7,8,0,yes,9/25/19,Facebook;Facebook,symbolic;math;deep learning;transformers,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Contrastive Learning of Structured World Models,Thomas Kipf;Elise van der Pol;Max Welling,t.n.kipf@uva.nl;e.e.vanderpol@uva.nl;m.welling@uva.nl,8;8;8,,Accept (Talk),0,10,1,yes,9/25/19,University of Amsterdam;University of Amsterdam;University of Amsterdam,state representation learning;graph neural networks;model-based reinforcement learning;relational learning;object discovery,143;143;143,62;62;62,m;m,europe,nl,n
ICLR,2020,Decentralized Deep Learning with Arbitrary Communication Compression,Anastasia Koloskova*;Tao Lin*;Sebastian U Stich;Martin Jaggi,anastasia.koloskova@epfl.ch;tao.lin@epfl.ch;sebastian.stich@epfl.ch;martin.jaggi@epfl.ch,3;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Masked Based Unsupervised Content Transfer,Ron Mokady;Sagie Benaim;Lior Wolf;Amit Bermano,sagiebenaim@gmail.com;ron.mokady@gmail.com;wolf@fb.com;amit.bermano@gmail.com,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Tel Aviv University;;Facebook;Tel-Aviv University,,30;-1;-1;-1,188;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Fair Resource Allocation in Federated Learning,Tian Li;Maziar Sanjabi;Ahmad Beirami;Virginia Smith,tianli@cmu.edu;maziar.sanjabi@gmail.com;ahmad.beirami@gmail.com;smithv@cmu.edu,6;3;3,,Accept (Poster),0,5,0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Carnegie Mellon University,federated learning;fairness;distributed optimization,1;-1;-1;1,27;-1;-1;27,f;f,usa,usa,y
ICLR,2020,Gap-Aware Mitigation of Gradient Staleness,Saar Barkai;Ido Hakimi;Assaf Schuster,saarbarkai@gmail.com;idohakimi@gmail.com;assaf@cs.technion.ac.il,6;3;3,,Accept (Poster),0,6,0,yes,9/25/19,Technion;Technion;Technion,distributed;asynchronous;large scale;gradient staleness;staleness penalization;sgd;deep learning;neural networks;optimization,-1;27;27,-1;-1;-1,u;m,NAN,NAN,y
ICLR,2020,A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES,Krishnamurthy (Dj) Dvijotham;Jamie Hayes;Borja Balle;Zico Kolter;Chongli Qin;Andras Gyorgy;Kai Xiao;Sven Gowal;Pushmeet Kohli,dvij@google.com;j.hayes@cs.ucl.ac.uk;bballe@google.com;zkolter@cs.cmu.edu;chongliqin@google.com;agyorgy@google.com;kaix@mit.edu;sgowal@google.com;pushmeet@google.com,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Google;University College London;Google;Carnegie Mellon University;Google;Google;Massachusetts Institute of Technology;Google;Google,verification of machine learning;certified robustness of neural networks,-1;52;-1;1;-1;-1;5;-1;-1,-1;-1;-1;27;-1;-1;5;-1;-1,m;m,NAN,NAN,y
ICLR,2020,I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively,Haotao Wang;Tianlong Chen;Zhangyang Wang;Kede Ma,htwang@tamu.edu;wiwjp619@tamu.edu;atlaswang@tamu.edu;kede.ma@cityu.edu.hk,3;8;3,,Accept (Poster),0,9,0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;The Hong Kong Polytechnic University,model comparison,46;46;46;118,177;177;177;171,m;m,asia,hk,n
ICLR,2020,Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification,Bennet Breier;Arno Onken,b.breier@sms.ed.ac.uk;aonken@inf.ed.ac.uk,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Edinburgh;University of Edinburgh,convolutional neural networks;neural network transparency;AI explainability;deep Taylor decomposition;supervised classification;zebrafish;transparency;behavioral research;optical flow,36;36,30;30,m;m,europe,uk,n
ICLR,2020,"On the steerability"" of generative adversarial networks""",Ali Jahanian*;Lucy Chai*;Phillip Isola,jahanian@mit.edu;lrchai@mit.edu;phillipi@mit.edu,8;8;8,,Accept (Poster),0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,generative adversarial network;latent space interpolation;dataset bias;model generalization,5;5;5,5;5;5,m;m,usa,usa,n
ICLR,2020,Imitation Learning via Off-Policy Distribution Matching,Ilya Kostrikov;Ofir Nachum;Jonathan Tompson,kostrikov@cs.nyu.edu;ofirnachum@google.com;tompson@google.com,6;6;6,,Accept (Poster),0,5,1,yes,9/25/19,New York University;Google;Google,reinforcement learning;deep learning;imitation learning;adversarial learning,22;-1;-1,29;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Function Space View of Bounded Norm Infinite Width ReLU Nets: The Multivariate Case,Greg Ongie;Rebecca Willett;Daniel Soudry;Nathan Srebro,gongie@uchicago.edu;willett@uchicago.edu;daniel.soudry@technion.ac.il;nati@ttic.edu,8;6;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of Chicago;University of Chicago;Technion, Technion;Toyota Technological Institute at Chicago",inductive bias;regularization;infinite-width networks;ReLU networks,51;51;27;-1,9;9;-1;-1,m;m,NAN,NAN,y
ICLR,2020,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,Kevin Clark;Minh-Thang Luong;Quoc V. Le;Christopher D. Manning,kevclark@cs.stanford.edu;thangluong@google.com;qvl@google.com;manning@cs.stanford.edu,8;6;8,,Accept (Poster),1,6,0,yes,9/25/19,Stanford University;Google;Google;Stanford University,Natural Language Processing;Representation Learning,5;-1;-1;5,4;-1;-1;4,m;m,usa,usa,n
ICLR,2020,Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel,Xin Qiu;Elliot Meyerson;Risto Miikkulainen,qiuxin.nju@gmail.com;elliot.meyerson@cognizant.com;risto@cognizant.com,6;6;8;6,,Accept (Poster),0,11,0,yes,9/25/19,Cognizant;Cognizant;Cognizant,Uncertainty Estimation;Neural Networks;Gaussian Process,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Span Recovery for Deep Neural Networks with Applications to Input Obfuscation,Rajesh Jayaram;David P. Woodruff;Qiuyi Zhang,rkjayara@cs.cmu.edu;dwoodruf@andrew.cmu.edu;qiuyiz@google.com,3;6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Google,Span recovery;low rank neural networks;adversarial attack,1;1;-1,27;27;-1,m;m,NAN,NAN,y
ICLR,2020,Posterior sampling for multi-agent reinforcement learning: solving extensive games with imperfect information,Yichi Zhou;Jialian Li;Jun Zhu,vofhqn@gmail.com;lijialia16@mails.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,6;6;8,,Accept (Talk),0,8,0,yes,9/25/19,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University",,-1;4;4,-1;23;23,m;m,NAN,NAN,y
ICLR,2020,Co-Attentive Equivariant Neural Networks: Focusing Equivariance On Transformations Co-Occurring in Data,David W. Romero;Mark Hoogendoorn,d.w.romeroguzman@vu.nl;m.hoogendoorn@vu.nl,6;8;6,,Accept (Poster),0,11,0,yes,9/25/19,VU University Amsterdam;VU University Amsterdam,Equivariant Neural Networks;Attention Mechanisms;Deep Learning,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Explanation  by Progressive  Exaggeration,Sumedha Singla;Brian Pollack;Junxiang Chen;Kayhan Batmanghelich,sumedha.singla@pitt.edu;kayhan@pitt.edu;cjx880409@gmail.com;kayhan@pitt.edu,8;6,,Accept (Spotlight),0,3,0,yes,9/25/19,University of Pittsburgh;University of Pittsburgh;;University of Pittsburgh,Explain;deep learning;black box;GAN;counterfactual,79;79;-1;79,113;113;-1;113,f;m,usa,usa,n
ICLR,2020,Principled Weight Initialization for Hypernetworks,Oscar Chang;Lampros Flokas;Hod Lipson,oscar.chang@columbia.edu;lamflokas@cs.columbia.edu;hod.lipson@columbia.edu,8;8;8,,Accept (Talk),0,6,1,yes,9/25/19,Columbia University;Columbia University;Columbia University,hypernetworks;initialization;optimization;meta-learning,24;24;24,16;16;16,m;m,usa,usa,n
ICLR,2020,On the Variance of the Adaptive Learning Rate and Beyond,Liyuan Liu;Haoming Jiang;Pengcheng He;Weizhu Chen;Xiaodong Liu;Jianfeng Gao;Jiawei Han,ll2@illinois.edu;jianghm@gatech.edu;penhe@microsoft.com;wzchen@microsoft.com;xiaodl@microsoft.com;jfgao@microsoft.com;hanj@illinois.edu,6;6;6,,Accept (Poster),4,5,0,yes,9/25/19,"University of Illinois, Urbana Champaign;Georgia Institute of Technology;Microsoft;Microsoft;Microsoft;Microsoft;University of Illinois, Urbana Champaign",warmup;adam;adaptive learning rate;variance,-1;13;-1;-1;-1;-1;-1,-1;38;-1;-1;-1;-1;-1,u;m,usa,usa,y
ICLR,2020,Curvature Graph Network,Ze Ye;Kin Sum Liu;Tengfei Ma;Jie Gao;Chao Chen,yeze16159@gmail.com;kiliu@cs.stonybrook.edu;tengfei.ma1@ibm.com;jgao@cs.stonybrook.edu;chao.chen.1@stonybrook.edu,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;International Business Machines;State University of New York, Stony Brook;State University of New York, Stony Brook",Deep Learning;Graph Convolution;Ricci Curvature.,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,"Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds",Jordan T. Ash;Chicheng Zhang;Akshay Krishnamurthy;John Langford;Alekh Agarwal,jordanta@cs.princeton.edu;chichengz@cs.arizona.edu;akshay.krishnamurthy@microsoft.com;jcl@microsoft.com;alekha@microsoft.com,8;6;8,,Accept (Talk),0,4,0,yes,9/25/19,Princeton University;University of Arizona;Microsoft;Microsoft;Microsoft,deep learning;active learning;batch active learning,30;194;-1;-1;-1,6;103;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,StructPool: Structured Graph Pooling via Conditional Random Fields,Hao Yuan;Shuiwang Ji,hao.yuan@tamu.edu;sji@tamu.edu,6;6;6,,Accept (Poster),0,5,1,yes,9/25/19,Texas A&M;Texas A&M,Graph Pooling;Representation Learning;Graph Analysis,46;46,177;177,u;m,NAN,NAN,n
ICLR,2020,Weakly Supervised Clustering by Exploiting Unique Class Count,Mustafa Umit Oner;Hwee Kuan Lee;Wing-Kin Sung,umitoner@comp.nus.edu.sg;leehk@bii.a-star.edu.sg;ksung@comp.nus.edu.sg,6;1;8,,Accept (Poster),0,8,0,yes,9/25/19,National University of Singapore;A*STAR;National University of Singapore,weakly supervised clustering;weakly supervised learning;multiple instance learning,17;-1;17,25;-1;25,m;m,asia,sg,y
ICLR,2020,Gradients as Features for Deep Representation Learning,Fangzhou Mu;Yingyu Liang;Yin Li,fmu@cs.wisc.edu;yliang@cs.wisc.edu;yin.li@wisc.edu,6;3;8,,Accept (Poster),0,4,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California,representation learning;gradient features;deep learning,36;36;36,62;62;62,u;u,usa,usa,n
ICLR,2020,Composition-based Multi-Relational Graph Convolutional Networks,Shikhar Vashishth;Soumya Sanyal;Vikram Nitin;Partha Talukdar,shikhar@iisc.ac.in;sanyal.soumya8@gmail.com;vikram.nitin@columbia.edu;ppt@iisc.ac.in,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Indian Institute of Science;;Columbia University;Indian Institute of Science,Graph Convolutional Networks;Multi-relational Graphs;Knowledge Graph Embeddings;Link Prediction,-1;-1;24;-1,301;-1;16;301,m;m,NAN,NAN,y
ICLR,2020,Behaviour Suite for Reinforcement Learning,Ian Osband;Yotam Doron;Matteo Hessel;John Aslanides;Eren Sezener;Andre Saraiva;Katrina McKinney;Tor Lattimore;Csaba Szepesvari;Satinder Singh;Benjamin Van Roy;Richard Sutton;David Silver;Hado Van Hasselt,ian.osband@gmail.com;ydoron@google.com;mtthss@google.com;jaslanides@google.com;esezener@google.com;andresnds@google.com;mckinneyk@google.com;lattimore@google.com;szepi@google.com;baveja@google.com;benvanroy@google.com;suttonr@google.com;davidsilver@google.com;hado@google.com,8;6;3,,Accept (Spotlight),0,11,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;benchmark;core issues;scalability;reproducibility,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;u,NAN,NAN,n
ICLR,2020,Identifying through Flows for Recovering Latent Representations,Shen Li;Bryan Hooi;Gim Hee Lee,maths.shenli@gmail.com;bhooi@comp.nus.edu.sg;dcslgh@nus.edu.sg,6;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Amsterdam;National University of Singapore;National University of Singapore,Representation learning;identifiable generative models;nonlinear-ICA,-1;17;17,-1;25;25,u;m,asia,sg,y
ICLR,2020,Federated Adversarial Domain Adaptation,Xingchao Peng;Zijun Huang;Yizhe Zhu;Kate Saenko,xpeng@bu.edu;zijun.huang@columbia.edu;yizhe.zhu@rutgers.edu;saenko@bu.edu,6;6;3,,Accept (Poster),2,5,0,yes,9/25/19,Boston University;Columbia University;Rutgers University;Boston University,Federated Learning;Domain Adaptation;Transfer Learning;Feature Disentanglement,79;24;30;79,61;16;-1;61,m;f,europe,it,y
ICLR,2020,High Fidelity Speech Synthesis with Adversarial Networks,Miko≈Çaj Bi≈Ñkowski;Jeff Donahue;Sander Dieleman;Aidan Clark;Erich Elsen;Norman Casagrande;Luis C. Cobo;Karen Simonyan,mikbinkowski@gmail.com;jeffdonahue@google.com;sedielem@google.com;aidanclark@google.com;eriche@google.com;ncasagrande@google.com;luisca@google.com;simonyan@google.com,8;6;8,,Accept (Talk),1,5,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,texttospeech;speechsynthesis;audiosynthesis;gans;generativeadversarialnetworks;implicitgenerativemodels,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;u,NAN,NAN,n
ICLR,2020,Why Not to Use Zero Imputation? Correcting Sparsity Bias in Training Neural Networks,Joonyoung Yi;Juhyuk Lee;Kwang Joon Kim;Sung Ju Hwang;Eunho Yang,joonyoung.yi@kaist.ac.kr;sehkmg@kaist.ac.kr;preppie@yuhs.ac;sjhwang82@kaist.ac.kr;eunhoy@kaist.ac.kr,6;6;6,,Accept (Poster),0,12,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Missing Data;Collaborative Filtering;Health Care;Tabular Data;High Dimensional Data;Deep Learning;Neural Networks,-1;-1;-1;-1;-1,110;110;-1;110;110,m;m,NAN,NAN,y
ICLR,2020,Adversarial Training and Provable Defenses: Bridging the Gap,Mislav Balunovic;Martin Vechev,bmislav@student.ethz.ch;martin.vechev@inf.ethz.ch,8;6;8,,Accept (Talk),2,8,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,adversarial examples;adversarial training;provable defense;convex relaxations;deep learning,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Can gradient clipping mitigate label noise?,Aditya Krishna Menon;Ankit Singh Rawat;Sashank J. Reddi;Sanjiv Kumar,adityakmenon@google.com;ankitsrawat@google.com;sashank@google.com;sanjivk@google.com,6;8;6,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Comparing Rewinding and Fine-tuning in Neural Network Pruning,Alex Renda;Jonathan Frankle;Michael Carbin,renda@csail.mit.edu;jfrankle@csail.mit.edu;mcarbin@csail.mit.edu,8;8;6,,Accept (Talk),0,4,1,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,pruning;sparsity;fine-tuning;lottery ticket,5;5;5,5;5;5,m;m,usa,usa,n
ICLR,2020,Meta-learning curiosity algorithms,Ferran Alet*;Martin F. Schneider*;Tomas Lozano-Perez;Leslie Pack Kaelbling,ferranalet@gmail.com;martinfs@mit.edu;tlp@csail.mit.edu;lpk@csail.mit.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,meta-learning;exploration;curiosity,5;5;5;5,5;5;5;5,m;m,usa,usa,n
ICLR,2020,Lookahead: A Far-sighted Alternative of Magnitude-based Pruning,Sejun Park*;Jaeho Lee*;Sangwoo Mo;Jinwoo Shin,sejun.park@kaist.ac.kr;jaeho-lee@kaist.ac.kr;swmo@kaist.ac.kr;jinwoos@kaist.ac.kr,6;6;6;6,,Accept (Poster),0,13,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,network magnitude-based pruning,-1;-1;-1;-1,110;110;110;110,u;m,NAN,NAN,n
ICLR,2020,Fantastic Generalization Measures and Where to Find Them,Yiding Jiang*;Behnam Neyshabur*;Hossein Mobahi;Dilip Krishnan;Samy Bengio,ydjiang@google.com;neyshabur@google.com;dilipkay@google.com;hmobahi@google.com;bengio@google.com,8;3;8,,Accept (Poster),1,4,0,yes,9/25/19,Google;Google;Google;Google;Google,Generalization;correlation;experiments,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Convergence of Gradient Methods on Bilinear Zero-Sum Games,Guojun Zhang;Yaoliang Yu,guojun.zhang@uwaterloo.ca;yaoliang.yu@uwaterloo.ca,8;6;3,,Accept (Poster),0,4,0,yes,9/25/19,University of Waterloo;University of Waterloo,GAN;gradient algorithm;convergence;min-max optimization;bilinear game,30;30,235;235,m;m,canada,ca,y
ICLR,2020,Multi-Agent Interactions Modeling with Correlated Policies,Minghuan Liu;Ming Zhou;Weinan Zhang;Yuzheng Zhuang;Jun Wang;Wulong Liu;Yong Yu,minghuanliu@sjtu.edu.cn;mingak@sjtu.edu.cn;wnzhang@sjtu.edu.cn;zhuangyuzheng@huawei.com;w.j@huawei.com;liuwulong@huawei.com;yyu@apex.sjtu.edu.cn,8;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Shanghai Jiao Tong University,Multi-agent reinforcement learning;Imitation learning,30;30;30;-1;-1;-1;30,157;157;157;-1;-1;-1;157,m;m,asia,cn,n
ICLR,2020,"Real or Not Real, that is the Question",Yuanbo Xiangli*;Yubin Deng*;Bo Dai*;Chen Change Loy;Dahua Lin,xy019@ie.cuhk.edu.hk;danny.s.deng.ds@gmail.com;doubledaibo@gmail.com;ccloy@ntu.edu.sg;dhlin@ie.cuhk.edu.hk,6;6;8,,Accept (Spotlight),0,9,0,yes,9/25/19,The Chinese University of Hong Kong;;Nanyang Technological University;Nanyang Technological University;The Chinese University of Hong Kong,GAN;generalization;realness;loss function,316;-1;43;43;316,35;-1;49;49;35,m;m,NAN,NAN,n
ICLR,2020,Structured Object-Aware Physics Prediction for Video Modeling and Planning,Jannik Kossen;Karl Stelzner;Marcel Hussing;Claas Voelcker;Kristian Kersting,kossen@stud.uni-heidelberg.de;stelzner@cs.tu-darmstadt.de;marcel.hussing@stud.tu-darmstadt.de;c.voelcker@stud.tu-darmstadt.de;kersting@cs.tu-darmstadt.de,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,Heidelberg University;TU Darmstadt;TU Darmstadt;TU Darmstadt;TU Darmstadt,self-supervised learning;probabilistic deep learning;structured models;video prediction;physics prediction;planning;variational auteoncoders;model-based reinforcement learning;VAEs;unsupervised;variational;graph neural networks;tractable probabilistic models;attend-infer-repeat;relational learning;AIR;sum-product networks;object-oriented;object-centric;object-aware;MCTS,194;59;59;59;59,44;-1;-1;-1;-1,m;m,europe,de,n
ICLR,2020,Gradient Descent Maximizes the Margin of Homogeneous Neural Networks,Kaifeng Lyu;Jian Li,vfleaking@gmail.com;lijian83@mail.tsinghua.edu.cn,6;8;8,,Accept (Talk),0,3,0,yes,9/25/19,"Princeton University;Tsinghua University, Tsinghua University",margin;homogeneous;gradient descent,30;4,6;23,u;u,NAN,NAN,y
ICLR,2020,Implementing Inductive bias for different navigation tasks through diverse RNN attrractors,Tie XU;Omri Barak,fexutie@gmail.com;omri.barak@gmail.com,6;6;3,,Accept (Poster),0,6,0,yes,9/25/19,Technion;Technion,navigation;Recurrent Neural Networks;dynamics;inductive bias;pre-training;reinforcement learning,-1;27,-1;-1,m;m,NAN,NAN,n
ICLR,2020,End to End Trainable Active Contours via Differentiable Rendering,Shir Gur;Tal Shaharabany;Lior Wolf,shiretzet@gmail.com;shaharabany@mail.tau.ac.il;wolf@fb.com,8;8;6,,Accept (Poster),0,6,2,yes,9/25/19,Tel Aviv University;Tel Aviv University;Facebook,,30;30;-1,188;188;-1,m;m,NAN,NAN,n
ICLR,2020,ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring,David Berthelot;Nicholas Carlini;Ekin D. Cubuk;Alex Kurakin;Kihyuk Sohn;Han Zhang;Colin Raffel,dberth@google.com;ncarlini@google.com;cubuk@google.com;kurakin@google.com;kihyuks@google.com;zhanghan@google.com;craffel@google.com,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,semi-supervised learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,DropEdge: Towards Deep Graph Convolutional Networks on Node Classification,Yu Rong;Wenbing Huang;Tingyang Xu;Junzhou Huang,yu.rong@hotmail.com;hwenbing@126.com;tingyangxu@tencent.com;jzhuang@uta.edu,3;3;6,,Accept (Poster),7,3,2,yes,9/25/19,"Tencent AI Lab;126;Tencent AI Lab;University of Texas, Arlington",graph neural network;over-smoothing;over-fitting;dropedge;graph convolutional networks,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Neural Tangents: Fast and Easy Infinite Neural Networks in Python,Roman Novak;Lechao Xiao;Jiri Hron;Jaehoon Lee;Alexander A. Alemi;Jascha Sohl-Dickstein;Samuel S. Schoenholz,romann@google.com;xlc@google.com;jh2084@cam.ac.uk;jaehlee@google.com;alemi@google.com;jaschasd@google.com;schsam@google.com,8;3;6,,Accept (Spotlight),0,12,0,yes,9/25/19,Google;Google;University of Cambridge;Google;Google;Google;Google,Infinite Neural Networks;Gaussian Processes;Neural Tangent Kernel;NNGP;NTK;Software Library;Python;JAX,-1;-1;79;-1;-1;-1;-1,-1;-1;3;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,FasterSeg: Searching for Faster Real-time Semantic Segmentation,Wuyang Chen;Xinyu Gong;Xianming Liu;Qian Zhang;Yuan Li;Zhangyang Wang,wuyang.chen@tamu.edu;xy_gong@tamu.edu;xianming.liu@horizon.ai;qian01.zhang@horizon.ai;yuan.li@horizon.ai;atlaswang@tamu.edu,8;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Texas A&M;Texas A&M;Horizon Robotics;Horizon Robotics;Horizon Robotics;Texas A&M,neural architecture search;real-time;segmentation,46;46;-1;-1;-1;46,177;177;-1;-1;-1;177,m;m,NAN,NAN,n
ICLR,2020,Understanding Knowledge Distillation in Non-autoregressive Machine Translation,Chunting Zhou;Jiatao Gu;Graham Neubig,chuntinz@andrew.cmu.edu;jgu@fb.com;gneubig@cs.cmu.edu,8;8;3,,Accept (Poster),0,5,2,yes,9/25/19,Carnegie Mellon University;Facebook;Carnegie Mellon University,knowledge distillation;non-autoregressive neural machine translation,1;-1;1,27;-1;27,f;m,usa,usa,n
ICLR,2020,Building Deep Equivariant Capsule Networks,Sai Raam Venkataraman;S. Balasubramanian;R. Raghunatha Sarma,vsairaam@sssihl.edu.in;sbalasubramanian@sssihl.edu.in;rraghunathasarma@sssihl.edu.in,8;6,,Accept (Talk),0,10,0,yes,9/25/19,Sri Sathya Sai Institute of Higher Learning;Sri Sathya Sai Institute of Higher Learning;Sri Sathya Sai Institute of Higher Learning,Capsule networks;equivariance,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Understanding Architectures Learnt by Cell-based Neural Architecture Search,Yao Shu;Wei Wang;Shaofeng Cai,shuyao@comp.nus.edu.sg;wangwei@comp.nus.edu.sg;shaofeng@comp.nus.edu.sg,8;6;3,,Accept (Poster),0,6,0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore,Neural Architecture Search;connection pattern;optimization;convergence;Lipschitz smoothness;gradient variance;generalization,17;17;17,25;25;25,f;m,asia,sg,y
ICLR,2020,Dynamically Pruned Message Passing Networks for Large-scale Knowledge Graph Reasoning,Xiaoran Xu;Wei Feng;Yunsheng Jiang;Xiaohui Xie;Zhiqing Sun;Zhi-Hong Deng,xiaoran.xu@hulu.com;wei.feng@hulu.com;yunsheng.jiang@hulu.com;xiaohui.xie@hulu.com;zhiqings@andrew.cmu.edu;zhdeng@pku.edu.cn,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Hulu LLC.;Hulu LLC.;Hulu LLC.;Hulu LLC.;Carnegie Mellon University;Peking University,knowledge graph reasoning;graph neural networks;attention mechanism,-1;-1;-1;-1;1;14,-1;-1;-1;-1;27;24,m;m,asia,cn,n
ICLR,2020,Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model,Wenhan Xiong;Jingfei Du;William Yang Wang;Veselin Stoyanov,xwhan@cs.ucsb.edu;jingfeidu@fb.com;william@cs.ucsb.edu;ves@fb.com,8;6;6,,Accept (Poster),0,5,0,yes,9/25/19,UC Santa Barbara;Facebook;UC Santa Barbara;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware,Xiandong Zhao;Ying Wang;Xuyi Cai;Cheng Liu;Lei Zhang,zhaoxiandong@ict.ac.cn;wangying2009@ict.ac.cn;caixuyi18s@ict.ac.cn;liucheng@ict.ac.cn;zlei@ict.ac.cn,6;6;3,,Accept (Poster),0,5,0,yes,9/25/19,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",quantization;integer-arithmetic-only DNN accelerator;acceleration,30;30;30;30;30,-1;-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Consistency Regularization for Generative Adversarial Networks,Han Zhang;Zizhao Zhang;Augustus Odena;Honglak Lee,zhanghan@google.com;zizhaoz@google.com;augustusodena@google.com;honglak@google.com,6;6;8,,Accept (Poster),0,5,1,yes,9/25/19,Google;Google;Google;Google,Generative Adversarial Networks;Consistency Regularization;GAN,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Short and Sparse Deconvolution --- A Geometric Approach,Yenson Lau;Qing Qu;Han-Wen Kuo;Pengcheng Zhou;Yuqian Zhang;John Wright,y.lau@columbia.edu;qq213@nyu.edu;hk2673@columbia.edu;pz2230@columbia.edu;yz2557@cornell.edu;jw2966@columbia.edu,6;3,,Accept (Poster),0,3,0,yes,9/25/19,Columbia University;New York University;Columbia University;Columbia University;Cornell University;Columbia University,,24;22;24;24;7;24,16;29;16;16;19;16,u;m,usa,usa,n
ICLR,2020,BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by Coupling Binary Activations,Hyungjun Kim;Kyungsu Kim;Jinseok Kim;Jae-Joon Kim,hyungjun.kim@postech.ac.kr;kyungsu.kim@postech.ac.kr;jinseok.kim@postech.ac.kr;jaejoon@postech.ac.kr,6;6;6,,Accept (Poster),1,7,1,yes,9/25/19,POSTECH;POSTECH;POSTECH;POSTECH,,118;118;118;118,146;146;146;146,m;m,asia,kr,n
ICLR,2020,Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention,Chen Zhao;Chenyan Xiong;Corby Rosset;Xia Song;Paul Bennett;Saurabh Tiwary,chenz@cs.umd.edu;chenyan.xiong@microsoft.com;corbin.rosset@microsoft.com;xiaso@microsoft.com;paul.n.bennett@microsoft.com;satiwary@microsoft.com,8;6;6,,Accept (Poster),0,8,0,yes,9/25/19,"University of Maryland, College Park;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft",Transformer-XH;multi-hop QA;fact verification;extra hop attention;structured modeling,12;-1;-1;-1;-1;-1,91;-1;-1;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,Sub-policy Adaptation for Hierarchical Reinforcement Learning,Alexander Li;Carlos Florensa;Ignasi Clavera;Pieter Abbeel,alexli1@berkeley.edu;florensa@berkeley.edu;iclavera@berkeley.edu;pabbeel@berkeley.edu,8;3,,Accept (Poster),0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,Hierarchical Reinforcement Learning;Transfer;Skill Discovery,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,y
ICLR,2020,"Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards",Allan Zhou;Eric Jang;Daniel Kappler;Alex Herzog;Mohi Khansari;Paul Wohlhart;Yunfei Bai;Mrinal Kalakrishnan;Sergey Levine;Chelsea Finn,ayz@stanford.edu;ejang@google.com;kappler@google.com;alexherzog@google.com;khansari@google.com;wohlhart@google.com;yunfeibai@google.com;kalakris@google.com;slevine@google.com;cbfinn@cs.stanford.edu,6;3;8,,Accept (Poster),0,4,0,yes,9/25/19,Stanford University;Google;Google;Google;Google;Google;Google;Google;Google;Stanford University,meta-learning;reinforcement learning;imitation learning,5;-1;-1;-1;-1;-1;-1;-1;-1;5,4;-1;-1;-1;-1;-1;-1;-1;-1;4,m;f,usa,usa,n
ICLR,2020,Deep Orientation Uncertainty Learning based on a Bingham Loss,Igor Gilitschenski;Roshni Sahoo;Wilko Schwarting;Alexander Amini;Sertac Karaman;Daniela Rus,igilitschenski@mit.edu;rsahoo@mit.edu;wilkos@mit.edu;amini@mit.edu;sertac@mit.edu;rus@csail.mit.edu,6;6,,Accept (Poster),0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Orientation Estimation;Directional Statistics;Bingham Distribution,5;5;5;5;5;5,5;5;5;5;5;5,m;f,usa,usa,n
ICLR,2020,Overlearning Reveals Sensitive Attributes,Congzheng Song;Vitaly Shmatikov,cs2296@cornell.edu;shmat@cs.cornell.edu,6;1;6,,Accept (Poster),0,3,0,yes,9/25/19,Cornell University;Cornell University,privacy;censoring representation;transfer learning,7;7,19;19,m;m,usa,usa,n
ICLR,2020,Understanding the Limitations of Conditional Generative Models,Ethan Fetaya;Joern-Henrik Jacobsen;Will Grathwohl;Richard Zemel,ethanf@cs.toronto.edu;j.jacobsen@vectorinstitute.ai;wgrathwohl@cs.toronto.edu;zemel@cs.toronto.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University of Toronto;Vector Institute;University of Toronto;University of Toronto,Conditional Generative Models;Generative Classifiers;Robustness;Adversarial Examples,18;-1;18;18,18;-1;18;18,m;m,canada,ca,n
ICLR,2020,Learning Disentangled Representations for CounterFactual Regression,Negar Hassanpour;Russell Greiner,hassanpo@ualberta.ca;rgreiner@ualberta.ca,8;8;3,,Accept (Poster),0,5,1,yes,9/25/19,University of Alberta;University of Alberta,Counterfactual Regression;Causal Effect Estimation;Selection Bias;Off-policy Learning,102;102,136;136,f;m,canada,ca,n
ICLR,2020,Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery,Kristian Hartikainen;Xinyang Geng;Tuomas Haarnoja;Sergey Levine,kristian.hartikainen@gmail.com;young.geng@berkeley.edu;tuomash@google.com;svlevine@eecs.berkeley.edu,6;6;6,,Accept (Poster),0,9,3,yes,9/25/19,University of Oxford;University of California Berkeley;Google;University of California Berkeley,reinforcement learning;semi-supervised learning;unsupervised learning;robotics;deep learning,46;-1;-1;-1,1;13;-1;13,m;m,usa,usa,n
ICLR,2020,Learning-Augmented Data Stream Algorithms,Tanqiu Jiang;Yi Li;Honghao Lin;Yisong Ruan;David P. Woodruff,taj320@lehigh.edu;yili@ntu.edu.sg;honghao_lin@sjtu.edu.cn;24320152202802@stu.xmu.edu.cn;dwoodruf@andrew.cmu.edu,8;8;3,,Accept (Poster),0,3,0,yes,9/25/19,Lehigh University;Nanyang Technological University;Shanghai Jiao Tong University;Xiamen University;Carnegie Mellon University,streaming algorithms;heavy hitters;F_p moment;distinct elements;cascaded norms,248;43;30;-1;1,633;49;157;579;27,u;m,usa,usa,y
ICLR,2020,"Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps",Tri Dao;Nimit Sohoni;Albert Gu;Matthew Eichhorn;Amit Blonder;Megan Leszczynski;Atri Rudra;Christopher R√©,trid@stanford.edu;nims@stanford.edu;albertgu@stanford.edu;mae226@cornell.edu;amitblon@buffalo.edu;mleszczy@stanford.edu;atri@buffalo.edu;chrismre@cs.stanford.edu,6;8;8,,Accept (Spotlight),0,5,1,yes,9/25/19,"Stanford University;Stanford University;Stanford University;Cornell University;State University of New York, Buffalo;Stanford University;State University of New York, Buffalo;Stanford University",structured matrices;efficient ML;algorithms;butterfly matrices;arithmetic circuits,5;5;5;7;-1;5;-1;5,4;4;4;19;-1;4;-1;4,m;m,usa,usa,y
ICLR,2020,Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP,Haonan Yu;Sergey Edunov;Yuandong Tian;Ari S. Morcos,haonanu@gmail.com;edunov@fb.com;yuandong@fb.com;arimorcos@gmail.com,6;3;3,,Accept (Poster),0,2,0,yes,9/25/19,Purdue University;Facebook;Facebook;Facebook,lottery tickets;nlp;transformer;rl;reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning the Arrow of Time for Problems in Reinforcement Learning,Nasim Rahaman;Steffen Wolf;Anirudh Goyal;Roman Remme;Yoshua Bengio,nasim.rahaman@tuebingen.mpg.de;steffen.wolf@iwr.uni-heidelberg.de;anirudhgoyal9119@gmail.com;roman.remme@iwr.uni-heidelberg.de;yoshua.bengio@mila.quebec,6;8;6,,Accept (Poster),0,16,0,yes,9/25/19,Max-Planck Institute;Heidelberg University;;Heidelberg University;Mila,Arrow of Time;Reinforcement Learning;AI-Safety,-1;194;-1;194;143,-1;44;-1;44;336,m;m,NAN,NAN,y
ICLR,2020,DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames,Erik Wijmans;Abhishek Kadian;Ari Morcos;Stefan Lee;Irfan Essa;Devi Parikh;Manolis Savva;Dhruv Batra,etw@gatech.edu;akadian@fb.com;arimorcos@gmail.com;leestef@oregonstate.edu;irfan@gatech.edu;parikh@gatech.edu;msavva@sfu.ca;dbatra@gatech.edu,8;8;3,,Accept (Poster),0,4,0,yes,9/25/19,Georgia Institute of Technology;Facebook;Facebook;Oregon State University;Georgia Institute of Technology;Georgia Institute of Technology;Simon Fraser University;Georgia Institute of Technology,autonomous navigation;habitat;embodied AI;pointgoal navigation;reinforcement learning,13;-1;-1;79;13;13;52;13,38;-1;-1;373;38;38;272;38,m;m,usa,usa,n
ICLR,2020,Information Geometry of Orthogonal Initializations and Training,Piotr Aleksander Sok√≥≈Ç;Il Memming Park,piotr.sokol@stonybrook.edu;memming.park@stonybrook.edu,6;8;6,,Accept (Poster),0,8,0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook",Fisher;mean-field;deep learning,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Strategies for Pre-training Graph Neural Networks,Weihua Hu*;Bowen Liu*;Joseph Gomes;Marinka Zitnik;Percy Liang;Vijay Pande;Jure Leskovec,weihuahu@stanford.edu;liubowen@stanford.edu;joegomes@stanford.edu;marinka@cs.stanford.edu;pliang@cs.stanford.edu;pande@stanford.edu;jure@cs.stanford.edu,6;6;6,,Accept (Spotlight),1,3,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Pre-training;Transfer learning;Graph Neural Networks,5;5;5;5;5;5;5,4;4;4;4;4;4;4,m;m,usa,usa,n
ICLR,2020,Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation,Hung-Yu Tseng;Hsin-Ying Lee;Jia-Bin Huang;Ming-Hsuan Yang,htseng6@ucmerced.edu;hlee246@ucmerced.edu;jbhuang@vt.edu;mhyang@ucmerced.edu,6;6;6,,Accept (Spotlight),0,5,0,yes,9/25/19,University of California at Merced;University of California at Merced;Virginia Tech;University of California at Merced,,-1;-1;64;-1,-1;-1;-1;-1,u;m,usa,usa,n
ICLR,2020,How much Position Information Do Convolutional Neural Networks Encode?,Md Amirul Islam*;Sen Jia*;Neil D. B. Bruce,amirul@scs.ryerson.ca;sen.jia@ryerson.ca;bruce@ryerson.ca,8;8;8,,Accept (Spotlight),0,3,6,yes,9/25/19,Ryerson University;Ryerson University;Ryerson University,network understanding;absolute position information,316;316;316,739;739;739,m;m,canada,ca,n
ICLR,2020,Generalization through Memorization: Nearest Neighbor Language Models,Urvashi Khandelwal;Omer Levy;Dan Jurafsky;Luke Zettlemoyer;Mike Lewis,urvashik@stanford.edu;omerlevy@gmail.com;jurafsky@stanford.edu;lsz@fb.com;mikelewis@fb.com,3;6;6,,Accept (Poster),1,8,0,yes,9/25/19,Stanford University;Tel Aviv University;Stanford University;Facebook;Facebook,language models;k-nearest neighbors,5;30;5;-1;-1,4;188;4;-1;-1,f;m,NAN,NAN,n
ICLR,2020,On the Relationship between Self-Attention and Convolutional Layers,Jean-Baptiste Cordonnier;Andreas Loukas;Martin Jaggi,jean-baptiste.cordonnier@epfl.ch;andreas.loukas@epfl.ch;martin.jaggi@epfl.ch,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,self-attention;attention;transformers;convolution;CNN;image;expressivity;capacity,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,On Bonus Based Exploration Methods In The Arcade Learning Environment,Adrien Ali Taiga;William Fedus;Marlos C. Machado;Aaron Courville;Marc G. Bellemare,adrien.alitaiga@gmail.com;liamfedus@google.com;marlosm@google.com;aaron.courville@gmail.com;bellemare@google.com,6;6,,Accept (Poster),0,2,0,yes,9/25/19,Google;Google;Google;University of Montreal;Google,exploration;arcade learning environment;bonus-based methods,-1;-1;-1;118;-1,-1;-1;-1;85;-1,u;m,NAN,NAN,n
ICLR,2020,The Curious Case of Neural Text Degeneration,Ari Holtzman;Jan Buys;Li Du;Maxwell Forbes;Yejin Choi,ahai@cs.washington.edu;jbuys@cs.uct.ac.za;dul2@cs.washington.edu;mbforbes@cs.washington.edu;yejin@cs.washington.edu,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Washington;University of Cape Town;University of Washington;University of Washington;University of Washington,generation;text;NLG;NLP;natural language;natural language generation;language model;neural;neural language model,11;445;11;11;11,26;136;26;26;26,m;f,usa,usa,n
ICLR,2020,A Mutual Information Maximization Perspective of Language Representation Learning,Lingpeng Kong;Cyprien de Masson d'Autume;Lei Yu;Wang Ling;Zihang Dai;Dani Yogatama,lingpenk@google.com;cyprien@google.com;leiyu@google.com;lingwang@google.com;zihangd@google.com;dyogatama@google.com,8;8;6,,Accept (Spotlight),0,5,1,yes,9/25/19,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Measuring Compositional Generalization: A Comprehensive Method on Realistic Data,Daniel Keysers;Nathanael Sch√§rli;Nathan Scales;Hylke Buisman;Daniel Furrer;Sergii Kashubin;Nikola Momchev;Danila Sinopalnikov;Lukasz Stafiniak;Tibor Tihon;Dmitry Tsarkov;Xiao Wang;Marc van Zee;Olivier Bousquet,keysers@google.com;schaerli@google.com;nkscales@google.com;hylke@google.com;danielfurrer@google.com;sergik@google.com;nikola@google.com;sinopalnikov@google.com;lukstafi@google.com;ttihon@google.com;tsar@google.com;wangxiao@google.com;marcvanzee@google.com;obousquet@google.com,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,compositionality;generalization;natural language understanding;benchmark;compositional generalization;compositional modeling;semantic parsing;generalization measurement,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,GLAD: Learning Sparse Graph Recovery,Harsh Shrivastava;Xinshi Chen;Binghong Chen;Guanghui Lan;Srinivas Aluru;Han Liu;Le Song,hshrivastava3@gatech.edu;xinshi.chen@gatech.edu;binghong@gatech.edu;george.lan@isye.gatech.edu;aluru@cc.gatech.edu;hanliu@northwestern.edu;lsong@cc.gatech.edu,8;8;6,,Accept (Poster),0,9,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Northwestern University;Georgia Institute of Technology,Meta learning;automated algorithm design;learning structure recovery;Gaussian graphical models,13;13;13;13;13;46;13,38;38;38;38;38;22;38,m;m,usa,usa,y
ICLR,2020,Query-efficient Meta Attack to Deep Neural Networks,Jiawei Du;Hu Zhang;Joey Tianyi Zhou;Yi Yang;Jiashi Feng,dujiawei@u.nus.edu;hu.zhang-1@student.uts.edu.au;joey.tianyi.zhou@gmail.com;yi.yang@uts.edu.au;elefjia@nus.edu.sg,8;6;6,,Accept (Poster),1,7,0,yes,9/25/19,National University of Singapore;University of Technology Sydney;;University of Technology Sydney;National University of Singapore,Adversarial attack;Meta learning,17;73;-1;73;17,25;193;-1;193;25,m;m,asia,sg,n
ICLR,2020,Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks,Arsalan Sharifnassab;Saber Salehkaleybar;S. Jamaloddin Golestani,a.sharifnassab@gmail.com;saber.salehk@gmail.com;golestani@sharif.edu,6;6,,Accept (Poster),0,2,0,yes,9/25/19,Sharif University of Technology;Sharif University of Technology;Sharif University of Technology,Spurious local minima;Loss landscape;Over-parameterization;Theory of deep learning;Optimization;Descent path,-1;316;316,-1;564;564,m;u,asia,ir,y
ICLR,2020,"A critical analysis of self-supervision, or what we can learn from a single image",Asano YM.;Rupprecht C.;Vedaldi A.,yuki@robots.ox.ac.uk;chrisr@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk,6;6;1,,Accept (Poster),0,4,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,self-supervision;feature representation learning;CNN,46;46;46,1;1;1,m;m,europe,uk,n
ICLR,2020,Geometric Insights into the Convergence of Nonlinear TD Learning,David Brandfonbrener;Joan Bruna,david.brandfonbrener@nyu.edu;bruna@cims.nyu.edu,8;6;3;8,,Accept (Poster),0,4,0,yes,9/25/19,New York University;New York University,TD;nonlinear;convergence;value estimation;reinforcement learning,22;22,29;29,m;m,usa,usa,y
ICLR,2020,Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning,Qing Qu;Yuexiang Zhai;Xiao Li;Yuqian Zhang;Zhihui Zhu,qingqu1006@gmail.com;ysz@berkeley.edu;xli@ee.cuhk.edu.hk;yqz.zhang@gmail.com;zzhu29@jhu.edu,8;8;8,,Accept (Talk),0,5,0,yes,9/25/19,University of Michigan;University of California Berkeley;The Chinese University of Hong Kong;Rutgers University;Johns Hopkins University,dictionary learning;sparse representations;nonconvex optimization,7;-1;316;30;73,21;13;35;-1;12,m;m,usa,usa,y
ICLR,2020,Network Deconvolution,Chengxi Ye;Matthew Evanusa;Hua He;Anton Mitrokhin;Tom Goldstein;James A. Yorke;Cornelia Fermuller;Yiannis Aloimonos,yechengxi@gmail.com;mevanusa@umd.edu;huah@umd.edu;amitrokh@umd.edu;tomg@cs.umd.edu;yorke@umd.edu;fer@umiacs.umd.edu;yiannis@cs.umd.edu,8;8;6,,Accept (Spotlight),0,3,0,yes,9/25/19,"Amazon;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",convolutional networks;network deconvolution;whitening,-1;12;12;12;12;12;12;12,-1;91;91;91;91;91;91;91,m;m,usa,usa,n
ICLR,2020,Pure and Spurious Critical Points: a Geometric Study of Linear Networks,Matthew Trager;Kathl√©n Kohn;Joan Bruna,matthew.trager@cims.nyu.edu;kathlen.korn@gmail.com;bruna@cims.nyu.edu,8;3;3,,Accept (Poster),0,5,0,yes,9/25/19,New York University;;New York University,Loss landscape;linear networks;algebraic geometry,22;-1;22,29;-1;29,u;m,usa,usa,y
ICLR,2020,PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search,Yuhui Xu;Lingxi Xie;Xiaopeng Zhang;Xin Chen;Guo-Jun Qi;Qi Tian;Hongkai Xiong,yuhuixu@sjtu.edu.cn;198808xc@gmail.com;zxphistory@gmail.com;1410452@tongji.edu.cn;guojunq@gmail.com;tian.qi1@huawei.com;xionghongkai@sjtu.edu.cn,6;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Shanghai Jiao Tong University;;;Tongji University;University of Central Florida;Huawei Technologies Ltd.;Shanghai Jiao Tong University,Neural Architecture Search;DARTS;Regularization;Normalization,30;-1;-1;316;73;-1;30,157;-1;-1;441;609;-1;157,m;m,asia,cn,n
ICLR,2020,Towards a Deep Network Architecture for Structured Smoothness,Haroun Habeeb;Oluwasanmi Koyejo,haroun7@gmail.com;sanmi@illinois.edu,6;6,,Accept (Poster),0,2,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",,-1;-1,-1;-1,m;m,usa,usa,n
ICLR,2020,RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?,Anil Kag;Ziming Zhang;Venkatesh Saligrama,anilkag@bu.edu;zzhang@merl.com;srv@bu.edu,8;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Boston University;Mitsubishi Electric Research Labs;Boston University,novel recurrent neural architectures;learning representations of outputs or states,79;-1;79,61;-1;61,m;m,europe,it,y
ICLR,2020,"Deep Imitative Models for Flexible Inference, Planning, and Control",Nicholas Rhinehart;Rowan McAllister;Sergey Levine,nrhineha@cs.cmu.edu;rmcallister@berkeley.edu;svlevine@eecs.berkeley.edu,8;8;6,,Accept (Poster),0,7,0,yes,9/25/19,Carnegie Mellon University;University of California Berkeley;University of California Berkeley,imitation learning;planning;autonomous driving,1;-1;-1,27;13;13,m;m,usa,usa,n
ICLR,2020,The Implicit Bias of Depth: How Incremental Learning Drives Generalization,Daniel Gissin;Shai Shalev-Shwartz;Amit Daniely,daniel.gissin@mail.huji.ac.il;shais@cs.huji.ac.il;amit.daniely@mail.huji.ac.il,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,gradient flow;gradient descent;implicit regularization;implicit bias;generalization;optimization;quadratic network;matrix sensing,85;85;85,216;216;216,m;m,europe,il,y
ICLR,2020,BackPACK: Packing more into Backprop,Felix Dangel;Frederik Kunstner;Philipp Hennig,felix.dangel@tuebingen.mpg.de;kunstner@cs.ubc.ca;philipp.hennig@uni-tuebingen.de,8;8;8,,Accept (Talk),0,3,0,yes,9/25/19,Max-Planck Institute;University of British Columbia;University of Tuebingen,,-1;64;143,-1;34;91,m;m,europe,de,n
ICLR,2020,Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality,Saurabh Khanna;Vincent Y. F. Tan,elesaur@nus.edu.sg;vtan@nus.edu.sg,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,National University of Singapore;National University of Singapore,Recurrent neural networks;Granger causality;Causal inference;Statistical Recurrent Unit,17;17,25;25,m;m,asia,sg,n
ICLR,2020,Detecting Extrapolation with Local Ensembles,David Madras;James Atwood;Alexander D'Amour,david.madras@mail.utoronto.ca;atwoodj@google.com;alexdamour@google.com,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Toronto University;Google;Google,extrapolation;reliability;influence functions;laplace approximation;ensembles;Rashomon set,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Few-shot Text Classification with Distributional Signatures,Yujia Bao;Menghua Wu;Shiyu Chang;Regina Barzilay,yujia@csail.mit.edu;rmwu@mit.edu;shiyu.chang@ibm.com;regina@csail.mit.edu,6;1;3,,Accept (Poster),0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology,text classification;meta learning;few shot learning,5;5;-1;5,5;5;-1;5,m;f,usa,usa,y
ICLR,2020,Scaling Autoregressive Video Models,Dirk Weissenborn;Oscar T√§ckstr√∂m;Jakob Uszkoreit,diwe@google.com;oscar.tackstrom@gmail.com;usz@google.com,8;6;8,,Accept (Spotlight),0,6,0,yes,9/25/19,Google;Sana Labs;Google,autoregressive models;video prediction;generative models;video generation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Reformer: The Efficient Transformer,Nikita Kitaev;Lukasz Kaiser;Anselm Levskaya,kitaev@cs.berkeley.edu;lukaszkaiser@google.com;levskaya@google.com,8;6;8,,Accept (Talk),4,3,0,yes,9/25/19,University of California Berkeley;Google;Google,attention;locality sensitive hashing;reversible layers,-1;-1;-1,13;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Robust Subspace Recovery Layer for Unsupervised Anomaly Detection,Chieh-Hsin Lai;Dongmian Zou;Gilad Lerman,laixx313@umn.edu;dzou@umn.edu;lerman@umn.edu,8;6;8,,Accept (Poster),0,6,0,yes,9/25/19,"University of Minnesota, Minneapolis;University of Minnesota, Minneapolis;University of Minnesota, Minneapolis",robust subspace recovery;unsupervised anomaly detection;outliers;latent space;autoencoder,73;73;73,79;79;79,m;m,NAN,NAN,y
ICLR,2020,SCALOR: Generative World Models with Scalable Object Representations,Jindong Jiang*;Sepehr Janghorbani*;Gerard De Melo;Sungjin Ahn,jindong.jiang@rutgers.edu;sj620@scarletmail.rutgers.edu;gdm@demelo.org;sjn.ahn@gmail.com,6;6;6,,Accept (Poster),0,7,0,yes,9/25/19,Rutgers University;Rutgers University;Rutgers University;Rutgers University,,30;30;30;30,-1;-1;-1;-1,m;f,usa,usa,n
ICLR,2020,Learning Robust Representations via Multi-View Information Bottleneck,Marco Federici;Anjan Dutta;Patrick Forr√©;Nate Kushman;Zeynep Akata,m.federici@uva.nl;duttanjan@gmail.com;patrickforre@gmail.com;nate@kushman.org;zeynepakata@gmail.com,8;6;8,,Accept (Poster),0,5,1,yes,9/25/19,University of Amsterdam;University of Exeter;University of Amsterdam;Google;University of Tuebingen,Information Bottleneck;Multi-View Learning;Representation Learning;Information Theory,143;316;143;-1;143,62;146;62;-1;91,m;f,europe,de,n
ICLR,2020,Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks,Tianyu Pang*;Kun Xu*;Jun Zhu,pty17@mails.tsinghua.edu.cn;kunxu.thu@gmail.com;dcszj@mail.tsinghua.edu.cn,6;6;6,,Accept (Poster),0,9,0,yes,9/25/19,"Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University",Trustworthy Machine Learning;Adversarial Robustness;Inference Principle;Mixup,4;-1;4,23;-1;23,m;m,NAN,NAN,n
ICLR,2020,Adversarial Lipschitz Regularization,D√°vid Terj√©k,david.terjek92@gmail.com,6;6;6,,Accept (Poster),0,9,0,yes,9/25/19,Alfr√©d R√©nyi Institute of Mathematics,generative adversarial networks;wasserstein generative adversarial networks;lipschitz regularization;adversarial training,-1,-1,m;u,NAN,NAN,n
ICLR,2020,Are Transformers universal approximators of sequence-to-sequence functions?,Chulhee Yun;Srinadh Bhojanapalli;Ankit Singh Rawat;Sashank Reddi;Sanjiv Kumar,chulheey@mit.edu;bsrinadh@google.com;ankitsrawat@google.com;sashank@google.com;sanjivk@google.com,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Massachusetts Institute of Technology;Google;Google;Google;Google,Transformer;universal approximation;contextual mapping;expressive power;permutation equivariance,5;-1;-1;-1;-1,5;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Escaping Saddle Points Faster with Stochastic Momentum,Jun-Kun Wang;Chi-Heng Lin;Jacob Abernethy,jimwang@gatech.edu;cl3385@gatech.edu;prof@gatech.edu,3;6;6,,Accept (Poster),0,9,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,SGD;momentum;escaping saddle point,13;13;13,38;38;38,m;m,usa,usa,y
ICLR,2020,SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum,Jianyu Wang;Vinayak Tantia;Nicolas Ballas;Michael Rabbat,jianyuw1@andrew.cmu.edu;tantia@fb.com;ballasn@fb.com;mikerabbat@fb.com,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook,distributed optimization;decentralized training methods;communication-efficient distributed training with momentum;large-scale parallel SGD,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,SUMO: Unbiased Estimation of Log Marginal Probability for Latent Variable Models,Yucen Luo;Alex Beatson;Mohammad Norouzi;Jun Zhu;David Duvenaud;Ryan P. Adams;Ricky T. Q. Chen,luoyc15@mails.tsinghua.edu.cn;abeatson@cs.princeton.edu;mnorouzi@google.com;dcszj@mail.tsinghua.edu.cn;duvenaud@cs.toronto.edu;rpa@princeton.edu;rtqichen@cs.toronto.edu,8;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Princeton University;Google;Tsinghua University, Tsinghua University;University of Toronto;Princeton University;University of Toronto",,4;30;-1;4;18;30;18,23;6;-1;23;18;6;18,f;m,canada,ca,y
ICLR,2020,Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control,Yaofeng Desmond Zhong;Biswadip Dey;Amit Chakraborty,y.zhong@princeton.edu;biswadip.dey@siemens.com;amit.chakraborty@siemens.com,8;6;8,,Accept (Poster),0,6,0,yes,9/25/19,Princeton University;Siemens Corporate Research;Siemens Corporate Research,Deep Model Learning;Physics-based Priors;Control of Mechanical Systems,30;-1;-1,6;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems,Chris Reinke;Mayalen Etcheverry;Pierre-Yves Oudeyer,chris.reinke@inria.fr;mayalen.etcheverry@inria.fr;chris.reinke@inria.fr;pierre-yves.oudeyer@inria.fr,8;6;6,,Accept (Talk),0,5,0,yes,9/25/19,INRIA;INRIA;INRIA;INRIA,deep learning;unsupervised Learning;self-organization;game-of-life,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,gr,n
ICLR,2020,On the Convergence of FedAvg on Non-IID Data,Xiang Li;Kaixuan Huang;Wenhao Yang;Shusen Wang;Zhihua Zhang,smslixiang@pku.edu.cn;hackyhuang@pku.edu.cn;yangwhsms@gmail.com;shusen.wang@stevens.edu;zhzhang@math.pku.edu.cn,8;8;6,,Accept (Talk),0,3,0,yes,9/25/19,Peking University;Peking University;Peking University;Stevens Institute of Technology;Peking University,Federated Learning;stochastic optimization;Federated Averaging,14;14;14;143;14,24;24;24;605;24,m;m,asia,cn,y
ICLR,2020,The asymptotic spectrum of the Hessian of DNN throughout training,Arthur Jacot;Franck Gabriel;Clement Hongler,arthur.jacot@epfl.ch;franck.gabriel@epfl.ch;clement.hongler@epfl.ch,3;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,theory of deep learning;loss surface;training;fisher information matrix,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,AutoQ: Automated Kernel-Wise Neural Network Quantization ,Qian Lou;Feng Guo;Minje Kim;Lantao Liu;Lei Jiang.,louqian@iu.edu;fengguo@iu.edu;minje@indiana.edu;lantao@iu.edu;jiang60@iu.edu,6;3;8;6,,Accept (Poster),0,3,0,yes,9/25/19,"Indiana University, Bloomington;Indiana University, Bloomington;Indiana University;Indiana University, Bloomington;Indiana University, Bloomington",AutoML;Kernel-Wise Neural Networks Quantization;Hierarchical Deep Reinforcement Learning,64;64;64;64;64,134;134;134;134;134,m;m,NAN,NAN,n
ICLR,2020,Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling,Yuping Luo;Huazhe Xu;Tengyu Ma,yupingl@cs.princeton.edu;huazhe_xu@eecs.berkeley.edu;tengyuma@stanford.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Princeton University;University of California Berkeley;Stanford University,imitation learning;model-based imitation learning;model-based RL;behavior cloning;covariate shift,30;-1;5,6;13;4,m;m,usa,usa,y
ICLR,2020,Projection-Based Constrained Policy Optimization,Tsung-Yen Yang;Justinian Rosca;Karthik Narasimhan;Peter J. Ramadge,ty3@princeton.edu;justinian.rosca@siemens.com;karthikn@cs.princeton.edu;ramadge@princeton.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Princeton University;Siemens Corporate Research;Princeton University;Princeton University,Reinforcement learning with constraints;Safe reinforcement learning,30;-1;30;30,6;-1;6;6,f;m,usa,usa,y
ICLR,2020,Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities,Baichuan Yuan;Xiaowei Wang;Jianxin Ma;Chang Zhou;Andrea L. Bertozzi;Hongxia Yang,ybcmath@gmail.com;daemon.wxw@alibaba-inc.com;majx13fromthu@gmail.com;ericzhou.zc@alibaba-inc.com;bertozzi@math.ucla.edu;yang.yhx@alibaba-inc.com,6;8;6,,Accept (Poster),0,3,0,yes,9/25/19,"University of California, Los Angeles;Alibaba Group;Alibaba Group;Alibaba Group;University of California, Los Angeles;Alibaba Group",VAE;collaborative filtering;recommender systems;spatial point process,-1;-1;-1;-1;-1;-1,17;-1;-1;-1;17;-1,m;f,NAN,NAN,y
ICLR,2020,Single Episode Policy Transfer in Reinforcement Learning,Jiachen Yang;Brenden Petersen;Hongyuan Zha;Daniel Faissol,yjiachen@gmail.com;petersen33@llnl.gov;zha@cc.gatech.edu;faissol1@llnl.gov,8;8;3,,Accept (Poster),0,7,0,yes,9/25/19,Georgia Institute of Technology;Lawrence Livermore National Labs;Georgia Institute of Technology;Lawrence Livermore National Labs,transfer learning;reinforcement learning,13;-1;13;-1,38;-1;38;-1,m;m,NAN,NAN,n
ICLR,2020,Transferable Perturbations of Deep Feature Distributions,Nathan Inkawhich;Kevin Liang;Lawrence Carin;Yiran Chen,nathan.inkawhich@duke.edu;kevin.liang@duke.edu;lcarin@duke.edu;yiran.chen@duke.edu,3;8;8,,Accept (Poster),0,6,0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,adversarial attacks;transferability;interpretability,46;46;46;46,20;20;20;20,m;m,europe,se,n
ICLR,2020,Pruned Graph Scattering Transforms,Vassilis N. Ioannidis;Siheng Chen;Georgios B. Giannakis,ioann006@umn.edu;schen@merl.com;georgios@umn.edu,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,"University of Minnesota, Minneapolis;Mitsubishi Electric Research Labs;University of Minnesota, Minneapolis",Graph scattering transforms;pruning;graph convolutional networks;stability;deep learning,73;-1;73,79;-1;79,m;m,NAN,NAN,y
ICLR,2020,Efficient Probabilistic Logic Reasoning with Graph Neural Networks,Yuyu Zhang;Xinshi Chen;Yuan Yang;Arun Ramamurthy;Bo Li;Yuan Qi;Le Song,yuyu@gatech.edu;xinshi.chen@gatech.edu;yuanyang@gatech.edu;arun.ramamurthy@siemens.com;lbo@illinois.edu;yuan.qi@antfin.com;lsong@cc.gatech.edu,3;3;1,,Accept (Poster),0,3,4,yes,9/25/19,"Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Siemens Corporate Research;University of Illinois, Urbana Champaign;Antfin;Georgia Institute of Technology",probabilistic logic reasoning;Markov Logic Networks;graph neural networks,13;13;13;-1;-1;-1;13,38;38;38;-1;-1;-1;38,m;m,usa,usa,n
ICLR,2020,Decoupling Representation and Classifier for Long-Tailed Recognition,Bingyi Kang;Saining Xie;Marcus Rohrbach;Zhicheng Yan;Albert Gordo;Jiashi Feng;Yannis Kalantidis,kang@u.nus.edu;xiesaining@gmail.com;maroffm@gmail.com;zhicheng.yan@live.com;albert.gordo.s@gmail.com;elefjia@nus.edu.sg;ykalant@image.ntua.gr,6;8;6,,Accept (Poster),0,4,1,yes,9/25/19,National University of Singapore;Facebook;Facebook;;Facebook;National University of Singapore;National Technical University of Athens,long-tailed recognition;classification,17;-1;-1;-1;-1;17;316,25;-1;-1;-1;-1;25;776,m;m,NAN,NAN,n
ICLR,2020,Coherent Gradients: An Approach to Understanding Generalization in Gradient Descent-based Optimization,Satrajit Chatterjee,satrajit@gmail.com,8;8;3,,Accept (Poster),0,21,0,yes,9/25/19,Google,generalization;deep learning,-1,-1,m,NAN,NAN,n
ICLR,2020,Environmental drivers of systematicity and generalization in a situated agent,Felix Hill;Andrew Lampinen;Rosalia Schneider;Stephen Clark;Matthew Botvinick;James L. McClelland;Adam Santoro,felixhill@google.com;lampinen@stanford.edo;rgschneider@google.com;clarkstephen@google.com;botvinick@google.com;jlmcc@google.com;adamsantoro@google.com,6;6;6,,Accept (Poster),0,19,0,yes,9/25/19,Google;;Google;Google;Google;Google;Google,systematicitiy;systematic;generalization;combinatorial;agent;policy;language;compositionality,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Compositional Language Continual Learning,Yuanpeng Li;Liang Zhao;Kenneth Church;Mohamed Elhoseiny,yuanpeng16@gmail.com;lzhao4ever@gmail.com;kenneth.ward.church@gmail.com;mohamed.elhoseiny@gmail.com,3;6;8,,Accept (Poster),0,4,0,yes,9/25/19,"Shanghai Jiao Tong University, Tsinghua University;Samsung;Baidu;KAUST",Compositionality;Continual Learning;Lifelong Learning;Sequence to Sequence Modeling,-1;-1;-1;102,-1;-1;-1;-1,m;m,europe,gr,n
ICLR,2020,Vid2Game: Controllable Characters Extracted from Real-World Videos,Oran Gafni;Lior Wolf;Yaniv Taigman,oran.gafni@gmail.com;wolf@fb.com;yaniv@fb.com,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Facebook;Facebook;Facebook,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Infinite-horizon Off-Policy Policy Evaluation with Multiple Behavior Policies,Xinyun Chen;Lu Wang;Yizhe Hang;Heng Ge;Hongyuan Zha,chenxinyun@cuhk.edu.cn;luwang@stu.ecnu.edu.cn;hangyhan@mail.ustc.edu.cn;hengge@mail.sdu.edu.cn;zhahy@cuhk.edu.cn,6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen;East China Normal University;University of Science and Technology of China;Shandong University;The Chinese University of Hong Kong, Shenzhen",off-policy policy evaluation;multiple importance sampling;kernel method;variance reduction,46;-1;-1;143;46,35;544;80;658;35,m;m,NAN,NAN,y
ICLR,2020,Learning Efficient Parameter Server Synchronization Policies for Distributed SGD,Rong Zhu;Sheng Yang;Andreas Pfadler;Zhengping Qian;Jingren Zhou,red.zr@alibaba-inc.com;yangsheng@hit.edu.cn;andreaswernerrober@alibaba-inc.com;zhengping.qzp@alibaba-inc.com;jingren.zhou@alibaba-inc.com,6;3;6,,Accept (Poster),0,9,0,yes,9/25/19,Alibaba Group;Harbin Institute of Technology;Alibaba Group;Alibaba Group;Alibaba Group,Distributed SGD;Paramter-Server;Synchronization Policy;Reinforcement Learning,-1;168;-1;-1;-1,-1;424;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unsupervised Clustering using Pseudo-semi-supervised Learning,Divam Gupta;Ramachandran Ramjee;Nipun Kwatra;Muthian Sivathanu,divam@cmu.edu;ramjee@microsoft.com;nipun.kwatra@microsoft.com;muthian@microsoft.com,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Carnegie Mellon University;Microsoft;Microsoft;Microsoft,Unsupervised Learning;Unsupervised Clustering;Deep Learning,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Tree-Structured Attention with Hierarchical Accumulation,Xuan-Phi Nguyen;Shafiq Joty;Steven Hoi;Richard Socher,nxphi47@gmail.com;sjoty@salesforce.com,8;6;6,,Accept (Poster),0,0,0,yes,9/25/19,Nanyang Technological University;SalesForce.com,Tree;Constituency Tree;Hierarchical Accumulation;Machine Translation;NMT;WMT;IWSLT;Text Classification;Sentiment Analysis,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Sparse Coding with Gated Learned ISTA,Kailun Wu;Yiwen Guo;Ziang Li;Changshui Zhang,wukl14@mails.tsinghua.edu.cn;guoyiwen.ai@bytedance.com;liza19@mails.tsinghua.edu.cn;zcs@mail.tsinghua.edu.cn,8;8;8,,Accept (Spotlight),0,4,0,yes,9/25/19,"Tsinghua University, Tsinghua University;ByteDance;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Sparse coding;deep learning;learned ISTA;convergence analysis,4;-1;4;4,23;-1;23;23,m;m,NAN,NAN,y
ICLR,2020,A Signal Propagation Perspective for Pruning Neural Networks at Initialization,Namhoon Lee;Thalaiyasingam Ajanthan;Stephen Gould;Philip H. S. Torr,namhoon@robots.ox.ac.uk;thalaiyasingam.ajanthan@anu.edu.au;stephen.gould@anu.edu.au;phst@robots.ox.ac.uk,8;3;6,,Accept (Spotlight),0,3,0,yes,9/25/19,University of Oxford;Australian National University;Australian National University;University of Oxford,neural network pruning;signal propagation perspective;sparse neural networks,46;102;102;46,1;50;50;1,m;m,europe,uk,y
ICLR,2020,Functional vs. parametric equivalence of ReLU networks,Mary Phuong;Christoph H. Lampert,bphuong@ist.ac.at;chl@ist.ac.at,3;8;6,,Accept (Poster),1,4,0,yes,9/25/19,Institute of Science and Technology Austria;Institute of Science and Technology Austria,ReLU networks;symmetry;functional equivalence;over-parameterization,-1;-1,-1;-1,f;m,NAN,NAN,y
ICLR,2020,Jacobian Adversarially Regularized Networks for Robustness,Alvin Chan;Yi Tay;Yew Soon Ong;Jie Fu,guoweial001@e.ntu.edu.sg;ytay017@e.ntu.edu.sg;asysong@ntu.edu.sg;jie.fu@polymtl.ca,6;3;6,,Accept (Poster),0,5,1,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Polytechnique Montreal,adversarial examples;robust machine learning;deep learning,43;43;43;316,49;49;49;-1,m;m,canada,ca,y
ICLR,2020,Reinforced active learning for image segmentation,Arantxa Casanova;Pedro O. Pinheiro;Negar Rostamzadeh;Christopher J. Pal,arantxa.casanova-paga@polymtl.ca;pedro@opinheiro.com;negar@elementai.com;chris.j.pal@gmail.com,6;6,,Accept (Poster),0,5,0,yes,9/25/19,Polytechnique Montreal;Deep Genomics;Element AI;Polytechnique Montreal,semantic segmentation;active learning;reinforcement learning,316;-1;-1;316,-1;-1;-1;-1,f;m,canada,ca,n
ICLR,2020,Maximum Likelihood Constraint Inference for Inverse Reinforcement Learning,Dexter R.R. Scobee;S. Shankar Sastry,dscobee@eecs.berkeley.edu;sastry@eecs.berkeley.edu,3;6;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley,learning from demonstration;inverse reinforcement learning;constraint inference,-1;-1,13;13,m;m,usa,usa,y
ICLR,2020,Weakly Supervised Disentanglement with Guarantees,Rui Shu;Yining Chen;Abhishek Kumar;Stefano Ermon;Ben Poole,ruishu@stanford.edu;cynnjjs@stanford.edu;abhishk@google.com;ermon@cs.stanford.edu;pooleb@google.com,8;8;3,,Accept (Poster),1,10,0,yes,9/25/19,Stanford University;Stanford University;Google;Stanford University;Google,disentanglement;theory of disentanglement;representation learning;generative models,5;5;-1;5;-1,4;4;-1;4;-1,m;m,NAN,NAN,y
ICLR,2020,PCMC-Net: Feature-based Pairwise Choice Markov Chains,Alix Lh√©ritier,alherit@gmail.com,8;6;6;3,,Accept (Poster),0,5,0,yes,9/25/19,Amadeus IT Group,choice modeling;pairwise choice Markov chains;deep learning;amortized inference;automatic differentiation;airline itinerary choice modeling,-1,-1,m;u,NAN,NAN,y
ICLR,2020,Capsules with Inverted Dot-Product Attention Routing,Yao-Hung Hubert Tsai;Nitish Srivastava;Hanlin Goh;Ruslan Salakhutdinov,yaohungt@cs.cmu.edu;nitish_srivastava@apple.com;hanlin@apple.com;rsalakhutdinov@apple.com,3;6;8,,Accept (Poster),1,4,0,yes,9/25/19,Carnegie Mellon University;Apple;Apple;Apple,capsule networks;routing;attention,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Contrastive Representation Distillation,Yonglong Tian;Dilip Krishnan;Phillip Isola,yonglong@mit.edu;dilipkay@google.com;phillipi@mit.edu,3;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,Knowledge Distillation;Representation Learning;Contrastive Learning;Mutual Information,5;-1;5,5;-1;5,m;m,usa,usa,n
ICLR,2020,Variance Reduction With Sparse Gradients,Melih Elibol;Lihua Lei;Michael I. Jordan,elibol@cs.berkeley.edu;lihualei@stanford.edu;jordan@cs.berkeley.edu,6;3;8,,Accept (Poster),0,6,0,yes,9/25/19,University of California Berkeley;Stanford University;University of California Berkeley,optimization;variance reduction;machine learning;deep neural networks,-1;5;-1,13;4;13,m;m,usa,usa,y
ICLR,2020,FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary,Yingzhen Yang;Jiahui Yu;Nebojsa Jojic;Jun Huan;Thomas S. Huang,superyyzg@gmail.com;jyu79@illinois.edu;jojic@microsoft.com;lukehuan@shenshangtech.com;t-huang1@illinois.edu,8;6;6,,Accept (Poster),0,2,0,yes,9/25/19,"Arizona State University;University of Illinois, Urbana Champaign;Microsoft;Shenshangtech;University of Illinois, Urbana Champaign",Compression of Convolutional Neural Networks;Filter Summary CNNs;Weight Sharing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n
ICLR,2020,RNA Secondary Structure Prediction By Learning Unrolled Algorithms,Xinshi Chen;Yu Li;Ramzan Umarov;Xin Gao;Le Song,xinshi.chen@gatech.edu;yu.li@kaust.edu.sa;ramzan.umarov@kaust.edu.sa;xin.gao@kaust.edu.sa;lsong@cc.gatech.edu,8;6;8;8,,Accept (Talk),0,12,0,yes,9/25/19,Georgia Institute of Technology;KAUST;KAUST;KAUST;Georgia Institute of Technology,RNA secondary structure prediction;learning algorithm;deep architecture design;computational biology,13;102;102;102;13,38;-1;-1;-1;38,f;m,usa,usa,n
ICLR,2020,The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget,Anirudh Goyal;Yoshua Bengio;Matthew Botvinick;Sergey Levine,anirudhgoyal9119@gmail.com;yoshua.bengio@mila.quebec;botvinick@google.com;svlevine@eecs.berkeley.edu,6;6,,Accept (Poster),0,10,1,yes,9/25/19,University of Montreal;Mila;Google;University of California Berkeley,Variational Information Bottleneck;Reinforcement learning,-1;143;-1;-1,-1;336;-1;13,m;m,usa,usa,n
ICLR,2020,Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models,Cheolhyoung Lee;Kyunghyun Cho;Wanmo Kang,bloodwass@kaist.ac.kr;kyunghyun.cho@nyu.edu;wanmo.kang@kaist.edu,6;6;8,,Accept (Poster),0,5,1,yes,9/25/19,Korea Advanced Institute of Science and Technology;New York University;KAIST,regularization;finetuning;dropout;dropconnect;adaptive L2-penalty;BERT;pretrained language model,-1;22;15,110;29;110,m;m,asia,in,y
ICLR,2020,Novelty Detection Via Blurring,Sungik Choi;Sae-Young Chung,si_choi@kaist.ac.kr;schung@kaist.ac.kr,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,novelty;anomaly;uncertainty,-1;-1,110;110,m;m,NAN,NAN,n
ICLR,2020,Locality and Compositionality in Zero-Shot Learning,Tristan Sylvain;Linda Petrini;Devon Hjelm,tristan.sylvain@gmail.com;lindapetrini@gmail.com;devon.hjelm@microsoft.com,6;8;6,,Accept (Poster),0,3,0,yes,9/25/19,Microsoft;;Microsoft,Zero-shot learning;Compositionality;Locality;Deep Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control",Nir Levine;Yinlam Chow;Rui Shu;Ang Li;Mohammad Ghavamzadeh;Hung Bui,nirlevine@google.com;yinlamchow@google.com;ruishu@stanford.edu;anglili@google.com;mgh@fb.com;v.hungbh1@vinai.io,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Stanford University;Google;Facebook;VinAI Research,Embed-to-Control;Representation Learning;Stochastic Optimal Control;VAE;iLQR,-1;-1;5;-1;-1;-1,-1;-1;4;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Federated Learning with Matched Averaging,Hongyi Wang;Mikhail Yurochkin;Yuekai Sun;Dimitris Papailiopoulos;Yasaman Khazaeni,hongyiwang@cs.wisc.edu;mikhail.yurochkin@ibm.com;yuekai@umich.edu;dimitris@papail.io;yasaman.khazaeni@us.ibm.com,8;8;6,,Accept (Talk),0,5,1,yes,9/25/19,University of Southern California;International Business Machines;University of Michigan;University of Wisconsin - Madison;International Business Machines,federated learning,36;-1;7;18;-1,62;-1;21;51;-1,m;f,NAN,NAN,n
ICLR,2020,Efficient and Information-Preserving Future Frame Prediction and Beyond,Wei Yu;Yichao Lu;Steve Easterbrook;Sanja Fidler,gnosis@cs.toronto.edu;yichao@cs.toronto.edu;sme@cs.toronto.edu;fidler@cs.toronto.edu,6;6;3,,Accept (Poster),0,3,0,yes,9/25/19,University of Toronto;University of Toronto;University of Toronto;University of Toronto,self-supervised learning;generative pre-training;video prediction;reversible architecture,18;18;18;18,18;18;18;18,m;f,canada,ca,n
ICLR,2020,Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds,Lukas Prantl;Nuttapong Chentanez;Stefan Jeschke;Nils Thuerey,lukas.prantl@tum.de;nuttapong26@gmail.com;jeschke@stefan-jeschke.com;nils.thuerey@tum.de,6;8;6,,Accept (Spotlight),0,3,0,yes,9/25/19,Technical University Munich;;Stefan-jeschke;Technical University Munich,point clouds;spatio-temporal representations;Lagrangian data;temporal coherence;super-resolution;denoising,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Asymptotics of Wide Networks from Feynman Diagrams,Ethan Dyer;Guy Gur-Ari,edyer@google.com;guyga@google.com,6;6;8,,Accept (Spotlight),0,4,0,yes,9/25/19,Google;Google,,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Unbiased Contrastive Divergence Algorithm for Training Energy-Based Latent Variable Models,Yixuan Qiu;Lingsong Zhang;Xiao Wang,yixuanq@andrew.cmu.edu;lingsong@purdue.edu;wangxiao@purdue.edu,6;8;8,,Accept (Spotlight),0,3,2,yes,9/25/19,Carnegie Mellon University;Purdue University;Purdue University,energy model;restricted Boltzmann machine;contrastive divergence;unbiased Markov chain Monte Carlo;distribution coupling,1;24;24,27;88;88,m;f,usa,usa,y
ICLR,2020,Frequency-based Search-control in Dyna,Yangchen Pan;Jincheng Mei;Amir-massoud Farahmand,pan6@ualberta.ca;jmei2@ualberta.ca;farahmand@vectorinstitute.ai,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Alberta;University of Alberta;Vector Institute,Model-based reinforcement learning;search-control;Dyna;frequency of a signal,102;102;-1,136;136;-1,m;m,NAN,NAN,y
ICLR,2020,Energy-based models for atomic-resolution protein conformations,Yilun Du;Joshua Meier;Jerry Ma;Rob Fergus;Alexander Rives,yilundu@mit.edu;jmeier@fb.com;maj@fb.com;robfergus@fb.com;arives@cs.nyu.edu,8;8;6,,Accept (Spotlight),0,5,0,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook;New York University,energy-based model;transformer;energy function;protein conformation,5;-1;-1;-1;22,5;-1;-1;-1;29,m;m,usa,usa,n
ICLR,2020,Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and Strategic Dialog History,Yiheng Zhou;Yulia Tsvetkov;Alan W Black;Zhou Yu,yihengz1@cs.cmu.edu;ytsvetko@cs.cmu.edu;awb@cs.cmu.edu;joyu@ucdavis.edu,6;3;6,,Accept (Poster),0,3,0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;University of California, Davis",dialog systems;history tracking,1;1;1;-1,27;27;27;55,m;f,usa,usa,n
ICLR,2020,Discovering Motor Programs by Recomposing Demonstrations,Tanmay Shankar;Shubham Tulsiani;Lerrel Pinto;Abhinav Gupta,tanmayshankar@fb.com;shubhtuls@fb.com;lerrel.pinto@gmail.com;abhinavg@cs.cmu.edu,3;8;6,,Accept (Poster),0,9,0,yes,9/25/19,Facebook;Facebook;New York University;Carnegie Mellon University,Learning from Demonstration;Imitation Learning;Motor Primitives,-1;-1;22;1,-1;-1;29;27,m;m,usa,usa,n
ICLR,2020,Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers,Junjie LIU;Zhe XU;Runbin SHI;Ray C. C. Cheung;Hayden K.H. So,jjliu@eee.hku.hk;zhexu22-c@my.cityu.edu.hk;rbshi@eee.hku.hk;r.cheung@cityu.edu.hk;hso@eee.hku.hk,6;3;6,,Accept (Poster),0,6,3,yes,9/25/19,The University of Hong Kong;The Hong Kong Polytechnic University;The University of Hong Kong;The Hong Kong Polytechnic University;The University of Hong Kong,neural network pruning;sparse learning;network compression;architecture search,92;118;92;118;92,35;171;35;171;35,m;m,NAN,NAN,n
ICLR,2020,RTFM: Generalising to New Environment Dynamics via Reading,Victor Zhong;Tim Rockt√§schel;Edward Grefenstette,victor@victorzhong.com;tim.rocktaeschel@gmail.com;egrefen@gmail.com,6;6;6,,Accept (Poster),1,4,0,yes,9/25/19,University of Washington;Facebook AI Research;Facebook,reinforcement learning;policy learning;reading comprehension;generalisation,11;-1;-1,26;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Causal Discovery with Reinforcement Learning,Shengyu Zhu;Ignavier Ng;Zhitang Chen,zhushengyu@huawei.com;ignavierng@cs.toronto.edu;chenzhitang2@huawei.com,8;8;8,,Accept (Talk),0,6,2,yes,9/25/19,Huawei Technologies Ltd.;University of Toronto;Huawei Technologies Ltd.,causal discovery;structure learning;reinforcement learning;directed acyclic graph,-1;18;-1,-1;18;-1,m;m,NAN,NAN,y
ICLR,2020,FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES,Jatin Chauhan;Deepak Nathani;Manohar Kaul,chauhanjatin100@gmail.com;deepakn1019@gmail.com;mkaul@iith.ac.in,6;3;6,,Accept (Poster),0,6,0,yes,9/25/19,Indian Institute of Technology Hyderabad;Google;Indian Institute of Technology Hyderabad,Few shot graph classification;graph spectral measures;super-classes,-1;-1;-1,-1;-1;713,u;u,NAN,NAN,n
ICLR,2020,Controlling generative models with continuous factors of variations,Antoine Plumerault;Herv√© Le Borgne;C√©line Hudelot,antoine.plumerault@cea.fr;herve.le-borgne@cea.fr;celine.hudelot@centralesupelec.fr,6;6;8,,Accept (Poster),0,4,0,yes,9/25/19,CEA;CEA;CentraleSupelec,Generative models;factor of variation;GAN;beta-VAE;interpretable representation;interpretability,194;194;-1,1027;1027;534,m;f,NAN,NAN,n
ICLR,2020,Defending Against Physically Realizable Attacks on Image Classification,Tong Wu;Liang Tong;Yevgeniy Vorobeychik,tongwu@wustl.edu;liangtong@wustl.edu;yvorobeychik@wustl.edu,8;8;3,,Accept (Spotlight),0,9,0,yes,9/25/19,"Washington University, St. Louis;Washington University, St. Louis;Washington University, St. Louis",defense against physical attacks;adversarial machine learning,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n
ICLR,2020,A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning,Soochan Lee;Junsoo Ha;Dongsu Zhang;Gunhee Kim,soochan.lee@vision.snu.ac.kr;junsooha@hanyang.ac.kr;96lives@snu.ac.kr;gunhee@snu.ac.kr,6;6;8,,Accept (Poster),0,4,1,yes,9/25/19,Seoul National University;Hanyang University;Seoul National University;Seoul National University,continual learning;task-free;task-agnostic,39;194;39;39,64;393;64;64,m;m,asia,kr,n
ICLR,2020,HiLLoC: lossless image compression with hierarchical latent variable models,James Townsend;Thomas Bird;Julius Kunze;David Barber,james.townsend@cs.ucl.ac.uk;thomas.bird@cs.ucl.ac.uk;julius.kunze@cs.ucl.ac.uk;david.barber@ucl.ac.uk,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,University College London;University College London;University College London;University College London,compression;variational inference;lossless compression;deep latent variable models,52;52;52;52,-1;-1;-1;-1,m;m,europe,uk,n
ICLR,2020,Multilingual Alignment of Contextual Word Representations,Steven Cao;Nikita Kitaev;Dan Klein,stevencao@berkeley.edu;kitaev@berkeley.edu;klein@berkeley.edu,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,multilingual;natural language processing;embedding alignment;BERT;word embeddings;transfer,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Jelly Bean World: A Testbed for Never-Ending Learning,Emmanouil Antonios Platanios;Abulhair Saparov;Tom Mitchell,e.a.platanios@cs.cmu.edu;asaparov@cs.cmu.edu;tom.mitchell@cs.cmu.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1,27;27;27,m;m,usa,usa,n
ICLR,2020,V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control,H. Francis Song;Abbas Abdolmaleki;Jost Tobias Springenberg;Aidan Clark;Hubert Soyer;Jack W. Rae;Seb Noury;Arun Ahuja;Siqi Liu;Dhruva Tirumala;Nicolas Heess;Dan Belov;Martin Riedmiller;Matthew M. Botvinick,songf@google.com;aabdolmaleki@google.com;springenberg@google.com;aidanclark@google.com;soyer@google.com;jwrae@google.com;snoury@google.com;arahuja@google.com;liusiqi@google.com;dhruvat@google.com;heess@google.com;danbelov@google.com;riedmiller@google.com;botvinick@google.com,6;6;6,,Accept (Poster),1,7,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;policy iteration;multi-task learning;continuous control,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Deep Graph Matching Consensus,Matthias Fey;Jan E. Lenssen;Christopher Morris;Jonathan Masci;Nils M. Kriege,matthias.fey@tu-dortmund.de;janeric.lenssen@udo.edu;christopher.morris@tu-dortmund.de;jonathan@nnaisense.com;nils.kriege@tu-dortmund.de,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,TU Dortmund;TU Dortmund University;TU Dortmund;NNAISENSE;TU Dortmund,graph matching;graph neural networks;neighborhood consensus;deep learning,248;248;248;-1;248,354;354;354;-1;354,m;m,europe,de,y
ICLR,2020,CATER: A diagnostic dataset for Compositional Actions & TEmporal Reasoning,Rohit Girdhar;Deva Ramanan,rgirdhar@cs.cmu.edu;deva@cs.cmu.edu,8;8;8,,Accept (Talk),0,3,1,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Video Understanding;Temporal Reasoning,1;1,27;27,m;m,usa,usa,n
ICLR,2020,Differentiable Reasoning over a Virtual Knowledge Base,Bhuwan Dhingra;Manzil Zaheer;Vidhisha Balachandran;Graham Neubig;Ruslan Salakhutdinov;William W. Cohen,bdhingra@andrew.cmu.edu;manzilzaheer@google.com;vbalacha@andrew.cmu.edu;gneubig@cs.cmu.edu;rsalakhu@cs.cmu.edu;wcohen@google.com,8;8;8,,Accept (Talk),0,6,0,yes,9/25/19,Carnegie Mellon University;Google;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Google,Question Answering;Multi-Hop QA;Deep Learning;Knowledge Bases;Information Extraction;Data Structures for QA,1;-1;1;1;1;-1,27;-1;27;27;27;-1,m;m,NAN,NAN,n
ICLR,2020,Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents,Christian Rupprecht;Cyril Ibrahim;Christopher J. Pal,christian.rupprecht@eng.ox.ac.uk;cyril.ibrahim@elementai.com;christopher.pal@polymtl.ca,6;3;8,,Accept (Poster),0,4,0,yes,9/25/19,University of Oxford;Element AI;Polytechnique Montreal,Visualization;Reinforcement Learning;Safety,46;-1;316,1;-1;-1,m;m,canada,ca,n
ICLR,2020,Intriguing Properties of Adversarial Training at Scale,Cihang Xie;Alan Yuille,cihangxie306@gmail.com;alan.l.yuille@gmail.com,6;8;6,,Accept (Poster),0,4,1,yes,9/25/19,University of Southern California;Johns Hopkins University,adversarial defense;adversarial machine learning,36;73,62;12,m;m,usa,usa,n
ICLR,2020,Four Things Everyone Should Know to Improve Batch Normalization,Cecilia Summers;Michael J. Dinneen,ceciliasummers07@gmail.com;mjd@cs.auckland.ac.nz,6;3;6,,Accept (Poster),0,5,2,yes,9/25/19,University of Auckland;University of Auckland,batch normalization,248;248,177;177,f;m,australasia,nz,n
ICLR,2020,Effect of Activation Functions on the Training of Overparametrized Neural Nets,Abhishek Panigrahi;Abhishek Shetty;Navin Goyal,abhishekpanigrahi034@gmail.com;ashetty1995@gmail.com;navingo@microsoft.com,8;6,,Accept (Poster),0,2,0,yes,9/25/19,Princeton University;Cornell University;Microsoft,activation functions;deep learning theory;neural networks,-1;7;-1,-1;19;-1,m;m,NAN,NAN,y
ICLR,2020,Differentiation of Blackbox Combinatorial Solvers,Marin Vlastelica Poganƒçiƒá;Anselm Paulus;Vit Musil;Georg Martius;Michal Rolinek,marin.vlastelica@tue.mpg.de;anselm.paulus@tuebingen.mpg.de;vejtek@atrey.karlin.mff.cuni.cz;georg.martius@tuebingen.mpg.de;michal.rolinek@tuebingen.mpg.de,8;8;8,,Accept (Spotlight),0,6,0,yes,9/25/19,"Max-Planck Institute;Max-Planck Institute;Charles University, Prague;Max-Planck Institute;Max-Planck Institute",combinatorial algorithms;deep learning;representation learning;optimization,-1;-1;316;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning,Gil Lederman;Markus Rabe;Sanjit Seshia;Edward A. Lee,gilled@berkeley.edu;mrabe@google.com;sshesia@eecs.berkeley.edu;eal@eecs.berkeley.edu,3;8;6,,Accept (Poster),0,4,0,yes,9/25/19,University of California Berkeley;Google;University of California Berkeley;University of California Berkeley,Logic;QBF;Logical Reasoning;SAT;Graph;Reinforcement Learning;GNN,-1;-1;-1;-1,13;-1;13;13,m;m,usa,usa,n
ICLR,2020,Inductive representation learning on temporal graphs,da Xu;chuanwei ruan;evren korpeoglu;sushant kumar;kannan achan,da.xu@walmartlabs.com;ruanchuanwei@gmail.com;ekorpeoglu@walmart.com;skumar4@walmartlabs.com;kachan@walmartlabs.com,8;6;6,,Accept (Poster),1,4,0,yes,9/25/19,Walmart Labs;;Walmart;Walmart Labs;Walmart Labs,temporal graph;inductive representation learning;functional time encoding;self-attention,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Multi-Scale Representation Learning  for Spatial Feature Distributions using Grid Cells,Gengchen Mai;Krzysztof Janowicz;Bo Yan;Rui Zhu;Ling Cai;Ni Lao,gengchen_mai@geog.ucsb.edu;janowicz@ucsb.edu;boyan1@linkedin.com;ruizhu@geog.ucsb.edu;lingcai@ucsb.edu;noon99@gmail.com,8;6;6,,Accept (Spotlight),0,7,1,yes,9/25/19,UC Santa Barbara;UC Santa Barbara;LinkedIn;UC Santa Barbara;UC Santa Barbara;mosaix.ai,Grid cell;space encoding;spatially explicit model;multi-scale periodic representation;unsupervised learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley Transform,Jun Li;Fuxin Li;Sinisa Todorovic,liju2@oregonstate.edu;fuxin.li@oregonstate.edu;sinisa@oregonstate.edu,3;6;6,,Accept (Poster),0,9,2,yes,9/25/19,Oregon State University;Oregon State University;Oregon State University,Orthonormality;Efficient Riemannian Optimization;the Stiefel manifold.,79;79;79,373;373;373,m;m,usa,usa,y
ICLR,2020,"Neural tangent kernels, transportation mappings, and universal approximation",Ziwei Ji;Matus Telgarsky;Ruicheng Xian,ziweiji2@illinois.edu;mjt@illinois.edu;rxian2@illinois.edu,6;8,,Accept (Poster),0,4,1,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Neural Tangent Kernel;universal approximation;Barron;transport mapping,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Dream to Control: Learning Behaviors by Latent Imagination,Danijar Hafner;Timothy Lillicrap;Jimmy Ba;Mohammad Norouzi,mail@danijar.com;countzero@google.com;jba@cs.toronto.edu;mnorouzi@google.com,6;8;6;8,,Accept (Spotlight),1,6,1,yes,9/25/19,"Department of Computer Science, University of Toronto;Google;University of Toronto;Google",world model;latent dynamics;imagination;planning by backprop;policy optimization;planning;reinforcement learning;control;representations;latent variable model;visual control;value function,18;-1;18;-1,18;-1;18;-1,m;m,NAN,NAN,n
ICLR,2020,From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech,Hyeong-Seok Choi;Changdae Park;Kyogu Lee,kekepa15@snu.ac.kr;cdpark@connect.ust.hk;kglee@snu.ac.kr,8;6;3,,Accept (Poster),1,5,0,yes,9/25/19,Seoul National University;The Hong Kong University of Science and Technology;Seoul National University,Multi-modal learning;Self-supervised learning;Voice profiling;Conditional GANs,39;-1;39,64;47;64,m;m,asia,kr,n
ICLR,2020,Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension,Xinyun Chen;Chen Liang;Adams Wei Yu;Denny Zhou;Dawn Song;Quoc V. Le,xinyun.chen@berkeley.edu;crazydonkey@google.com;adamsyuwei@google.com;dennyzhou@google.com;dawnsong.travel@gmail.com;qvl@google.com,8;6;6,,Accept (Spotlight),0,8,0,yes,9/25/19,University of California Berkeley;Google;Google;Google;University of California Berkeley;Google,neural symbolic;reading comprehension;question answering,-1;-1;-1;-1;-1;-1,13;-1;-1;-1;13;-1,f;m,NAN,NAN,n
ICLR,2020,Population-Guided Parallel Policy Search for Reinforcement Learning,Whiyoung Jung;Giseung Park;Youngchul Sung,wy.jung@kaist.ac.kr;gs.park@kaist.ac.kr;ycsung@kaist.ac.kr,6;8;3,,Accept (Poster),0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Parallel Learning;Population Based Learning,-1;-1;-1,110;110;110,m;m,NAN,NAN,y
ICLR,2020,Abstract Diagrammatic Reasoning with Multiplex Graph Networks,Duo Wang;Mateja Jamnik;Pietro Lio,wd263@cam.ac.uk;mateja.jamnik@cl.cam.ac.uk;pietro.lio@cl.cam.ac.uk,6;3;6,,Accept (Poster),0,7,0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge,reasoning;Raven Progressive Matrices;graph neural networks;multiplex graphs,79;79;79,3;3;3,m;m,europe,uk,n
ICLR,2020,Logic and the 2-Simplicial Transformer,James Clift;Dmitry Doryn;Daniel Murfet;James Wallbridge,jamesedwardclift@gmail.com;dmitry.doryn@gmail.com;d.murfet@unimelb.edu.au;james.wallbridge@gmail.com,3;3;8,,Accept (Poster),0,8,0,yes,9/25/19,The University of Melbourne;;The University of Melbourne;Kavli IPMU,transformer;logic;reinforcement learning;reasoning,-1;-1;85;-1,-1;-1;32;-1,m;m,asia,in,n
ICLR,2020,Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies,Sungryull Sohn;Hyunjae Woo;Jongwook Choi;Honglak Lee,srsohn@umich.edu;hjwoo@umich.edu;jwook@umich.edu;honglak@eecs.umich.edu,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,University of Michigan;University of Michigan;University of Michigan;University of Michigan,Meta reinforcement learning;subtask graph,7;7;7;7,21;21;21;21,m;m,usa,usa,n
ICLR,2020,A Latent Morphology Model for Open-Vocabulary Neural Machine Translation,Duygu Ataman;Wilker Aziz;Alexandra Birch,duyguataman@gmail.com;will.aziz@gmail.com;a.birch@ed.ac.uk,6;6;8,,Accept (Spotlight),0,0,0,yes,9/25/19,University of Zurich;University of Amsterdam;University of Edinburgh,neural machine translation;low-resource languages;latent-variable models,118;143;36,90;62;30,f;f,europe,uk,n
ICLR,2020,Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification,Yixiao Ge;Dapeng Chen;Hongsheng Li,yxge@link.cuhk.edu.hk;chendapeng@sensetime.com;hsli@ee.cuhk.edu.hk,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,The Chinese University of Hong Kong;SenseTime Group Limited;The Chinese University of Hong Kong,Label Refinery;Unsupervised Domain Adaptation;Person Re-identification,316;-1;316,35;-1;35,m;m,NAN,NAN,n
ICLR,2020,Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling,Hao Zhang;Bo Chen;Long Tian;Zhengjue Wang;Mingyuan Zhou,zhanghao_xidian@163.com;bchen@mail.xidian.edu.cn;tianlong_xidian@163.com;zhengjuewang@163.com;mingyuan.zhou@mccombs.utexas.edu,6;3;8,,Accept (Poster),0,4,0,yes,9/25/19,"163;Xidian University;163;163;University of Texas, Austin",Deep topic model;image generation;text generation;raster-scan-GAN;zero-shot learning,-1;-1;-1;-1;-1,-1;919;-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control,Tsui-Wei Weng;Krishnamurthy (Dj) Dvijotham*;Jonathan Uesato*;Kai Xiao*;Sven Gowal*;Robert Stanforth*;Pushmeet Kohli,twweng@mit.edu;dvij@google.com;juesato@google.com;kaix@mit.edu;sgowal@google.com;stanforth@google.com;pushmeet@google.com,6;6;3,,Accept (Poster),0,8,0,yes,9/25/19,Massachusetts Institute of Technology;Google;Google;Massachusetts Institute of Technology;Google;Google;Google,deep learning;reinforcement learning;robustness;adversarial examples,5;-1;-1;5;-1;-1;-1,5;-1;-1;5;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget,Jack Turner;Elliot J. Crowley;Michael O'Boyle;Amos Storkey;Gavin Gray,jack.turner@ed.ac.uk;elliot.j.crowley@ed.ac.uk;mob@inf.ed.ac.uk;a.storkey@ed.ac.uk;g.d.b.gray@ed.ac.uk,6;3;6,,Accept (Poster),0,3,0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh;University of Edinburgh;University of Edinburgh,model compression;architecture search;efficiency;budget;convolutional neural networks,36;36;36;36;36,30;30;30;30;30,m;m,europe,uk,n
ICLR,2020,Decoding As Dynamic Programming For Recurrent Autoregressive Models,Najam Zaidi;Trevor Cohn;Gholamreza Haffari,syed.zaidi1@monash.edu;t.cohn@unimelb.edu.au;reza.haffari@gmail.com,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Monash University;The University of Melbourne;Monash University,Decoding,92;85;-1,75;32;-1,m;m,asia,in,n
ICLR,2020,LEARNING EXECUTION THROUGH NEURAL CODE FUSION,Zhan Shi;Kevin Swersky;Daniel Tarlow;Parthasarathy Ranganathan;Milad Hashemi,zshi17@cs.utexas.edu;kswersky@google.com;dtarlow@google.com;parthas@google.com;miladh@google.com,6;8;3,,Accept (Poster),0,3,0,yes,9/25/19,"University of Texas, Austin;Google;Google;Google;Google",code understanding;graph neural networks;learning program execution;execution traces;program performance,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions,Yao Qin;Nicholas Frosst;Sara Sabour;Colin Raffel;Garrison Cottrell;Geoffrey Hinton,yaq007@eng.ucsd.edu;frosst@google.com;sasabour@google.com;craffel@google.com;gary@eng.ucsd.edu;geoffhinton@google.com,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,"University of California, San Diego;Google;Google;Google;University of California, San Diego;Google",Adversarial Examples;Detection of adversarial attacks,-1;-1;-1;-1;-1;-1,31;-1;-1;-1;31;-1,f;m,NAN,NAN,n
ICLR,2020,Reconstructing continuous distributions of 3D protein structure from cryo-EM images,Ellen D. Zhong;Tristan Bepler;Joseph H. Davis;Bonnie Berger,zhonge@mit.edu;tbepler@mit.edu;jhdavis@mit.edu;bab@mit.edu,8;8;6,,Accept (Spotlight),0,3,1,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,generative models;proteins;3D reconstruction;cryo-EM,5;5;5;5,5;5;5;5,f;f,usa,usa,n
ICLR,2020,Sampling-Free Learning of Bayesian Quantized Neural Networks,Jiahao Su;Milan Cvitkovic;Furong Huang,jiahaosu@terpmail.umd.edu;mcvitkov@caltech.edu;furongh@cs.umd.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,"University of Maryland, College Park;California Institute of Technology;University of Maryland, College Park",Bayesian neural networks;Quantized neural networks,12;143;12,91;2;91,m;f,usa,usa,y
ICLR,2020,On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach,Yuanhao Wang*;Guodong Zhang*;Jimmy Ba,yuanhao-16@mails.tsinghua.edu.cn;gdzhang@cs.toronto.edu;jba@cs.toronto.edu,6;6;6,,Accept (Poster),1,21,0,yes,9/25/19,"Tsinghua University, Tsinghua University;University of Toronto;University of Toronto",minimax optimization;smooth differentiable games;local convergence;generative adversarial networks;optimization,4;18;18,23;18;18,m;m,canada,ca,y
ICLR,2020,Lagrangian Fluid Simulation with Continuous Convolutions,Benjamin Ummenhofer;Lukas Prantl;Nils Thuerey;Vladlen Koltun,benjamin.ummenhofer@intel.com;lukas.prantl@tum.de;nils.thuerey@tum.de;vkoltun@gmail.com,8;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Intel;Technical University Munich;Technical University Munich;Intel,particle-based physics;fluid mechanics;continuous convolutions;material estimation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well,Vipul Gupta;Santiago Akle Serrano;Dennis DeCoste,vipul_gupta@berkeley.edu;sakle@apple.com;ddecoste@apple.com,6;6;3,,Accept (Poster),0,3,0,yes,9/25/19,University of California Berkeley;Apple;Apple,Large batch training;Distributed neural network training;Stochastic Weight Averaging,-1;-1;-1,13;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Adversarial AutoAugment,Xinyu Zhang;Qiang Wang;Jian Zhang;Zhao Zhong,zhangxinyu10@huawei.com;wangqiang168@huawei.com;zhangjian157@huawei.com;zorro.zhongzhao@huawei.com,6;6;6,,Accept (Poster),0,10,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Automatic Data Augmentation;Adversarial Learning;Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search,Arber Zela;Julien Siems;Frank Hutter,zelaa@cs.uni-freiburg.de;siemsj@cs.uni-freiburg.de;fh@cs.uni-freiburg.de,1;8;8,,Accept (Poster),0,5,0,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Neural Architecture Search;Deep Learning;Computer Vision,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,You Only Train Once: Loss-Conditional Training of Deep Networks,Alexey Dosovitskiy;Josip Djolonga,adosovitskiy@gmail.com;josip@djolonga.com,6;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Google;Google,deep learning;image generation,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP,Yuanhao Wang;Kefan Dong;Xiaoyu Chen;Liwei Wang,yuanhao-16@mails.tsinghua.edu.cn;dkf16@mails.tsinghua.edu.cn;cxy30@pku.edu.cn;wanglw@cis.pku.edu.cn,6;6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Peking University;Peking University",theory;reinforcement learning;sample complexity,4;4;14;14,23;23;24;24,m;m,asia,cn,y
ICLR,2020,Deep Audio Priors Emerge From Harmonic Convolutional Networks,Zhoutong Zhang;Yunyun Wang;Chuang Gan;Jiajun Wu;Joshua B. Tenenbaum;Antonio Torralba;William T. Freeman,ztzhang@mit.edu;wyy@mit.edu;ganchuang1990@gmail.com;jiajunwu@mit.edu;jbt@mit.edu;torralba@mit.edu;billf@mit.edu,6;6;6,,Accept (Poster),0,6,2,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Audio;Deep Prior,5;5;-1;5;5;5;5,5;5;-1;5;5;5;5,m;m,usa,usa,n
ICLR,2020,Abductive Commonsense Reasoning,Chandra Bhagavatula;Ronan Le Bras;Chaitanya Malaviya;Keisuke Sakaguchi;Ari Holtzman;Hannah Rashkin;Doug Downey;Wen-tau Yih;Yejin Choi,chandrab@allenai.org;ronanlb@allenai.org;chaitanyam@allenai.org;keisukes@allenai.org;arih@allenai.org;hrashkin@uw.edu;dougd@allenai.org;scottyih@fb.com;yejinc@allenai.org,8;6;6,,Accept (Poster),0,4,0,yes,9/25/19,"Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;University of Washington, Seattle;Allen Institute for Artificial Intelligence;Facebook;Allen Institute for Artificial Intelligence",Abductive Reasoning;Commonsense Reasoning;Natural Language Inference;Natural Language Generation,-1;-1;-1;-1;-1;11;-1;-1;-1,-1;-1;-1;-1;-1;26;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures,Huanrui Yang;Wei Wen;Hai Li,huanrui.yang@duke.edu;wei.wen@duke.edu;hai.li@duke.edu,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Duke University;Duke University;Duke University,Deep neural network;Sparsity inducing regularizer;Model compression,46;46;46,20;20;20,m;f,europe,se,n
ICLR,2020,DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling,Sachin Mehta;Rik Koncel-Kedziorski;Mohammad Rastegari;Hannaneh Hajishirzi,sacmehta@uw.edu;kedzior@uw.edu;mohammadr@allenai.org;hannaneh@washington.edu,6;6;3,,Accept (Poster),0,13,1,yes,9/25/19,"University of Washington, Seattle;University of Washington, Seattle;Allen Institute for Artificial Intelligence;University of Washington",sequence modeling;input representations;language modeling;word embedding,11;11;-1;11,26;26;-1;26,m;f,usa,usa,n
ICLR,2020,Never Give Up: Learning Directed Exploration Strategies,Adri√† Puigdom√®nech Badia;Pablo Sprechmann;Alex Vitvitskyi;Daniel Guo;Bilal Piot;Steven Kapturowski;Olivier Tieleman;Martin Arjovsky;Alexander Pritzel;Andrew Bolt;Charles Blundell,adriap@google.com;psprechmann@google.com;avlife@google.com;danielguo@google.com;piot@google.com;skapturowski@google.com;tieleman@google.com;martinarjovsky@gmail.com;apritzel@google.com;abolt@google.com;cblundell@google.com,6;8;6,,Accept (Poster),0,5,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;;Google;Google;Google,deep reinforcement learning;exploration;intrinsic motivation,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks,Yu Bai;Jason D. Lee,yubai.pku@gmail.com;jasondlee88@gmail.com,6;6;6,,Accept (Poster),0,4,1,yes,9/25/19,SalesForce.com;Princeton University,Neural Tangent Kernels;over-parametrized neural networks;deep learning theory,-1;30,-1;6,m;m,usa,usa,y
ICLR,2020,Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity,Jingzhao Zhang;Tianxing He;Suvrit Sra;Ali Jadbabaie,jzhzhang@mit.edu;tianxing@mit.edu;suvrit@mit.edu;jadbabai@mit.edu,8;8;8,,Accept (Talk),0,8,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Adaptive methods;optimization;deep learning,5;5;5;5,5;5;5;5,m;m,usa,usa,y
ICLR,2020,Thieves on Sesame Street! Model Extraction of BERT-based APIs,Kalpesh Krishna;Gaurav Singh Tomar;Ankur P. Parikh;Nicolas Papernot;Mohit Iyyer,kalpesh@cs.umass.edu;gtomar@google.com;aparikh@google.com;papernot@google.com;miyyer@cs.umass.edu,8;6;8,,Accept (Poster),0,3,1,yes,9/25/19,"University of Massachusetts, Amherst;Google;Google;Google;University of Massachusetts, Amherst",model extraction;BERT;natural language processing;pretraining language models;model stealing;deep learning security,24;-1;-1;-1;24,209;-1;-1;-1;209,m;m,usa,usa,n
ICLR,2020,GraphZoom: A Multi-level Spectral Approach for Accurate and Scalable Graph Embedding,Chenhui Deng;Zhiqiang Zhao;Yongyu Wang;Zhiru Zhang;Zhuo Feng,cd574@cornell.edu;qzzhao@mtu.edu;yongyuw@mtu.edu;zhiruz@cornell.edu;zfeng12@stevens.edu,6;8;8,,Accept (Talk),0,7,0,yes,9/25/19,Cornell University;Michigan Technological University;Michigan Technological University;Cornell University;Stevens Institute of Technology,graph embedding;unsupervised learning;multi-level optimization;spectral graph theory,7;316;316;7;143,19;-1;-1;19;605,m;m,usa,usa,n
ICLR,2020,Low-Resource Knowledge-Grounded Dialogue Generation,Xueliang Zhao;Wei Wu;Chongyang Tao;Can Xu;Dongyan Zhao;Rui Yan,xl.zhao@pku.edu.cn;wuwei@microsoft.com;chongyangtao@pku.edu.cn;can.xu@microsoft.com;zhaody@pku.edu.cn;ruiyan@pku.edu.cn,6;8;8,,Accept (Poster),0,4,0,yes,9/25/19,Peking University;Microsoft;Peking University;Microsoft;Peking University;Peking University,,14;-1;14;-1;14;14,24;-1;24;-1;24;24,m;m,asia,cn,n
ICLR,2020,Diverse Trajectory Forecasting with Determinantal Point Processes,Ye Yuan;Kris M. Kitani,yyuan2@cs.cmu.edu;kkitani@cs.cmu.edu,6;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Diverse Inference;Generative Models;Trajectory Forecasting,1;1,27;27,m;m,usa,usa,n
ICLR,2020,Maxmin Q-learning: Controlling the Estimation Bias of Q-learning,Qingfeng Lan;Yangchen Pan;Alona Fyshe;Martha White,qlan3@ualberta.ca;pan6@ualberta.ca;alona@ualberta.ca;whitem@ualberta.ca,6;3;8,,Accept (Poster),0,11,0,yes,9/25/19,University of Alberta;University of Alberta;University of Alberta;University of Alberta,reinforcement learning;bias and variance reduction,102;102;102;102,136;136;136;136,u;f,canada,ca,y
ICLR,2020,Editable Neural Networks,Anton Sinitsin;Vsevolod Plokhotnyuk;Dmitry Pyrkin;Sergei Popov;Artem Babenko,ant.sinitsin@gmail.com;vsevolod-pl@yandex.ru;alagaster@yandex.ru;sapopov@yandex-team.ru;artem.babenko@phystech.edu,6;3;8,,Accept (Poster),0,8,0,yes,9/25/19,Higher School of Economics;Higher School of Economics;;Yandex;Moscow Institute of Physics and Technology,editing;editable;meta-learning;maml,-1;-1;-1;-1;-1,-1;-1;-1;-1;234,m;m,NAN,NAN,n
ICLR,2020,Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness,Tianyu Pang;Kun Xu;Yinpeng Dong;Chao Du;Ning Chen;Jun Zhu,pty17@mails.tsinghua.edu.cn;kunxu.thu@gmail.com;dyp17@mails.tsinghua.edu.cn;duchao0726@gmail.com;ningchen@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,6;6;8;6,,Accept (Poster),0,14,0,yes,9/25/19,"Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Trustworthy Machine Learning;Adversarial Robustness;Training Objective;Sample Density,4;-1;4;-1;4;4,23;-1;23;-1;23;23,m;m,NAN,NAN,y
ICLR,2020,Self-labelling via simultaneous clustering and representation learning,Asano YM.;Rupprecht C.;Vedaldi A.,yuki@robots.ox.ac.uk;chrisr@robots.ox.ac.uk;vedaldi@robots.ox.ac.uk,8;3;8,,Accept (Spotlight),0,5,4,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,self-supervision;feature representation learning;clustering,46;46;46,1;1;1,m;m,europe,uk,n
ICLR,2020,Semi-Supervised Generative Modeling for Controllable Speech Synthesis,Raza Habib;Soroosh Mariooryad;Matt Shannon;Eric Battenberg;RJ Skerry-Ryan;Daisy Stanton;David Kao;Tom Bagby,raza.habib@cs.ucl.ac.uk;soroosh@google.com;mattshannon@google.com;ebattenberg@google.com;rjryan@google.com;daisy@google.com;davidkao@google.com;tombagby@google.com,6;8;6,,Accept (Poster),0,9,0,yes,9/25/19,University College London;Google;Google;Google;Google;Google;Google;Google,TTS;Speech Synthesis;Semi-supervised Models;VAE;disentanglement,52;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks,Sanchari Sen;Balaraman Ravindran;Anand Raghunathan,sen9@purdue.edu;ravi@cse.iitm.ac.in;raghunathan@purdue.edu,6;6;1,,Accept (Poster),0,3,0,yes,9/25/19,Purdue University;Indian Institute of Technology Madras;Purdue University,ensembles;mixed precision;robustness;adversarial attacks,24;-1;24,88;641;88,f;m,usa,usa,n
ICLR,2020,Training Recurrent Neural Networks Online by Learning Explicit State Variables,Somjit Nath;Vincent Liu;Alan Chan;Xin Li;Adam White;Martha White,somjit@ualberta.ca;vliu1@ualberta.ca;achan4@ualberta.ca;xzli@ualberta.ca;amw8@ualberta.ca;whitem@ualberta.ca,6;6;3,,Accept (Poster),0,9,0,yes,9/25/19,University of Alberta;University of Alberta;University of Alberta;University of Alberta;University of Alberta;University of Alberta,Recurrent Neural Network;Partial Observability;Online Prediction;Incremental Learning,102;102;102;102;102;102,136;136;136;136;136;136,m;f,canada,ca,y
ICLR,2020,MEMO: A Deep Network for Flexible Combination of Episodic Memories,Andrea Banino;Adri√† Puigdom√®nech Badia;Raphael K√∂ster;Martin J. Chadwick;Vinicius Zambaldi;Demis Hassabis;Caswell Barry;Matthew Botvinick;Dharshan Kumaran;Charles Blundell,abanino@google.com;adriap@google.com;rkoster@google.com;mjchadwick@google.com;vzambaldi@google.com;dhteam@google.com;caswell.barry@ucl.ac.uk;botvinick@google.com;dkumaran@google.com;cblundell@google.com,8;6,,Accept (Poster),0,2,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;University College London;Google;Google;Google,Memory Augmented Neural Networks;Deep Learning,-1;-1;-1;-1;-1;-1;52;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Differentiable learning of numerical rules in knowledge graphs,Po-Wei Wang;Daria Stepanova;Csaba Domokos;J. Zico Kolter,poweiw@cs.cmu.edu;daria.stepanova@de.bosch.com;csaba.domokos@de.bosch.com;zkolter@cs.cmu.edu,3;6;6,,Accept (Poster),0,6,0,yes,9/25/19,Carnegie Mellon University;Bosch;Bosch;Carnegie Mellon University,knowledge graphs;rule learning;differentiable neural logic,1;-1;-1;1,27;297;297;27,m;m,usa,usa,n
ICLR,2020,Multiplicative Interactions and Where to Find Them,Siddhant M. Jayakumar;Wojciech M. Czarnecki;Jacob Menick;Jonathan Schwarz;Jack Rae;Simon Osindero;Yee Whye Teh;Tim Harley;Razvan Pascanu,sidmj@google.com;lejlot@google.com;jmenick@google.com;schwarzjn@google.com;jwrae@google.com;osindero@google.com;ywteh@google.com;tharley@google.com;razp@google.com,8;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google,multiplicative interactions;hypernetworks;attention,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Recurrent neural circuits for contour detection,Drew Linsley*;Junkyung Kim*;Alekh Ashok;Thomas Serre,drew_linsley@brown.edu;junkyung_kim@brown.edu;alekh_karkada_ashok@brown.edu;thomas_serre@brown.edu,6;8;6,,Accept (Poster),0,7,0,yes,9/25/19,Brown University;Brown University;Brown University;Brown University,Contextual illusions;visual cortex;recurrent feedback;neural circuits,85;85;85;85,53;53;53;53,m;m,usa,usa,n
ICLR,2020,Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks,Wei Hu;Lechao Xiao;Jeffrey Pennington,huwei@cs.princeton.edu;xlc@google.com;jpennin@google.com,6;8;3,,Accept (Poster),0,3,0,yes,9/25/19,Princeton University;Google;Google,deep learning theory;non-convex optimization;orthogonal initialization,30;-1;-1,6;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Sliced Cramer Synaptic Consolidation for Preserving Deeply Learned Representations,Soheil Kolouri;Nicholas A. Ketz;Andrea Soltoggio;Praveen K. Pilly,skolouri@hrl.com;naketz@hrl.com;a.soltoggio@lboro.ac.uk;pkpilly@hrl.com,8;6,,Accept (Spotlight),0,2,0,yes,9/25/19,"HRL Laboratories, LLC;HRL Laboratories, LLC;Loughborough University;HRL Laboratories, LLC",selective plasticity;catastrophic forgetting;intransigence,-1;-1;445;-1,-1;-1;374;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Outlier Rejection for Self-Supervised Keypoint Learning,Jiexiong Tang;Hanme Kim;Vitor Guizilini;Sudeep Pillai;Rares Ambrus,jiexiong@kth.se;hanme.kim@tri.global;vitor.guizilini@tri.global;sudeep.pillai@tri.global;rares.ambrus@tri.global,6;8;6,,Accept (Poster),0,8,0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;Toyota Research Institute;Toyota Research Institute;Toyota Research Institute;Toyota Research Institute",Self-Supervised Learning;Keypoint Detection;Outlier Rejection;Deep Learning,194;-1;-1;-1;-1,222;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,Alexei Baevski;Steffen Schneider;Michael Auli,alexei.b@gmail.com;stes@fb.com;michael.auli@gmail.com,8;8;6;8,,Accept (Poster),0,5,0,yes,9/25/19,Facebook;Facebook;Facebook,speech recognition;speech representation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Fair Comparison of Graph Neural Networks for Graph Classification,Federico Errica;Marco Podda;Davide Bacciu;Alessio Micheli,federico.errica@phd.unipi.it;marco.podda@di.unipi.it;bacciu@di.unipi.it;micheli@di.unipi.it,8;6;6,,Accept (Poster),0,12,0,yes,9/25/19,University of Pisa;University of Pisa;University of Pisa;University of Pisa,graph neural networks;graph classification;reproducibility;graph representation learning,248;248;248;248,366;366;366;366,m;m,europe,il,n
ICLR,2020,Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models,Xisen Jin;Zhongyu Wei;Junyi Du;Xiangyang Xue;Xiang Ren,xisenjin@usc.edu;zywei@fudan.edu.cn;junyidu@usc.edu;xyxue@fudan.edu.cn;xiangren@usc.edu,6;8;6,,Accept (Spotlight),0,7,0,yes,9/25/19,University of Southern California;Fudan University;University of Southern California;Fudan University;University of Southern California,natural language processing;interpretability,36;73;36;73;36,62;109;62;109;62,m;m,usa,usa,n
ICLR,2020,Understanding Why Neural Networks Generalize Well Through GSNR of Parameters,Jinlong Liu;Yunzhi Bai;Guoqing Jiang;Ting Chen;Huayan Wang,ljlwykqh@126.com;yunzhi.bai@outlook.fr;jianggq@pku.edu.cn;roushi0322@sina.cn;wanghuayan@kuaishou.com,6;6;3,,Accept (Spotlight),0,4,0,yes,9/25/19,126;Kuaishou Technology;Peking University;;Kuaishou Technology,DNN;generalization;GSNR;gradient descent,-1;-1;14;-1;-1,-1;-1;24;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Intrinsic Motivation for Encouraging Synergistic Behavior,Rohan Chitnis;Shubham Tulsiani;Saurabh Gupta;Abhinav Gupta,ronuchit@mit.edu;shubhtuls@fb.com;saurabhg@illinois.edu;abhinavg@cs.cmu.edu,6;8;6,,Accept (Poster),0,4,0,yes,9/25/19,"Massachusetts Institute of Technology;Facebook;University of Illinois, Urbana Champaign;Carnegie Mellon University",reinforcement learning;intrinsic motivation;synergistic;robot manipulation,5;-1;-1;1,5;-1;-1;27,m;m,usa,usa,n
ICLR,2020,Sharing Knowledge in Multi-Task Deep Reinforcement Learning,Carlo D'Eramo;Davide Tateo;Andrea Bonarini;Marcello Restelli;Jan Peters,carlo@robot-learning.de;davide@robot-learning.de;andrea.bonarini@polimi.it;marcello.restelli@polimi.it;peters@ias.tu-darmstadt.de,6;6;6,,Accept (Poster),0,3,0,yes,9/25/19,TU Darmstadt;TU Darmstadt;Politecnico di Milano;Politecnico di Milano;TU Darmstadt,Deep Reinforcement Learning;Multi-Task,59;59;143;143;59,-1;-1;-1;-1;-1,m;m,europe,de,y
ICLR,2020,Provable Filter Pruning for Efficient Neural Networks,Lucas Liebenwein;Cenk Baykal;Harry Lang;Dan Feldman;Daniela Rus,lucasl@mit.edu;baykal@mit.edu;hlang08@gmail.com;dannyf.post@gmail.com;rus@csail.mit.edu,3;6;3,,Accept (Poster),0,5,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of Haifa;Massachusetts Institute of Technology,theory;compression;filter pruning;neural networks,5;5;5;194;5,5;5;5;544;5,m;f,usa,usa,y
ICLR,2020,Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks,Yuhang Li;Xin Dong;Wei Wang,loafyuhang@gmail.com;xindong@g.harvard.edu;wangwei@comp.nus.edu.sg,6;3;6,,Accept (Poster),0,4,1,yes,9/25/19,Yale University;Harvard University;National University of Singapore,Quantization;Efficient Inference;Neural Networks,-1;52;17,-1;7;25,u;m,asia,sg,n
ICLR,2020,Variational Recurrent Models for Solving Partially Observable Control Tasks,Dongqi Han;Kenji Doya;Jun Tani,dongqi.han@oist.jp;doya@oist.jp;jun.tani@oist.jp,6;8;6,,Accept (Poster),0,6,0,yes,9/25/19,Okinawa Institute of Science and Technology (OIST);Okinawa Institute of Science and Technology (OIST);Okinawa Institute of Science and Technology (OIST),Reinforcement Learning;Deep Learning;Variational Inference;Recurrent Neural Network;Partially Observable;Robotic Control;Continuous Control,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference,Lasse Espeholt;Rapha√´l Marinier;Piotr Stanczyk;Ke Wang;Marcin Michalski‚Äé,lespeholt@google.com;raphaelm@google.com;stanczyk@google.com;kewa@google.com;michalski@google.com,8;6;8,,Accept (Talk),0,4,0,yes,9/25/19,Google;Google;Google;Google;Google,machine learning;reinforcement learning;scalability;distributed;DeepMind Lab;ALE;Atari-57;Google Research Football,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Discriminative Particle Filter Reinforcement Learning for Complex Partial observations,Xiao Ma;Peter Karkus;David Hsu;Wee Sun Lee;Nan Ye,xiao-ma@comp.nus.edu.sg;karkus@comp.nus.edu.sg;dyhsu@comp.nus.edu.sg;leews@comp.nus.edu.sg;nan.ye@uq.edu.au,8;6;8,,Accept (Poster),0,5,0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;National University of Singapore;University of Queensland,Reinforcement Learning;Partial Observability;Differentiable Particle Filtering,17;17;17;17;248,25;25;25;25;66,f;m,australasia,au,n
ICLR,2020,White Noise Analysis of Neural Networks,Ali Borji;Sikun Lin,aliborji@gmail.com;sikun@ucsb.edu,3;8;6;6,,Accept (Spotlight),0,7,0,yes,9/25/19,HCL America;UC Santa Barbara,Classification images;spike triggered analysis;deep learning;network visualization;adversarial attack;adversarial defense;microstimulation;computational neuroscience,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering ,Sam Lobel*;Chunyuan Li*;Jianfeng Gao;Lawrence Carin,samuel_lobel@brown.edu;chunyuan.li@microsoft.com;jfgao@microsoft.com;lcarin@duke.edu,8;6;6,,Accept (Poster),0,3,0,yes,9/25/19,Brown University;Microsoft;Microsoft;Duke University,Collaborative Filtering;Recommender Systems;Actor-Critic;Learned Metrics,85;-1;-1;46,53;-1;-1;20,m;m,europe,se,n
ICLR,2020,Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets,Dongxian Wu;Yisen Wang;Shu-Tao Xia;James Bailey;Xingjun Ma,wu-dx16@mails.tsinghua.edu.cn;eewangyisen@gmail.com;xiast@sz.tsinghua.edu.cn;baileyj@unimelb.edu.au;xingjun.ma@unimelb.edu.au,8;6;6,,Accept (Spotlight),0,4,1,yes,9/25/19,"Tsinghua University, Tsinghua University;Peking University;Tsinghua University, Tsinghua University;The University of Melbourne;The University of Melbourne",Adversarial Example;Transferability;Skip Connection;Neural Network,4;14;4;85;85,23;24;23;32;32,m;m,NAN,NAN,n
ICLR,2020,The Local Elasticity of Neural Networks,Hangfeng He;Weijie Su,hangfeng@seas.upenn.edu;suw@wharton.upenn.edu,6;6;6,,Accept (Poster),0,6,0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania,,20;20,11;11,m;m,usa,usa,n
ICLR,2020,Deep probabilistic subsampling for task-adaptive compressed sensing,Iris A.M. Huijben;Bastiaan S. Veeling;Ruud J.G. van Sloun,i.a.m.huijben@tue.nl;basveeling@gmail.com;r.j.g.v.sloun@tue.nl,6;6;6,,Accept (Poster),0,8,1,yes,9/25/19,Eindhoven University of Technology;Google;Eindhoven University of Technology,,-1;-1;-1,185;-1;185,f;m,NAN,NAN,n
ICLR,2020,Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning,Hengyuan Hu;Jakob N Foerster,hengyuan@fb.com;jakobfoerster@gmail.com,8;8;8,,Accept (Spotlight),0,9,0,yes,9/25/19,Facebook;University of Toronto,multi-agent RL;theory of mind,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,On the Need for Topology-Aware Generative Models for Manifold-Based Defenses,Uyeong Jang;Susmit Jha;Somesh Jha,wjang@cs.wisc.edu;susmit.jha@sri.com;jha@cs.wisc.edu,8;6;3,,Accept (Poster),0,6,0,yes,9/25/19,University of Southern California;SRI International;University of Southern California,Manifold-based Defense;Robust Learning;Adversarial Attacks,36;-1;36,62;-1;62,m;m,usa,usa,y
ICLR,2020,Functional Regularisation for  Continual Learning with Gaussian Processes,Michalis K. Titsias;Jonathan Schwarz;Alexander G. de G. Matthews;Razvan Pascanu;Yee Whye Teh,mtitsias@google.com;schwarzjn@google.com;alexmatthews@google.com;razp@google.com;ywteh@google.com,3;6;6,,Accept (Poster),0,5,0,yes,9/25/19,Google;Google;Google;Google;Google,Continual Learning;Gaussian Processes;Lifelong learning;Incremental Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Graph inference learning for semi-supervised classification,Chunyan Xu;Zhen Cui;Xiaobin Hong;Tong Zhang;Jian Yang;Wei Liu,cyx@njust.edu.cn;zhen.cui@njust.edu.cn;xbhong@njust.edu.cn;tong.zhang@njust.edu.cn;csjyang@njust.edu.cn;wl2223@columbia.edu,6;6;6,,Accept (Poster),0,0,0,yes,9/25/19,Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Nanjing University of Science and Technology;Columbia University,semi-supervised classification;graph inference learning,52;52;52;52;52;24,144;144;144;144;144;16,f;m,usa,usa,n
ICLR,2020,Input Complexity and Out-of-distribution Detection with Likelihood-based Generative Models,Joan Serr√†;David √Ålvarez;Vicen√ß G√≥mez;Olga Slizovskaia;Jos√© F. N√∫√±ez;Jordi Luque,joansj@gmail.com;davidalvarezdlt@gmail.com;vicen.gomez@upf.edu;oslizovskaia@gmail.com;jfn237@nyu.edu;jordi.luqueserrano@telefonica.com,6;3;3,,Accept (Poster),0,5,0,yes,9/25/19,Dolby Laboratories;;Universitat Pompeu Fabra;;New York University;Telefonica Research,OOD;generative models;likelihood,-1;-1;-1;-1;22;-1,-1;-1;-1;-1;29;-1,m;m,NAN,NAN,n
ICLR,2020,AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty,Dan Hendrycks*;Norman Mu*;Ekin Dogus Cubuk;Barret Zoph;Justin Gilmer;Balaji Lakshminarayanan,hendrycks@berkeley.edu;normanmu@google.com;cubuk@google.com;barretzoph@google.com;gilmer@google.com;balajiln@google.com,8;8;3,,Accept (Poster),0,14,0,yes,9/25/19,University of California Berkeley;Google;Google;Google;Google;Google,robustness;uncertainty,-1;-1;-1;-1;-1;-1,13;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learn to Explain Efficiently via Neural Logic Inductive Learning,Yuan Yang;Le Song,yyang754@gatech.edu;lsong@cc.gatech.edu,6;8;3,,Accept (Poster),0,14,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology,inductive logic programming;interpretability;attention,13;13,38;38,m;m,usa,usa,n
ICLR,2020,Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation,Ziyang Tang*;Yihao Feng*;Lihong Li;Dengyong Zhou;Qiang Liu,ztang@cs.utexas.edu;yihao@cs.utexas.edu;lihongli.cs@gmail.com;dennyzhou@google.com;lqiang@cs.utexas.edu,8;8;6,,Accept (Spotlight),0,10,0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin;Amazon;Google;University of Texas, Austin",off-policy evaluation;infinite horizon;doubly robust;reinforcement learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Towards Stable and Efficient Training of Verifiably Robust Neural Networks,Huan Zhang;Hongge Chen;Chaowei Xiao;Sven Gowal;Robert Stanforth;Bo Li;Duane Boning;Cho-Jui Hsieh,huan@huan-zhang.com;chenhg@mit.edu;xiaocw@umich.edu;sgowal@google.com;stanforth@google.com;lbo@illinois.edu;boning@mtl.mit.edu;chohsieh@cs.ucla.edu,6;3;8,,Accept (Poster),3,7,0,yes,9/25/19,"Carnegie Mellon University;Massachusetts Institute of Technology;University of Michigan;Google;Google;University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;University of California, Los Angeles",Robust Neural Networks;Verifiable Training;Certified Adversarial Defense,1;5;7;-1;-1;-1;5;-1,27;5;21;-1;-1;-1;5;17,m;m,usa,usa,n
ICLR,2020,Adversarial Policies: Attacking Deep Reinforcement Learning,Adam Gleave;Michael Dennis;Cody Wild;Neel Kant;Sergey Levine;Stuart Russell,gleave@berkeley.edu;michael_dennis@berkeley.edu;codywild@berkeley.edu;kantneel@berkeley.edu;svlevine@eecs.berkeley.edu;russell@cs.berkeley.edu,6;6;6,,Accept (Poster),0,8,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,deep RL;adversarial examples;security;multi-agent,-1;-1;-1;-1;-1;-1,13;13;13;13;13;13,m;m,usa,usa,n
ICLR,2020,Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation,Nitin Rathi;Gopalakrishnan Srinivasan;Priyadarshini Panda;Kaushik Roy,rathi2@purdue.edu;srinivg@purdue.edu;priya.panda@yale.edu;kaushik@purdue.edu,6;6;6,,Accept (Poster),0,4,0,yes,9/25/19,Purdue University;Purdue University;Yale University;Purdue University,spiking neural networks;ann-snn conversion;spike-based backpropagation;imagenet,24;24;73;24,88;88;8;88,m;m,usa,usa,n
ICLR,2020,Towards Verified Robustness under Text Deletion Interventions,Johannes Welbl;Po-Sen Huang;Robert Stanforth;Sven Gowal;Krishnamurthy (Dj) Dvijotham;Martin Szummer;Pushmeet Kohli,johannes.welbl.14@ucl.ac.uk;posenhuang@google.com;stanforth@google.com;sgowal@google.com;dvij@google.com;szummer@google.com;pushmeet@google.com,8;6;6;3,,Accept (Poster),0,4,0,yes,9/25/19,University College London;Google;Google;Google;Google;Google;Google,natural language processing;specification;verification;model undersensitivity;adversarial;interval bound propagation,52;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,N-BEATS: Neural basis expansion analysis for interpretable time series forecasting,Boris N. Oreshkin;Dmitri Carpov;Nicolas Chapados;Yoshua Bengio,boris@elementai.com;dmitri.carpov@elementai.com;chapados@elementai.com;yoshua.bengio@mila.quebec,6;8;6,,Accept (Poster),0,8,0,yes,9/25/19,Element AI;Element AI;Element AI;Mila,time series forecasting;deep learning,-1;-1;-1;143,-1;-1;-1;336,m;m,NAN,NAN,n
ICLR,2020,Improving Adversarial Robustness Requires Revisiting Misclassified Examples,Yisen Wang;Difan Zou;Jinfeng Yi;James Bailey;Xingjun Ma;Quanquan Gu,eewangyisen@gmail.com;knowzou@ucla.edu;jinfengyi.ustc@gmail.com;baileyj@unimelb.edu.au;xingjun.ma@unimelb.edu.au;qgu@cs.ucla.edu,6;6;8,,Accept (Poster),0,5,1,yes,9/25/19,"Peking University;University of California, Los Angeles;JD AI Research;The University of Melbourne;The University of Melbourne;University of California, Los Angeles",Robustness;Adversarial Defense;Adversarial Training,14;-1;-1;85;85;-1,24;17;-1;32;32;17,m;m,usa,usa,n
ICLR,2020,On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning,Jian Li;Xuanyuan Luo;Mingda Qiao,ljiian83@mail.tsinghua.edu.cn;luo-xy19@mails.tsinghua.edu.cn;mqiao@stanford.edu,6;6;6,,Accept (Poster),1,9,1,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Stanford University",learning theory;generalization;nonconvex learning;stochastic gradient descent;Langevin dynamics,4;4;5,23;23;4,f;m,usa,usa,y
ICLR,2020,SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition,Zhixuan Lin;Yi-Fu Wu;Skand Vishwanath Peri;Weihao Sun;Gautam Singh;Fei Deng;Jindong Jiang;Sungjin Ahn,zxlin@zju.edu.cn;yifu.wu@gmail.com;pvskand@protonmail.com;ws383@scarletmail.rutgers.edu;singh.gautam.iitg@gmail.com;fei.deng@rutgers.edu;jindong.jiang@rutgers.edu;sjn.ahn@gmail.com,6;6;6;3,,Accept (Poster),0,8,0,yes,9/25/19,Zhejiang University;Rutgers University;Oregon State University;Rutgers University;;Rutgers University;Rutgers University;Rutgers University,Generative models;Unsupervised scene representation;Object-oriented representation;spatial attention,39;30;79;30;-1;30;30;30,107;-1;373;-1;-1;-1;-1;-1,m;f,usa,usa,n
ICLR,2020,Learning from Unlabelled Videos Using Contrastive Predictive Neural 3D Mapping,Adam W. Harley;Shrinidhi K. Lakshmikanth;Fangyu Li;Xian Zhou;Hsiao-Yu Fish Tung;Katerina Fragkiadaki,aharley@cmu.edu;kowshika@cmu.edu;fangyul@cmu.edu;zhouxian@cmu.edu;htung@cs.cmu.edu;katef@cs.cmu.edu,6;6;6;3,,Accept (Poster),0,8,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,3D feature learning;unsupervised learning;inverse graphics;object discovery,1;1;1;1;1;1,27;27;27;27;27;27,m;f,usa,usa,n
ICLR,2020,CLN2INV: Learning Loop Invariants with Continuous Logic Networks,Gabriel Ryan;Justin Wong;Jianan Yao;Ronghui Gu;Suman Jana,gabe@cs.columbia.edu;justin.wong@columbia.edu;jy3022@columbia.edu;ronghui.gu@columbia.edu;suman@cs.columbia.edu,3;8,,Accept (Poster),0,6,1,yes,9/25/19,Columbia University;Columbia University;Columbia University;Columbia University;Columbia University,loop invariants;deep learning;logic learning,24;24;24;24;24,16;16;16;16;16,m;m,usa,usa,y
ICLR,2020,"Pay Attention to Features, Transfer Learn Faster CNNs",Kafeng Wang;Xitong Gao;Yiren Zhao;Xingjian Li;Dejing Dou;Cheng-Zhong Xu,kf.wang@siat.ac.cn;xt.gao@siat.ac.cn;yiren.zhao@cl.cam.ac.uk;lixingjian@baidu.com;doudejing@baidu.com;czxu@um.edu.mo,6;6;8,,Accept (Poster),0,3,0,yes,9/25/19,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chinese Academy of Sciences;University of Cambridge;Baidu;Baidu;University of Macau",transfer learning;pruning;faster CNNs,30;30;79;-1;-1;-1,-1;-1;3;-1;-1;307,m;m,europe,de,n
ICLR,2020,Sign-OPT: A Query-Efficient Hard-label Adversarial Attack,Minhao Cheng;Simranjit Singh;Patrick H. Chen;Pin-Yu Chen;Sijia Liu;Cho-Jui Hsieh,mhcheng@ucla.edu;simranjit@cs.ucla.edu;patrickchen@ucla.edu;pin-yu.chen@ibm.com;sijia.liu@ibm.com;chohsieh@cs.ucla.edu,6;3,,Accept (Poster),0,2,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;International Business Machines;International Business Machines;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1,17;17;17;-1;-1;17,m;m,usa,usa,y
ICLR,2020,GraphQA: Protein Model Quality Assessment using Graph Convolutional Network,Federico Baldassarre;David Men√©ndez Hurtado;Arne Elofsson;Hossein Azizpour,baldassarre.fe@gmail.com;david.menendez.hurtado@scilifelab.se;arne@bioinfo.se;azizpour@kth.se,3;6;3,,Reject,1,6,0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;Science for Life Laboratory;;KTH Royal Institute of Technology, Stockholm, Sweden",Protein Quality Assessment;Graph Networks;Representation Learning,194;-1;-1;194,222;-1;-1;222,m;m,NAN,NAN,n
ICLR,2020,Compositional Embeddings: Joint Perception and Comparison of Class Label Sets,Zeqian Li;Jacob Whitehill,zli14@wpi.edu;jrwhitehill@wpi.edu,6;6;3,,Reject,0,4,0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute,Embedding;One-shot Learning;Compositional Representation,143;143,628;628,m;m,usa,usa,n
ICLR,2020,Generating Multi-Sentence Abstractive Summaries of Interleaved Texts,Sanjeev Kumar Karn;Francine Chen;Yan-Ying Chen;Ulli Waltinger;Hinrich Sch√ºtze,skarn@cis.lmu.de;chen@fxpal.com;yanying@fxpal.com;ulli.waltinger@siemens.com;hinrich@hotmail.com,3;3;6,,Reject,0,4,0,yes,9/25/19,Institut f√ºr Informatik;FX Palo Alto Laboratory;FX Palo Alto Laboratory;Siemens Corporate Research;Centrum fuer Informations- und Sprachverarbeitung,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Generalizing Reinforcement Learning to Unseen Actions,Ayush Jain*;Andrew Szot*;Jincheng Zhou;Joseph J. Lim,ayushj@usc.edu;szot@usc.edu;jinchenz@usc.edu;limjj@usc.edu,6;6;3,,Reject,0,5,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;University of Southern California,reinforcement learning;unsupervised representation learning;generalization,36;36;36;36,62;62;62;62,m;m,usa,usa,n
ICLR,2020,Mixture-of-Experts Variational Autoencoder for clustering and generating from similarity-based representations,Andreas Kopf;Vincent Fortuin;Vignesh Ram Somnath;Manfred Claassen,akopf@ethz.ch;fortuin@inf.ethz.ch;vsomnath@student.ethz.ch;mclaassen@ethz.ch,3;6;6,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Variational Autoencoder;Clustering;Generative model,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,On Symmetry and Initialization for Neural Networks,Ido Nachum;Amir Yehudayoff,ido0808@gmail.com;amir.yehudayoff@gmail.com,3;3,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Technion,Neural Network Theory;Symmetry,-1;-1,-1;-1,m;m,asia,in,y
ICLR,2020,Training Interpretable Convolutional Neural Networks towards Class-specific Filters,Haoyu Liang;Zhihao Ouyang;Hang Su;Yuyuan Zeng;Zihao He;Shu-tao Xia;Jun Zhu;Bo Zhang,lianghy18@mails.tsinghua.edu.cn;oyzh18@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;zengyy19@mails.tsinghua.edu.cn;zihaoh@usc.edu;xiast@sz.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,6;6;3,,Reject,0,8,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Southern California;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",class-specific filters;interpretability;disentangled representation;filter ambiguity;gate,4;4;4;4;36;4;4;4,23;23;23;23;62;23;23;23,m;m,NAN,NAN,n
ICLR,2020,InfoCNF: Efficient Conditional Continuous Normalizing Flow Using Adaptive Solvers,Tan M. Nguyen;Animesh Garg;Richard G. Baraniuk;Anima Anandkumar,mn15@rice.edu;garg@cs.toronto.edu;richb@rice.edu;anima@caltech.edu,3;3;6;1,,Reject,0,10,0,yes,9/25/19,Rice University;University of Toronto;Rice University;California Institute of Technology,continuous normalizing flows;conditioning;adaptive solvers;gating networks,92;18;92;143,105;18;105;2,m;f,usa,usa,n
ICLR,2020,All SMILES Variational Autoencoder for Molecular Property Prediction and Optimization,Zaccary Alperstein;Artem Cherkasov;Jason Rolfe,zalperst@gmail.com;artc@interchange.ubc.ca;rolfe22@gmail.com,3;6;3,,Reject,2,7,0,yes,9/25/19,University of British Columbia;University of British Columbia;D-Wave Systems,generative modelling;variational autoencoder;chemistry;cheminformatics;chemoinformatics;molecular property optimization,-1;64;-1,-1;34;-1,m;m,NAN,NAN,n
ICLR,2020,On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints,Damien Teney;Ehsan Abbasnejad;Anton van den Hengel,damien.teney@adelaide.edu.au;ehsan.abbasnejad@adelaide.edu.au;anton.vandenhengel@adelaide.edu.au,6;3;3,,Reject,0,5,0,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,regularizers;vision;language;vqa;visual question answering,102;102;102,120;120;120,m;m,NAN,NAN,n
ICLR,2020,Learning Latent Representations for Inverse Dynamics using Generalized Experiences,Aditi Mavalankar;Sicun Gao,amavalan@eng.ucsd.edu;sicung@ucsd.edu,3;3;3,,Reject,0,4,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego",deep reinforcement learning;continuous control;inverse dynamics model,-1;-1,31;31,f;m,usa,usa,n
ICLR,2020,Differentiable Architecture Compression,Shashank Singh;Ashish Khetan;Zohar Karnin,sss1@andrew.cmu.edu;khetan2@illinois.edu;zkarnin@gmail.com,3;6;6,,Reject,0,3,0,yes,9/25/19,"Carnegie Mellon University;University of Illinois, Urbana Champaign;Amazon",,1;-1;-1,27;-1;-1,m;m,NAN,NAN,y
ICLR,2020,On Stochastic Sign Descent Methods,Mher Safaryan;Peter Richt√°rik,mher.safaryan@gmail.com;peter.richtarik@kaust.edu.sa,6;3;3,,Reject,0,4,0,yes,9/25/19,KAUST;KAUST,non-convex optimization;stochastic optimization;gradient compression,102;102,-1;-1,m;m,europe,gr,y
ICLR,2020,The Generalization-Stability Tradeoff in Neural Network Pruning,Brian R. Bartoldson;Ari S. Morcos;Adrian Barbu;Gordon Erlebacher,bbartoldson@fsu.edu;arimorcos@gmail.com;abarbu@stat.fsu.edu;gerlebacher@fsu.edu,3;1;1,,Reject,0,7,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Facebook;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,pruning;generalization;stability;dynamics;regularization,-1;-1;-1;-1,299;-1;299;299,m;m,NAN,NAN,n
ICLR,2020,Evaluations and Methods for Explanation through Robustness Analysis,Cheng-Yu Hsieh;Chih-Kuan Yeh;Xuanqing Liu;Pradeep Ravikumar;Seungyeon Kim;Sanjiv Kumar;Cho-Jui Hsieh,r05922048@ntu.edu.tw;cjyeh@cs.cmu.edu;xqliu@cs.ucla.edu;pradeepr@cs.cmu.edu;seungyeonk@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;3,,Reject,1,6,0,yes,9/28/20,"Nanyang Technological University;Carnegie Mellon University;University of California, Los Angeles;Carnegie Mellon University;Google;Google;University of California, Los Angeles",Interpretability;Explanations;Adversarial Robustness,43;1;-1;1;-1;-1;-1,49;27;17;27;-1;-1;17,m;m,usa,usa,n
ICLR,2020,Unsupervised Meta-Learning for Reinforcement Learning,Abhishek Gupta;Benjamin Eysenbach;Chelsea Finn;Sergey Levine,abhigupta@berkeley.edu;beysenba@cs.cmu.edu;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,3;1;3,,Reject,0,4,0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;University of California Berkeley;University of California Berkeley,Meta-Learning;Reinforcement Learning,-1;1;-1;-1,13;27;13;13,m;m,usa,usa,y
ICLR,2020,A General Upper Bound for Unsupervised Domain Adaptation,Dexuan Zhang;Tatsuya Harada,dexuan.zhang@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,1;3;6,,Reject,0,10,0,yes,9/25/19,The University of Tokyo;The University of Tokyo,unsupervised domain adaptation;upper bound;joint error;hypothesis space constraint;cross margin discrepancy,64;64,36;36,m;m,NAN,NAN,n
ICLR,2020,FoveaBox: Beyound Anchor-based Object Detection,Tao Kong;Fuchun Sun;Huaping Liu;Yuning Jiang;Lei Li;Jianbo Shi,taokongcn@gmail.com;fcsun@tsinghua.edu.cn;hpliu@tsinghua.edu.cn;jiangyuning@bytedance.com;lileilab@bytedance.com;jshi@seas.upenn.edu,6;6;3,,Reject,1,4,0,yes,9/25/19,"ByteDance;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;ByteDance;ByteDance;University of Pennsylvania",,-1;4;4;-1;-1;20,-1;23;23;-1;-1;11,m;m,usa,usa,n
ICLR,2020,CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting,Chaoyun Zhang;Marco Fiore;Iain Murray;Paul Patras,chaoyun.zhang@ed.ac.uk;marco.fiore@ieiit.cnr.it;i.murray@ed.ac.uk;paul.patras@ed.ac.uk,8;3;3,,Reject,0,7,0,yes,9/25/19,University of Edinburgh;;University of Edinburgh;University of Edinburgh,spatio-temporal forecasting;point cloud stream forecasting;recurrent neural network,36;-1;36;36,30;-1;30;30,m;m,europe,uk,n
ICLR,2020,Step Size Optimization,Gyoung S. Na;Dongmin Hyeon;Hwanjo Yu,ngs0726@gmail.com;dmhyeon@postech.ac.kr;hwanjoyu@postech.ac.kr,3;3,,Reject,1,4,0,yes,9/25/19,POSTECH;POSTECH;POSTECH,Deep Learning;Step Size Adaptation;Nonconvex Optimization,-1;118;118,-1;146;146,u;m,asia,kr,n
ICLR,2020,Neural Arithmetic Unit by reusing many small pre-trained networks,Ammar Ahmad;Oneeb Babar;Murtaza Taj,ammarahmad977@gmail.com;oneebalibabar@gmail.com;murtaza.taj@lums.edu.pk,1;1;1,,Reject,0,0,0,yes,9/25/19,Boston University;Lahore University of Management Sciences;Lahore University of Management Sciences,NALU;feed forward NN,-1;-1;-1,-1;932;932,u;m,NAN,NAN,n
ICLR,2020,OvA-INN: Continual Learning with Invertible Neural Networks,HOCQUET Guillaume;BICHLER Olivier;QUERLIOZ Damien,guillaume.hocquet@live.fr;olivier.bichler@cea.fr;damien.querlioz@c2n.upsaclay.fr,6;6;3,,Reject,0,5,0,yes,9/25/19,CEA;CEA; University of Paris-Sud,Deep Learning;Continual Learning;Invertible Neural Networks,-1;194;-1,-1;1027;-1,u;u,asia,in,n
ICLR,2020,Amortized Nesterov's Momentum: Robust and Lightweight  Momentum for Deep Learning,Kaiwen Zhou;Yanghua Jin;Qinghua Ding;James Cheng,kwzhou@cse.cuhk.edu.hk;jinyh@preferred.jp;qhding@cse.cuhk.edu.hk;jcheng@cse.cuhk.edu.hk,3;8;3;1,,Reject,0,9,0,yes,9/25/19,"Department of Computer Science and Engineering, The Chinese University of Hong Kong;Preferred Networks, Inc.;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong",momentum;nesterov;optimization;deep learning;neural networks,46;-1;46;46,35;-1;35;35,u;m,NAN,NAN,y
ICLR,2020,Improving Sample Efficiency in Model-Free Reinforcement Learning from Images,Denis Yarats;Amy Zhang;Ilya Kostrikov;Brandon Amos;Joelle Pineau;Rob Fergus,denisyarats@cs.nyu.edu;amyzhang@fb.com;ik1078@nyu.edu;brandon.amos.cs@gmail.com;jpineau@fb.com;robfergus@fb.com,6;3;6,,Reject,0,2,0,yes,9/25/19,New York University;Facebook;New York University;Facebook;Facebook;Facebook,reinforcement learning;model-free;off-policy;image-based reinforcement learning;continuous control,22;-1;22;-1;-1;-1,29;-1;29;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Curriculum Learning for Deep Generative Models with Clustering,Deli Zhao;Jiapeng Zhu;Zhenfang Guo;Bo Zhang,zhaodeli@gmail.com;jengzhu0@gmail.com;guozhenfang@pku.edu.cn;zhangbo@xiaomi.com,6;1,,Reject,0,3,0,yes,9/25/19,Alibaba Group;Hong Kong University of Science and Technology;Peking University;Xiaomi,curriculum learning;generative adversarial network,-1;-1;14;-1,-1;47;24;-1,m;m,NAN,NAN,y
ICLR,2020,Autoencoder-based Initialization for Recurrent Neural Networks with a Linear Memory,Antonio Carta;Alessandro Sperduti;Davide Bacciu,antonio.carta@di.unipi.it;sperduti@math.unipd.it;bacciu@di.unipi.it,3;1;3,,Reject,0,3,0,yes,9/25/19,University of Pisa;Universita' degli studi di Padova;University of Pisa,recurrent neural networks;autoencoders;orthogonal RNNs,248;-1;248,366;-1;366,m;m,europe,il,n
ICLR,2020,Universal Approximation with Deep Narrow Networks,Patrick Kidger;Terry Lyons,kidger@maths.ox.ac.uk;tlyons@maths.ox.ac.uk,6;8;3,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford,deep learning;universal approximation;deep narrow networks,46;46,1;1,m;m,europe,uk,y
ICLR,2020,Probing Emergent Semantics in Predictive Agents via Question Answering,Abhishek Das;Federico Carnevale;Hamza Merzic;Laura Rimell;Rosalia Schneider;Alden Hung;Josh Abramson;Arun Ahuja;Stephen Clark;Greg Wayne;Felix Hill,abhshkdz@gatech.edu;fedecarnev@google.com;hamzamerzic@google.com;laurarimell@google.com;rgschneider@google.com;aldenhung@google.com;jabramson@google.com;arahuja@google.com;clarkstephen@google.com;gregwayne@google.com;felixhill@google.com,3;8;6,,Reject,0,9,0,yes,9/25/19,Georgia Institute of Technology;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,question-answering;predictive models,13;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,38;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically Motivated Exploration,Jingwei Zhang;Niklas Wetzel;Nicolai Dorka;Joschka Boedecker;Wolfram Burgard,zhang@cs.uni-freiburg.de;wetzel@cs.uni-freiburg.de;dorka@informatik.uni-freiburg.de;jboedeck@cs.uni-freiburg.de;burgard@informatik.uni-freiburg.de,3;8;6;3,,Reject,0,8,0,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Reinforcement Learning;Exploration;Intrinsic Motivation;Sparse Rewards,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Stein Bridging: Enabling Mutual Reinforcement between Explicit and Implicit Generative Models,Qitian Wu;Rui Gao;Hongyuan Zha,echo740@sjtu.edu.cn;rui.gao@mccombs.utexas.edu;zha@cc.gatech.edu,3;1;3,,Reject,0,7,0,yes,9/25/19,"Shanghai Jiao Tong University;University of Texas, Austin;Georgia Institute of Technology",generative models;generative adversarial networks;energy models,30;-1;13,157;-1;38,m;m,usa,usa,y
ICLR,2020,New Loss Functions for Fast Maximum Inner Product Search,Ruiqi Guo;Quan Geng;David Simcha;Felix Chern;Phil Sun;Sanjiv Kumar,guorq@google.com;qgeng@google.com;dsimcha@google.com;fchern@google.com;sunphil@google.com;sanjivk@google.com,3;3;6,,Reject,0,3,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,End-to-end named entity recognition and relation extraction using pre-trained language models,John Giorgi;Xindi Wang;Nicola Sahar;Won Young Shin;Gary Bader;Bo Wang,john.giorgi@utoronto.ca;xindi.wang@uhnresearch.ca;nicola.sahar@mail.utoronto.ca;wonyoung.shin@mail.utoronto.ca;gary.bader@utoronto.ca;bowang@vectorinstitute.ai,6;3;1,,Reject,1,4,1,yes,9/25/19,Toronto University;University Health Network;Toronto University;Toronto University;Toronto University;Vector Institute,named entity recognition;relation extraction;information extraction;information retrival;transfer learning;multi-task learning;BERT;transformers;language models,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,AdaGAN: Adaptive GAN for Many-to-Many Non-Parallel Voice Conversion,Maitreya Patel;Mirali Purohit;Mihir Parmar;Nirmesh J. Shah;Hemant A. Patil,maitreya_patel@daiict.ac.in;purohit_mirali@daiict.ac.in;mihirparmar@asu.edu;nirmesh88_shah@daiict.ac.in;hemant_patil@daiict.ac.in,1;1;6,,Reject,1,3,0,yes,9/25/19,"Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar;Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar;SUN YAT-SEN UNIVERSITY;Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar;Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar",Voice Conversion;Deep Learning;Non parallel;GAN;AdaGAN;AdaIN,-1;-1;-1;-1;-1,-1;-1;299;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Goal-Conditioned Video Prediction,Oleh Rybkin;Karl Pertsch;Frederik Ebert;Dinesh Jayaraman;Chelsea Finn;Sergey Levine,oleh@seas.upenn.edu;pertsch@usc.edu;febert@berkeley.edu;dineshjayaraman@berkeley.edu;cbfinn@cs.stanford.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,4,0,yes,9/25/19,University of Pennsylvania;University of Southern California;University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,predictive models;video prediction;latent variable models,20;36;-1;-1;5;-1,11;62;13;13;4;13,m;m,usa,usa,n
ICLR,2020,wMAN: WEAKLY-SUPERVISED MOMENT ALIGNMENT NETWORK FOR TEXT-BASED VIDEO SEGMENT RETRIEVAL,Reuben Tan;Huijuan Xu;Kate Saenko;Bryan A. Plummer,rxtan@bu.edu;huijuan@berkeley.edu;saenko@bu.edu;bplumme2@illinois.edu,6;6;3;3,,Reject,0,5,0,yes,9/25/19,"Boston University;University of California Berkeley;Boston University;University of Illinois, Urbana Champaign",vision;language;video moment retrieval,79;-1;79;-1,61;13;61;-1,m;m,usa,usa,n
ICLR,2020,Data augmentation instead of explicit regularization,Alex Hernandez-Garcia;Peter K√∂nig,alexhg15@gmail.com;pkoenig@uos.de,3;1;3,,Reject,0,9,0,yes,9/25/19,University of Montreal;University of Osnabr√ºck,data augmentation;implicit regularization;explicit regularization;object recognition;convolutional neural networks,-1;316,-1;-1,m;m,europe,de,n
ICLR,2020,Implicit Œª-Jeffreys Autoencoders: Taking the Best of Both Worlds,Aibek Alanov;Max Kochurov;Artem Sobolev;Daniil Yashkov;Dmitry Vetrov,alanov.aibek@gmail.com;maxim.v.kochurov@gmail.com;asobolev@bayesgroup.ru;daniil.yashkov@phystech.edu;vetrovd@yandex.ru,3;3;3,,Reject,0,5,0,yes,9/25/19,Higher School of Economics;;;Moscow Institute of Physics and Technology;Higher School of Economics,Variational Inference;Generative Adversarial Networks,-1;-1;-1;-1;-1,-1;-1;-1;234;-1,m;m,NAN,NAN,n
ICLR,2020,LOSSLESS SINGLE IMAGE SUPER RESOLUTION FROM LOW-QUALITY JPG IMAGES,Yong Shi;Biao Li;Bo Wang;Zhiquan Qi;Jiabin Liu;Fan Meng,yshi@unomaha.edu;libiao17@mails.ucas.ac.cn;wangbo@uibe.edu.cn;qizhiquan@foxmail.com;liujiabin008@126.com;mengfan@cufe.edu.cn,3;6;1,,Reject,0,1,0,yes,9/25/19,"University of Nebraska, Omaha;Chinese Academy of Sciences;University of Science and Technology of China;University of Science and Technology of China;126;University of Science and Technology of China",Super Resolution;Low-quality JPG;Recovering details,194;30;-1;-1;-1;-1,-1;-1;80;80;-1;80,m;m,NAN,NAN,n
ICLR,2020,Improving Batch Normalization with Skewness Reduction for Deep Neural Networks,Pak Lun Kevin Ding;Sarah Martin;Baoxin Li,kevinding@asu.edu;samart44@asu.edu;baoxin.li@asu.edu,3;3;3,,Reject,0,0,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Batch Normalization;Deep Learning,-1;-1;-1,299;299;299,m;m,NAN,NAN,n
ICLR,2020,Cascade Style Transfer,Zhizhong Wang;Lei Zhao;Qihang Mo;Sihuan Lin;Zhiwen Zuo;Wei Xing;Dongming Lu,endywon@zju.edu.cn;cszhl@zju.edu.cn;moqihang@zju.edu.cn;linsh@zju.edu.cn;zzwcs@zju.edu.cn;wxing@zju.edu.cn;ldm@zju.edu.cn,1;1;1,,Reject,0,0,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,style transfer;cascade;quality;flexibility;domain-independent;serial;parallel,39;39;39;39;39;39;39,107;107;107;107;107;107;107,u;u,asia,cn,n
ICLR,2020,Recurrent Hierarchical Topic-Guided Neural Language Models,Dandan Guo;Bo Chen;Ruiying Lu;Mingyuan Zhou,gdd_xidian@126.com;bchen@mail.xidian.edu.cn;ruiyinglu_xidian@163.com;mingyuan.zhou@mccombs.utexas.edu,1;1;8;8;8,,Reject,0,8,4,yes,9/25/19,"126;Xidian University;Xidian University;University of Texas, Austin",Bayesian deep learning;recurrent gamma belief net;larger-context language model;variational inference;sentence generation;paragraph generation,-1;-1;-1;-1,-1;919;919;-1,u;m,usa,usa,n
ICLR,2020,The Frechet Distance of training and test distribution predicts the generalization gap,Julian Zilly;Hannes Zilly;Oliver Richter;Roger Wattenhofer;Andrea Censi;Emilio Frazzoli,jzilly@ethz.ch;hzilly@ethz.ch;richtero@ethz.ch;wattenhofer@ethz.ch;acensi@ethz.ch;emilio.frazzoli@idsc.mavt.ethz.ch,3;3;3,,Reject,0,0,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Generalization;Transfer learning;Frechet distance;Optimal transport;Domain adaptation;Distribution shift;Invariance,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Objective Mismatch in Model-based Reinforcement Learning,Nathan Lambert;Brandon Amos;Omry Yadan;Roberto Calandra,nol@berkeley.edu;brandon.amos.cs@gmail.com;omry@fb.com;rcalandra@fb.com,3;3;3,,Reject,0,4,0,yes,9/25/19,University of California Berkeley;Facebook;Facebook;Facebook,Model-based Reinforcement learning;dynamics model;reinforcement learning,-1;-1;-1;-1,13;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Explainable Models Using Attribution Priors,Gabriel Erion;Joseph D. Janizek;Pascal Sturmfels;Scott M. Lundberg;Su-In Lee,erion@cs.washington.edu;jjanizek@cs.washington.edu;psturm@cs.washington.edu;slund1@cs.washington.edu;suinlee@cs.washington.edu,8;3;1,,Reject,0,6,0,yes,9/25/19,University of Washington;University of Washington;University of Washington;University of Washington;University of Washington,Deep Learning;Interpretability;Attributions;Explanations;Biology;Health;Computational Biology,11;11;11;11;11,26;26;26;26;26,m;f,usa,usa,n
ICLR,2020,Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models,Anand Ramakrishnan;Warren B. Jackson;Kent Evans,aramakrishnan@wpi.edu;jackson@parc.com;kent.evans@parc.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Worcester Polytechnic Institute;Palo Alto Research Center (Xerox PARC);Palo Alto Research Center (Xerox PARC),Composition;extrapolation;boosting;autocorrelation;systematic errors,143;-1;-1,628;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Semi-supervised 3D Face Reconstruction with Nonlinear Disentangled Representations,Zhongpai Gao;Juyong Zhang;Yudong Guo;Chao Ma;Guangtao Zhai;Xiaokang Yang,gaozhongpai@sjtu.edu.cn;juyong@ustc.edu.cn;gyd2011@mail.ustc.edu.cn;chaoma@sjtu.edu.cn;zhaiguangtao@sjtu.edu.cn;xkyang@sjtu.edu.cn,3;1;3,,Reject,0,0,0,yes,9/25/19,Shanghai Jiao Tong University;University of Science and Technology of China;University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,3D face reconstruction;semi-supervised learning;disentangled representation;inverse rendering;graph convolutional networks,30;-1;-1;30;30;30,157;80;80;157;157;157,m;m,asia,cn,n
ICLR,2020,Efficient Exploration via State Marginal Matching,Lisa Lee;Benjain Eysenbach;Emilio Parisotto;Erix Xing;Sergey Levine;Ruslan Salakhutdinov,lslee@cs.cmu.edu;beysenba@cs.cmu.edu;eparisot@cs.cmu.edu;epxing@cs.cmu.edu;svlevine@eecs.berkeley.edu;rsalakhu@cs.cmu.edu,3;3;3,,Reject,0,6,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;University of California Berkeley;Carnegie Mellon University,reinforcement learning;exploration;distribution matching;robotics,1;1;1;1;-1;1,27;27;27;27;13;27,f;m,usa,usa,y
ICLR,2020,Adversarial Filters of Dataset Biases,Ronan Le Bras;Swabha Swayamdipta;Chandra Bhagavatula;Rowan Zellers;Matthew Peters;Ashish Sabharwal;Yejin Choi,ronanlb@allenai.org;swabhas@allenai.org;chandrab@allenai.org;rowanz@cs.washington.edu;matthewp@allenai.org;ashishs@allenai.org;yejinc@allenai.org,6;6;6,,Reject,0,4,1,yes,9/25/19,Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;University of Washington;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence;Allen Institute for Artificial Intelligence,,-1;-1;-1;11;-1;-1;-1,-1;-1;-1;26;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Insights on Visual Representations for Embodied Navigation Tasks,Erik Wijmans;Julian Straub;Irfan Essa;Dhruv Batra;Judy Hoffman;Ari Morcos,etw@gatech.edu;julian.straub@oculus.com;irfan@gatech.edu;dbatra@gatech.edu;judy@gatech.edu;arimorcos@gmail.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Georgia Institute of Technology;Oculus;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Facebook,,13;-1;13;13;13;-1,38;-1;38;38;38;-1,m;m,NAN,NAN,n
ICLR,2020,Crafting Data-free Universal Adversaries with Dilate Loss,Deepak Babu Sam;ABINAYA K;Sudharsan K A;Venkatesh Babu RADHAKRISHNAN,deepaksam@iisc.ac.in;abinayak@iisc.ac.in;sudharsanka16@gmail.com;venky@iisc.ac.in,8;3;6;3,,Reject,0,4,0,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;;Indian Institute of Science,,-1;-1;-1;-1,301;301;-1;301,m;u,NAN,NAN,y
ICLR,2020,Stochastic Gradient Descent with Biased but Consistent Gradient Estimators,Jie Chen;Ronny Luss,chenjie@us.ibm.com;rluss@us.ibm.com,6;1;3;3,,Reject,0,15,0,yes,9/25/19,International Business Machines;International Business Machines,Stochastic optimization;biased gradient estimator;graph convolutional networks,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Wasserstein Robust Reinforcement Learning,Mohammed Amin Abdullah;Hang Ren;Haitham Bou-Ammar;Vladimir Milenkovic;Rui Luo;Mingtian Zhang;Jun Wang,mohammed.abdullah@huawei.com;hang.ren1@huawei.com;haitham.ammar@huawei.com;vladimir.milenkovic@huawei.com;ruiluo@huawei.com;w.j@huawei.com,3;3;3,,Reject,0,5,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Reinforcement Learning;Robustness;Wasserstein distance,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,A Training Scheme for the Uncertain Neuromorphic Computing Chips,Qingtian Zhang;Bin Gao;Huaqiang Wu,zhangqt0103@mail.tsinghua.edu.cn;gaob1@tsinghua.edu.cn;wuhq@tsinghua.edu.cn,1;6;1,,Reject,0,2,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",deep learning;neuromorphic computing;uncertainty;training,4;4;4,23;23;23,u;m,NAN,NAN,n
ICLR,2020,A Stochastic Trust Region Method for Non-convex Minimization,Zebang Shen;Pan Zhou;Cong Fang;Jiahao Xie;Alejandro Ribeiro,shenzebang@zju.edu.cn;pzhou@u.nus.edu;fangcong@pku.edu.cn;xiejh@zju.edu.cn;aribeiro@seas.upenn.edu,3;6;8;3,,Reject,0,7,0,yes,9/25/19,Zhejiang University;National University of Singapore;Peking University;Zhejiang University;University of Pennsylvania,,39;17;14;39;20,107;25;24;107;11,m;m,usa,usa,y
ICLR,2020,MoET: Interpretable and Verifiable Reinforcement Learning via Mixture of Expert Trees,Marko Vasic;Andrija Petrovic;Kaiyuan Wang;Mladen Nikolic;Rishabh Singh;Sarfraz Khurshid,vasic@utexas.edu;aapetrovic@mas.bg.ac.rs;kaiyuanw@google.com;nikolic@matf.bg.ac.rs;rising@google.com;khurshid@ece.utexas.edu,3;6;6,,Reject,0,7,0,yes,9/25/19,"University of Texas, Austin;University of Belgrade - Faculty of Organizational Sciences;Google;University of Belgrade - Faculty of Organizational Sciences;Google;University of Texas, Austin",explainable machine learning;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Deceptive Opponent Modeling with Proactive Network Interdiction for Stochastic Goal Recognition Control,Junren Luo;Wei Gao;Zhiyong Liao;Weilin Yuan;Wanpeng Zhang;Shaofei Chen,luojunren17@nudt.edu.cn;gaowei14@nudt.edu.cn,1;1;1,,Reject,0,0,0,yes,9/25/19,National University of Defense Technology;National University of Defense Technology,,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Regularization Matters in Policy Optimization,Zhuang Liu;Xuanlin Li;Bingyi Kang;Trevor Darrell,zhuangl@berkeley.edu;xuanlinli17@berkeley.edu;kang@u.nus.edu;trevor@eecs.berkeley.edu,3;3;6,,Reject,0,12,1,yes,9/25/19,University of California Berkeley;University of California Berkeley;National University of Singapore;University of California Berkeley,Regularization;Policy Optimization;Reinforcement Learning,-1;-1;17;-1,13;13;25;13,m;m,usa,usa,n
ICLR,2020,Sentence embedding with contrastive multi-views learning,Antoine Simoulin,antoine.simoulin@gmail.com,1;1;3,,Reject,0,0,0,yes,9/25/19,0,contrastive;multi-views;linguistic;embedding,,,m;u,NAN,NAN,n
ICLR,2020,Robust Domain Randomization for Reinforcement Learning,Reda Bahi Slaoui;William R. Clements;Jakob N. Foerster;S√©bastien Toth,reda.bahi.slaoui@gmail.com;william.clements@unchartech.com;jakobfoerster@gmail.com;sebastien.toth@unchartech.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Ecole Normale Superieure;Uncharted Technologies;;Uncharted Technologies,reinforcement learning;domain randomization;domain adaptation,-1;-1;-1;-1,-1;-1;-1;-1,m;u,NAN,NAN,y
ICLR,2020,Regularizing Trajectories to Mitigate Catastrophic Forgetting,Paul Michel;Elisabeth Salesky;Graham Neubig,pmichel1@cs.cmu.edu;esalesky@gmail.com;gneubig@cs.cmu.edu,6;1;3,,Reject,0,6,0,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University,Continual Learning;Regularization;Adaptation;Natural Gradient,1;-1;1,27;-1;27,m;m,usa,usa,n
ICLR,2020,Coloring graph neural networks for node disambiguation,George Dasoulas;Ludovic Dos Santos;Kevin Scaman;Aladin Virmaux,george.dasoulas1@gmail.com;kevin.scaman@gmail.com;ludovic.dos.santos@huawei.com;aladin.virmaux@huawei.com,6;1;3,,Reject,0,5,0,yes,9/25/19,Ecole polytechnique;INRIA;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Graph neural networks;separability;node disambiguation;universal approximation;representation learning,-1;-1;-1;-1,93;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Undersensitivity in Neural Reading Comprehension,Johannes Welbl;Pasquale Minervini;Max Bartolo;Pontus Stenetorp;Sebastian Riedel,johannes.welbl.14@ucl.ac.uk;p.minervini@gmail.com;maxbartolo@gmail.com;pontus.stenetorp@gmail.com;s.riedel@ucl.ac.uk,6;3;6,,Reject,0,3,0,yes,9/25/19,University College London;University College London;University College London;University College London;University College London,reading comprehension;undersensitivity;adversarial questions;adversarial training;robustness;biased data setting,52;52;52;52;52,-1;-1;-1;-1;-1,m;m,europe,uk,n
ICLR,2020,RotationOut as a Regularization Method for Neural Network,Kai Hu;Barnabas Poczos,kaihu@cmu.edu;bapoczos@cs.cmu.edu,3;3;3,,Reject,0,6,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,Neural Network;Regularization,1;1,27;27,m;m,usa,usa,y
ICLR,2020,Meta-Learning with Network Pruning for Overfitting Reduction,Hongduan Tian;Bo Liu;Xiao-Tong Yuan;Qingshan Liu,hongduan_tian@nuist.edu.cn;kfliubo@gmail.com;xtyuan1980@gmail.com;qsliu@nuist.edu.cn,3;3;3,,Reject,0,5,0,yes,9/25/19,University of Science and Technology of China;Rutgers University;University of Science and Technology of China;University of Science and Technology of China,Meta-Learning;Few-shot Learning;Network Pruning;Generalization Analysis,-1;30;-1;-1,80;-1;80;80,m;m,NAN,NAN,y
ICLR,2020,An implicit function learning approach for parametric modal regression,Yangchen Pan;Martha White;Amir-massoud Farahmand,pan6@ualberta.ca;whitem@ualberta.ca;farahmand@vectorinstitute.ai,1;3;6,,Reject,0,3,0,yes,9/25/19,University of Alberta;University of Alberta;Vector Institute,regression;modal regression;implicit function theorem;multivalue function,102;102;-1,136;136;-1,u;m,NAN,NAN,y
ICLR,2020,On the Evaluation of Conditional GANs,Terrance DeVries;Adriana Romero;Luis Pineda;Graham W. Taylor;Michal Drozdzal,terrance@uoguelph.ca;adrianars@fb.com;lep@fb.com;gwtaylor@uoguelph.ca;mdrozdzal@fb.com,3;1;3,,Reject,0,5,0,yes,9/25/19,University of Guelph;Facebook;Facebook;University of Guelph;Facebook,FJD;Frechet Joint Distance;GAN;cGAN;generative adversarial network;conditional;evaluation;metric;FID;Frechet Inception Distance,248;-1;-1;248;-1,558;-1;-1;558;-1,m;m,NAN,NAN,n
ICLR,2020,CZ-GEM:  A  FRAMEWORK  FOR DISENTANGLED REPRESENTATION LEARNING,Akash Srivastava;Yamini Bansal;Yukun Ding;Bernhard Egger;Prasanna Sattigeri;Josh Tenenbaum;David D. Cox;Dan Gutfreund,akash.srivastava@me.com;ybansal@g.harvard.edu;yding5@nd.edu;egger@mit.edu;psattig@us.ibm.com;jbt@mit.edu;david.d.cox@ibm.com;dgutfre@us.ibm.com,1;1;3,,Reject,0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Harvard University;University of Notre Dame;Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology;International Business Machines;International Business Machines,disentangled representation learning;gan;generative model;simulator,5;52;118;5;-1;5;-1;-1,5;7;157;5;-1;5;-1;-1,m;m,NAN,NAN,n
ICLR,2020,On Weight-Sharing and Bilevel Optimization in Architecture Search,Mikhail Khodak;Liam Li;Maria-Florina Balcan;Ameet Talwalkar,khodak@cmu.edu;me@liamcli.com;ninamf@cs.cmu.edu;talwalkar@cmu.edu,3;3,,Reject,0,2,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,neural architecture search;weight-sharing;bilevel optimization;non-convex optimization;hyperparameter optimization;model selection,1;1;1;1,27;27;27;27,m;m,usa,usa,y
ICLR,2020,Are there any 'object detectors' in the hidden layers of CNNs trained to identify objects or scenes?,Ella M. Gale;Nicholas Martin;Ryan Blything;Anh Nguyen;Jeffrey S. Bowers,ella.gale@bristol.ac.uk;nm13850@bristol.ac.uk;ryan.blything@bristol.ac.uk;anhnguyen@auburn.edu;j.bowers@bristol.ac.uk,3;3;8,,Reject,0,3,0,yes,9/25/19,University of Bristol;University of Bristol;University of Bristol;Auburn University;University of Bristol,neural networks;localist coding;selectivity;object detectors;CCMAS;CNNs;activation maximisation;information representation;network dissection;interpretabillity;signal detection,118;118;118;445;118,87;87;87;651;87,f;m,europe,uk,n
ICLR,2020,Dimensional Reweighting Graph Convolution Networks,Xu Zou;Qiuye Jia;Jianwei Zhang;Chang Zhou;Zijun Yao;Hongxia Yang;Jie Tang,zoux18@mails.tsinghua.edu.cn;jqy@stanford.edu;zhangjianwei.zjw@alibaba-inc.com;ericzhou.zc@alibaba-inc.com;yaozijun@bupt.edu.cn;yang.yhx@alibaba-inc.com;jietang@tsinghua.edu.cn,3;6;3,,Reject,0,7,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Stanford University;Alibaba Group;Alibaba Group;Beijing University of Post and Telecommunication;Alibaba Group;Tsinghua University, Tsinghua University",graph convolutional networks;representation learning;mean field theory;variance reduction;node classification,4;5;-1;-1;-1;-1;4,23;4;-1;-1;-1;-1;23,m;m,NAN,NAN,y
ICLR,2020,Leveraging inductive bias of neural networks for learning without explicit human annotations,Fatih Furkan Yilmaz;Reinhard Heckel,fy11@rice.edu;rh43@rice.edu,6;3,,Reject,0,2,0,yes,9/25/19,Rice University;Rice University,dataset construction;deep learning;candidate examples,92;92,105;105,m;m,australasia,au,n
ICLR,2020,XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and Question Answering,Jasdeep Singh;Bryan McCann;Nitish Shirish Keskar;Caiming Xiong;Richard Socher,jasdeep@cs.stanford.edu;bmccann@salesforce.com;nkeskar@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,1;8;3,,Reject,0,0,0,yes,9/25/19,Stanford University;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,cross-lingual;transfer learning;BERT,5;-1;-1;-1;-1,4;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Ergodic Inference: Accelerate Convergence by Optimisation,Yichuan Zhang;Jos√© Miguel Hern√°ndez-Lobato,yichuan.zhang@eng.cam.ac.uk;jmh233@cam.ac.uk,3;8;3,,Reject,0,3,2,yes,9/25/19,University of Cambridge;University of Cambridge,MCMC;variational inference;statistical inference,79;79,3;3,m;m,europe,uk,n
ICLR,2020,Synthetic vs Real: Deep Learning on Controlled Noise,Lu Jiang;Di Huang;Weilong Yang,lujiang@google.com;dihuang@google.com;weilongyang@google.com,3;6;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google,controlled experiments;robust deep learning;corrupted label;real-world noisy data,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Layerwise Learning Rates for Object Features in Unsupervised and Supervised Neural Networks And Consequent Predictions for the Infant Visual System,Rhodri Cusack;Cliona O'Doherty;Anna Birbeck;Anna Truzzi,cusackrh@tcd.ie;odoherc1@tcd.ie;birbecka@tcd.ie;truzzia@tcd.ie,3;3;3,,Reject,0,5,0,yes,9/25/19,"Trinity College, Dublin;Trinity College, Dublin;Trinity College, Dublin;Trinity College, Dublin",deep learning;unsupervised;supervised;infant learning;age of acquisition;DeepCluster;CORnet;AlexNet,-1;-1;-1;-1,164;164;164;164,m;f,NAN,NAN,n
ICLR,2020,Non-Sequential Melody Generation,Mitchell Billard;Robert Bishop;Moustafa Elsisy;Laura Graves;Antonina Kolokolova;Vineel Nagisetty;Zachary Northcott;Heather Patey,mlb238@mun.ca;r.bishop@mun.ca;mmatelsisy@mun.ca;cmgraves@mun.ca;kol@mun.ca;vnagisetty@mun.ca;zmnorthcott@mun.ca;hpatey@gmail.com,1;3;1,,Reject,0,3,0,yes,9/25/19,Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;Memorial University of Newfoundland;,melody generation;DCGAN;dilated convolutions,445;445;445;445;445;445;445;-1,557;557;557;557;557;557;557;-1,m;u,asia,in,n
ICLR,2020,A Dynamic Approach to Accelerate Deep Learning Training,John Osorio;Adri√† Armejach;Eric Petit;Marc Casas,john.osorio@bsc.es;adria.armejach@bsc.es;eric.petit@intel.com;marc.casas@bsc.es,3;3;3,,Reject,0,4,0,yes,9/25/19,Barcelona Supercomputing Center;Barcelona Supercomputing Center;Intel;Barcelona Supercomputing Center,reduced precision;bfloat16;CNN;DNN;dynamic precision;mixed precision,445;445;-1;445,-1;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,Emergence of Compositional Language with Deep Generational Transmission,Michael Cogswell;Jiasen Lu;Stefan Lee;Devi Parikh;Dhruv Batra,cogswell@gatech.edu;jiasenlu@gatech.edu;steflee@gatech.edu;parikh@gatech.edu;dbatra@gatech.edu,6;1;6,,Reject,0,6,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Cultural Evolution;Deep Learning;Language Emergence,13;13;13;13;13,38;38;38;38;38,m;m,usa,usa,n
ICLR,2020,AutoGrow: Automatic Layer Growing in Deep Convolutional Networks,Wei Wen;Feng Yan;Hai Li,wei.wen@duke.edu;fyan@unr.edu;hai.li@duke.edu,3;3;3,,Reject,0,3,1,yes,9/25/19,"Duke University;University of Nevada, Reno;Duke University",Growing;depth;neural networks;automation,46;248;46,20;-1;20,m;f,europe,se,n
ICLR,2020,Model-Agnostic Feature Selection with Additional Mutual Information,Mukund Sudarshan;Aahlad Manas Puli;Lakshmi Subramanian;Sriram Sankararaman;Rajesh Ranganath,ms7490@nyu.edu;apm470@nyu.edu;lakshmi@cs.nyu.edu;sriram@cs.ucla.edu;rajeshr@cims.nyu.edu,6;3;3,,Reject,0,5,0,yes,9/25/19,"New York University;New York University;New York University;University of California, Los Angeles;New York University",feature selection;interpretability;randomization;fdr control;p-values,22;22;22;-1;22,29;29;29;17;29,m;m,usa,usa,y
ICLR,2020,Certifying Neural Network Audio Classifiers,Wonryong Ryou;Mislav Balunovic;Gagandeep Singh;Martin Vechev,wryou@student.ethz.ch;bmislav@student.ethz.ch;gsingh@inf.ethz.ch;martin.vechev@inf.ethz.ch,6;1;3,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Adversarial Examples;Audio Classifier;Speech Recognition;Certified Robustness;Deep Learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Wasserstein-Bounded Generative Adversarial Networks,Peng Zhou;Bingbing Ni;Lingxi Xie;Xiaopeng Zhang;Hang Wang;Cong Geng;Qi Tian,zhoupengcv@sjtu.edu.cn;nibingbing@sjtu.edu.cn;198808xc@gmail.com;zxphistory@gmail.com;wang--hang@sjtu.edu.cn;gengcong@sjtu.edu.cn;tian.qi1@huawei.com,1;3;6,,Reject,0,0,0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;;;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Huawei Technologies Ltd.,GAN;WGAN;GENERATIVE ADVERSARIAL NETWORKS,30;30;-1;-1;30;30;-1,157;157;-1;-1;157;157;-1,m;m,NAN,NAN,y
ICLR,2020,An Explicitly Relational Neural Network Architecture,Murray Shanahan;Kyriacos Nikiforou;Antonia Creswell;Christos Kaplanis;David Barrett;Marta Garnelo,mshanahan@google.com;knikiforou@google.com;tonicreswell@google.com;christos.kaplanis14@imperial.ac.uk;barrettdavid@google.com;garnelo@google.com,6;6;6,,Reject,0,4,1,yes,9/25/19,Google;Google;Google;Imperial College London;Google;Google,relational representation,-1;-1;-1;52;-1;-1,-1;-1;-1;10;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Do Deep Neural Networks for Segmentation Understand Insideness?,Kimberly M Villalobos;Vilim Stih;Amineh Ahmadinejad;Jamell Dozier;Andrew Francl;Frederico Azevedo;Tomotake Sasaki;Xavier Boix,kimvc@mit.edu;vilim@neuro.mpg.de;amineh@mit.edu;jamell@mit.edu;francl@mit.edu;fazevedo@mit.edu;tomotake.sasaki@fujitsu.com;xboix@mit.edu,6;6;3,,Reject,0,7,1,yes,9/25/19,Massachusetts Institute of Technology;Max-Planck Institute;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Fujitsu Laboratories Ltd.;Massachusetts Institute of Technology,Image Segmentation;Deep Networks for Spatial Relationships;Visual Routines;Recurrent Neural Networks,5;-1;5;5;5;5;-1;5,5;-1;5;5;5;5;-1;5,f;m,usa,usa,y
ICLR,2020,Split LBI for Deep Learning: Structural Sparsity via Differential Inclusion Paths,Yanwei Fu;Chen Liu;Donghao Li;Xinwei Sun;Jinshan ZENG;Yuan Yao,yanweifu@fudan.edu.cn;corwinliu9669@gmail.com;donghao.li@connect.ust.hk;xinsun@microsoft.com;jsh.zeng@gmail.com;yuany@ust.hk,3;8;6,,Reject,0,7,0,yes,9/25/19,Fudan University;;The Hong Kong University of Science and Technology;Microsoft;Australian National University;The Hong Kong University of Science and Technology,,73;-1;-1;-1;102;-1,109;-1;47;-1;50;47,m;m,NAN,NAN,y
ICLR,2020,Contextual Text Style Transfer,Yu Cheng;Zhe Gan;Yizhe Zhang;Oussama Elachqar;Dianqi Li;Jingjing Liu,yu.cheng@microsoft.com;zhe.gan@microsoft.com;yizhe.zhang@microsoft.com;ouelachq@microsoft.com;dianqili@uw.edu;jingjl@microsoft.com,3;3;6,,Reject,0,0,0,yes,9/25/19,"Microsoft;Microsoft;Microsoft;Microsoft;University of Washington, Seattle;Microsoft",,-1;-1;-1;-1;11;-1,-1;-1;-1;-1;26;-1,m;f,NAN,NAN,n
ICLR,2020,FLAT MANIFOLD VAES,Nutan Chen;Alexej Klushyn;Francesco Ferroni;Justin Bayer;Patrick van der Smagt,nutan.chen@gmail.com;a.klushyn@gmail.com;francescoferroni1@gmail.com;bayer.justin@googlemail.com;smagt@argmax.ai,1;6;6,,Reject,0,11,0,yes,9/25/19,"Machine Learning Research Lab, Volkswagen Group;Technical University Munich;Argo AI;Machine Learning Research Lab, Volkswagen Group;Volkswagen Group, Machine Learning Research Lab (MLRL)",,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,An Information Theoretic Approach to Distributed Representation Learning,Abdellatif Zaidi;Inaki Estella Aguerri,abdellatif.zaidi@u-pem.fr;inaki.estella@huawei.com,3;3;8;6,,Reject,0,0,0,yes,9/25/19,Universit√© Paris-Est;Huawei Technologies Ltd.,Information Bottleneck;Distributed Learning,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,LIA: Latently Invertible Autoencoder with Adversarial Learning,Jiapeng Zhu;Deli Zhao;Bolei Zhou;Bo Zhang,jengzhu0@gmail.com;zhaodeli@gmail.com;bzhou@ie.cuhk.edu.hk;zhangbo@xiaomi.com,3;3;3;3,,Reject,0,5,0,yes,9/25/19,Hong Kong University of Science and Technology;Alibaba Group;The Chinese University of Hong Kong;Xiaomi,variational autoencoder;generative adversarial network,-1;-1;316;-1,47;-1;35;-1,m;m,NAN,NAN,n
ICLR,2020,Connecting the Dots Between MLE and RL for Sequence Prediction,Bowen Tan;Zhiting Hu;Zichao Yang;Ruslan Salakhutdinov;Eric Xing,bwkevintan@gmail.com;zhitinghu@gmail.com;yangtze2301@gmail.com;rsalakhu@cs.cmu.edu;epxing@cs.cmu.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,"Carnegie Mellon University;University of California, San Diego;;Carnegie Mellon University;Carnegie Mellon University",Sequence generation;sequence prediction;reinforcement learning,-1;-1;-1;1;1,-1;31;-1;27;27,m;m,usa,usa,n
ICLR,2020,BEYOND SUPERVISED LEARNING: RECOGNIZING UNSEEN ATTRIBUTE-OBJECT PAIRS WITH VISION-LANGUAGE FUSION AND ATTRACTOR NETWORKS,Hui Chen;Zhixiong Nan;Nanning Zheng,chenhui0622@stu.xjtu.edu.cn;nanzhixiong@stu.xjtu.edu.cn;nnzheng@mail.xjtu.edu.cn,1;3;1,,Reject,0,0,0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,image understanding,-1;-1;-1,555;555;555,m;m,NAN,NAN,n
ICLR,2020,Distance-based Composable Representations with Neural Networks,Graham Spinks;Marie-Francine Moens,graham.spinks@cs.kuleuven.be;sien.moens@cs.kuleuven.be,3;3;6,,Reject,0,4,0,yes,9/25/19,KU Leuven;KU Leuven,Representation learning;Wasserstein distance;Composability;Templates,143;143,45;45,m;m,europe,be,n
ICLR,2020,Efficient Deep Representation Learning by Adaptive Latent Space Sampling,Yuanhan Mo;Shuo Wang;Chengliang Dai;Rui Zhou;Zhongzhao Teng;Wenjia Bai;Yike Guo,y.mo16@imperial.ac.uk;shuo.wang@imperial.ac.uk;c.dai@imperial.ac.uk;rui.zhou18@imperial.ac.uk;zt215@cam.ac.uk;w.bai@imperial.ac.uk;y.guo@imperial.ac.uk,8;3;6,,Reject,0,4,0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London;University of Cambridge;Imperial College London;Imperial College London,Deep learning;Data efficiency,52;52;52;52;79;52;52,10;10;10;10;3;10;10,m;m,europe,uk,n
ICLR,2020,Out-of-Distribution Detection Using Layerwise Uncertainty in Deep Neural Networks,Hirono Okamoto;Masahiro Suzuki;Yutaka Matsuo,h-okamoto@weblab.t.u-tokyo.ac.jp;masa@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,3;1;1,,Reject,0,6,0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo,out-of-distribution;uncertainty,64;64;64,36;36;36,m;m,NAN,NAN,n
ICLR,2020,Effect of top-down connections in Hierarchical Sparse Coding,Victor Boutin;Angelo Franciosini;Franck Ruffier;Laurent Perrinet,victor.boutin@univ-amu.fr;angelo.franciosini@univ-amu.fr;franck.ruffier@univ-amu.fr;laurent.perrinet@univ-amu.fr,3;3;3,,Reject,0,4,0,yes,9/25/19,Aix Marseille Univ;Aix Marseille Univ;Aix Marseille Univ;Aix Marseille Univ,Hierarchical Sparse Coding;Convolutional Sparse Coding;Top-down connections,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Multitask Soft Option Learning,Maximilian Igl;Andrew Gambardella;Jinke He;Nantas Nardelli;N. Siddharth;Wendelin B√∂hmer;Shimon Whiteson,maximilian.igl@gmail.com;gambs@robots.ox.ac.uk;jinkehe1996@gmail.com;nantas@robots.ox.ac.uk;nsid@robots.ox.ac.uk;wendelin.boehmer@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk,8;3,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford;;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Hierarchical Reinforcement Learning;Reinforcement Learning;Control as Inference;Options;Multitask Learning,-1;46;-1;46;46;46;46,-1;1;-1;1;1;1;1,m;m,europe,uk,n
ICLR,2020,Compositional Transfer in Hierarchical Reinforcement Learning,Markus Wulfmeier;Abbas Abdolmaleki;Roland Hafner;Jost Tobias Springenberg;Michael Neunert;Tim Hertweck;Thomas Lampe;Noah Siegel;Nicolas Heess;Martin Riedmiller,mwulfmeier@google.com;aabdolmaleki@google.com;rhafner@google.com;springenberg@google.com;neunertm@google.com;thertweck@google.com;thomaslampe@google.com;heess@google.com;riedmiller@google.com,3;3;6,,Reject,0,5,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google,Multitask;Transfer Learning;Reinforcement Learning;Hierarchical Reinforcement Learning;Compositional;Off-Policy,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Federated User Representation Learning,Duc Bui;Kshitiz Malik;Jack Goetz;Seungwhan Moon;Honglei Liu;Anuj Kumar;Kang G. Shin,ducbui@umich.edu;kmalik2@fb.com;jrgoetz@umich.edu;shanemoon@fb.com;honglei@fb.com;anujk@fb.com;kgshin@umich.edu,8;3;1,,Reject,0,3,0,yes,9/25/19,University of Michigan;Facebook;University of Michigan;Facebook;Facebook;Facebook;University of Michigan,Machine Learning;Federated Learning;Personalization;User Representation,7;-1;7;-1;-1;-1;7,21;-1;21;-1;-1;-1;21,m;m,usa,usa,n
ICLR,2020,Fairness with Wasserstein Adversarial Networks,serrurier Mathieu;Loubes Jean-Michel;Edouard Pauwels,mathieu.serrurier@irit.fr;loubes@math.univ-toulouse.fr;edouard.pauwels@irit.fr,1;1;1,,Reject,0,0,0,yes,9/25/19,"IRIT, CNRS;Universit√© de Toulouse;IRIT, CNRS",,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Quantum Expectation-Maximization for Gaussian Mixture Models,Iordanis Kerenidis;Anupam Prakash;Alessandro Luongo,jkeren@gmail.com;anupamprakash1@gmail.com;aluongo@irif.fr,3;3;1,,Reject,0,7,0,yes,9/25/19,Universit√© Paris Diderot;;Universite Paris Diderot,Quantum;ExpectationMaximization;Unsupervised;QRAM,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Deep Evidential Uncertainty,Alexander Amini;Wilko Schwarting;Ava Soleimany;Daniela Rus,amini@mit.edu;wilkos@mit.edu;asolei@mit.edu;rus@csail.mit.edu,6;6;3,,Reject,0,12,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Evidential deep learning;Uncertainty estimation;Epistemic uncertainty,5;5;5;5,5;5;5;5,m;f,usa,usa,n
ICLR,2020,Variational Information Bottleneck for Unsupervised Clustering: Deep Gaussian Mixture Embedding,Yigit Ugur;George Arvanitakis;Abdellatif Zaidi,ygtugur@gmail.com;george.arvanitakis@huawei.com;abdellatif.zaidi@u-pem.fr,3;3;3,,Reject,1,0,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Universit√© Paris-Est,clustering;Variational Information Bottleneck;Gaussian Mixture Model,-1;-1;-1,-1;-1;-1,u;m,NAN,NAN,y
ICLR,2020,Multi-scale Attributed Node Embedding,Benedek Rozemberczki;Carl Allen;Rik Sarkar,benedek.rozemberczki@gmail.com;carl.allen@ed.ac.uk;rsarkar@inf.ed.ac.uk,6;6;3,,Reject,0,5,0,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh,network embedding;graph embedding;node embedding;network science;graph representation learning,36;36;36,30;30;30,m;m,europe,uk,y
ICLR,2020,Model Inversion Networks for Model-Based Optimization,Aviral Kumar;Sergey Levine,aviralkumar2907@gmail.com;svlevine@eecs.berkeley.edu,6;3;1,,Reject,0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley,data-driven optimization;model-based optimization,-1;-1,13;13,m;m,usa,usa,y
ICLR,2020,Variational Autoencoders with Normalizing Flow Decoders,Rogan Morrow;Wei-Chen Chiu,rogan.o.morrow@gmail.com;walon@cs.nctu.edu.tw,3;3;6,,Reject,0,4,0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,,118;118,564;564,u;m,asia,tw,n
ICLR,2020,Adversarial Attacks on Copyright Detection Systems,Parsa Saadatpanah;Ali Shafahi;Tom Goldstein,parsa@cs.umd.edu;ashafahi@cs.umd.edu;tomg@cs.umd.edu,3;3;3;6,,Reject,0,5,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",,12;12;12,91;91;91,m;m,usa,usa,n
ICLR,2020,MODiR: Multi-Objective Dimensionality Reduction for Joint Data Visualisation,Tim Repke;Ralf Krestel,tim.repke@hpi.uni-potsdam.de;ralf.krestel@hpi.de,1;3,,Reject,0,0,0,yes,9/25/19,University of Potsdam;Hasso Plattner Institute,dimensionality reduction;visualisation;text visualisation;network drawing,445;143,272;-1,u;m,europe,de,n
ICLR,2020,Actor-Critic Approach for Temporal Predictive Clustering,Changhee Lee;Mihaela van der Schaar,chl8856@gmail.com;mihaela@ee.ucla.edu,3;3;6,,Reject,0,4,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",Temporal Clustering;Predictive Clustering;Actor-Critic,-1;-1,-1;17,m;f,usa,usa,n
ICLR,2020,NeuroFabric: Identifying Ideal Topologies for Training A Priori Sparse Networks,Mihailo Isakov;Michel A. Kinsy,mihailo@bu.edu;mkinsy@bu.edu,3;3;3;3,,Reject,0,5,0,yes,9/25/19,Boston University;Boston University,Sparsity;model compression;training;topology,79;79,61;61,m;m,europe,it,y
ICLR,2020,Chart Auto-Encoders for Manifold Structured  Data,Stephan Schonsheck;Jie Chen;Rongjie Lai,schons@rpi.edu;chenjie@us.ibm.com;lair@rpi.edu,6;3;3,,Reject,0,7,0,yes,9/25/19,Rensselaer Polytechnic Institute;International Business Machines;Rensselaer Polytechnic Institute,Auto-encoder;differential manifolds;multi-charted latent space,248;-1;248,438;-1;438,m;m,usa,usa,n
ICLR,2020,Putting Machine Translation in Context with the Noisy Channel Model,Lei Yu;Laurent Sartran;Wojciech Stokowiec;Wang Ling;Lingpeng Kong;Phil Blunsom;Chris Dyer,leiyu@google.com;lsartran@google.com;wstokowiec@google.com;lingwang@google.com;lingpenk@google.com;pblunsom@google.com;cdyer@google.com,3;3;6,,Reject,0,5,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,machine translation;context-aware machine translation;bayes rule,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Optimizing Data Usage via Differentiable Rewards,Xinyi Wang;Hieu Pham;Paul Michel;Antonios Anastasopoulos;Graham Neubig;Jaime Carbonell,xinyiw1@cs.cmu.edu;hyhieu@cmu.edu;pmichel1@cs.cmu.edu;aanastas@andrew.cmu.edu;gneubig@cs.cmu.edu;jgc@cs.cmu.edu,3;6;6,,Reject,0,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,data selection;multilingual neural machine translation;data usage optimzation;transfer learning;classification,1;1;1;1;1;1,27;27;27;27;27;27,f;m,usa,usa,n
ICLR,2020,Representing Model Uncertainty of Neural Networks in Sparse Information Form,Jongseok Lee;Rudolph Triebel,jongseok.lee@dlr.de;rudolph.triebel@dlr.de,3;1;3;6,,Reject,0,9,0,yes,9/25/19,German Aerospace Center (DLR);German Aerospace Center (DLR),Model Uncertainty;Neural Networks;Sparse representation,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Unsupervised Learning of Efficient and Robust Speech Representations,Kazuya Kawakami;Luyu Wang;Chris Dyer;Phil Blunsom;Aaron van den Oord,kawakamik@google.com;luyuwang@google.com;cdyer@google.com;pblunsom@google.com;avdnoord@google.com,6;6;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Kolmogorov Complexity Approach to Generalization in Deep Learning,Hazar Yueksel;Kush R. Varshney;Brian Kingsbury,hazar.yueksel@ibm.com;krvarshn@us.ibm.com;bedk@us.ibm.com,1;8;3;3,,Reject,0,9,0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines,Kolmogorov complexity;information distance;generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Learning Invariants through Soft Unification,Nuri Cingillioglu;Alessandra Russo,nuri.cingillioglu13@imperial.ac.uk;a.russo@imperial.ac.uk,1;3;3,,Reject,0,3,0,yes,9/25/19,Imperial College London;Imperial College London,representation learning;neural networks;unification,52;52,10;10,m;f,europe,uk,n
ICLR,2020,Collapsed amortized variational inference for switching nonlinear dynamical systems,Zhe Dong;Bryan A. Seybold;Kevin P. Murphy;Hung H. Bui,zhedong@google.com;baseybold@gmail.com;kpmurphy@google.com;bui.h.hung@gmail.com,8;3;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring  for Minimax Problems and GANs,Ernest K. Ryu;Kun Yuan;Wotao Yin,eryu@math.ucla.edu;kunyuan@ucla.edu;wotaoyin@math.ucla.edu,1;6;6,,Reject,0,4,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",GAN;minimax problems;stochastic gradients,-1;-1;-1,17;17;17,m;m,usa,usa,y
ICLR,2020,Event Discovery for History Representation in Reinforcement Learning,Aleksandr Ermolov;Enver Sangineto;Nicu Sebe,aleksandr.ermolov@unitn.it;enver.sangineto@unitn.it;niculae.sebe@unitn.it,3;6;1,,Reject,0,25,0,yes,9/25/19,University of Trento;University of Trento;University of Trento,reinforcement learning;self-supervision;POMDP,143;143;143,307;307;307,m;m,europe,gr,n
ICLR,2020,Learning to Rank Learning Curves,Martin Wistuba;Tejaswini Pedapati,martin.wistuba@ibm.com;tejaswinip@us.ibm.com,6;3;6,,Reject,0,5,0,yes,9/25/19,International Business Machines;International Business Machines,,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,Scoring-Aggregating-Planning: Learning task-agnostic priors from interactions and sparse rewards for zero-shot generalization,Huazhe Xu;Boyuan Chen;Yang Gao;Trevor Darrell,huazhe_xu@eecs.berkeley.edu;boyuanchen@berkeley.edu;yg@eecs.berkeley.edu;trevordarrell@eecs.berkeley.edu,3;6;6,,Reject,0,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,learning priors from exploration data;policy zero-shot generalization;reward shaping;model-based,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n
ICLR,2020,Topic Models with Survival Supervision: Archetypal Analysis and Neural Approaches,George H. Chen;Linhong Li;Ren Zuo;Amanda Coston;Jeremy C. Weiss,georgechen@cmu.edu;linhongl@andrew.cmu.edu;renzuo.wren@gmail.com;acoston@cs.cmu.edu;jeremyweiss@cmu.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;;Carnegie Mellon University;Carnegie Mellon University,,1;1;-1;1;1,27;27;-1;27;27,m;m,usa,usa,n
ICLR,2020,Way Off-Policy Batch Deep Reinforcement Learning of Human Preferences in Dialog,Natasha Jaques;Asma Ghandeharioun;Judy Hanwen Shen;Craig Ferguson;Agata Lapedriza;Noah Jones;Shixiang Gu;Rosalind Picard,jaquesn@mit.edu;asma_gh@mit.edu;judyshen@mit.edu;fergusoc@mit.edu;agata@mit.edu;ncjones@mit.edu;shanegu@google.com;picard@media.mit.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,batch reinforcement learning;deep learning;dialog;off-policy;human preferences,5;5;5;5;5;5;-1;5,5;5;5;5;5;5;-1;5,f;f,usa,usa,n
ICLR,2020,Well-Read Students Learn Better: On the Importance of Pre-training Compact Models,Iulia Turc;Ming-Wei Chang;Kenton Lee;Kristina Toutanova,iuliaturc@google.com;mingweichang@google.com;kentonl@google.com;kristout@google.com,1;6;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google,NLP;self-supervised learning;language model pre-training;knowledge distillation;BERT;compact models,-1;-1;-1;-1,-1;-1;-1;-1,f;f,NAN,NAN,n
ICLR,2020,Model Imitation for Model-Based Reinforcement Learning,Yueh-Hua Wu;Ting-Han Fan;Peter J. Ramadge;Hao Su,kriswu8021@gmail.com;tinghanf@princeton.edu;ramadge@princeton.edu;haosu@eng.ucsd.edu,6;6;6,,Reject,0,5,0,yes,9/25/19,"National Taiwan University;Princeton University;Princeton University;University of California, San Diego",Model-Based Reinforcement Learning,-1;30;30;-1,-1;6;6;31,m;m,usa,usa,y
ICLR,2020,Black Box Recursive Translations for Molecular Optimization,Farhan Damani;Vishnu Sresht;Stephen Ra,farhand7@gmail.com;vishnu.sresht@pfizer.com;stephen.ra@pfizer.com,6;3;3;6,,Reject,0,9,0,yes,9/25/19,Princeton University;Pfizer R&D;Pfizer R&D,molecules;chemistry;drug design;generative models;application;translation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Improving the Generalization of Visual Navigation Policies using Invariance Regularization,Michel Aractingi;Christopher Dance;Julien Perez;Tomi Silander,michel.aractingi@naverlabs.com;christopher.dance@naverlabs.com;julien.perez@naverlabs.com;tomi.silander@naverlabs.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Naver Labs Europe;Naver Labs Europe;Naver Labs Europe;Naver Labs Europe,Generalization;Deep Reinforcement Learning;Invariant Representation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PatchFormer: A neural architecture for self-supervised representation learning on images,Aravind Srinivas;Pieter Abbeel,aravind@cs.berkeley.edu;pabbeel@cs.berkeley.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,University of California Berkeley;University of California Berkeley,Unsupervised Learning;Representation Learning;Transformers,-1;-1,13;13,m;m,usa,usa,n
ICLR,2020,Learning from Positive and Unlabeled Data  with Adversarial Training,Wenpeng Hu;Ran Le;Bing Liu;Feng Ji;Haiqing Chen;Dongyan Zhao;Jinwen Ma;Rui Yan,wenpeng.hu@pku.edu.cn;leran.pku@gmail.com;dcsliub@pku.edu.cn;zhongxiu.jf@alibaba-inc.com;zhaody@pku.edu.cn;jinwen.ma@pku.edu.cn;rui.yan@pku.edu.cn,3;3;6,,Reject,0,6,0,yes,9/25/19,Peking University;;Peking University;Alibaba Group;Peking University;Peking University;Peking University,Positive and Unlabeled learning,14;-1;14;-1;14;14;14,24;-1;24;-1;24;24;24,m;m,asia,cn,y
ICLR,2020,PNAT: Non-autoregressive Transformer by Position Learning,Yu Bao;Hao Zhou;Jiangtao Feng;Mingxuan Wang;Shujian Huang;Jiajun Chen;Lei Li,baoy@smail.nju.edu.cn;zhouhao.nlp@bytedance.com;fengjiangtao@bytedance.com;wangmingxuan.89@bytedance.com;huangsj@nju.edu.cn;chenjj@nju.edu.cn;lilei.02@bytedance.com,3;3;6,,Reject,2,9,0,yes,9/25/19,Zhejiang University;ByteDance;ByteDance;ByteDance;Zhejiang University;Zhejiang University;ByteDance,Text Generation,39;-1;-1;-1;39;39;-1,107;-1;-1;-1;107;107;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Boolean Circuits with Neural Networks,Eran Malach;Shai Shalev-Shwartz,eran.malach@mail.huji.ac.il;shais@cs.huji.ac.il,6;3;6,,Reject,0,4,0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,neural-networks;deep learning theory,85;85,216;216,u;m,europe,il,y
ICLR,2020,Stagnant zone segmentation with U-net,Selam Waktola;Laurent Babout;Krzysztof Grudzien,selam.waktola@gmail.com,1;1;1,,Reject,0,1,0,yes,9/25/19,0,,,,m;m,NAN,NAN,n
ICLR,2020,Model-based Saliency for the Detection of Adversarial Examples,Lisa Schut;Yarin Gal,lisaschut94@gmail.com;yarin.gal@cs.ox.ac.uk,6;1;3,,Reject,0,6,0,yes,9/25/19,University of Oxford;University of Oxford,Adversarial Examples;Defense;Model-based Saliency,46;46,1;1,f;m,europe,uk,n
ICLR,2020,Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation,Mengyu Chu;You Xie;Jonas Mayer;Laura Leal-Taix√©;Nils Th√ºrey,mengyu.chu@tum.de;you.xie@tum.de;jonas.a.mayer@tum.de;leal.taixe@tum.de;nils.thuerey@tum.de,3;8;6;3,,Reject,0,9,0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich,adversarial training;generative models;unpaired video translation;video super-resolution;temporal coherence;self-supervision;cycle-consistency,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,R-TRANSFORMER: RECURRENT NEURAL NETWORK ENHANCED TRANSFORMER,Zhiwei Wang;Yao Ma;Zitao Liu;Jiliang Tang,wangzh65@msu.edu;mayao4@msu.edu;liuzitao@100tal.com;tangjili@msu.edu,3;3;6,,Reject,0,0,0,yes,9/25/19,Michigan State University;Michigan State University;TAL Education Group;Michigan State University,Sequence Modeling;Multi-head Attention;RNNs,102;102;-1;102,84;84;-1;84,m;m,usa,usa,n
ICLR,2020,A closer look at network resolution for efficient network design,Taojiannan Yang;Sijie Zhu;Yan Shen;Mi Zhang;Andrew Willis;Chen Chen,tyang30@uncc.edu;szhu3@uncc.edu;yanshen6@msu.edu;mizhang@msu.edu;arwillis@uncc.edu;chen.chen@uncc.edu,3;6;3,,Reject,0,10,0,yes,9/25/19,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;Michigan State University;Michigan State University;University of North Carolina, Charlotte;University of North Carolina, Charlotte",deep learning;computer vision;efficient network design;dynamic neural networks,64;64;102;102;64;64,-1;-1;84;84;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning in Confusion: Batch Active Learning with Noisy Oracle,Gaurav Gupta;Anit Kumar Sahu;Wan-Yi Lin,ggaurav@usc.edu;anit.sahu@gmail.com;wan-yi.lin@us.bosch.com,1;1;6,,Reject,0,4,0,yes,9/25/19,University of Southern California;Amazon;Bosch,Active Learning;Noisy Oracle;Model Uncertainty;Image classification,36;-1;-1,62;-1;297,m;f,NAN,NAN,n
ICLR,2020,On Predictive Information Sub-optimality of RNNs,Zhe Dong;Deniz Oktay;Ben Poole;Alexander A. Alemi,zhedong@google.com;doktay@princeton.edu;pooleb@google.com;alemi@google.com,3;6;3,,Reject,0,3,0,yes,9/25/19,Google;Princeton University;Google;Google,,-1;30;-1;-1,-1;6;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Match prediction from group comparison data using neural networks,Sunghyun Kim;Minje jang;Changho Suh,koishkim@gmail.com;jmj427@lunit.io;chsuh@kaist.ac.kr,3;1;6;6,,Reject,0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Lunit Inc.;Korea Advanced Institute of Science and Technology,Neural networks;Group comparison;Match prediction;Rank aggregation,-1;-1;-1,-1;-1;110,m;m,NAN,NAN,n
ICLR,2020,Feature Partitioning for Efficient Multi-Task Architectures,Alejandro Newell;Lu Jiang;Chong Wang;Li-Jia Li;Jia Deng,anewell@cs.princeton.edu;lujiang@google.com;chong.wang@bytedance.com;lijiali@cs.stanford.edu;jiadeng@princeton.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,Princeton University;Google;ByteDance;Stanford University;Princeton University,multi-task learning;neural architecture search;multi-task architecture search,30;-1;-1;5;30,6;-1;-1;4;6,m;m,usa,usa,n
ICLR,2020,Learnable Group Transform For Time-Series,Romain Cosentino;Behnaam Aazhang,rc57@rice.edu;aaz@rice.edu,8;3;3,,Reject,0,9,0,yes,9/25/19,Rice University;Rice University,Group Transform;Time-Frequency Representation;Wavelet Transform;Group Theory;Representation Theory;Time-Series,92;92,105;105,u;m,australasia,au,y
ICLR,2020,SesameBERT: Attention for Anywhere,Ta-Chun Su;Hsiang-Chih Cheng,gene11117@gmail.com;musicmilif@gmail.com,3;3;3,,Reject,0,4,0,yes,9/25/19,National Taiwan University;Stanford University,Natural Language Processing;Deep Learning;Self Attention,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Towards A Unified Min-Max Framework for Adversarial Exploration and Robustness,Jingkang Wang;Tianyun Zhang;Sijia Liu;Pin-Yu Chen;Jiacen Xu;Makan Fardad;Bo Li,wangjksjtu@gmail.com;tzhan120@syr.edu;sijia.liu@ibm.com;pin-yu.chen@ibm.com;coldstudy@sjtu.edu.cn;makan@syr.edu;lxbosky@gmail.com,3;8;3,,Reject,0,8,0,yes,9/25/19,University of Toronto;Syracuse University;International Business Machines;International Business Machines;Shanghai Jiao Tong University;Syracuse University;University of California Berkeley,Ensemble attack;adversarial training;diversity promotion,18;194;-1;-1;30;194;-1,18;292;-1;-1;157;292;13,m;f,usa,usa,y
ICLR,2020,Towards Scalable Imitation Learning for Multi-Agent Systems with Graph Neural Networks,Siyu Zhou;Chaitanya Rajasekhar;Mariano J. Phielipp;Heni Ben Amor,siyu.zhou.ac@gmail.com;crajase1@asu.edu;mariano.j.phielipp@intel.com;hbenamor@asu.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,Arizona State University;SUN YAT-SEN UNIVERSITY;Intel;SUN YAT-SEN UNIVERSITY,Graph Neural Networks;Scalability;Swarms;Imitation,-1;-1;-1;-1,-1;299;-1;299,m;m,NAN,NAN,n
ICLR,2020,Dual-module Inference for Efficient Recurrent Neural Networks,Liu Liu;Lei Deng;Shuangchen Li;Jingwei Zhang;Yihua Yang;Zhenyu Gu;Yufei Ding;Yuan Xie,liu_liu@ucsb.edu;leideng@ucsb.edu;shuangchen.li@alibaba-inc.com;jingwei.zhang@alibaba-inc.com;yihua.yang@alibaba-inc.com;zhenyu.gu@alibaba-inc.com;yufeiding@cs.ucsb.edu;yuanxie@ece.ucsb.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,UC Santa Barbara;UC Santa Barbara;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;UC Santa Barbara;UC Santa Barbara,memory-efficient RNNs;dynamic execution;computation skipping,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,On Federated Learning of Deep Networks from Non-IID Data: Parameter Divergence and the Effects of Hyperparametric Methods,Heejae Kim;Taewoo Kim;Chan-Hyun Youn,kim881019@kaist.ac.kr;taewoo_kim@kaist.ac.kr;chyoun@kaist.ac.kr,3;3;1,,Reject,1,15,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Federated learning;Iterative parameter averaging;Deep networks;Decentralized non-IID data;Hyperparameter optimization methods,-1;-1;-1,110;110;110,m;m,NAN,NAN,y
ICLR,2020,DeepXML: Scalable & Accurate Deep Extreme Classification for Matching User Queries to Advertiser Bid Phrases,Kunal Dahiya;Anshul Mittal;Deepak Saini;Kushal Dave;Himanshu Jain;Sumeet Agarwal;Manik Varma,kunalsdahiya@gmail.com;anshulmittal71@gmail.com;desaini@microsoft.com;kudave@microsoft.com;himanshu.j689@gmail.com;sumeet@iitd.ac.in;manik@microsoft.com,6;3;6,,Reject,0,5,0,yes,9/25/19,Indian Institute of Technology Delhi;Indian Institute of Technology Delhi;Microsoft;Microsoft;;Indian Institute of Technology Delhi;Microsoft,extreme multi label learning;extreme classification;deep extreme multi label learning;deep extreme classification;large output space,-1;-1;-1;-1;-1;-1;-1,441;441;-1;-1;-1;441;-1,m;m,NAN,NAN,n
ICLR,2020,Few-Shot Regression via Learning Sparsifying Basis Functions,Yi Loo;Yiluan Guo;Ngai-Man Cheung,loo_yi@sutd.edu.sg;guoyl1990@outlook.com;ngaiman_cheung@sutd.edu.sg,3;3;3,,Reject,1,3,0,yes,9/25/19,Singapore University of Technology and Design;;Singapore University of Technology and Design,meta-learning;few-shot learning;regression;learning basis functions;self-attention,-1;-1;-1,-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Address2vec: Generating vector embeddings for blockchain analytics,Ali Hussein;Samiiha Nalwooga,ali.hussein@ronininstitute.org;nsamiiha@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Ronin Institute;Stockholm University,crypto-currency;bitcoin;blockchain;2vec,-1;-1,-1;-1,m;f,asia,in,n
ICLR,2020,Energy-Aware Neural Architecture Optimization with Fast Splitting Steepest Descent,Dilin Wang;Meng Li;Lemeng Wu;Vikas Chandra;Qiang Liu,dilin@cs.utexas.edu;meng.li@fb.com;lmwu@cs.utexas.edu;vchandra@fb.com;lqiang@cs.utexas.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,"University of Texas, Austin;Facebook;University of Texas, Austin;Facebook;University of Texas, Austin",Neural architecture optimization;splitting steepest descent,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Equilibrium Propagation with Continual Weight Updates,Maxence Ernoult;Julie Grollier;Damien Querlioz;Yoshua Bengio;Benjamin Scellier,maxence.ernoult@u-psud.fr;julie.grollier@cnrs-thales.fr;damien.querlioz@u-psud.fr;yoshua.bengio@mila.quebec;benjamin.scellier@umontreal.ca,3;3;8,,Reject,0,5,0,yes,9/25/19,UPSud/INRIA University Paris-Saclay;;UPSud/INRIA University Paris-Saclay;Mila;University of Montreal,Biologically Plausible Neural Networks;Equilibrium Propagation,-1;-1;-1;143;118,-1;-1;-1;336;85,m;m,canada,ca,y
ICLR,2020,IsoNN: Isomorphic Neural Network for Graph Representation Learning and Classification,Lin Meng;Jiawei Zhang,lin@ifmlab.org;jiawei@ifmlab.org,6;3;1,,Reject,1,4,0,yes,9/25/19,Florida State University;SUN YAT-SEN UNIVERSITY,Deep Learning;Graph Neural Network,-1;-1,-1;299,u;u,NAN,NAN,y
ICLR,2020,LDMGAN: Reducing Mode Collapse in GANs with Latent Distribution Matching,Zhiwen Zuo;Lei Zhao;Huiming Zhang;Qihang Mo;Haibo Chen;Zhizhong Wang;AiLin Li;Lihong Qiu;Wei Xing;Dongming Lu,zzwcs@zju.edu.cn;cszhl@zju.edh.cn;qinglanwuji@zju.edu.cn;moqihang@zju.edu.cn;feng123@zju.edu.cn;endywon@zju.edu.cn;11921050@zju.edu.cn;zjusheldon@zju.edu.cn;wxing@zju.edu.cn;ldm@zju.edu.cn,1;3;1,,Reject,0,0,0,yes,9/25/19,Zhejiang University;;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,Deep Learning;Unsupervised Learning;Generative Adversarial Networks;Mode Collapse;AutoEncoder,39;-1;39;39;39;39;39;39;39;39,107;-1;107;107;107;107;107;107;107;107,m;m,asia,cn,n
ICLR,2020,Reinforcement Learning with Chromatic Networks,Xingyou Song;Krzysztof Choromanski;Jack Parker-Holder;Yunhao Tang;Wenbo Gao;Aldo Pacchiano;Tamas Sarlos;Deepali Jain;Yuxiang Yang,xingyousong@google.com;kchoro@google.com;jh3764@columbia.edu;yt2541@columbia.edu;wg2279@columbia.edu;pacchiano@berkeley.edu;stamas@google.com;jaindeepali@google.com;yxyang@google.com,3;3;6,,Reject,0,5,0,yes,9/25/19,Google;Google;Columbia University;Columbia University;Columbia University;University of California Berkeley;Google;Google;Google,reinforcement;learning;chromatic;networks;partitioning;efficient;neural;architecture;search;weight;sharing;compactification,-1;-1;24;24;24;-1;-1;-1;-1,-1;-1;16;16;16;13;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Generalized Natural Language Grounded Navigation via Environment-agnostic Multitask Learning,Xin Wang;Vihan Jain;Eugene Ie;William Wang;Zornitsa Kozareva;Sujith Ravi,xwang@cs.ucsb.edu;vihanjain@google.com;eugeneie@google.com;william@cs.ucsb.edu;kozareva@google.com;sravi@google.com,6;3;6,,Reject,0,6,0,yes,9/25/19,UC Santa Barbara;Google;Google;UC Santa Barbara;Google;Google,Natural Language Grounded Navigation;Multitask Learning;Agnostic Learning,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Mincut Pooling in Graph Neural Networks,Filippo Maria Bianchi;Daniele Grattarola;Cesare Alippi,fibi@norceresearch.no;grattd@usi.ch;alippc@usi.ch,3;8;3,,Reject,0,5,0,yes,9/25/19,NORCE the Norwegian Research Center;Universit√† della Svizzera Italiana;Universit√† della Svizzera Italiana,Graph Neural Networks;Pooling;Graph Cuts;Spectral Clustering,-1;194;194,-1;341;341,m;m,europe,ch,n
ICLR,2020,Off-Policy Actor-Critic with Shared Experience Replay,Simon Schmitt;Matteo Hessel;Karen Simonyan,suschmitt@google.com;mtthss@google.com;simonyan@google.com,6;6;6,,Reject,0,4,1,yes,9/25/19,Google;Google;Google,Reinforcement Learning;Off-Policy Learning;Experience Replay,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Striving for Simplicity in Off-Policy Deep Reinforcement Learning,Rishabh Agarwal;Dale Schuurmans;Mohammad Norouzi,rishabhagarwal@google.com;schuurmans@google.com;mnorouzi@google.com,3;3;3,,Reject,0,7,1,yes,9/25/19,Google;Google;Google,reinforcement learning;off-policy;batch RL;offline RL;benchmark,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Scheduling the Learning Rate Via Hypergradients: New Insights and a New Algorithm,Michele Donini;Luca Franceschi;Orchid Majumder;Massimiliano Pontil;Paolo Frasconi,mikko108382892@gmail.com;luca.franceschi@iit.it;orchid@amazon.com;massimiliano.pontil@gmail.com;paolo.frasconi@unifi.it,6;1,,Reject,0,6,0,yes,9/25/19,Amazon;Istituto Italiano di Tecnologia;Amazon;;Universit√† di Firenze,automl;hyperparameter optimization;learning rate;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Improving Federated Learning Personalization via Model Agnostic Meta Learning,Yihan Jiang;Jakub Koneƒçn√Ω;Keith Rush;Sreeram Kannan,yihanrogerjiang@gmail.com;konkey@google.com;krush@google.com;ksreeram@uw.edu,1;1;3,,Reject,1,4,0,yes,9/25/19,"University of Washington, Seattle;Google;Google;University of Washington, Seattle",Federated Learning;Model Agnostic Meta Learning;Personalization,-1;-1;-1;11,-1;-1;-1;26,m;m,NAN,NAN,n
ICLR,2020,Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View,Yiping Lu;Zhuohan Li;Di He;Zhiqing Sun;Bin Dong;Tao Qin;Liwei Wang;Tie-Yan Liu,yplu@stanford.edu;zhuohan@berkeley.edu;di_he@pku.edu.cn;zhiqings@andrew.cmu.edu;bindong@math.pku.edu.cn;taoqin@microsoft.com;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,3;1;3,,Reject,0,1,0,yes,9/25/19,Stanford University;University of California Berkeley;Peking University;Carnegie Mellon University;Peking University;Microsoft;Peking University;Microsoft,Transformer;Ordinary Differential Equation;Multi-Particle Dynamic System;Natural Language Processing,5;-1;14;1;14;-1;14;-1,4;13;24;27;24;-1;24;-1,m;m,NAN,NAN,n
ICLR,2020,Optimising Neural Network Architectures for Provable Adversarial Robustness,Henry Gouk;Timothy M. Hospedales,hgouk@inf.ed.ac.uk;t.hospedales@ed.ac.uk,3;1;1,,Reject,0,0,0,yes,9/25/19,University of Edinburgh;University of Edinburgh,Provable adversarial robustness;Lipschitz neural networks;network architectures,36;36,30;30,m;m,europe,uk,y
ICLR,2020,AN EFFICIENT HOMOTOPY TRAINING ALGORITHM FOR NEURAL NETWORKS,Qipin Chen;Wenrui Hao,qzc18@psu.edu;wxh64@psu.edu,3;3;1,,Reject,0,0,0,yes,9/25/19,Pennsylvania State University;Pennsylvania State University,Homotopy training algorithm;Convergence analysis;Neural networks,43;43,-1;-1,m;m,usa,usa,y
ICLR,2020,Improving End-to-End Object Tracking Using Relational Reasoning,Fabian B. Fuchs;Adam R. Kosiorek;Li Sun;Oiwi Parker Jones;Ingmar Posner,fabian@robots.ox.ac.uk;adamk@robots.ox.ac.uk;kevin@robots.ox.ac.uk;oiwi.parkerjones@jesus.ox.ac.uk;ingmar@robots.ox.ac.uk,6;3;3,,Reject,0,5,1,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Relational Reasoning;Tracking;Intuitive Physics;Real-World Application;Permutation Invariance,46;46;46;46;46,1;1;1;1;1,m;m,europe,uk,n
ICLR,2020,Bandlimiting Neural Networks Against Adversarial Attacks,Yuping Lin;Kasra Ahmadi K. A.;Hui Jiang,yuping@eecs.yorku.ca;kasraah@eecs.yorku.ca;hj@cse.yorku.ca,1;3;6,,Reject,0,0,0,yes,9/25/19,York University;York University;York University,adversarial examples;adversarial attack defense;neural network;Fourier analysis,194;194;194,416;416;416,m;m,asia,kr,y
ICLR,2020,NoiGAN: NOISE AWARE KNOWLEDGE GRAPH EMBEDDING WITH GAN,Kewei Cheng;Yikai Zhu;Ming Zhang;Yizhou Sun,viviancheng@cs.ucla.edu;zhuyikai.zyk@gmail.com;mzhang_cs@pku.edu.cn;yzsun@cs.ucla.edu,3;3;1,,Reject,0,3,0,yes,9/25/19,"University of California, Los Angeles;;Peking University;University of California, Los Angeles",Knowledge graph embedding;Noise aware,-1;-1;14;-1,17;-1;24;17,f;f,usa,usa,n
ICLR,2020,Gradient Surgery for Multi-Task Learning,Tianhe Yu;Saurabh Kumar;Abhishek Gupta;Karol Hausman;Sergey Levine;Chelsea Finn,tianheyu@cs.stanford.edu;szk@stanford.edu;abhigupta@berkeley.edu;hausmankarol@gmail.com;svlevine@eecs.berkeley.edu;cbfinn@cs.stanford.edu,3;6;3,,Reject,0,6,0,yes,9/25/19,Stanford University;Stanford University;University of California Berkeley;Google;University of California Berkeley;Stanford University,multi-task learning;deep learning,5;5;-1;-1;-1;5,4;4;13;-1;13;4,m;f,usa,usa,y
ICLR,2020,Filter redistribution templates for iteration-lessconvolutional model reduction,Ramon Izquierdo Cordova;Walterio Mayol Cuevas,ri16164@bristol.ac.uk;walterio.mayol-cuevas@bristol.ac.uk,3;6;3;6,,Reject,0,6,0,yes,9/25/19,University of Bristol;University of Bristol,Model reduction;Pruning;filter distribution,118;118,87;87,m;m,europe,uk,n
ICLR,2020,Value-Driven Hindsight Modelling,Arthur Guez;Fabio Viola;Theophane Weber;Lars Buesing;Steven Kapturowski;Doina Precup;David Silver;Nicolas Heess,aguez@google.com;fviola@google.com;theophane@google.com;lbuesing@google.com;skapturowski@google.com;doinap@google.com;davidsilver@google.com;heess@google.com,6;6;6,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,JAUNE: Justified And Unified Neural language Evaluation,Hassan Kan√©;Yusuf Kocyigit;Ali Abdalla;Pelkins Ajanoh;Mohamed Coulibali,hassanmohamed@alum.mit.edu;yusuf.kocyigit@boun.edu.tr;aabdalla@alum.mit.edu;pelkins@alum.mit.edu;mohamed-konoufo.coulibali.1@ulaval.ca,1;1;1,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Bogazici University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Laval university,NLP;Evaluation Metrics;Summarization;Translation;BLEU;ROUGE;Transformers,5;316;5;5;-1,5;672;5;5;272,m;m,NAN,NAN,n
ICLR,2020,Extreme Values are Accurate and Robust in Deep Networks,Jianguo Li;Mingjie Sun;Changshui Zhang,jianguo.li@intel.com;sunmj15@gmail.com;zcs@tsinghua.edu.cn,3;3;8,,Reject,0,4,0,yes,9/25/19,"Intel;;Tsinghua University, Tsinghua University",Biological inspired CNN architecture design;Adversarial Robustness Architecture,-1;-1;4,-1;-1;23,m;m,NAN,NAN,n
ICLR,2020,"Scaling Laws for the Principled Design, Initialization, and Preconditioning of ReLU Networks",Aaron Defazio;Leon Bottou,aaron.defazio@gmail.com;leon@bottou.org,3;1;3,,Reject,0,4,0,yes,9/25/19,Facebook;Facebook,initialization;mlp;relu,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Overcoming Catastrophic Forgetting via Hessian-free Curvature Estimates,Leonid Butyrev;Georgios Kontes;Christoffer L√∂ffler;Christopher Mutschler,butyreld@iis.fraunhofer.de;georgios.kontes@iis.fraunhofer.de;christoffer.loeffler@iis.fraunhofer.de;christopher.mutschler@iis.fraunhofer.de,3;1;3,,Reject,0,1,0,yes,9/25/19,Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS,catastrophic forgetting;multi-task learning;continual learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Functionally Decomposed Hierarchies for Continuous Navigation Tasks,Lukas Jendele;Sammy Christen;Emre Aksan;Otmar Hilliges,lukas.jendele@gmail.com;sammy.christen@inf.ethz.ch;eaksan@inf.ethz.ch;otmar.hilliges@inf.ethz.ch,6;6;3,,Reject,0,8,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Hierarchical reinforcement learning;planning;navigation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Hindsight Trust Region Policy Optimization,Hanbo Zhang;Site Bai;Xuguang Lan;Nanning Zheng,zhanghanbo163@stu.xjtu.edu.cn;best99317@stu.xjtu.edu.cn;xglan@xjtu.edu.cn;nnzheng@xjtu.edu.cn,3;3;6,,Reject,0,5,0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,Hindsight;Sparse Reward;Reinforcement Learning;Policy Gradients,-1;-1;-1;-1,555;555;555;555,m;m,NAN,NAN,y
ICLR,2020,The Probabilistic Fault Tolerance of Neural Networks in the Continuous Limit,El-Mahdi El-Mhamdi;Rachid Guerraoui;Andrei Kucharavy;Sergei Volodin,elmahdi.elmhamdi@epfl.ch;rachid.guerraoui@epfl.ch;andrei.kucharavy@epfl.ch;sergei.volodin@epfl.ch,1;3;8,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Robustness;theory of neural networks;fault tolerance;continuous limit;Taylor expansion;error bound;neuromorphic computing;continuous networks;functional derivative,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Parallel Neural Text-to-Speech,Kainan Peng;Wei Ping;Zhao Song;Kexin Zhao,pengkainan@baidu.com;weiping.thu@gmail.com;zhaosong02@baidu.com;zhaokexin01@baidu.com,3;6;1,,Reject,1,3,0,yes,9/25/19,Baidu;NVIDIA;Baidu;Baidu,text-to-speech;non-autoregressive model;parallel decoding,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation",Jiawei Ma*;Zheng Shou*;Alireza Zareian;Hassan Mansour;Anthony Vetro;Shih-Fu Chang,jm4743@columbia.edu;zs2262@columbia.edu;alireza@cs.columbia.edu;mansour@merl.com;avetro@merl.com;sc250@columbia.edu,6;1;3,,Reject,0,5,0,yes,9/25/19,Columbia University;Columbia University;Columbia University;Mitsubishi Electric Research Labs;Mitsubishi Electric Research Labs;Columbia University,self-attention;cross-dimensional;multivariate time series;imputation,24;24;24;-1;-1;24,16;16;16;-1;-1;16,m;m,usa,usa,n
ICLR,2020,Differential Privacy in Adversarial Learning with Provable Robustness,NhatHai Phan;My T. Thai;Ruoming Jin;Han Hu;Dejing Dou,phan@njit.edu;mythai@cise.ufl.edu;rjin1@kent.edu;hh255@njit.edu;dou@cs.uoregon.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,New Jersey Institute of Technology;University of Florida;Bilkent University;New Jersey Institute of Technology;University of Oregon,differential privacy;adversarial learning;robustness bound;adversarial example,-1;168;316;-1;194,564;174;548;564;288,m;m,europe,de,y
ICLR,2020,On Layer Normalization in the Transformer Architecture,Ruibin Xiong;Yunchang Yang;Di He;Kai Zheng;Shuxin Zheng;Huishuai Zhang;Yanyan Lan;Liwei Wang;Tie-Yan Liu,xiongruibin18@mails.ucas.ac.cn;1500010650@pku.edu.cn;dihe@microsoft.com;zhengk92@pku.edu.cn;shuxin.zheng@microsoft.com;huishuai.zhang@microsoft.com;lanyanyan@ict.ac.cn;wanglw@cis.pku.edu.cn;tyliu@microsoft.com,6;6;6,,Reject,2,11,0,yes,9/25/19,"Chinese Academy of Sciences;Peking University;Microsoft;Peking University;Microsoft;Microsoft;Institute of Computing Technology, Chinese Academy of Sciences;Peking University;Microsoft",Transformer;BERT;Layer Normalization;Natural Language Processing,30;14;-1;14;-1;-1;30;14;-1,-1;24;-1;24;-1;-1;-1;24;-1,m;m,NAN,NAN,y
ICLR,2020,Learning RNNs with Commutative State Transitions,Edo Cohen-Karlik;Amir Globerson,edocoh@gmail.com;amir.globerson@gmail.com,1;1;3,,Reject,0,3,0,yes,9/25/19,Tel Aviv University;Tel Aviv University,,-1;30,-1;188,m;m,europe,il,y
ICLR,2020,Deep Bayesian Structure Networks,Zhijie Deng;Yucen Luo;Jun Zhu;Bo Zhang,dzj17@mails.tsinghua.edu.cn;luoyc15@mails.tsinghua.edu.cn;dcszj@tsinghua.edu.cn;dcszb@tsinghua.edu.cn,3;3;6,,Reject,0,8,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",,4;4;4;4,23;23;23;23,m;m,NAN,NAN,n
ICLR,2020,RPGAN: random paths as a latent space for GAN interpretability,Andrey Voynov;Artem Babenko,an.voynov@gmail.com;artem.babenko@phystech.edu,3;3;8,,Reject,0,3,0,yes,9/25/19,Yandex;Moscow Institute of Physics and Technology,generative models;GAN;interpretability,-1;-1,-1;234,m;m,NAN,NAN,n
ICLR,2020,MissDeepCausal: causal inference from incomplete data using deep latent variable models,Julie Josse;Imke Mayer;Jean-Philippe Vert,julie.josse@polytechnique.edu;imke.mayer@polytechnique.edu;jpvert@google.com,6;6;6,,Reject,0,5,0,yes,9/25/19,Ecole polytechnique;Ecole polytechnique;Google,treatment effect estimation;missing values;variational autoencoders;importance sampling;double robustness,-1;-1;-1,93;93;-1,f;m,NAN,NAN,n
ICLR,2020,Active Learning Graph Neural Networks via Node Feature Propagation,Yuexin Wu;Yichong Xu;Aarti Singh;Artur Dubrawski;Yiming Yang,yuexinw@andrew.cmu.edu;yichongx@cs.cmu.edu;aarti@cs.cmu.edu;awd@cs.cmu.edu;yiming@cs.cmu.edu,3;1;8,,Reject,2,4,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Graph Learning;Active Learning,1;1;1;1;1,27;27;27;27;27,m;f,usa,usa,y
ICLR,2020,DUAL ADVERSARIAL MODEL FOR GENERATING 3D POINT CLOUD,Yuhang Zhang;Zhenwei Miao;Tiebin Mi;Robert Caiming Qiu,hang_universe@sjtu.edu.cn;zhenwei.mzw@alibaba-inc.com;mitiebin@sjtu.edu.cn;rcqiu@sjtu.edu.cn,1;6;6,,Reject,0,4,0,yes,9/25/19,Shanghai Jiao Tong University;Alibaba Group;Shanghai Jiao Tong University;Shanghai Jiao Tong University,point cloud;generative;latent space,30;-1;30;30,157;-1;157;157,m;m,asia,cn,n
ICLR,2020,LabelFool: A Trick in the Label Space,Yujia Liu;Tingting Jiang;Ming Jiang,yujia_liu@pku.edu.cn;ttjiang@pku.edu.cn;ming-jiang@pku.edu.cn,3;3;1,,Reject,0,10,0,yes,9/25/19,Peking University;Peking University;Peking University,Adversarial attack;LabelFool;Imperceptibility;Label space,14;14;14,24;24;24,f;m,asia,cn,n
ICLR,2020,Unsupervised Generative 3D Shape Learning from Natural Images,Attila Szabo;Givi Meishvili;Paolo Favaro,attila.szabo@inf.unibe.ch;givi.meishvili@inf.unibe.ch;paolo.favaro@inf.unibe.ch,3;3;8,,Reject,2,5,0,yes,9/25/19,University of Bern;University of Bern;University of Bern,unsupervised;3D;differentiable;rendering;disentangling;interpretable,316;316;316,113;113;113,m;m,europe,uk,n
ICLR,2020,Prestopping: How Does Early Stopping Help Generalization Against Label Noise?,Hwanjun Song;Minseok Kim;Dongmin Park;Jae-Gil Lee,songhwanjun@kaist.ac.kr;minseokkim@kaist.ac.kr;dongminpark@kaist.ac.kr;jaegil@kaist.ac.kr,3;3;6;3,,Reject,2,9,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,noisy label;label noise;robustness;deep learning;early stopping,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,Deep Reinforcement Learning with Implicit Human Feedback,Duo Xu;Mohit Agarwal;Raghupathy Sivakumar;Faramarz Fekri,dxu3016@gatech.edu;me.agmohit@gatech.edu;siva@ece.gatech.edu;faramarz.fekri@ece.gatech.edu,3;1;3,,Reject,0,1,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Error-Potentials;Implicit Human Feedback;Deep Reinforcement Learning;Human-assistance,13;13;13;13,38;38;38;38,m;m,usa,usa,n
ICLR,2020,"Manifold Modeling in Embedded Space: A Perspective for Interpreting Deep Image Prior""""",Tatsuya Yokota;Hidekata Hontani;Qibin Zhao;Andrzej Cichocki,t.yokota@nitech.ac.jp;hontani@nitech.ac.jp;qibin.zhao@riken.jp;a.cichocki@riken.jp,6;6;6,,Reject,0,10,0,yes,9/25/19,Nagoya Institute of Technology;Nagoya Institute of Technology;RIKEN;RIKEN,Deep image prior;Manifold model;Auto-encoder;Convolutional neural network;Delay-embedding;Hankelization;Tensor completion;Image inpainting;Supperresolution,-1;-1;-1;-1,1157;1157;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Self-Imitation Learning via Trajectory-Conditioned Policy for Hard-Exploration Tasks,Yijie Guo;Jongwook Choi;Marcin Moczulski;Samy Bengio;Mohammad Norouzi;Honglak Lee,guoyijie@umich.edu;jwook@umich.edu;moczulski@google.com;bengio@google.com;mnorouzi@google.com;honglak@google.com,6;1;3,,Reject,0,5,0,yes,9/25/19,University of Michigan;University of Michigan;Google;Google;Google;Google,imitation learning;hard-exploration tasks;exploration and exploitation,7;7;-1;-1;-1;-1,21;21;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Improving Semantic Parsing with Neural Generator-Reranker Architecture,Huseyin A. Inan;Gaurav Singh Tomar;Huapu Pan,hinan1@stanford.edu;gtomar@google.com;huapupan@google.com,3;1;3,,Reject,0,5,0,yes,9/25/19,Stanford University;Google;Google,Natural Language Processing;Semantic Parsing;Neural Reranking,5;-1;-1,4;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Make Generalizable and Diverse Predictions for Retrosynthesis,Benson Chen;Tianxiao Shen;Tommi S. Jaakkola;Regina Barzilay,bensonc@mit.edu;tianxiao@mit.edu;tommi@csail.mit.edu;regina@csail.mit.edu,6;6;1,,Reject,0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Chemistry;Retrosynthesis;Transformer;Pre-training;Diversity,5;5;5;5,5;5;5;5,m;f,usa,usa,n
ICLR,2020,Benefit of Interpolation in Nearest Neighbor Algorithms,Yue Xing;Qifan Song;Guang Cheng,xing49@purdue.edu;qfsong@purdue.edu;chengg@purdue.edu,6;1;3,,Reject,0,5,0,yes,9/25/19,Purdue University;Purdue University;Purdue University,Data Interpolation;Multiplicative Constant;W-Shaped Double Descent;Nearest Neighbor Algorithm,24;24;24,88;88;88,f;m,usa,usa,y
ICLR,2020,Learning to Reach Goals Without Reinforcement Learning,Dibya Ghosh;Abhishek Gupta;Justin Fu;Ashwin Reddy;Coline Devin;Benjamin Eysenbach;Sergey Levine,dibya.ghosh@berkeley.edu;abhigupta@berkeley.edu;justinjfu@eecs.berkeley.edu;adreddy@berkeley.edu;coline@berkeley.edu;beysenba@cs.cmu.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,8,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;Carnegie Mellon University;University of California Berkeley,Reinforcement Learning;Goal Reaching;Imitation Learning,-1;-1;-1;-1;-1;1;-1,13;13;13;13;13;27;13,m;m,usa,usa,y
ICLR,2020,Refining the variational posterior through iterative optimization,Marton Havasi;Jasper Snoek;Dustin Tran;Jonathan Gordon;Jos√© Miguel Hern√°ndez-Lobato,mh740@cam.ac.uk;jsnoek@google.com;trandustin@google.com;jg801@cam.ac.uk;jmh233@cam.ac.uk,6;3;6;6,,Reject,0,8,0,yes,9/25/19,University of Cambridge;Google;Google;University of Cambridge;University of Cambridge,uncertainty estimation;variational inference;auxiliary variables;Bayesian neural networks,79;-1;-1;79;79,3;-1;-1;3;3,m;m,europe,uk,n
ICLR,2020,Off-policy Bandits with Deficient Support,Noveen Sachdeva;Yi Su;Thorsten Joachims,ernoveen@gmail.com;ys756@cornell.edu;tj@cs.cornell.edu,6;3;3,,Reject,0,5,0,yes,9/25/19,International Institute of Information Technology Hyderabad;Cornell University;Cornell University,Recommender System;Search Engine;Counterfactual Learning,-1;7;7,-1;19;19,m;m,usa,usa,y
ICLR,2020,iSparse: Output Informed Sparsification of Neural Networks,Yash Garg;K. Selcuk Candan,ygarg@asu.edu;candan@asu.edu,1;3;3,,Reject,0,3,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,dropout;dropconnect;sparsification;deep learning;neural network,-1;-1,299;299,m;m,NAN,NAN,n
ICLR,2020,Towards understanding the true loss surface of deep neural networks using random matrix theory and iterative spectral methods,Diego Granziol;Timur Garipov;Dmitry Vetrov;Stefan Zohren;Stephen Roberts;Andrew Gordon Wilson,diego@robots.ox.ac.uk;timgaripov@gmail.com;vetrovd@yandex.ru;zohren@robots.ox.ac.uk;sjrob@robots.ox.ac.uk;andrewgw@cims.nyu.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,University of Oxford;Massachusetts Institute of Technology;Higher School of Economics;University of Oxford;University of Oxford;New York University,Random Matrix theory;deep learning;deep learning theory;hessian eigenvalues;true risk,46;5;-1;46;46;22,1;5;-1;1;1;29,m;m,usa,usa,y
ICLR,2020,PROTOTYPE-ASSISTED ADVERSARIAL LEARNING FOR UNSUPERVISED DOMAIN ADAPTATION,Dapeng Hu;Jian Liang*;Qibin Hou;Hanshu Yan;Jiashi Feng,dapeng.hu@u.nus.edu;liangjian92@gmail.com;andrewhoux@gmail.com;hanshu.yan@u.nus.edu;elefjia@nus.edu.sg,3;3,,Reject,0,5,0,yes,9/25/19,National University of Singapore;;National University of Singapore;National University of Singapore;National University of Singapore,Domain Adaptation;Transfer Learning;Adversarial Learning,17;-1;17;17;17,25;-1;25;25;25,m;m,asia,sg,n
ICLR,2020,Likelihood Contribution based Multi-scale Architecture for Generative Flows,Hari Prasanna Das;Pieter Abbeel;Costas J. Spanos,hpdas@eecs.berkeley.edu;pabbeel@cs.berkeley.edu;spanos@eecs.berkeley.edu,3;3;3,,Reject,0,10,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Generative Flow;Normalizing Flow;Multi-scale Architecture;RealNVP;Dimension Factorization,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Understanding Top-k Sparsification in Distributed Deep Learning,Shaohuai Shi;Xiaowen Chu;Ka Chun Cheung;Simon See,csshshi@comp.hkbu.edu.hk;chxw@comp.hkbu.edu.hk;chcheung@nvidia.com;ssee@nvidia.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Boston University;Boston University;NVIDIA;NVIDIA,Distributed Deep Learning;SGD;Gradient Sparsification;Communication-efficient SGD;Top-k,79;79;-1;-1,61;61;-1;-1,m;m,NAN,NAN,n
ICLR,2020,AN ATTENTION-BASED DEEP NET FOR LEARNING TO RANK,Diego Klabjan;Baiyang Wang,d-klabjan@northwestern.edu;baiyang@u.northwestern.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,Northwestern University;Northwestern University,learning to rank;deep learning,46;46,22;22,m;m,usa,usa,n
ICLR,2020,Modeling question asking using neural program generation,Ziyun Wang;Brenden M. Lake,ziyunw@nyu.edu;brenden@nyu.edu,6;1;6,,Reject,0,5,0,yes,9/25/19,New York University;New York University,question asking;language generation;program induction;reinforcement learning;density estimation;cognitive science,22;22,29;29,m;m,usa,usa,n
ICLR,2020,Acutum: When Generalization Meets Adaptability,Xunpeng Huang;Zhengyang Liu;Zhe Wang;Yue Yu;Lei Li,huangxunpeng@bytedance.com;liuzhengyang.lozycs@bytedance.com;wang.10982@osu.edu;yuyue.elaine@bytedance.com;lilei.02@bytedance.com,3;1;6,,Reject,0,5,0,yes,9/25/19,ByteDance;ByteDance;Ohio State University;ByteDance;ByteDance,optimization;momentum;adaptive gradient methods,-1;-1;59;-1;-1,-1;-1;70;-1;-1,u;m,NAN,NAN,y
ICLR,2020,Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning,Eric Arazo;Diego Ortego;Paul Albert;Noel E. O'Connor;Kevin McGuinness,eric.arazo@insight-centre.org;diego.ortego@insight-centre.org;paul.albert@insight-centre.org;noel.oconnor@dcu.ie;kevin.mcguinness@dcu.ie,3;8;3,,Reject,0,5,0,yes,9/25/19,Insight Centre for Data Analytics;Insight Centre for Data Analytics;Insight Centre for Data Analytics;Dublin City University;Dublin City University,Semi-supervised learning;pseudo-labeling;deep semi-supervised learning;confirmation bias;image classification,-1;-1;-1;-1;-1,-1;-1;-1;601;601,m;m,NAN,NAN,n
ICLR,2020,Revisiting the Generalization of Adaptive Gradient Methods,Naman Agarwal;Rohan Anil;Elad Hazan;Tomer Koren;Cyril Zhang,namanagarwal@google.com;rohananil@google.com;ehazan@cs.princeton.edu;tkoren@google.com;cyril.zhang@princeton.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,Google;Google;Princeton University;Google;Princeton University,Adaptive Methods;AdaGrad;Generalization,-1;-1;30;-1;30,-1;-1;6;-1;6,m;m,usa,usa,y
ICLR,2020,ConQUR: Mitigating Delusional Bias in Deep Q-Learning,DiJia-Andy Su;Jayden Ooi;Tyler Lu;Dale Schuurmans;Craig Boutilier‚Äé,andy.2008.su@gmail.com;jayden@alum.mit.edu;tyler.lu@gmail.com;schuurmans@google.com;cboutilier@google.com,3;3;6,,Reject,0,4,0,yes,9/25/19,Princeton University;Massachusetts Institute of Technology;Google;Google;Google,reinforcement learning;q-learning;deep reinforcement learning;Atari,-1;5;-1;-1;-1,-1;5;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Weight-space symmetry in neural network loss landscapes revisited,Berfin Simsek;Johanni Brea;Bernd Illing;Wulfram Gerstner,berfin.simsek@epfl.ch;johanni.brea@epfl.ch;bernd.illing@epfl.ch;wulfram.gerstner@epfl.ch,3;6;3,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Weight-space symmetry;neural network landscapes,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Collaborative Filtering With A Synthetic Feedback Loop,Wenlin Wang;Hongteng Xu;Ruiyi Zhang;Wenqi Wang;Lawrence Carin,wlwang616@gmail.com;hongtengxu313@gmail.com;ryzhang@cs.duke.edu;wenqiwang@fb.com,6;3;3,,Reject,0,0,0,yes,9/25/19,"Duke University;University of Illinois, Urbana-Champaign;Duke University;Facebook",,-1;-1;46;-1,-1;-1;20;-1,m;m,NAN,NAN,n
ICLR,2020,Empowering Graph Representation Learning with Paired Training and Graph Co-Attention,Andreea Deac;Yu-Hsiang Huang;Petar Velickovic;Pietro Lio;Jian Tang,deacandr@mila.quebec;huang.yu-hsiang@courrier.uqam.ca;petar.velickovic@cst.cam.ac.uk;pl219@cam.ac.uk;jian.tang@hec.ca,3;3;3,,Reject,0,3,0,yes,9/25/19,Mila;UQAM;University of Cambridge;University of Cambridge;HEC Montreal,graph neural networks;graph co-attention;paired graphs;molecular properties;drug-drug interaction,143;-1;79;79;-1,336;-1;3;3;-1,f;m,canada,ca,n
ICLR,2020,Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models,Yiding Feng;Ekaterina Khmelnitskaya;Denis Nekipelov,yidingfeng2021@u.northwestern.edu;eak5rf@virginia.edu;denis@virginia.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,Northwestern University;University of Virginia;University of Virginia,Reinforcement learning;Policy Gradient;Global Concavity;Dynamic Discrete Choice Model,46;52;52,22;107;107,m;m,usa,usa,y
ICLR,2020,Training Provably Robust Models by Polyhedral Envelope Regularization,Chen Liu;Mathieu Salzmann;Sabine S√ºsstrunk,chen.liu@epfl.ch;mathieu.salzmann@epfl.ch;sabine.susstrunk@epfl.ch,3;8;3,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,deep learning;adversarial attack;robust certification,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,y
ICLR,2020,Unifying Graph Convolutional Networks as Matrix Factorization,Zhaocheng Liu;Qiang Liu;Haoli Zhang;Jun Zhu,zhaocheng.liu@realai.ai;qiang.liu@realai.ai;haoli.zhang@realai.ai;dcszj@mail.tsinghua.edu.cn,1;6;1,,Reject,0,7,0,yes,9/25/19,"RealAI;RealAI;RealAI;Tsinghua University, Tsinghua University",graph convolutional networks;matrix factorization;unification,-1;-1;-1;4,-1;-1;-1;23,u;m,NAN,NAN,n
ICLR,2020,Adversarial Inductive Transfer Learning with input and output space adaptation,Hossein Sharifi-Noghabi;Shuman Peng;Olga Zolotareva;Colin C. Collins;Martin Ester,hsharifi@sfu.ca;shumanp@sfu.ca;ozolotareva@techfak.uni-bielefeld.de;ccollins@prostatecentre.com;ester@sfu.ca,3;3;6,,Reject,0,4,0,yes,9/25/19,Simon Fraser University;Simon Fraser University;Bielefeld University;Prostatecentre;Simon Fraser University,Inductive transfer learning;adversarial learning;multi-task learning;pharmacogenomics;precision oncology,52;52;316;-1;52,272;272;166;-1;272,m;m,canada,ca,n
ICLR,2020,Leveraging Simple Model Predictions for Enhancing its Performance,Amit Dhurandhar;Karthikeyan Shanmugam;Ronny Luss,adhuran@us.ibm.com;karthikeyan.shanmugam2@ibm.com;rluss@us.ibm.com,6;6;6;1,,Reject,1,5,0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines,simple models;interpretability;resource constraints,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Transfer via Modelling Multi-level Task Dependency,Haonan Wang;Zhenbang Wu;Ziniu Hu;Yizhou Sun,haonan3@illinois.edu;zw12@illinois.edu;bull@cs.ucla.edu;yzsun@cs.ucla.edu,1;3;3;3,,Reject,0,4,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of California, Los Angeles;University of California, Los Angeles",multi-task learning;attention mechanism,-1;-1;-1;-1,-1;-1;17;17,m;f,usa,usa,n
ICLR,2020,Disentangling Style and Content in Anime Illustrations,Sitao Xiang;Hao Li,sitaoxia@usc.edu;hao@hao-li.com,3;6;3,,Reject,0,6,0,yes,9/25/19,University of Southern California;Hao-li,Adversarial Training;Generative Models;Style Transfer;Anime,36;-1,62;-1,u;u,NAN,NAN,n
ICLR,2020,Targeted sampling of enlarged neighborhood via Monte Carlo tree search for TSP,Zhang-Hua Fu;Kai-Bin Qiu;Meng Qiu;Hongyuan Zha,fuzhanghua@cuhk.edu.cn;20150008030@m.scnu.edu.cn;qiumeng.sz@gmail.com;zhahy@cuhk.edu.cn,1;1;3,,Reject,0,0,0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen;East China Normal University;;The Chinese University of Hong Kong, Shenzhen",Travelling salesman problem;Monte Carlo tree search;Reinforcement learning;Variable neighborhood search,46;-1;-1;46,35;544;-1;35,u;m,NAN,NAN,n
ICLR,2020,S2VG: Soft Stochastic Value Gradient method,Xiaoyu Tan;Chao Qu;Junwu Xiong;James Zhang,xiaoyu_tan@u.nus.edu;chaoqu.technion@gmail.com;junwu.xjw@antfin.com;james.z@antfin.com,1;1;3,,Reject,0,3,0,yes,9/25/19,National University of Singapore;;Antfin;Antfin,Model-based reinforcement learning;soft stochastic value gradient,17;-1;-1;-1,25;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,Learning to Defense by Learning to Attack,Zhehui Chen;Haoming Jiang;Yuyang Shi;Bo Dai;Tuo Zhao,zhchen@gatech.edu;jianghm@gatech.edu;yyshi@gatech.edu;bodai@google.com;tourzhao@gatech.edu,6;3;6,,Reject,0,5,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Google;Georgia Institute of Technology,,13;13;13;-1;13,38;38;38;-1;38,m;m,usa,usa,n
ICLR,2020,Model Architecture Controls Gradient Descent Dynamics: A Combinatorial Path-Based Formula,Xin Zhou;Newsha Ardalani,chow459@gmail.com;newsha@baidu.com,3;6;3,,Reject,0,5,0,yes,9/25/19,University of Michigan;Baidu,,-1;-1,-1;-1,u;f,NAN,NAN,y
ICLR,2020,Natural- to formal-language generation using Tensor Product Representations,Kezhen Chen;Qiuyuan Huang;Hamid Palangi;Paul Smolensky;Kenneth D. Forbus;Jianfeng Gao,kezhenchen2021@u.northwestern.edu;qihua@microsoft.com;hpalangi@microsoft.com;paul.smolensky@gmail.com;forbus@northwestern.edu;jfgao@microsoft.com,8;3;3,,Reject,0,8,0,yes,9/25/19,Northwestern University;Microsoft;Microsoft;Microsoft;Northwestern University;Microsoft,Neural Symbolic Reasoning;Deep Learning;Natural Language Processing;Structural Representation;Interpretation of Learned Representations,46;-1;-1;-1;46;-1,22;-1;-1;-1;22;-1,u;m,NAN,NAN,n
ICLR,2020,Unsupervised Out-of-Distribution Detection with Batch Normalization,Jiaming Song;Yang Song;Stefano Ermon,jiaming.tsong@gmail.com;yangsong@cs.stanford.edu;ermon@cs.stanford.edu,1;6;1,,Reject,0,0,0,yes,9/25/19,Stanford University;Stanford University;Stanford University,,5;5;5,4;4;4,m;m,usa,usa,y
ICLR,2020,Distribution Matching Prototypical Network for Unsupervised Domain Adaptation,Lei Zhu;Wei Wang;Mei Hui Zhang;Beng Chin Ooi;Chang Yao,e0203764@u.nus.edu;wangwei@comp.nus.edu.sg;meihui_zhang@bit.edu.cn;ooibc@comp.nus.edu.sg;yaochang@zjuici.com,3;3;1,,Reject,0,10,0,yes,9/25/19,National University of Singapore;National University of Singapore;Beijing Institute of Technology;National University of Singapore;Zjuici,Deep Learning;Unsupervised Domain Adaptation;Distribution Modeling,17;17;-1;17;-1,25;25;661;25;-1,m;m,NAN,NAN,n
ICLR,2020,Deep Hierarchical-Hyperspherical Learning (DH^2L),Youngsung Kim;Jae-Joon Han,yskim.ee@gmail.com;jae-joon.han@samsung.com,3;6;3,,Reject,0,4,0,yes,9/25/19,Samsung;Samsung,,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Markov Logic Networks,Giuseppe Marra;Ond≈ôej Ku≈æelka,g.marra@unifi.it;kuzelo1@gmail.com,6;1;6,,Reject,0,3,0,yes,9/25/19,Universit√† di Firenze;Czech Technical University in Prague,Statistical Relational Learning;Markov Logic Networks,-1;168,-1;956,m;m,NAN,NAN,n
ICLR,2020,Deep Randomized Least Squares Value Iteration,Guy Adam;Tom Zahavy;Oron Anschel;Nahum Shimkin,guyadam3@gmail.com;tomzahavy@gmail.com;oronanschel@gmail.com;shimkin@ee.technion.ac.il,1;3;1,,Reject,0,6,0,yes,9/25/19,"Technion, Technion;DeepMind;Amazon;Technion, Technion",Thompson Sampling;Deep Learning;Reinforcement Learning,27;-1;-1;27,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Safe Policy Learning for Continuous Control,Yinlam Chow;Ofir Nachum;Aleksandra Faust;Edgar Duenez-Guzman;Mohammad Ghavamzadeh,yinlamchow@google.com;ofirnachum@google.com;sandrafaust@google.com;duenez@google.com;mgh@fb.com,6;8;6,,Reject,0,6,2,yes,9/25/19,Google;Google;Google;Google;Facebook,reinforcement learning;policy gradient;safety,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Unsupervised Distillation of Syntactic Information from Contextualized Word Representations,Shauli Ravfogel;Yanai Elazar;Jacob Goldberger;Yoav Goldberg,shauli.ravfogel@gmail.com;yanaiela@gmail.com;jacob.goldberger@biu.ac.il;yogo@cs.biu.ac.il,6;8;6;1,,Reject,0,12,0,yes,9/25/19,Bar Ilan University;Bar Ilan University;Bar Ilan University;Bar Ilan University,dismantlement;contextualized word representations;language models;representation learning,-1;102;102;102,-1;513;513;513,m;m,europe,il,n
ICLR,2020,Discriminator Based Corpus Generation for General Code Synthesis,Alexander Wild;Barry Porter,a.wild3@lancaster.ac.uk;b.f.porter@lancaster.ac.uk,1;1;1,,Reject,2,1,0,yes,9/25/19,Lancaster University;Lancaster University,Code Synthesis;Neural Code Synthesis,248;248,140;140,m;m,europe,uk,n
ICLR,2020,Situating Sentence Embedders with Nearest Neighbor Overlap,Lucy H. Lin;Noah A. Smith,lucylin@cs.washington.edu;nasmith@cs.washington.edu,3;1;1,,Reject,0,2,0,yes,9/25/19,University of Washington;University of Washington,sentence embeddings;nearest neighbors;semantic similarity,11;11,26;26,f;m,usa,usa,n
ICLR,2020,Lattice Representation Learning,Luis A Lastras,lastrasl@us.ibm.com,3;3;3,,Reject,0,3,0,yes,9/25/19,International Business Machines,lattices;representation learning;coding theory;lossy source coding;information theory,-1,-1,m;u,NAN,NAN,y
ICLR,2020,Towards Understanding the Transferability of Deep Representations,Hong Liu;Mingsheng Long;Jianmin Wang;Michael I. Jordan,h-l17@mails.tsinghua.edu.cn;mingsheng@tsinghua.edu.cn;jimwang@tsinghua.edu.cn;jordan@cs.berkeley.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of California Berkeley",Transfer Learning;Fine-tuning;Deep Neural Networks,4;4;4;-1,23;23;23;13,m;m,usa,usa,y
ICLR,2020,Improved Training of Certifiably Robust Models,Chen Zhu;Renkun Ni;Ping-yeh Chiang;Hengduo Li;Furong Huang;Tom Goldstein,chenzhu@cs.umd.edu;rn9zm@cs.umd.edu;pingyeh.chiang@gmail.com;hdli@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,6;3;3,,Reject,0,6,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",Convex Relaxation;Certified Robustness;Regularization,12;12;12;12;12;12,91;91;91;91;91;91,m;m,usa,usa,y
ICLR,2020,Learning from Label Proportions with Consistency Regularization,Kuen-Han Tsai;Hsuan-Tien Lin,r06922066@csie.ntu.edu.tw;htlin@csie.ntu.edu.tw,3;6;3,,Reject,0,4,0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University,learning from label proportions;consistency regularization;semi-supervised learning,43;43,49;49,u;m,asia,sg,n
ICLR,2020,Learning Compact Embedding Layers via Differentiable Product Quantization,Ting Chen;Lala Li;Yizhou Sun,iamtingchen@gmail.com;lala@google.com;yzsun@cs.ucla.edu,3;6;3,,Reject,0,6,0,yes,9/25/19,"Google;Google;University of California, Los Angeles",efficient modeling;compact embedding;embedding table compression;differentiable product quantization,-1;-1;-1,-1;-1;17,m;f,usa,usa,y
ICLR,2020,{COMPANYNAME}11K: An Unsupervised Representation Learning Dataset for Arrhythmia Subtype Discovery,Shawn Tan;Guillaume Androz;Ahmad Chamseddine;Pierre Fecteau;Aaron Courville;Yoshua Bengio;Joseph Paul Cohen,shawn@wtf.sg;guillaume.androz@icentia.com;doctor.ahmad89@gmail.com;pierre.fecteau@icentia.com;aaron.courville@gmail.com;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,3;3,,Reject,0,2,1,yes,9/25/19,University of Montreal;Icentia Inc.;;Icentia;University of Montreal;Mila;Stanford University,representation learning;healthcare;medical;clinical;dataset;ecg;cardiology;heart;discovery;anomaly detection;out of distribution,-1;-1;-1;-1;118;143;5,-1;-1;-1;-1;85;336;4,m;m,usa,usa,n
ICLR,2020,NADS: Neural Architecture Distribution Search for Uncertainty Awareness,Randy Ardywibowo;Shahin Boluki;Xinyu Gong;Zhangyang Wang;Xiaoning Qian,randyardywibowo@tamu.edu;s.boluki@tamu.edu;gong1994@tamu.edu;atlaswang@tamu.edu;xqian@tamu.edu,8;1;3,,Reject,0,4,1,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;Texas A&M;Texas A&M,Neural Architecture Search;Bayesian ensembling;out-of-distribution detection;uncertainty quantification;density estimation,46;46;46;46;46,177;177;177;177;177,m;m,NAN,NAN,n
ICLR,2020,Learning World Graph Decompositions To Accelerate Reinforcement Learning,Wenling Shang;Alex Trott;Stephan Zheng;Caiming Xiong;Richard Socher,w.shang@uva.nl;atrott@salesforce.com;stephan.zheng@salesforce.com;cxiong@salesforce.com;richard@socher.org,6;3;3,,Reject,0,8,0,yes,9/25/19,University of Amsterdam;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,environment decomposition;subgoal discovery;generative modeling;reinforcement learning;unsupervised learning,143;-1;-1;-1;-1,62;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Group-Transformer: Towards A Lightweight Character-level Language Model,Sungrae Park;Geewook Kim;Junyeop Lee;Junbum Cha;Ji-Hoon Kim Hwalsuk Lee,sungrae.park@navercorp.com;geewook@sys.i.kyoto-u.ac.jp;junyeop.lee@navercorp.com;junbum.cha@navercorp.com;genesis.kim@navercorp.com;hwalsuk.lee@navercorp.com,6;6;1,,Reject,0,10,0,yes,9/25/19,NAVER;Kyoto University;NAVER;NAVER;NAVER;NAVER,Transformer;Lightweight model;Language Modeling;Character-level language modeling,-1;168;-1;-1;-1;-1,-1;65;-1;-1;-1;-1,m;m,europe,gr,n
ICLR,2020,Learning DNA folding patterns with Recurrent Neural Networks ,Michal Rozenwald;Aleksandra Galitsyna;Ekaterina Khrameeva;Grigory Sapunov;Mikhail S. Gelfand,michal.rozenwald@gmail.com;agalitzina@gmail.com;ekhrameeva@gmail.com;grigory.sapunov@gmail.codelfm;mikhail.gelfand@gmail.com,1;3;3,,Reject,0,5,0,yes,9/25/19,Higher School of Economics;;;;Higher School of Economics,Machine Learning;Recurrent Neural Networks;3D chromatin structure;topologically associating domains;computational biology.,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,asia,in,n
ICLR,2020,TSInsight: A local-global attribution framework for interpretability in time-series data,Shoaib Ahmed Siddiqui;Dominique Mercier;Andreas Dengel;Sheraz Ahmed,shoaib_ahmed.siddiqui@dfki.de;dominique.mercier@dfki.de;andreas.dengel@dfki.de;sheraz.ahmed@dfki.de,3;1;1,,Reject,0,7,0,yes,9/25/19,German Research Center for AI;German Research Center for AI;German Research Center for AI;German Research Center for AI,Deep Learning;Representation Learning;Convolutional Neural Networks;Time-Series Analysis;Feature Importance;Visualization;Demystification,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Imagining the Latent Space of a Variational Auto-Encoders,Zezhen Zeng;Jonathon Hare;Adam Pr√ºgel-Bennett,zz8n17@ecs.soton.ac.uk;jsh2@ecs.soton.ac.uk;apb@ecs.soton.ac.uk,3;3;1,,Reject,0,5,0,yes,9/25/19,University of Southampton;University of Southampton;University of Southampton,VAE;GAN,194;194;194,122;122;122,m;m,europe,uk,n
ICLR,2020,Quantum Semi-Supervised Kernel Learning,Seyran Saeedi;Aliakbar Panahi;Tom Arodz,saeedis@vcu.edu;panahia@vcu.edu;tarodz@vcu.edu,6;6;6,,Reject,0,3,0,yes,9/25/19,Virginia Commonwealth University;Virginia Commonwealth University;Virginia Commonwealth University,quantum machine learning;semi-supervised learning;support vector machines,248;248;248,-1;-1;-1,f;m,usa,usa,n
ICLR,2020,Interpretable Network Structure for Modeling Contextual Dependency,Xindian Ma;Peng Zhang;Xiaoliu Mao;Yehua Zhang;Nan Duan;Yuexian Hou;Ming Zhou.,xindianma@tju.edu.cn;pzhang@tju.edu.cn;xiaoliumao@tju.edu.cn;yehua_zhang@tju.edu.cn;nanduan@microsoft.com;yxhou@tju.edu.cn;mingzhou@microsoft.com,3;1;3,,Reject,0,3,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Microsoft;Zhejiang University;Microsoft,Language Model;Recurrent Neural Network;Separation Rank,39;39;39;39;-1;39;-1,107;107;107;107;-1;107;-1,u;m,NAN,NAN,n
ICLR,2020,Frequency Principle: Fourier Analysis Sheds Light on Deep Neural Networks,Zhi-Qin John Xu;Yaoyu Zhang;Tao Luo;Yanyang Xiao;Zheng Ma,xuzhiqin@sjtu.edu.cn;yaoyu@ias.edu;luo196@purdue.edu;xyy82148@gmail.com;ma531@purdue.edu,6;3;3,,Reject,0,5,0,yes,9/25/19,"Shanghai Jiao Tong University;Institue for Advanced Study, Princeton;Purdue University;;Purdue University",deep learning;training behavior;Fourier analysis;generalization,30;-1;24;-1;24,157;-1;88;-1;88,m;m,usa,usa,n
ICLR,2020,S-Flow GAN,Miron Yakov;Coscas Yona,yakov.miron@gmail.com;yona.coscas@gmail.com,1;3;1,,Reject,0,0,0,yes,9/25/19,Tel Aviv University;Elbit Systems Ltd,GAN;Image Generation;AI;Generative Models;CV,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Role of two learning rates in convergence of model-agnostic meta-learning,Shiro Takagi;Yoshihiro Nagano;Yuki Yoshida;Masato Okada,takagi@mns.k.u-tokyo.ac.jp;nagano@mns.k.u-tokyo.ac.jp;yoshida@mns.k.u-tokyo.ac.jp;okada@edu.k.u-tokyo.ac.jp,3;3;1,,Reject,0,8,0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,meta-learning;convergence,64;64;64;64,36;36;36;36,m;m,NAN,NAN,n
ICLR,2020,Neural Subgraph Isomorphism Counting,Xin Liu;Haojie Pan;Mutian He;Yangqiu Song;Xin Jiang,xliucr@cse.ust.hk;hpanad@cse.ust.hk;mhear@cse.ust.hk;yqsong@cse.ust.hk;jiang.xin@huawei.com,6;3;3;3,,Reject,0,5,0,yes,9/25/19,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Huawei Technologies Ltd.,subgraph isomorphism;graph neural networks,-1;-1;-1;-1;-1,47;47;47;47;-1,m;m,NAN,NAN,n
ICLR,2020,Semantic Hierarchy Emerges in the Deep Generative Representations for Scene Synthesis,Ceyuan Yang;Yujun Shen;Bolei Zhou,limbo0066@gmail.com;sy116@ie.cuhk.edu.hk;bzhou@ie.cuhk.edu.hk,6;3;6,,Reject,0,5,0,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,Feature visualization;feature interpretation;generative models,-1;316;316,-1;35;35,m;m,NAN,NAN,n
ICLR,2020,Decoupling Adaptation from Modeling with Meta-Optimizers for Meta Learning,S√©bastien M.R. Arnold;Shariq Iqbal;Fei Sha,arnolds@usc.edu;shariqiqbal2810@gmail.com;fsha@google.com,3;3;6,,Reject,0,7,0,yes,9/25/19,University of Southern California;University of Southern California;Google,meta-learning;MAML;analysis;depth;meta-optimizers,36;36;-1,62;62;-1,m;f,NAN,NAN,n
ICLR,2020,Black-box Adversarial Attacks with Bayesian Optimization,Satya Narayan Shukla;Anit Kumar Sahu;Devin Willmott;J. Zico Kolter,snshukla@cs.umass.edu;anit.sahu@gmail.com;devin.willmott@uky.edu;zkolter@cs.cmu.edu,6;3;1,,Reject,0,6,0,yes,9/25/19,"University of Massachusetts, Amherst;Amazon;University of Kentucky;Carnegie Mellon University",black-box adversarial attacks;bayesian optimization,24;-1;194;1,209;-1;490;27,m;m,usa,usa,n
ICLR,2020,Adversarial Imitation Attack,Mingyi Zhou;Jing Wu;Yipeng Liu;Xiaolin Huang;Shuaicheng Liu;Liaqat Ali;Xiang Zhang;Ce Zhu,zhoumingyi@std.uestc.edu.cn;wujing@std.uestc.edu.cn;yipengliu@uestc.edu.cn;xiaolinhuang@sjtu.edu.cn;liushuaicheng@uestc.edu.cn;engr_liaqat183@yahoo.com;uestchero@uestc.edu.cn;eczhu@uestc.edu.cn,6;3;3,,Reject,0,3,0,yes,9/25/19,University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Shanghai Jiao Tong University;University of Electronic Science and Technology of China;;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China,Adversarial examples;Security;Machine learning;Deep neural network;Computer vision,-1;-1;-1;30;-1;-1;-1;-1,628;628;628;157;628;-1;628;628,u;m,NAN,NAN,n
ICLR,2020,LOGAN:  Latent Optimisation for Generative Adversarial Networks,Yan Wu;Jeff Donahue;David Balduzzi;Karen Simonyan;Timothy Lillicrap,yanwu@google.com;jeffdonahue@google.com;dbalduzzi@google.com;simonyan@google.com;countzero@google.com,6;6,,Reject,0,2,2,yes,9/25/19,Google;Google;Google;Google;Google,GAN;adversarial training;generative model;game theory,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Searching for Stage-wise Neural Graphs In the Limit,Xin Zhou;Dejing Dou;Boyang Li,chow459@gmail.com;doudejing@baidu.com;libo0001@gmail.com,3;1,,Reject,0,3,0,yes,9/25/19,University of Michigan;Baidu;Nanyang Technological University,neural architecture search;graphon;random graphs,-1;-1;43,-1;-1;49,m;m,asia,sg,y
ICLR,2020,Attention Interpretability Across NLP Tasks,Shikhar Vashishth;Shyam Upadhyay;Gaurav Singh Tomar;Manaal Faruqui,shikhar@iisc.ac.in;shyamupa@google.com;gtomar@google.com;mfaruqui@google.com,6;6;1,,Reject,1,5,0,yes,9/25/19,Indian Institute of Science;Google;Google;Google,Attention;NLP;Interpretability,-1;-1;-1;-1,301;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,LSTOD: Latent Spatial-Temporal Origin-Destination prediction model and its applications in ride-sharing platforms,Fan Zhou;Haibo Zhou;Hongtu Zhu,zhoufan@mail.shufe.edu.cn;zhou@bios.unc.edu;zhuhongtu@didiglobal.com,1;6;1,,Reject,0,3,0,yes,9/25/19,"Shanghai University of Finance and Economics;University of North Carolina, Chapel Hill;Didi Chuxing",Origin-Destination Flow;Spatial Adjacent Convolution Network;Periodically Shift Attention Mechanism,-1;64;-1,852;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unsupervised Universal Self-Attention Network for Graph Classification,Dai Quoc Nguyen;Tu Dinh Nguyen;Dinh Phung,dai.nguyen@monash.edu;tu.dinh.nguyen@monash.edu;dinh.phung@monash.edu,3;1;3,,Reject,6,7,0,yes,9/25/19,Monash University;Monash University;Monash University,Graph embedding;graph classification;universal self-attention network;graph neural network,92;92;92,75;75;75,m;m,australasia,au,n
ICLR,2020,Efficacy of Pixel-Level OOD Detection for Semantic Segmentation,Matt Angus;Krzysztof Czarnecki;Rick Salay,m2angus@gsd.uwaterloo.ca;rsalay@gsd.uwaterloo.ca;k2czarne@gsd.uwaterloo.ca,3;1;3,,Reject,0,0,0,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo,Out-of-Distribution Detection;Semantic Segmentation;Deep Learning,30;30;30,235;235;235,m;m,canada,ca,n
ICLR,2020,CURSOR-BASED ADAPTIVE QUANTIZATION FOR DEEP NEURAL NETWORK,Bapu Li(*);Yanwen Fan(*);Zhiyu Cheng;Yingze Bao (* means equal contribution),baopuli@baidu.com;fanyanwen@baidu.com;zhiyucheng@baidu.com;baoyingze@baidu.com,3;6;3,,Reject,0,4,0,yes,9/25/19,Baidu;Baidu;Baidu;Baidu,,-1;-1;-1;-1,-1;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,MMD GAN with Random-Forest Kernels,Tao Huang;Zhen Han;Xu Jia;Hanyuan Hang,tao.huang2018@ruc.edu.cn;handarkholme@ruc.edu.cn;jiayushenyang@gmail.com;hanyuan0725@gmail.com,1;1;3,,Reject,0,0,0,yes,9/25/19,"University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;South China University of Technology;University of Twente",GANs;MMD;kernel;random forest;unbiased gradients,-1;-1;-1;143,-1;-1;501;247,u;u,europe,gr,y
ICLR,2020,Hyperparameter Tuning and Implicit Regularization in Minibatch SGD,Samuel L Smith;Erich Elsen;Soham De,slsmith@google.com;eriche@google.com;sohamde@google.com,3;3;3,,Reject,1,4,0,yes,9/25/19,Google;Google;Google,SGD;momentum;batch size;learning rate;noise;temperature;implicit regularization;optimization;generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Quantum Optical Experiments Modeled by Long Short-Term Memory,Thomas Adler;Manuel Erhard;Mario Krenn;Johannes Brandstetter;Johannes Kofler;Sepp Hochreiter,adler@ml.jku.at;manuel.erhard@univie.ac.at;mario.krenn@univie.ac.at;brandstetter@ml.jku.at;kofler@ml.jku.at;hochreit@ml.jku.at,3;1;1,,Reject,0,0,0,yes,9/25/19,Johannes Kepler University Linz;University of Vienna;University of Vienna;Johannes Kepler University Linz;Johannes Kepler University Linz;Johannes Kepler University Linz,Recurrent Networks;LSTM;Sequence Analysis;Binary Classification,-1;194;194;-1;-1;-1,-1;134;134;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Variational Hashing-based Collaborative Filtering with Self-Masking,Casper Hansen;Christian Hansen;Jakob Grue Simonsen;Stephen Alstrup;Christina Lioma,c.hansen@di.ku.dk;chrh@di.ku.dk;simonsen@di.ku.dk;s.alstrup@di.ku.dk;c.lioma@di.ku.dk,3;3;1,,Reject,0,4,0,yes,9/25/19,University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen,hashing;collaborative filtering;information retrieval;supervised learning,92;92;92;92;92,101;101;101;101;101,m;f,europe,dk,n
ICLR,2020,Customizing Sequence Generation with Multi-Task Dynamical Systems,Alex Bird;Christopher K. I. Williams,abird@turing.ac.uk;ckiw@inf.ed.ac.uk,6;6;6,,Reject,0,4,0,yes,9/25/19,Alan Turing Institute;University of Edinburgh,Time-series modelling;Dynamical systems;RNNs;Multi-task learning,-1;36,-1;30,m;m,europe,uk,n
ICLR,2020,Batch Normalization is a Cause of Adversarial Vulnerability,Angus Galloway;Anna Golubeva;Thomas Tanay;Medhat Moussa;Graham W. Taylor,gallowaa@uoguelph.ca;agolubeva@perimeterinstitute.ca;thomas.tanay.13@ucl.ac.uk;mmoussa@uoguelph.ca;gwtaylor@uoguelph.ca,3;1;3,,Reject,3,8,0,yes,9/25/19,University of Guelph;Perimeter Institute;University College London;University of Guelph;University of Guelph,batch normalization;adversarial examples;robustness,248;-1;52;248;248,558;-1;-1;558;558,m;m,canada,ca,n
ICLR,2020,Enhancing Language Emergence through Empathy,Marie Ossenkopf,mos@vs.uni-kassel.de,1;1;1,,Reject,0,1,0,yes,9/25/19,University of Kassel,multi-agent deep reinforcement learning;emergent communication;auxiliary tasks,445,94,f;u,europe,uk,n
ICLR,2020,A Data-Efficient Mutual Information Neural Estimator for Statistical Dependency Testing,Xiao Lin;Indranil Sur;Samuel A. Nastase;Uri Hasson;Ajay Divakaran;Mohamed R. Amer,xiao.lin@sri.com;indranil.sur@sri.com;mohamed.rabie.amer@gmail.com;ajay.divakaran@sri.com;snastase@princeton.edu;hasson@princeton.edu,1;6;3,,Reject,0,4,0,yes,9/25/19,SRI International;SRI International;Robust.AI;SRI International;Princeton University;Princeton University,mutual information;fMRI;inter-subject correation;mutual information neural estimation;meta-learning;statistical test of dependency,-1;-1;-1;-1;30;30,-1;-1;-1;-1;6;6,m;m,usa,usa,y
ICLR,2020,SMiRL: Surprise Minimizing RL in Entropic Environments,Glen Berseth;Daniel Geng;Coline Devin;Dinesh Jayaraman;Chelsea Finn;Sergey Levine,gberseth@gmail.com;dangengdg@berkeley.edu;coline.devin@gmail.com;dinesh.jayaraman123@gmail.com;cbfinn@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;DeepMind;University of Pennsylvania;University of California Berkeley;University of California Berkeley,intrinsic motivation;reinforcement learning;unsurpervised RL,-1;-1;-1;20;-1;-1,13;13;-1;11;13;13,m;m,usa,usa,n
ICLR,2020,The Role of Embedding Complexity in Domain-invariant Representations,Ching-Yao Chuang;Antonio Torralba;Stefanie Jegelka,cychuang@mit.edu;torralba@mit.edu;stefje@mit.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,domain adaptation;domain-invariant representations;model complexity;theory;deep learning,5;5;5,5;5;5,m;f,usa,usa,y
ICLR,2020,Learning to Infer User Interface Attributes from Images,Philippe Schlattner;Pavol Bielik;Martin Vechev,pschlatt@ethz.ch;pavol.bielik@inf.ethz.ch;martin.vechev@inf.ethz.ch,1;3;8,,Reject,0,8,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Semi-supervised Learning by Coaching,Hieu Pham;Quoc V. Le,hyhieu@cmu.edu;qvl@google.com,3;3;3,,Reject,0,7,0,yes,9/25/19,Carnegie Mellon University;Google,semi-supervised;teacher;student;label propagation;image classification,1;-1,27;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Representations in Reinforcement Learning: an Information Bottleneck Approach,Yingjun Pei;Xinwen Hou,peiyingjun4@gmail.com;xwhou@nlpr.ia.ac.cn,3;6;3,,Reject,0,4,0,yes,9/25/19,"Beijing University of Post and Telecommunication;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",representation learning;reinforcement learning;information bottleneck,-1;30,-1;-1,u;u,NAN,NAN,y
ICLR,2020,Evaluating Lossy Compression Rates of Deep Generative Models,Sicong Huang;Alireza Makhzani;Yanshuai Cao;Roger Grosse,huang@cs.toronto.edu;a.makhzani@gmail.com;yanshuai.cao@borealisai.com;rgrosse@cs.toronto.edu,3;8;3,,Reject,0,4,0,yes,9/25/19,University of Toronto;;Borealis AI;University of Toronto,Deep Learning;Generative Models;Information Theory;Rate Distortion Theory,18;-1;-1;18,18;-1;-1;18,m;m,canada,ca,n
ICLR,2020,Kronecker Attention Networks,Hongyang Gao;Zhengyang Wang;Shuiwang Ji,hongyang.gao@tamu.edu;zhengyang.wang@tamu.edu;sji@tamu.edu,3;3;3,,Reject,0,0,0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M,,46;46;46,177;177;177,m;m,NAN,NAN,y
ICLR,2020,Stochastic Neural Physics Predictor,Piotr Tatarczyk;Damian Mrowca;Li Fei-Fei;Daniel L. K. Yamins;Nils Thuerey,piotr.tatarczyk@tum.de;mrowca@stanford.edu;feifeili@cs.stanford.edu;yamins@stanford.edu;nils.thuerey@tum.de,3;3;6,,Reject,0,4,0,yes,9/25/19,Technical University Munich;Stanford University;Stanford University;Stanford University;Technical University Munich,physics prediction;forward dynamics;stochastic environments;dropout,-1;5;5;5;-1,-1;4;4;4;-1,m;m,NAN,NAN,n
ICLR,2020,Spectral Nonlocal Block for Neural Network,Lei Zhu;Qi She;Lidan Zhang;Ping guo,lei1.zhu@intel.com;qi.she@intel.com;lidan.zhang@intel.com;ping.guo@intel.com,6;6;3;1,,Reject,0,6,0,yes,9/25/19,Intel;Intel;Intel;Intel,Nonlocal Neural Network;Image Classification;Action Recgonition,-1;-1;-1;-1,-1;-1;-1;-1,m;u,NAN,NAN,n
ICLR,2020,Metagross: Meta Gated Recursive Controller Units for Sequence Modeling,Yi Tay;Yikang Shen;Alvin Chan;Yew Soon Ong,ytay017@e.ntu.edu.sg;yikang.shn@gmail.com;guoweial001@e.ntu.edu.sg;asysong@ntu.edu.sg,3;3;3,,Reject,0,0,0,yes,9/25/19,Nanyang Technological University;University of Montreal;Nanyang Technological University;Nanyang Technological University,Deep Learning;Natural Language Processing;Recurrent Neural Networks,43;118;43;43,49;85;49;49,m;m,asia,sg,n
ICLR,2020,Diving into Optimization of Topology in Neural Networks,Kun Yuan;Quanquan Li;Yucong Zhou;Jing Shao;Junjie Yan,yuankun@sensetime.com;liquanquan@sensetime.com;zhouyucong@sensetime.com;shaojing@sensetime.com;yanjunjie@sensetime.com,6;6;3;3,,Reject,0,7,0,yes,9/25/19,SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,The Usual Suspects? Reassessing Blame for VAE Posterior Collapse,Bin Dai;Ziyu Wang;David Wipf,daib13@mails.tsinghua.edu.cn;wzy196@gmail.com;davidwipf@gmail.com,3;8;3,,Reject,0,8,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Amazon",variational autoencoder;posterior collapse,4;4;-1,23;23;-1,m;m,NAN,NAN,y
ICLR,2020,Generative Restricted Kernel Machines,Arun Pandey;Joachim Schreurs;Johan A.K. Suykens,arun.pandey@esat.kuleuven.be;joachim.schreurs@esat.kuleuven.be;johan.suykens@esat.kuleuven.be,6;3;3,,Reject,0,5,1,yes,9/25/19,KU Leuven;KU Leuven;KU Leuven,Generative models;Kernel methods;Deep learning,143;143;143,45;45;45,m;m,europe,be,n
ICLR,2020,GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation,Marc Brockschmidt,mabrocks@microsoft.com,6;8;3,,Reject,0,14,0,yes,9/25/19,Microsoft,Graph Neural Networks,-1,-1,m;u,NAN,NAN,n
ICLR,2020,Which Tasks Should Be Learned Together in Multi-task Learning?,Trevor Standley;Amir R. Zamir;Dawn Chen;Leonidas Guibas;Jitendra Malik;Silvio Savarese,tstand@cs.stanford.edu;zamir@cs.stanford.edu;sdawnchen@gmail.com;guibas@cs.stanford.edu;malik@eecs.berkeley.edu;ssilvio@stanford.edu,6;6;6,,Reject,0,4,0,yes,9/25/19,Stanford University;Stanford University;;Stanford University;University of California Berkeley;Stanford University,multi-task learning;Computer Vision,5;5;-1;5;-1;5,4;4;-1;4;13;4,m;m,usa,usa,n
ICLR,2020,Distillation $\approx$ Early Stopping? Harvesting Dark Knowledge Utilizing Anisotropic Information Retrieval For Overparameterized NN,Bin Dong;Jikai Hou;Yiping Lu;Zhihua Zhang,dongbin@math.pku.edu.cn;houjikai@pku.edu.cn;yplu@stanford.edu;zhzhang@math.pku.edu.cn,3;8;1,,Reject,0,10,0,yes,9/25/19,Peking University;Peking University;Stanford University;Peking University,Distillation;Learning Thoery;Corrupted Label,14;14;5;14,24;24;4;24,m;m,asia,cn,y
ICLR,2020,How Does Learning Rate Decay Help Modern Neural Networks?,Kaichao You;Mingsheng Long;Jianmin Wang;Michael I. Jordan,youkaichao@gmail.com;mingsheng@tsinghua.edu.cn;jimwang@tsinghua.edu.cn;jordan@cs.berkeley.edu,3;1;1,,Reject,0,0,0,yes,9/25/19,"Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of California Berkeley",Learning rate decay;Optimization;Explainability;Deep learning;Transfer learning,-1;4;4;-1,-1;23;23;13,m;m,usa,usa,n
ICLR,2020,Incorporating Horizontal Connections in Convolution by Spatial Shuffling,Ikki Kishida;Hideki Nakayama,kishida@nlab.ci.i.u-tokyo.ac.jp;nakayama@nlab.ci.i.u-tokyo.ac.jp,3;3;3,,Reject,0,0,0,yes,9/25/19,The University of Tokyo;The University of Tokyo,shuffle;convolution;receptive field;classification;horizontal connections,64;64,36;36,m;m,NAN,NAN,n
ICLR,2020,Learning Cluster Structured Sparsity by Reweighting,Yulun Jiang;Lei Yu;Haijian Zhang;Zhou Liu,yljblues@whu.edu.cn;ly.wd@whu.edu.cn;haijian.zhang@whu.edu.cn;liuzhou@whu.edu.cn,1;6;3,,Reject,0,3,0,yes,9/25/19,Wuhan University;Wuhan University;Wuhan University;Wuhan University,Sparse Recovery;Sparse Representation;Structured Sparsity,194;194;194;194,354;354;354;354,u;u,europe,uk,n
ICLR,2020,Continuous Meta-Learning without Tasks,James Harrison;Apoorva Sharma;Chelsea Finn;Marco Pavone,jharrison@stanford.edu;apoorva@stanford.edu;cbfinn@cs.stanford.edu;pavone@stanford.edu,3;6;8,,Reject,0,4,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,Meta-learning;Continual learning;changepoint detection;Bayesian learning,5;5;5;5,4;4;4;4,m;m,usa,usa,n
ICLR,2020,Generative Adversarial Networks For Data Scarcity Industrial Positron Images With Attention,Mingwei Zhu;Min Zhao;Min Yao;Ruipeng Guo,zhumingwei@nuaa.edu.cn;xymzhao@126.com;ym_nuaa@163.com;rpguo@nuaa.edu.cn,1;1;1,,Reject,0,0,0,yes,9/25/19,Nanjing University of Aeronautics and Astronautics;126;163;Nanjing University of Aeronautics and Astronautics,,52;-1;-1;52,1024;-1;-1;1024,u;u,NAN,NAN,n
ICLR,2020,Support-guided Adversarial Imitation Learning,Ruohan Wang;Carlo Ciliberto;Pierluigi Amadori;Yiannis Demiris,r.wang16@ic.ac.uk;c.ciliberto@imperial.ac.uk;p.amadori@imperial.ac.uk;y.demiris@imperial.ac.uk,6;6;1,,Reject,0,3,0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,Adversarial Imitation Learning;Reinforcement Learning;Learning from Demonstrations,52;52;52;52,10;10;10;10,m;m,europe,uk,y
ICLR,2020,IS THE LABEL TRUSTFUL: TRAINING BETTER DEEP LEARNING MODEL VIA UNCERTAINTY MINING NET,Yang Sun;Abhishek Kolagunda;Steven Eliuk;Xiaolong Wang,yang.sun1@ibm.com;abhishek.kolagunda@ibm.com;steven.eliuk@ibm.com;visionxiaolong@gmail.com,3;1;6,,Reject,0,5,0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines,Semi-supervised Learning;Robust Learning;Deep Generative Model,-1;-1;-1;-1,-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Learning with Social Influence through  Interior Policy Differentiation,Hao Sun;Bo Dai;Jiankai Sun;Zhenghao Peng;Guodong Xu;Dahua Lin;Bolei Zhou,sh018@ie.cuhk.edu.hk;doubledaibo@gmail.com;sunjiankai@sensetime.com;pengzh@ie.cuhk.edu.hk;xg018@ie.cuhk.edu.hk;dhlin@ie.cuhk.edu.hk;bzhou@ie.cuhk.edu.hk,3;3;3,,Reject,1,4,0,yes,9/25/19,The Chinese University of Hong Kong;Nanyang Technological University;SenseTime Group Limited;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,Reinforcement Learning;Social Uniqueness;Policy Differentiation,316;43;-1;316;316;316;316,35;49;-1;35;35;35;35,m;m,NAN,NAN,y
ICLR,2020,Selfish Emergent Communication,Michael Noukhovitch;Travis LaCroix;Aaron Courville,michael.noukhovitch@umontreal.ca;tlacroix@uci.edu;aaron.courville@gmail.com,3;1;6,,Reject,0,23,0,yes,9/25/19,"University of Montreal;University of California, Irvine;University of Montreal",multi agent reinforcement learning;emergent communication;game theory,118;-1;118,85;96;85,m;m,canada,ca,n
ICLR,2020,Coordinated Exploration via Intrinsic Rewards for Multi-Agent Reinforcement Learning,Shariq Iqbal;Fei Sha,shariqiqbal2810@gmail.com;fsha@google.com,6;3;3,,Reject,0,3,0,yes,9/25/19,University of Southern California;Google,multi-agent reinforcement learning;multi-agent;exploration;intrinsic motivation;MARL;coordinated exploration,36;-1,62;-1,m;m,NAN,NAN,n
ICLR,2020,Mutual Exclusivity as a Challenge for Deep Neural Networks,Kanishk Gandhi;Brenden Lake,kanishk.gandhi@nyu.edu;brenden@nyu.edu,6;8;6,,Reject,0,8,0,yes,9/25/19,New York University;New York University,Cognitive Science;Deep Learning;Word Learning;Lifelong Learning,22;22,29;29,m;m,usa,usa,n
ICLR,2020,The Differentiable Cross-Entropy Method,Brandon Amos;Denis Yarats,brandon.amos.cs@gmail.com;denisyarats@cs.nyu.edu,3;3;3,,Reject,1,6,0,yes,9/25/19,Facebook;New York University,machine learning;differentiable optimization;control;reinforcement learning,-1;22,-1;29,m;m,usa,usa,y
ICLR,2020,DS-VIC: Unsupervised Discovery of Decision States for Transfer in RL,Nirbhay Modhe;Prithvijit Chattopadhyay;Mohit Sharma;Abhishek Das;Devi Parikh;Dhruv Batra;Ramakrishna Vedantam,nirbhaym@gatech.edu;prithvijit3@gatech.edu;sharma.mohit.916@gmail.com;abhshkdz@gatech.edu;parikh@gatech.edu;dbatra@gatech.edu;ramav@fb.com,3;3;3;3,,Reject,0,6,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Facebook,reinforcement learning;probabilistic inference;variational inference;intrinsic control;transfer learning,13;13;-1;13;13;13;-1,38;38;-1;38;38;38;-1,m;m,NAN,NAN,y
ICLR,2020,Exploration Based Language Learning for Text-Based Games,Andrea Madotto;Mahdi Namazifar;Joost Huizinga;Piero Molino;Adrien Ecoffet;Huaixiu Zheng;Alexandros Papangelis;Dian Yu;Chandra Khatri;Gokhan Tur,amadotto@connect.ust.hk;mahdin@uber.com;jhuizinga@uber.com;piero@uber.com;adrienle@uber.com;huaixiu.zheng@uber.com;apapangelis@uber.com;dianyu@ucdavis.edu;chandrak@uber.com;gokhan@uber.com,6;3;3,,Reject,0,5,0,yes,9/25/19,"The Hong Kong University of Science and Technology;Uber;Uber;Uber;Uber;Uber;Uber;University of California, Davis;Uber;Uber",Text-Based Games;Exploration;Language Learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,47;-1;-1;-1;-1;-1;-1;55;-1;-1,m;m,southamerica,br,n
ICLR,2020,Representation Learning with Multisets,Vasco Portilheiro,vascop@stanford.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,Stanford University,multisets;fuzzy sets;permutation invariant;representation learning;containment;partial order;clustering,5,4,m;u,usa,usa,y
ICLR,2020,Deep Gradient Boosting -- Layer-wise Input Normalization of Neural Networks,Erhan Bilal,ebilal@us.ibm.com,3;3;3,,Reject,1,3,0,yes,9/25/19,International Business Machines,sgd;dgb;boosting;batch norm;input norm,-1,-1,m;u,NAN,NAN,n
ICLR,2020,Multi-Dimensional Explanation of Reviews,Diego Antognini;Claudiu Musat;Boi Faltings,diego.antognini@epfl.ch;claudiu.musat@swisscom.com;boi.faltings@epfl.ch,3;3;6,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swisscom;Swiss Federal Institute of Technology Lausanne,deep learning;explanation;interpretability;reviews;multi-aspect;sentiment analysis;mask,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ISBNet: Instance-aware Selective Branching Networks,Shaofeng Cai;Yao Shu;Wei Wang;Gang Chen;Beng Chin Ooi,shaofeng@comp.nus.edu.sg;shuyao@comp.nus.edu.sg;wangwei@comp.nus.edu.sg;cg@zju.edu.cn;ooibc@comp.nus.edu.sg,3;3,,Reject,0,2,0,yes,9/25/19,National University of Singapore;National University of Singapore;National University of Singapore;Zhejiang University;National University of Singapore,neural networks;neural architecture search;efficient inference,17;17;17;39;17,25;25;25;107;25,m;m,asia,sg,n
ICLR,2020,Inferring Dynamical Systems with Long-Range Dependencies through Line Attractor Regularization,Dominik Schmidt;Georgia Koppe;Max Beutelspacher;Daniel Durstewitz,dominik.schmidt@zi-mannheim.de;georgia.koppe@zi-mannheim.de;max.beutelspacher@mailbox.org;daniel.durstewitz@zi-mannheim.de,3;6;1,,Reject,0,4,0,yes,9/25/19,Central Institute of Mental Health;Central Institute of Mental Health;;Central Institute of Mental Health,Recurrent Neural Networks;Nonlinear State Space Models;Generative Models;Long short-term memory;vanishing/exploding gradient problem;Nonlinear dynamics;Interpretable machine learning;Time series analysis,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,SoftAdam: Unifying SGD and Adam for better stochastic gradient descent,Abraham J. Fetterman;Christina H. Kim;Joshua Albrecht,abe@sourceress.co;christina@sourceress.co;josh@sourceress.co,3;1;3,,Reject,1,3,0,yes,9/25/19,Princeton University;;University of Pittsburgh,Optimization;SGD;Adam;Generalization;Deep Learning,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,BERT-AL: BERT for Arbitrarily Long Document Understanding,Ruixuan Zhang;Zhuoyu Wei;Yu Shi;Yining Chen,903276268@pku.edu.cn;zhuoyu.wei@microsoft.com;yushi@microsoft.com;yining.chen@microsoft.com,3;3;3;6,,Reject,0,0,0,yes,9/25/19,Peking University;Microsoft;Microsoft;Microsoft,,14;-1;-1;-1,24;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,NEURAL EXECUTION ENGINES,Yujun Yan;Kevin Swersky;Danai Koutra;Parthasarathy Ranganathan;Milad Hashemi,yujunyan@umich.edu;kswersky@google.com;dkoutra@umich.edu;parthas@google.com;miladh@google.com,3;3;1,,Reject,0,4,0,yes,9/25/19,University of Michigan;Google;University of Michigan;Google;Google,neural computation;strong generalization;numerical reasoning,7;-1;7;-1;-1,21;-1;21;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Learning Good Policies By Learning Good Perceptual Models,Yilun Du;Phillip Isola,yilundu@mit.edu;phillipi@mit.edu,1;3;1,,Reject,0,0,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,visual representation learning;reinforcement learning;curiosity,5;5,5;5,m;m,usa,usa,n
ICLR,2020,Quaternion Equivariant Capsule Networks for 3D Point Clouds,Yongheng Zhao;Tolga Birdal;Jan Eric Lenssen;Emanuele Menegatti;Leonidas Guibas;Federico Tombari,zhao@dei.unipd.it;tbirdal@stanford.edu;janeric.lenssen@udo.edu;emg@dei.unipd.it;guibas@cs.stanford.edu;tombari@google.com,3;6;6,,Reject,0,4,0,yes,9/25/19,Universita' degli studi di Padova;Stanford University;TU Dortmund University;Universita' degli studi di Padova;Stanford University;Google,3d;capsule networks;pointnet;quaternion;equivariant networks;rotations;local reference frame,-1;5;248;-1;5;-1,-1;4;354;-1;4;-1,m;m,NAN,NAN,y
ICLR,2020,Informed Temporal Modeling via Logical Specification of Factorial LSTMs,Hongyuan Mei;Guanghui Qin;Minjie Xu;Jason Eisner,hongyuanmei@gmail.com;gqin@jhu.edu;chokkyvista06@gmail.com;jason@cs.jhu.edu,3;3;1,,Reject,0,1,0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;Bloomberg LP;Johns Hopkins University,factorized LSTM;temporal point process;event streams;structural bias;Datalog,73;73;-1;73,12;12;-1;12,m;m,usa,usa,n
ICLR,2020,Needles in Haystacks: On Classifying Tiny Objects in Large Images,Nick Pawlowski;Suvrat Bhooshan;Nicolas Ballas;Francesco Ciompi;Ben Glocker;Michal Drozdzal,pawlowski.nick@gmail.com;sbh@fb.com;ballasn@fb.com;f.ciompi@gmail.com;b.glocker@imperial.ac.uk;mdrozdzal@fb.com,3;3;1,,Reject,0,3,0,yes,9/25/19,Google;Facebook;Facebook;Radboud University Medical Center;Imperial College London;Facebook,computer vision;CNNs;small objects;low signal-to-noise image classification,-1;-1;-1;248;52;-1,-1;-1;-1;-1;10;-1,m;m,NAN,NAN,n
ICLR,2020,Probabilistic View of Multi-agent Reinforcement Learning: A Unified Approach,Shubham Gupta;Ambedkar Dukkipati,shubhamg@iisc.ac.in;ambedkar@iisc.ac.in,3;1;3,,Reject,1,3,0,yes,9/25/19,Indian Institute of Science;Indian Institute of Science,multi-agent reinforcement learning;maximum entropy reinforcement learning,-1;-1,301;301,m;m,NAN,NAN,n
ICLR,2020,Hope For The Best But Prepare For The Worst: Cautious Adaptation In RL Agents,Jesse Zhang;Brian Cheung;Chelsea Finn;Dinesh Jayaraman;Sergey Levine,jessezhang@berkeley.edu;bcheung@berkeley.edu;cbfinn@cs.stanford.edu;dineshjayaraman@berkeley.edu;svlevine@eecs.berkeley.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley;University of California Berkeley,safety;risk;uncertainty;adaptation,-1;-1;5;-1;-1,13;13;4;13;13,m;m,usa,usa,n
ICLR,2020,Abstractive Dialog Summarization with Semantic Scaffolds,Lin Yuan;Zhou Yu,yuanlinzju@gmail.com;joyu@ucdavis.edu,1;1;3,,Reject,0,0,0,yes,9/25/19,"Zhejiang University;University of California, Davis",Abstractive Summarization;Dialog;Multi-task Learning,-1;-1,-1;55,m;f,usa,usa,n
ICLR,2020,Relative Pixel Prediction For Autoregressive Image Generation,Wang Ling;Chris Dyer;Lei Yu;Lingpeng Kong;Dani Yogatama;Susannah Young,lingwang@google.com;cdyer@google.com;leiyu@google.com;lingpenk@google.com;dyogatama@google.com;susannahy@google.com,3;3;3,,Reject,0,0,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Image Generation;Autoregressive,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Integrative Tensor-based Anomaly Detection System For Satellites,Youjin Shin;Sangyup Lee;Shahroz Tariq;Myeong Shin Lee;OkchulJung;Daewon Chung;Simon Woo,youjin.shin.1@stonybrook.edu;shahroz@g.skku.edu;sangyup.lee@g.skku.edu;mslee@kari.re.kr;ocjung@kari.re.kr;dwchung@kari.re.kr;swoo@g.skku.edu,1;3,,Reject,0,0,0,yes,9/25/19,"State University of New York, Stony Brook;Peking University;Peking University;;;;Peking University",Tensor decomposition;Anomaly detection,-1;14;14;-1;-1;-1;14,-1;24;24;-1;-1;-1;24,f;m,asia,cn,n
ICLR,2020,Gram-Gauss-Newton Method: Learning Overparameterized Neural Networks for Regression Problems,Tianle Cai*;Ruiqi Gao*;Jikai Hou*;Siyu Chen;Dong Wang;Di He;Zhihua Zhang;Liwei Wang,caitianle1998@pku.edu.cn;grq@pku.edu.cn;1600010681@pku.edu.cn;siyuchen@pku.edu.cn;wangdongcis@pku.edu.cn;di_he@pku.edu.cn;zhzhang@math.pku.edu.cn;wanglw@cis.pku.edu.cn,3;3;3;6;1,,Reject,0,6,0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;Peking University;Peking University;Peking University;Peking University,Deep learning;Optimization;Second-order method;Neural Tangent Kernel regression,14;14;14;14;14;14;14;14,24;24;24;24;24;24;24;24,m;m,asia,cn,y
ICLR,2020,A Greedy Approach to Max-Sliced Wasserstein GANs,Andr√°s Horv√°th,horvath.andras@itk.ppke.hu,1;1;1,,Reject,0,0,0,yes,9/25/19,Pazmany Peter catholic University,GEnerative Adversarial Networks;GANs;Wasserstein distances;Sliced Wasserstein Distance;Max-sliced Wasserstein distance,-1,-1,m,NAN,NAN,n
ICLR,2020,Improving Sequential Latent Variable Models with Autoregressive Flows,Joseph Marino;Lei Chen;Jiawei He;Stephan Mandt,jmarino@caltech.edu;lei_chen_4@sfu.ca;jiawei_he_2@sfu.ca;stephan.mandt@gmail.com,6;3;6,,Reject,0,4,0,yes,9/25/19,"California Institute of Technology;Simon Fraser University;Simon Fraser University;University of California, Irvine",Autoregressive Flows;Sequence Modeling;Latent Variable Models;Video Modeling;Variational Inference,143;52;52;-1,2;272;272;96,m;m,usa,usa,n
ICLR,2020,Symmetry and Systematicity,Jeff Mitchell;Jeff Bowers,jeff.mitchell@bristol.ac.uk;j.bowers@bristol.ac.uk,1;1;3,,Reject,0,9,0,yes,9/25/19,University of Bristol;University of Bristol,symmetry;systematicity;convolution;symbols;generalisation,118;118,87;87,m;m,europe,uk,n
ICLR,2020,Towards Interpretable Evaluations: A Case Study of Named Entity Recognition,Jinlan Fu;Pengfei Liu;Xuanjing Huang,fujl16@fudan.edu.cn;pfliu14@fudan.edu.cn;xjhuang@fudan.edu.cn,3;3;8,,Reject,0,7,0,yes,9/25/19,Fudan University;Fudan University;Fudan University,interpretable evaluation;dataset biases;model biases;NER,73;73;73,109;109;109,f;f,asia,cn,n
ICLR,2020,Bootstrapping the Expressivity with Model-based Planning,Kefan Dong;Yuping Luo;Tengyu Ma,dkf16@mails.tsinghua.edu.cn;yupingl@cs.princeton.edu;tengyuma@cs.stanford.edu,6;3;3,,Reject,0,5,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Princeton University;Stanford University",reinforcement learning theory;model-based reinforcement learning;planning;expressivity;approximation theory;deep reinforcement learning theory,4;30;5,23;6;4,m;m,usa,usa,y
ICLR,2020,Score and Lyrics-Free Singing Voice Generation,Jen-Yu Liu;Yu-Hua Chen;Yin-Cheng Yeh;Yi-Hsuan Yang,ciauaishere@gmail.com;r08946011@ntu.edu.tw;deanyeh.ee01@g2.nctu.edu.tw;affige@gmail.com,3;3;1;3,,Reject,0,7,0,yes,9/25/19,National Taiwan University;Nanyang Technological University;National Chiao Tung University;National Tsing Hua University,singing voice generation;GAN;generative adversarial network,-1;43;118;194,-1;49;564;365,u;m,asia,tw,n
ICLR,2020,RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling,Jinsung Yoon;Sercan O. Arik;Tomas Pfister,jsyoon0823@gmail.com;soarik@google.com;tpfister@google.com,6;3,,Reject,0,3,0,yes,9/25/19,Google;Google;Google,Interpretability;Explanable AI;Explanability,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Characterizing Missing Information in Deep Networks Using Backpropagated Gradients,Gukyeong Kwon;Mohit Prabhushankar;Dogancan Temel;Ghassan AlRegib,gukyeong.kwon@gatech.edu;mohit.p@gatech.edu;cantemel@gatech.edu;alregib@gatech.edu,3;1;3,,Reject,0,0,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Representation learning;Missing Information in Deep Networks;Gradient-based Representation,13;13;13;13,38;38;38;38,m;m,usa,usa,n
ICLR,2020,Improving Multi-Manifold GANs with a Learned Noise Prior,Matthew Amodio;Smita Krishnaswamy,matthew.amodio@yale.edu;smita.krishnaswamy@yale.edu,3;8;6,,Reject,0,3,0,yes,9/25/19,Yale University;Yale University,GAN;generative adversarial network;ensemble,73;73,8;8,m;f,europe,fi,n
ICLR,2020,Unsupervised Domain Adaptation through Self-Supervision,Yu Sun;Eric Tzeng;Trevor Darrell;Alexei A. Efros,yusun@berkeley.edu;etzeng@eecs.berkeley.edu;trevor@eecs.berkeley.edu;efros@eecs.berkeley.edu,6;6;3,,Reject,2,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,unsupervised domain adaptation,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n
ICLR,2020,Adversarial Paritial Multi-label Learning,Yan Yan;Yuhong Guo,yanyan.nwpu@gmail.com;yuhongguo.cs@gmail.com,8;3;3,,Reject,0,0,0,yes,9/25/19,Northwestern Polytechnical University;Carleton University,,-1;194,-1;535,m;f,canada,ca,y
ICLR,2020,Iterative Target Augmentation for Effective Conditional Generation,Kevin Yang;Wengong Jin;Kyle Swanson;Regina Barzilay;Tommi Jaakkola,yangk@berkeley.edu;wengong@csail.mit.edu;swansonk.14@gmail.com;regina@csail.mit.edu;tommi@csail.mit.edu,3;6;6,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology,data augmentation;generative models;self-training;molecular optimization;program synthesis,-1;5;-1;5;5,13;5;-1;5;5,m;m,usa,usa,n
ICLR,2020,Hyperbolic Discounting and Learning Over Multiple Horizons,William Fedus;Carles Gelada;Yoshua Bengio;Marc G. Bellemare;Hugo Larochelle,liam.fedus@gmail.com;carlesgelada@hotmail.com;yoshua.bengio@mila.quebec;bellemare@google.com;hugolarochelle@google.com,6;6;3,,Reject,0,7,0,yes,9/25/19,University of Montreal;;Mila;Google;Google,Deep learning;reinforcement learning;discounting;hyperbolic discounting;auxiliary tasks,-1;-1;143;-1;-1,-1;-1;336;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Can I Trust the Explainer? Verifying Post-Hoc Explanatory Methods,Oana-Maria Camburu*;Eleonora Giunchiglia*;Jakob Foerster;Thomas Lukasiewicz;Phil Blunsom,ocamburu@gmail.com;eleonora.giunchiglia@cs.ox.ac.uk;jakobfoerster@gmail.com;thomas.lukasiewicz@gmail.com;philblunsom@gmail.com,3;3;3,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford;;University of Oxford;University of Oxford,explainability;neural networks,46;46;-1;46;-1,1;1;-1;1;-1,f;m,asia,in,n
ICLR,2020,A Fine-Grained Spectral Perspective on Neural Networks,Greg Yang;Hadi Salman,gregyang@microsoft.com;hadicsalman@gmail.com,6;3;6,,Reject,0,7,0,yes,9/25/19,Microsoft;Massachusetts Institute of Technology,Neural Tangent Kernel;Neural Network Gaussian Process;Spectral theory;Eigenvalues;Harmonic analysis,-1;5,-1;5,m;m,usa,usa,n
ICLR,2020,Low Rank Training of Deep Neural Networks for Emerging Memory Technology,Albert Gural;Phillip Nadeau;Mehul Tikekar;Boris Murmann,agural@stanford.edu;phillip.nadeau@analog.com;mehul.tikekar@analog.com;murmann@stanford.edu,3;3;3;6,,Reject,0,5,0,yes,9/25/19,Stanford University;Analog Devices;Analog Devices;Stanford University,low rank training;kronecker sum;emerging memory;non-volatile memory;rram;reram;federated learning,5;-1;-1;5,4;-1;-1;4,m;m,usa,usa,n
ICLR,2020,Cyclic Graph Dynamic Multilayer Perceptron for Periodic Signals,Mikio Furokawa;Erik Gest;Takayuki Hirano;Kamal Youcef-Toumi,mikiof@mit.edu;erikgest@mit.edu;takayuki_hirano@jsw.co.jp;youcef@mit.edu,3;6;3;3,,Reject,0,0,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Massachusetts Institute of Technology,,5;5;-1;5,5;5;-1;5,m;m,usa,usa,n
ICLR,2020,Atomic Compression Networks,Jonas Falkner;Josif Grabocka;Lars Schmidt-Thieme,falkner@ismll.uni-hildesheim.de;josif@ismll.uni-hildesheim.de;schmidt-thieme@ismll.uni-hildesheim.de,6;1;1,,Reject,0,4,0,yes,9/25/19,University of Hildesheim;University of Hildesheim;University of Hildesheim,Network Compression,445;445;445,-1;-1;-1,m;m,europe,de,n
ICLR,2020,Simplicial Complex Networks,Mohammad Firouzi;Sadra Boreiri;Hamed Firouzi,mfirouzi@alphabist.com;sadra.boreiri@epfl.ch;hfirouzi@alphabist.com,1;1,,Reject,0,0,0,yes,9/25/19,Alphabist;Swiss Federal Institute of Technology Lausanne;Alphabist,topological data analysis;supervised learning;simplicial approximation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Non-asymptotic comparison of SVRG and SGD: tradeoffs between compute and speed,Qingru Zhang;Yuhuai Wu;Fartash Faghri;Tianzong Zhang;Jimmy Ba,qrzhang98@gmail.com;ywu@cs.toronto.edu;faghri@cs.toronto.edu;ztz16@mails.tsinghua.edu.cn;jba@cs.toronto.edu,6;3;1,,Reject,0,5,0,yes,9/25/19,"Georgia Institute of Technology;University of Toronto;University of Toronto;Tsinghua University, Tsinghua University;University of Toronto",variance reduction;non-asymptotic analysis;trade-off;computational cost;convergence speed,13;18;18;4;18,38;18;18;23;18,m;m,canada,ca,y
ICLR,2020,PAC-Bayesian Neural Network Bounds,Yossi Adi;Alex Schwing;Tamir Hazan,yossiadidrum@gmail.com;aschwing@illinois.edu;tamir.hazan@technion.ac.il,3;6;3,,Reject,0,5,0,yes,9/25/19,"Facebook;University of Illinois, Urbana Champaign;Technion, Technion",PAC-Bayesian bounds;PAC-Bayes;Generalization bounds;Bayesian inference,-1;-1;27,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning,Paul Barde;Julien Roy;F√©lix G. Harvey;Derek Nowrouzezahrai;Christopher Pal,paul.b.barde@gmail.com;jul.roy1311@gmail.com;c212.felixh@gmail.com;derek@cim.mcgill.ca;christopher.pal@polymtl.ca,6;8;3,,Reject,1,10,0,yes,9/25/19,INRIA;;Unity Technologies;McGill University;Polytechnique Montreal,Reinforcement Learning;Multi-Agent;Continuous Control;Regularization;Coordination;Inductive biases,-1;-1;-1;102;316,-1;-1;-1;42;-1,m;m,canada,ca,n
ICLR,2020,Stabilizing Transformers for Reinforcement Learning,Emilio Parisotto;Francis Song;Jack Rae;Razvan Pascanu;Caglar Gulcehre;Siddhant Jayakumar;Max Jaderberg;Rapha√´l Lopez Kaufman;Aidan Clark;Seb Noury;Matt Botvinick;Nicolas Heess;Raia Hadsell,eparisot@cs.cmu.edu;songf@google.com;jwrae@google.com;razp@google.com;caglarg@google.com;sidmj@google.com;jaderberg@google.com;rlopezkaufman@google.com;aidanclark@google.com;snoury@google.com;botvinick@google.com;heess@google.com;raia@google.com,1;3;3,,Reject,0,7,0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,Deep Reinforcement Learning;Transformer;Reinforcement Learning;Self-Attention;Memory;Memory for Reinforcement Learning,1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,27;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Deep k-NN for Noisy Labels,Dara Bahri;Heinrich Jiang;Maya Gupta,dbahri@google.com;heinrichj@google.com;mayagupta@google.com,1;1;6,,Reject,0,2,0,yes,9/25/19,Google;Google;Google,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,y
ICLR,2020,Annealed Denoising score matching: learning Energy based model in high-dimensional spaces,Zengyi Li;Yubei Chen;Friedrich T. Sommer,zengyi_li@berkeley.edu;yubeic@eecs.berkeley.edu;fsommer@berkeley.edu,3;6;3,,Reject,0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Energy based models;score matching;annealing;likelihood;generative model;unsupervised learning,-1;-1;-1,13;13;13,m;m,usa,usa,y
ICLR,2020,Sparse Networks from Scratch: Faster Training without Losing Performance,Tim Dettmers;Luke Zettlemoyer,dettmers@cs.washington.edu;lsz@cs.washington.edu,6;3;6,,Reject,0,6,0,yes,9/25/19,University of Washington;University of Washington,sparse learning;sparse networks;sparsity;efficient deep learning;efficient training,11;11,26;26,m;m,usa,usa,n
ICLR,2020,TPO: TREE SEARCH POLICY OPTIMIZATION FOR CONTINUOUS ACTION SPACES,Amir Yazdanbakhsh;Ebrahim Songhori;Robert Ormandi;Anna Goldie;Azalia Mirhoseini,ayazdan@google.com;esonghori@google.com;ormandi@google.com;agoldie@google.com;azalia@google.com,1;3;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google;Google,monte-carlo tree search;reinforcement learning;tree search;policy optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Sample-Based Point Cloud Decoder Networks,Erich Merrill;Alan Fern,merriler@oregonstate.edu;alan.fern@oregonstate.edu,3;3;1,,Reject,0,0,0,yes,9/25/19,Oregon State University;Oregon State University,point cloud;autoencoder,79;79,373;373,m;m,usa,usa,n
ICLR,2020,Bayesian Residual Policy Optimization: Scalable Bayesian Reinforcement Learning with Clairvoyant Experts,Gilwoo Lee;Brian Hou;Sanjiban Choudhury;Siddhartha S. Srinivasa,gilwoo@cs.uw.edu;bhou@cs.uw.edu;sanjibac@cs.uw.edu;siddh@cs.uw.edu,3;3;6,,Reject,0,4,0,yes,9/25/19,"University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle;University of Washington, Seattle",Bayesian Residual Reinforcement Learning;Residual Reinforcement Learning;Bayes Policy Optimization,11;11;11;11,26;26;26;26,-1;-1,NAN,NAN,n
ICLR,2020,Efficient Inference and Exploration for Reinforcement Learning,Yi Zhu;Jing Dong;Henry Lam,yizhu2020@u.northwestern.edu;jing.dong@gsb.columbia.edu;khl2114@columbia.edu,3;1;6,,Reject,0,4,0,yes,9/25/19,Northwestern University;Columbia University;Columbia University,Reinforcement Learning;Efficient Exploration;Asymptotic Analysis;Statistical Inference,46;24;24,22;16;16,m;m,usa,usa,y
ICLR,2020,Poisoning Attacks with Generative Adversarial Nets,Luis Mu√±oz-Gonz√°lez;Bjarne Pfitzner;Matteo Russo;Javier Carnerero-Cano;Emil C. Lupu,l.munoz@imperial.ac.uk;bjarne.pfitzner@hpi.de;matteor@princeton.edu;j.carnerero-cano18@imperial.ac.uk;e.c.lupu@imperial.ac.uk,6;6;3,,Reject,0,3,0,yes,9/25/19,Imperial College London;Hasso Plattner Institute;Princeton University;Imperial College London;Imperial College London,data poisoning;adversarial machine learning;generative adversarial nets,52;143;30;52;52,10;-1;6;10;10,m;m,europe,uk,n
ICLR,2020,Keyframing the Future: Discovering Temporal Hierarchy with Keyframe-Inpainter Prediction,Karl Pertsch;Oleh Rybkin;Jingyun Yang;Konstantinos G. Derpanis;Kostas Daniilidis;Joseph J. Lim;Andrew Jaegle,pertsch@usc.edu;oleh@seas.upenn.edu;jingyuny@usc.edu;kosta@ryerson.ca;kostas@seas.upenn.edu;limjj@usc.edu;ajaegle@upenn.edu,3;3;6,,Reject,0,7,0,yes,9/25/19,University of Southern California;University of Pennsylvania;University of Southern California;Ryerson University;University of Pennsylvania;University of Southern California;University of Pennsylvania,representation learning;variational inference;video generation;temporal hierarchy,36;20;36;316;20;36;20,62;11;62;739;11;62;11,m;m,usa,usa,n
ICLR,2020,An Empirical Study on Post-processing Methods for Word Embeddings,Shuai Tang;Mahta Mousavi;Virginia R. de Sa,shuaitang93@ucsd.edu;mahta@ucsd.edu;desa@ucsd.edu,1;6;3,,Reject,0,1,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego",word vectors;post-processing method;centralised kernel alignment;shrinkage,-1;-1;-1,31;31;31,m;f,usa,usa,n
ICLR,2020,Winning the Lottery with Continuous Sparsification,Pedro Savarese;Hugo Silva;Michael Maire,savarese@ttic.edu;hugoandradesilva664@gmail.com;mmaire@uchicago.edu,3;6;3,,Reject,0,6,0,yes,9/25/19,Toyota Technological Institute at Chicago;;University of Chicago,,-1;-1;51,-1;-1;9,m;m,usa,usa,n
ICLR,2020,Rethinking Curriculum Learning With Incremental Labels And Adaptive Compensation,Madan Ravi Ganesh;Jason J. Corso,madantrg@umich.edu;jjcorso@umich.edu,3;1;6,,Reject,0,4,0,yes,9/25/19,University of Michigan;University of Michigan,Curriculum Learning;Incremental Label Learning;Label Smoothing;Deep Learning,7;7,21;21,m;m,usa,usa,n
ICLR,2020,Zero-Shot Policy Transfer with Disentangled Attention,Josh Roy;George Konidaris,josh_roy@brown.edu;gdk@cs.brown.edu,1;1;1,,Reject,0,3,0,yes,9/25/19,Brown University;Brown University,Transfer Learning;Reinforcement Learning;Attention;Domain Adaptation;Representation Learning;Feature Extraction,85;85,53;53,m;m,usa,usa,n
ICLR,2020,P-BN: Towards Effective Batch Normalization in the Path Space,Xufang Luo;Qi Meng;Wei Chen;Tie-Yan Liu,luoxufang@buaa.edu.cn;meq@microsoft.com;wche@microsoft.com;tyliu@microsoft.com,3;3;3,,Reject,0,4,0,yes,9/25/19,Beihang University;Microsoft;Microsoft;Microsoft,,102;-1;-1;-1,594;-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Convolutional Tensor-Train LSTM for Long-Term Video Prediction,Jiahao Su;Wonmin Byeon;Furong Huang;Jan Kautz;Animashree Anandkumar,jiahaosu@terpmail.umd.edu;wonmin.byeon@gmail.com;furongh@cs.umd.edu;jkautz@nvidia.com;animakumar@gmail.com,3;3;3,,Reject,0,4,0,yes,9/25/19,"University of Maryland, College Park;NVIDIA;University of Maryland, College Park;NVIDIA;California Institute of Technology",Tensor decomposition;Video prediction,12;-1;12;-1;143,91;-1;91;-1;2,m;f,usa,usa,n
ICLR,2020,Task-Based Top-Down Modulation Network for Multi-Task-Learning Applications,Hila Levi;Shimon Ullman,hila.levi@weizmann.ac.il;shimon.ullman@weizmann.ac.il,3;3;3,,Reject,0,6,0,yes,9/25/19,Weizmann Institute;Weizmann Institute,deep learning;multi-task learning,118;118,-1;-1,f;m,NAN,NAN,n
ICLR,2020,Variational Constrained Reinforcement Learning with Application to Planning at Roundabout,Yuan Tian;Minghao Han;Lixian Zhang;Wulong Liu;Jun Wang;Wei Pan,yuantian013@163.com;mhhan@hit.edu.cn;lixianzhang@hit.edu.cn;liuwulong@huawei.com;jun.wang@cs.ucl.ac.uk;wei.pan@tudelft.nl,1;1;1,,Reject,0,0,0,yes,9/25/19,163;Harbin Institute of Technology;Harbin Institute of Technology;Huawei Technologies Ltd.;University College London;Delft University of Technology,Safe reinforcement learning;Autonomous driving;obstacle avoidance,-1;168;168;-1;52;-1,-1;424;424;-1;-1;67,m;m,NAN,NAN,n
ICLR,2020,Learning a Spatio-Temporal Embedding for Video Instance Segmentation,Anthony Hu;Alex Kendall;Roberto Cipolla,ah2029@cam.ac.uk;alex@wayve.ai;rc10001@cam.ac.uk,3;6;3,,Reject,0,4,0,yes,9/25/19,University of Cambridge;Wayve;University of Cambridge,computer;vision;video;instance;segmentation;metric;learning,79;-1;79,3;-1;3,m;m,europe,uk,n
ICLR,2020,Deep Ensembles: A Loss Landscape Perspective,Stanislav Fort;Clara Huiyi Hu;Balaji Lakshminarayanan,stanislav.fort@gmail.com;clarahu@google.com;balajiln@google.com,8;3;3,,Reject,0,5,0,yes,9/25/19,Stanford University;Google;Google,loss landscape;deep ensemble;subspace;tunnel;low loss;connector;weight averaging;dropout;gaussian;connectivity;diversity;function space,5;-1;-1,4;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Adversarial Privacy Preservation under Attribute Inference Attack,Han Zhao;Jianfeng Chi;Yuan Tian;Geoffrey J. Gordon,han.zhao@cs.cmu.edu;jc6ub@virginia.edu;yuant@virginia.edu;geoff.gordon@microsoft.com,3;6;3,,Reject,0,4,1,yes,9/25/19,Carnegie Mellon University;University of Virginia;University of Virginia;Microsoft,,1;52;52;-1,27;107;107;-1,m;m,NAN,NAN,y
ICLR,2020,Deep Innovation Protection,Sebastian Risi;Kenneth O. Stanley,sebr@itu.dk;kstanley@uber.com,6;6;3,,Reject,0,3,0,yes,9/25/19,IT University of Copenhagen;Uber,Neuroevolution;innovation protection;world models;genetic algorithm,168;-1,101;-1,m;m,southamerica,br,n
ICLR,2020,Meta-Learning Runge-Kutta,Nadine Behrmann;Patrick Schramowski;Kristian Kersting,nadine.behrmann@freenet.de;schramowski@cs.tu-darmstadt.de;kersting@cs.tu-darmstadt.de,3;3;3,,Reject,0,6,0,yes,9/25/19,Bosch;TU Darmstadt;TU Darmstadt,,-1;59;59,297;-1;-1,f;m,europe,de,y
ICLR,2020,"Credible Sample Elicitation by Deep Learning, for Deep Learning",Yang Liu;Zuyue Fu;Zhuoran Yang;Zhaoran Wang,yangliu@ucsc.edu;zuyuefu2022@u.northwestern.edu;zy6@princeton.edu;zhaoranwang@gmail.com,6;1,,Reject,0,3,0,yes,9/25/19,University of Southern California;Northwestern University;Princeton University;Northwestern University,,36;46;30;46,62;22;6;22,m;m,usa,usa,y
ICLR,2020,Continuous Graph Flow,Zhiwei Deng;Megha Nawhal;Lili Meng;Greg Mori,zhiweid@princeton.edu;mnawhal@sfu.ca;lilimeng1103@gmail.com;mori@cs.sfu.ca,3;3;3,,Reject,1,3,0,yes,9/25/19,Princeton University;Simon Fraser University;University of British Columbia;Simon Fraser University,graph flow;normalizing flow;continuous message passing;reversible graph neural networks,30;52;64;52,6;272;34;272,m;m,canada,ca,n
ICLR,2020,Extreme Value k-means Clustering,Sixiao Zheng;Yanxi Hou;Yanwei Fu;Jianfeng Feng,sxzheng18@fudan.edu.cn;yxhou@fudan.edu.cn;yanweifu@fudan.edu.cn;jffeng@fudan.edu.cn,3;3;1;6,,Reject,0,0,0,yes,9/25/19,Fudan University;Fudan University;Fudan University;Fudan University,unsupervised learning;clustering;k-means;Extreme Value Theory,73;73;73;73,109;109;109;109,m;m,asia,cn,y
ICLR,2020,Hallucinative Topological Memory for Zero-Shot Visual Planning,Kara Liu;Thanard Kurutach;Pieter Abbeel;Aviv Tamar,karamarieliu@berkeley.edu;thanard.kurutach@berkeley.edu;pabbeel@cs.berkeley.edu;aviv.tamar.mail@gmail.com,1;8;6,,Reject,0,5,0,yes,9/25/19,"University of California Berkeley;University of California Berkeley;University of California Berkeley;Technion, Technion",Visual Planning;Model-Based RL;Representation Learning,-1;-1;-1;27,13;13;13;-1,f;m,NAN,NAN,n
ICLR,2020,On the Decision Boundaries of Deep Neural Networks: A Tropical Geometry Perspective,Motasem Alfarra;Adel Bibi;Hasan Hammoud;Mohamed Gaafar;Bernard Ghanem,motasem.alfarra@kaust.edu.sa;adel.bibi@kaust.edu.sa;hasan.hammoud@kaust.edu.sa;muhamed.gaafar@gmail.com;bernard.ghanem@kaust.edu.sa,1;8;3,,Reject,1,9,0,yes,9/25/19,KAUST;KAUST;KAUST;Zalando SE;KAUST,Decision boundaries;Neural Network;Tropical Geometry;Network Pruning;Adversarial Attacks;Lottery Ticket Hypothesis,102;102;102;-1;102,-1;-1;-1;-1;-1,m;m,europe,gr,y
ICLR,2020,Encoder-decoder Network as Loss Function for Summarization,Glen Jeh,glenjeh@gmail.com,1;6;1,,Reject,0,4,0,yes,9/25/19,0,encoder-decoder;summarization;loss functions,,,m,NAN,NAN,n
ICLR,2020,Unsupervised Learning of Automotive 3D Crash Simulations using LSTMs,Amin Abbasloo;Jochen Garcke;Rodrigo Iza-Teran,amin.abbasloo@scai.fraunhofer.de;garcke@ins.uni-bonn.de;rodrigo.iza-teran@scai.fraunhofer.de,3;3;3,,Reject,0,1,0,yes,9/25/19,Fraunhofer IIS;University of Bonn;Fraunhofer IIS,LSTM;surface data;geometric deep learning;numerical simulation,-1;143;-1,-1;106;-1,m;m,NAN,NAN,n
ICLR,2020,Dynamic Instance Hardness,Tianyi Zhou;Shengjie Wang;Jeff A. Bilmes,tianyizh@uw.edu;wangsj@cs.washington.edu;bilmes@uw.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,"University of Washington, Seattle;University of Washington;University of Washington, Seattle",training dynamics;instance hardness;curriculum learning;neural nets memorization,11;11;11,26;26;26,m;m,NAN,NAN,y
ICLR,2020,Beyond Classical Diffusion: Ballistic Graph Neural Network,Yimeng Min,minyimen@mila.quebec,3;3;1,,Reject,0,4,0,yes,9/25/19,Mila,Graph Convolutional Network;Diffusion;Transportation;Machine Learning,143,336,m;m,NAN,NAN,n
ICLR,2020,INSTANCE CROSS ENTROPY FOR DEEP METRIC LEARNING,Xinshao Wang;Elyor Kodirov;Yang Hua;Neil M. Robertson,xwang39@qub.ac.uk;elyor@anyvision.co;y.hua@qub.ac.uk;n.robertson@qub.ac.uk,3;1;8,,Reject,0,7,1,yes,9/25/19,Queen's University Belfast;Anyvision;Queen's University Belfast;Queen's University Belfast,Deep Metric Learning;Instance Cross Entropy;Sample Mining/Weighting;Image Retrieval,248;-1;248;248,204;-1;204;204,m;m,europe,uk,n
ICLR,2020,Retrieving Signals in the Frequency Domain with Deep Complex Extractors,Chiheb Trabelsi;Olexa Bilaniuk;Ousmane Dia;Ying Zhang;Mirco Ravanelli;Jonathan Binas;Negar Rostamzadeh;Christopher  J Pal,chiheb.trabelsi@polymtl.ca;olexa.bilaniuk@umontreal.ca;ousmane@elementai.com;ying@elementai.com;mirco.ravanelli@gmail.com;jbinas@gmail.com;negar@elementai.com;christopher.pal@elementai.com,6;3;6,,Reject,0,7,0,yes,9/25/19,Polytechnique Montreal;University of Montreal;Element AI;Element AI;University of Montreal;University of Montreal;Element AI;Element AI,Deep Complex Networks;Signal Extraction,316;118;-1;-1;118;118;-1;-1,-1;85;-1;-1;85;85;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Copula approach for hyperparameter transfer learning,David Salinas;Huibin Shen;Valerio Perrone,david.salinas.pro@gmail.com;huibishe@amazon.com;vperrone@amazon.com,3;1;6,,Reject,0,4,0,yes,9/25/19,Amazon;Amazon;Amazon,Hyperparameter optimization;Bayesian Optimization;Gaussian Process;Copula;Transfer-learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Out-of-distribution Detection in Few-shot Classification,Kuan-Chieh Wang;Paul Vicol;Eleni Triantafillou;Chia-Cheng Liu;Richard Zemel,wangkua1@cs.toronto.edu;pvicol@cs.toronto.edu;eleni@cs.toronto.edu;cc.liu2018@gmail.com;zemel@cs.toronto.edu,3;3;3,,Reject,0,5,0,yes,9/25/19,University of Toronto;University of Toronto;University of Toronto;;University of Toronto,few-shot classification;out-of-distribution detection;uncertainty estimate,18;18;18;-1;18,18;18;18;-1;18,m;m,canada,ca,n
ICLR,2020,GQ-Net: Training Quantization-Friendly Deep Networks,Rundong Li;Rui Fan,lird@shanghaitech.edu.cn;fanrui@shanghaitech.edu.cn,3;3;6,,Reject,0,8,0,yes,9/25/19,ShanghaiTech University;ShanghaiTech University,Network quantization;Efficient deep learning,316;316,-1;-1,m;m,asia,cn,n
ICLR,2020,The divergences minimized by non-saturating GAN training,Matt Shannon,matt.shannon.personal@gmail.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Google,GAN,-1,-1,m,NAN,NAN,n
ICLR,2020,"Translation Between Waves,  wave2wave",Tsuyoshi Okita;Hirotaka Hachiya;Sozo Inoue;Naonori Ueda,tsuyoshi.okita@gmail.com;hirotaka.hachiya@riken.jp;sozo.inoue@riken.jp;naonori.ueda@riken.jp,1;1;3,,Reject,0,0,0,yes,9/25/19,Kyushu Institute of Technology;RIKEN;RIKEN;RIKEN,sequence to sequence model;signal to signal;deep learning;RNN;encoder-decoder model,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,MixUp as Directional Adversarial Training,Guillaume Perrault-Archambault;Yongyi Mao;Hongyu Guo;Richong Zhang,gperr050@uottawa.ca;yymao@eecs.uottawa.ca;hongyu.guo@nrc-cnrc.gc.ca;zhangrc@act.buaa.edu.cn,1;3;3,,Reject,0,8,0,yes,9/25/19,University of Ottawa;University of Ottawa;National Research Council Canada;Beihang University,MixUp;Adversarial Training;Untied MixUp,248;248;-1;102,141;141;-1;594,m;m,asia,cn,y
ICLR,2020,Deep Multiple Instance Learning with Gaussian Weighting,Basura Fernando;Hakan Bilen,basura.fernando@anu.edu.au;hbilen@ed.ac.uk,8;3;3,,Reject,0,3,0,yes,9/25/19,Australian National University;University of Edinburgh,Multiple instance learning;deep learning,102;36,50;30,m;m,europe,uk,n
ICLR,2020,DyNet: Dynamic Convolution for Accelerating Convolution Neural Networks,Kane Zhang;Jian Zhang;Qiang Wang;Zhao Zhong,zhangyikang5@huawei.com;zhangjian157@huawei.com;wangqiang168@huawei.com;zorro.zhongzhao@huawei.com,6;3;3,,Reject,0,8,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,CNNs;dynamic convolution kernel,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Growing Action Spaces,Gregory Farquhar;Laura Gustafson;Zeming Lin;Shimon Whiteson;Nicolas Usunier;Gabriel Synnaeve,gregory.farquhar@cs.ox.ac.uk;lgustafson@fb.com;zlin@fb.com;shimon.whiteson@cs.ox.ac.uk;usunier@fb.com;gab@fb.com,3;3;6,,Reject,0,3,0,yes,9/25/19,University of Oxford;Facebook;Facebook;University of Oxford;Facebook;Facebook,reinforcement learning;curriculum learning;multi-agent reinforcement learning,46;-1;-1;46;-1;-1,1;-1;-1;1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Model Ensemble-Based Intrinsic Reward for Sparse Reward Reinforcement Learning,Giseung Park;Whiyoung Jung;Sungho Choi;Youngchul Sung,gs.park@kaist.ac.kr;wy.jung@kaist.ac.kr;sungho.choi@kaist.ac.kr;ycsung@kaist.ac.kr,3;3;6,,Reject,0,5,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement Learning;Intrinsic Reward;Dynamics Model;Ensemble,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,y
ICLR,2020,Differentiable Hebbian Consolidation for Continual Learning,Vithursan Thangarasa;Thomas Miconi;Graham W. Taylor,vthangar@uoguelph.ca;tmiconi@uber.com;gwtaylor@uoguelph.ca,3;6;6,,Reject,0,7,0,yes,9/25/19,University of Guelph;Uber;University of Guelph,continual learning;catastrophic forgetting;Hebbian learning;synaptic plasticity;neural networks,248;-1;248,558;-1;558,m;m,canada,ca,n
ICLR,2020,Meta-Graph: Few shot Link Prediction via Meta Learning,Avishek Joey Bose;Ankit Jain;Piero Molino;William L. Hamilton,joey.bose@mail.mcgill.ca;ankit.jain@uber.com;piero.molino@uber.com;wlh@cs.mcgill.ca,6;6;6,,Reject,0,5,0,yes,9/25/19,McGill University;Uber;Uber;McGill University,Meta Learning;Link Prediction;Graph Representation Learning;Graph Neural Networks,102;-1;-1;102,42;-1;-1;42,m;m,canada,ca,n
ICLR,2020,EXPLOITING SEMANTIC COHERENCE TO IMPROVE PREDICTION IN SATELLITE SCENE IMAGE ANALYSIS: APPLICATION TO DISEASE DENSITY ESTIMATION,Rahman Sanya;Gilbert Maiga;Ernest Mwebaze,hbasanya@gmail.com;gilmaiga@gmail.com;emwebaze@gmail.com,1;3;1,,Reject,0,1,0,yes,9/25/19,Makerere University;;Google AI,semantic coherence;satellite scene image analysis;convolutional neural networks;disease density,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,VAENAS: Sampling Matters in Neural Architecture Search,Shizheng Qin;Yichen Zhu;Pengfei Hou;Xiangyu Zhang;Wenqiang Zhang;Jian Sun,szqin17@fudan.edu.cn;k.zhu@mail.utoronto.ca;houpengfei@megvii.com;zhangxiangyu@megvii.com;wqzhang@fudan.edu.cn;sunjian@megvii.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Fudan University;Toronto University;Megvii Technology Inc.;Megvii Technology Inc.;Fudan University;Megvii Technology Inc.,,73;-1;-1;-1;73;-1,109;-1;-1;-1;109;-1,m;m,NAN,NAN,n
ICLR,2020,Aggregating explanation methods for neural networks stabilizes explanations,Laura Rieger;Lars Kai Hansen,lauri@dtu.dk,8;3;8,,Reject,0,7,0,yes,9/25/19,Technical University of Denmark,explainability;deep learning;interpretability;XAI,-1,182,m;f,NAN,NAN,n
ICLR,2020,Towards Stable and comprehensive Domain Alignment: Max-Margin Domain-Adversarial Training,Jianfei Yang;Han Zou;Yuxun Zhou;Lihua Xie,yang0478@e.ntu.edu.sg;hanzou@berkeley.edu;yxzhou@berkeley.edu;elhxie@ntu.edu.sg,6;3;3,,Reject,0,3,0,yes,9/25/19,Nanyang Technological University;University of California Berkeley;University of California Berkeley;Nanyang Technological University,domain adaptation;transfer learning;adversarial training,43;-1;-1;43,49;13;13;49,m;m,asia,sg,n
ICLR,2020,In-Domain Representation Learning For Remote Sensing,Maxim Neumann;Andre Susano Pinto;Xiaohua Zhai;Neil Houlsby,maximneumann@google.com;andresp@google.com;xzhai@google.com;neilhoulsby@google.com,3;3;1,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google,Representation learning;remote sensing,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Ternary MobileNets via Per-Layer Hybrid Filter Banks,Dibakar Gope;Jesse G Beu;Urmish Thakker;Matthew Mattina,dibakar.gope@arm.com;jesse.beu@arm.com;urmish.thakker@arm.com;matthew.mattina@arm.com,3;3;3,,Reject,0,3,0,yes,9/25/19,arm;arm;arm;arm,Model compression;ternary quantization;energy-efficient models,59;59;59;59,289;289;289;289,m;m,asia,in,n
ICLR,2020,Avoiding Negative Side-Effects and Promoting Safe Exploration with Imaginative Planning,Dhruv Ramani;Benjamin Eysenbach,dhruvramani98@gmail.com;beysenba@cs.cmu.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,National Institute of Technology Warangal;Carnegie Mellon University,Reinforcement Learning;AI-Safety;Model-Based Reinforcement Learning;Safe-Exploration,-1;1,-1;27,m;m,usa,usa,n
ICLR,2020,Exploring the Correlation between Likelihood of Flow-based Generative Models and Image Semantics,Xin WANG;SiuMing Yiu,xwang@cs.hku.hk;smyiu@cs.hku.hk,3;1;3,,Reject,0,8,0,yes,9/25/19,The University of Hong Kong;The University of Hong Kong,flow-based generative models;out-of-distribution samples detection;likelihood robustness,92;92,35;35,u;m,NAN,NAN,n
ICLR,2020,Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization,Ali Ramezani-Kebrya;Fartash Faghri;Ilya Markov;Vitalii Aksenov;Dan Alistarh;Daniel M. Roy,alir@vectorinstitute.ai;faghri@cs.toronto.edu;droy@utstat.toronto.edu;dan.alistarh@ist.ac.at;markovilya197@gmail.com;vitalii.aksenov@ist.ac.at,3;6;3,,Reject,0,5,0,yes,9/25/19,Vector Institute;University of Toronto;University of Toronto;Institute of Science and Technology Austria;;Institute of Science and Technology Austria,,-1;18;18;-1;-1;-1,-1;18;18;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Scalable Neural Learning for Verifiable Consistency with Temporal Specifications,Sumanth Dathathri;Johannes Welbl;Krishnamurthy (Dj) Dvijotham;Ramana Kumar;Aditya Kanade;Jonathan Uesato;Sven Gowal;Po-Sen Huang;Pushmeet Kohli,sdathath@caltech.edu;johannes.welbl.14@ucl.ac.uk;dvij@google.com;ramanakumar@google.com;akanade@google.com;juesato@google.com;sgowal@google.com;posenhuang@google.com;pushmeet@google.com,3;6;8;1,,Reject,0,9,0,yes,9/25/19,California Institute of Technology;University College London;Google;Google;Google;Google;Google;Google;Google,Verification;Recurrent Neural Networks;Reinforcement Learning;Temporal Logic;Adversarial Robustness,143;52;-1;-1;-1;-1;-1;-1;-1,2;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,EvoNet: A Neural Network for Predicting the Evolution of Dynamic Graphs,Changmin Wu;Giannis Nikolentzos;Michalis Vazirgiannis,changmin.wu@polytechnique.edu;giannisnik@hotmail.com;mvazirg@lix.polytechnique.fr,3;3;1,,Reject,0,0,0,yes,9/25/19,"Ecole polytechnique;Ecole polytechnique;Ecole Polytechnique, France",temporal graphs;graph neural network;graph generative model;graph topology prediction,-1;-1;-1,93;93;-1,m;m,NAN,NAN,n
ICLR,2020,SGD Learns One-Layer Networks in WGANs,Qi Lei;Jason D. Lee;Alexandros G. Dimakis;Constantinos Daskalakis,leiqi@ices.utexas.edu;jasondlee88@gmail.com;dimakis@austin.utexas.edu;costis@csail.mit.edu,3;6;3,,Reject,0,3,0,yes,9/25/19,"University of Texas, Austin;Princeton University;University of Texas, Austin;Massachusetts Institute of Technology",Wasserstein GAN;global min-max;one-layer network,-1;30;-1;5,-1;6;-1;5,f;m,usa,usa,y
ICLR,2020,Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation,Raphael Gontijo Lopes;Dong Yin;Ben Poole;Justin Gilmer;Ekin D. Cubuk,iraphael@google.com;dongyin@berkeley.edu;pooleb@google.com;gilmer@google.com;cubuk@google.com,3;3;8,,Reject,0,5,0,yes,9/25/19,Google;University of California Berkeley;Google;Google;Google,Data Augmentation;Out-of-distribution;Robustness;Generalization;Computer Vision;Corruption,-1;-1;-1;-1;-1,-1;13;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Tensorized Embedding Layers for Efficient Model Compression,Oleksii Hrinchuk;Valentin Khrulkov;Leyla Mirvakhabova;Ivan Oseledets,oleksii.hrinchuk@skoltech.ru;khrulkov.v@gmail.com;leyla.mirvakhabova@skoltech.ru;i.oseledets@skoltech.ru,8;3;6,,Reject,0,4,0,yes,9/25/19,Skolkovo Institute of Science and Technology;Yandex;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology,Embedding layers compression;tensor networks;low-rank factorization,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,russia,n
ICLR,2020,Training Deep Networks with Stochastic Gradient Normalized by Layerwise Adaptive Second Moments,Boris Ginsburg;Patrice Castonguay;Oleksii Hrinchuk;Oleksii Kuchaiev;Vitaly Lavrukhin;Ryan Leary;Jason Li;Huyen Nguyen;Yang Zhang;Jonathan M. Cohen,boris.ginsburg@gmail.com;pcastonguay@nvidia.com;grinchuk.alexey@gmail.com;kuchaev@gmail.com;vlavrukhin@yahoo.com;rleary@nvidia.com;jasoli@nvidia.com;huyenntkvn@gmail.com;yangzhang@nvidia.com;jocohen@nvidia.com,6;3;3,,Reject,0,3,0,yes,9/25/19,NVIDIA;NVIDIA;Moscow Institute of Physics and Technology;NVIDIA;;NVIDIA;NVIDIA;;NVIDIA;NVIDIA,deep learning;optimization;SGD;Adam;NovoGrad;large batch training,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;234;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Time-Aware Assistance Functions for Numerical Fluid Solvers,Kiwon Um;Yun (Raymond) Fei;Philipp Holl;Nils Thuerey,kiwon.um@tum.de;yf2320@columbia.edu;philipp.holl@tum.de;nils.thuerey@tum.de,6;3;3,,Reject,0,3,0,yes,9/25/19,Technical University Munich;Columbia University;Technical University Munich;Technical University Munich,PDEs;convolutional neural networks;numerical simulation;fluids,-1;24;-1;-1,-1;16;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Why do These Match? Explaining the Behavior of Image Similarity Models,Bryan A. Plummer;Mariya I. Vasileva;Vitali Petsiuk;Kate Saenko;David Forsyth,bplumme2@illinois.edu;mvasile2@illinois.edu;vpetsiuk@bu.edu;saenko@bu.edu;daf@illinois.edu,6;6;3,,Reject,0,5,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Boston University;Boston University;University of Illinois, Urbana Champaign",explainable artificial intelligence;image similarity;artificial intelligence for fashion,-1;-1;79;79;-1,-1;-1;61;61;-1,m;m,usa,usa,n
ICLR,2020,Towards an Adversarially Robust Normalization Approach,Muhammad Awais;Fahad Shamshad;Sung-Ho Bae,awais@khu.ac.kr;fahad.shamshad@itu.edu.pk;shbae@khu.ac.kr,3;3;6,,Reject,3,0,0,yes,9/25/19,"Kyung Hee University;ITU of Punjab Lahore, Pakistan;Kyung Hee University",robustness;BatchNorm;adversarial,445;-1;445,319;-1;319,m;m,asia,kr,n
ICLR,2020,When Does Self-supervision Improve Few-shot Learning?,Jong-Chyi Su;Subhransu Maji;Bharath Hariharan,jcsu@cs.umass.edu;smaji@cs.umass.edu;bharathh@cs.cornell.edu,3;3;8,,Reject,0,4,0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;Cornell University",Few-shot learning;Self-supervised learning;Meta-learning;Multi-task learning,24;24;7,209;209;19,m;m,usa,usa,n
ICLR,2020,D3PG: Deep Differentiable Deterministic Policy Gradients,Tao Du;Yunfei Li;Jie Xu;Andrew Spielberg;Kui Wu;Daniela Rus;Wojciech Matusik,taodu@csail.mit.edu;l-yf16@mails.tsinghua.edu.cn;jiex@csail.mit.edu;aespielberg@csail.mit.edu;walker.kui.wu@gmail.com;rus@csail.mit.edu;wojciech@csail.mit.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,"Massachusetts Institute of Technology;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology",differentiable simulator;model-based control;policy gradients,5;4;5;5;5;5;5,5;23;5;5;5;5;5,m;m,usa,usa,n
ICLR,2020,Sparse Transformer: Concentrated Attention Through Explicit Selection,Guangxiang Zhao;Junyang Lin;Zhiyuan Zhang;Xuancheng Ren;Xu Sun,1701214310@pku.edu.cn;junyang.ljy@alibaba-inc.com;zzy1210@pku.edu.cn;renxc@pku.edu.cn;xusun@pku.edu.cn,1;3;6,,Reject,1,7,0,yes,9/25/19,Peking University;Alibaba Group;Peking University;Peking University;Peking University,Attention;Transformer;Machine Translation;Natural Language Processing;Sparse;Sequence to sequence learning,14;-1;14;14;14,24;-1;24;24;24,m;m,asia,cn,n
ICLR,2020,SAFE-DNN: A Deep Neural Network with Spike Assisted Feature Extraction for Noise Robust Inference,Xueyuan She;Priyabrata Saha;Daehyun Kim;Yun Long;Saibal Mukhopadhyay,xshe6@gatech.edu;priyabratasaha@gatech.edu;daehyun.kim@gatech.edu;yunlong@gatech.edu;saibal.mukhopadhyay@ece.gatech.edu,3;6;3,,Reject,1,4,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Noise robust;deep learning;DNN;image classification,13;13;13;13;13,38;38;38;38;38,m;m,usa,usa,n
ICLR,2020,TWIN GRAPH CONVOLUTIONAL NETWORKS: GCN WITH DUAL GRAPH SUPPORT FOR SEMI-SUPERVISED LEARNING,Feng Shi;Yizhou Zhao;Ziheng Xu;Tianyang Liu;Song-Chun Zhu,shi.feng@cs.ucla.edu;yizhouzhao@ucla.edu;lawrencexu@ucla.edu,3;1;3,,Reject,0,0,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Graph;Neural Networks;Deep Learning;semi-supervised learning,-1;-1;-1,17;17;17,m;m,usa,usa,n
ICLR,2020,"Calibration, Entropy Rates, and Memory in Language Models",Mark Braverman;Xinyi Chen;Sham Kakade;Karthik Narasimhan;Cyril Zhang;Yi Zhang,mbraverm@cs.princeton.edu;xinyic@google.com;sham@cs.washington.edu;karthikn@cs.princeton.edu;cyril.zhang@cs.princeton.edu;y.zhang@cs.princeton.edu,6;6;3,,Reject,0,4,0,yes,9/25/19,Princeton University;Google;University of Washington;Princeton University;Princeton University;Princeton University,information theory;natural language processing;calibration,30;-1;11;30;30;30,6;-1;26;6;6;6,m;m,usa,usa,y
ICLR,2020,Deep End-to-end Unsupervised Anomaly Detection ,Li Tangqing;Wang Zheng;Liu Siying;Daniel Lin Wen-Yan,li_tangqing@u.nus.edu;sliu50@illinois.edu;zhwang@i2r.a-star.edu.sg;daniellin@smu.edu.sg,3;6;1,,Reject,0,5,0,yes,9/25/19,"National University of Singapore;University of Illinois, Urbana Champaign;Institute for Infocomm Research, A*STAR;Singapore Management University",,17;-1;-1;79,25;-1;-1;-1,u;m,asia,sg,n
ICLR,2020,Role-Wise Data Augmentation for Knowledge Distillation,Jie Fu;Xue Geng;Bohan Zhuang;Xingdi Yuan;Adam Trischler;Jie Lin;Vijay Chandrasekhar;Chris Pal,jie.fu@polymtl.ca;geng_xue@i2r.a-star.edu.sg;bohan.zhuang@adelaide.edu.au;eryua@microsoft.com;adam.trischler@microsoft.com;lin-j@i2r.a-star.edu.sg;vijay@i2r.a-star.edu.sg;christopher.pal@polymtl.ca,3;3;6,,Reject,0,4,0,yes,9/25/19,"Polytechnique Montreal;Institute for Infocomm Research, A*STAR;The University of Adelaide;Microsoft;Microsoft;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Polytechnique Montreal",Data Augmentation;Knowledge Distillation,316;-1;102;-1;-1;-1;-1;316,-1;-1;120;-1;-1;-1;-1;-1,m;m,canada,ca,n
ICLR,2020,HighRes-net: Multi-Frame Super-Resolution by Recursive Fusion,Michel Deudon;Alfredo Kalaitzis;Md Rifat Arefin;Israel Goytom;Zhichao Lin;Kris Sankaran;Vincent Michalski;Samira E Kahou;Julien Cornebise;Yoshua Bengio,michel.deudon@elementai.com;freddie@element.ai;rifat.arefin515@gmail.com;isrugeek@gmail.com;zhichao.lin@elementai.com;sankaran.kris@gmail.com;vincent.michalski@gmx.de;samira.ebrahimi-kahou@polymtl.ca;julien@elementai.com;yoshua.bengio@mila.quebec,8;3;1,,Reject,0,17,1,yes,9/25/19,Element AI;Element AI;;;Element AI;;University of Montreal;Polytechnique Montreal;Element AI;Mila,multi-frame super-resolution;super-resolution;remote sensing;fusion;de-aliasing;deep learning;registration,-1;-1;-1;-1;-1;-1;118;316;-1;143,-1;-1;-1;-1;-1;-1;85;-1;-1;336,m;m,NAN,NAN,n
ICLR,2020,Sparse and Structured Visual Attention,Pedro Henrique Martins;Vlad Niculae;Zita Marinho;Andr√© F.T. Martins,pedrohenriqueamartins@gmail.com;vlad@vene.ro;zita.marinho@priberam.pt;andre.martins@unbabel.com,3;3;6,,Reject,0,3,0,yes,9/25/19,Instituto Superior T√©cnico;University of Amsterdam;;Unbabel,Sparsity;attention;structured attention;total variation;fused lasso;image captioning,-1;143;-1;-1,-1;62;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Policy Tree Network,Zac Wellmer;Sepanta Zeighami;James Kwok,zac@1984.ai;szeighami@connect.ust.hk;jamesk@cse.ust.hk,3;1;3,,Reject,0,8,0,yes,9/25/19,Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,Reinforcement Learning,-1;-1;-1,-1;47;47,m;m,NAN,NAN,y
ICLR,2020,Bias-Resilient Neural Network,Ehsan Adeli;Qingyu Zhao;Adolf Pfefferbaum;Edith V. Sullivan;Fei-Fei Li;Juan Carlos Niebles;Kilian M. Pohl,eadeli@stanford.edu;qingyuz@stanford.edu;edie@stanford.edu;dolfp@stanford.edu;feifeili@cs.stanford.edu;jniebles@cs.stanford.edu;kilian.pohl@stanford.edu,8;1;3,,Reject,0,8,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,Invariant Feature Learning;Vanished Correlation;Generative Adversarial Networks;Gender Shades;Fairness in Machine Learning,5;5;5;5;5;5;5,4;4;4;4;4;4;4,m;m,usa,usa,n
ICLR,2020,ASYNCHRONOUS MULTI-AGENT GENERATIVE ADVERSARIAL IMITATION LEARNING,Xin Zhang;Weixiao Huang;Renjie Liao;Yanhua Li,xzhang17@wpi.edu;whuang2@wpi.edu;rjliao@cs.toronto.edu;yli15@wpi.edu,1;6;6,,Reject,1,20,0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute;University of Toronto;Worcester Polytechnic Institute,Multi-agent;Imitation Learning;Inverse Reinforcement Learning,143;143;18;143,628;628;18;628,f;m,usa,usa,y
ICLR,2020,Efficient Training of Robust and Verifiable Neural Networks,Akhilan Boopathy;Lily Weng;Sijia Liu;Pin-Yu Chen;Luca Daniel,akhilan@mit.edu;twweng@mit.edu;sijia.liu@ibm.com;pin-yu.chen@ibm.com;dluca@mit.edu,1;1;3,,Reject,0,6,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;International Business Machines;International Business Machines;Massachusetts Institute of Technology,,5;5;-1;-1;5,5;5;-1;-1;5,m;m,usa,usa,y
ICLR,2020,Adversarial Video Generation on Complex Datasets,Aidan Clark;Jeff Donahue;Karen Simonyan,aidanclark@google.com;jeffdonahue@google.com;simonyan@google.com,3;3;6,,Reject,1,4,0,yes,9/25/19,Google;Google;Google,GAN;generative model;generative adversarial network;video prediction,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Data Augmentation in Training CNNs: Injecting Noise to Images,Murtaza Eren Akbiyik,erenakbiyik@gmail.com,3;1;3,,Reject,2,0,0,yes,9/25/19,International Business Machines,deep learning;data augmentation;convolutional neural networks;noise;image processing;SSIM,-1,-1,m,NAN,NAN,n
ICLR,2020,Variational Diffusion Autoencoders with Random Walk Sampling,Henry Li;Ofir Lindenbaum;Xiuyuan Cheng;Alexander Cloninger,henryli@eng.ucsd.edu;ofir.lindenbaum@yale.edu;xiuyuan.cheng@duke.edu;acloninger@ucsd.edu,8;3;1,,Reject,0,4,0,yes,9/25/19,"University of California, San Diego;Yale University;Duke University;University of California, San Diego",generative models;variational inference;manifold learning;diffusion maps,-1;73;46;-1,31;8;20;31,m;m,usa,usa,y
ICLR,2020,"INFERENCE, PREDICTION, AND ENTROPY RATE OF CONTINUOUS-TIME, DISCRETE-EVENT PROCESSES",Sarah Marzen;James P. Crutchfield,smarzen@cmc.edu;chaos@cse.ucdavis.edu,1;3;1,,Reject,0,0,0,yes,9/25/19,"Central Methodist College;University of California, Davis",continuous-time prediction,-1;-1,-1;55,f;m,usa,usa,n
ICLR,2020,Scale-Equivariant Neural Networks with Decomposed Convolutional Filters,Wei Zhu;Qiang Qiu;Robert Calderbank;Guillermo Sapiro;Xiuyuan Cheng,zhu@math.duke.edu;qiang.qiu@duke.edu;robert.calderbank@duke.edu;guillermo.sapiro@duke.edu;xiuyuan.cheng@duke.edu,6;3;6,,Reject,1,5,0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University;Duke University,scale-equivariant;convolutional neural network;deformation robustness,46;46;46;46;46,20;20;20;20;20,m;m,europe,se,y
ICLR,2020,Dynamic Scale Inference by Entropy Minimization,Dequan Wang;Evan Shelhamer;Bruno Olshausen;Trevor Darrell,dqwang@eecs.berkeley.edu;shelhamer@cs.berkeley.edu;baolshausen@berkeley.edu;trevor@eecs.berkeley.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,unsupervised learning;dynamic inference;equivariance;entropy,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n
ICLR,2020,The Effect of Residual Architecture on the Per-Layer Gradient of Deep Networks,Etai Littwin;Lior Wolf,etai.littwin@gmail.com;wolf@fb.com,1;6;6,,Reject,0,4,1,yes,9/25/19,Tel Aviv University;Facebook,,30;-1,188;-1,m;m,NAN,NAN,n
ICLR,2020,City Metro Network Expansion with Reinforcement Learning,Yu Wei;Minjia Mao;Xi Zhao;Jianhua Zou,weiyu123112@163.com;maominjia@foxmail.com;zhaoxi1@mail.xjtu.edu.cn;jhzou@sei.xjtu.edu.cn,3;3;3,,Reject,0,0,0,yes,9/25/19,Xi'an Jiaotong University;Foxmail;Xi'an Jiaotong University;Xi'an Jiaotong University,,-1;-1;-1;-1,555;-1;555;555,m;m,NAN,NAN,n
ICLR,2020,Dropout: Explicit Forms and Capacity Control,Raman Arora;Peter L. Bartlett;Poorya Mianjy;Nathan Srebro,arora@cs.jhu.edu;bartlett@cs.berkeley.edu;mianjy@jhu.edu;nati@ttic.edu,1;1;3;1,,Reject,0,5,0,yes,9/25/19,Johns Hopkins University;University of California Berkeley;Johns Hopkins University;Toyota Technological Institute at Chicago,,73;-1;73;-1,12;13;12;-1,m;m,NAN,NAN,y
ICLR,2020,Verification of Generative-Model-Based Visual Transformations,Matthew Mirman;Timon Gehr;Martin Vechev,matthew.mirman@inf.ethz.ch;timon.gehr@inf.ethz.ch;martin.vechev@inf.ethz.ch,3;3;6,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,robustness certification;formal verification;robustness analysis;latent space interpolations,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Beyond GANs: Transforming without a Target Distribution,Matthew Amodio;David van Dijk;Ruth Montgomery;Guy Wolf;Smita Krishnaswamy,matthew.amodio@yale.edu;david.vandijk@yale.edu;ruth.montgomery@yale.edu;guy.wolf@umontreal.ca;smita.krishnaswamy@yale.edu,6;6;3,,Reject,0,3,0,yes,9/25/19,Yale University;Yale University;Yale University;University of Montreal;Yale University,GAN;domain transfer;computational biology;latent space manipulations,73;73;73;118;73,8;8;8;85;8,m;f,europe,fi,n
ICLR,2020,On Variational Learning of Controllable Representations for Text without Supervision,Peng Xu;Yanshuai Cao;Jackie Chi Kit Cheung,pxu4@ualberta.ca;yanshuaicao@gmail.com;jcheung@cs.mcgill.ca,8;3;6,,Reject,0,5,1,yes,9/25/19,University of Alberta;;McGill University,sequence variational autoencoders;unsupervised learning;controllable text generation;text style transfer,102;-1;102,136;-1;42,m;m,canada,ca,n
ICLR,2020,Demystifying Graph Neural Network Via Graph Filter Assessment,Yewen Wang;Ziniu Hu;Yusong Ye;Yizhou Sun,wyw10804@gmail.com;bull@cs.ucla.edu;yusongye@g.ucla.edu;yzsun@cs.ucla.edu,8;1;3,,Reject,3,6,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Graph Neural Networks;Graph convolutional filter analysis;representational power,-1;-1;-1;-1,17;17;17;17,u;f,usa,usa,y
ICLR,2020,Individualised Dose-Response Estimation using Generative Adversarial Nets,Ioana Bica;James Jordon;Mihaela van der Schaar,ioana.bica@eng.ox.ac.uk;james.jordon@wolfson.ox.ac.uk;mschaar@turing.ac.uk,1;3;3,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford;Alan Turing Institute,individualised dose-response estimation;treatment effects;causal inference;generative adversarial networks,46;46;-1,1;1;-1,f;f,NAN,NAN,n
ICLR,2020,"``Best-of-Many-Samples"" Distribution Matching""",Apratim Bhattacharyya;Mario Fritz;Bernt Schiele,abhattac@mpi-inf.mpg.de;fritz@cispa.saarland;schiele@mpi-inf.mpg.de,3;3;6,,Reject,0,0,0,yes,9/25/19,Max-Planck Institute;CISPA Helmholtz Center for Information Security;Max-Planck Institute,Distribution Matching;Generative Adversarial Networks;Variational Autoencoders,-1;92;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Swoosh! Rattle! Thump! - Actions that Sound,Dhiraj Gandhi;Abhinav Gupta;Lerrel Pinto,g.prakashchand@gmail.com;abhinavg@cs.cmu.edu;lerrel.pinto@gmail.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;New York University,Sound;Action;Audio Representations,-1;1;22,-1;27;29,m;m,usa,usa,n
ICLR,2020,Near-Zero-Cost Differentially Private Deep Learning with Teacher Ensembles,Lichao Sun;Yingbo Zhou;Jia Li;Richard Socher;Philip S. Yu;Caiming Xiong,james.lichao.sun@gmail.com;yingbo.zhou@salesforce.com;jia.li@salesforce.com;rsocher@salesforce.com;psyu@uic.edu;cxiong@salesforce.com,1;1;1,,Reject,0,3,0,yes,9/25/19,"Lehigh University;SalesForce.com;SalesForce.com;SalesForce.com;University of Illinois, Chicago;SalesForce.com",,248;-1;-1;-1;-1;-1,633;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,On the Tunability of Optimizers in Deep Learning,Prabhu Teja S*;Florian Mai*;Thijs Vogels;Martin Jaggi;Francois Fleuret,prabhu.teja@idiap.ch;florian.mai@idiap.ch;thijs.vogels@epfl.ch;martin.jaggi@epfl.ch;francois.fleuret@idiap.ch,3;3,,Reject,0,10,0,yes,9/25/19,Idiap Research Institute;Idiap Research Institute;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Idiap Research Institute,Optimization;Benchmarking;Hyperparameter optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,GUIDEGAN:  ATTENTION  BASED  SPATIAL  GUIDANCE FOR  IMAGE-TO-IMAGE TRANSLATION,Yu Lin;Yigong Wang;Yifan Li;Zhuoyi Wang;Yang Gao;Latifur Khan,yxl163430@utdallas.edu;yxw158830@utdallas.edu;yli@utdallas.edu;zhuoyi.wang1@utdallas.edu;yxg122530@utdallas.edu;lkhan@utdallas.edu,3;3;3,,Reject,0,5,0,yes,9/25/19,"University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas;University of Texas, Dallas",Image-to-Image translation;Attention Learning;GAN,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,f;m,usa,usa,n
ICLR,2020,ROBUST GENERATIVE ADVERSARIAL NETWORK,Shufei Zhang;Zhuang Qian;Kaizhu Huang;Rui Zhang;Jimin Xiao,shufei.zhang@xjtlu.edu.cn;qz2009425@gmail.com;kaizhu.huang@xjtlu.edu.cn;rui.zhang02@xjtlu.edu.cn;jimin.xiao@xjtlu.edu.cn,1;3;3,,Reject,0,0,0,yes,9/25/19,Xi'an Jiaotong-Liverpool University;;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University;Xi'an Jiaotong-Liverpool University,Generative Adversarial Network;Robustness;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;u,NAN,NAN,y
ICLR,2020,Decoupling Hierarchical Recurrent Neural Networks With Locally Computable Losses,Asier Mujika;Felix Weissenberger;Angelika Steger,asierm@inf.ethz.ch;felix.weissenberger@inf.ethz.ch;steger@inf.ethz.ch,1;1;1,,Reject,0,1,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Branched Multi-Task Networks: Deciding What Layers To Share,Simon Vandenhende;Stamatios Georgoulis;Bert De Brabandere;Luc Van Gool,simon.vandenhende@kuleuven.be;georgous@ee.ethz.ch;bert.debrabandere@esat.kuleuven.be;vangool@vision.ee.ethz.ch,3;6;1,,Reject,0,5,0,yes,9/25/19,KU Leuven;Swiss Federal Institute of Technology;KU Leuven;Swiss Federal Institute of Technology,Multi-Task Learning;Neural Network Architectures;Deep learning;Efficient Architectures,143;-1;143;-1,45;-1;45;-1,m;m,NAN,NAN,n
ICLR,2020,Variational pSOM: Deep Probabilistic Clustering with Self-Organizing Maps,Laura Manduchi;Matthias H√ºser;Gunnar R√§tsch;Vincent Fortuin,lauraman@student.ethz.ch;matthias.hueser@inf.ethz.ch;gunnar.ratsch@ratschlab.org;fortuin@inf.ethz.ch,3;3;3,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;MSKCC New York;Swiss Federal Institute of Technology,Self-organizing maps;Generative models;Unsupervised representation learning,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Tensor Graph Convolutional Networks for Prediction on Dynamic Graphs,Osman Asif Malik;Shashanka Ubaru;Lior Horesh;Misha E. Kilmer;Haim Avron,osman.malik.87@gmail.com;shashanka.ubaru@ibm.com;lhoresh@us.ibm.com;misha.kilmer@tufts.edu;haimav@tauex.tau.ac.il,3;6;1,,Reject,0,5,0,yes,9/25/19,"University of Colorado, Boulder;International Business Machines;International Business Machines;Tufts University;Tel Aviv University",graph convolutional networks;graph learning;dynamic graphs;edge classification;tensors,59;-1;-1;194;30,123;-1;-1;139;188,m;m,europe,il,y
ICLR,2020,Mint: Matrix-Interleaving for Multi-Task Learning,Tianhe Yu;Saurabh Kumar;Eric Mitchell;Abhishek Gupta;Karol Hausman;Sergey Levine;Chelsea Finn,tianheyu@cs.stanford.edu;szk@stanford.edu;eric.anthony.mitchell95@gmail.com;abhigupta@berkeley.edu;hausmankarol@gmail.com;svlevine@eecs.berkeley.edu;cbfinn@cs.stanford.edu,3;3;3;6,,Reject,0,5,0,yes,9/25/19,Stanford University;Stanford University;;University of California Berkeley;Google;University of California Berkeley;Stanford University,multi-task learning,5;5;-1;-1;-1;-1;5,4;4;-1;13;-1;13;4,m;f,usa,usa,y
ICLR,2020,Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients,Chengcheng Ma;Baoyuan Wu;Shibiao Xu;Yanbo Fan;Yong Zhang;Xiaopeng Zhang;Zhifeng Li,machengcheng2016@gmail.com;wubaoyuan1987@gmail.com;shibiao.xu@ia.ac.cn;fanyanbo0124@gmail.com;zhangyong201303@gmail.com;xiaopeng.zhang@ia.ac.cn;michaelzfli@tencent.com,6;6;3,,Reject,0,3,0,yes,9/25/19,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;The Chinese University of Hong Kong, Shenzhen;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tencent AI Lab;;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Tencent AI Lab",,-1;46;30;-1;-1;30;-1,-1;35;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Multi-objective Neural Architecture Search via Predictive Network Performance Optimization,Han Shi;Renjie Pi;Hang Xu;Zhenguo Li;James T. Kwok;Tong Zhang,hshiac@cse.ust.hk;pipilu@connect.hku.hk;xbjxh@live.com;li.zhenguo@huawei.com;jamesk@cse.ust.hk;tongzhang@tongzhang-ml.org,3;3;3,,Reject,1,8,0,yes,9/25/19,The Hong Kong University of Science and Technology;The University of Hong Kong;Huawei Technologies Ltd.;Huawei Technologies Ltd.;The Hong Kong University of Science and Technology;Google,,-1;92;-1;-1;-1;-1,47;35;-1;-1;47;-1,m;m,NAN,NAN,n
ICLR,2020,CONFEDERATED MACHINE LEARNING ON HORIZONTALLY AND VERTICALLY SEPARATED MEDICAL DATA FOR LARGE-SCALE HEALTH SYSTEM INTELLIGENCE,Dianbo Liu;Tim Miller;Kenneth Mandl,dianbo.liu@childrens.harvard.edu;timothy.miller@childrens.harvard.edu;kenneth.mandl@childrens.harvard.edu,3;1;1,,Reject,0,0,0,yes,9/25/19,Harvard University;Harvard University;Harvard University,Confederated learning;siloed medical data;representation joining,52;52;52,7;7;7,m;m,usa,usa,n
ICLR,2020,On Evaluating Explainability Algorithms,Gokula Krishnan Santhanam;Ali Alami-Idrissi;Nuno Mota;Anika Schumann;Ioana Giurgiu,gst@zurich.ibm.com;aai@zurich.ibm.com;nuno.motagoncalves@epfl.ch;ikh@zurich.ibm.com;igi@zurich.ibm.com,1;3;1,,Reject,0,6,0,yes,9/25/19,International Business Machines;International Business Machines;Swiss Federal Institute of Technology Lausanne;International Business Machines;International Business Machines,interpretability;Deep Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,FRICATIVE PHONEME DETECTION WITH ZERO DELAY,Metehan Yurt;Alberto N. Escalante B.;Veniamin I. Morgenshtern,metehan.yurt@fau.de;alberto.escalante@sivantos.com;veniamin.morgenshtern@fau.de,3;3;6,,Reject,0,3,0,yes,9/25/19,Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg;Sivantos;Friedrich-Alexander Universit√§t Erlangen-N√ºrnberg,fricative detection;phoneme detection;speech recognition;deep learning;hearing aids;zero delay;extrapolation;TIMIT,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Deep Mining: Detecting Anomalous Patterns in Neural Network Activations with Subset Scanning,Skyler Speakman;Celia Cintas;Victor Akinwande;Srihari Sridharan;Edward McFowland III,skyler@ke.ibm.com;celia.cintas@ibm.com;victor.akinwande1@ibm.com;sriharis.sridharan@ke.ibm.com;mcfowland@umn.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,"International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Minnesota, Minneapolis",anomalous pattern detection;subset scanning;node activations;adversarial noise,-1;-1;-1;-1;73,-1;-1;-1;-1;79,m;m,NAN,NAN,n
ICLR,2020,"GRAPHS, ENTITIES, AND STEP MIXTURE",Kyuyong Shin;Wonyoung Shin;Jung-Woo Ha;Sunyoung Kwon,p37329@gmail.com;wyshin@kaist.ac.kr;jungwoo.ha@navercorp.com;sunny.kwon@navercorp.com,3;6;3,,Reject,0,7,0,yes,9/25/19,NAVER;Korea Advanced Institute of Science and Technology;NAVER;NAVER,Graph Neural Network;Random Walk;Attention,-1;-1;-1;-1,-1;110;-1;-1,m;f,europe,gr,n
ICLR,2020,Learning Human Postural Control with Hierarchical Acquisition Functions,Nils Rottmann;Tjasa Kunavar;Jan Babic;Jan Peters;Elmar Rueckert,rottmann@rob.uni-luebeck.de;tjasa.kunavar@ijs.si;jan.babic@ijs.si;mail@jan-peters.net;rueckert@ai-lab.science,1;1,,Reject,0,3,0,yes,9/25/19,Universit√§t zu L√ºbeck;Jozef Stefan institute;Jozef Stefan institute;TU Darmstadt;Universit√§t zu L√ºbeck,Human Postural Control Model;Hierarchical Bayesian Optimization;Acquisition Function,-1;-1;-1;59;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unknown-Aware Deep Neural Network,Lei Cao;Yizhou Yan;Samuel Madden;Elke Rundensteiner,lcao@csail.mit.edu;yyan2@wpi.edu;madden@csail.mit.edu;rundenst@cs.wpi.edu,8;3;3,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Worcester Polytechnic Institute;Massachusetts Institute of Technology;Worcester Polytechnic Institute,unknown;rejection;CNN;product relationship,5;143;5;143,5;628;5;628,m;f,usa,usa,n
ICLR,2020,Low Bias Gradient Estimates for Very Deep Boolean Stochastic Networks,Adeel Pervez;Taco Cohen;Efstratios Gavves,a.a.pervez@uva.nl;tacos@qti.qualcomm.com;efstratios.gavves@gmail.com,3;6;6,,Reject,0,11,0,yes,9/25/19,"University of Amsterdam;Qualcomm Inc, QualComm;University of Amsterdam",,143;-1;143,62;-1;62,m;m,europe,nl,y
ICLR,2020,SoftLoc: Robust Temporal Localization under Label Misalignment,Julien Schroeter;Kirill Sidorov;Dave Marshall,schroeterj1@cardiff.ac.uk;sidorovk@cardiff.ac.uk;marshallad@cardiff.ac.uk,3;6;3,,Reject,0,6,0,yes,9/25/19,Cardiff University;Cardiff University;Cardiff University,deep learning;temporal localization;robustness;label misalignment;music;time series,168;168;168,196;196;196,m;m,europe,uk,n
ICLR,2020,Learning Video Representations using Contrastive Bidirectional Transformer,Chen Sun;Fabien Baradel;Kevin Murphy;Cordelia Schmid,chensun@google.com;fabien.baradel@insa-lyon.fr;kpmurphy@google.com;cordelias@google.com,6;6;6,,Reject,0,3,0,yes,9/25/19,Google;INSA de Lyon;Google;Google,self-supervised learning;video representations;cross-modal learning,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,ShardNet: One Filter Set to Rule Them All,Saumya Jetley;Tommaso Cavallari;Philip Torr;Stuart Golodetz,sjetley@robots.ox.ac.uk;tommaso.cavallari@five.ai;phil@five.ai;stuart@five.ai,3;3;1,,Reject,0,7,0,yes,9/25/19,University of Oxford;FiveAI;FiveAI;FiveAI,neural network compression;filter sharing;network interpretability,46;-1;-1;-1,1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Explaining Time Series by Counterfactuals,Sana Tonekaboni;Shalmali Joshi;David Duvenaud;Anna Goldenberg,stonekaboni@cs.toronto.edu;shalmali@vectorinstitute.ai;duvenaud@cs.toronto.edu;anna.goldenberg@utoronto.ca,6;3;3,,Reject,0,4,0,yes,9/25/19,University of Toronto;Vector Institute;University of Toronto;Toronto University,explainability;counterfactual modeling;time series,18;-1;18;-1,18;-1;18;-1,f;f,NAN,NAN,n
ICLR,2020,On the Linguistic Capacity of Real-time Counter Automata,William Merrill,vikingarnir.will@gmail.com,6;1;6,,Reject,0,4,0,yes,9/25/19,Allen Institute for Artificial Intelligence,formal language theory;counter automata;natural language processing;deep learning,-1,-1,m,NAN,NAN,y
ICLR,2020,The fairness-accuracy landscape of neural classifiers,Susan Wei;Marc Niethammer,susan.wei@unimelb.edu.au;mn@cs.unc.edu,1;6;3,,Reject,0,5,0,yes,9/25/19,"The University of Melbourne;University of North Carolina, Chapel Hill",,85;64,32;-1,f;m,NAN,NAN,n
ICLR,2020,Corpus Based Amharic Sentiment Lexicon Generation,Girma Neshir;Andeas Rauber;and Solomon Atnafu,girma1978@gmail.com;rauber@ifs.tuwien.ac.at;solomon.atnafu@aau.edu.et,1;1;1,,Reject,0,0,0,yes,9/25/19,Addis Ababa University;TU Wien Vienna University of Technology;Addis Ababa University,Amharic sentiment lexicon;Amharic sentiment classification;seed words,-1;102;-1,-1;360;-1,m;m,NAN,NAN,n
ICLR,2020,MaskConvNet: Training Efficient ConvNets from Scratch via Budget-constrained Filter Pruning,Raden Mu'az Mun'im;Jie Lin;Vijay Chandrasekhar;Koichi Shinoda,raden.m.muaz@gmail.com;lin-j@i2r.a-star.edu.sg;vijay@i2r.a-star.edu.sg;shinoda@ks.cs.titech.ac.jp,3;3;3,,Reject,0,8,0,yes,9/25/19,"Universiti Teknologi Malaysia;Institute for Infocomm Research, A*STAR;Institute for Infocomm Research, A*STAR;Tokyo Institute of Technology",Structured Pruning;Sparsity Regularization;Budget-Aware,-1;-1;-1;168,674;-1;-1;299,m;m,asia,jp,n
ICLR,2020,Curvature-based Robustness Certificates against Adversarial Examples,Sahil Singla;Soheil Feizi,ssingla@cs.umd.edu;sfeizi@cs.umd.edu,6;6;6,,Reject,0,8,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park",Adversarial examples;Robustness certificates;Adversarial attacks;Machine Learning Security,12;12,91;91,m;m,usa,usa,y
ICLR,2020,Pipelined Training with Stale Weights of Deep Convolutional Neural Networks,Lifu Zhang;Tarek S. Abdelrahman,lifu.zhang@mail.utoronto.ca;tsa@ece.utoronto.ca,3;6;3;3,,Reject,0,6,0,yes,9/25/19,Toronto University;Toronto University,Distributed CNN Training;Pipelined Backpropagation;Training with Stale Weights,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Information Plane Analysis of Deep Neural Networks via Matrix--Based Renyi's Entropy and Tensor Kernels,Kristoffer Wickstr√∏m;Sigurd L√∏kse;Michael Kampffmeyer;Shujian Yu;Jose Principe;Robert Jenssen,kristoffer.k.wickstrom@uit.no;sigurd.lokse@uit.no;michael.c.kampffmeyer@uit.no;yusjlcy9011@cnel.ufl.edu;principe@cnel.ufl.edu;robert.jenssen@uit.no,3;6;6,,Reject,0,4,0,yes,9/25/19,UiT The Arctic University of Norway;UiT The Arctic University of Norway;UiT The Arctic University of Norway;University of Florida;University of Florida;UiT The Arctic University of Norway,information plane;information theory;deep neural networks;entropy;mutual information;tensor kernels,-1;-1;-1;168;168;-1,419;419;419;174;174;419,m;m,NAN,NAN,y
ICLR,2020,Disentangled Representation Learning with Sequential Residual Variational Autoencoder,Nanxiang Li;Shabnam Ghaffarzadegan;Liu Ren,nanxiang.li@us.bosch.com;shabnam.ghaffarzadegan@us.bosch.com;liu.ren@us.bosch.com,3;8;3,,Reject,0,3,0,yes,9/25/19,Bosch;Bosch;Bosch,Disentangled Representation Learning;Variational Autoencoder;Residual Learning,-1;-1;-1,297;297;297,m;m,NAN,NAN,n
ICLR,2020,MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics,Mohammadamin Barekatain;Ryo Yonetani;Masashi Hamaya,m.barekatain@tum.de;ryo.yonetani@sinicx.com;masashi.hamaya@sinicx.com,1;8;6,,Reject,0,7,0,yes,9/25/19,Technical University Munich;OMRON SINIC X;OMRON SINIC X,reinforcement learning;transfer learning;policy aggregation;residual policy learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Simultaneous Classification and Out-of-Distribution Detection Using Deep Neural Networks,Aristotelis-Angelos Papadopoulos;Nazim Shaikh;Jiamian Wang;Mohammad Reza Rajati,aristotp@usc.edu;nshaikh@usc.edu;jiamianw@usc.edu;rajati@usc.edu,6;1;3,,Reject,0,11,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;University of Southern California,Out-of-Distribution Detection;OOD detection;Outlier Exposure;Classification;Open-World Classification;Anomaly Detection;Novelty Detection;Calibration;Neural Networks,36;36;36;36,62;62;62;62,m;m,usa,usa,n
ICLR,2020,"Learning vector representation of local content and matrix representation of local motion, with implications for V1",Ruiqi Gao;Jianwen Xie;Siyuan Huang;Yufan Ren;Song-Chun Zhu;Ying Nian Wu,ruiqigao@ucla.edu;jianwen@ucla.edu;huangsiyuan@ucla.edu;3160104704@zju.edu.cn;sczhu@stat.ucla.edu;ywu@stat.ucla.edu,3;1;6,,Reject,0,5,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;Zhejiang University;University of California, Los Angeles;University of California, Los Angeles",Representation learning;V1;neuroscience,-1;-1;-1;39;-1;-1,17;17;17;107;17;17,f;m,usa,usa,n
ICLR,2020,Data Valuation using Reinforcement Learning,Jinsung Yoon;Sercan O. Arik;Tomas Pfister,jsyoon0823@gmail.com;soarik@google.com;tpfister@google.com,6;6;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google,Data valuation;Domain adaptation;Robust learning;Corrupted sample discovery,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Reject Illegal Inputs: Scaling Generative Classifiers with Supervised Deep Infomax,Xin WANG;SiuMing Yiu,xwang@cs.hku.hk;smyiu@cs.hku.hk,3;8;3,,Reject,0,3,1,yes,9/25/19,The University of Hong Kong;The University of Hong Kong,generative classifiers;selective classification;classification with rejection,92;92,35;35,u;m,NAN,NAN,n
ICLR,2020,Surrogate-Based Constrained Langevin Sampling With Applications to Optimal Material Configuration Design,Thanh V Nguyen;Youssef Mroueh;Samuel C. Hoffman;Payel Das;Pierre Dognin;Giuseppe Romano;Chinmay Hegde,thanhng@iastate.edu;mroueh@us.ibm.com;shoffman@ibm.com;daspa@us.ibm.com;pdognin@us.ibm.com;romanog@mit.edu;chinmay@iastate.edu,3;6;6,,Reject,0,4,0,yes,9/25/19,Iowa State University;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Massachusetts Institute of Technology;Iowa State University,Black-box Constrained Langevin sampling;surrogate methods;projected and proximal methods;approximation theory of gradients;nano-porous material configuration design,194;-1;-1;-1;-1;5;194,399;-1;-1;-1;-1;5;399,m;m,usa,usa,y
ICLR,2020,VILD: Variational Imitation Learning with Diverse-quality Demonstrations,Voot Tangkaratt;Bo Han;Mohammad Emtiyaz Khan;Masashi Sugiyama,voot.tangkaratt@riken.jp;bo.han@riken.jp;emtiyaz.khan@riken.jp;sugi@k.u-tokyo.ac.jp,6;3;6,,Reject,0,4,0,yes,9/25/19,RIKEN;RIKEN;RIKEN;The University of Tokyo,Imitation learning;inverse reinforcement learning;noisy demonstrations,-1;-1;-1;64,-1;-1;-1;36,m;m,NAN,NAN,n
ICLR,2020,OPTIMAL BINARY QUANTIZATION FOR DEEP NEURAL NETWORKS,Hadi Pouransari;Oncel Tuzel,mpouransari@apple.com;onceltuzel@gmail.com,3;3;6;6,,Reject,0,5,1,yes,9/25/19,Apple;Apple,Binary Neural Networks;Quantization,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Through Limited Self-Supervision: Improving Time-Series Classification Without Additional Data via Auxiliary Tasks,Ian Fox;Harry Rubin-Falcone;Jenna Wiens,ifox@umich.edu;hrf@umich.edu;wiensj@umich.edu,1;3;1,,Reject,0,4,0,yes,9/25/19,University of Michigan;University of Michigan;University of Michigan,Sequential Representation Learning;Self-Supervision;Function Approximation,7;7;7,21;21;21,m;f,usa,usa,n
ICLR,2020,Robust Natural Language Representation Learning for Natural Language Inference by Projecting Superficial Words out,Wanyun Cui;Guangyu Zheng;Wei Wang,cui.wanyun@sufe.edu.cn;simonzgy@outlook.com;weiwang1@fudan.edu.cn,1;3;1,,Reject,0,0,0,yes,9/25/19,University of Science and Technology of China;;Fudan University,natural language inference;first order logic,-1;-1;73,80;-1;109,m;f,asia,cn,n
ICLR,2020,DSReg: Using Distant Supervision as a Regularizer,Yuxian Meng;Muyu Li;Xiaoya Li;Wei Wu;Fei Wu;Jiwei Li,yuxian_meng@shannonai.com;muyu_li@shannonai.com;xiaoya_li@shannonai.com;wei_wu@shannonai.com;wufei@zju.edu.cn;jiwei_li@shannonai.com,6;3;3,,Reject,0,2,0,yes,9/25/19,Shannon.AI;Shannon.AI;Shannon.AI;Shannon.AI;Zhejiang University;Shannon.AI,,-1;-1;-1;-1;39;-1,-1;-1;-1;-1;107;-1,m;m,NAN,NAN,n
ICLR,2020,MxPool: Multiplex Pooling for Hierarchical Graph Representation Learning,Yanyan Liang;Yanfeng Zhang;Fangjing Wang;Qian Xu,13354227340@163.com;zhangyf@mail.neu.edu.cn;inggraph@qq.com;xuqian1286@163.com,3;3;3,,Reject,0,0,0,yes,9/25/19,163;Northeastern University;;163,GNN;graph pooling;graph representation learning,-1;16;-1;-1,-1;906;-1;-1,f;f,asia,in,n
ICLR,2020,Non-linear System Identification from Partial Observations via Iterative Smoothing and Learning,Kunal Menda;Jean de Becdeli√®vre;Jayesh K Gupta;Ilan Kroo;Mykel J. Kochenderfer;Zachary Manchester,kmenda@stanford.edu;jeandb@stanford.edu;jkg@cs.stanford.edu;kroo@stanford.edu;mykel@stanford.edu;zacmanchester@stanford.edu,6;6;6,,Reject,0,6,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,System Identification;Dynamical Systems;Partial Observations;Non-linear Programming;Expectation Maximization;Neural Networks,5;5;5;5;5;5,4;4;4;4;4;4,m;m,usa,usa,n
ICLR,2020,Policy Message Passing: A New Algorithm for Probabilistic Graph Inference,Zhiwei Deng;Greg Mori,zhiweid@princeton.edu;mori@cs.sfu.ca,1;3;3,,Reject,0,0,0,yes,9/25/19,Princeton University;Simon Fraser University,graph inference algorithm;graph reasoning;variational inference,30;52,6;272,m;m,canada,ca,n
ICLR,2020,Learning Mahalanobis Metric Spaces via Geometric Approximation Algorithms,Diego Ihara;Neshat Mohammadi;Anastasios Sidiropoulos,dihara@gmail.com;nmoham24@uic.edu;sidiropo@uic.edu,3;6;3,,Reject,0,3,0,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",Metric Learning;Geometric Algorithms;Approximation Algorithms,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y
ICLR,2020,On Understanding Knowledge Graph Representation,Carl Allen*;Ivana Balazevic*;Timothy M Hospedales,carl.allen@ed.ac.uk;ivana.balazevic@ed.ac.uk;t.hospedales@ed.ac.uk,6;6;6,,Reject,1,6,1,yes,9/25/19,University of Edinburgh;University of Edinburgh;University of Edinburgh,knowledge graphs;word embedding;representation learning,36;36;36,30;30;30,m;m,europe,uk,n
ICLR,2020,Learning to Prove Theorems by Learning to Generate Theorems,Mingzhe Wang;Jia Deng,mingzhew@cs.princeton.edu;jiadeng@princeton.edu,6;6;3,,Reject,0,6,0,yes,9/25/19,Princeton University;Princeton University,,30;30,6;6,m;m,usa,usa,n
ICLR,2020,Augmenting Self-attention with Persistent Memory,Sainbayar Sukhbaatar;Edouard Grave;Guillaume Lample;Herve Jegou;Armand Joulin,sainbar@fb.com;egrave@fb.com;guismay@fb.com;rvj@fb.com;ajoulin@fb.com,3;6;6,,Reject,0,2,0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook;Facebook,transformer;language modeling;self-attention,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Realism Index: Interpolation in Generative Models With Arbitrary Prior,≈Åukasz Struski;Jacek Tabor;Igor Podolak;Aleksandra Nowak;Krzysztof Maziarz,lukasz.struski@uj.edu.pl;jacek.tabor@uj.edu.pl;igor.podolak@uj.edu.pl;aknoow@gmail.com;krzysztof.s.maziarz@gmail.com,3;3,,Reject,0,6,0,yes,9/25/19,Jagiellonian University;Jagiellonian University;Jagiellonian University;;Microsoft,,-1;-1;-1;-1;-1,610;610;610;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Fully Convolutional Graph Neural Networks using Bipartite Graph Convolutions,Marcel Nassar;Xin Wang;Evren Tumer,nassar.marcel@gmail.com;caseus.viridis@gmail.com;nervetumer@gmail.com,3;1;3,,Reject,1,3,0,yes,9/25/19,"Intel;Cerebras Systems, Inc;University of California, San Francisco",Graph Neural Networks;Graph Convolutional Networks,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Selective sampling for accelerating  training of deep neural networks,Berry Weinstein;Shai Fine;Yacov Hel-Or,berry.weinstein@post.idc.ac.il;shai.fine@idc.ac.il;toky@idc.ac.il,1;1;3,,Reject,0,2,0,yes,9/25/19,interdisciplinary center herzliya;interdisciplinary center herzliya;interdisciplinary center herzliya,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Hierarchical Graph-to-Graph Translation for Molecules,Wengong Jin;Regina Barzilay;Tommi Jaakkola,wengong@csail.mit.edu;regina@csail.mit.edu;tommi@csail.mit.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,graph generation;deep learning,5;5;5,5;5;5,m;m,usa,usa,n
ICLR,2020,MelNet: A Generative Model for Audio in the Frequency Domain,Sean Vasquez;Mike Lewis,seanjv@mit.edu;mikelewis@fb.com,6;3;8,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Facebook,,5;-1,5;-1,m;m,NAN,NAN,n
ICLR,2020,End-to-end learning of energy-based representations for irregularly-sampled signals and images,Ronan Fablet;Lucas Drumetz;Fran√ßois Rousseau,ronan.fablet@imt-atlantique.fr;lucas.drumetz@imt-atlantique.fr;francois.rousseau@imt-atlantique.fr,3;1;1,,Reject,0,0,0,yes,9/25/19,IMT Atlantique;IMT Atlantique;IMT Atlantique,end-to-end-learning;irregularly-sampled data;energy representations;optimal interpolation,-1;-1;-1,393;393;393,m;m,NAN,NAN,n
ICLR,2020,Reparameterized Variational Divergence Minimization for Stable Imitation,Dilip Arumugam;Debadeepta Dey;Alekh Agarwal;Asli Celikyilmaz;Elnaz Nouri;Eric Horvitz;Bill Dolan,dilip@cs.stanford.edu;dedey@microsoft.com;alekha@microsoft.com;aslicel@microsoft.com;elnouri@microsoft.com;horvitz@microsoft.com;billdol@microsoft.com,1;1;1,,Reject,0,9,0,yes,9/25/19,Stanford University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Imitation Learning;Reinforcement Learning;Adversarial Learning;Learning from Demonstration,5;-1;-1;-1;-1;-1;-1,4;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,TrojanNet: Exposing the Danger of Trojan Horse Attack on Neural Networks,Chuan Guo;Ruihan Wu;Kilian Q. Weinberger,cg563@cornell.edu;rw565@cornell.edu;kqw4@cornell.edu,3;3;3,,Reject,0,1,0,yes,9/25/19,Cornell University;Cornell University;Cornell University,machine learning security,7;7;7,19;19;19,m;m,usa,usa,y
ICLR,2020,SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks,Jingwei GUAN;Cheng PAN;Songnan LI and Dahai YU,jwguan37@gmail.com;pancheng@tcl.com;lisn@tcl.com;dahai.yu@tcl.com,3;3;1,,Reject,0,0,0,yes,9/25/19,Chinese University of Hong Kong;Tcl;Tcl;Tcl,Super Resolution GAN Denoise,-1;-1;-1;-1,-1;15;15;15,f;m,asia,in,n
ICLR,2020,Detecting malicious PDF using CNN,Raphael Fettaya;Yishay Mansour,raphaelfettaya@gmail.com;mansour.yishay@gmail.com,1;1;3,,Reject,0,1,0,yes,9/25/19,Tel Aviv University;Tel Aviv University,Cybersecurity;Convolutional Neural Network;Malware,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Novelty Search in representational space for sample efficient exploration,Ruo Yu Tao;Vincent Fran√ßois-Lavet;Joelle Pineau,ruo.tao@mail.mcgill.ca;vincent.francois-lavet@mail.mcgill.ca;jpineau@cs.mcgill.ca,1;6;3,,Reject,0,3,0,yes,9/25/19,McGill University;McGill University;McGill University,Reinforcement Learning;Exploration,102;102;102,42;42;42,m;f,canada,ca,n
ICLR,2020,"Feature-Robustness, Flatness and Generalization Error for Deep Neural Networks",Henning Petzka;Linara Adilova;Michael Kamp;Cristian Sminchisescu,henning.petzka@gmail.com;adylova.linara.r@gmail.com;info@michaelkamp.org;cristian.sminchisescu@math.lth.se,1;3;3,,Reject,0,8,1,yes,9/25/19,Lund University;Ruhr-Universt√§t Bochum;CISPA Helmholtz-Zentrum f√ºr Informationssicherheit;Lund University,robustness;flatness;generalization error;loss surface;deep neural networks;feature space,445;-1;-1;445,98;-1;-1;98,m;m,asia,cn,y
ICLR,2020,Robust Cross-lingual Embeddings from Parallel Sentences ,Ali Sabet;Prakhar Gupta;Jean-Baptiste Cordonnier;Robert West;Martin Jaggi,asabet@uwaterloo.ca;prakhar.gupta@epfl.ch;jean-baptiste.cordonnier@epfl.ch;robert.west@epfl.ch;martin.jaggi@epfl.ch,3;3;8,,Reject,0,4,0,yes,9/25/19,University of Waterloo;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Cross-lingual embeddings;sent2vec;word2vec;bilingual;word translation;sentence retrieval;text;NLP;word vectors;sentence vectors,30;-1;-1;-1;-1,235;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PowerSGD: Powered Stochastic Gradient Descent Methods for Accelerated Non-Convex Optimization,Jun Liu;Beitong Zhou;Weigao Sun;Ruijuan Chen;Claire J. Tomlin;Ye Yuan,j.liu@uwaterloo.ca;zhoubt@hust.edu.cn;sunweigao@outlook.com;ruijuanchen@hust.edu.cn;tomlin@eecs.berkeley.edu;yye@hust.edu.cn,3;3;8,,Reject,1,5,0,yes,9/25/19,University of Waterloo;Hong Kong University of Science and Technology;;Hong Kong University of Science and Technology;University of California Berkeley;Hong Kong University of Science and Technology,stochastic gradient descent;non-convex optimization;powerball function;acceleration,30;-1;-1;-1;-1;-1,235;47;-1;47;13;47,m;m,NAN,NAN,y
ICLR,2020,Unaligned Image-to-Sequence Transformation with Loop Consistency,Siyang Wang;Justin Lazarow;Kwonjoon Lee;Zhuowen Tu,siw030@ucsd.edu;jlazarow@ucsd.edu;kwl042@ucsd.edu;ztu@ucsd.edu,1;3;3,,Reject,0,0,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;University of California, San Diego",,-1;-1;-1;-1,31;31;31;31,f;m,usa,usa,n
ICLR,2020,Progressive Compressed Records: Taking a Byte Out of Deep Learning Data,Michael Kuchnik;George Amvrosiadis;Virginia Smith,mkuchnik@andrew.cmu.edu;gamvrosi@cmu.edu;smithv@cmu.edu,3;6;3;6,,Reject,0,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Deep Learning;Storage;Bandwidth;Compression,1;1;1,27;27;27,m;f,usa,usa,n
ICLR,2020,Training a Constrained Natural Media Painting Agent using Reinforcement Learning ,Biao Jia;Jonathan Brandt;Radomir Mech;Ning Xu;Byungmoon Kim;Dinesh Manocha,biao@cs.umd.edu;jbrandt@adobe.com;rmech@adobe.com;nxu@adobe.com;bmkim@adobe.com;dm@cs.umd.edu,3;1;1,,Reject,0,0,0,yes,9/25/19,"University of Maryland, College Park;Adobe Systems;Adobe Systems;Adobe Systems;Adobe Systems;University of Maryland, College Park",,12;-1;-1;-1;-1;12,91;-1;-1;-1;-1;91,m;m,usa,usa,n
ICLR,2020,Disentangling Improves VAEs' Robustness to Adversarial Attacks,Matthew Willetts;Alexander Camuto;Stephen Roberts;Chris Holmes,mwilletts@turing.ac.uk;acamuto@turing.ac.uk;sroberts@turing.ac.uk;cholmes@turing.ac.uk,3;6;3,,Reject,0,5,1,yes,9/25/19,Alan Turing Institute;Alan Turing Institute;Alan Turing Institute;Alan Turing Institute,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Exploring Cellular Protein Localization Through Semantic Image Synthesis,Daniel Li;Qiang Ma;Andrew Liu;Justin Cheung;Dana Pe‚Äôer;Itsik Pe‚Äôer,daniel.li@columbia.edu;ma.qiang@columbia.edu;andrew@ml.berkeley.edu;justin.cheung@stonybrookmedicine.edu;peerster@gmail.com;itsik@cs.columbia.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,Columbia University;Columbia University;University of California Berkeley;Renaissance School of Medicine at Stony Brook University;;Columbia University,Computational biology;image synthesis;GANs;exploring multiplex images;attention;interpretability,24;24;-1;43;-1;24,16;16;13;304;-1;16,m;m,usa,usa,n
ICLR,2020,Encoder-Agnostic Adaptation for Conditional Language Generation,Zachary M. Ziegler;Luke Melas-Kyriazi;Sebastian Gehrmann;Alexander M. Rush,zziegler@g.harvard.edu;lmelaskyriazi@college.harvard.edu;gehrmann@seas.harvard.edu;srush@seas.harvard.edu,8;8;3,,Reject,0,4,0,yes,9/25/19,Harvard University;Harvard University;Harvard University;Harvard University,NLP;generation;pretraining,52;52;52;52,7;7;7;7,m;m,usa,usa,n
ICLR,2020,Better Knowledge Retention through Metric Learning,Ke Li*;Shichong Peng*;Kailas Vodrahalli*;Jitendra Malik,ke.li@eecs.berkeley.edu;shichong.peng@mail.utoronto.ca;kailasv@berkeley.edu;malik@eecs.berkeley.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,University of California Berkeley;Toronto University;University of California Berkeley;University of California Berkeley,metric learning;continual learning;catastrophic forgetting,-1;-1;-1;-1,13;-1;13;13,m;m,usa,usa,n
ICLR,2020,Robust Learning with Jacobian Regularization,Judy Hoffman;Daniel A. Roberts;Sho Yaida,judy@gatech.edu;dan@diffeo.com;shoyaida@fb.com,6;3;3,,Reject,0,3,0,yes,9/25/19,Georgia Institute of Technology;Diffeo;Facebook,Supervised Representation Learning;Few-Shot Learning;Regularization;Adversarial Defense;Deep Learning,13;-1;-1,38;-1;-1,f;m,NAN,NAN,n
ICLR,2020,CAN ALTQ LEARN FASTER: EXPERIMENTS AND THEORY,Bowen Weng;Huaqing Xiong;Yingbin Liang;Wei Zhang,weng.172@buckeyemail.osu.edu;xiong.309@buckeyemail.osu.edu;liang.889@osu.edu;zhangw3@sustech.edu.cn,3;3;1,,Reject,0,3,0,yes,9/25/19,Ohio State University;Ohio State University;Ohio State University;Southern University of Science and Technology,Reinforcement Learning;Q-Learning;Adam;Restart;Convergence Analysis,59;59;59;-1,70;70;70;317,m;m,NAN,NAN,y
ICLR,2020,A NEW POINTWISE CONVOLUTION IN DEEP NEURAL NETWORKS THROUGH EXTREMELY FAST AND NON PARAMETRIC TRANSFORMS,Joonhyun Jeong;Sung-Ho Bae,doublejtoh@khu.ac.kr;shbae@khu.ac.kr,3;8;3,,Reject,0,5,0,yes,9/25/19,Kyung Hee University;Kyung Hee University,Pointwise Convolution;Discrete Walsh-Hadamard Transform;Discrete Cosine-Transform,445;445,319;319,m;m,asia,kr,n
ICLR,2020,"Making the Shoe Fit: Architectures, Initializations, and Tuning for Learning with Privacy",Nicolas Papernot;Steve Chien;Shuang Song;Abhradeep Thakurta;Ulfar Erlingsson,papernot@google.com;schien@google.com;athakurta@google.com;shuangsong@google.com;ulfar@google.com,6;6;3,,Reject,0,7,0,yes,9/25/19,Google;Google;Google;Google;Google,differential privacy;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Toward Understanding Generalization of Over-parameterized Deep ReLU network trained with SGD in Student-teacher Setting,Yuandong Tian,yuandong.tian@gmail.com,3;3;3,,Reject,0,8,0,yes,9/25/19,Facebook,deep ReLU network;theoretical analysis;generalization;training dynamics;student teacher setting;interpolation region;over-parameterization,-1,-1,m,NAN,NAN,y
ICLR,2020,Ordinary differential equations on graph networks,Juntang Zhuang;Nicha Dvornek;Xiaoxiao Li;James S. Duncan,j.zhuang@yale.edu;nicha.dvornek@yale.edu;xiaoxiao.li@yale.edu;james.duncan@yale.edu,1;6;3,,Reject,0,13,0,yes,9/25/19,Yale University;Yale University;Yale University;Yale University,Graph Networks;Ordinary differential equation,73;73;73;73,8;8;8;8,m;m,europe,fi,y
ICLR,2020,Poincar√© Wasserstein Autoencoder,Ivan Ovinnikov,ivan.ovinnikov@inf.ethz.ch,3;6;3,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology,Variational inference;hyperbolic geometry;hierarchical latent space;representation learning,-1,-1,m,NAN,NAN,n
ICLR,2020,Learning Neural Surrogate Model for Warm-Starting Bayesian Optimization,Haotian Zhang;Jian Sun;Zongben Xu,zht570795275@stu.xjtu.edu.cn;jiansun@xjtu.edu.cn;zbxu@xjtu.edu.cn,3;3;1,,Reject,0,3,0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,Bayesian optimization;meta learning;neural network;surrogate model;hyper-parameters tuning,-1;-1;-1,555;555;555,m;m,NAN,NAN,n
ICLR,2020,Music Source Separation in the Waveform Domain,Alexandre Defossez;Nicolas Usunier;Leon Bottou;Francis Bach,defossez@fb.com;usunier@fb.com;leonb@fb.com;francis.bach@inria.fr,8;3;3,,Reject,0,8,0,yes,9/25/19,Facebook;Facebook;Facebook;INRIA,source separation;audio synthesis;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,gr,n
ICLR,2020,Self-Attentional Credit Assignment for Transfer in Reinforcement Learning,Johan Ferret;Rapha√´l Marinier;Matthieu Geist;Olivier Pietquin,jferret@google.com;raphaelm@google.com;mfgeist@google.com;pietquin@google.com,8;3;6,,Reject,1,5,0,yes,9/25/19,Google;Google;Google;Google,reinforcement learning;transfer learning;credit assignment,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Gradient Descent can Learn Less Over-parameterized Two-layer Neural Networks on Classification Problems,Atsushi Nitanda;Geoffrey Chinot;Taiji Suzuki,nitanda@mist.i.u-tokyo.ac.jp;geoffreychinot@gmail.com;taiji@mist.i.u-tokyo.ac.jp,8;3;3,,Reject,0,5,0,yes,9/25/19,The University of Tokyo;;The University of Tokyo,gradient descent;neural network;over-parameterization,64;-1;64,36;-1;36,f;f,NAN,NAN,y
ICLR,2020,Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning,Yufei Wang*;Ziju Shen*;Zichao Long;Bin Dong,wang.yufei@pku.edu.cn;zjshen@pku.edu.cn;zlong@pku.edu.cn;dongbin@math.pku.edu.cn,3;3;6,,Reject,0,3,0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University,Numerical Methods;Conservation Laws;Reinforcement Learning,14;14;14;14,24;24;24;24,f;m,asia,cn,n
ICLR,2020,Discovering the compositional structure of vector representations with Role Learning Networks,Paul Soulos;Tom McCoy;Tal Linzen;Paul Smolensky,psoulos1@jhu.edu;tom.mccoy@jhu.edu;tal.linzen@jhu.edu;paul.smolensky@gmail.com,6;3;6,,Reject,0,4,0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University;Microsoft,compositionality;generalization;neurosymbolic;symbolic structures;interpretability;tensor product representations,73;73;73;-1,12;12;12;-1,m;m,NAN,NAN,n
ICLR,2020,A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem,Zhihao Xing;Shikui Tu,xingzhihao@sjtu.edu.cn;tushikui@sjtu.edu.cn,6;6;1,,Reject,0,5,0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Traveling Salesman Problem;Graph Neural Network;Monte Carlo Tree Search,30;30,157;157,u;m,asia,cn,n
ICLR,2020,A bi-diffusion based layer-wise sampling method for deep learning in large graphs,Yu He;Shiyang Wen;Wenjin Wu;Yan Zhang;Siran Yang;Yuan Wei;Di Zhang;Guojie  Song;Wei Lin;Liang Wang;Bo Zheng,herve.hy@alibaba-inc.com;shiyang.wsy@alibaba-inc.com;kevin.wwj@alibaba-inc.com;zy143424@alibaba-inc.com;siran.ysr@alibaba-inc.com;yuanxi.wy@alibaba-inc.com;di.zhangd@alibaba-inc.com;gjsong@pku.edu.cn;yangkun.lw@alibaba-inc.com;liangbo.wl@alibaba-inc.com;bozheng@alibaba-inc.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Peking University;Alibaba Group;Alibaba Group;Alibaba Group,Layerwise Sampling;Graph Neural Networks;Attention Mechanism,-1;-1;-1;-1;-1;-1;-1;14;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;24;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,Noise Regularization for Conditional Density Estimation,Jonas Rothfuss;Fabio Ferreira;Simon Boehm;Simon Walther;Maxim Ulrich;Tamim Asfour;Andreas Krause,jonas.rothfuss@gmail.com;fabioferreira@mailbox.org;simonboehm@gmx.de;simon.walther@kit.edu;maxim.ulrich@kit.edu;asfour@kit.edu;krausea@ethz.ch,6;3;3,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology;Universit√§t Freiburg;Swiss Federal Institute of Technology;Karlsruhe Institute of Technology;Karlsruhe Institute of Technology;Karlsruhe Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1;168;168;168;-1,-1;-1;-1;174;174;174;-1,m;m,NAN,NAN,y
ICLR,2020,Learning with Protection: Rejection of Suspicious Samples under Adversarial Environment,Masahiro Kato;Yoshihiro Fukuhara;Hirokatsu Kataoka;Shigeo Morishima,mkato.csecon@gmail.com;gatheluck@gmail.com;hirokatsu.kataoka@aist.go.jp;shigeo@waseda.jp,3;3;3,,Reject,0,3,0,yes,9/25/19,Cyberagent;;AIST;Waseda University,Learning with Rejection;Adversarial Examples,-1;-1;15;316,-1;-1;110;790,m;m,asia,jp,n
ICLR,2020,Transition Based Dependency Parser for Amharic Language Using Deep Learning,Mizanu Zelalem;Million Meshesha (PhD),mizatmymail@gmail.com;meshe84@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Bahir Dar Institute of technology;Addis Ababa University,Amharic dependency parsing;arc-eager transition;LSTM;Transition action prediction;Relationship type prediction,-1;-1,-1;-1,m;u,asia,in,n
ICLR,2020,V1Net: A computational model of cortical horizontal connections,Vijay Veerabadran;Virginia R. de Sa,vveeraba@ucsd.edu;desa@ucsd.edu,1;1;3,,Reject,0,3,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego",Biologically plausible deep learning;Recurrent Neural Networks;Perceptual grouping;horizontal connections;visual neuroscience;perceptual robustness;Gestalt psychology,-1;-1,31;31,m;f,usa,usa,n
ICLR,2020,HOW IMPORTANT ARE NETWORK WEIGHTS? TO WHAT EXTENT DO THEY NEED AN UPDATE?,Fawaz Sammani;Mahmoud Elsayed;Abdelsalam Hamdi,fawaz.sammani@aol.com;elsayedmahmoud@aol.com;abdelsalam.h.a.a@gmail.com,1;3;1,,Reject,0,3,0,yes,9/25/19,Multimedia University;;Multimedia University,weights update;weights importance;weight freezing,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,INTERNAL-CONSISTENCY CONSTRAINTS FOR EMERGENT COMMUNICATION,Charles Lovering;Ellie Pavlick,charles_lovering@brown.edu;ellie_pavlick@brown.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,Brown University;Brown University,Emergent Communication;Speaker-Listener Models,85;85,53;53,m;f,usa,usa,n
ICLR,2020,Not All Features Are Equal: Feature Leveling Deep Neural Networks for Better Interpretation,Yingjing Lu;Runde Yang,yingjinl@andrew.cmu.edu;ry82@cornell.edu,1;3;3;3,,Reject,0,0,0,yes,9/25/19,Carnegie Mellon University;Cornell University,,1;7,27;19,m;m,usa,usa,n
ICLR,2020,Neural Networks for Principal Component Analysis: A New Loss Function Provably Yields Ordered Exact Eigenvectors ,Reza Oftadeh;Jiayi Shen;Zhangyang Wang;Dylan Shell,oftadeh.reza@gmail.com;asjyjya-617@tamu.edu;atlaswang@tamu.edu;dshell@tamu.edu,6;6;3,,Reject,0,4,0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M;Texas A&M,Principal Component Analysis;Autoencoder;Neural Network,46;46;46;46,177;177;177;177,m;m,NAN,NAN,y
ICLR,2020,GENN: Predicting Correlated Drug-drug Interactions with Graph Energy Neural Networks,Tengfei Ma;Junyuan Shang;Cao Xiao;Jimeng Sun,tengfei.ma1@ibm.com;sjy1203@pku.edu.cn;cao.xiao@iqvia.com;sun@cc.gatech.edu,6;3;3,,Reject,0,4,0,yes,9/25/19,International Business Machines;Peking University;IQVIA;Georgia Institute of Technology,graph neural networks;energy model;structure prediction;drug-drug-interaction,-1;14;-1;13,-1;24;-1;38,m;m,usa,usa,n
ICLR,2020,Efficient Systolic Array Based on Decomposable MAC for Quantized Deep Neural Networks,Ning-Chi Huang;Huan-Jan Chou;Kai-Chiang Wu,nchuang@cs.nctu.edu.tw;kulugu2.cs07g@nctu.edu.tw;kcw@cs.nctu.edu.tw,1;3;3,,Reject,0,0,0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University;National Chiao Tung University,,118;118;118,564;564;564,u;m,asia,tw,n
ICLR,2020,DeepEnFM: Deep neural networks with Encoder enhanced Factorization Machine,Qiang Sun;Zhinan Cheng;Yanwei Fu;Wenxuan Wang;Yu-Gang Jiang;Xiangyang Xue,sunqiang85@gmail.com;zhinancheng.bryan@gmail.com;yanweifu@fudan.edu.cn;wxwang.iris@gmail.com;ygj@fudan.edu.cn;xyxue@fudan.edu.cn,1;3;1,,Reject,0,3,0,yes,9/25/19,Fudan University;;Fudan University;Fudan University;Fudan University;Fudan University,CTR;Attention;Transformer;Encoder,73;-1;73;73;73;73,109;-1;109;109;109;109,m;m,asia,cn,n
ICLR,2020,Statistically Consistent Saliency Estimation,Emre Barut;Shunyan Luo,barut@gwu.edu;shine_lsy@gwu.edu,8;8;3;6;6,,Reject,0,7,0,yes,9/25/19,George Washington University;George Washington University,Deep Learning Interpretation;Saliency Estimation;High Dimensional Statistics,194;194,198;198,m;m,usa,usa,y
ICLR,2020,Towards Physics-informed Deep Learning for Turbulent Flow Prediction,Rui Wang;Karthik Kashinath;Mustafa Mustafa;Adrian Albert;Rose Yu,wang.rui4@husky.neu.edu;kkashinath@lbl.gov;mmustafa@lbl.gov;aalbert@lbl.gov;roseyu@northeastern.edu,6;3;6,,Reject,3,7,0,yes,9/25/19,Northeastern University;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;Northeastern University,,16;-1;-1;-1;16,906;-1;-1;-1;906,m;f,usa,usa,n
ICLR,2020,Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators,Yongseok Choi;Junyoung Park;Subin Yi;Dong-Yeon Cho,yschoi@sktbrain.com;jypark@sktbrain.com;yisubin@sktbrain.com;dycho24@sktbrain.com,3;3;3,,Reject,0,3,0,yes,9/25/19,SK Telecom;SK Telecom;SK Telecom;SK Telecom,Meta-learning;few-shot learning;multi-domain,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,Wei Zhou;Yiying Li;Yongxin Yang;Huaimin Wang;Timothy M. Hospedales,zhouwei14@nudt.edu.cn;liyiying10@nudt.edu.cn;yongxin.yang@ed.ac.uk;hmwang@nudt.edu.cn;t.hospedales@ed.ac.uk,3;3;6,,Reject,0,6,0,yes,9/25/19,National University of Defense Technology;National University of Defense Technology;University of Edinburgh;National University of Defense Technology;University of Edinburgh,off-policy actor-critic;reinforcement learning;meta-learning,-1;-1;36;-1;36,-1;-1;30;-1;30,u;m,europe,uk,n
ICLR,2020,Using Explainabilty to Detect Adversarial Attacks,Ohad Amosy and Gal Chechik,amosy3@gmail.com;gal.chechik@gmail.com,3;3;1;3,,Reject,2,0,0,yes,9/25/19,Bar Ilan University;Bar Ilan University,adversarial;detection;explainability,102;102,513;513,m;m,europe,il,n
ICLR,2020,Random Bias Initialization Improving Binary Neural Network Training,Xinlin Li;Vahid Partovi Nia,xinlin.li1@huawei.com;vahid.partovinia@huawei.com,1;1;3,,Reject,0,0,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.,Binarized Neural Network;Activation function;Initialization;Neural Network Acceleration,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Bayesian Inference for Large Scale Image Classification,Jonathan Heek;Nal Kalchbrenner,jheek@google.com;nalk@google.com,6;3;6,,Reject,0,3,0,yes,9/25/19,Google;Google,image classification;bayesian inference;mcmc;imagenet,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Self-Supervised GAN Compression,Chong Yu;Jeff Pool,chongy@nvidia.com;jpool@nvidia.com,3;6;6,,Reject,0,4,0,yes,9/25/19,NVIDIA;NVIDIA,compression;pruning;generative adversarial networks;GAN,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Generative Hierarchical Models for Parts, Objects, and Scenes",Fei Deng;Zhuo Zhi;Sungjin Ahn,fei.deng@rutgers.edu;zhizz001@stu.xjtu.edu.cn;sjn.ahn@gmail.com,3;3;3,,Reject,0,6,0,yes,9/25/19,Rutgers University;Xi'an Jiaotong University;Rutgers University,,30;-1;30,-1;555;-1,f;m,usa,usa,n
ICLR,2020,SDGM: Sparse Bayesian Classifier Based on a Discriminative Gaussian Mixture Model,Hideaki Hayashi;Seiichi Uchida,hayashi@ait.kyushu-u.ac.jp;uchida@ait.kyushu-u.ac.jp,3;3;1,,Reject,0,3,0,yes,9/25/19,Kyushu University;Kyushu University,classification;sparse Bayesian learning;Gaussian mixture model,-1;-1,460;460,m;m,NAN,NAN,n
ICLR,2020,Analytical Moment Regularizer for Training Robust Networks,Modar Alfadly;Adel Bibi;Muhammed Kocabas;Bernard Ghanem,modar.alfadly@kaust.edu.sa;adel.bibi@kaust.edu.sa;muhammed.kocabas@tue.mpg.de;bernard.ghanem@kaust.edu.sa,3;1;3,,Reject,1,3,0,yes,9/25/19,KAUST;KAUST;Max-Planck Institute;KAUST,robustness;analytic regularizer;first moment,102;102;-1;102,-1;-1;-1;-1,m;m,europe,gr,y
ICLR,2020,ROBUST DISCRIMINATIVE REPRESENTATION LEARNING VIA GRADIENT RESCALING: AN EMPHASIS REGULARISATION PERSPECTIVE,Xinshao Wang;Yang Hua;Elyor Kodirov;Neil M. Robertson,xwang39@qub.ac.uk;y.hua@qub.ac.uk;elyor@anyvision.co;n.robertson@qub.ac.uk,6;3;3,,Reject,0,7,1,yes,9/25/19,Queen's University Belfast;Queen's University Belfast;Anyvision;Queen's University Belfast,examples weighting;emphasis regularisation;gradient scaling;abnormal training examples,248;248;-1;248,204;204;-1;204,m;m,europe,uk,n
ICLR,2020,Multi-step Greedy Policies in Model-Free Deep Reinforcement Learning,Yonathan Efroni;Manan Tomar;Mohammad Ghavamzadeh,jonathan.efroni@gmail.com;manan.tomar@gmail.com;mgh@fb.com,3;3;6,,Reject,0,8,0,yes,9/25/19,Microsoft;;Facebook,Reinforcement Learning;Multi-step greedy policies;Model free Reinforcement Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Hidden incentives for self-induced distributional shift,David Scott Krueger;Tegan Maharaj;Shane Legg;Jan Leike,davidscottkrueger@gmail.com;tegan.jrm@gmail.com;legg@google.com;leike@google.com,6;1;1,,Reject,0,5,0,yes,9/25/19,University of Montreal;Polytechnique Montreal;Google;Google,distributional shift;safety;incentives;specification;content recommendation;reinforcement learning;online learning;ethics,-1;316;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Temporal Abstraction with Information-theoretic Constraints for Hierarchical Reinforcement Learning,Wenshan Wang;Yaoyu Hu;Sebastian Scherer,wenshanw@andrew.cmu.edu;yaoyuh@andrew.cmu.edu;basti@andrew.cmu.edu,3;1;3,,Reject,0,12,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,hierarchical reinforcement learning;temporal abstraction,1;1;1,27;27;27,f;m,usa,usa,n
ICLR,2020,Generalized Clustering by Learning to Optimize Expected Normalized Cuts,Azade Nazi;Will Hang;Anna Goldie;Sujith Ravi;Azalia Mirhoseini,azade@google.com;agoldie@google.com;sravi@google.com;azalia@google.com;willhang@stanford.edu,6;6;6,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google;Stanford University,Clustering;Normalized cuts;Generalizability,-1;-1;-1;-1;5,-1;-1;-1;-1;4,f;f,usa,usa,n
ICLR,2020,Adversarially Robust Neural Networks via Optimal Control: Bridging Robustness with Lyapunov Stability,Zhiyang Chen;Hang Su,zy-chen17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn,1;6;1,,Reject,2,0,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",adversarial defense;optimal control;Lyapunov stability,4;4,23;23,m;m,NAN,NAN,y
ICLR,2020,Temporal Difference Weighted Ensemble For Reinforcement Learning,Takuma Seno;Michita Imai,seno@ailab.ics.keio.ac.jp;michita@ailab.ics.keio.ac.jp,1;3;8,,Reject,0,6,0,yes,9/25/19,Keio University;Keio University,reinforcement learning;ensemble;deep q-network,248;248,692;692,m;m,asia,jp,n
ICLR,2020,Learning Generative Image Object Manipulations from Language Instructions,Martin L√§ngkvist;Andreas Persson;Amy Loutfi,martin.langkvist@oru.se;andreas.persson@oru.se;amy.loutfi@oru.se,3;3;1,,Reject,0,0,0,yes,9/25/19,Centre for Applied Autonomous Sensor Systems;Centre for Applied Autonomous Sensor Systems;Centre for Applied Autonomous Sensor Systems,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks,Arushi Gupta;Sanjeev Arora,arushig@princeton.edu;arora@cs.princeton.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,Princeton University;Princeton University,saliency;attribution;interpretability;sanity checks,30;30,6;6,f;m,usa,usa,y
ICLR,2020,Impact of the latent space on the ability of GANs to fit the distribution,Thomas Pinetz;Daniel Soukup;Thomas Pock,thomas.pinetz@ait.ac.at;daniel.soukup@ait.ac.at;pock@icg.tugraz.at,1;1;1,,Reject,0,0,0,yes,9/25/19,AIT Austrian Institute Of Technology;AIT Austrian Institute Of Technology;Graz University of Technology,Deep Learning;Generative Adversarial Networks;Compression;Perceptual Quality,-1;-1;118,-1;-1;542,m;m,europe,cz,y
ICLR,2020,At Your Fingertips: Automatic Piano Fingering Detection,Amit Moryossef;Yanai Elazar;Yoav Goldberg,amitmoryossef@gmail.com;yanaiela@gmail.com;yoav.goldberg@gmail.com,1;3;1,,Reject,0,2,0,yes,9/25/19,Bar Ilan University;Bar Ilan University;Bar-Ilan University,piano;fingering;dataset,-1;102;102,-1;513;513,m;m,europe,il,n
ICLR,2020,Latent Question Reformulation and Information Accumulation for Multi-Hop Machine Reading,Quentin Grail;Julien Perez;Eric Gaussier,quentin.grail@naverlabs.com;julien.perez@naverlabs.com;eric.gaussier@imag.fr,8;3;3,,Reject,0,4,0,yes,9/25/19,Naver Labs Europe;Naver Labs Europe;French National Center for Scientific Research,question-answering;machine comprehension;deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Deep Variational Semi-Supervised Novelty Detection,Tal Daniel;Thanard Kurutach;Aviv Tamar,taldanielm@campus.technion.ac.il;thanard.kurutach@berkeley.edu;avivt@technion.ac.il,6;6;3,,Reject,0,4,0,yes,9/25/19,"Technion, Technion;University of California Berkeley;Technion, Technion",anomaly detection;semi-supervised anomaly detection;variational autoencoder,27;-1;27,-1;13;-1,m;m,NAN,NAN,n
ICLR,2020,Occlusion  resistant  learning  of  intuitive physics from videos,Ronan Riochet;Josef Sivic;Ivan Laptev;Emmanuel Dupoux,ronan.riochet@inria.fr;josef.sivic@ens.fr;ivan.laptev@inria.fr;emmanuel.dupoux@gmail.com,3;6;3;3,,Reject,0,4,0,yes,9/25/19,INRIA;Ecole Normale Superieure;INRIA;INRIA,,-1;118;-1;-1,-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,"Compressive Recovery Defense: A Defense Framework for $\ell_0, \ell_2$ and $\ell_\infty$ norm attacks.",Jasjeet Dhaliwal;Kyle Hambrook,jasjeet.dhaliwal@sjsu.edu;kyle.hambrook@sjsu.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,adversarial input;adversarial machine learning;neural networks;compressive sensing.,-1;-1,299;299,m;m,NAN,NAN,y
ICLR,2020,Causally Correct Partial Models for Reinforcement Learning,Danilo J. Rezende;Ivo Danihelka;George Papamakarios;Nan Rosemary Ke;Ray Jiang;Theophane Weber;Karol Gregor;Hamza Merzic;Fabio Viola;Jane Wang;Jovana Mitrovic;Frederic Besse;Ioannis Antonoglou;Lars Buesing;Julian Schrittwieser;Thomas Hubert;David Silver,danilor@google.com;danihelka@google.com;gpapamak@google.com;rosemary.nan.ke@gmail.com;rayjiang@google.com;theophane@google.com;karolg@google.com;hamzamerzic@google.com;fviola@google.com;wangjane@google.com;mitrovic@google.com;fbesse@google.com;ioannisa@google.com;lbuesing@google.com;swj@google.com;tkhubert@google.com;davidsilver@google.com,8;1;3;6,,Reject,0,7,0,yes,9/25/19,Google;Google;Google;;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,causality;model-based reinforcement learning,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning scalable and transferable multi-robot/machine sequential assignment planning via graph embedding,Hyunwook Kang;Aydar Mynbay;James R. Morrison;Jinkyoo Park,hwkang@tamu.edu;aydar.mynbay@bluehole.net;james.morrison@kaist.edu;jinkyoo.park@kaist.ac.kr,3;3;3,,Reject,0,3,0,yes,9/25/19,Texas A&M;;KAIST;Korea Advanced Institute of Science and Technology,reinforcement learning;multi-robot/machine;scheduling;planning;scalability;transferability;mean-field inference;graph embedding,46;-1;15;-1,177;-1;110;110,m;m,NAN,NAN,y
ICLR,2020,Improving Evolutionary Strategies with Generative Neural Networks,Louis Faury;Cl√©ment Calauz√®nes;Olivier Fercoq,l.faury@criteo.com;c.calauzenes@criteo.com;olivier.fercoq@telecom-paris.fr,8;6;6,,Reject,0,3,0,yes,9/25/19,Criteo;Criteo;T√©l√©com Paris,black-box optimization;evolutionary strategies;generative neural networks,-1;-1;-1,-1;-1;187,m;m,NAN,NAN,n
ICLR,2020,Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning,Mitchell A Gordon;Kevin Duh;Nicholas Andrews,mgordo37@jhu.edu;kevinduh@cs.jhu.edu;noa@jhu.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,compression;pruning;pre-training;BERT;language modeling;transfer learning;ML;NLP,73;73;73,12;12;12,m;m,usa,usa,n
ICLR,2020,REFINING MONTE CARLO TREE SEARCH AGENTS BY MONTE CARLO TREE SEARCH,Katsuki Ohto,katsuki.ohto@gmail.com,1;1;1,,Reject,0,3,0,yes,9/25/19,0,Reinforcement Learning;Monte Carlo Tree Search;Alpha Zero,,,m,NAN,NAN,n
ICLR,2020,Smooth Kernels Improve Adversarial Robustness and Perceptually-Aligned Gradients,Haohan Wang;Xindi Wu;Songwei Ge;Zachary C. Lipton;Eric P. Xing,haohanw@cs.cmu.edu;xindiw@andrew.cmu.edu;songweig@andrew.cmu.edu;zlipton@cmu.edu;epxing@cs.cmu.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,adversarial robustness;computer vision;smoothness regularization,1;1;1;1;1,27;27;27;27;27,m;m,usa,usa,y
ICLR,2020,Modeling treatment events in disease progression,Guanyang Wang;Yumeng Zhang;Yong Deng;Xuxin Huang;Lukasz Kidzinski,guanyang@stanford.edu;zym3008@gmail.com;yongdeng@stanford.edu;xxhuang@stanford.edu;lukasz.kidzinski@stanford.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,Stanford University;;Stanford University;Stanford University;Stanford University,disease progression;treatment events;matrix completion,5;-1;5;5;5,4;-1;4;4;4,m;m,usa,usa,y
ICLR,2020,Collaborative Generated Hashing for Market Analysis and Fast Cold-start Recommendation,Yan Zhang;Ivor W. Tsang;Lixin Duan;Guowu Yang,yixianqianzy@gmail.com;ivor.tsang@uts.edu.au;lxduan@gmail.com;guowu@uestc.edu.cn,1;1;1,,Reject,0,0,0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China,Recommender system;generated model;market analysis;hash;cold start,-1;73;-1;-1,-1;193;628;628,u;m,NAN,NAN,n
ICLR,2020,Are Few-shot Learning Benchmarks Too Simple ?,Gabriel Huang;Hugo Larochelle;Simon Lacoste-Julien,gbxhuang@gmail.com;hugolarochelle@google.com;slacoste@iro.umontreal.ca,6;3;3,,Reject,0,7,0,yes,9/25/19,University of Montreal;Google;University of Montreal,few-shot;classification;meta-learning;benchmark;omniglot;miniimagenet;meta-dataset;learning to cluster;learning;cluster;unsupervised,-1;-1;118,-1;-1;85,m;m,canada,ca,n
ICLR,2020,Towards trustworthy predictions from deep neural networks with fast adversarial calibration,Christian Tomani;Florian Buettner,christian.tomani@gmail.com;fbuettner.phys@gmail.com,3;3;3,,Reject,0,6,0,yes,9/25/19,Technical University Munich;Siemens Corporate Research,deep learning;uncertainty;calibration;domain shift;robustness,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Collaborative Training of Balanced Random Forests for Open Set Domain Adaptation,Jongbin Ryu;Jiun Bae;Jongwoo Lim,jongbin.ryu@gmail.com;maybe@hanyang.ac.kr;jlim@hanyang.ac.kr,3;3;6,,Reject,0,3,0,yes,9/25/19,Ajou University;Hanyang University;Hanyang University,,-1;194;194,852;393;393,m;m,asia,kr,n
ICLR,2020,Accelerated Variance Reduced Stochastic Extragradient Method for Sparse Machine Learning Problems,Fanhua Shang;Lin Kong;Yuanyuan Liu;Hua Huang;Hongying Liu,fhshang@xidian.edu.cn;xdkonglin0511@163.com;yyliu@xidian.edu.cn;huanghua1115@outlook.com;hyliu@xidian.edu.cn,8;1;6,,Reject,0,5,0,yes,9/25/19,Xidian University;163;Xidian University;;Xidian University,non-smooth optimization;SVRG;proximal operator;extragradient descent;momentum acceleration,-1;-1;-1;-1;-1,919;-1;919;-1;919,m;f,asia,cn,y
ICLR,2020,Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Nonconvex Optimization,Anas Barakat;Pascal Bianchi,anas.barakat@telecom-paristech.fr;pascal.bianchi@telecom-paristech.fr,3;3;3,,Reject,0,0,0,yes,9/25/19,T√©l√©com ParisTech;T√©l√©com ParisTech,nonconvex optimization;adaptive methods,-1;-1,187;187,m;m,NAN,NAN,y
ICLR,2020,RTC-VAE: HARNESSING THE PECULIARITY OF TOTAL CORRELATION  IN LEARNING DISENTANGLED REPRESENTATIONS,Ze Cheng;Juncheng B Li;Chenxu Wang;Jixuan Gu;Hao Xu;Xinjian Li;Florian Metze,ze.cheng@cn.bosch.com;junchenl@cs.cmu.edu;chenxujwang@gmail.com;jixuan.gu@sjtu.edu.cn;hao.xu-1@colorado.edu;xinjianl@cs.cmu.edu;fmetze@cs.cmu.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,"Bosch;Carnegie Mellon University;;Shanghai Jiao Tong University;University of Colorado, Boulder;Carnegie Mellon University;Carnegie Mellon University",Total Correlation;VAEs;Disentanglement,-1;1;-1;30;59;1;1,297;27;-1;157;123;27;27,m;m,usa,usa,y
ICLR,2020,Generalized Bayesian Posterior Expectation Distillation for Deep Neural Networks,Meet P. Vadera;Benjamin M. Marlin,mvadera@cs.umass.edu;marlin@cs.umass.edu,3;6;6,,Reject,0,7,0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst",Bayesian Neural Networks;Distillation,24;24,209;209,m;m,usa,usa,n
ICLR,2020,Towards Simplicity in Deep Reinforcement Learning: Streamlined Off-Policy Learning,Che Wang;Yanqiu Wu;Quan Vuong;Keith Ross,cw1681@nyu.edu;yanqiu.wu@nyu.edu;quan.hovuong@gmail.com;keithwross@nyu.edu,6;3;3,,Reject,0,11,0,yes,9/25/19,New York University;New York University;;New York University,Deep Reinforcement Learning;Sample Efficiency;Off-Policy Algorithms,22;22;-1;22,29;29;-1;29,m;m,usa,usa,n
ICLR,2020,A shallow feature extraction network with a large receptive field for stereo matching tasks,Jianguo Liu;Yunjian Feng;Guo Ji;Fuwu Yan,ljg424@163.com;1029515027@whut.edu.cn;18754806756@163.com;yanfw@whut.edu.cn,3;1;6,,Reject,0,0,0,yes,9/25/19,163;South China University of Technology;163;South China University of Technology,stereo matching;feature extraction network;convolution neural network;receptive field,-1;-1;-1;-1,-1;501;-1;501,u;u,NAN,NAN,n
ICLR,2020,Evaluating Semantic Representations of Source Code,Yaza Wainakh;Moiz Rauf;Michael Pradel,yaza.wainakh@gmail.com;moiz.rauf@iste.uni-stuttgart.de;michael@binaervarianz.de,6;3;1,,Reject,0,3,0,yes,9/25/19,Fraunhofer Institute for Computer Graphics Research IGD;University of Stuttgart;University of Stuttgart,embeddings;representation;source code;identifiers,-1;118;118,-1;292;292,m;m,europe,de,n
ICLR,2020,UW-NET: AN INCEPTION-ATTENTION NETWORK FOR UNDERWATER IMAGE CLASSIFICATION,Miao Yang and Ke Hu;Chongyi Li;Zhiqiang Wei,lemonmiao@gmial.com;kexisibest@outlook.com;lichongyi@tju.edu.cn;weizhiqiang@ouc.edu.cn,3;1;3,,Reject,0,0,0,yes,9/25/19,"Gmial;;Zhejiang University;University of Illinois, Urbana-Champaign",Underwater image;Convolutional neural network;Image classification;Inception module;Attention module,-1;-1;39;-1,-1;-1;107;-1,u;u,usa,usa,n
ICLR,2020,Deep Generative Classifier for Out-of-distribution Sample Detection,Dongha Lee;Sehun Yu;Hwanjo Yu,dongha0914@postech.ac.kr;hunu12@postech.ac.kr;hwanjoyu@postech.ac.kr,3;6;3,,Reject,1,3,0,yes,9/25/19,POSTECH;POSTECH;POSTECH,Out-of-distribution Detection;Generative Classifier;Deep Neural Networks;Multi-class Classification;Gaussian Discriminant Analysis,118;118;118,146;146;146,m;m,asia,kr,n
ICLR,2020,Adaptive Loss Scaling for Mixed Precision Training,Ruizhe Zhao;Brian Vogel;Tanvir Ahmed,ruizhe.zhao15@imperial.ac.uk;vogel@preferred.jp;tanvira@preferred.jp,3;3;6,,Reject,0,3,0,yes,9/25/19,"Imperial College London;Preferred Networks, Inc.;Preferred Networks, Inc.",Deep Learning;Mixed Precision Training;Loss Scaling;Backpropagation,52;-1;-1,10;-1;-1,m;m,NAN,NAN,n
ICLR,2020,On importance-weighted autoencoders,Axel Finke;Alexandre H. Thiery,axelfinke42@gmail.com;a.h.thiery@nus.edu.sg,8;3;6,,Reject,0,5,0,yes,9/25/19,Loughborough University;National University of Singapore,variational inference;autoencoders;importance sampling,445;17,374;25,m;m,asia,sg,y
ICLR,2020,Mixed Precision Training With 8-bit Floating Point,Naveen Mellempudi;Sudarshan Srinivasan;Dipankar Das;Bharat Kaul,naveen.k.mellempudi@intel.com;sudarshan.srinivasan@intel.com;dipankar.das@intel.com;bharat.kaul@intel.com,6;1;6,,Reject,0,7,0,yes,9/25/19,Intel;Intel;Intel;Intel,8-bit training;8-bit floating point;low precision training;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Functional Characterization of Randomly Initialized Gradient Descent in Deep ReLU Networks,Justin Sahs;Aneel Damaraju;Ryan Pyle;Onur Tavaslioglu;Josue Ortega Caro;Hao Yang Lu;Ankit Patel,justin.sahs@bcm.edu;amd18@rice.edu;ryan.pyle@bcm.edu;onur.tavaslioglu@bcm.edu;josue.ortegacaro@bcm.edu;hl61@rice.edu;ankitp@bcm.edu,3;6;3,,Reject,0,4,0,yes,9/25/19,Baylor College of Medicine;Rice University;Baylor College of Medicine;Baylor College of Medicine;Baylor College of Medicine;Rice University;Baylor College of Medicine,Inductive Bias;Generalization;Interpretability;Functional Characterization;Loss Surface;Initialization,-1;92;-1;-1;-1;92;-1,-1;105;-1;-1;-1;105;-1,m;m,NAN,NAN,y
ICLR,2020,ASGen: Answer-containing Sentence Generation to Pre-Train Question Generator for Scale-up Data in Question Answering,Akhil Kedia;Sai Chetan Chinthakindi;Seohyun Back;Haejun Lee;Jaegul Choo,akhil.kedia@samsung.com;sai.chetan@samsung.com;scv.back@samsung.com;haejun82.lee@samsung.com;jchoo@korea.ac.kr,6;6,,Reject,0,9,0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Korea University,Question Answering;Machine Reading Comprehension;Data Augmentation;Question Generation;Answer Generation,-1;-1;-1;-1;168,-1;-1;-1;-1;179,m;m,asia,kr,n
ICLR,2020,Invariance vs Robustness of Neural Networks,Sandesh Kamath;Amit Deshpande;K V Subrahmanyam,amitdesh@microsoft.com;ksandeshk@cmi.ac.in;kv@cmi.ac.in,3;1;3,,Reject,0,0,0,yes,9/25/19,Microsoft;Chennai Mathematical Institute;Chennai Mathematical Institute,Invariance;Adversarial;Robustness,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Modelling the influence of data structure on learning in neural networks,S. Goldt;M. M√©zard;F. Krzakala;L. Zdeborov√°,goldt.sebastian@gmail.com;marc.mezard@gmail.com;florent.krzakala@gmail.com;lenka.zdeborova@gmail.com,1;1;3,,Reject,0,6,0,yes,9/25/19,SISSA;;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Neural Networks;Generative models;Synthetic data sets;Generalisation;Stochastic Gradient descent,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,A Perturbation Analysis of Input Transformations for Adversarial Attacks,Adam Dziedzic;Sanjay Krishnan,ady@uchicago.edu;skr@uchicago.edu,3;3;6,,Reject,0,7,0,yes,9/25/19,University of Chicago;University of Chicago,adversarial examples;defenses;stochastic channels;deterministic channels;input transformations;compression;noise;convolutional neural networks,51;51,9;9,m;m,usa,usa,n
ICLR,2020,Understanding Isomorphism Bias in Graph Data Sets ,Ivanov Sergey;Sviridov Sergey;Evgeny Burnaev,ivanovserg990@gmail.com;sergei.sviridov@gmail.com;e.burnaev@skoltech.ru,6;1;1;3,,Reject,0,5,0,yes,9/25/19,Criteo;;Skolkovo Institute of Science and Technology,graph classification;data sets;graph representation learning,-1;-1;-1,-1;-1;-1,m;m,europe,russia,y
ICLR,2020,Data-Efficient Image Recognition with Contrastive Predictive Coding,Olivier J Henaff;Aravind Srinivas;Jeffrey De Fauw;Ali Razavi;Carl Doersch;S. M. Ali Eslami;Aaron van den Oord,henaff@google.com;aravind@cs.berkeley.edu;defauw@google.com;alirazavi@google.com;doersch@google.com;aeslami@google.com;avdnoord@google.com,3;3;6;3,,Reject,0,5,0,yes,9/25/19,Google;University of California Berkeley;Google;Google;Google;Google;Google,Deep learning;representation learning;contrastive methods;unsupervised learning;self-supervised learning;vision;data-efficiency,-1;-1;-1;-1;-1;-1;-1,-1;13;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,OBJECT-ORIENTED REPRESENTATION OF 3D SCENES,Chang Chen;Sungjin Ahn,chang.chen@rutgers.edu;sjn.ahn@gmail.com,3;6;3;3,,Reject,0,9,0,yes,9/25/19,Rutgers University;Rutgers University,unsupervised learning;representation learning;3D scene decomposition;3D detection,30;30,-1;-1,m;m,usa,usa,n
ICLR,2020,Barcodes as summary of objective functions' topology,Serguei Barannikov;Alexander Korotin;Dmitry Oganesyan;Daniil Emtsev;Evgeny Burnaev,serguei.barannikov@imj-prg.fr;a.korotin@skoltech.ru;d.oganesyan@skoltech.ru;demtsev@student.ethz.ch;e.burnaev@skoltech.ru,1;1;1,,Reject,0,3,0,yes,9/25/19,"CNRS, Institut Mathematiques de Jussieu, Paris Diderot University;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Swiss Federal Institute of Technology;Skolkovo Institute of Science and Technology",Barcodes;canonical form invariants;loss surface;gradient complexes,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,europe,russia,n
ICLR,2020,Asynchronous Stochastic Subgradient Methods for General Nonsmooth Nonconvex Optimization,Vyacheslav Kungurtsev;Malcolm Egan;Bapi Chatterjee;Dan Alistarh,vyacheslav.kungurtsev@fel.cvut.cz;malcom.egan@insa-lyon.fr;bapi.chatterjee@ist.ac.at;dan.alistarh@ist.ac.at,3;3;3,,Reject,0,6,0,yes,9/25/19,Czech Technical University in Prague;INSA de Lyon;Institute of Science and Technology Austria;Institute of Science and Technology Austria,optimziation;stochastic optimization;asynchronous parallel architecture;deep neural networks,168;-1;-1;-1,956;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Top-down training for neural networks,Shucong Zhang;Cong-Thanh Do;Rama Doddipatla;Erfan Loweimi;Peter Bell;Steve Renals,s1603602@sms.ed.ac.uk;cong-thanh.do@crl.toshiba.co.uk;rama.doddipatla@crl.toshiba.co.uk;e.loweimi@ed.ac.uk;peter.bell@ed.ac.uk;s.renals@ed.ac.uk,3;3;3,,Reject,1,5,0,yes,9/25/19,University of Edinburgh;Toshiba Research Europe Ltd.;Toshiba Research Europe Ltd.;University of Edinburgh;University of Edinburgh;University of Edinburgh,Neural network training;speech recognition,36;-1;-1;36;36;36,30;-1;-1;30;30;30,u;m,europe,uk,n
ICLR,2020,A new perspective in understanding of Adam-Type algorithms and beyond,Zeyi Tao;Qi Xia;Qun Li,ztao@email.wm.edu;qxia01@email.wm.edu;liqun@cs.wm.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,College of William and Mary;College of William and Mary;College of William and Mary,Machine Learning;Algorithm;Adam;First-Order Method,194;194;194,-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Subjective Reinforcement Learning for Open Complex Environments,Zhile Yang*;Haichuan Gao*;Xin Su;Shangqi Guo;Feng Chen,yzl18@mails.tsinghua.edu.cn;ghc18@mails.tsinghua.edu.cn;suxin16@mails.tsinghua.edu.cn;gsq15@mails.tsinghua.edu.cn;chenfeng@mail.tsinghua.edu.cn,3;3;1,,Reject,0,5,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",reinforcement learning theory;subjective learning,4;4;4;4;4,23;23;23;23;23,u;m,NAN,NAN,n
ICLR,2020,Discriminative Variational Autoencoder for Continual Learning with Generative Replay,Woo-Young Kang;Cheol-Ho Han;Byoung-Tak Zhang,rkddndud50@gmail.com;chhan@bi.snu.ac.kr;btzhang@bi.snu.ac.kr,1;1;3,,Reject,0,7,0,yes,9/25/19,Kakao Brain;Seoul National University;Seoul National University,Continual learning;Generative replay;Variational Autoencoder,-1;39;39,-1;64;64,u;m,asia,kr,n
ICLR,2020,BOSH: An Efficient Meta Algorithm for Decision-based Attacks,Zhenxin Xiao;Puyudi Yang;Yuchen Jiang;Kai-Wei Chang;Cho-Jui Hsieh,alanshawzju@gmail.com;pydyang@ucdavis.edu;jyc@zju.edu.cn;kw@kwchang.net;chohsieh@cs.ucla.edu,3;3,,Reject,0,3,0,yes,9/25/19,"Zhejiang University;University of California, Davis;Zhejiang University;University of California-Los Angeles;University of California, Los Angeles",,-1;-1;39;-1;-1,-1;55;107;17;17,m;m,usa,usa,y
ICLR,2020,Behavior Regularized Offline Reinforcement Learning,Yifan Wu;George Tucker;Ofir Nachum,yw4@andrew.cmu.edu;gjt@google.com;ofirnachum@google.com,6;6;6,,Reject,0,3,0,yes,9/25/19,Carnegie Mellon University;Google;Google,reinforcement learning;offline RL;batch RL,1;-1;-1,27;-1;-1,m;m,NAN,NAN,n
ICLR,2020,HyperEmbed:  Tradeoffs Between Resources and Performance in NLP Tasks with Hyperdimensional Computing enabled embedding of n-gram statistics ,Pedro Alonso;Kumar Shridhar;Denis Kleyko;Evgeny Osipov;Marcus Liwicki,pedro.alonso@ltu.se;kumar@neuralspace.ai;denis.kleyko@ltu.se;evgeny.osipov@ltu.se;marcus.liwicki@ltu.se,3;1;3,,Reject,0,3,0,yes,9/25/19,Lule√• University of Technology;;Lule√• University of Technology;Lule√• University of Technology;Lule√• University of Technology,NLP;Hyperdimensional computing;n-gram statistics;word representation;semantic hashing,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Semi-Supervised Learning with Normalizing Flows,Pavel Izmailov;Polina Kirichenko;Marc Finzi;Andrew Wilson,izmailovpavel@gmail.com;pk1822@nyu.edu;maf820@nyu.edu;andrew@cornell.edu,6;1;1,,Reject,0,4,1,yes,9/25/19,New York University;New York University;New York University;Cornell University,Semi-Supervised Learning;Normalizing Flows,22;22;22;7,29;29;29;19,m;m,usa,usa,n
ICLR,2020,Attacking Lifelong Learning Models with Gradient Reversion,Yunhui Guo;Mingrui Liu;Yandong Li;Liqiang Wang;Tianbao Yang;Tajana Rosing,yug185@eng.ucsd.edu;mingrui-liu@uiowa.edu;lyndon.leeseu@outlook.com;lwang@cs.ucf.edu;tianbao-yang@uiowa.edu;tajana@ucsd.edu,3;3;3,,Reject,0,0,0,yes,9/25/19,"University of California, San Diego;University of Iowa;;University of Central Florida;University of Iowa;University of California, San Diego",lifelong learning;adversarial learning,-1;168;-1;73;168;-1,31;227;-1;609;227;31,m;f,usa,usa,n
ICLR,2020,Deep amortized clustering,Juho Lee;Yoonho Lee;Yee Whye Teh,juho@aitrics.com;einet89@gmail.com;y.w.teh@stats.ox.ac.uk,3;3;3,,Reject,0,5,0,yes,9/25/19,AITRICS;AITRICS;University of Oxford,clustering;amortized inference;meta learning;deep learning,-1;-1;46,-1;-1;1,m;m,europe,uk,n
ICLR,2020,Laconic Image Classification: Human vs. Machine Performance,Javier Carrasco;Aidan Hogan;Jorge P√©rez,jaco_1031@hotmail.com;aidhog@gmail.com;jorge.perez.rojas@gmail.com,1;6;6,,Reject,0,4,0,yes,9/25/19,Universidad de Chile;Universidad de Chile;Universidad de Chile,minimal images;entropy;human vs. machine performance,-1;316;316,-1;-1;-1,m;m,southamerica,cl,n
ICLR,2020,Understanding and Stabilizing GANs' Training Dynamics with Control Theory,Kun Xu;Chongxuan Li;Huanshu Wei;Jun Zhu;Bo Zhang,kunxu.thu@gmail.com;chongxuanli1991@gmail.com;weihuanshu94@hotmail.com;dcszj@mail.tsinghua.edu.cn;dcszb@mail.tsinghua.edu.cn,6;3;3,,Reject,0,7,0,yes,9/25/19,"Tsinghua University;;;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Generative Adversarial Nets;Stability Analysis;Control Theory,-1;-1;-1;4;4,-1;-1;-1;23;23,m;m,NAN,NAN,n
ICLR,2020,Benefits of Overparameterization in Single-Layer Latent Variable Generative Models,Rares-Darius Buhai;Andrej Risteski;Yoni Halpern;David Sontag,rbuhai@mit.edu;aristesk@andrew.cmu.edu;yhalpern@google.com;dsontag@csail.mit.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Carnegie Mellon University;Google;Massachusetts Institute of Technology,overparameterization;unsupervised;parameter recovery;rigorous experiments,5;1;-1;5,5;27;-1;5,m;m,usa,usa,n
ICLR,2020,Detecting Noisy Training Data with Loss Curves,Geoff Pleiss;Tianyi Zhang;Ethan R. Elenberg;Kilian Q. Weinberger,geoff@cs.cornell.edu;tz58@cornell.edu;eelenberg@asapp.com;kqw4@cornell.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Cornell University;Cornell University;ASAPP Inc.;Cornell University,Deep learning;noisy data;robust training,7;7;-1;7,19;19;-1;19,m;m,usa,usa,n
ICLR,2020,On Concept-Based Explanations in Deep Neural Networks,Chih-Kuan Yeh;Been Kim;Sercan Arik;Chun-Liang Li;Pradeep Ravikumar;Tomas Pfister,cjyeh@cs.cmu.edu;beenkim.mit@gmail.com;soarik@google.com;chunliang.tw@gmail.com;pradeep.ravikumar@gmail.com;tpfister@google.com,6;6;3;3,,Reject,0,9,0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Carnegie Mellon University;Google,concept-based explanations;interpretability,1;-1;-1;-1;1;-1,27;-1;-1;-1;27;-1,m;m,NAN,NAN,y
ICLR,2020,Trajectory representation learning for Multi-Task NMRDPs planning,Firas JARBOUI;Vianney PERCHET;Roman EGGER,firasjarboui@gmail.com;vianney.perchet@gmail.com;roman.egger@fh-salzburg.ac.at,6;3;3,,Reject,0,4,0,yes,9/25/19,ENS Paris-Saclay;;University of Innsbruck,Representation Learning;State Estimation;Non Markovian Decision Process,-1;-1;-1,-1;-1;415,m;m,NAN,NAN,n
ICLR,2020,Distribution-Guided Local Explanation for Black-Box Classifiers,Weijie Fu;Meng Wang;Mengnan Du;Ninghao Liu;Shijie Hao;Xia Hu,fwj.edu@gmail.com;eric.mengwang@gmail.com;dumengnan@tamu.edu;nhliu43@tamu.edu;hfut.hsj@gmail.com;hu@cse.tamu.edu,6;3;3,,Reject,0,6,0,yes,9/25/19,Hefei University of Technology;;Texas A&M;Texas A&M;;Texas A&M,explanation;cnn;saliency map,-1;-1;46;46;-1;46,-1;-1;177;177;-1;177,m;m,NAN,NAN,n
ICLR,2020,Keyword Spotter Model for Crop Pest and Disease Monitoring from Community Radio Data,Benjamin Akera;Joyce Nakatumba-Nabende;Ali Hussein;Daniel Ssendiwala;Jonathan Mukiibi,akeraben@gmail.com;jnakatumba@cis.mak.ac.ug;ali.hussein@ronininstitute.org;ssendiwaladaniel@gmail.com;jonmuk7@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Makerere University;Makerere University;Ronin Institute;;Makerere University,keyword spotter;radio data;crop pest and disease;agriculture,-1;-1;-1;-1;-1,-1;605;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Shallow VAEs with RealNVP Prior Can Perform as Well as Deep Hierarchical VAEs,Haowen Xu;Wenxiao Chen;Jinlin Lai;Zhihan Li;Youjian Zhao;Dan Pei,xhw15@mails.tsinghua.edu.cn;chen-wx17@mails.tsinghua.edu.cn;laijl16@mails.tsinghua.edu.cn;lizhihan17@mails.tsinghua.edu.cn;zhaoyoujian@tsinghua.edu.cn;peidan@tsinghua.edu.cn,6;3;3,,Reject,0,0,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Variational Auto-encoder;RealNVP;learnable prior,4;4;4;4;4;4,23;23;23;23;23;23,m;m,NAN,NAN,n
ICLR,2020,Adaptive network sparsification with dependent variational beta-Bernoulli dropout,Juho Lee;Saehoon Kim;Jaehong Yoon;Hae Beom Lee;Eunho Yang;Sung Ju Hwang,juho@aitrics.com;shkim@aitrics.com;jaehong.yoon@kaist.ac.kr;haebeom.lee@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,6;3;6;3,,Reject,0,6,0,yes,9/25/19,AITRICS;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,network sparsification;variational inference;pruning,-1;-1;-1;-1;-1;-1,-1;-1;110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,Scalable Generative Models for Graphs with Graph Attention Mechanism,Wataru Kawai;Yusuke Mukuta;Tatsuya Harada,w-kawai@mi.t.u-tokyo.ac.jp;mukuta@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,3;1;3,,Reject,0,9,0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo,Graph Generative Model;Attention Mechanism,64;64;64,36;36;36,m;m,NAN,NAN,n
ICLR,2020,On the Dynamics and Convergence of Weight Normalization for Training Neural Networks,Yonatan Dukler;Quanquan Gu;Guido Montufar,ydukler@math.ucla.edu;qgu@cs.ucla.edu;montufar@math.ucla.edu,3;6;3,,Reject,0,4,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Normalization methods;Weight Normalization;Convergence Theory,-1;-1;-1,17;17;17,m;m,usa,usa,y
ICLR,2020,Semi-Supervised Few-Shot Learning with Prototypical Random Walks,Ahmed Ayyad;Nassir Navab;Mohamed Elhoseiny;Shadi Albarqouni,a.3ayad@gmail.com;nassir.navab@tum.de;mohamed.elhoseiny@gmail.com;shadi.albarqouni@tum.de,3;3;3,,Reject,0,4,0,yes,9/25/19,Technical University Munich;Technical University Munich;KAUST;Technical University Munich,Few-Shot Learning;Semi-Supervised Learning;Random Walks,-1;-1;102;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Agent as Scientist: Learning to Verify Hypotheses,Kenneth Marino;Rob Fergus;Arthur Szlam;Abhinav Gupta,kdmarino@cs.cmu.edu;fergus@cs.nyu.edu;aszlam@fb.com;abhinavg@cs.cmu.edu,3;3;1,,Reject,0,5,0,yes,9/25/19,Carnegie Mellon University;New York University;Facebook;Carnegie Mellon University,,1;22;-1;1,27;29;-1;27,m;m,usa,usa,n
ICLR,2020,Generating Robust Audio Adversarial Examples using Iterative Proportional Clipping,Hongting Zhang;Qiben Yan;Pan Zhou,htzhang@hust.edu.cn;qyan@msu.edu;panzhou@hust.edu.cn,3;3;6,,Reject,0,6,0,yes,9/25/19,Hong Kong University of Science and Technology;Michigan State University;Hong Kong University of Science and Technology,audio adversarial examples;attack;machine learning,-1;102;-1,47;84;47,u;m,NAN,NAN,n
ICLR,2020,Lean Images for Geo-Localization,Moti Kadosh;Yael Moses;Ariel Shamir,arik@idc.ac.il;yael@idc.ac.il,3;3;3,,Reject,0,0,0,yes,9/25/19,interdisciplinary center herzliya;interdisciplinary center herzliya,Geo Localization;Deep Learning;Computer Vision;Camera Localization,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Are Powerful Graph Neural Nets Necessary? A Dissection on Graph Classification,Ting Chen;Song Bian;Yizhou Sun,iamtingchen@gmail.com;biansonghz@gmail.com;yzsun@cs.ucla.edu,3;6;6,,Reject,0,5,0,yes,9/25/19,"Google;;University of California, Los Angeles",graph neural nets;graph classification;set function,-1;-1;-1,-1;-1;17,m;f,usa,usa,n
ICLR,2020,DEEP GRAPH SPECTRAL EVOLUTION NETWORKS FOR GRAPH TOPOLOGICAL TRANSFORMATION,Liang Zhao;Qingzhe Li;Negar Etemadyrad;Xiaojie Guo,lzhao9@gmu.edu,6;3,,Reject,0,3,0,yes,9/25/19,George Mason University,deep graph learning;graph transformation;brain network,85,282,m;m,usa,usa,n
ICLR,2020,Robust Federated Learning Through Representation Matching and Adaptive Hyper-parameters,Hesham Mostafa,hesham.mostafa@intel.com,3;3;6,,Reject,0,4,0,yes,9/25/19,Intel,federated learning;hyper-parameter tuning;regularization,-1,-1,m,NAN,NAN,n
ICLR,2020,Enforcing Physical Constraints in Neural Neural Networks through Differentiable PDE Layer,"Chiyu Max"" Jiang;Karthik Kashinath;Prabhat;Philip Marcus""",chiyu.jiang@berkeley.edu;kkashinath@lbl.gov;prabhat@lbl.gov;pmarcus@me.berkeley.edu,3;6;3,,Reject,0,0,0,yes,9/25/19,University of California Berkeley;Lawrence Berkeley National Lab;Lawrence Berkeley National Lab;University of California Berkeley,PDE;Hard Constraints;Turbulence;Super-Resolution;Spectral Methods,-1;-1;-1;-1,13;-1;-1;13,m;m,usa,usa,n
ICLR,2020,Evo-NAS: Evolutionary-Neural Hybrid Agent for Architecture Search,Krzysztof Maziarz;Mingxing Tan;Andrey Khorlin;Kuang-Yu Samuel Chang;Andrea Gesmundo,krzysztof.s.maziarz@gmail.com;tanmingxing@google.com;akhorlin@google.com;kysc@google.com;agesmundo@google.com,3;6;3,,Reject,1,11,0,yes,9/25/19,Microsoft;Google;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,HUBERT Untangles BERT to Improve Transfer across NLP Tasks,Mehrad Moradshahi;Hamid Palangi;Monica S. Lam;Paul Smolensky;Jianfeng Gao,mehrad@stanford.edu;hpalangi@microsoft.com;lam@cs.stanford.edu;paul.smolensky@gmail.com;jfgao@microsoft.com,1;3;3,,Reject,1,4,0,yes,9/25/19,Stanford University;Microsoft;Stanford University;Microsoft;Microsoft,Tensor Product Representation;BERT;Transfer Learning;Neuro-Symbolic Learning,5;-1;5;-1;-1,4;-1;4;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning De-biased Representations with Biased Representations,Hyojin Bahng;Sanghyuk Chun;Sangdoo Yun;Jaegul Choo;Seong Joon Oh,hjj552@korea.ac.kr;sanghyuk.c@navercorp.com;sangdoo.yun@navercorp.com;jchoo@korea.ac.kr;coallaoh@linecorp.com,6;6;6,,Reject,0,6,1,yes,9/25/19,Korea University;NAVER;NAVER;Korea University;LINE,Generalization;Bias;Dataset bias,168;-1;-1;168;-1,179;-1;-1;179;358,f;m,asia,ir,n
ICLR,2020,ICNN: INPUT-CONDITIONED FEATURE REPRESENTATION LEARNING FOR TRANSFORMATION-INVARIANT NEURAL NETWORK,Suraj Tripathi;Chirag Singh;Abhay Kumar,surajtripathi93@gmail.com;c.singh@samsung.com;abykumar12011@gmail.com,3;1;3,,Reject,0,1,0,yes,9/25/19,"Indian Institute of Technology Delhi;Samsung;University of Wisconsin, Madison",Transformation-invariance;Reconstruction;Run-time Convolution Filter generation,-1;-1;-1,-1;-1;-1,m;m,asia,in,y
ICLR,2020,Learning Latent State Spaces for Planning through Reward Prediction,Aaron Havens;Yi Ouyang;Prabhat Nagarajan;Yasuhiro Fujita,ahavens2@illinois.edu;ouyangyi@preferred-america.com;prabhat@preferred.jp;fujita@preferred.jp,3;3;6,,Reject,0,4,0,yes,9/25/19,"University of Illinois, Urbana Champaign;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Deep Reinforcement Learning;Representation Learning;Model Based Reinforcement Learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Certified Robustness to Adversarial Label-Flipping Attacks via Randomized Smoothing,Elan Rosenfeld;Ezra Winston;Pradeep Ravikumar;J. Zico Kolter,ekr@andrew.cmu.edu;ewinston@andrew.cmu.edu;pradeepr@cs.cmu.edu;zkolter@cs.cmu.edu,3;3;3,,Reject,0,8,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Adversarial Robustness;Label Flipping Attack;Data Poisoning Attack,1;1;1;1,27;27;27;27,m;m,usa,usa,n
ICLR,2020,Optimistic Adaptive Acceleration for Optimization,Jun-Kun Wang;Xiaoyun Li;Ping Li,jimwang@gatech.edu;xl374@scarletmail.rutgers.edu;liping11@baidu.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Georgia Institute of Technology;Rutgers University;Baidu,,13;30;-1,38;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Hierarchical Bayes Autoencoders,Shuangfei Zhai;Carlos Guestrin;Joshua M. Susskind,szhai@apple.com;guestrin@apple.com;jsusskind@apple.com,1;1;3,,Reject,0,5,0,yes,9/25/19,Apple;Apple;Apple,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Project and Forget: Solving Large Scale Metric Constrained Problems,Anna C. Gilbert;Rishi Sonthalia,annacg@umich.edu;rsonthal@umich.edu,6;3;6,,Reject,0,8,1,yes,9/25/19,University of Michigan;University of Michigan,metric constrained problems;metric learning;metric nearness;correlation clustering;Bregman projection;cutting planes;large scale optimization,7;7,21;21,f;m,usa,usa,y
ICLR,2020,Deep Auto-Deferring Policy for Combinatorial Optimization,Sungsoo Ahn;Younggyo Seo;Jinwoo Shin,sungsoo.ahn@kaist.ac.kr;younggyo.seo@kaist.ac.kr;jinwoos@kaist.ac.kr,6;3;6,,Reject,0,6,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,deep reinforcement learning;combinatorial optimization,-1;-1;-1,110;110;110,m;m,NAN,NAN,n
ICLR,2020,Under what circumstances do local codes emerge in feed-forward neural networks,Ella M. Gale;Nicolas Martin,ella.gale@bristol.ac.uk;nm13850@bristol.ac.uk,1;3;3;3,,Reject,0,0,0,yes,9/25/19,University of Bristol;University of Bristol,localist coding;emergence;contructionist science;neural networks;feed-forward;learning representation;distributed coding;generalisation;memorisation;biological plausibility;deep-NNs;training conditions,118;118,87;87,f;m,europe,uk,n
ICLR,2020,Reinforcement Learning with Structured Hierarchical Grammar Representations of Actions,Petros Christodoulou;Robert Lange;Ali Shafti;A. Aldo Faisal,petros.christodoulou18@imperial.ac.uk;rtl17@ic.ac.uk;a.shafti@imperial.ac.uk;a.faisal@imperial.ac.uk,3;8;1,,Reject,0,4,0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,Hierarchical Reinforcement Learning;Action Representations;Macro-Actions;Action Grammars,52;52;52;52,10;10;10;10,m;m,europe,uk,n
ICLR,2020,Global Adversarial Robustness Guarantees for Neural Networks,Luca Laurenti;Andrea Patane;Matthew Wicker;Luca Bortolussi;Luca Cardelli;Marta Kwiatkowska,luca.laurenti@cs.ox.ac.uk;andrea.patane@chch.ox.ac.uk;matthew.wicker@wolfson.ox.ac.uk;luca.bortolussi@gmail.com;luca.a.cardelli@gmail.com;marta.kwiatkowska@cs.ox.ac.uk,3;1;1,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;;;University of Oxford,Adversarial Robustness;Statistical Guarantees;Deep Neural Networks;Bayesian Neural Networks,46;46;46;-1;-1;46,1;1;1;-1;-1;1,m;f,europe,uk,y
ICLR,2020,Learning Calibratable Policies using Programmatic Style-Consistency,Eric Zhan;Albert Tseng;Yisong Yue;Adith Swaminathan;Matthew Hausknecht,ezhan@caltech.edu;atseng@caltech.edu;yyue@caltech.edu;adswamin@microsoft.com;mahauskn@microsoft.com,6;3;3,,Reject,0,4,0,yes,9/25/19,California Institute of Technology;California Institute of Technology;California Institute of Technology;Microsoft;Microsoft,imitation learning;conditional generation;data programming,143;143;143;-1;-1,2;2;2;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Alternating Recurrent Dialog Model with Large-Scale Pre-Trained Language Models,Qingyang Wu;Yichi Zhang;Yu Li;Zhou Yu,wilwu@ucdavis.edu;zhangyic17@mails.tsinghua.edu.cn;yooli@ucdavis.edu;joyu@ucdavis.edu,1;3;8,,Reject,0,4,0,yes,9/25/19,"University of California, Davis;Tsinghua University, Tsinghua University;University of California, Davis;University of California, Davis",NLP;Pre-training;GPT-2;Text Generation;Dialog Generation,-1;4;-1;-1,55;23;55;55,m;f,usa,usa,n
ICLR,2020,Learning to Reason: Distilling Hierarchy via Self-Supervision and Reinforcement Learning,Jung-Su Ha;Young-Jin Park;Hyeok-Joo Chae;Soon-Seo Park;Han-Lim Choi,jung-su.ha@ipvs.uni-stuttgart.de;yjpark@lics.kaist.ac.kr;hjchae@lics.kaist.ac.kr;sspark@lics.kaist.ac.kr;hanlimc@kaist.ac.kr,6;1;3,,Reject,0,10,0,yes,9/25/19,University of Stuttgart;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Reinforcement learning;Self-supervised learning;unsupervised learning;representation learning,118;-1;-1;-1;-1,292;110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,The Geometry of Sign Gradient Descent,Lukas Balles;Fabian Pedregosa;Nicolas Le Roux,lukas.balles@tuebingen.mpg.de;f@bianp.net;nicolas@le-roux.name,3;1;3,,Reject,0,4,0,yes,9/25/19,Max-Planck Institute;Google;Google,Sign gradient descent;signSGD;steepest descent;Adam,-1;-1;-1,-1;-1;-1,m;m,asia,in,y
ICLR,2020,Effective Use of Variational Embedding Capacity in Expressive End-to-End Speech Synthesis,Eric Battenberg;Soroosh Mariooryad;Daisy Stanton;RJ Skerry-Ryan;Matt Shannon;David Kao;Tom Bagby,ebattenberg@google.com;soroosh@google.com;daisy@google.com;rjryan@google.com;mattshannon@google.com;davidkao@google.com;tombagby@google.com,6;6;3,,Reject,0,7,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,Speech Synthesis;Deep Generative Models;Latent Variable Models;Unsupervised Representation Learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,The problem with DDPG: understanding failures in deterministic environments with sparse rewards,Guillaume Matheron;Olivier Sigaud;Nicolas Perrin,matheron@isir.upmc.fr;olivier.sigaud@upmc.fr;perrin@isir.upmc.fr,6;3;3,,Reject,0,4,0,yes,9/25/19,"Universit√© Pierre et Marie Curie - Paris 6;Computer Science Lab  - Pierre and Marie Curie University, Paris, France;Universit√© Pierre et Marie Curie - Paris 6",ddpg;reinforcement learning;deep learning;policy gradient,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Enhanced Convolutional Neural Tangent Kernels,Dingli Yu;Ruosong Wang;Zhiyuan Li;Wei Hu;Ruslan Salakhutdinov;Sanjeev Arora;Simon S. Du,dingliy@cs.princeton.edu;ruosongw@andrew.cmu.edu;zhiyuanli@cs.princeton.edu;huwei@cs.princeton.edu;rsalakhu@cs.cmu.edu;arora@cs.princeton.edu;ssdu@ias.edu,3;6;6,,Reject,0,6,0,yes,9/25/19,"Princeton University;Carnegie Mellon University;Princeton University;Princeton University;Carnegie Mellon University;Princeton University;Institue for Advanced Study, Princeton",neural tangent kernel;data augmentation;global average pooling;kernel regression;deep learning theory;kernel design,30;1;30;30;1;30;-1,6;27;6;6;27;6;-1,m;m,NAN,NAN,y
ICLR,2020,COMBINED FLEXIBLE ACTIVATION FUNCTIONS FOR DEEP NEURAL NETWORKS,Renlong Jie;Junbin Gao;Andrey Vasnev;Minh-Ngoc Tran,renlong.jie@sydney.edu.au;junbin.gao@sydney.edu.au;andrey.vasnev@sydney.edu.au;minh-ngoc.tran@sydney.edu.au,1;3;3,,Reject,0,4,0,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney;University of Sydney,Flexible;Activation Functions;Deep Learning;Regularization,64;64;64;64,60;60;60;60,m;m,europe,uk,n
ICLR,2020,Meta-RCNN: Meta Learning for Few-Shot Object Detection,Xiongwei Wu;Doyen Sahoo;Steven C. H. Hoi,xwwu.2015@smu.edu.sg;dsahoo@salesforce.com;shoi@salesforce.com,6;3;8,,Reject,0,3,0,yes,9/25/19,Singapore Management University;SalesForce.com;SalesForce.com,Few-shot detection;Meta-Learning;Object Detection,79;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,AutoSlim: Towards One-Shot Architecture Search for Channel Numbers,Jiahui Yu;Thomas Huang,jyu79@illinois.edu;t-huang1@illinois.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",AutoSlim;Neural Architecture Search;Efficient Networks;Network Pruning,-1;-1,-1;-1,m;m,usa,usa,n
ICLR,2020,Learning from Imperfect Annotations: An End-to-End Approach,Emmanouil Antonios Platanios;Maruan Al-Shedivat;Eric Xing;Tom Mitchell,e.a.platanios@cs.cmu.edu;alshedivat@cs.cmu.edu;epxing@cs.cmu.edu;tom.mitchell@cs.cmu.edu,6;6;6,,Reject,0,4,1,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1,27;27;27;27,m;m,usa,usa,n
ICLR,2020,Feature Map Transform Coding for Energy-Efficient CNN Inference,Brian Chmiel;Chaim Baskin;Ron Banner;Evgenii Zheltonozhskii;Yevgeny Yermolin;Alex Karbachevsky;Alex M. Bronstein;Avi Mendelson,brian.chmiel@intel.com;chaimbaskin@cs.technion.ac.il;ron.banner@intel.com;evgeniizh@campus.technion.ac.il;yevgeny_ye@campus.technion.ac.il;alex.k@cs.technion.ac.il;bron@cs.technion.ac.il;avi.mendelson@cs.technion.ac.il,3;3;8,,Reject,0,3,0,yes,9/25/19,"Intel;Technion, Technion;Intel;Technion, Technion;Technion, Technion;Technion, Technion;Technion, Technion;Technion, Technion",compression;efficient inference;quantization;memory bandwidth;entropy,-1;27;-1;27;27;27;27;27,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Zero-Shot Out-of-Distribution Detection with Feature Correlations,Chandramouli S Sastry;Sageev Oore,chandramouli.sastry@gmail.com;osageev@gmail.com,3;8;3,,Reject,0,11,0,yes,9/25/19,Dalhousie University;Dalhousie University,out-of-distribution;gram matrices;classification;out-of-distribution detection,316;316,269;269,m;m,canada,ca,n
ICLR,2020,Neural Video Encoding,Abel Brown;Robert DiPietro,abelb@nvidia.com;rdipietro@nvidia.com,1;1;3,,Reject,0,0,0,yes,9/25/19,NVIDIA;NVIDIA,Kolmogorov complexity;differentiable programming;convolutional neural networks,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Continuous Adaptation in Multi-agent Competitive Environments,Kuei-Tso Lee;Sheng-Jyh Wang,fuj30089@gmail.com;shengjyh@faculty.nctu.edu.tw,1;1,,Reject,0,4,0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,multi-agent environment;continuous adaptation;Nash equilibrium;deep counterfactual regret minimization;reinforcement learning;stochastic game;baseball,-1;118,-1;564,u;m,asia,tw,n
ICLR,2020,Simple and Effective Stochastic Neural Networks,Tianyuan Yu;Yongxin Yang;Da Li;Timothy Hospedales;Tao Xiang,tianyuan.yu@surrey.ac.uk;yongxin.yang@surrey.ac.uk;dali.darren@hotmail.com;t.hospedales@ed.ac.uk;t.xiang@surrey.ac.uk,6;3;3,,Reject,0,3,0,yes,9/25/19,University of Surrey;University of Surrey;;University of Edinburgh;University of Surrey,stochastic neural networks;pruning;adversarial defence;label noise,168;168;-1;36;168,260;260;-1;30;260,m;m,europe,uk,n
ICLR,2020,On The Difficulty of Warm-Starting Neural Network Training,Jordan T. Ash;Ryan P. Adams,jordanta@cs.princeton.edu;rpa@princeton.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,Princeton University;Princeton University,deep learning;neural networks,30;30,6;6,m;m,usa,usa,y
ICLR,2020,Thwarting finite difference adversarial attacks with output randomization,Haidar Khan;Dan Park;Azer Khan;B√ºlent Yener,haidark@gmail.com;parkd5@gmail.com;azerkkhan@gmail.com;byener@gmail.com,3;6;3;3,,Reject,0,7,0,yes,9/25/19,Amazon;;;Rensselaer Polytechnic Institute,black box adversarial attacks;adversarial examples;defense;deep learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming,Claudio Michaelis;Benjamin Mitzkus;Robert Geirhos;Evgenia Rusak;Oliver Bringmann;Alexander S. Ecker;Matthias Bethge;Wieland Brendel,claudio.michaelis@uni-tuebingen.de;benjamin.mitzkus@uni-tuebingen.de;robert@geirhos.de;evgenia.rusak@bethgelab.org;oliver.bringmann@uni-tuebingen.de;alexander.ecker@uni-tuebingen.de;matthias@bethgelab.org;wieland.brendel@bethgelab.org,3;3;3,,Reject,0,6,0,yes,9/25/19,"University of Tuebingen;University of Tuebingen;;Centre for Integrative Neuroscience, AG Bethge;University of Tuebingen;University of Tuebingen;Centre for Integrative Neuroscience, AG Bethge;Centre for Integrative Neuroscience, AG Bethge",deep learning;object detection;robustness;neural networks;data augmentation;autonomous driving,143;143;-1;-1;143;143;-1;-1,91;91;-1;-1;91;91;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Negative Sampling in Variational Autoencoders,Adri√°n Csisz√°rik;Beatrix Benk≈ë;D√°niel Varga,csadrian@renyi.hu;bbeatrix1010@gmail.com;daniel@renyi.hu,3;6;3,,Reject,0,5,0,yes,9/25/19,Alfr√©d R√©nyi Institute of Mathematics;;Alfr√©d R√©nyi Institute of Mathematics,Variational Autoencoder;generative modelling;out-of-distribution detection,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,An Empirical and Comparative Analysis of Data Valuation with Scalable Algorithms,Ruoxi Jia;Xuehui Sun;Jiacen Xu;Ce Zhang;Bo Li;Dawn Song,ruoxijia@berkeley.edu;zidaneandmessi@sjtu.edu.cn;coldstudy@sjtu.edu.cn;ce.zhang@inf.ethz.ch;lxbosky@gmail.com;dawnsong@gmail.com,1;1;3,,Reject,0,9,0,yes,9/25/19,University of California Berkeley;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Swiss Federal Institute of Technology;University of California Berkeley;University of California Berkeley,Data valuation;machine learning,-1;30;30;-1;-1;-1,13;157;157;-1;13;13,f;f,usa,usa,y
ICLR,2020,Attraction-Repulsion Actor-Critic for Continuous Control Reinforcement Learning,Thang Doan;Bogdan Mazoure;Audrey Durand;Joelle Pineau;R Devon Hjelm,thang.doan@mail.mcgill.ca;bogdan.mazoure@mail.mcgill.ca;audrey.durand@ift.ulaval.ca;jpineau@cs.mcgill.ca;devon.hjelm@microsoft.com,3;3;8,,Reject,0,4,0,yes,9/25/19,McGill University;McGill University;Laval university;McGill University;Microsoft,reinforcement learning;continuous control;multi-agent;mujoco,102;102;-1;102;-1,42;42;272;42;-1,f;m,NAN,NAN,n
ICLR,2020,NormLime: A New Feature Importance Metric for Explaining Deep Neural Networks,Isaac Ahern;Adam Noack;Luis Guzman-Nateras;Dejing Dou;Boyang Li;Jun Huan,isaac@biofidelic.com;anoack2@uoregon.edu;lguzmann@uoregon.edu;dou@cs.uoregon.edu;boyangli@baidu.com;huanjun@baidu.com,3;6;6,,Reject,0,3,0,yes,9/25/19,University of Oregon;University of Oregon;University of Oregon;University of Oregon;Baidu;Baidu,Machine Learning;Deep Learning;Interpretability;Feature Importance;Salience,194;194;194;194;-1;-1,288;288;288;288;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unsupervised Learning of Node Embeddings by Detecting Communities,Chi Thang Duong;Dung Hoang;Truong Giang Le Ba;Thanh Le Cong;Hongzhi Yin;Matthias Weidlich;Quoc Viet Hung Nguyen;Karl Aberer,thang.duong@epfl.ch;dungmin97@gmail.com;giangpna98@gmail.com;thanhcls1316@gmail.com;h.yin1@uq.edu.au;matthias.weidlich@hu-berlin.de;quocviethung1@gmail.com;karl.aberer@epfl.ch,3;3;3,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;;;Hong Kong University of Science and Technology;University of Queensland;Humboldt Universit√§t Berlin;Griffith University;Swiss Federal Institute of Technology Lausanne,Unsupervised Learning;Graph Embedding;Community Detection;Mincut;Normalized cut;Deep Learning,-1;-1;-1;-1;248;-1;-1;-1,-1;-1;-1;47;66;-1;240;-1,m;m,NAN,NAN,y
ICLR,2020,Global graph curvature,Liudmila Prokhorenkova;Egor Samosvat;Pim van der Hoorn,ostroumova-la@yandex-team.ru;sameg@yandex-team.ru;pimvdhoorn@gmail.com,6;6;3,,Reject,0,8,0,yes,9/25/19,Yandex;Yandex;Eindhoven University of Technology,graph curvature;graph embedding;hyperbolic space;distortion;Ollivier curvature;Forman curvature,-1;-1;-1,-1;-1;185,f;m,NAN,NAN,y
ICLR,2020,Invertible generative models for  inverse problems: mitigating representation error and dataset bias,Muhammad Asim;Ali Ahmed;Paul Hand,msee16001@itu.edu.pk;ali.ahmed@itu.edu.pk;p.hand@northeastern.edu,6;1;3;6,,Reject,0,4,0,yes,9/25/19,"ITU of Punjab Lahore, Pakistan;ITU of Punjab Lahore, Pakistan;Northeastern University",Invertible generative models;inverse problems;generative prior;Glow;compressed sensing;denoising;inpainting.,-1;-1;16,-1;-1;906,m;m,usa,usa,n
ICLR,2020,Decaying momentum helps neural network training,John Chen;Anastasios Kyrillidis,jc114@rice.edu;anastasios@rice.edu,6;3;3,,Reject,0,10,0,yes,9/25/19,Rice University;Rice University,sgd;momentum;adam;optimization;deep learning,92;92,105;105,m;m,australasia,au,n
ICLR,2020,GRAPH NEIGHBORHOOD ATTENTIVE POOLING,Zekarias Tilahun Kefato;Sarunas Girdzijauskas,zekarias@kth.se;sarunasg@kth.se,3;3;3,,Reject,0,3,0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",Network Representation Learning;Attentive Pooling Networks;Context-sensitive Embedding;Mutual Attention;Link Prediction;Node Clustering,194;194,222;222,m;m,NAN,NAN,n
ICLR,2020,Quantum algorithm for finding the negative curvature direction,Kaining Zhang;Min-Hsiu Hsieh;Liu Liu;Dacheng Tao,kzha3670@uni.sydney.edu.au;min-hsiu.hsieh@uts.edu.au;liu.liu1@sydney.edu.au;dacheng.tao@sydney.edu.au,6;6;3,,Reject,0,4,0,yes,9/25/19,University of Sydney;University of Technology Sydney;University of Sydney;University of Sydney,quantum algorithm;negative curvature,64;73;64;64,60;193;60;60,u;m,europe,uk,y
ICLR,2020,"Walking on the Edge: Fast, Low-Distortion Adversarial Examples",Hanwei Zhang;Teddy Furon;Yannis Avrithis;Laurent Amsaleg,hanwei.zhang@irisa.fr;teddy.furon@inria.fr;yannis@avrithis.net;laurent.amsaleg@irisa.fr,3;3;6,,Reject,0,5,0,yes,9/25/19,IRISA;INRIA;INRIA;IRISA,Deep learning;adversarial attack,-1;-1;-1;-1,-1;-1;-1;-1,f;m,europe,fr,n
ICLR,2020,"Deep Reasoning Networks:  Thinking Fast and Slow, for Pattern De-mixing",Di Chen;Yiwei Bai;Wenting Zhao;Sebastian Ament;John M. Gregoire;Carla P. Gomes,di@cs.cornell.edu;bywbilly@cs.cornell.edu;wzhao@cs.cornell.edu;ament@cs.cornell.edu;gregoire@caltech.edu;gomes@cs.cornell.edu,3;6;3,,Reject,0,4,0,yes,9/25/19,Cornell University;Cornell University;Cornell University;Cornell University;California Institute of Technology;Cornell University,Deep Reasoning Network;Pattern De-mixing,7;7;7;7;143;7,19;19;19;19;2;19,m;f,usa,usa,n
ICLR,2020,Measuring Calibration in Deep Learning,Jeremy Nixon;Mike Dusenberry;Ghassen Jerfel;Linchuan Zhang;Dustin Tran,jeremynixon@google.com;dusenberrymw@google.com;ghassen@google.com;linchzhang@google.com;trandustin@google.com,6;3;1,,Reject,0,0,0,yes,9/25/19,Google;Google;Google;Google;Google,Deep Learning;Multiclass Classification;Classification;Uncertainty Estimation;Calibration,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Towards Understanding the Regularization of Adversarial Robustness on Neural Networks,Yuxin Wen;Shuai Li;Kui Jia,wen.yuxin@mail.scut.edu.cn;lishuai918@gmail.com;kuijia@scut.edu.cn,6;3;6,,Reject,0,7,0,yes,9/25/19,South China University of Technology;;South China University of Technology,Adversarial robustness;Statistical Learning;Regularization,-1;-1;-1,501;-1;501,f;m,NAN,NAN,y
ICLR,2020,BRIDGING ADVERSARIAL SAMPLES AND ADVERSARIAL NETWORKS,Faqiang Liu;Mingkun Xu;Guoqi Li;Jing Pei;Luping Shi,lfq18@mails.tsinghua.edu.cn;xmk18@mails.tsinghua.edu.cn;liguoqi@mail.tsinghua.edu.cn;peij@mail.tsinghua.edu.cn;lpshi@mail.tsinghua.edu.cn,6;3;3,,Reject,0,6,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",ADVERSARIAL SAMPLES;ADVERSARIAL NETWORKS,4;4;4;4;4,23;23;23;23;23,m;m,NAN,NAN,n
ICLR,2020,Kernel and Rich Regimes in Overparametrized Models,Blake Woodworth;Suriya Gunasekar;Pedro Savarese;Edward Moroshko;Itay Golan;Jason Lee;Daniel Soudry;Nathan Srebro,blake@ttic.edu;suriya@ttic.edu;savarese@ttic.edu;edward.moroshko@gmail.com;sitaygo@campus.technion.ac.il;jasondlee88@gmail.com;daniel.soudry@gmail.com;nati@ttic.edu,6;8;3,,Reject,0,3,0,yes,9/25/19,"Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;;Technion, Technion;Princeton University;Technion, Technion;Toyota Technological Institute at Chicago",Overparametrized;Implicit;Bias;Regularization;Kernel;Rich;Adaptive;Regime,-1;-1;-1;-1;27;30;27;-1,-1;-1;-1;-1;-1;6;-1;-1,m;m,NAN,NAN,y
ICLR,2020,The Intriguing Effects of Focal Loss on the Calibration of Deep Neural Networks,Jishnu Mukhoti;Viveka Kulharia;Amartya Sanyal;Stuart Golodetz;Philip Torr;Puneet Dokania,jishnumukhoti7@gmail.com;viveka@robots.ox.ac.uk;amartya.sanyal@cs.ox.ac.uk;stuart@five.ai;philip.torr@eng.ox.ac.uk;puneet@robots.ox.ac.uk,6;3;6,,Reject,0,13,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;FiveAI;University of Oxford;University of Oxford,,-1;46;46;-1;46;46,-1;1;1;-1;1;1,m;m,europe,uk,y
ICLR,2020,Domain-Invariant Representations: A Look on Compression and Weights,Victor Bouvier;C√©line Hudelot;Cl√©ment Chastagnol;Philippe Very;Myriam Tami,vbouvier@sidetrade.com;celine.hudelot@centralesupelec.fr;cchastagnol@sidetrade.com;pveryranchet@gmail.com;myriam.tami@centralesupelec.fr,3;3;3,,Reject,0,5,0,yes,9/25/19,Sidetrade;CentraleSupelec;Sidetrade;;CentraleSupelec,Domain Adaptation;Invariant Representation;Compression;Machine Learning Theory,-1;-1;-1;-1;-1,-1;534;-1;-1;534,m;f,NAN,NAN,y
ICLR,2020,Last-iterate convergence rates for min-max optimization,Jacob Abernethy;Kevin A. Lai;Andre Wibisono,prof@gatech.edu;nykal212@gmail.com;andrwbsn@gmail.com,6;6;6,,Reject,0,5,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Yale University,min-max optimization;zero-sum game;saddle point;last-iterate convergence;non-asymptotic convergence;global rates;Hamiltonian;sufficiently bilinear,13;13;73,38;38;8,m;m,europe,fi,y
ICLR,2020,Implicit Generative Modeling for Efficient Exploration,Neale Ratzlaff;Qinxun Bai;Li Fuxin;Wei Xu,ratzlafn@oregonstate.edu;qinxun.bai@horizon.ai;lif@oregonstate.edu;wei.xu@horizon.ai,3;3;3,,Reject,0,4,0,yes,9/25/19,Oregon State University;Horizon Robotics;Oregon State University;Horizon Robotics,Reinforcement Learning;Exploration;Intrinsic Reward;Implicit Generative Models,79;-1;79;-1,373;-1;373;-1,m;m,NAN,NAN,n
ICLR,2020,Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration,Zhenyu Wu;Ye Yuan;Zhaowen Wang;Jianming Zhang;Zhangyang Wang;Hailin Jin,wuzhenyu_sjtu@tamu.edu;ye.yuan@tamu.edu;zhawang@adobe.com;jianmzha@adobe.com;atlaswang@tamu.edu;hljin@adobe.com,3;6;1,,Reject,0,4,0,yes,9/25/19,Texas A&M;Texas A&M;Adobe Systems;Adobe Systems;Texas A&M;Adobe Systems,Generative Adversarial Networks;Mode Collapse;Calibration,46;46;-1;-1;46;-1,177;177;-1;-1;177;-1,m;m,NAN,NAN,n
ICLR,2020,Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning,Jianda Chen;Shangyu Chen;Sinno Jialin Pan,jianda001@e.ntu.edu.sg;schen025@e.ntu.edu.sg;sinnopan@ntu.edu.sg,3;3;6,,Reject,0,4,0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University,,43;43;43,49;49;49,m;m,asia,sg,n
ICLR,2020,Generalized Zero-shot ICD Coding,Congzheng Song;Shanghang Zhang;Najmeh Sadoughi;Pengtao Xie;Eric Xing,cs2296@cornell.edu;shanghang.zhang@petuum.com;najmeh.sadoughi@petuum.com;pengtao.xie@petuum.com;eric.xing@petuum.com,3;6;6,,Reject,0,4,0,yes,9/25/19,Cornell University;Petuum Inc.;Petuum Inc.;Petuum Inc.;Petuum Inc.,Generalized Zero-shot Learning;ICD Coding;NLP;Generative Model;Deep Learning,7;-1;-1;-1;-1,19;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Unsupervised Disentanglement of Pose, Appearance and Background from Images and Videos",Aysegul Dundar;Kevin J Shih;Animesh Garg;Robert Pottorf;Andrew Tao;Bryan Catanzaro,aysegul.dundar89@gmail.com;kjshih2@illinois.edu;garg@cs.stanford.edu;rpottorff@gmail.com;atao@nvidia.com;bcatanzaro@nvidia.com,3;6;6,,Reject,0,4,0,yes,9/25/19,"NVIDIA;University of Illinois, Urbana Champaign;Stanford University;;NVIDIA;NVIDIA",unsupervised landmark discovery,-1;-1;5;-1;-1;-1,-1;-1;4;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,A Bayes-Optimal View on Adversarial Examples,Eitan Richardson;Yair Weiss,eitan.richardson@gmail.com;yweiss@cs.huji.ac.il,1;6;3,,Reject,0,12,1,yes,9/25/19,Google;Hebrew University of Jerusalem,Adversarial Examples;Generative Models,-1;85,-1;216,m;m,europe,il,n
ICLR,2020,"Carpe Diem, Seize the Samples Uncertain at the Moment"" for Adaptive Batch Selection""",Hwanjun Song;Minseok Kim;Sundong Kim;Jae-Gil Lee,songhwanjun@kaist.ac.kr;minseokkim@kaist.ac.kr;sundong@ibs.re.kr;jaegil@kaist.ac.kr,3;6;3,,Reject,0,3,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Institute for Basic Science;Korea Advanced Institute of Science and Technology,batch selection;uncertain sample;acceleration;convergence,-1;-1;-1;-1,110;110;-1;110,m;m,NAN,NAN,n
ICLR,2020,EXACT ANALYSIS OF CURVATURE CORRECTED LEARNING DYNAMICS IN DEEP LINEAR NETWORKS,Dongsung Huh,dongsunghuh@gmail.com,6;6;1,,Reject,0,5,0,yes,9/25/19,International Business Machines,,-1,-1,m,NAN,NAN,n
ICLR,2020,TreeCaps: Tree-Structured Capsule Networks for Program Source Code Processing,Vinoj Jayasundara;Nghi Duy Quoc Bui;Lingxiao Jiang;David Lo,vinojjayasundara@gmail.com;dqnbui.2016@phdis.smu.edu.sg;lxjiang@smu.edu.sg;davidlo@smu.edu.sg,1;3;1,,Reject,0,4,0,yes,9/25/19,"University of Maryland, College Park;Singapore Management University;Singapore Management University;Singapore Management University",Program Classification;Capsule Networks;Deep Learning,12;79;79;79,91;-1;-1;-1,m;m,asia,sg,n
ICLR,2020,Pre-trained Contextual Embedding of Source Code,Aditya Kanade;Petros Maniatis;Gogul Balakrishnan;Kensen Shi,akanade@google.com;maniatis@google.com;bgogul@google.com;kshi@google.com,6;3;6,,Reject,0,14,1,yes,9/25/19,Google;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,AdaX: Adaptive Gradient Descent with Exponential Long Term Memory,Wenjie Li;Zhaoyang Zhang;Xinjiang Wang;Ping Luo,li3549@purdue.edu;zhaoyangzhang@link.cuhk.edu.hk;swanxinjiang@gmail.com;pluo.lhi@gmail.com,3;3;1;3,,Reject,0,4,0,yes,9/25/19,Purdue University;The Chinese University of Hong Kong;SenseTime Group Limited;The University of Hong Kong,Optimization Algorithm;Machine Learning;Deep Learning;Adam,24;316;-1;92,88;35;-1;35,m;m,NAN,NAN,y
ICLR,2020,MIST: Multiple Instance Spatial Transformer Networks,Baptiste Angles;Simon Kornblith;Shahram Izadi;Andrea Tagliasacchi;Kwang Moo Yi,baptiste.angles@gmail.com;skornblith@google.com;shahrami@google.com;taglia@google.com;kyi@uvic.ca,3;3;6,,Reject,0,3,0,yes,9/25/19,Apple;Google;Google;Google;University of Victoria,,-1;-1;-1;-1;194,-1;-1;-1;-1;449,m;m,europe,cy,n
ICLR,2020,Differentiable Bayesian Neural Network Inference for Data Streams,Namuk Park;Taekyu Lee;Songkuk Kim,namuk.park@yonsei.ac.kr;taekyu.lee@yonsei.ac.kr;songkuk@yonsei.ac.kr,3;3;8,,Reject,0,4,0,yes,9/25/19,Yonsei University;Yonsei University;Yonsei University,Bayesian neural network;approximate predictive inference;data stream;histogram,143;143;143,196;196;196,m;m,asia,cn,n
ICLR,2020,CAT: Compression-Aware Training for bandwidth reduction,Chaim Baskin;Brian Chmiel;Evgenii Zheltonozhskii;Ron Banner;Alex M. Bronstein;Avi Mendelson,chaimbaskin@cs.technion.ac.il;brian.chmiel@intel.com;evgeniizh@campus.technion.ac.il;ron.banner@intel.com;bron@cs.technion.ac.il;avi.mendelson@cs.technion.ac.il,6;6;6,,Reject,0,5,0,yes,9/25/19,"Technion, Technion;Intel;Technion, Technion;Intel;Technion, Technion;Technion, Technion",compression;quantization;efficient inference;memory bandwidth;entropy;compression-aware training;Huffman;variable length coding,27;-1;27;-1;27;27,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Using Logical Specifications of Objectives in Multi-Objective Reinforcement Learning,Kolby Nottingham;Anand Balakrishnan;Jyotirmoy Deshmukh;Connor Christopherson;David Wingate,kolbytn@byu.edu;anandbal@usc.edu;jdeshmukh@usc.edu;connormc@byu.edu;wingated@cs.byu.edu,3;6;3,,Reject,0,4,0,yes,9/25/19,The Hong Kong Polytechnic University;University of Southern California;University of Southern California;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,reinforcement learning;multi-objective;multi-task;propositional logic,118;36;36;118;118,171;62;62;171;171,m;m,asia,hk,n
ICLR,2020,High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection,VSR Veeravasarapu;Deepak Mittal;Abhishek Goel;Maneesh Singh,vsr.veera@gmail.com;deepak.mittal@verisk.com;abhishek.goel@verisk.com;maneesh.singh@verisk.com,1;1;3,,Reject,0,0,0,yes,9/25/19,Verisk Analytics;Verisk Analytics;Verisk Analytics;Verisk Analytics,Computer Vision;Object Contour Detection;Curriculum Learning;Wavelets;Aerial Imagery,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning General and Reusable Features via Racecar-Training,You Xie;Nils Thuerey,you.xie@tum.de;nils.thuerey@tum.de,1;3,,Reject,0,3,0,yes,9/25/19,Technical University Munich;Technical University Munich,transfer learning;neural networks;generalization;reusable features,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Weakly-supervised Knowledge Graph Alignment with Adversarial Learning,Meng Qu;Jian Tang;Yoshua Bengio,meng.qu@umontreal.ca;jian.tang@hec.ca;yoshua.bengio@mila.quebec,6;6;3,,Reject,0,4,0,yes,9/25/19,University of Montreal;HEC Montreal;Mila,,118;-1;143,85;-1;336,m;m,NAN,NAN,y
ICLR,2020,Differentially Private Mixed-Type Data Generation For Unsupervised Learning,Uthaipon Tantipongpipat;Chris Waites;Digvijay Boob;Amaresh Siva;Rachel Cummings,uthaipon@gmail.com;cwaites10@gmail.com;digvijaybb40@gmail.com;ankit.siva@gatech.edu;racheladcummings@gmail.com,1;3,,Reject,0,1,0,yes,9/25/19,Twitter;;;Georgia Institute of Technology;Columbia University,Differential privacy;synthetic data;private data generation;mixed-type;unsupervised learning;autoencoder;GAN;private deep learning,-1;-1;-1;13;24,-1;-1;-1;38;16,m;f,usa,usa,y
ICLR,2020,Defense against Adversarial Examples by Encoder-Assisted Search in the Latent Coding Space,Wenjing Huang;Shikui Tu;Lei Xu,huangwenjing@sjtu.edu.cn;tushikui@sjtu.edu.cn,3;3;3;6,,Reject,1,7,0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Adversarial Defense;Auto-encoder;Adversarial Attack;GAN,30;30,157;157,m;m,asia,cn,n
ICLR,2020,Matrix Multilayer Perceptron,Jalil Taghia;Maria B√•nkestad;Fredrik Lindsten;Thomas Sch√∂n,jalil.taghia@ericsson.com;maria.bankestad@ri.se;fredrik.lindsten@liu.se;thomas.schon@it.uu.se,6;6;3,,Reject,0,3,0,yes,9/25/19,Ericsson;RISE Research Institutes of Sweden;Link√∂ping University;Uppsala University,Multilayer Perceptron;symmetric positive definite;heteroscedastic regression;covariance estimation,-1;-1;-1;194,-1;-1;407;102,m;m,europe,se,n
ICLR,2020,A Simple Dynamic Learning Rate Tuning Algorithm For Automated Training of DNNs,Koyel Mukherjee;Alind Khare;Yogish Sabharwal;Ashish Verma,koyelmjee@gmail.com;kharealind@gmail.com;ysabharwal@in.ibm.com;ashish.verma1@ibm.com,1;1;1,,Reject,0,7,0,yes,9/25/19,"University of Maryland, College Park;;International Business Machines;International Business Machines",adaptive LR tuning algorithm;generalization,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Structural Language Models for Any-Code Generation,Uri Alon;Roy Sadaka;Omer Levy;Eran Yahav,urialon@cs.technion.ac.il;roysadaka@gmail.com;omerlevy@gmail.com;yahave@cs.technion.ac.il,6;6;1,,Reject,0,6,0,yes,9/25/19,"Technion, Technion;;Tel Aviv University;Technion, Technion",Program Generation;Structural Language Model;SLM;Generative Model;Code Generation,27;-1;30;27,-1;-1;188;-1,m;m,NAN,NAN,n
ICLR,2020,Hierarchical Disentangle Network for Object Representation Learning,Shishi Qiao;Ruiping Wang;Shiguang Shan;Xilin Chen,qiaoshishi14@mails.ucas.ac.cn;wangruiping@ict.ac.cn;sgshan@ict.ac.cn;xlchen@ict.ac.cn,8;1;1;6,,Reject,0,5,0,yes,9/25/19,"Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",,30;30;30;30,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Improved Training Techniques for Online Neural Machine Translation,Maha Elbayad;Laurent Besacier;Jakob Verbeek,maha.elbayad@inria.fr;laurent.besacier@univ-grenoble-alpes.fr;jakob.verbeek@inria.fr,3;3;6,,Reject,0,3,0,yes,9/25/19,INRIA;University of Grenoble-Alpes;INRIA,Deep learning;natural language processing;Machine translation,-1;-1;-1,-1;-1;-1,f;m,europe,gr,n
ICLR,2020,Removing the Representation Error of GAN Image Priors Using the Deep Decoder,Max Daniels;Reinhard Heckel;Paul Hand,daniels.g@husky.neu.edu;rh43@rice.edu;p.hand@northeastern.edu,1;3;3,,Reject,0,3,0,yes,9/25/19,Northeastern University;Rice University;Northeastern University,deep decoder;deep image prior;GAN;inverse problems,16;92;16,906;105;906,m;m,usa,usa,n
ICLR,2020,Learning a Behavioral Repertoire from Demonstrations,Niels Justesen;Miguel Gonz√°lez Duque;Daniel Cabarcas Jaramillo;Jean-Baptiste Mouret;Sebastian Risi,noju@itu.edu;migonzalez@unal.edu.co;dcarbarc@unal.edu.co;jean-baptiste.mouret@inria.fr;sebr@itu.dk,1;3;3,,Reject,0,0,0,yes,9/25/19,"ITU of Punjab Lahore, Pakistan;Universidad Nacional de Colombia;Universidad Nacional de Colombia;INRIA;IT University of Copenhagen",Behavioral Repertoires;Imitation Learning;Deep Learning;Adaptation;StarCraft 2,-1;-1;-1;-1;168,-1;-1;-1;-1;101,m;m,europe,dk,n
ICLR,2020,One-Shot Neural Architecture Search via Compressive Sensing,Minsu Cho;Mohammadreza Soltani;Chinmay Hegde,chomd90@iastate.edu;mohammadreza.soltani@duke.edu;chinmay@iastate.edu,1;3;3,,Reject,0,4,0,yes,9/25/19,Iowa State University;Duke University;Iowa State University,deep learning;autoML;neural architecture search;image classification;language modeling,194;46;194,399;20;399,m;m,usa,usa,y
ICLR,2020,Deep Audio Prior,Yapeng Tian;Chenliang Xu;Dingzeyu Li,yapengtian@rochester.edu;chenliang.xu@rochester.edu;dinli@adobe.com,3;6;6,,Reject,0,5,0,yes,9/25/19,University of Rochester;University of Rochester;Adobe Systems,deep audio prior;blind sound separation;deep learning;audio representation,102;102;-1,173;173;-1,m;m,NAN,NAN,n
ICLR,2020,XD: Cross-lingual Knowledge Distillation for Polyglot Sentence Embeddings,Maksym Del;Mark Fishel,max.del.edu@gmail.com;fishel@ut.ee,1;6;6;3,,Reject,1,4,0,yes,9/25/19,University of Tartu;University of Tartu,cross-lingual transfer;sentence embeddings;polyglot language models;knowledge distillation;natural language inference;embedding alignment;embedding mapping,-1;316,-1;319,m;m,europe,uk,n
ICLR,2020,Graph Neural Networks for Soft Semi-Supervised Learning on Hypergraphs,Naganand Yadati;Tingran Gao;Shahab Asoodeh;Partha Talukdar;Anand Louis,y.naganand@gmail.com;trg17@uchicago.edu;shahab@seas.harvard.edu;ppt@iisc.ac.in;anandl@iisc.ac.in,3;3;3,,Reject,0,4,0,yes,9/25/19,Indian Institute of Science;University of Chicago;Harvard University;Indian Institute of Science;Indian Institute of Science,Graph Neural Networks;Soft Semi-supervised Learning;Hypergraphs,-1;51;52;-1;-1,-1;9;7;301;301,m;m,NAN,NAN,y
ICLR,2020,Self-Supervised State-Control through Intrinsic Mutual Information Rewards,Rui Zhao;Volker Tresp;Wei Xu,zhaorui.in.germany@gmail.com;volker.tresp@siemens.com;wei.xu@horizon.ai,6;3;3,,Reject,0,4,0,yes,9/25/19,Siemens AG;Siemens Corporate Research;Horizon Robotics,Intrinsic Reward;Deep Reinforcement Learning;Skill Discovery;Mutual Information;Self-Supervised Learning;Unsupervised Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Generative Model for Molecular Distance Geometry,Gregor N. C. Simm;Jos√© Miguel Hern√°ndez-Lobato,gncsimm@gmail.com;jmh233@cam.ac.uk,6;3;6,,Reject,1,8,0,yes,9/25/19,University of Cambridge;University of Cambridge,graph neural networks;variational autoencoders;distance geometry;molecular conformation,-1;79,-1;3,m;m,europe,uk,n
ICLR,2020,Multigrid Neural Memory,Tri Huynh;Michael Maire;Matthew R. Walter,trihuynh@uchicago.edu;mmaire@uchicago.edu;mwalter@ttic.edu,3;6;3,,Reject,0,5,1,yes,9/25/19,University of Chicago;University of Chicago;Toyota Technological Institute at Chicago,multigrid architecture;memory network;convolutional neural network,51;51;-1,9;9;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Design of Contests and All-Pay Auctions using Multi-Agent Simulation,Thomas Anthony;Ian Gemp;Janos Kramar;Tom Eccles;Andrea Tacchetti;Yoram Bachrach,twa@google.com;imgemp@google.com;janosk@google.com;eccles@google.com;atacchet@google.com;yorambac@gmail.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,Auctions;Mechanism Design;Multi-Agent;Fictitious Play,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Geometry-aware Generation of Adversarial and Cooperative Point Clouds,Yuxin Wen;Jiehong Lin;Ke Chen;Kui Jia,wen.yuxin@mail.scut.edu.cn;lin.jiehong@mail.scut.edu.cn;chenk@scut.edu.cn;kuijia@scut.edu.cn,3;3;8,,Reject,0,3,0,yes,9/25/19,South China University of Technology;South China University of Technology;South China University of Technology;South China University of Technology,Adversarial attack;Point cloud classification,-1;-1;-1;-1,501;501;501;501,m;m,NAN,NAN,n
ICLR,2020,Point Process Flows,Nazanin Mehrasa;Ruizhi Deng;Mohamed Osama Ahmed;Bo Chang;Jiawei He;Thibaut Durand;Marcus Brubaker;Greg Mori,nmehrasa@sfu.ca;ruizhid@sfu.ca;mohamed.o.ahmed@borealisai.com;bchang@stat.ubc.ca;jha203@sfu.ca;thibaut.p.durand@borealisai.com;marcus.brubaker@borealisai.com;mori@cs.sfu.ca,6;3;3,,Reject,0,7,0,yes,9/25/19,Simon Fraser University;Simon Fraser University;Borealis AI;University of British Columbia;Simon Fraser University;Borealis AI;Borealis AI;Simon Fraser University,Temporal Point Process;Intensity-free Point Process,52;52;-1;64;52;-1;-1;52,272;272;-1;34;272;-1;-1;272,f;m,canada,ca,y
ICLR,2020,Learning Effective Exploration Strategies For Contextual Bandits,Amr Sharaf;Hal Daum√© III,amr@cs.umd.edu;hal@umiacs.umd.edu,1;1;3,,Reject,0,5,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park",meta-learning;contextual bandits;imitation learning,12;12,91;91,m;m,usa,usa,y
ICLR,2020,From English to Foreign Languages: Transferring Pre-trained Language Models,Ke Tran,ketranmanh@gmail.com,3;6;3,,Reject,0,2,1,yes,9/25/19,Amazon,pretrained language model;zero-shot transfer;parsing;natural language inference,-1,-1,m;m,NAN,NAN,n
ICLR,2020,Leveraging Adversarial Examples to Obtain Robust Second-Order Representations,Mohit Prabhushankar;Gukyeong Kwon;Dogancan Temel;Ghassan AlRegib,mohit.p@gatech.edu;gukyeong.kwon@gatech.edu;cantemel@gatech.edu;alregib@gatech.edu,3;1;1,,Reject,0,0,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Second-order representation;adversarial examples;robustness;gradients,13;13;13;13,38;38;38;38,m;m,usa,usa,n
ICLR,2020,Multi-Agent Hierarchical Reinforcement Learning for Humanoid Navigation,Glen Berseth;Brandon haworth;Seonghyeon Moon;Mubbasir Kapadia;Petros Faloutsos,gberseth@gmail.com;m.brandon.haworth@gmail.com;sm2062@cs.rutgers.edu;mubbasir.kapadia@gmail.com;pfaloutsos@gmail.com,3;3;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;;Rutgers University;;York University,Multi-Agent Reinforcement Learning;Reinforcement Learning;Hierarchical Reinforcement Learning,-1;-1;30;-1;-1,13;-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,SemanticAdv: Generating Adversarial Examples via Attribute-Conditional Image Editing,Haonan Qiu;Chaowei Xiao;Lei Yang;Xinchen Yan;HongLak Lee;Bo Li,haonanqiu@link.cuhk.edu.cn;xiaocw@umich.edu;yl016@ie.cuhk.edu.hk;xcyan@umich.edu;honglak@eecs.umich.edu;lxbosky@gmail.com,3;6;6,,Reject,1,8,0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen;University of Michigan;The Chinese University of Hong Kong;University of Michigan;University of Michigan;University of California Berkeley",adversarial examples;semantic attack,46;7;316;7;7;-1,35;21;35;21;21;13,m;f,usa,usa,n
ICLR,2020,Semantic Pruning for Single Class Interpretability,Kamila Abdiyeva;Martin Lukac;Kanat Alimanov,kabdiyeva@nu.edu.kz;martin.lukac@nu.edu.kz;kanat.alimanov@nu.edu.kz,3;3;1,,Reject,0,5,0,yes,9/25/19,Australian National University;Australian National University;Australian National University,deep learning;semantic pruning;filter correlation,102;102;102,50;50;50,f;m,australasia,au,n
ICLR,2020,Dual Graph Representation Learning,Huiling Zhu;Xin Luo;Hankz Hankui Zhuo,zhuhling6@mail.sysu.edu.cn;luo35@mail2.sysu.edu.cn;zhuohank@mail.sysu.edu.cn,3;3;1,,Reject,0,0,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1,299;299;299,m;m,NAN,NAN,n
ICLR,2020,Semi-Implicit Back Propagation,Ren Liu;Xiaoqun Zhang,liur0810@sjtu.edu.cn;xqzhang@sjtu.edu.cn,1;1;3,,Reject,0,0,0,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,Optimization;Neural Network;Proximal mapping;Back propagation;Implicit,30;30,157;157,u;f,asia,cn,n
ICLR,2020,The Effect of Neural Net Architecture on Gradient Confusion & Training Performance,Karthik A. Sankararaman;Soham De;Zheng Xu;W. Ronny Huang;Tom Goldstein,karthikabinavs@gmail.com;sohamde@google.com;xuzh@cs.umd.edu;wrhuang@cs.umd.edu;tomg@cs.umd.edu,8;1;3,,Reject,0,6,0,yes,9/25/19,"Facebook;Google;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",neural network architecture;speed of training;layer width;network depth,-1;-1;12;12;12,-1;-1;91;91;91,m;m,usa,usa,y
ICLR,2020,Frequency Analysis for Graph Convolution Network,Hoang NT;Takanori Maehara,hoang.nguyen.rh@riken.jp;takanori.maehara@riken.jp,6;1;6,,Reject,0,7,0,yes,9/25/19,RIKEN;RIKEN,graph signal processing;frequency analysis;graph convolution neural network;simplified convolution network;semi-supervised vertex classification,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,A SPIKING SEQUENTIAL MODEL: RECURRENT LEAKY INTEGRATE-AND-FIRE,Daiheng Gao;Hongwei Wang;Hehui Zhang;Meng Wang;Zhenzhi Wu,samuel.gao023@gmail.com;hongwei.wang@lynxi.com;zhh@bupt.edu.cn;wangmeng_wm@bupt.edu.cn;zhenzhi.wu@lynxi.com,3;1;1,,Reject,0,0,0,yes,9/25/19,"Alibaba Group;Lynxi technologies Co., Ltd.;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Lynxi technologies Co., Ltd.",spiking neural network;RNN;spiking mode;brain-inspired;text summarization;DVS,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Expected Tight Bounds for Robust Deep Neural Network Training,Salman Alsubaihi;Adel Bibi;Modar Alfadly;Abdullah Hamdi;Bernard Ghanem,salman.subaihi@kaust.edu.sa;adel.bibi@kaust.edu.sa;modar.alfadly@kaust.edu.sa;abdullah.hamdi@kaust.edu.sa;bernard.ghanem@kaust.edu.sa,3;3;3,,Reject,1,6,0,yes,9/25/19,KAUST;KAUST;KAUST;KAUST;KAUST,network robustness;network verification;interval bound propagation,102;102;102;102;102,-1;-1;-1;-1;-1,m;m,europe,gr,y
ICLR,2020,Neural Operator Search,Wei Li;Shaogang Gong;Xiatian Zhu,w.li@qmul.ac.uk;s.gong@qmul.ac.uk;eddy.zhuxt@gmail.com,6;3;3,,Reject,0,6,0,yes,9/25/19,Queen Mary University London;Queen Mary University London;University of Surrey,deep learning;autoML;neural architecture search;image classification;attention learning;dynamic convolution,-1;-1;168,-1;-1;260,m;m,europe,uk,n
ICLR,2020,Behavior-Guided Reinforcement Learning,Aldo Pacchiano;Jack Parker-Holder;Yunhao Tang;Anna Choromanska;Krzysztof Choromanski;Michael I. Jordan,pacchiano@berkeley.edu;jh3764@columbia.edu;yt2541@columbia.edu;achoroma@gmail.com;kchoro@google.com;jordan@cs.berkeley.edu,1;3;6,,Reject,0,6,0,yes,9/25/19,University of California Berkeley;Columbia University;Columbia University;New York University;Google;University of California Berkeley,Reinforcement Learning;Optimal Transport;Evolution Strategies,-1;24;24;22;-1;-1,13;16;16;29;-1;13,m;m,usa,usa,y
ICLR,2020,"Semi-supervised semantic segmentation needs strong, high-dimensional perturbations",Geoff French;Timo Aila;Samuli Laine;Michal Mackiewicz;Graham Finlayson,g.french@uea.ac.uk;taila@nvidia.com;slaine@nvidia.com;m.mackiewicz@uea.ac.uk;g.finlayson@uea.ac.uk,3;3;3,,Reject,0,5,0,yes,9/25/19,University of East Anglia;NVIDIA;NVIDIA;University of East Anglia;University of East Anglia,computer vision;semantic segmentation;semi-supervised;consistency regularisation,-1;-1;-1;-1;-1,191;-1;-1;191;191,m;m,NAN,NAN,n
ICLR,2020,Interpretations are useful: penalizing explanations to align neural networks with prior knowledge,Laura Rieger;Chandan Singh;W. James Murdoch;Bin Yu,lauri@dtu.dk;c_singh@berkeley.edu;jmurdoch@berkeley.edu;binyu@berkeley.edu,6;3;3,,Reject,2,5,0,yes,9/25/19,Technical University of Denmark;University of California Berkeley;University of California Berkeley;University of California Berkeley,explainability;deep learning;interpretability;computer vision,-1;-1;-1;-1,182;13;13;13,f;f,usa,usa,n
ICLR,2020,Axial Attention in Multidimensional Transformers,Jonathan Ho;Nal Kalchbrenner;Dirk Weissenborn;Tim Salimans,jonathanho@google.com;nalk@google.com;diwe@google.com;salimans@google.com,1;6;1;3,,Reject,0,6,0,yes,9/25/19,Google;Google;Google;Google,self-attention;transformer;images;videos,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Adversarial Robustness as a Prior for Learned Representations,Logan Engstrom;Andrew Ilyas;Shibani Santurkar;Dimitris Tsipras;Brandon Tran;Aleksander Madry,engstrom@mit.edu;ailyas@mit.edu;shibani@mit.edu;tsipras@mit.edu;btran115@mit.edu;madry@mit.edu,3;3;6,,Reject,0,12,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,adversarial robustness;adversarial examples;robust optimization;representation learning;feature visualization,5;5;5;5;5;5,5;5;5;5;5;5,m;m,usa,usa,n
ICLR,2020,Equivariant neural networks and equivarification,Erkao Bao;Linqi Song,baoerkao@gmail.com;linqi.song@cityu.edu.hk,6;3;3;3,,Reject,0,6,0,yes,9/25/19,Simons Center for Geometry and Physics;The Hong Kong Polytechnic University,equivariant;invariant;neural network;equivarification,-1;118,-1;171,m;m,asia,hk,y
ICLR,2020,Do recent advancements in model-based deep reinforcement learning really improve data efficiency?,Kacper Piotr Kielak,k.kielak@bham.ac.uk,3;3;3,,Reject,1,4,0,yes,9/25/19,Birmingham University,deep learning;reinforcement learning;data efficiency;DQN;Rainbow;SimPLe,-1,-1,m,NAN,NAN,n
ICLR,2020,Efficient meta reinforcement learning via meta goal generation,Haotian Fu;Hongyao Tang;Jianye Hao,haotianfu@tju.edu.cn;bluecontra@tju.edu.cn;jianye.hao@tju.edu.cn,1;1;3,,Reject,0,3,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University,,39;39;39,107;107;107,u;u,asia,cn,n
ICLR,2020,The Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions,Ahmed M. Alaa;Mihaela van der Schaar,a7med3laa@hotmail.com;mihaelaucla@gmail.com,3;6;3;6,,Reject,0,7,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",,-1;-1,-1;-1,m;f,asia,in,y
ICLR,2020,Generative Adversarial Nets for Multiple Text Corpora,Diego Klabjan;Baiyang Wang,d-klabjan@northwestern.edu;baiyang@u.northwestern.edu,3;3;1,,Reject,0,0,0,yes,9/25/19,Northwestern University;Northwestern University,GAN;NLP;embeddings,46;46,22;22,m;u,usa,usa,y
ICLR,2020,Learning Similarity Metrics for Numerical Simulations,Georg Kohl;Kiwon Um;Nils Thuerey,georg.kohl@tum.de;kiwon.um@tum.de;nils.thuerey@tum.de,6;3;8,,Reject,0,4,0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,metric learning;CNNs;PDEs;numerical simulation;perceptual evaluation;physics simulation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Universal Adversarial Attack Using Very Few Test Examples,Amit Deshpande;Sandesh Kamath;K V Subrahmanyam,amitdesh@microsoft.com;ksandeshk@cmi.ac.in;kv@cmi.ac.in,3;3;3,,Reject,0,0,0,yes,9/25/19,Microsoft;Chennai Mathematical Institute;Chennai Mathematical Institute,universal;adversarial;SVD,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Improved Generalization Bound of Permutation Invariant Deep Neural Networks,Akiyoshi Sannai;Masaaki Imaizumi,akiyoshi.sannai@riken.jp;imaizumi@ism.ac.jp,1;6;3,,Reject,0,8,0,yes,9/25/19,"RIKEN;The Institute of Statistical Mathematics, Japan",Deep Neural Network;Invariance;Symmetry;Group;Generalization,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates,Yang Liu;Hongyi Guo,yangliu@ucsc.edu;guohongyi@sjtu.edu.cn,3;3;8,,Reject,0,11,0,yes,9/25/19,University of Southern California;Shanghai Jiao Tong University,learning with noisy labels;empirical risk minimization;peer loss,36;30,62;157,m;m,asia,cn,y
ICLR,2020,Mode Connectivity and Sparse Neural Networks,Jonathan Frankle;Gintare Karolina Dziugaite;Daniel M. Roy;Michael Carbin,jfrankle@csail.mit.edu;karolina.dziugaite@gmail.com;droy@utstat.toronto.edu;mcarbin@csail.mit.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,Massachusetts Institute of Technology;ServiceNow;University of Toronto;Massachusetts Institute of Technology,sparsity;mode connectivity;lottery ticket;optimization landscape,5;-1;18;5,5;-1;18;5,m;m,usa,usa,n
ICLR,2020,Generating valid Euclidean distance matrices,Moritz Hoffmann;Frank Noe,moritz.hoffmann@fu-berlin.de;frank.noe@fu-berlin.de,8;3;8,,Reject,0,3,0,yes,9/25/19,Freie Universit√§t Berlin;Freie Universit√§t Berlin,euclidean distance matrices;wgan;point clouds;molecular structures,316;316,-1;-1,m;m,europe,de,n
ICLR,2020,GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended Animation,Jiawei Zhang;Lin Meng,jiawei@ifmlab.org;lin@ifmlab.org,6;3;3,,Reject,0,7,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Florida State University,Graph Neural Networks;Node Classification;Representation Learning,-1;-1,299;-1,m;m,asia,in,y
ICLR,2020,Deep Spike Decoder (DSD),Emrah Adamey;Tarin Ziyaee;Nishanth Alapati;Jun Ye,emrah@ctrl-labs.com;tarin@ctrl-labs.com;nishanth@ctrl-labs.com;jun@ctrl-labs.com,1;1,,Reject,0,1,0,yes,9/25/19,Ctrl-labs;Ctrl-labs;Ctrl-labs;Ctrl-labs,self-supervised;deep learning;spike sorting;EMG;sEMG;autoencoder;inductive bias,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Efficient High-Dimensional Data Representation Learning via Semi-Stochastic Block Coordinate Descent Methods,Bingkun Wei;Yangyang Li;Fanhua Shang;Yuanyuan Liu;Hongying Liu;Shengmei Shen,bkwei028@gmail.com;1615401247li@gmail.com;fhshang@xidian.edu.cn;yyliu@xidian.edu.cn;hyliu@xidian.edu.cn;jane.shen@pensees.ai,6;3;3,,Reject,0,3,0,yes,9/25/19,Xidian University;;Xidian University;Xidian University;Xidian University;Xidian University,Sparse learning;Hard thresholding;High-dimensional regression,-1;-1;-1;-1;-1;-1,-1;-1;919;919;919;-1,m;f,asia,in,y
ICLR,2020,Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs,Zeyuan Chen;Shaoliang Nie;Tianfu Wu;Christopher G. Healey,zchen23@ncsu.edu;snie@ncsu.edu;tianfu_wu@ncsu.edu;healey@ncsu.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Face Completion;GANs;Conditional Image Synthesis;Interpretability;Frequency-Oriented Attention,-1;-1;-1;-1,299;299;299;299,m;m,NAN,NAN,n
ICLR,2020,Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?,Ofir Nachum;Haoran Tang;Xingyu Lu;Shixiang Gu;Honglak Lee;Sergey Levine,ofirnachum@google.com;hrtang.alex@berkeley.edu;xingyulu0701@berkeley.edu;shanegu@google.com;honglak@google.com;svlevine@eecs.berkeley.edu,3;3;3,,Reject,0,4,0,yes,9/25/19,Google;University of California Berkeley;University of California Berkeley;Google;Google;University of California Berkeley,rl;hierarchy;reinforcement learning,-1;-1;-1;-1;-1;-1,-1;13;13;-1;-1;13,m;m,usa,usa,n
ICLR,2020,Improving Exploration of Deep Reinforcement Learning using Planning for Policy Search,Jakob J. Hollenstein;Erwan Renaudo;Justus Piater,jakob.hollenstein@uibk.ac.at;erwan.renaudo@uibk.ac.at;justus.piater@uibk.ac.at,3;1;1,,Reject,0,3,0,yes,9/25/19,University of Innsbruck;University of Innsbruck;University of Innsbruck,reinforcement learning;kinodynamic planning;policy search,-1;-1;-1,415;415;415,m;m,NAN,NAN,n
ICLR,2020,"Improved Training Speed, Accuracy, and Data Utilization via Loss Function Optimization",Santiago Gonzalez;Risto Miikkulainen,slgonzalez@utexas.edu;risto@cs.utexas.edu,3;3;1,,Reject,0,0,0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin",metalearning;evolutionary computation;loss functions;optimization;genetic programming,-1;-1,-1;-1,m;m,usa,usa,n
ICLR,2020,Knowledge Hypergraphs: Prediction Beyond Binary Relations,Bahare Fatemi;Perouz Taslakian;David Vazquez;David Poole,bfatemi@cs.ubc.ca;perouz@elementai.com;dvazquez@elementai.com;poole@cs.ubc.ca,3;6;1,,Reject,0,5,0,yes,9/25/19,University of British Columbia;Element AI;Element AI;University of British Columbia,knowledge graphs;knowledge hypergraphs;knowledge hypergraph completion,64;-1;-1;64,34;-1;-1;34,f;m,canada,ca,y
ICLR,2020,FR-GAN: Fair and Robust Training,Yuji Roh;Kangwook Lee;Gyeong Jo Hwang;Steven Euijong Whang;Changho Suh,rohyj113@gmail.com;kangwook.lee@wisc.edu;hkj4276@kaist.ac.kr;swhang@kaist.ac.kr;chsuh@kaist.ac.kr,3;3;3,,Reject,0,3,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;University of Southern California;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,generative adversarial networks;model fairness;model robustness,-1;36;-1;-1;-1,110;62;110;110;110,f;m,NAN,NAN,y
ICLR,2020,Unsupervised Intuitive Physics from Past Experiences,Sebastien Ehrhardt;Aron Monszpart;Niloy Mitra;Andrea Vedaldi,hyenal@robots.ox.ac.uk;aron@nianticlabs.com;n.mitra@cs.ucl.ac.uk;vedaldi@robots.ox.ac.uk,3;3;3,,Reject,0,7,0,yes,9/25/19,University of Oxford;Niantic Inc.;University College London;University of Oxford,Intuitive physics;Deep learning,46;-1;52;46,1;-1;-1;1,m;m,europe,uk,n
ICLR,2020,Continual Learning with Delayed Feedback,THEIVENDIRAM PRANAVAN;TERENCE SIM,pranavan@u.nus.edu;tsim@comp.nus.edu.sg,1;1;1,,Reject,0,0,0,yes,9/25/19,National University of Singapore;National University of Singapore,,17;17,25;25,m;m,asia,sg,n
ICLR,2020,Adapting to Label Shift with Bias-Corrected Calibration,Avanti Shrikumar;Amr M. Alexandari;Anshul Kundaje,avanti.shrikumar@gmail.com;amr.alexandari@gmail.com;anshul@kundaje.net,6;1;3,,Reject,0,3,0,yes,9/25/19,Stanford University;Stanford University;Stanford University,calibration;label shift;domain adaptation;temperature scaling;em;bbse,-1;5;-1,-1;4;-1,f;m,asia,in,y
ICLR,2020,On the Unintended Social Bias of Training Language Generation Models with News Articles,Omar U. Florez,omar.florez@aggiemail.usu.edu,1;3;1,,Reject,0,0,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY,Fair AI;latent representations;sequence to sequence,-1,299,m,NAN,NAN,n
ICLR,2020,Attacking Graph Convolutional Networks via Rewiring,Yao Ma;Suhang Wang;Tyler Derr;Lingfei Wu;Jiliang Tang,mayao4@msu.edu;szw494@psu.edu;derrtyle@msu.edu;wuli@us.ibm.com;tangjili@msu.edu,6;3;6;3,,Reject,0,5,0,yes,9/25/19,Michigan State University;Pennsylvania State University;Michigan State University;International Business Machines;Michigan State University,Graph Neural Networks;Rewiring;Adversarial Attacks,102;43;102;-1;102,84;-1;84;-1;84,m;m,usa,usa,n
ICLR,2020,Modeling Fake News in Social Networks with Deep Multi-Agent Reinforcement Learning,Christoph Aymanns;Matthias Weber;Co-Pierre Georg;Jakob Foerster,christoph.aymanns@gmail.com;matthias.weber@unisg.ch;cogeorg@gmail.com;jakobfoerster@gmail.com,3;1;1,,Reject,0,9,0,yes,9/25/19,University of St Gallen;University of St. Gallen;;University of Toronto,deep multi-agent reinforcement learning;fake news;social networks;information aggregation,-1;-1;-1;-1,435;435;-1;-1,m;m,asia,in,n
ICLR,2020,Group-Connected Multilayer Perceptron Networks,Mohammad Kachuee;Sajad Darabi;Shayan Fazeli;Majid Sarrafzadeh,mkachuee@ucla.edu;sajad.darabi@cs.ucla.edu;shayan@cs.ucla.edu;majid@cs.ucla.edu,3;3;3,,Reject,0,5,0,yes,9/28/20,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",,-1;-1;-1;-1,17;17;17;17,m;m,usa,usa,n
ICLR,2020,Neural ODEs for Image Segmentation with Level Sets,Rafael Valle;Fitsum Reda;Mohammad Shoeybi;Patrick Legresley;Andrew Tao;Bryan Catanzaro,rafaelvalle@nvidia.com;freda@nvidia.com;mshoeybi@nvidia.com;plegresley@nvidia.com;atao@nvidia.com;bcatanzaro@nvidia.com,3;1;3,,Reject,1,0,0,yes,9/25/19,NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA;NVIDIA,neural odes;level sets;image segmentation,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Knowledge Transfer via Student-Teacher Collaboration,Tianxiao Gao;Ruiqin Xiong;Zhenhua Liu;Siwei ma;Feng Wu;Tiejun Huang;Wen Gao,gtx@pku.edu.cn;rqxiong@pku.edu.cn;liu-zh@pku.edu.cn;swma@pku.edu.cn;fengwu@ustc.edu.cn;tjhuang@pku.edu.cn;wgao@pku.edu.cn,6;8;3,,Reject,1,4,0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;University of Science and Technology of China;Peking University;Peking University,Network Compression and Acceleration;Knowledge Transfer;Student-Teacher Collaboration;Deep Learning.,14;14;14;14;-1;14;14,24;24;24;24;80;24;24,m;m,asia,cn,n
ICLR,2020,VIMPNN: A physics informed neural network for estimating potential energies of out-of-equilibrium systems,Jay Morgan;Adeline Paiement;Christian Klinke,j.p.morgan@swansea.ac.uk;adeline.paiement@univ-tln.fr;christian.klinke@uni-rostock.de,6;6;6,,Reject,0,3,0,yes,9/25/19,Swansea University;CNRS university Toulon;Rostock University,neural network;chemical energy estimation;density functional theory,-1;-1;-1,266;-1;-1,m;m,usa,usa,n
ICLR,2020,AutoLR: A Method for Automatic Tuning of Learning Rate,Nipun Kwatra;V Thejas;Nikhil Iyer;Ramachandran Ramjee;Muthian Sivathanu,nkwatra@microsoft.com;thejasvenkatesh97@gmail.com;t-niiyer@microsoft.com;ramjee@microsoft.com;muthian@microsoft.com,6;3,,Reject,0,12,0,yes,9/25/19,"Microsoft;BITS Pilani, BITS Pilani;Microsoft;Microsoft;Microsoft",Automatic Learning Rate;Deep Learning;Generalization;Stochastic Optimization,-1;445;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Continuous Convolutional Neural Network forNonuniform Time Series,Hui Shi;Yang Zhang;Hao Wu;Shiyu Chang;Kaizhi Qian;Mark Hasegawa-Johnson;Jishen Zhao,hshi@ucsd.edu;yang.zhang2@ibm.com;haowu11@illinois.edu;kqian3@illinois.edu;jhasegaw@illinois.edu;jzhao@ucsd.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,"University of California, San Diego;International Business Machines;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of California, San Diego",,-1;-1;-1;-1;-1;-1,31;-1;-1;-1;-1;31,f;f,usa,usa,y
ICLR,2020,Test-Time Training for Out-of-Distribution Generalization,Yu Sun;Xiaolong Wang;Zhuang Liu;John Miller;Alexei A. Efros;Moritz Hardt,yusun@berkeley.edu;dragonwxl123@gmail.com;zhuangl@berkeley.edu;miller_john@berkeley.edu;efros@eecs.berkeley.edu;hardt@berkeley.edu,6;6;6,,Reject,1,3,0,yes,9/25/19,"University of California Berkeley;University of California, San Diego;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley",out-of-distribution;distribution shifts,-1;-1;-1;-1;-1;-1,13;31;13;13;13;13,m;m,usa,usa,y
ICLR,2020,MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING,Prudencio Tossou;Basile Dura;Daniel Cohen;Mario Marchand;Fran√ßois Laviolette;Alexandre Lacoste,tossouprudencio@gmail.com;basile@invivoai.ca;daniel@invivoai.ca;mario.marchand@ift.ulaval.ca;francois.laviolette@ift.ulaval.ca;allac@elementai.com,6;3;8;3;6,,Reject,3,8,0,yes,9/25/19,InVivo AI;;;Laval university;Laval university;Element AI,few-shot learning;few-shot regression;deep kernel learning;biological assay modelling;drug discovery,-1;-1;-1;-1;-1;-1,-1;-1;-1;272;272;-1,m;m,NAN,NAN,n
ICLR,2020,Hybrid Weight Representation: A Quantization Method Represented with Ternary and Sparse-Large Weights,Jinbae Park;Sung-Ho Bae,qkrwlsqo94@gmail.com;shbae@khu.ac.kr,3;3;6,,Reject,0,3,0,yes,9/25/19,Kyung Hee University;Kyung Hee University,quantized neural networks;centralized quantization;hybrid weight representation;weighted ridge;ternary weight,-1;445,-1;319,m;m,asia,kr,n
ICLR,2020,Amharic Negation Handling,Girma Neshir,girma1978@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,0,Negation Handling Algorithm;Amharic Sentiment Analysis;Amharic Sentiment lexicon;char level;word level ngram;machine learning;hybrid,,,m,NAN,NAN,n
ICLR,2020,Stiffness: A New Perspective on Generalization in Neural Networks,Stanislav Fort;Pawe≈Ç Krzysztof Nowak;Stanis≈Çaw Jastrzebski;Srini Narayanan,stanislav.fort@gmail.com;powalnow@google.com;staszek.jastrzebski@gmail.com;srinin@google.com,3;3;6,,Reject,0,11,0,yes,9/25/19,Stanford University;Google;Jagiellonian University;Google,stiffness;gradient alignment;critical scale,5;-1;-1;-1,4;-1;610;-1,m;m,NAN,NAN,n
ICLR,2020,POP-Norm: A Theoretically Justified and More Accelerated Normalization Approach,Hanyang Peng;Shiqi Yu,philoso_phy0922@163.com;shiqi.yu@gmai.com,3;3;1,,Reject,0,0,0,yes,9/25/19,163;Gmai,Batch Normalization;Optimization;Accelerate Training,-1;-1,-1;-1,u;m,NAN,NAN,y
ICLR,2020,A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models,Elman Mansimov;Alex Wang;Kyunghyun Cho,elman.mansimov@gmail.com;wangalexc@gmail.com;kyunghyun.cho@nyu.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,New York University;;New York University,nlp;sequence modeling;natural language generation;machine translation;BERT;Sesame Street,-1;-1;22,-1;-1;29,m;m,usa,usa,n
ICLR,2020,Pushing the bounds of dropout,G√°bor Melis;Charles Blundell;Tom√°≈° Koƒçisk√Ω;Karl Moritz Hermann;Chris Dyer;Phil Blunsom,melisgl@google.com;cblundell@google.com;tkocisky@google.com;kmh@google.com;cdyer@google.com;pblunsom@google.com,3;3;3,,Reject,0,0,0,yes,9/25/19,Google;Google;Google;Google;Google;Google,dropout;language,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,CRNet: Image Super-Resolution Using A Convolutional Sparse Coding  Inspired Network,Menglei Zhang;Zhou Liu;Jingwei He;Lei Yu,zmlhome@whu.edu.cn;liuzhou@whu.edu.cn;jingwei_he@whu.edu.cn;ly.wd@whu.edu.cn,3;1;1,,Reject,0,0,0,yes,9/25/19,Wuhan University;Wuhan University;Wuhan University;Wuhan University,Convolutional sparse coding;LISTA;image super-resolution,194;194;194;194,354;354;354;354,m;m,europe,uk,n
ICLR,2020,Hierarchical Graph Matching Networks for Deep Graph Similarity Learning,Xiang Ling;Lingfei Wu;Saizhuo Wang;Tengfei Ma;Fangli Xu;Chunming Wu;Shouling Ji,lingxiang@zju.edu.cn;lwu@email.wm.edu;szwang@zju.edu.cn;tengfei.ma1@ibm.com;lili@yixue.us;wuchunming@zju.edu.cn;sji@zju.edu.cn,6;3;3,,Reject,0,4,0,yes,9/25/19,Zhejiang University;College of William and Mary;Zhejiang University;International Business Machines;Squirrel AI Learning;Zhejiang University;Zhejiang University,Graph Neural Network;Graph Matching Network;Graph Similarity Learning,39;194;39;-1;-1;39;39,107;-1;107;-1;-1;107;107,m;m,asia,cn,n
ICLR,2020,RATE-DISTORTION OPTIMIZATION GUIDED AUTOENCODER FOR GENERATIVE APPROACH,Keizo Kato;Jing Zhou;Akira Nakagawa,kato.keizo@jp.fujitsu.com;zhoujing@cn.fujitsu.com;anaka@jp.fujitsu.com,1;3;3,,Reject,0,6,0,yes,9/25/19,Fujitsu Laboratories Ltd.;Fujitsu Laboratories Ltd.;Fujitsu Laboratories Ltd.,Autoencoder;Rate-distortion optimization;Generative model;Unsupervised learning;Jacobian,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Recognize the Unseen Visual Predicates,Defa Zhu;Si Liu;Wentao Jiang;Guanbin Li;Tianyi Wu;Guodong Guo,zhudefa@iie.ac.cn;liusi@buaa.edu.cn;jiangwentao@buaa.edu.cn;liguanbin@mail.sysu.edu.cn;wutianyi01@baidu.com;guoguodong01@baidu.com,6;3;6,,Reject,0,5,0,yes,9/25/19,"Institute of information engineering, CAS;Beihang University;Beihang University;SUN YAT-SEN UNIVERSITY;Baidu;Baidu",Visual Relationship Detection;Scene Graph Generation;Knowledge;Zero-shot Learning,-1;102;102;-1;-1;-1,-1;594;594;299;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Self-supervised Training of Proposal-based Segmentation via Background Prediction,Isinsu Katircioglu;Helge Rhodin;Victor Constantin;J√∂rg Sp√∂rri;Mathieu Salzmann;Pascal Fua,isinsu.katircioglu@epfl.ch;rhodin@cs.ubc.ca;victor.constantin@epfl.ch;joerg.spoerri@balgrist.ch;mathieu.salzmann@epfl.ch;pascal.fua@epfl.ch,6;3;3,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;University of British Columbia;Swiss Federal Institute of Technology Lausanne;University of Zurich;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;64;-1;118;-1;-1,-1;34;-1;90;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Constrained Markov Decision Processes via Backward Value Functions,Harsh Satija;Philip Amortila;Joelle Pineau,harsh.satija@mail.mcgill.ca;philip.amortila@mail.mcgill.ca;jpineau@cs.mcgill.ca,3;8;3,,Reject,0,3,0,yes,9/25/19,McGill University;McGill University;McGill University,Reinforcement Learning;Constrained Markov Decision Processes;Deep Reinforcement Learning,102;102;102,42;42;42,m;f,canada,ca,y
ICLR,2020,Deep Interaction Processes for Time-Evolving Graphs,xiaofu chang;jianfeng wen;xuqin liu;yanming fang;le song;yuan qi,xiaofu.cxf@antfin.com;sylvain.wjf@antfin.com;xuqin.lxq@antfin.com;yanming.fym@mybank.cn;le.song@antfin.com;yuan.qi@antfin.com,3;3;3,,Reject,0,5,0,yes,9/25/19,Antfin;Antfin;Antfin;;Antfin;Antfin,deep temporal point process;multiple time resolutions;dynamic continuous time-evolving graph;anti-fraud detection,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,On summarized validation curves and generalization,Mohammad Hashir;Yoshua Bengio;Joseph Paul Cohen,mohammad.hashir.khan@umontreal.ca;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,3;3;1,,Reject,0,5,0,yes,9/25/19,University of Montreal;Mila;Stanford University,model selection;deep learning;early stopping;validation curves,118;143;5,85;336;4,m;m,usa,usa,n
ICLR,2020,The Visual Task Adaptation Benchmark,Xiaohua Zhai;Joan Puigcerver;Alexander Kolesnikov;Pierre Ruyssen;Carlos Riquelme;Mario Lucic;Josip Djolonga;Andre Susano Pinto;Maxim Neumann;Alexey Dosovitskiy;Lucas Beyer;Olivier Bachem;Michael Tschannen;Marcin Michalski;Olivier Bousquet;Sylvain Gelly;Neil Houlsby,xzhai@google.com;jpuigcerver@google.com;alexander.kolesnikoff@gmail.com;pierrot@google.com;rikel@googel.com;lucic@google.com;josipd@google.com;andresp@google.com;maximneumann@google.com;adosovitskiy@gmail.com;lbeyer@google.com;bachem@google.com;tschannen@google.com;michalski@google.com;obousquet@google.com;sylvaingelly@google.com;neilhoulsby@google.com,8;3;6,,Reject,0,7,0,yes,9/25/19,Google;Google;Google;Google;Google Inc;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,representation learning;self-supervised learning;benchmark;large-scale study,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,SPREAD  DIVERGENCE,Mingtian Zhang;David Barber;Thomas Bird;Peter Hayes;Raza Habib,mingtian.zhang.17@ucl.ac.uk;david.barber@ucl.ac.uk;thomas.bird.17@ucl.ac.uk;peter.hayes.15@ucl.ac.uk;r.habib@cs.ucl.ac.uk,3;1;3,,Reject,0,3,0,yes,9/25/19,University College London;University College London;University College London;University College London;University College London,divergence minimization;generative model;variational inference,52;52;52;52;52,-1;-1;-1;-1;-1,m;m,europe,uk,n
ICLR,2020,Adversarially learned anomaly detection for time series data,Alexander Geiger;Alfredo Cuesta-Infante;Kalyan Veeramachaneni,geigera@mit.edu;alfredo.cuesta@urjc.es;kalyanv@mit.edu,1;3;1,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Universidad Rey Juan Carlos;Massachusetts Institute of Technology,anomaly detection;gan,5;316;5,5;-1;5,m;m,usa,usa,n
ICLR,2020,CEB Improves Model Robustness,Ian Fischer;Alex A. Alemi,iansf@google.com;alemi@google.com,6;3;3,,Reject,0,5,0,yes,9/25/19,Google;Google,Information Theory;Adversarial Robustness,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Mildly Overparametrized Neural Nets can Memorize Training Data Efficiently,Rong Ge;Runzhe Wang;Haoyu Zhao,rongge@cs.duke.edu;wrz16@mails.tsinghua.edu.cn;zhaohy16@mails.tsinghua.edu.cn,1;3;8,,Reject,0,3,0,yes,9/25/19,"Duke University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",nonconvex optimization;optimization landscape;overparametrization,46;4;4,20;23;23,m;m,NAN,NAN,y
ICLR,2020,Data-Driven Approach to Encoding and Decoding 3-D Crystal Structures,Jordan Hoffmann;Louis Maestrati;Yoshihide Sawada;Jian Tang;Jean Michel Sellier;Yoshua Bengio,jhoffmann@g.harvard.edu;maestratilouis@gmail.com;sawada.yoshihide@jp.panasonic.com;jian.tang@hec.ca;jeanmichel.sellier@mila.quebec;yoshua.bengio@mila.quebec,8;1;3,,Reject,0,6,0,yes,9/25/19,Harvard University;;Panasonic Corporation;HEC Montreal;Mila;Mila,,52;-1;-1;-1;143;143,7;-1;-1;-1;336;336,m;m,NAN,NAN,n
ICLR,2020,Mean Field Models for Neural Networks in Teacher-student Setting,Lexing Ying;Yuandong Tian,lexing@stanford.edu;yuandong@fb.com,3;3;1,,Reject,0,5,0,yes,9/25/19,Stanford University;Facebook,mean field model;optimal transport;ResNet,5;-1,4;-1,m;m,NAN,NAN,y
ICLR,2020,A novel Bayesian estimation-based word embedding model for sentiment analysis,Jingyao Tang;Yun Xue;Ziwen Wang;Haoliang Zhao,manderous@foxmail.com;995438712@qq.com;773473833@qq.com;1044012786@qq.com,6;1;3,,Reject,0,3,0,yes,9/25/19,Foxmail;;;South China Normal University,sentiment analysis;sentiment word embeddings;maximum likelihood estimation;Bayesian estimation,-1;-1;-1;-1,-1;-1;-1;-1,u;u,asia,in,n
ICLR,2020,Improving Gradient Estimation in Evolutionary Strategies With Past Descent Directions,Florian Meier;Asier Mujika;Marcelo Gauy;Angelika Steger,meierflo@inf.ethz.ch;asierm@inf.ethz.ch;marcelo.matheus@inf.ethz.ch;steger@inf.ethz.ch,3;3;6,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Evolutionary Strategies;Surrogate Gradients,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,y
ICLR,2020,Few-Shot Few-Shot Learning and the role of Spatial Attention,Yann Lifchitz;Yannis Avrithis;Sylvaine Picard,yann.lifchitz@safrangroup.com;yannis@avrithis.net;sylvaine.picard@safrangroup.com,3;3;1,,Reject,0,3,0,yes,9/25/19,Safran;INRIA;Safran,few-shot learning;spatial attention,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Generative Cleaning Networks with Quantized Nonlinear Transform  for  Deep Neural Network Defense,Jianhe Yuan;Zhihai He,yuanjia@missouri.edu;hezhi@missouri.edu,1;8;3,,Reject,0,10,0,yes,9/25/19,"University of Missouri, Columbia;University of Missouri, Columbia",Adversarial Defense;Adversarial Attack,316;316,424;424,u;m,NAN,NAN,n
ICLR,2020,Clustered Reinforcement Learning,Xiao Ma;Shen-Yi Zhao;Zhao-Heng Yin;Wu-Jun Li,max@lamda.nju.edu.cn;zhaosy@lamda.nju.edu.cn;zhaohengyin@gmail.com;liwujun@nju.edu.cn,3;6;3,,Reject,0,0,0,yes,9/25/19,Zhejiang University;Zhejiang University;;Zhejiang University,,39;39;-1;39,107;107;-1;107,u;u,asia,cn,n
ICLR,2020,Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders,Yang Li;Julien Amelot;Xin Zhou;Samy Bengio;Si Si,liyang@google.com;jamelot@google.com;zhouxin@google.com;bengio@google.com;sisidaisy@google.com,3;1;3,,Reject,0,3,0,yes,9/25/19,Google;Google;Google;Google;Google,Transformer;decoder;user interface;layout design,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Visual Imitation with Reinforcement Learning using Recurrent Siamese Networks,Glen Berseth;Christopher Pal,gberseth@gmail.com;christopher.pal@polymtl.ca,8;3;3,,Reject,0,6,0,yes,9/28/20,University of California Berkeley;Polytechnique Montreal,imitation learning;reinforcement learning;imitation from video,-1;316,13;-1,m;m,canada,ca,n
ICLR,2020,Deep Graph Translation,Xiaojie Guo;Lingfei Wu;Liang Zhao,xguo7@gmu.edu;wuli@us.ibm.com;lzhao9@gmu.edu,3;3;8,,Reject,0,5,0,yes,9/25/19,George Mason University;International Business Machines;George Mason University,Graph translation;graph generation;deep neural network,85;-1;85,282;-1;282,m;m,usa,usa,n
ICLR,2020,GAN-based Gaussian Mixture Model Responsibility Learning,Wanming Huang;Shuai Jiang;Xuan Liang;Ian Oppermann;Richard Yi Da Xu,wanming.huang@student.uts.edu.au;shuai.jiang-1@student.uts.edu.au;xuan.liang@student.uts.edu.au;ianopper@outlook.com;yida.xu@uts.edu.au,1;3;1,,Reject,0,0,0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,Generative Adversarial Networks,73;73;73;73;73,193;193;193;193;193,u;m,australasia,au,n
ICLR,2020,CROSS-DOMAIN CASCADED DEEP TRANSLATION,Oren Katzir;Dani Lischinski;Daniel Cohen-Or,orenkatzir@mail.tau.ac.il;cohenor@gmail.com;danix3d@gmail.com,6;6;3,,Reject,0,5,0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Hebrew University of Jerusalem,computer vision;image translation;generative adversarial networks,30;30;85,188;188;216,m;m,europe,il,n
ICLR,2020,Mean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks,Soufiane Hayou;Arnaud Doucet;Judith Rousseau,soufiane.hayou@stats.ox.ac.uk;doucet@stats.ox.ac.uk;judith.rousseau@stats.ox.ac.uk,6;6;3,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,,46;46;46,1;1;1,m;f,europe,uk,y
ICLR,2020,NORML: Nodal Optimization for Recurrent Meta-Learning,David van Niekerk,davidpetrus94@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,0,meta-learning;learning to learn;few-shot classification;memory-based optimization,,,m,NAN,NAN,n
ICLR,2020,Programmable Neural Network Trojan for Pre-trained Feature Extractor,Yu Ji;Zinxin Liu;Xing Hu;Peiqi Wang;Youhui Zhang,jiy15@mails.tsinghua.edu.cn;liuzixin18@mails.tsinghua.edu.cn;xinghu@ucsb.edu;wpq14@mails.tsinghua.edu.cn;zyh02@tsinghua.edu.cn,3;1;6,,Reject,0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;UC Santa Barbara;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Neural Network;Trojan;Security,4;4;-1;4;4,23;23;-1;23;23,m;m,NAN,NAN,n
ICLR,2020,Contextual Inverse Reinforcement Learning,Philip Korsunsky;Stav Belogolovsky;Tom Zahavy;Chen Tessler;Shie Mannor,philip.korsunsky@gmail.com;stav.belo@gmail.com;tomzahavy@gmail.com;chen.tessler@gmail.com;shie@ee.technion.ac.il,6;3;6,,Reject,0,13,0,yes,9/25/19,"Technion, Technion;;DeepMind;Technion, Technion;Technion, Technion",Contextual MDP;Inverse Reinforcement Learning;Reinforcement Learning;Mirror Descent,-1;-1;-1;27;27,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Convolutional Bipartite Attractor Networks,Michael L. Iuzzolino;Yoram Singer;Michael C. Mozer,michael.iuzzolino@colorado.edu;yoram.singer@gmail.com;mcmozer@google.com,3;3;3,,Reject,0,3,0,yes,9/25/19,"University of Colorado, Boulder;;Google",attractor network;recurrent network;energy function;convolutional network;image completion;super-resolution,59;-1;-1,123;-1;-1,m;m,NAN,NAN,n
ICLR,2020,DeepSimplex: Reinforcement Learning of Pivot Rules Improves the Efficiency of Simplex Algorithm in Solving Linear Programming Problems,Varun Suriyanarayana;Onur Tavaslioglu;Ankit B. Patel;Andrew J. Schaefer,vs478@cornell.edu;onur.tavaslioglu@bcm.edu;ankit.patel@bcm.edu;andrew.schaefer@rice.edu,1;3;1,,Reject,0,4,0,yes,9/25/19,Cornell University;Baylor College of Medicine;Baylor College of Medicine;Rice University,Simplex Algorithm;Pivoting Rules;Reinforcement Learning;Combinatorial Optimization;Supervised Learning;Travelling Salesman Problem,7;-1;-1;92,19;-1;-1;105,m;m,australasia,au,n
ICLR,2020,Temporal-difference learning for nonlinear value function approximation in the lazy training regime,Andrea Agazzi;Jianfeng Lu,agazzi@math.duke.edu;jianfeng@math.duke.edu,6;6;3;3,,Reject,0,5,0,yes,9/25/19,Duke University;Duke University,deep reinforcement learning;function approximation;temporal-difference;lazy training,46;46,20;20,m;m,europe,se,y
ICLR,2020,Off-policy Multi-step Q-learning,Gabriel Kalweit;Maria Huegle;Joschka Boedecker,kalweitg@cs.uni-freiburg.de;hueglem@informatik.uni-freiburg.de;jboedeck@informatik.uni-freiburg.de,1;3;3,,Reject,0,14,0,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Multi-step Learning;Off-policy Learning;Q-learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Towards Interpretable Molecular Graph Representation Learning,Emmanuel Noutahi;Dominique Beani;Julien Horwood;Prudencio Tossou,emmanuel@invivoai.com;dominique@invivoai.com;julien@invivoai.com;prudencio@invivoai.com,6;1;6,,Reject,0,5,0,yes,9/25/19,InVivo AI;InVivo AI;InVivo AI;InVivo AI,molecular graphs;graph pooling;hierarchical;GNN;Laplacian;drug discovery,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Effective Mechanism to Mitigate Injuries During NFL Plays ,Arraamuthan Arulanantham;Ahamed Arshad Ahamed Anzar;Gowshalini Rajalingam;Krusanth Ingran;Prasanna S. Haddela,anzanfas@gmail.com;arulanantham.arraamuthan@my.sliit.lk;it16113800@my.sliit.lk;krusanth7@gmail.com;prasanna@sliit.lk,1;1;1,,Reject,0,0,0,yes,9/25/19,Srilanka Institute of information Technology;Srilanka Institute of information Technology;Srilanka Institute of information Technology;;Srilanka Institute of information Technology,Concussion;American football;Predictive modelling;Injuries;NFL Plays;Optimization,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,u;u,NAN,NAN,n
ICLR,2020,Ecological Reinforcement Learning,John D. Co-Reyes;Suvansh Sanjeev;Glen Berseth;Abhishek Gupta;Sergey Levine,jcoreyes@eecs.berkeley.edu;suvansh@berkeley.edu;gberseth@gmail.com;abhigupta@berkeley.edu;svlevine@eecs.berkeley.edu,1;3;3,,Reject,0,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,non-episodic;environment analysis;reward shaping;curriculum learning,-1;-1;-1;-1;-1,13;13;13;13;13,m;m,usa,usa,n
ICLR,2020,CP-GAN: Towards a Better Global Landscape of GANs,Ruoyu Sun;Tiantian Fang;Alex Schwing,ruoyus@illinois.edu;tf6@illinois.edu;aschwing@illinois.edu,8;3;3,,Reject,0,5,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",GAN;global landscape;non-convex optimization;min-max optimization;dynamics,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Learning Semantically Meaningful Representations Through Embodiment,Viviane Clay;Peter K√∂nig;Kai-Uwe K√ºhnberger;Gordon Pipa,vkakerbeck@uos.de;pkoenig@uos.de;kkuehnbe@uos.de;gpipa@uos.de,3;1;3,,Reject,0,6,1,yes,9/25/19,University of Osnabr√ºck;University of Osnabr√ºck;University of Osnabr√ºck;University of Osnabr√ºck,reinforcement learning;deep learning;embodied;embodiment;embodied cognition;representation learning;representations;sparse coding,316;316;316;316,-1;-1;-1;-1,f;m,europe,de,n
ICLR,2020,Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks in Molecular Graph Analysis,Katsuhiko Ishiguro;Shin-ichi Maeda;Masanori Koyama,k.ishiguro.jp@ieee.org;ichi@preferred.jp;masomatics@preferred.jp,3;6;6,,Reject,0,4,0,yes,9/25/19,"Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Graph Neural Networks;molecular graph analysis;supernode;auxiliary module,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,End-To-End Input Selection for Deep Neural Networks,Stefan Oehmcke;Fabian Gieseke,stefan.oehmcke@gmail.com;fabian.gieseke@di.ku.dk,3;3;3,,Reject,0,4,0,yes,9/25/19,University of Copenhagen;University of Copenhagen,Deep Learning;Input Selection;Gumbel Softmax Trick;Remote Sensing;Feature Selection,92;92,101;101,m;m,europe,dk,n
ICLR,2020,Learning Curves for Deep Neural Networks: A field theory perspective,Omry Cohen;Or Malka;Zohar Ringel,omrycohen.38.talpiot@gmail.com;or.malka@mail.huji.ac.il;zohar.ringel@mail.huji.ac.il,1;3;8,,Reject,0,4,0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,Gaussian Processes;Neural Tangent Kernel;Learning Curves;Field Theory;Statistical Mechanics;Generalization;Deep neural networks,-1;85;85,-1;216;216,m;m,europe,il,n
ICLR,2020,Regional based query in graph active learning,Abel Roy;Louzoun Yoram,royabel10@gmail.com;louzouy@math.biu.ac.il,1;6,,Reject,0,2,0,yes,9/25/19,Bar Ilan University;Bar Ilan University,Active Learning;Graph Convolution Networks;Graph;Graph Topology,-1;102,-1;513,m;m,europe,il,n
ICLR,2020,Analysis and Interpretation of Deep CNN Representations as Perceptual Quality Features,Taimoor Tariq;Munchurl Kim,taimoor.tariq@kaist.ac.kr;mkimee@kaist.ac.kr,3;6;3;3,,Reject,0,7,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,interpretation;perceptual quality;perceptual loss;image-restoration.,-1;-1,110;110,m;m,NAN,NAN,n
ICLR,2020,Dynamical System Embedding for Efficient Intrinsically Motivated Artificial Agents,Ruihan Zhao;Stas Tiomkin;Pieter Abbeel,philipzhao@berkeley.edu;stas@berkeley.edu;pabbeel@cs.berkeley.edu,1;3;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,intrinsic motivation;empowerment;latent representation;encoder,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Siamese Attention Networks,Hongyang Gao;Yaochen Xie;Shuiwang Ji,hongyang.gao@tamu.edu;ethanycx@tamu.edu;sji@tamu.edu,6;6;3,,Reject,0,2,0,yes,9/25/19,Texas A&M;Texas A&M;Texas A&M,,46;46;46,177;177;177,m;m,NAN,NAN,n
ICLR,2020,Network Pruning for Low-Rank Binary Index,Dongsoo Lee;Se Jung Kwon;Byeongwook Kim;Parichay Kapoor;Gu-Yeon Wei,dslee3@gmail.com;mogndrewk@gmail.com;quddnr145@gmail.com;kparichay@gmail.com;gywei@g.harvard.edu,3;1;3,,Reject,0,0,0,yes,9/25/19,Samsung;Samsung;Samsung;;Harvard University,Pruning;Model compression;Index compression;low-rank;binary matrix decomposition,-1;-1;-1;-1;52,-1;-1;-1;-1;7,m;m,usa,usa,n
ICLR,2020,Attention Privileged Reinforcement Learning for Domain Transfer,Sasha Salter;Dushyant Rao;Markus Wulfmeier;Raia Hadsell;Ingmar Posner,sasha@robots.ox.ac.uk;dushyantr@google.com;mwulfmeier@google.com;raia@google.com;ingmar@robots.ox.ac.uk,3;1;3,,Reject,0,11,0,yes,9/25/19,University of Oxford;Google;Google;Google;University of Oxford,sim-to-real;domain randomisation;attention;transfer learning;reinforcement learning,46;-1;-1;-1;46,1;-1;-1;-1;1,m;m,europe,uk,n
ICLR,2020,Wildly Unsupervised Domain Adaptation and Its Powerful and Efficient Solution,Feng Liu;Jie Lu;Bo Han;Gang Niu;Guangquan Zhang;Masashi Sugiyama,feng.liu-2@student.uts.edu.au;jie.lu@uts.edu.au;bo.han@riken.jp;gang.niu@riken.jp;guangquan.zhang@uts.edu.au;sugi@k.u-tokyo.ac.jp,1;8;3,,Reject,0,9,0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;RIKEN;RIKEN;University of Technology Sydney;The University of Tokyo,,73;73;-1;-1;73;64,193;193;-1;-1;193;36,m;m,NAN,NAN,y
ICLR,2020,"Deep RL for Blood Glucose Control: Lessons, Challenges, and Opportunities",Ian Fox;Joyce Lee;Rodica Busui;Jenna Wiens,ifox@umich.edu;joyclee@med.umich.edu;rpbusui@umich.edu;wiensj@umich.edu,3;3,,Reject,0,4,0,yes,9/25/19,University of Michigan;University of Michigan;University of Michigan;University of Michigan,Deep Reinforcement Learning;Diabetes;Artificial Pancreas;Control,7;7;7;7,21;21;21;21,m;f,usa,usa,n
ICLR,2020,Learning Likelihoods with Conditional Normalizing Flows ,Christina Winkler;Daniel Worrall;Emiel Hoogeboom;Max Welling,christina.winkler.94@gmail.com;d.e.worrall@uva.nl;e.hoogeboom@uva.nl;m.welling@uva.nl,3;6;6,,Reject,2,5,0,yes,9/25/19,Technical University Munich;University of Amsterdam;University of Amsterdam;University of Amsterdam,Likelihood learning;conditional normalizing flows;generative modelling;super-resolution;vessel segmentation,-1;143;143;143,-1;62;62;62,f;m,europe,nl,n
ICLR,2020,Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality,Eric Nalisnick;Akihiro Matsukawa;Yee Whye Teh;Balaji Lakshminarayanan,e.nalisnick@eng.cam.ac.uk;matsukaw@deshaw.com;ywteh@google.com;balajiln@google.com,3;6;6,,Reject,0,6,0,yes,9/25/19,University of Cambridge;D. E. Shaw & Co.;Google;Google,Deep generative models;out-of-distribution detection;safety,79;-1;-1;-1,3;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,A Mechanism of Implicit Regularization in Deep Learning,Masayoshi Kubo;Genki Sugiura;Kenta Shinzato;Momose Oyama,kubo@i.kyoto-u.ac.jp;sugiura.genki.42n@st.kyoto-u.ac.jp;shinzato.kenta.82r@st.kyoto-u.ac.jp;oyama.momose.75c@st.kyoto-u.ac.jp,3;3;1,,Reject,0,10,0,yes,9/25/19,Kyoto University;Kyoto University;Kyoto University;Kyoto University,Implicit Regularization;Generalization;Deep Neural Network;Low Complexity,168;168;168;168,65;65;65;65,m;f,europe,fi,y
ICLR,2020,Scaleable input gradient regularization for adversarial robustness,Chris Finlay;Adam M Oberman,christopher.finlay@mail.mcgill.ca;adam.oberman@mcgill.ca,3;6;3,,Reject,0,12,0,yes,9/25/19,McGill University;McGill University,adversarial robustness;gradient regularization;robust certification;robustness bounds,102;102,42;42,m;m,canada,ca,y
ICLR,2020,Weakly-Supervised Trajectory Segmentation for Learning Reusable Skills,Parsa Mahmoudieh;Trevor Darrell;Deepak Pathak,parsa.m@berkeley.edu;trevor@eecs.berkeley.edu;pathak@berkeley.edu,3;3;1,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,skills;demonstration;agent;sub-task;primitives;robot learning;manipulation,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Compositional Visual Generation with Energy Based Models,Yilun Du;Shuang Li;Igor Mordatch,yilundu@mit.edu;lishuang@mit.edu;mordatch@google.com,3;6;6,,Reject,0,10,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Google,Compositional Generation;Energy Based Model;Compositionality;Generative Models,5;5;-1,5;5;-1,m;m,NAN,NAN,n
ICLR,2020,Fourier networks for uncertainty estimates and out-of-distribution detection,Hartmut Maennel;Alexandru »öifrea,hartmutm@google.com;tifreaa@student.ethz.ch,3;6;1,,Reject,2,3,0,yes,9/25/19,Google;Swiss Federal Institute of Technology,Fourier network;out-of-distribution detection;large initialization;uncertainty;ensembles,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Finding Winning Tickets with Limited (or No) Supervision,Mathilde Caron;Ari Morcos;Piotr Bojanowski;Julien Mairal;Armand Joulin,mathilde@fb.com;arimorcos@gmail.com;bojanowski@fb.com;julien.mairal@inria.fr;ajoulin@fb.com,1;3;6;3,,Reject,0,5,0,yes,9/25/19,Facebook;Facebook;Facebook;INRIA;Facebook,Lottery Tickets Hypothesis;Self-Supervised Learning;Deep Learning;Image Recognition,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,DASGrad: Double Adaptive Stochastic Gradient,Kin Gutierrez;Cristian Challu;Jin Li;Artur Dubrawski,kdgutier@cs.cmu.edu;cchallu@cs.cmu.edu;jinl2@cs.cmu.edu;awd@cs.cmu.edu,6;3;3,,Reject,0,2,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,stochastic convex optimization;adaptivity;online learning;transfer learning,1;1;1;1,27;27;27;27,m;m,usa,usa,y
ICLR,2020,Physics-Aware Flow Data Completion Using Neural Inpainting,Sebastien Foucher;Jingwei Tang;Vinicius da Costa de Azevedo;Byungsoo Kim;Markus Gross;Barbara Solenthaler,sfoucher@ethz.ch;jingwei.tang@inf.ethz.ch;vinicius.azevedo@inf.ethz.ch;kimby@inf.ethz.ch;grossm@inf.ethz.ch;solenthaler@inf.ethz.ch,1;3;3,,Reject,0,0,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,neural inpainting;fluid dynamics;flow data completion;physics-aware network,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Towards Modular Algorithm Induction,Daniel A. Abolafia;Rishabh Singh;Manzil Zaheer;Charles Sutton,danabo@google.com;rising@google.com;manzilzaheer@google.com;charlessutton@google.com,1;1;1,,Reject,0,1,0,yes,9/25/19,Google;Google;Google;Google,algorithm induction;reinforcement learning;program synthesis;modular,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PROVABLY BENEFITS OF DEEP HIERARCHICAL RL,Zeyu Jia;Simon S. Du;Ruosong Wang;Mengdi Wang;Lin F. Yang,jiazy@pku.edu.cn;ssdu@ias.edu;ruosongw@andrew.cmu.edu;mengdiw@princeton.edu;linyang@ee.ucla.edu,1;3;3,,Reject,0,3,0,yes,9/25/19,"Peking University;Institue for Advanced Study, Princeton;Carnegie Mellon University;Princeton University;University of California, Los Angeles",hierarchical model;reinforcement learning;low regret;online learning;tabular reinforcement learning,14;-1;1;30;-1,24;-1;27;6;17,m;m,usa,usa,y
ICLR,2020,Effects of Linguistic Labels on Learned Visual Representations in Convolutional Neural Networks: Labels matter!,Seoyoung Ahn;Gregory Zelinsky;Gary Lupyan,seoyoung.ahn@stonybrook.edu;gregory.zelinsky@stonybrook.edu;lupyan@wisc.edu,6;6;6,,Reject,0,6,0,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;University of Southern California",category learning;visual representation;linguistic labels;human behavior prediction,-1;-1;36,-1;-1;62,f;m,usa,usa,n
ICLR,2020,What Can Learned Intrinsic Rewards Capture?,Zeyu Zheng;Junhyuk Oh;Matteo Hessel;Zhongwen Xu;Manuel Kroiss;Hado van Hasselt;David Silver;Satinder Singh,zeyu@umich.edu;junhyuk@google.com;mtthss@google.com;zhongwen@google.com;makro@google.com;hado@google.com;davidsilver@google.com;baveja@google.com,6;6;6,,Reject,0,8,0,yes,9/25/19,University of Michigan;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;deep reinforcement learning;intrinsic movitation,7;-1;-1;-1;-1;-1;-1;-1,21;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,QXplore: Q-Learning Exploration by Maximizing Temporal Difference Error,Riley Simmons-Edler;Ben Eisner;Daniel Yang;Anthony Bisulco;Eric Mitchell;Sebastian Seung;Daniel Lee,rileys@cs.princeton.edu;ben.a.eisner@gmail.com;daniel.yang17@gmail.com;arb426@cornell.edu;eric.anthony.mitchell95@gmail.com;sseung@princeton.edu;daniel.d.lee@samsung.com,3;3;3,,Reject,0,5,0,yes,9/25/19,Princeton University;Samsung;;Cornell University;;Princeton University;Samsung,Deep Reinforcement Learning;Exploration,30;-1;-1;7;-1;30;-1,6;-1;-1;19;-1;6;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Clustering Processes,Ari Pakman;Yueqi Wang;Catalin Mitelut;JinHyung Lee;Liam Paninski,aripakman@gmail.com;yueqi.wang.pku@gmail.com;mitelutco@gmail.com;jl4303@columbia.edu;liam@stat.columbia.edu,3;6;6,,Reject,0,3,0,yes,9/25/19,Columbia University;Google;;Columbia University;Columbia University,amortized inference;probabilistic clustering;mixture models;exchangeability;spike sorting,24;-1;-1;24;24,16;-1;-1;16;16,m;m,usa,usa,n
ICLR,2020,Pre-training as Batch Meta Reinforcement Learning with tiMe ,Quan Vuong;Shuang Liu;Minghua Liu;Kamil Ciosek;Hao Su;Henrik Iskov Christensen,quan.hovuong@gmail.com;s3liu@eng.ucsd.edu;minghua@ucsd.edu;kamil.ciosek@microsoft.com;haosu@eng.ucsd.edu;hichristensen@ucsd.edu,3;1;3,,Reject,0,10,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego;Microsoft;University of California, San Diego;University of California, San Diego",Reinforcement Learning;Deep Reinforcement Learning;Meta Reinforcement Learning;Batch Reinforcement Learning;Transfer Learning,-1;-1;-1;-1;-1;-1,-1;31;31;-1;31;31,-1;-1,usa,usa,n
ICLR,2020,Neural Architecture Search in Embedding Space,chun-ting liu,jimliu741523@gmail.com,1;3;3,,Reject,0,3,0,yes,9/25/19,0,neural architecture search;nas;automl,,,m;m,NAN,NAN,n
ICLR,2020,Multi-Task Learning via Scale Aware Feature Pyramid Networks and Effective Joint Head,Feng Ni,nifeng@pku.edu.cn,3;3,,Reject,0,1,0,yes,9/25/19,Peking University,Multi-Task Learning;Object Detection;Instance Segmentation,14,24,m,asia,cn,n
ICLR,2020,BANANAS: Bayesian Optimization with Neural Networks for Neural Architecture Search,Colin White;Willie Neiswanger;Yash Savani,crwhite@cs.cmu.edu;willie@cs.cmu.edu;yash@realityengines.ai,3;3;3,,Reject,2,9,3,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,neural architecture search;Bayesian optimization,1;1;1,27;27;27,m;m,usa,usa,n
ICLR,2020,Isolating Latent Structure with Cross-population Variational Autoencoders,Joe Davison;Kristen A. Severson;Soumya Ghosh,jddavison@g.harvard.edu;kristen.severson@ibm.com;ghoshso@us.ibm.com,6;3;3,,Reject,0,0,0,yes,9/25/19,Harvard University;International Business Machines;International Business Machines,variational autoencoder;latent variable model;probabilistic graphical model;machine learning;deep learning;continual learning,52;-1;-1,7;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Stabilizing Off-Policy Reinforcement Learning with Conservative Policy Gradients,Chen Tessler;Nadav Merlis;Shie Mannor,chen.tessler@gmail.com;merlis.nadav@gmail.com;shiemannor@gmail.com,3;3;1,,Reject,0,3,0,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion",Deep Reinforcement Learning;Variance Reduction;Policy Gradient,27;27;27,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,When Covariate-shifted Data Augmentation Increases Test Error And How to Fix It,Sang Michael Xie*;Aditi Raghunathan*;Fanny Yang;John C. Duchi;Percy Liang,xie@cs.stanford.edu;aditir@stanford.edu;fannyang@stanford.edu;jduchi@stanford.edu;pliang@cs.stanford.edu,3;6;3,,Reject,0,5,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,data augmentation;adversarial training;interpolation;overparameterized,5;5;5;5;5,4;4;4;4;4,m;m,usa,usa,y
ICLR,2020,Learning robust visual representations using data augmentation invariance,Alex Hernandez-Garcia;Peter K√∂nig;Tim C. Kietzmann,alexhg15@gmail.com;pkoenig@uos.de;t.kietzmann@donders.ru.nl,3;6;3,,Reject,0,3,0,yes,9/25/19,University of Montreal;University of Osnabr‚àö¬∫ck;Radboud University Nijmegen,deep neural networks;visual cortex;invariance;data augmentation,-1;316;248,-1;-1;128,m;m,NAN,NAN,n
ICLR,2020,Learning to Generate Grounded Visual Captions without Localization Supervision,Chih-Yao Ma;Yannis Kalantidis;Ghassan AlRegib;Peter Vajda;Marcus Rohrbach;Zsolt Kira,cyma@gatech.edu;ykalant@image.ntua.gr;vajdap@fb.com;alregib@gatech.edu;maroffm@gmail.com;zkira@gatech.edu,3;6;6,,Reject,0,8,0,yes,9/25/19,Georgia Institute of Technology;National Technical University of Athens;Facebook;Georgia Institute of Technology;Facebook;Georgia Institute of Technology,image captioning;video captioning;self-supervised learning;visual grounding,13;316;-1;13;-1;13,38;776;-1;38;-1;38,m;m,usa,usa,n
ICLR,2020,On Empirical Comparisons of Optimizers for Deep Learning,Dami Choi;Christopher J. Shallue;Zachary Nado;Jaehoon Lee;Chris J. Maddison;George E. Dahl,choidami@cs.toronto.edu;shallue@google.com;znado@google.com;jaehlee@google.com;cmaddis@google.com;gdahl@google.com,1;6;6,,Reject,4,19,0,yes,9/25/19,University of Toronto;Google;Google;Google;Google;Google,Deep learning;optimization;adaptive gradient methods;Adam;hyperparameter tuning,18;-1;-1;-1;-1;-1,18;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,LEARNING DIFFICULT PERCEPTUAL TASKS WITH HODGKIN-HUXLEY NETWORKS,Alan Lockett;Ankit Patel;Paul Pfaffinger,alan.lockett@gmail.com;ankitp@bcm.edu;paulp@bcm.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,IDSIA;Baylor College of Medicine;Baylor College of Medicine,conductance-weighted averaging;neural modeling;normalization methods,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Adversarial Robustness Against the Union of Multiple Perturbation Models,Pratyush Maini;Eric Wong;Zico Kolter,pratyush.maini@gmail.com;ericwong@cs.cmu.edu;zkolter@cs.cmu.edu,3;6;1,,Reject,2,9,0,yes,9/25/19,Indian Institute of Technology Delhi;Carnegie Mellon University;Carnegie Mellon University,adversarial;robustness;multiple perturbation;MNIST;CIFAR10,-1;1;1,-1;27;27,m;m,usa,usa,n
ICLR,2020,LightPAFF: A Two-Stage Distillation Framework for Pre-training and Fine-tuning,Kaitao Song;Hao Sun;Xu Tan;Tao Qin;Jianfeng Lu;Hongzhi Liu;Tie-Yan Liu,kt.song@njust.edu.cn;sigmeta@pku.edu.cn;xuta@microsoft.com;taoqin@microsoft.com;lujf@njust.edu.cn;liuhz@pku.edu.cn;tyliu@microsoft.com,3;6;6,,Reject,0,4,0,yes,9/25/19,Nanjing University of Science and Technology;Peking University;Microsoft;Microsoft;Nanjing University of Science and Technology;Peking University;Microsoft,Knowledge Distillation;Pre-training;Fine-tuning;BERT;GPT-2;MASS,52;14;-1;-1;52;14;-1,144;24;-1;-1;144;24;-1,m;m,NAN,NAN,n
ICLR,2020,LocalGAN: Modeling Local Distributions for Adversarial Response Generation,Zhen Xu;Baoxun Wang;Huan Zhang;Kexin Qiu;Deyuan Zhang;Chengjie Sun,xuzhenhit@gmail.com;baoxun.wang@gmail.com;zhanghuan123@pku.edu.cn;kq2131@columbia.edu;dyzhang@sau.edu.cn;cjsun@insun.hit.edu.cn,3;3;1,,Reject,0,8,0,yes,9/25/19,Harbin Institute of Technology;Tencent AI Lab;Peking University;Columbia University;Shenyang Aerospace University;Harbin Institute of Technology,neural response generation;adversarial learning;local distribution;energy-based distribution modeling,-1;-1;14;24;-1;168,-1;-1;24;16;-1;424,m;m,asia,cn,y
ICLR,2020,Partial Simulation for Imitation Learning,Nir Baram;Shie Mannor,nirb@campus.technion.ac.il;shie@ee.technion.ac.il,3;6;1,,Reject,0,3,0,yes,9/25/19,"Technion, Technion;Technion, Technion",Reinforcement Learning;Imitation Learning;Behavior Cloning;Partial Simulation,27;27,-1;-1,m;m,NAN,NAN,y
ICLR,2020,Progressive Upsampling Audio Synthesis via Effective Adversarial Training,Youngwoo Cho;Minwook Chang;Gerard Jounghyun Kim;Jaegul Choo,cyw314@gmail.com;fromme0528@gmail.com;gjkim@korea.ac.kr;jchoo@korea.ac.kr,1;6;3,,Reject,0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;;Korea University;Korea University,audio synthesis;sound effect generation;generative adversarial network;progressive training;raw-waveform,-1;-1;168;168,110;-1;179;179,m;m,asia,kr,n
ICLR,2020,A Quality-Diversity Controllable GAN for Text Generation,Xingyu Lou;Kaihe Xu;Zhongliang Li;Tian Xia;Shaojun Wang;Jing Xiao,louxingyu83064256@163.com;xukaihenupt@gmail.com;zlli0520@gmail.com;summerrainet2008@gmail.com;swang.usa@gmail.com;jing.xiaoj@gmail.com,1;1;3,,Reject,0,3,0,yes,9/25/19,Pingan P&C insurance;;;;Pingan P&C insurance;Pingan P&C insurance,text generation;GAN;quality-diversity;generalized Jensen-Shannon divergence,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,asia,in,n
ICLR,2020,Unsupervised-Learning of time-varying features,Henrik H√∏eg;Matthias Brix;Oswin Krause,lvt956@alumni.ku.dk;brixmatthias@gmail.com;oswin.krause@di.ku.dk,1;1;3,,Reject,0,4,0,yes,9/25/19,University of Copenhagen;;University of Copenhagen,Representation Learning;Variational Autoencoder;Unsupervised Learning;Deep-Learning;Registration,92;-1;92,101;-1;101,m;m,europe,dk,n
ICLR,2020,Improving Visual Relation Detection using Depth Maps,Sahand Sharifzadeh;Sina Moayed Baharlou;Max Berrendorf;Rajat Koner;Volker Tresp,sharifzadeh@dbs.ifi.lmu.de;sina.baharlou@gmail.com;berrendorf@dbs.ifi.lmu.de;koner@dbs.ifi.lmu.de;volker.tresp@siemens.com,6;3;3,,Reject,0,8,1,yes,9/25/19,Institut f√ºr Informatik;;Institut f√ºr Informatik;Institut f√ºr Informatik;Siemens Corporate Research,Visual Relation Detection;Scene Graph Generation,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,DeepAGREL: Biologically plausible deep learning via direct reinforcement,Isabella Pozzi;Sander M. Bohte;Pieter R. Roelfsema,pozzi@cwi.nl;s.m.bohte@cwi.nl;p.roelfsema@nin.knaw.nl,6;6;1,,Reject,1,4,0,yes,9/25/19,Centrum voor Wiskunde en Informatica;Centrum voor Wiskunde en Informatica; Netherlands Institute for Neuroscience,biologically plausible deep learning;reinforcement learning;feedback gating;image claassification,-1;-1;-1,-1;-1;-1,f;m,asia,in,n
ICLR,2020,Learn Interpretable Word Embeddings Efficiently with von Mises-Fisher Distribution,Minghong Yao;Liansheng Zhuang;Houqiang Li;Jian Yang;Shafei Wang,mhyao1@mail.ustc.edu.cn;lszhuang@ustc.edu.cn;lihq@ustc.edu.cn;nanwuyaoshi@163.com;rockingsandstorm@163.com,8;1;1,,Reject,0,0,0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China;163;163,word embedding;natural language processing,-1;-1;-1;-1;-1,80;80;80;-1;-1,m;f,asia,in,n
ICLR,2020,Mirror Descent View For Neural Network Quantization,Thalaiyasingam Ajanthan;Kartik Gupta;Philip H. S. Torr;Richard Hartley;Puneet K. Dokania,thalaiyasingam.ajanthan@anu.edu.au;kartik.gupta@anu.edu.au;phst@robots.ox.ac.uk;richard.hartley@anu.edu.au;puneet@robots.ox.ac.uk,3;6;3;8,,Reject,0,4,0,yes,9/25/19,Australian National University;Australian National University;University of Oxford;Australian National University;University of Oxford,mirror descent;network quantization;numerical stability,102;102;46;102;46,50;50;1;50;1,m;m,europe,uk,y
ICLR,2020,Topological Autoencoders,Michael Moor;Max Horn;Bastian Rieck;Karsten Borgwardt,michael.moor@bsse.ethz.ch;max.horn@bsse.ethz.ch;bastian.rieck@bsse.ethz.ch;karsten.borgwardt@bsse.ethz.ch,6;8;3,,Reject,0,4,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Topology;Deep Learning;Autoencoders;Persistent Homology;Representation Learning;Dimensionality Reduction;Topological Machine Learning;Topological Data Analysis,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Utilizing Edge Features in Graph Neural Networks via Variational Information Maximization,Pengfei Chen;Weiwen Liu;Chang-Yu Hsieh;Guangyong Chen;Pheng Ann Heng,chenpf.cuhk@gmail.com;wwliu@cse.cuhk.edu.hk;kimhsieh@tencent.com;gycchen@tencent.com;pheng@cse.cuhk.edu.hk,3;6;8;3,,Reject,0,4,0,yes,9/25/19,"The Chinese University of Hong Kong;Department of Computer Science and Engineering, The Chinese University of Hong Kong;Tencent AI Lab;Tencent AI Lab;Department of Computer Science and Engineering, The Chinese University of Hong Kong",Graph Neural Network;Edge Feature;Mutual Information,316;46;-1;-1;46,35;35;-1;-1;35,m;m,NAN,NAN,y
ICLR,2020,Redundancy-Free Computation Graphs for Graph Neural Networks,Zhihao Jia;Sina Lin;Rex Ying;Jiaxuan You;Jure Leskovec;Alex Aiken.,zhihao@cs.stanford.edu;silin@microsoft.com;rexying@stanford.edu;jiaxuan@stanford.edu;jure@cs.stanford.edu;aiken@cs.stanford.edu,3;6;6,,Reject,1,5,0,yes,9/25/19,Stanford University;Microsoft;Stanford University;Stanford University;Stanford University;Stanford University,Graph Neural Networks;Runtime Performance,5;-1;5;5;5;5,4;-1;4;4;4;4,m;m,usa,usa,y
ICLR,2020,Long History Short-Term Memory for Long-Term Video Prediction,Wonmin Byeon;Jan Kautz,wonmin.byeon@gmail.com;jkautz@nvidia.com,3;3;3,,Reject,0,17,0,yes,9/25/19,NVIDIA;NVIDIA,LSTM;video;long-term prediction,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,How the Softmax Activation Hinders the Detection of Adversarial and Out-of-Distribution Examples in Neural Networks,Jonathan Aigrain;Marcin Detyniecki,jonathan.aigrain@axa.com;marcin.detyniecki@axa.com,1;1;3,,Reject,0,3,0,yes,9/25/19,AXA;AXA,Adversarial examples;out-of-distribution;detection;softmax;logits,-1;-1,-1;-1,m;m,europe,gr,n
ICLR,2020,Solving Packing Problems by Conditional Query Learning,Dongda Li;Changwei Ren;Zhaoquan Gu;Yuexuan Wang;Francis Lau,lidongda@gzhu.edu.cn;rcw@zju.edu.cn;zqgu@gzhu.edu.cn;amywang@zju.edu.cn;fcmlau@cs.hku.hk,1;3;6,,Reject,0,3,0,yes,9/25/19,"Guangzhou University, China, Tsinghua University;Zhejiang University;Guangzhou University, China, Tsinghua University;Zhejiang University;The University of Hong Kong",Neural Combinatorial Optimization;Reinforcement Learning;Packing Problem,4;39;4;39;92,23;107;23;107;35,m;m,NAN,NAN,n
ICLR,2020,Context Based Machine Translation With Recurrent Neural Network For English-Amharic Translation ,Yeabsira Asefa Ashengo;Rosa Tsegaye Aga;Surafel Lemma Abebe,yeabsira.asefa@aait.edu.et;rosatsegaye@gmail.com;surafel.lemma@aait.edu.et,1;1;1,,Reject,0,4,0,yes,9/25/19,Addis Ababa Institute of Technology;;Addis Ababa Institute of Technology,Context based machine translation;machine translation;Neural network machine translation;English to Amharic machine translation,-1;-1;-1,-1;-1;-1,-1;-1,NAN,NAN,n
ICLR,2020,"Long-term planning, short-term adjustments",Hamed Khorasgani;Chi Zhang;Chetan Gupta;Susumu Serita,hamed.khorasgani@hal.hitachi.com;chi.zhang@hal.hitachi.com;chetan.gupta@hal.hitachi.com;susumu.serita@hal.hitachi.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;Hitachi Ltd. R&D group;Hitachi Ltd. R&D group,Deep Reinforcement Learning;Control,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Boosting Network: Learn by Growing Filters and Layers via SplitLBI,Zuyuan Zhong;Chen Liu;Yanwei Fu;Yuan Yao,zyzhong19@fudan.edu.cn;corwinliu9669@gmail.com;yanweifu@fudan.edu.cn;yuany@ust.hk,3;6;3,,Reject,0,4,0,yes,9/25/19,Fudan University;;Fudan University;The Hong Kong University of Science and Technology,,73;-1;73;-1,109;-1;109;47,m;f,NAN,NAN,n
ICLR,2020,MULTI-STAGE INFLUENCE FUNCTION,Hongge Chen;Si Si;Yang Li;Ciprian Chelba;Sanjiv Kumar;Duane Boning;Cho-Jui Hsieh,chenhg@mit.edu;sisidaisy@google.com;liyang@google.com;ciprianchelba@google.com;sanjivk@google.com;boning@mtl.mit.edu;chohsieh@cs.ucla.edu,6;3;6,,Reject,0,4,0,yes,9/25/19,"Massachusetts Institute of Technology;Google;Google;Google;Google;Massachusetts Institute of Technology;University of California, Los Angeles",influence function;multistage training;pretrained model,5;-1;-1;-1;-1;5;-1,5;-1;-1;-1;-1;5;17,m;m,usa,usa,y
ICLR,2020,$\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach,Jiaye Teng;Guang-He Lee;Yang Yuan,2016110299@live.sufe.edu.cn;guanghe@csail.mit.edu;yuanyang@tsinghua.edu.cn,6;3;3,,Reject,2,4,0,yes,9/25/19,"University of Science and Technology of China;Massachusetts Institute of Technology;Tsinghua University, Tsinghua University",,-1;5;4,80;5;23,m;m,NAN,NAN,y
ICLR,2020,Scaling Up Neural Architecture Search with Big Single-Stage Models,Jiahui Yu;Pengchong Jin;Hanxiao Liu;Gabriel Bender;Pieter-Jan Kindermans;Mingxing Tan;Thomas Huang;Xiaodan Song;Quoc Le,jyu79@illinois.edu;pengchong@google.com;hanxiaol@google.com;gbender@google.com;pikinder@google.com;tanmingxing@google.com;t-huang1@illinois.edu;xiaodansong@google.com;qvl@google.com,3;3;6,,Reject,0,3,0,yes,9/25/19,"University of Illinois, Urbana Champaign;Google;Google;Google;Google;Google;University of Illinois, Urbana Champaign;Google;Google",Single-Stage Neural Architecture Search,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,CONTRIBUTION OF INTERNAL REFLECTION IN LANGUAGE EMERGENCE WITH AN UNDER-RESTRICTED SITUATION,Kense Todo;Masayuki Yamamura,k_todo@ali.c.titech.ac.jp;my@c.titech.ac.jp,3;3,,Reject,0,3,0,yes,9/25/19,Tokyo Institute of Technology;Tokyo Institute of Technology,Language emergence;Conceptual grounding;Reflection;Cognitive bias,168;168,299;299,m;m,asia,jp,n
ICLR,2020,MIM: Mutual Information Machine,Micha Livne;Kevin Swersky;David J. Fleet,mlivne@cs.toronto.edu;kswersky@google.com;leet@cs.toronto.edu,1;1;6,,Reject,2,5,0,yes,9/25/19,University of Toronto;Google;University of Toronto,Mutual Information;Representation Learning;Generative Models;Probability Density Estimator,18;-1;18,18;-1;18,m;m,canada,ca,n
ICLR,2020,Variable Complexity in the Univariate and Multivariate Structural Causal Model,Tomer Galanti;Ofir Nabati;Lior Wolf,tomerga2@post.tau.ac.il;ofirnabati@mail.tau.ac.il;wolf@fb.com,6;6;3,,Reject,0,5,0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Facebook,,30;30;-1,188;188;-1,m;m,NAN,NAN,n
ICLR,2020,Copy That! Editing Sequences by Copying Spans,Sheena Panthaplackel;Miltiadis Allamanis;Marc Brockschmidt,spantha@cs.utexas.edu;miallama@microsoft.com;mabrocks@microsoft.com,6;3;6,,Reject,0,6,0,yes,9/25/19,"University of Texas, Austin;Microsoft;Microsoft",span copying;sequence generation;editing;code repair,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,OmniNet: A unified architecture for multi-modal multi-task learning,Subhojeet Pramanik;Priyanka Agrawal;Aman Hussain,subhojeetpramanik@gmail.com;pagrawal.ml@gmail.com;email@amanhussain.com,6;1;3,,Reject,0,6,0,yes,9/25/19,International Business Machines;;University of Amsterdam,multimodal;multi-task;transformer;spatio-temporal;attention-networks;neural-network,-1;-1;143,-1;-1;62,m;m,europe,nl,n
ICLR,2020,QGAN: Quantize Generative Adversarial Networks to Extreme low-bits,Peiqi Wang;Yu Ji;Xinfeng Xie;Yongqiang Lyu;Dongsheng Wang;Yuan Xie,wpq14@tsinghua.org.cn;jiy15@mails.tsinghua.edu.cn;xinfeng@ucsb.edu;luyq@tsinghua.edu.cn;wds@mail.tsinghua.edu.cn;yuanxie@ucsb.edu,3;6;3,,Reject,0,3,0,yes,9/25/19,"SenseTime Group Limited;Tsinghua University, Tsinghua University;UC Santa Barbara;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;UC Santa Barbara",generative adversarial networks;quantization;extreme low bits,-1;4;-1;4;4;-1,-1;23;-1;23;23;-1,f;m,NAN,NAN,n
ICLR,2020,Imagine That! Leveraging Emergent Affordances for Tool Synthesis in Reaching Tasks,Yizhe Wu;Sudhanshu Kasewa;Oliver Groth;Sasha Salter;Li Sun;Oiwi Parker Jones;Ingmar Posner,ywu@robots.ox.ac.uk;su@robots.ox.ac.uk;ogroth@robots.ox.ac.uk;sasha@robots.ox.ac.uk;kevin@robots.ox.ac.uk;oiwi.parkerjones@jesus.ox.ac.uk;ingmar@robots.ox.ac.uk,3;1;3,,Reject,0,8,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,Affordance Learning;Imagination;Generative Models;Activation Maximisation,46;46;46;46;46;46;46,1;1;1;1;1;1;1,m;m,europe,uk,n
ICLR,2020,Enhancing Attention with Explicit Phrasal Alignments,Xuan-Phi Nguyen;Shafiq Joty;Thanh-Tung Nguyen,nxphi47@gmail.com;sjoty@salesforce.com;ng0155ng@e.ntu.edu.sg,6;3;8,,Reject,0,0,0,yes,9/25/19,Nanyang Technological University;SalesForce.com;Nanyang Technological University,NMT;Phrasal Attention;Machine Translation;Language Modeling,-1;-1;43,-1;-1;49,m;m,asia,sg,n
ICLR,2020,A GOODNESS OF FIT MEASURE FOR GENERATIVE NETWORKS,Lorenzo Luzi;Randall Balestriero;Richard Baraniuk,lorenzo.luzi.28@gmail.com;randallbalestriero@gmail.com;richb@rice.edu,3;1;3,,Reject,0,4,0,yes,9/25/19,Rice University;Rice University;Rice University,generative adversarial networks;goodness of fit;inception score;empirical approximation error;validation metric;frechet inception score,-1;92;92,-1;105;105,m;m,australasia,au,n
ICLR,2020,Learning Neural Causal Models from Unknown Interventions,Nan Rosemary Ke;Olexa Bilaniuk;Anirudh Goyal;Stephan Bauer;Hugol Larochelle;Chris Pal;Yoshua Bengio,rosemary.nan.ke@gmail.com;obilaniu@gmail.com;anirudhgoyal9119@gmail.com;stefan.a.bauer@gmail.com;hugolarochelle@google.com;chris.j.pal@gmail.com;yoshua.bengio@mila.quebec,6;8;3,,Reject,0,13,0,yes,9/25/19,University of Montreal;;;;Google;Polytechnique Montreal;Mila,deep learning;graphical models;meta learning,-1;-1;-1;-1;-1;316;143,-1;-1;-1;-1;-1;-1;336,f;m,NAN,NAN,n
ICLR,2020,SLM Lab: A Comprehensive Benchmark and Modular Software Framework for Reproducible Deep Reinforcement Learning,Wah Loon Keng;Laura Graesser;Milan Cvitkovic,kengzwl@gmail.com;lhgraesser@gmail.com;mcvitkov@caltech.edu,3;8;3,,Reject,0,3,0,yes,9/25/19,AppLovin;Google;California Institute of Technology,reinforcement learning;machine learning;benchmark;reproducibility;software;framework;implementation issues;parallelization;software platforms,-1;-1;143,-1;-1;2,m;m,usa,usa,n
ICLR,2020,ADA+: A GENERIC FRAMEWORK WITH MORE ADAPTIVE EXPLICIT ADJUSTMENT FOR LEARNING RATE,Yue Zhao;Xiangsheng Huang;Ludan Kou,oasis.random.time@gmail.com;xiangsheng.huang@ia.ac.cn;2015019051@mail.buct.edu.cn,3;3;1,,Reject,0,0,0,yes,9/25/19,"Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;University of Science and Technology of China",Optimization;Adaptive Methods;Convergence;Convolutional Neural Network,-1;30;-1,-1;-1;80,m;m,NAN,NAN,y
ICLR,2020,A‚ãÜMCTS: SEARCH WITH THEORETICAL GUARANTEE USING POLICY AND VALUE FUNCTIONS,Xian Wu;Yuandong Tian;Lexing Ying,xwu20@stanford.edu;yuandong@fb.com;lexing@stanford.edu,1;3;6,,Reject,0,4,0,yes,9/25/19,Stanford University;Facebook;Stanford University,tree search;reinforcement learning;value neural network;policy neural network,5;-1;5,4;-1;4,m;m,usa,usa,y
ICLR,2020,Faster Neural Network Training with Data Echoing,Dami Choi;Alexandre Passos;Christopher J. Shallue;George E. Dahl,choidami@cs.toronto.edu;apassos@google.com;shallue@google.com;gdahl@google.com,6;3;3,,Reject,0,3,0,yes,9/25/19,University of Toronto;Google;Google;Google,systems;faster training;large scale,18;-1;-1;-1,18;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Sparse Weight Activation Training,Md Aamir Raihan;Tor M. Aamodt,araihan@ece.ubc.ca;aamodt@ece.ubc.ca,3;6;3,,Reject,0,9,0,yes,9/25/19,University of British Columbia;University of British Columbia,Sparsity;Training;Acceleration;Pruning;Compression,64;64,34;34,m;m,canada,ca,n
ICLR,2020,BOOSTING ENCODER-DECODER CNN FOR INVERSE PROBLEMS,Eunju Cha;Jaeduck Jang;Junho Lee;Eunha Lee;Jong Chul Ye,eunju.cha@kaist.ac.kr;jduck.jang@samsung.com;jh0325.lee@samsung.com;eunhayo.lee@samsung.com;jong.ye@kaist.ac.kr,6;1;3,,Reject,0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Samsung;Samsung;Samsung;Korea Advanced Institute of Science and Technology,Prediction error;Boosting;Encoder-decoder convolutional neural network;Inverse problem,-1;-1;-1;-1;-1,110;-1;-1;-1;110,f;m,NAN,NAN,y
ICLR,2020,Unsupervised Spatiotemporal Data Inpainting,Yuan Yin;Arthur Pajot;Emmanuel de B√©zenac;Patrick Gallinari,yuan.yin@lip6.fr;arthur.pajot@lip6.fr;emmanuel.de-bezenac@lip6.fr;patrick.gallinari@lip6.fr,3;3;6,,Reject,0,5,0,yes,9/25/19,LIP6;LIP6;LIP6;LIP6,Deep Learning;Adversarial;MAP;GAN;neural networks;video,445;445;445;445,-1;-1;-1;-1,m;m,asia,ir,n
ICLR,2020,Deep geometric matrix completion:  Are we doing it right?,Amit Boyarski;Sanketh Vedula;Alex Bronstein,amitboy@cs.technion.ac.il;sanketh@cs.technion.ac.il;bron@cs.technion.ac.il,3;6;3,,Reject,1,6,0,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion",Geometric Matrix Completion;Spectral Graph Theory;Functional Maps;Deep Linear Networks,27;27;27,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Predictive Coding for Boosting Deep Reinforcement Learning with Sparse Rewards,Xingyu Lu;Pieter Abbeel;Stas Tiomkin,xingyulu0701@berkeley.edu;pabbeel@cs.berkeley.edu;stas@berkeley.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;representation learning;reward shaping;predictive coding,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Improved Structural Discovery and Representation Learning of Multi-Agent Data,Jennifer Hobbs;Matthew Holbrook;Nathan Frank;Long Sha;Patrick Lucey,jennifer.hobbs@statsperform.com;matthewholbrook@statsperform.com;nathan.frank@statsperform.com;long.sha@statsperform.com;patrick.lucey@statsperform.com,1;6;3,,Reject,0,7,0,yes,9/25/19,Stats Perform;Stats Perform;Stats Perform;Stats Perform;Stats Perform,multi-agent;gaussian mixture;permutation learning;representation learning;group structure,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Laplacian Denoising Autoencoder,Jianbo Jiao;Linchao Bao;Yunchao Wei;Shengfeng He;Honghui Shi;Rynson Lau;Thomas Huang,jiaojianbo.i@gmail.com;linchaobao@gmail.com;wychao1987@gmail.com;shengfenghe7@gmail.com;shihonghui3@gmail.com;rynson.lau@cityu.edu.hk;t-huang1@illinois.edu,6;6;3,,Reject,0,4,0,yes,9/25/19,"University of Oxford;Tencent AI Lab;University of Technology Sydney;South China University of Technology;University of Oregon;The Hong Kong Polytechnic University;University of Illinois, Urbana Champaign",unsupervised;representation learning;Laplacian,46;-1;73;-1;194;118;-1,1;-1;193;501;288;171;-1,m;m,usa,usa,n
ICLR,2020,A Boolean Task Algebra for Reinforcement Learning,Geraud Nangue Tasse;Steven James;Benjamin Rosman,nanguetasse2000s@gmail.com;steven.james@wits.ac.za;brosman@csir.co.za,8;3;3,,Reject,0,10,0,yes,9/25/19,University of the Witwatersrand;University of the Witwatersrand;CSIR,Reinforcement Learning;Transfer;Composition;Lifelong;Multi-task;Deep Reinforcement learning,-1;-1;194,-1;193;-1,m;m,asia,in,y
ICLR,2020,"On Iterative Neural Network Pruning, Reinitialization, and the Similarity of Masks",Michela Paganini;Jessica Forde,michela@fb.com;jzf2101@columbia.edu,1;3;3,,Reject,0,4,0,yes,9/25/19,Facebook;Columbia University,Pruning;Lottery Tickets;Science of Deep Learning;Experimental Deep Learning;Empirical Study,-1;24,-1;16,f;f,usa,usa,n
ICLR,2020,Semantics Preserving Adversarial Attacks,Ousmane Amadou Dia;Elnaz Barshan;Reza Babanezhad,ousmane@elementai.com;elnaz.barshan@elementai.com;babanezhad@gmail.com,1;6;6,,Reject,0,15,0,yes,9/25/19,Element AI;Element AI;Samsung,black-box adversarial attacks;stein variational inference;adversarial images and tex,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unified recurrent network for many feature types,Alexander Stec;Diego Klabjan;Jean Utke,stec@u.northwestern.edu;d-klabjan@northwestern.edu;jutke@allstate.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Northwestern University;Northwestern University;Allstate,sparse;recurrent;asynchronous;time;series,46;46;-1,22;22;-1,m;m,NAN,NAN,n
ICLR,2020,How noise affects the Hessian spectrum in overparameterized neural networks,Mingwei Wei;David Schwab,m.wei@u.northwestern.edu;dschwab@gc.cuny.edu,6;3;6,,Reject,0,6,0,yes,9/25/19,Northwestern University;The City University of New York,noise;optimization;loss landscape;Hessian,46;-1,22;-1,m;m,NAN,NAN,y
ICLR,2020,Symmetric-APL Activations: Training Insights and Robustness to Adversarial Attacks,Mohammadamin Tavakoli;Forest Agostinelli;Pierre Baldi,mohamadt@uci.edu;fagostin@uci.edu;pfbaldi@ics.uci.edu,6;1;3,,Reject,0,4,0,yes,9/25/19,"University of California, Irvine;University of California, Irvine;University of California, Irvine",Activation function;Adaptive;Training;Robustness;Adversarial attack,-1;-1;-1,96;96;96,m;m,usa,usa,y
ICLR,2020,Temporal Probabilistic Asymmetric Multi-task Learning,Nguyen Anh Tuan;Hyewon Jeong;Eunho Yang;Sungju Hwang,nanhtuan@kaist.ac.kr;jhw162@kaist.ac.kr;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,6;6;3,,Reject,0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Multi-task learning;Time-series analysis;Variational Inference,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,Learning Deep-Latent Hierarchies by Stacking Wasserstein Autoencoders,Benoit Gaujac;Ilya Feige;David Barber,benoit.gaujac.16@ucl.ac.uk;ilya@faculty.ai;david.barber@ucl.ac.uk,1;3;6,,Reject,0,3,0,yes,9/25/19,University College London;Faculty;University College London,Generative modelling;Optimal Transport,52;-1;52,-1;-1;-1,m;m,europe,uk,n
ICLR,2020,Feature Selection using Stochastic Gates,Yutaro Yamada;Ofir Lindenbaum;Sahand Negahban;Yuval Kluger,yutaro.yamada@yale.edu;ofirlin@gmail.com;sahand.negahban@yale.edu;yuval.kluger@yale.edu,6;3;3,,Reject,1,3,0,yes,9/25/19,Yale University;Yale University;Yale University;Yale University,Feature selection;classification;regression;survival analysis,73;73;73;73,8;8;8;8,m;m,europe,fi,y
ICLR,2020,Stablizing Adversarial Invariance Induction by Discriminator Matching,Yusuke Iwasawa;Kei Akuzawa;Yutaka Matsuo,iwasawa@weblab.t.u-tokyo.ac.jp;akuzawa-kei@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,3;1;3,,Reject,0,4,0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo,invariance induction;adversarial training;domain generalization,64;64;64,36;36;36,m;m,NAN,NAN,y
ICLR,2020,Revisiting Gradient Episodic Memory for Continual Learning,Zhiyi Chen;Tong Lin*,chenzhiy16@mails.tsinghua.edu.cn;lintong@pku.edu.cn,1;3;1,,Reject,0,0,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Peking University",,4;14,23;24,m;f,asia,cn,n
ICLR,2020,"Unifying Question Answering, Text Classification, and Regression via Span Extraction",Nitish Shirish Keskar;Bryan McCann;Caiming Xiong;Richard Socher,nkeskar@salesforce.com;bmccann@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,3;3;3,,Reject,0,3,0,yes,9/25/19,SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,NLP;span-extraction;BERT,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Reinforcement Learning with Probabilistically Complete Exploration,Philippe Morere;Tom Blau;Gilad Francis;Fabio Ramos,philippe.morere@sydney.edu.au;tom.blau@sydney.edu.au;gilad.francis@sydney.edu.au;fabio.ramos@sydney.edu.au,3;6;3,,Reject,0,4,0,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney;University of Sydney,Reinforcement Learning;Exploration;sparse rewards;learning from demonstration,64;64;64;64,60;60;60;60,m;m,europe,uk,y
ICLR,2020,Global Momentum Compression for Sparse Communication in Distributed SGD,Shen-Yi Zhao;Yin-Peng Xie;Hao Gao;Wu-Jun Li,zhaosy@lamda.nju.edu.cn;xieyp@lamda.nju.edu.cn;gaoh@lamda.nju.edu.cn;liwujun@nju.edu.cn,3;3;3,,Reject,0,0,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University,Distributed momentum SGD;Communication compression,39;39;39;39,107;107;107;107,m;m,asia,cn,y
ICLR,2020,Quantifying uncertainty with GAN-based priors,Dhruv V. Patel;Assad A. Oberai,dhruvvpa@usc.edu;aoberai@usc.edu,3;3;3,,Reject,0,9,0,yes,9/25/19,University of Southern California;University of Southern California,Bayesian inference;Uncertainty quantification;Generative adversarial networks,36;36,62;62,m;m,usa,usa,n
ICLR,2020,Analyzing Privacy Loss in Updates of Natural Language Models,Shruti Tople;Marc Brockschmidt;Boris K√∂pf;Olga Ohrimenko;Santiago Zanella-B√©guelin,t-shtopl@microsoft.com;mabrocks@microsoft.com;boris.koepf@microsoft.com;oohrim@microsoft.com;santiago@microsoft.com,6;3;3,,Reject,0,7,0,yes,9/25/19,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Language Modelling;Privacy,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Layer Flexible Adaptive Computation Time for Recurrent Neural Networks,Lida Zhang;Diego Klabjan,lidazhang2018@u.northwestern.edu;d-klabjan@northwestern.edu,3;3;3,,Reject,0,0,0,yes,9/25/19,Northwestern University;Northwestern University,,46;46,22;22,f;m,usa,usa,n
ICLR,2020,Gumbel-Matrix Routing for Flexible Multi-task Learning,Krzysztof Maziarz;Efi Kokiopoulou;Andrea Gesmundo;Luciano Sbaiz;Gabor Bartok;Jesse Berent,krzysztof.s.maziarz@gmail.com;kokiopou@google.com;agesmundo@google.com;sbaiz@google.com;bartok@google.com;jberent@google.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Microsoft;Google;Google;Google;Google;Google,,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"OPTIMAL TRANSPORT, CYCLEGAN, AND PENALIZED LS FOR UNSUPERVISED LEARNING IN INVERSE PROBLEMS",Byeongsu Sim;Gyutaek Oh;Sungjun Lim;and Jong Chul Ye,byeongsu.s@kaist.ac.kr;okt0711@kaist.ac.kr;sungjunlim@gmail.com;jong.ye@kaist.ac.kr,6;6;1,,Reject,0,9,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;;Korea Advanced Institute of Science and Technology,Optimal transport;CycleGAN;penalized LS;unsupervised learning;and inverse problems,-1;-1;-1;-1,110;110;-1;110,m;m,NAN,NAN,y
ICLR,2020,Stabilizing DARTS with Amended Gradient Estimation on Architectural Parameters,Kaifeng Bi;Changping Hu;Lingxi Xie;Xin Chen;Longhui Wei;Qi Tian,bikaifeng@huawei.com;huchangping@huawei.com;198808xc@gmail.com;1410452@tongji.edu.cn;weilonghui1@huawei.com;tian.qi1@huawei.com,3;3;6;6,,Reject,0,12,0,yes,9/28/20,Huawei Technologies Ltd.;Huawei Technologies Ltd.;;Tongji University;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Neural Architecture Search;DARTS;Stability,-1;-1;-1;316;-1;-1,-1;-1;-1;441;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Why ADAM Beats SGD for Attention Models	",Jingzhao Zhang;Sai Praneeth Karimireddy;Andreas Veit;Seungyeon Kim;Sashank J Reddi;Sanjiv Kumar;Suvrit Sra,jzhzhang@mit.edu;sai.karimrieddy@epfl.ch;aveit@google.com;seungyeonk@google.com;sashank@google.com;sanjivk@google.com;suvrit@mit.edu,3;6;6,,Reject,1,4,0,yes,9/25/19,Massachusetts Institute of Technology;Swiss Federal Institute of Technology Lausanne;Google;Google;Google;Google;Massachusetts Institute of Technology,Optimization;ADAM;Deep learning,5;-1;-1;-1;-1;-1;5,5;-1;-1;-1;-1;-1;5,-1;-1,usa,usa,y
ICLR,2020,Multi-Sample Dropout for Accelerated Training and Better Generalization,Hiroshi Inoue,inouehrs@jp.ibm.com,1;3;1,,Reject,0,3,0,yes,9/25/19,International Business Machines,dropout;regularization;convolutional neural networks,-1,-1,m,NAN,NAN,n
ICLR,2020,Prototype Recalls for Continual Learning,Mengmi Zhang;Tao Wang;Joo Hwee Lim;Jiashi Feng,mengmi@u.nus.edu;twangnh@gmail.com;joohwee@i2r.a-star.edu.sg;elefjia@nus.edu.sg,3;1;3,,Reject,0,0,0,yes,9/25/19,"National University of Singapore;;Institute for Infocomm Research, A*STAR;National University of Singapore",continual learning;catastrophic forgetting;prototypes;image classification;few-shot continual learning,17;-1;-1;17,25;-1;-1;25,f;m,asia,sg,n
ICLR,2020,Learning Surrogate Losses,Josif Grabocka;Randolf Scholz;Lars Schmidt-Thieme,josif@ismll.uni-hildesheim.de;rscholz@ismll.uni-hildesheim.de;schmidt-thieme@ismll.uni-hildesheim.de,8;3;3,,Reject,0,10,0,yes,9/25/19,University of Hildesheim;University of Hildesheim;University of Hildesheim,Surrogate losses;Non-differentiable losses,445;445;445,-1;-1;-1,m;m,europe,de,n
ICLR,2020,Recurrent Independent Mechanisms,Anirudh Goyal;Alex Lamb;Shagun Sodhani;Jordan Hoffmann;Sergey Levine;Yoshua Bengio;Bernhard Scholkopf,anirudhgoyal9119@gmail.com;alex6200@gmail.com;sshagunsodhani@gmail.com;jhoffmann@g.harvard.edu;svlevine@eecs.berkeley.edu;yoshua.bengio@mila.quebec;bs@tuebingen.mpg.de,6;6;6,,Reject,0,13,0,yes,9/28/20,University of Montreal;;Facebook;Harvard University;University of California Berkeley;Mila;Max-Planck Institute,modular representations;better generalization;learning mechanisms,-1;-1;-1;52;-1;143;-1,-1;-1;-1;7;13;336;-1,m;m,NAN,NAN,n
ICLR,2020,Anomaly Detection Based on Unsupervised Disentangled Representation Learning in Combination with Manifold Learning,Xiaoyan Li;Iluju Kiringa;Tet Yeap;Xiaodan Zhu;Yifeng Li,xli343@uottawa.ca;iluju.kiringa@uottawa.ca;tyeap@uottawa.ca;xiaodan.zhu@queensu.ca;yifeng.li@nrc-cnrc.gc.ca,3;3;6,,Reject,0,7,0,yes,9/25/19,University of Ottawa;University of Ottawa;University of Ottawa;Queens University;National Research Council Canada,anomaly detection;disentangled representation learning;manifold learning,248;248;248;248;-1,141;141;141;258;-1,m;m,NAN,NAN,n
ICLR,2020,Stochastic Mirror Descent on Overparameterized Nonlinear Models,Navid Azizan;Sahin Lale;Babak Hassibi,azizan@caltech.edu;alale@caltech.edu;hassibi@caltech.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,California Institute of Technology;California Institute of Technology;California Institute of Technology,deep learning;optimization;overparameterized;stochastic gradient descent;mirror descent,143;143;143,2;2;2,m;m,usa,usa,y
ICLR,2020,On the implicit minimization of alternative loss functions when training deep networks,Alexandre Lemire Paquin;Brahim Chaib-draa;Philippe Gigu√®re,alexandre.lemire-paquin.1@ulaval.ca;brahim.chaib-draa@ift.ulaval.ca;philippe.giguere@ift.ulaval.ca,1;3;3,,Reject,0,0,0,yes,9/25/19,Laval university;Laval university;Laval university,implicit minimization;optimization bias;margin based loss functions;flat minima,-1;-1;-1,272;272;272,m;m,NAN,NAN,n
ICLR,2020,UWGAN: UNDERWATER GAN FOR REAL-WORLD UNDERWATER COLOR RESTORATION AND DEHAZING,Nan Wang;Yabin Zhou;Fenglei Han;Lichao Wan;Haitao Zhu;Yaojing Zheng,nanwangmail@hrbeu.edu.cn;zyb0977@163.com;fenglei_han@hrbeu.edu.cn;wanlch1203@hrbeu.edu.cn;zhuhaitao_heu@163.com;yaojingzheng_heu@163.com,3;3;3,,Reject,0,5,0,yes,9/25/19,University of Science and Technology of China;163;University of Science and Technology of China;University of Science and Technology of China;163;163,underwater image;image restoration;image enhancement;GAN;CNNs,-1;-1;-1;-1;-1;-1,80;-1;80;80;-1;-1,f;f,asia,in,n
ICLR,2020,LEARNING  TO LEARN  WITH  BETTER  CONVERGENCE,Patrick H. Chen;Sashank Reddi;Sanjiv Kumar;Cho-Jui Hsieh,patrickchen@g.ucla.edu;sashank@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,3;3;1,,Reject,0,0,0,yes,9/25/19,"University of California, Los Angeles;Google;Google;University of California, Los Angeles",,-1;-1;-1;-1,17;-1;-1;17,m;m,usa,usa,n
ICLR,2020,Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,Francesco Croce;Matthias Hein,francesco91.croce@gmail.com;matthias.hein@uni-tuebingen.de,6;6;6,,Reject,0,3,0,yes,9/25/19,University of Tuebingen;University of Tuebingen,adversarial attacks;adversarial robustness,143;143,91;91,m;m,europe,de,n
ICLR,2020,Octave Graph Convolutional Network,Heng Chang;Yu Rong;Somayeh Sojoudi;Junzhou Huang;Wenwu Zhu,changh17@mails.tsinghua.edu.cn;yu.rong@hotmail.com;sojoudi@berkeley.edu;jzhuang@uta.edu;wwzhu@tsinghua.edu.cn,6;3;3,,Reject,0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tencent AI Lab;University of California Berkeley;University of Texas, Arlington;Tsinghua University, Tsinghua University",Graph Convolutional Networks;Octave Convolution;Graph Mining,4;-1;-1;-1;4,23;-1;13;-1;23,m;m,NAN,NAN,n
ICLR,2020,"Lift-the-flap: what, where and when for context reasoning",Mengmi Zhang;Claire Tseng;Karla Montejo;Joseph Kwon;Gabriel Kreiman,mengmi.zhang@childrens.harvard.edu;ctseng@college.harvard.edu;kmont057@fiu.edu;joseph.kwon@yale.edu;gabriel.kreiman@tch.harvard.edu,3;3;6,,Reject,0,8,0,yes,9/25/19,"Harvard University;Harvard University;Indiana University, Bloomington;Yale University;Harvard University",contextual reasoning;visual recognition;human behavior;intelligent sampling,52;52;64;73;52,7;7;134;8;7,f;m,usa,usa,n
ICLR,2020,The Dynamics of Signal Propagation in Gated Recurrent Neural Networks,Dar Gilboa;Bo Chang;Minmin Chen;Greg Yang;Samuel S. Schoenholz;Ed H. Chi;Jeffrey Pennington,dg2893@columbia.edu;bchang@stat.ubc.ca;minminc@google.com;gregyang@microsoft.com;schsam@google.com;edchi@google.com;jpennin@google.com,3;8;1,,Reject,0,0,0,yes,9/25/19,Columbia University;University of British Columbia;Google;Microsoft;Google;Google;Google,recurrent neural networks;theory of deep learning,24;64;-1;-1;-1;-1;-1,16;34;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Regulatory Focus: Promotion and Prevention Inclinations in Policy Search,Lanxin Lei;Zhizhong Li;Xiaoyang Li;Cong Qiu;Dahua Lin,leilansen@gmail.com;lizz@sensetime.com;lixiaoyang@nbu.edu.cn;qiucong@sensetime.com;dhlin@ie.cuhk.edu.hk,3;3;3,,Reject,0,0,0,yes,9/25/19,University of Electronic Science and Technology of China;SenseTime Group Limited;Boston University;SenseTime Group Limited;The Chinese University of Hong Kong,Reinforcement Learning;Regulatory Focus;Promotion and Prevention;Exploration,-1;-1;79;-1;316,-1;-1;61;-1;35,f;m,NAN,NAN,n
ICLR,2020,WaveFlow: A Compact Flow-based Model for Raw Audio,Wei Ping;Kainan Peng;Kexin Zhao;Zhao Song,weiping.thu@gmail.com,8;6;3,,Reject,3,3,1,yes,9/25/19,NVIDIA,flow-based models;raw audio;waveforms;speech synthesis;generative models,-1,-1,m;m,NAN,NAN,n
ICLR,2020,Identifying Weights and Architectures of Unknown ReLU Networks,David Rolnick;Konrad P. Kording,drolnick@seas.upenn.edu;koerding@gmail.com,3;1;6;6,,Reject,1,5,0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania,deep neural network;ReLU;piecewise linear function;linear region;activation region;weights;parameters;architecture,20;20,11;11,m;m,usa,usa,n
ICLR,2020,On PAC-Bayes Bounds for Deep Neural Networks using the Loss Curvature,Konstantinos Pitas,konstantinos.pitas@epfl.ch,1;3;1,,Reject,0,13,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne,PAC-Bayes;Hessian;curvature;lower bound;Variational Inference,-1,-1,m;m,NAN,NAN,n
ICLR,2020,RoBERTa: A Robustly Optimized BERT Pretraining Approach,Yinhan Liu;Myle Ott;Naman Goyal;Jingfei Du;Mandar Joshi;Danqi Chen;Omer Levy;Mike Lewis;Luke Zettlemoyer;Veselin Stoyanov,yinhanliu@fb.com;myleott@fb.com;namangoyal@instagram.com;jingfeidu@fb.com;mandar90@cs.washington.edu;danqic@cs.princeton.edu;omerlevy@gmail.com;mikelewis@fb.com;lsz@fb.com;ves@fb.com,6;6;6,,Reject,0,4,0,yes,9/25/19,Facebook;Facebook;Instagram;Facebook;University of Washington;Princeton University;Tel Aviv University;Facebook;Facebook;Facebook,Deep learning;language representation learning;natural language understanding,-1;-1;-1;-1;11;30;30;-1;-1;-1,-1;-1;-1;-1;26;6;188;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,A Coordinate-Free Construction of Scalable Natural Gradient,Kevin Luk;Roger Grosse,kevin.kh.luk@gmail.com;rgrosse@cs.toronto.edu,3;3;3,,Reject,0,4,0,yes,9/25/19,Facebook;University of Toronto,Natural gradient;second-order optimization;K-FAC;parameterization invariance;deep learning,-1;18,-1;18,m;m,canada,ca,y
ICLR,2020,Evaluating and Calibrating Uncertainty Prediction in Regression Tasks,Dan Levi;Liran Gispan;Niv Giladi;Ethan Fetaya,danmlevi@gmail.com;liran.gispan@gm.com;giladiniv@gmail.com;ethanf@cs.toronto.edu,1;3;1,,Reject,0,0,0,yes,9/25/19,"General Motors;General Motors;Technion, Technion;University of Toronto",Uncertainty Estimation;Regression;Deep learning,-1;-1;27;18,-1;-1;-1;18,m;m,canada,ca,n
ICLR,2020,Why Does the VQA Model Answer No?: Improving Reasoning through Visual and Linguistic Inference,Seungjun Jung;Junyoung Byun;Kyujin Shim;Changick Kim,seungjun45@kaist.ac.kr;bjyoung@kaist.ac.kr;kjshim1028@kaist.ac.kr;changick@kaist.ac.kr,6;6;3,,Reject,0,3,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Image Captioning;Visual Question Answering;Explainable A.I;Beam Search;Constrained Beam Search,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,Modeling Winner-Take-All Competition in Sparse Binary Projections,Wenye Li,wyli@cuhk.edu.cn,3;8;6,,Reject,0,4,0,yes,9/25/19,"The Chinese University of Hong Kong, Shenzhen",Sparse Representation;Sparse Binary Projection;Winner-Take-All,46,35,m;m,NAN,NAN,n
ICLR,2020,When Robustness Doesn‚Äôt Promote Robustness: Synthetic vs. Natural Distribution Shifts on ImageNet,Rohan Taori;Achal Dave;Vaishaal Shankar;Nicholas Carlini;Benjamin Recht;Ludwig Schmidt,rohantaori@berkeley.edu;achald@cs.cmu.edu;vaishaal@berkeley.edu;nicholas@carlini.com;brecht@berkeley.edu;ludwigschmidt2@gmail.com,3;6;3,,Reject,0,6,0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;University of California Berkeley;Google;University of California Berkeley;University of California Berkeley,robustness;distribution shift;image corruptions;adversarial robustness;reliable machine learning,-1;1;-1;-1;-1;-1,13;27;13;-1;13;-1,m;m,asia,in,n
ICLR,2020,Perturbations are not Enough: Generating Adversarial Examples with Spatial Distortions,He Zhao;Trung Le;Paul Montague;Olivier De Vel;Tamas Abraham;Dinh Phung,ethanhezhao@gmail.com;trunglm@monash.edu;paul.montague@dst.defence.gov.au;olivier.devel@dst.defence.gov.au;tamas.abraham@dst.defence.gov.au;dinh.phung@monash.edu,3;1;3,,Reject,1,3,0,yes,9/25/19,Monash University;Monash University;Defence Science and Technology Group;Defence Science and Technology Group;Defence Science and Technology Group;Monash University,,92;92;-1;-1;-1;92,75;75;-1;-1;-1;75,m;m,australasia,au,y
ICLR,2020,Adaptive Data Augmentation with Deep Parallel Generative Models,Boli Fang;Miao Jiang;Abhirag Nagpure;Jerry Shen,bfang@iu.edu;miajiang@iu.edu;anagpure@iu.edu;hashen@iu.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,"Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington;Indiana University, Bloomington",,64;64;64;64,134;134;134;134,m;m,NAN,NAN,n
ICLR,2020,Visual Explanation for Deep Metric Learning,Sijie Zhu;Taojiannan Yang;Chen Chen,szhu3@uncc.edu;tyang30@uncc.edu;chen.chen@uncc.edu,6;3;8,,Reject,0,5,0,yes,9/25/19,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte",Metric Learning;Visual Explanation,64;64;64,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Continual Learning via Neural Pruning,Siavash Golkar;Micheal Kagan;Kyunghyun Cho,siavash.golkar@gmail.com;makagan@slac.stanford.edu;kyunghyun.cho@nyu.edu,3;3;3,,Reject,0,0,0,yes,9/25/19,Flatiron Institute;Stanford University;New York University,continual learning;lifelong learning;catastrophic forgetting;sparsification,-1;5;22,-1;4;29,m;m,usa,usa,n
ICLR,2020,Continual Learning using the SHDL Framework with Skewed Replay Distributions,Amarjot Singh;Jay McClelland,as2436@stanford.edu;jlmcc@stanford.edu,1;1;1,,Reject,0,0,0,yes,9/25/19,Stanford University;Stanford University,Continual Learning;Catastrophic Forgetting;SHDL;CIFAR-100,5;5,4;4,m;m,usa,usa,n
ICLR,2020,Goten: GPU-Outsourcing Trusted Execution of Neural Network Training and Prediction,Lucien K.L. Ng;Sherman S.M. Chow;Anna P.Y. Woo;Donald P. H. Wong;Yongjun Zhao,nkl018@ie.cuhk.edu.hk;smchow@ie.cuhk.edu.hk;woopuiyung@gmail.com;foreverjun.zhao@gmail.com,1;6;1,,Reject,0,7,0,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong;;Nanyang Technological University,machine learning;security;privacy;TEE;trusted processors;Intel SGX;GPU;high-performance,316;316;-1;43,35;35;-1;49,m;m,asia,sg,n
ICLR,2020,One-way prototypical networks,Anna Kruspe,anna.kruspe@dlr.de,8;3;3,,Reject,0,0,0,yes,9/25/19,German Aerospace Center (DLR),few-shot learning;one-shot learning;prototypical networks;one-class classification;anomaly detection;outlier detection;matching networks,-1,-1,f,NAN,NAN,n
ICLR,2020,FLUID FLOW MASS TRANSPORT FOR GENERATIVE NETWORKS,Jingrong Lin;Keegan Lensink;Eldad Haber,jlin@eoas.ubc.ca;klensink@eoas.ubc.ca;ehaber@eoas.ubc.ca,1;3;3,,Reject,0,0,0,yes,9/25/19,University of British Columbia;University of British Columbia;University of British Columbia,generative network;optimal mass transport;gaussian mixture;model matching,64;64;64,34;34;34,f;m,canada,ca,n
ICLR,2020,Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration,Si-An Chen;Chun-Liang Li;Hsuan-Tien Lin,r05922089@csie.ntu.edu.tw;chunlial@cs.cmu.edu;htlin@csie.ntu.edu.tw,3;3;3,,Reject,0,2,0,yes,9/25/19,Nanyang Technological University;Carnegie Mellon University;Nanyang Technological University,generative adversarial network;GAN;model compatibility;machine learning efficacy,43;1;43,49;27;49,m;m,asia,sg,n
ICLR,2020,Generative Imputation and Stochastic Prediction,Mohammad Kachuee;Kimmo K√§rkk√§inen;Orpaz Goldstein;Sajad Darabi;Majid Sarrafzadeh,mkachuee@ucla.edu;kimmo@cs.ucla.edu;orpgol@cs.ucla.edu;sajad.darabi@cs.ucla.edu;majid@cs.ucla.edu,6;6;6,,Reject,0,9,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",,-1;-1;-1;-1;-1,17;17;17;17;17,m;m,usa,usa,n
ICLR,2020,Denoising Improves Latent Space Geometry in Text Autoencoders,Tianxiao Shen;Jonas Mueller;Regina Barzilay;Tommi Jaakkola,tianxiao@mit.edu;jonasmue@amazon.com;regina@csail.mit.edu;tommi@csail.mit.edu,6;3;6,,Reject,0,10,0,yes,9/25/19,Massachusetts Institute of Technology;Amazon;Massachusetts Institute of Technology;Massachusetts Institute of Technology,controllable text generation;autoencoders;denoising;latent space geometry,5;-1;5;5,5;-1;5;5,f;m,usa,usa,y
ICLR,2020,Information-Theoretic Local Minima Characterization and Regularization,Zhiwei Jia;Hao Su,zjia@ucsd.edu;haosu@eng.ucsd.edu,1;8;3,,Reject,0,18,0,yes,9/25/19,"University of California, San Diego;University of California, San Diego",local minima;generalization;regularization;deep learning theory,-1;-1,31;31,m;m,usa,usa,y
ICLR,2020,Wider Networks Learn Better Features,Dar Gilboa;Guy Gur-Ari,dg2893@columbia.edu;guyga@google.com,3;1;3,,Reject,0,0,0,yes,9/25/19,Columbia University;Google,Interpretability;transfer learning,24;-1,16;-1,m;m,NAN,NAN,n
ICLR,2020,GENERALIZATION GUARANTEES FOR NEURAL NETS VIA HARNESSING THE LOW-RANKNESS OF JACOBIAN,Samet Oymak;Zalan Fabian;Mingchen Li;Mahdi Soltanolkotabi,sametoymak@gmail.com;zfabian@usc.edu;mli176@ucr.edu;msoltoon@gmail.com,3;3;3,,Reject,0,3,0,yes,9/25/19,"University of California, Riverside;University of Southern California;University of California, Riverside;University of Southern California",Theory of neural nets;low-rank structure of Jacobian;optimization and generalization theory,-1;36;-1;36,249;62;249;62,m;m,usa,usa,y
ICLR,2020,Implicit competitive regularization in GANs,Florian Schaefer;Hongkai Zheng;Anima Anandkumar,florian.schaefer@caltech.edu;devzhk@sjtu.edu.cn;anima@caltech.edu,6;6;8;1,,Reject,0,7,0,yes,9/25/19,California Institute of Technology;Shanghai Jiao Tong University;California Institute of Technology,GAN;competitive optimization;game theory,143;30;143,2;157;2,m;f,usa,usa,n
ICLR,2020,TWO-STEP UNCERTAINTY NETWORK FOR TASKDRIVEN SENSOR PLACEMENT,Yangyang Sun;Yang Zhang;Hassan Foroosh;Shuo Pang,yangyang@knights.ucf.edu;yangzhang@knights.ucf.edu;foroosh@cs.ucf.edu;pang@creol.ucf.edu,1;1,,Reject,0,0,0,yes,9/25/19,University of Central Florida;University of Central Florida;University of Central Florida;University of Central Florida,Uncertainty Estimation;Sensor Placement;Sequential Control;Adaptive Sensing,73;73;73;73,609;609;609;609,m;m,usa,usa,n
ICLR,2020,Efficient Content-Based Sparse Attention with Routing Transformers,Aurko Roy*;Mohammad Taghi Saffar*;David Grangier;Ashish Vaswani,aurkor@google.com;msaffar@google.com;grangier@google.com;avaswani@google.com,3;3;6,,Reject,0,2,0,yes,9/25/19,Google;Google;Google;Google,Sparse attention;autoregressive;generative models,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Implicit Rugosity Regularization via Data Augmentation,Daniel LeJeune;Randall Balestriero;Hamid Javadi;Richard G. Baraniuk,dlejeune@rice.edu;randallbalestriero@gmail.com;hh35@rice.edu;richb@rice.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Rice University;Rice University;Rice University;Rice University,deep networks;implicit regularization;Hessian;rugosity;curviness;complexity,92;92;92;92,105;105;105;105,m;m,australasia,au,y
ICLR,2020,Balancing Cost and Benefit with Tied-Multi Transformers,Raj Dabre;Raphael Rubino;Atsushi Fujita,raj.dabre@nict.go.jp;raphael.rubino@nict.go.jp;fujita@paraphrasing.org,1;6;1,,Reject,0,3,0,yes,9/25/19,"National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology;Nara Institute of Science and Technology",tied models;encoder-decoder;multi-layer softmaxing;depth prediction;model compression,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Learning to Learn Kernels with Variational Random Features,Haoliang Sun;Yingjun Du;Jun Xu;Yilong Yin;Xiantong Zhen;Ling Shao,haolsun.cn@gmail.com;duyingjun@buaa.edu.cn;nankaimathxujun@gmail.com;ylyin@sdu.edu.cn;zhenxt@gmail.com;ling.shao@ieee.org,6;6;8,,Reject,0,7,0,yes,9/25/19,Shandong University;Beihang University;;Shandong University;University of Amsterdam;Inception Institute of Artificial Intelligence,Meta-learning;few-shot learning;Random Fourier Feature;Kernel learning,-1;102;-1;143;143;-1,-1;594;-1;658;62;-1,m;m,asia,in,n
ICLR,2020,Learning Numeral Embedding,Chengyue Jiang;Zhonglin Nian;Kaihao Guo;Shanbo Chu;Yinggong Zhao;Libin Shen;Kewei Tu,jiangchy@shanghaitech.edu.cn;nianzhl@shanghaitech.edu.cn;guokh@shanghaitech.edu.cn;chushb@leyantech.com;ygzhao@leyantech.com;libin@leyantech.com;tukw@shanghaitech.edu.cn,3;6;6,,Reject,0,4,0,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;Leyantech;Leyantech;Leyantech;ShanghaiTech University,Natural Language Processing;Numeral Embedding;Word Embedding;Out-of-vocabulary Problem,316;316;316;-1;-1;-1;316,-1;-1;-1;-1;-1;-1;-1,f;m,asia,cn,n
ICLR,2020,Label Cleaning with Likelihood Ratio Test,Songzhu Zheng;Pengxiang Wu;Aman Goswami;Mayank Goswami;Dimitris Metaxas;Chao Chen,zheng.songzhu@stonybrook.edu;pxiangwu@gmail.com;ag77in@gmail.com;mayank.isi@gmail.com;dnm@cs.rutgers.edu;chao.chen.1@stonybrook.edu,8;3;3,,Reject,0,4,0,yes,9/25/19,"State University of New York, Stony Brook;;;;Rutgers University;State University of New York, Stony Brook",Deep Learning,-1;-1;-1;-1;30;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Fast Task Adaptation for Few-Shot Learning,Yingying Zhang;Qiaoyong Zhong;Di Xie;Shiliang Pu,zhangyingying7@hikvision.com;zhongqiaoyong@hikvision.com;xiedi@hikvision.com;pushiliang@hikvision.com,8;1;3,,Reject,6,7,0,yes,9/25/19,Hikvision Research Institute;Hikvision Research Institute;Hikvision Research Institute;Hikvision Research Institute,Few-Shot Learning;Metric-Softmax Loss;Fast Task Adaptation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Using Objective Bayesian Methods to Determine the Optimal Degree of Curvature within the Loss Landscape,Devon Jarvis;Richard Klein;Benjamin Rosman,devonjarvi@gmail.com;kleinric@gmail.com;benjros@gmail.com,1;6;1,,Reject,0,7,0,yes,9/25/19,University of the Witwatersrand;University of the Witwatersrand;University of the Witwatersrand,Objective Bayes;Information Geometry;Artificial Neural Networks,-1;-1;-1,193;193;193,m;m,NAN,NAN,n
ICLR,2020,VIDEO AFFECTIVE IMPACT PREDICTION WITH MULTIMODAL FUSION AND LONG-SHORT TEMPORAL CONTEXT,Yin Zhao;Longjun Cai;Chaoping Tu;Jie Zhang;Wu Wei,yinzhao.zy@alibaba-inc.com;longjun.clj@alibaba-inc.com;chaoping.tcp@alibaba-inc.com;auzj_alex@mail.scut.edu.cn;weiwu@scut.edu.cn,1;1;3,,Reject,0,0,0,yes,9/25/19,Alibaba Group;Alibaba Group;Alibaba Group;South China University of Technology;South China University of Technology,multi-modal fusion;affective computing;temporal context;residual-based training strategy,-1;-1;-1;-1;-1,-1;-1;-1;501;501,f;m,NAN,NAN,n
ICLR,2020,UNITER: Learning UNiversal Image-TExt Representations,Yen-Chun Chen;Linjie Li;Licheng Yu;Ahmed El Kholy;Faisal Ahmed;Zhe Gan;Yu Cheng;Jingjing Liu,yen-chun.chen@microsoft.com;lindsey.li@microsoft.com;licheng.yu@microsoft.com;ahmed.elkholy@microsoft.com;fiahmed@microsoft.com;zhe.gan@microsoft.com;yu.cheng@microsoft.com;jingjl@microsoft.com,6;6;6,,Reject,0,12,0,yes,9/25/19,Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft,Self-supervised Representation Learning;Large-scale Pre-training;Vision and Language,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,"Fast Linear Interpolation for Piecewise-Linear Functions, GAMs, and Deep Lattice Networks",Nathan Zhang;Kevin Canini;Sean Silva;and Maya R. Gupta,nzhang32@gmail.com;canini@google.com;silvasean@google.com;mayagupta@google.com,3;3;1,,Reject,0,3,0,yes,9/25/19,Stanford University;Google;Google;Google,hardware;compiler;MLIR;runtime;CPU;interpolation,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Knowledge Graph Embedding: A Probabilistic Perspective and Generalization Bounds,Ondrej Kuzelka;Yuyi Wang,kuzelo1@gmail.com;yuyiwang920@gmail.com,6;1;3,,Reject,0,11,0,yes,9/25/19,Czech Technical University in Prague;Swiss Federal Institute of Technology,knowledge graph embedding;generalization bounds,168;-1,956;-1,m;m,NAN,NAN,y
ICLR,2020,BUZz: BUffer Zones for defending  adversarial examples in image classification,Phuong Ha Nguyen*;Kaleel Mahmood*;Lam M. Nguyen;Thanh Nguyen;Marten van Dijk,phuongha.ntu@gmail.com;kaleel.mahmood@uconn.edu;lamnguyen.mltd@gmail.com;thanhng@iastate.edu;marten.van_dijk@uconn.edu,1;3;3,,Reject,0,5,0,yes,9/25/19,University of Connecticut;University of Connecticut;International Business Machines;Iowa State University;University of Connecticut,adversarial machine learning;machine learning security,168;168;-1;194;168,393;393;-1;399;393,m;m,usa,usa,n
ICLR,2020,Domain Aggregation Networks for Multi-Source Domain Adaptation,Junfeng Wen;Russell Greiner;Dale Schuurmans,junfengwen@gmail.com;rgreiner@ualberta.ca;daes@ualberta.ca,6;3;6,,Reject,0,6,0,yes,9/25/19,Layer 6 AI;University of Alberta;University of Alberta,Domain Adaptation;Transfer Learning;Deep Learning,-1;102;102,-1;136;136,m;m,canada,ca,y
ICLR,2020,Privacy-preserving Representation Learning by Disentanglement,Tassilo Klein;Moin Nabi,tassilo.klein@sap.com;m.nabi@sap.com,1;3;1,,Reject,1,0,0,yes,9/25/19,SAP;SAP,,316;316,258;258,m;m,asia,in,n
ICLR,2020,Angular Visual Hardness,Beidi Chen;Weiyang Liu;Animesh Garg;Zhiding Yu;Anshumali Shrivastava;Jan Kautz;Anima Anandkumar,beidi.chen@rice.edu;wyliu@gatech.edu;garg@cs.stanford.edu;zhidingy@nvidia.com;anshumali@rice.edu;jkautz@nvidia.com;anima@caltech.edu,1;8;8,,Reject,0,7,0,yes,9/25/19,Rice University;Georgia Institute of Technology;Stanford University;NVIDIA;Rice University;NVIDIA;California Institute of Technology,angular similarity;self-training;hard samples mining,92;13;5;-1;92;-1;143,105;38;4;-1;105;-1;2,f;f,usa,usa,n
ICLR,2020,Autoencoders and Generative Adversarial Networks for Imbalanced Sequence Classification,Stephanie Ger;Diego Klabjan,stephanieger@u.northwestern.edu;d-klabjan@northwestern.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Northwestern University;Northwestern University,imbalanced multivariate time series classification,46;46,22;22,f;m,usa,usa,n
ICLR,2020,Multiagent Reinforcement Learning in Games with an Iterated Dominance Solution,Yoram Bachrach;Tor Lattimore;Marta Garnelo;Julien Perolat;David Balduzzi;Thomas Anthony;Satinder Singh;Thore Graepel,yorambac@gmail.com;lattimore@google.com;garnelo@google.com;perolat@google.com;dbalduzzi@google.com;twa@google.com;baveja@google.com;thore@google.com,1;6;3;6,,Reject,0,8,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,multiagent;reinforcement learning;iterated dominance;mechanism design;Nash equilibrium,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Blockwise Adaptivity:  Faster Training and Better Generalization in Deep Learning,Shuai Zheng;James T. Kwok,zs910504@gmail.com;jamesk@cse.ust.hk,3;6;1,,Reject,0,3,0,yes,9/25/19,Amazon;The Hong Kong University of Science and Technology,optimization;deep learning;blockwise adaptivity,-1;-1,-1;47,m;m,NAN,NAN,y
ICLR,2020,Self-Educated Language Agent with Hindsight Experience Replay for Instruction Following,Geoffrey Cideron;Mathieu Seurin;Florian Strub;Olivier Pietquin,geoffrey.cideron@inria.fr;mathieu.seurin@inria.fr;fstrub@google.com;pietquin@google.com,6;6;3,,Reject,0,8,0,yes,9/25/19,INRIA;INRIA;Google;Google,Language;reinforcement learning;instruction following;Hindsight Experience Replay,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Extreme Triplet Learning: Effectively Optimizing Easy Positives and Hard Negatives,Hong Xuan;Robert Pless,xuanhong@gwu.edu;pless@gwu.edu,3;8;3,,Reject,0,2,0,yes,9/25/19,George Washington University;George Washington University,Triplet Learning;Easy Positive;Hard Negatives,194;194,198;198,m;m,usa,usa,n
ICLR,2020,MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit,John Palowitch;Bryan Perozzi,johnpalowitch@gmail.com;bperozzi@acm.org,6;6;3,,Reject,0,5,0,yes,9/25/19,"University of North Carolina, Chapel Hill;Google",Graph Embeddings;Representation Learning,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,DYNAMIC SELF-TRAINING FRAMEWORK  FOR GRAPH CONVOLUTIONAL NETWORKS,Ziang Zhou;Shenzhong Zhang;Zengfeng Huang,15300180085@fudan.edu.cn;17210980007@fudan.edu.cn;huangzf@fudan.edu.cn,3;6;6,,Reject,0,3,0,yes,9/25/19,Fudan University;Fudan University;Fudan University,self-training;semi-supervised learning;graph convolutional networks,73;73;73,109;109;109,m;m,asia,cn,n
ICLR,2020,TOWARDS FEATURE SPACE ADVERSARIAL ATTACK,Qiuling Xu;Guanhong Tao;Siyuan Cheng;Lin Tan;Xiangyu Zhang,xu1230@purdue.edu;taog@purdue.edu;516030910472@sjtu.edu.cn;lintan@purdue.edu;xyzhang@cs.purdue.edu,6;3;6,,Reject,0,3,0,yes,9/25/19,Purdue University;Purdue University;Shanghai Jiao Tong University;Purdue University;Purdue University,,24;24;30;24;24,88;88;157;88;88,m;m,usa,usa,n
ICLR,2020,DIVA: Domain Invariant Variational Autoencoder,Maximilian Ilse;Jakub M. Tomczak;Christos Louizos;Max Welling,ilse.maximilian@gmail.com;jakubmkt@gmail.com;chr.louizos@gmail.com;welling.max@gmail.com,6;3;3,,Reject,0,7,0,yes,9/25/19,"University of Amsterdam;VU University Amsterdam;Qualcomm Inc, QualComm;University of California, Irvine",representation learning;generative models;domain generalization;invariance,143;-1;-1;-1,62;-1;-1;96,m;m,usa,usa,n
ICLR,2020,Optimal Attacks on Reinforcement Learning Policies,Alessio Russo;Alexandre Proutiere,alessior@kth.se;alepro@kth.se,3;6;6,,Reject,0,6,0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",,194;194,222;222,m;m,NAN,NAN,y
ICLR,2020,Recurrent Event Network : Global Structure Inference Over Temporal Knowledge Graph,Woojeong Jin;He Jiang;Meng Qu;Tong Chen;Changlin Zhang;Pedro¬†Szekely;Xiang Ren,woojeong.jin@usc.edu;jian567@usc.edu;meng.qu@umontreal.ca;tongc2@andrew.cmu.edu;changlin.zhang@usc.edu;pszekely@isi.edu;xiangren@usc.edu,6;3;3,,Reject,0,9,0,yes,9/25/19,University of Southern California;University of Southern California;University of Montreal;Carnegie Mellon University;University of Southern California;USC/ISI;University of Southern California,Temporal Knowledge Graphs;Representation Learning;Graph Sequence Inference;Knowledge Graph Completion,36;36;118;1;36;-1;36,62;62;85;27;62;-1;62,m;m,usa,usa,y
ICLR,2020,Continual Learning with Gated Incremental Memories for Sequential Data Processing,Andrea Cossu;Antonio Carta;Davide Bacciu,cossu48@gmail.com;antonio.carta@di.unipi.it;bacciu@di.unipi.it,3;3;1,,Reject,0,3,0,yes,9/25/19,Scuola Normale Superiore;University of Pisa;University of Pisa,continual learning;recurrent neural networks;progressive networks;gating autoencoders;sequential data processing,-1;248;248,152;366;366,m;m,europe,il,n
ICLR,2020,Context-Aware Object Detection With Convolutional Neural Networks,Yizhou Yan;Lei Cao;Samuel Madden;Elke Rundensteiner,yyan2@wpi.edu;lcao@csail.mit.edu;madden@csail.mit.edu;rundenst@cs.wpi.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Worcester Polytechnic Institute;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Worcester Polytechnic Institute,Object Detection;CNN;Context;CRF,143;5;5;143,628;5;5;628,f;f,usa,usa,n
ICLR,2020,Resizable Neural Networks,Yichen Zhu;Xiangyu Zhang;Tong Yang;Jian Sun,k.zhu@mail.utoronto.ca;zhangxiangyu@megvii.com;yangtong@megvii.com;sunjian@megvii.com,3;6;3,,Reject,0,3,0,yes,9/25/19,Toronto University;Megvii Technology Inc.;Megvii Technology Inc.;Megvii Technology Inc.,,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,SPROUT: Self-Progressing Robust Training,Minhao Cheng;Pin-Yu Chen;Sijia Liu;Shiyu Chang;Cho-Jui Hsieh;Payel Das,mhcheng@ucla.edu;pin-yu.chen@ibm.com;sijia.liu@ibm.com;shiyu.chang@ibm.com;chohsieh@cs.ucla.edu;daspa@us.ibm.com,3;6;3,,Reject,0,6,0,yes,9/25/19,"University of California, Los Angeles;International Business Machines;International Business Machines;International Business Machines;University of California, Los Angeles;International Business Machines",robustness;robust training;trustworthy machine learning,-1;-1;-1;-1;-1;-1,17;-1;-1;-1;17;-1,m;f,NAN,NAN,n
ICLR,2020,FALCON: Fast and Lightweight Convolution for Compressing and Accelerating CNN,Chun Quan;Jun-Gi Jang;Hyun Dong Lee;U Kang,chunquan_cs@outlook.com;elnino4@snu.ac.kr;hyundonglee1015@gmail.com;ukang@snu.ac.kr,6;6;3,,Reject,0,5,0,yes,9/25/19,Seoul National University;Seoul National University;;Seoul National University,CNN compression;CNN acceleration;model compression,-1;39;-1;39,-1;64;-1;64,m;m,asia,kr,y
ICLR,2020,Conditional Invertible Neural Networks for Guided Image Generation,Lynton Ardizzone;Carsten L√ºth;Jakob Kruse;Carsten Rother;Ullrich K√∂the,lynton.ardizzone@iwr.uni-heidelberg.de;clueth@live.de;jakob.kruse@iwr.uni-heidelberg.de;carsten.rother@iwr.uni-heidelberg.de;ullrich.koethe@iwr.uni-heidelberg.de,6;6;3;8,,Reject,0,4,0,yes,9/25/19,Heidelberg University;;Heidelberg University;Heidelberg University;Heidelberg University,Invertible neural networks;generative models;conditional generation,194;-1;194;194;194,44;-1;44;44;44,m;m,europe,de,n
ICLR,2020,Domain-Independent Dominance of Adaptive Methods,Pedro Savarese;David McAllester;Sudarshan Babu;Michael Maire,savarese@ttic.edu;mcallester@ttic.edu;sudarshan@ttic.edu;mmaire@uchicago.edu,3;6;3,,Reject,0,8,0,yes,9/25/19,Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago;University of Chicago,,-1;-1;-1;51,-1;-1;-1;9,m;m,usa,usa,y
ICLR,2020,RISE and DISE: Two Frameworks for Learning from Time Series with Missing Data,Alberto Garcia-Duran;Robert West,alberto.duran@epfl.ch;robert.west@epfl.ch,3;1;3,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Time Series;Missing Data;RNN,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models,Liu Yang;George Em Karniadakis,liu_yang@brown.edu;george_karniadakis@brown.edu,3;3;8,,Reject,0,7,0,yes,9/25/19,Brown University;Brown University,generative models;optimal transport;GANs;flow-based models,85;85,53;53,m;m,usa,usa,n
ICLR,2020,Power up! Robust Graph Convolutional Network based on Graph Powering,Ming Jin;Heng Chang;Wenwu Zhu;Somayeh Sojoudi,jinming@berkeley.edu;changh@berkeley.edu;wwzhu@tsinghua.edu.cn;sojoudi@berkeley.edu,3;3;3,,Reject,0,7,0,yes,9/25/19,"University of California Berkeley;University of California Berkeley;Tsinghua University, Tsinghua University;University of California Berkeley",graph mining;graph neural network;adversarial robustness,-1;-1;4;-1,13;13;23;13,m;f,usa,usa,y
ICLR,2020,DIME: AN INFORMATION-THEORETIC DIFFICULTY MEASURE FOR AI DATASETS,Peiliang Zhang;Huan Wang;Nikhil Naik;Caiming Xiong;Richard Socher,pez35@pitt.edu;huan.wang@salesforce.com;nnaik@salesforce.com;cxiong@salesforce.com;rsocher@salesforce.com,3;3;1,,Reject,0,4,0,yes,9/25/19,University of Pittsburgh;SalesForce.com;SalesForce.com;SalesForce.com;SalesForce.com,Information Theory;Fano‚Äôs Inequality;Difficulty Measure;Donsker-Varadhan Representation;Theory,79;-1;-1;-1;-1,113;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Improved Detection of Adversarial Attacks via Penetration Distortion Maximization,Shai Rozenberg;Gal Elidan;Ran El-Yaniv,shairoz@cs.technion.ac.il;elidan@google.com;elyaniv@google.com,3;6;3,,Reject,0,3,0,yes,9/25/19,"Technion, Technion;Google;Google",Adversarial Examples;Adversarial Attacks;Adversarial Defense;White-Box threat models,27;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,X-Forest: Approximate Random Projection Trees for Similarity Measurement,Yikai Zhao;Peiqing Chen;Zidong Zhao;Tong Yang;Jie Jiang;Bin Cui;Gong Zhang;Steve Uhlig,zyk@pku.edu.cn;chenpeiqing@pku.edu.cn;benkerd@pku.edu.cn;yangtongemail@gmail.com;jie.jiang@pku.edu.cn;bin.cui@pku.edu.cn;nicholas.zhang@huawei.com;steve.uhlig@qmul.ac.uk,1;3;3,,Reject,0,0,0,yes,9/25/19,Peking University;Peking University;Peking University;;Peking University;Peking University;Huawei Technologies Ltd.;Queen Mary University London,,14;14;14;-1;14;14;-1;-1,24;24;24;-1;24;24;-1;-1,m;m,europe,uk,y
ICLR,2020,Out-of-Distribution Image Detection Using the Normalized Compression Distance,Sehun Yu;Donga Lee;Hwanjo Yu,hunu12@postech.ac.kr;dongha0914@postech.ac.kr;hwanjoyu@postech.ac.kr,3;3;6,,Reject,0,5,0,yes,9/25/19,POSTECH;POSTECH;POSTECH,Out-of-Distribution Detection;Normalized Compression Distance;Convolutional Neural Networks,118;118;118,146;146;146,m;m,asia,kr,n
ICLR,2020,A Deep Recurrent Neural Network via Unfolding Reweighted l1-l1 Minimization,Huynh Van Luong;Duy Hung Le;Nikos Deligiannis,hvanluon@etrovub.be;dle@etrovub.be;ndeligia@etrovub.be,3;6;8,,Reject,0,3,0,yes,9/25/19,Vrije Universiteit Brussel;Vrije Universiteit Brussel;Vrije Universiteit Brussel,,-1;-1;-1,235;235;235,m;m,NAN,NAN,y
ICLR,2020,Meta-Learning for Variational Inference,Ruqi Zhang;Yingzhen Li;Chris De Sa;Sam Devlin;Cheng Zhang,rz297@cornell.edu;yingzhen.li@microsoft.com;cdesa@cs.cornell.edu;sam.devlin@microsoft.com;cheng.zhang@microsoft.com,3;3;8,,Reject,0,7,0,yes,9/25/19,Cornell University;Microsoft;Cornell University;Microsoft;Microsoft,Variational inference;Meta-learning,7;-1;7;-1;-1,19;-1;19;-1;-1,f;f,NAN,NAN,y
ICLR,2020,All Simulations Are Not Equal: Simulation Reweighing for Imperfect Information Games,Qucheng Gong;Yuandong Tian,qucheng@fb.com;yuandong@fb.com,1;3;3,,Reject,0,3,0,yes,9/25/19,Facebook;Facebook,Contract Bridge;Simulation;Imperfect Information Games;Reweigh;Belief Modeling,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,GRASPEL: GRAPH SPECTRAL LEARNING AT SCALE,Yongyu Wang;Zhiqiang Zhao;Zhuo Feng,yongyuw@mtu.edu;qzzhao@mtu.edu;zfeng12@stevens.edu,1;3;6,,Reject,0,4,0,yes,9/25/19,Michigan Technological University;Michigan Technological University;Stevens Institute of Technology,Spectral graph theory;graph learning;data clustering;t-SNE visualization,316;316;143,-1;-1;605,m;m,usa,usa,y
ICLR,2020,Latent Variables on Spheres for Sampling and Inference,Deli Zhao;Jiapeng Zhu;Bo Zhang,zhaodeli@gmail.com;jengzhu0@gmail.com;zhangbo@xiaomi.com,6;1;6,,Reject,1,5,0,yes,9/25/19,Alibaba Group;Hong Kong University of Science and Technology;Xiaomi,variational autoencoder;generative adversarial network,-1;-1;-1,-1;47;-1,m;m,NAN,NAN,y
ICLR,2020,Detecting Change in Seasonal Pattern via Autoencoder and Temporal Regularization,Raphael Fettaya;Dor Bank;Rachel Lemberg;Linoy Barel,raphaelfettaya@gmail.com;doban@microsoft.com;rlemberg@microsoft.com;t-libare@microsoft.com,1;3;1;3,,Reject,0,0,0,yes,9/25/19,Tel Aviv University;Microsoft;Microsoft;Microsoft,Autoencoder;Change Point Detection;Timeseries,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Ladder Polynomial Neural Networks,Li-Ping Liu;Ruiyuan Gu;Xiaozhe Hu,liping.liu@tufts.edu;ruiyuan.gu@tufts.edu;xiaozhe.hu@tufts.edu,3;6;6,,Reject,0,3,0,yes,9/25/19,Tufts University;Tufts University;Tufts University,polynomial neural networks,194;194;194,139;139;139,m;m,usa,usa,n
ICLR,2020,Universal Safeguarded Learned Convex Optimization with Guaranteed Convergence,Howard Heaton;Xiaohan Chen;Zhangyang Wang;Wotao Yin,heaton@math.ucla.edu;chernxh@tamu.edu;atlaswang@tamu.edu;wotao.yin@alibaba-inc.com,3;3;3,,Reject,0,7,0,yes,9/25/19,"University of California, Los Angeles;Texas A&M;Texas A&M;Alibaba Group",L2O;learn to optimize;fixed point;machine learning;neural network;ADMM;LADMM;ALISTA;D-LADMM,-1;46;46;-1,17;177;177;-1,m;m,NAN,NAN,y
ICLR,2020,Knockoff-Inspired Feature Selection via Generative Models,Marco F. Duarte;Siwei Feng,mduarte@ecs.umass.edu;siwei@umass.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst",feature selection;variable selection;knockoff variables;supervised learning,24;24,209;209,m;m,usa,usa,n
ICLR,2020,Diagnosing the Environment Bias in Vision-and-Language Navigation,Yubo Zhang;Hao Tan;Mohit Bansal,zhangyb@cs.unc.edu;airsplay@cs.unc.edu;mbansal@cs.unc.edu,6;3;6,,Reject,0,8,2,yes,9/25/19,"University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",vision-and-language navigation;generalization;environment bias diagnosis,64;64;64,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Entropy Minimization In Emergent Languages,Eugene Kharitonov;Rahma Chaabouni;Diane Bouchacourt;Marco Baroni,eugene.kharitonov@gmail.com;rchaabouni@fb.com;dianeb@fb.com;marco.baroni@unitn.it,1;6;6;6,,Reject,0,8,0,yes,9/25/19,Facebook;Facebook;Facebook;University of Trento,language emergence,-1;-1;-1;143,-1;-1;-1;307,m;m,europe,gr,n
ICLR,2020,Improving SAT Solver Heuristics with Graph Networks and Reinforcement Learning,Vitaly Kurin;Saad Godil;Shimon Whiteson;Bryan Catanzaro,vitaliykurin@gmail.com;sgodil@nvidia.com;shimon.whiteson@gmail.com;bcatanzaro@nvidia.com,8;3;3,,Reject,1,5,0,yes,9/25/19,University of Oxford;NVIDIA;University of Oxford;NVIDIA,SAT;reinforcement learning;graph neural networks;heuristics;DQN;boolean satisfiability,-1;-1;46;-1,-1;-1;1;-1,m;m,NAN,NAN,n
ICLR,2020,Toward Understanding The Effect of Loss Function on The Performance of Knowledge Graph Embedding,Mojtaba Nayyeri;Chengjin Xu;Yadollah Yaghoobzadeh;Hamed Shariat Yazdi;Jens Lehmann,nayyeri@cs.uni-bonn.de;xuc@cs.uni-bonn.de;yayaghoo@microsoft.com;shariat@cs.uni-bonn.de;jens.lehmann@cs.uni-bonn.de,6;3;1;3,,Reject,0,8,0,yes,9/25/19,University of Bonn;University of Bonn;Microsoft;University of Bonn;University of Bonn,Knowledge graph embedding;Translation based embedding;loss function;relation pattern,143;143;-1;143;143,106;106;-1;106;106,m;m,europe,uk,n
ICLR,2020,Multi-Precision Policy Enforced Training (MuPPET) : A precision-switching strategy for quantised fixed-point training of CNNs,Aditya Rajagopal;Diederik A. Vink;Stylianos I. Venieris;Christos-Savvas Bouganis,aditya.rajagopal14@imperial.ac.uk;diederik.vink14@imperial.ac.uk;stelios.ven10@gmail.com;christos-savvas.bouganis@imperial.ac.uk,3;3;3,,Reject,0,3,0,yes,9/25/19,Imperial College London;Imperial College London;Samsung;Imperial College London,,52;52;-1;52,10;10;-1;10,m;m,europe,uk,n
ICLR,2020,R2D2: Reuse & Reduce via Dynamic Weight Diffusion for Training Efficient NLP Models,Yi Tay;Aston Zhang;Shuai Zhang;Alvin Chan;Luu Anh Tuan;Siu Cheung Hui,ytay017@e.ntu.edu.sg;astonz@amazon.com;cheungshuai@outlook.com;guoweial001@e.ntu.edu.sg;tuanluu@csail.mit.edu;asschui@ntu.edu.sg,3;6;6,,Reject,0,3,0,yes,9/25/19,Nanyang Technological University;Amazon;Swiss Federal Institute of Technology;Nanyang Technological University;Massachusetts Institute of Technology;Nanyang Technological University,Deep Learning;Natural Language Processing,43;-1;-1;43;5;43,49;-1;-1;49;5;49,m;m,asia,sg,n
ICLR,2020,Variational Autoencoders for Opponent Modeling in Multi-Agent Systems,Georgios Papoudakis;Stefano V. Albrecht,g.papoudakis@ed.ac.uk;s.albrecht@ed.ac.uk,3;1;6,,Reject,0,6,0,yes,9/25/19,University of Edinburgh;University of Edinburgh,reinforcement learning;multi-agent systems;representation learning,36;36,30;30,m;m,europe,uk,n
ICLR,2020,SELF-KNOWLEDGE DISTILLATION ADVERSARIAL ATTACK,Ma Xiaoxiong[1];Wang Renzhi[1];Tian Cong;Dong Zeqian;Duan Zhenhua,maxrumi@163.com;shanicky4ever@gmail.com;tico_tools@163.com;zqdong@stu.xidian.edu.cn;zhenhua_duan@126.com,3;1;3,,Reject,1,6,0,yes,9/25/19,163;;163;Xidian University;126,Adversarial Examples;Transferability;black-box targeted attack;Distillation,-1;-1;-1;-1;-1,-1;-1;-1;919;-1,m;m,asia,in,n
ICLR,2020,Continual Deep Learning by Functional Regularisation of Memorable Past,Pingbo Pan;Alexander Immer;Siddharth Swaroop;Runa Eschenhagen;Richard E Turner;Mohammad Emtiyaz Khan,pingbo.pan@student.uts.edu.au;alexander.immer@epfl.ch;ss2163@cam.ac.uk;reschenhagen@uni-osnabrueck.de;ret26@cam.ac.uk;emtiyaz.khan@riken.jp,1;1;6,,Reject,0,5,0,yes,9/25/19,University of Technology Sydney;Swiss Federal Institute of Technology Lausanne;University of Cambridge;Universit√§t Osnabr√ºck;University of Cambridge;RIKEN,Continual learning;deep learning;functional regularisation,73;-1;79;-1;79;-1,193;-1;3;-1;3;-1,m;m,NAN,NAN,y
ICLR,2020,Model Comparison of Beer data classification using an electronic nose,Mohammed Abdi;Aminat Adebiyi;Andrea Fasoli;Alberto Mannari;Ronald Labby;Luisa Bozano,mohammed.munir.abdi@ibm.com;aminat.adebiyi@ibm.com;andrea.fasoli@ibm.com;alberto.mannari@ibm.com;rlabby@us.ibm.com;lbozano@us.ibm.com,1;1;1,,Reject,0,0,0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines,Electronic Nose;EVA;modular;olfaction;sensitivity;selectivity;analyte;temperature oscillated waveforms;features;fingerprint,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Deep Multi-View Learning via Task-Optimal CCA,Heather D. Couture;Roland Kwitt;J.S. Marron;Melissa Troester;Charles M. Perou;Marc Niethammer,heather@pixelscientia.com;roland.kwitt@gmail.com;marron@unc.edu;troester@unc.edu;chuck_perou@med.unc.edu;mn@cs.unc.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,"Pixel Scientia Labs;University of Salzburg;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill;University of North Carolina, Chapel Hill",multi-view;components analysis;CCA;representation learning;deep learning,-1;248;64;64;64;64,-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Unsupervised Representation Learning by Predicting Random Distances,Hu Wang;Guansong Pang;Chunhua Shen;Congbo Ma,hu.wang@adelaide.edu.au;pangguansong@gmail.com;chunhua.shen@adelaide.edu.au;201520121828@mail.scut.edu.cn,6;6;3,,Reject,0,4,0,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide;South China University of Technology,representation learning;unsupervised learning;anomaly detection;clustering,102;102;102;-1,120;120;120;501,m;m,NAN,NAN,n
ICLR,2020,Qgraph-bounded Q-learning: Stabilizing Model-Free Off-Policy Deep Reinforcement Learning,Sabrina Hoppe;Marc Toussaint,sabrina.hoppe@de.bosch.com;marc.toussaint@informatik.uni-stuttgart.de,6;3;1,,Reject,0,4,0,yes,9/25/19,Bosch;University of Stuttgart,deep learning;reinforcement learning;model-free reinforcement learning;Q-learning;DDPG,-1;118,297;292,f;m,europe,de,n
ICLR,2020,Neural Maximum Common Subgraph Detection with Guided Subgraph Extraction,Yunsheng Bai;Derek Xu;Ken Gu;Xueqing Wu;Agustin Marinovic;Christopher Ro;Yizhou Sun;Wei Wang,yba@ucla.edu;derekqxu@ucla.edu;ken.qgu@gmail.com;shirley0@mail.ustc.edu.cn;amarinovic@ucla.edu;christopher.j.ro@gmail.com;yzsun@cs.ucla.edu;weiwang@cs.ucla.edu,3;3;6,,Reject,0,9,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;;University of Science and Technology of China;University of California, Los Angeles;;University of California, Los Angeles;University of California, Los Angeles",graph matching;maximum common subgraph;graph neural networks;subgraph extraction;graph alignment,-1;-1;-1;-1;-1;-1;-1;-1,17;17;-1;80;17;-1;17;17,m;f,usa,usa,n
ICLR,2020,Blockwise Self-Attention for Long Document Understanding,Jiezhong Qiu;Hao Ma;Omer Levy;Scott Wen-tau Yih;Sinong Wang;Jie Tang,qiujz16@mails.tsinghua.edu.cn;gabe.hao.ma@gmail.com;omerlevy@gmail.com;scottyih@gmail.com;sinongwang@fb.com;jietang@tsinghua.edu.cn,3;6;6,,Reject,0,4,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Facebook;Tel Aviv University;Facebook AI Research;Facebook;Tsinghua University, Tsinghua University",BERT;Transformer,4;-1;30;-1;-1;4,23;-1;188;-1;-1;23,m;m,NAN,NAN,n
ICLR,2020,GroSS Decomposition: Group-Size Series Decomposition for Whole Search-Space Training,Henry Howard-Jenkins;Yiwen Li;Victor Adrian Prisacariu,henryhj@robots.ox.ac.uk;kate@robots.ox.ac.uk;victor@robots.ox.ac.uk,3;6;3,,Reject,0,4,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,architecture search;block term decomposition;network decomposition;network acceleration;group convolution,46;46;46,1;1;1,m;m,europe,uk,n
ICLR,2020,Emergence of Collective Policies Inside Simulations with Biased Representations,Jooyeon Kim;Alice Oh,jooyeon.kim@kaist.ac.kr;alice.oh@kaist.edu,3;1;3,,Reject,0,1,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;KAIST,collective policy;biased representation;model-based RL;simulation;imagination;virtual environment,-1;15,110;110,m;f,asia,in,n
ICLR,2020,On unsupervised-supervised risk and one-class neural networks,Christophe Cerisara,cerisara@loria.fr,3;3;6,,Reject,0,3,0,yes,9/25/19,University of Lorraine,unsupervised training;one-class models,-1,624,m,NAN,NAN,n
ICLR,2020,Shifted Randomized Singular Value Decomposition,Ali Basirat,ali.basirat@lingfil.uu.se,1;1;3,,Reject,0,0,0,yes,9/25/19,Uppsala University,SVD;PCA;Randomized Algorithms,194,102,m;m,europe,se,n
ICLR,2020,Encoding Musical Style with Transformer Autoencoders,Kristy Choi;Curtis Hawthorne;Ian Simon;Monica Dinculescu;Jesse Engel,kechoi@cs.stanford.edu;fjord@google.com;iansimon@google.com;noms@google.com;jesseengel@google.com,3;6,,Reject,0,4,0,yes,9/25/19,Stanford University;Google;Google;Google;Google,music generation;sequence-to-sequence model;controllable generation,5;-1;-1;-1;-1,4;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Adaptive Adversarial Imitation Learning,Yiren Lu;Jonathan Tompson;Sergey Levine,luyiren92@gmail.com;tompson@google.com;slevine@google.com,6;3;1,,Reject,0,7,0,yes,9/25/19,University of Pennsylvania;Google;Google,Imitation Learning;Reinforcement Learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness,Haichao Zhang;Wei Xu,hczhang1@gmail.com;wei.xu@horizon.ai,6;3;3,,Reject,1,8,0,yes,9/25/19,Horizon Robotics;Horizon Robotics,adversarial training;adversarial robustness,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,Do Image Classifiers Generalize Across Time?,Vaishaal Shankar;Achal Dave;Rebecca Roelofs;Deva Ramanan;Ben Recht;Ludwig Schmidt,vaishaal@berkeley.edu;achald@cs.cmu.edu;roelofs@cs.berkely.edu;deva@cs.cmu.edu;brecht@berkeley.edu;ludwigschmidt2@gmail.com,3;3;6,,Reject,0,5,0,yes,9/25/19,University of California Berkeley;Carnegie Mellon University;;Carnegie Mellon University;University of California Berkeley;University of California Berkeley,robustness;image classification;distribution shift,-1;1;-1;1;-1;-1,13;27;-1;27;13;-1,m;m,asia,in,n
ICLR,2020,Manifold Learning and Alignment with Generative Adversarial Networks,Jiseob Kim;Seungjae Jung;Hyundo Lee;Byoung-Tak Zhang,jkim@bi.snu.ac.kr;sjjung@bi.snu.ac.kr;hdlee@bi.snu.ac.kr;btzhang@bi.snu.ac.kr,6;6;6,,Reject,0,6,0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Generative Adversarial Networks;Manifold Learning;Manifold Alignment,39;39;39;39,64;64;64;64,m;m,asia,kr,y
ICLR,2020,Count-guided Weakly Supervised Localization Based on Density Map,Ming Ma;Stephan Chalup;Fayeem Aziz;Yang Liu;Defu Cheng;Zhijian Zhou,mmingabc@outlook.com;stephan.chalup@newcastle.edu.au;mdfayeembin.aziz@uon.edu.au;liu15@mails.jlu.edu.cn;chengdefu@jlu.edu.cn;zhouzhijian@jlu.edu.cn,1;3;3,,Reject,0,0,0,yes,9/25/19,"Jilin University;University of Newcastle, Australia;University of Newcastle, Australia;Jilin University;Jilin University;Jilin University",Semi-supervised Learning;Weakly Supervised Localization;Variational Autoencoder;Density Map;Counting,-1;316;316;-1;-1;-1,-1;311;311;952;952;952,m;m,NAN,NAN,n
ICLR,2020,Neural Phrase-to-Phrase Machine Translation,Jiangtao;Feng;Lingpeng Kong;Po-sen Huang;Chong;Wang;Da;Huang Jiayuan;Mao;Kan;Qiao;Dengyong;Zhou,lingpenk@google.com,3;3;3,,Reject,0,0,0,yes,9/25/19,Google,,-1,-1,m;m,NAN,NAN,n
ICLR,2020,Walking the Tightrope: An Investigation of the Convolutional Autoencoder Bottleneck,Ilja Manakov;Markus Rohm;Volker Tresp,ilja.manakov@med.uni-muenchen.de;markus.rohm@med.uni-muenchen.de;volker.tresp@siemens.com,6;3;3,,Reject,0,8,0,yes,9/25/19,Ludwig-Maximilians-Universit√§t M√ºnchen;Ludwig-Maximilians-Universit√§t M√ºnchen;Siemens Corporate Research,convolutional autoencoder;bottleneck;representation learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,LEX-GAN: Layered Explainable Rumor Detector Based on Generative Adversarial Networks,Mingxi Cheng;Yizhi Li;Shahin Nazarian;Paul Bogdan,mingxic@usc.edu;yizhi.li@bupt.edu.cn;shahin.nazarian@usc.edu;pbogdan@usc.edu,3;1;8;1,,Reject,0,8,0,yes,9/25/19,University of Southern California;Beijing University of Post and Telecommunication;University of Southern California;University of Southern California,explainable rumor detection;layered generative adversarial networks,36;-1;36;36,62;-1;62;62,f;m,usa,usa,n
ICLR,2020,A New Multi-input Model with the Attention Mechanism for Text Classification,Junhao Qiu;Ronghua Shi;Fangfang Li (the corresponding author);Jinjing Shi;Wangmin Liao,qiujunhao@csu.edu.cn;shirh@csu.edu.cn;lifangfang@csu.edu.cn;shijinjing@csu.edu.cn;0909123117@csu.edu.cn,1;1;1,,Reject,0,0,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Natural Language Processing;Text Classification;Densent;Multi-input Model;Attention Mechanism,-1;-1;-1;-1;-1,299;299;299;299;299,m;m,NAN,NAN,n
ICLR,2020,Stochastic Prototype Embeddings,Tyler R. Scott;Karl Ridgeway;Michael C. Mozer,tysc7237@colorado.edu;karl.ridgeway@colorado.edu;mcmozer@google.com,3;3;3,,Reject,0,5,0,yes,9/25/19,"University of Colorado, Boulder;University of Colorado, Boulder;Google",deep embeddings;stochastic embeddings;probabilistic embeddings;deep metric learning;few-shot learning,59;59;-1,123;123;-1,m;m,NAN,NAN,n
ICLR,2020,GraphNVP: an Invertible Flow-based Model for Generating Molecular Graphs,Kaushalya Madhawa;Katsuhiko Ishiguro;Kosuke Nakago;Motoki Abe,kaushalya@net.c.titech.ac.jp;k.ishiguro.jp@ieee.org;nakago@preferred.jp;motoki@preferred.jp,3;3;3,,Reject,0,3,0,yes,9/25/19,"Tokyo Institute of Technology;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",Graph Neural Networks;graph generative model;invertible flow;graphNVP,168;-1;-1;-1,299;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Contrastive Multiview Coding,Yonglong Tian;Dilip Krishnan;Phillip Isola,yonglong@mit.edu;dilipkay@google.com;phillipi@mit.edu,3;6;6,,Reject,0,3,0,yes,9/25/19,Massachusetts Institute of Technology;Google;Massachusetts Institute of Technology,Representation Learning;Unsupervised Learning;Self-supervsied Learning;Multiview Learning,5;-1;5,5;-1;5,m;m,usa,usa,n
ICLR,2020,RGTI:Response generation via templates integration for End to End dialog,Yuxin Zhang;Songyan Liu,zhangyuxin960625@gmail.com;anchor3l31@gmail.com,1;1;1;1,,Reject,0,0,0,yes,9/25/19,Beijing University of Post and Telecommunication;Chinese Academy of Sciences,End-to-end dialogue systems;transformer;pointer-generate network,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Improving the Gating Mechanism of Recurrent Neural Networks,Albert Gua;Caglar Gulcehre;Tom le Paine;Razvan Pascanu;Matt Hoffman,gua@google.com;caglarg@google.com;mwhoffman@google.com;razp@google.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google,recurrent neural networks;LSTM;GRUs;gating mechanisms;deep learning;reinforcement learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Analyzing the Role of Model Uncertainty for Electronic Health Records,Michael W. Dusenberry;Dustin Tran;Edward Choi;Jonas Kemp;Jeremy Nixon;Ghassen Jerfel;Katherine Heller;Andrew M. Dai,dusenberrymw@google.com;trandustin@google.com;mp2893@gmail.com;jonasbkemp@google.com;jeremynixon@google.com;ghassen@google.com;kheller@google.com;adai@google.com,3;3,,Reject,2,3,0,yes,9/25/19,Google;Google;Korea Advanced Institute of Science and Technology;Google;Google;Google;Google;Google,medicine;uncertainty;neural networks;Bayesian;electronic health records,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;110;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Leveraging Entanglement Entropy for Deep Understanding of  Attention Matrix in Text Matching,Peng Zhang;XiaoLiu Mao;XinDian Ma;BenYou Wang;Jing Zhang;Jun Wang;DaWei Song,pzhang@tju.edu.cn;xiaoliumao@tju.edu.cn;xindianma@tju.edu.cn;wang@dei.unipd.it;18738996120@163.com;jun.wang@cs.ucl.ac.uk;dwsong@bit.edu.cn,1;1;3,,Reject,0,3,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Universita' degli studi di Padova;163;University College London;Beijing Institute of Technology,Quantum entanglement entropy;Attention Matrix,39;39;39;-1;-1;52;-1,107;107;107;-1;-1;-1;661,m;m,NAN,NAN,n
ICLR,2020,Superbloom: Bloom filter meets Transformer,John Anderson;Qingqing Huang;Walid Krichene;Steffen Rendle;Li Zhang,janders@google.com;qqhuang@google.com;walidk@google.com;srendle@google.com;liqzhang@google.com,6;3;3,,Reject,0,5,0,yes,9/25/19,Google;Google;Google;Google;Google,Bloom filter;Transformer;word pieces;contextual embeddings,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,LEARNING TO IMPUTE: A GENERAL FRAMEWORK FOR SEMI-SUPERVISED LEARNING,Wei-Hong Li;Chuan-Sheng Foo;Hakan Bilen,w.h.li@ed.ac.uk;foo_chuan_sheng@i2r.a-star.edu.sg;hbilen@ed.ac.uk,3;3;3,,Reject,0,4,0,yes,9/25/19,"University of Edinburgh;Institute for Infocomm Research, A*STAR;University of Edinburgh",Semi-supervised Learning;Meta-Learning;Learning to label,36;-1;36,30;-1;30,m;m,europe,uk,n
ICLR,2020,Reflection-based Word Attribute Transfer,Yoichi Ishibashi;Katsuhito Sudoh;Koichiro Yoshino;Satoshi Nakamura,ishibashi.yoichi.ir3@is.naist.jp;sudoh@is.naist.jp;koichiro@is.naist.jp;s-nakamura@is.naist.jp,6;6;6,,Reject,0,4,0,yes,9/25/19,"Nara Institute of Science and Technology, Japan;Nara Institute of Science and Technology, Japan;Nara Institute of Science and Technology, Japan;Nara Institute of Science and Technology, Japan",embedding;representation learning;analogy;geometry,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks,Shuxuan Guo;Jose M. Alvarez;Mathieu Salzmann,shuxuan.guo@epfl.ch;josea@nvidia.com;mathieu.salzmann@epfl.ch,6;3,,Reject,0,5,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;NVIDIA;Swiss Federal Institute of Technology Lausanne,Compact Network Training;Linear Expansion;Over-parameterization;Knowledge Transfer,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PopSGD: Decentralized Stochastic Gradient Descent in the Population Model,Giorgi Nadiradze;Amirmojtaba Sabour;Aditya Sharma;Ilia Markov;Vitaly Aksenov;Dan Alistarh.,giorgi.nadiradze@ist.ac.at;amsabour79@gmail.com;adityasharma.2000.as@gmail.com;ilia.markov@ist.ac.at;aksenov.vitaly@gmail.com;dan.alistarh@ist.ac.at,3;1,,Reject,0,7,0,yes,9/25/19,Institute of Science and Technology Austria;;;Institute of Science and Technology Austria;ITMO University;Institute of Science and Technology Austria,Distributed machine learning;distributed optimization;decentralized parallel SGD;population protocols,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;480;-1,m;m,NAN,NAN,y
ICLR,2020,Wide Neural Networks are Interpolating Kernel Methods: Impact of Initialization on Generalization,Manuel Nonnenmacher;David Reeb;Ingo Steinwart,manuel.nonnenmacher@de.bosch.com;david.reeb@de.bosch.com;ingo.steinwart@mathematik.uni-stuttgart.de,1;1;6;3,,Reject,0,5,0,yes,9/25/19,Bosch;Bosch;University of Stuttgart,overparametrization;generalization;initialization;gradient descent;kernel methods;deep learning theory,-1;-1;118,297;297;292,m;m,europe,de,y
ICLR,2020,Improved Mutual Information Estimation,Youssef Mroueh*;Igor Melnyk*;Pierre Dognin*;Jerret Ross*;Tom Sercu*,mroueh@us.ibm.com;igor.melnyk@ibm.com;pdognin@us.ibm.com;rossja@us.ibm.com;tom.sercu@gmail.com,1;3;3;6,,Reject,0,7,0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;Facebook,mutual information;variational bound;kernel methods;Neural estimators;mutual information maximization;self-supervised learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Confidence Scores Make Instance-dependent Label-noise Learning Possible,Antonin Berthon;Bo Han;Gang Niu;Tongliang Liu;Masashi Sugiyama,berthon.antonin@gmail.com;bo.han@riken.jp;gang.niu@riken.jp;tongliang.liu@sydney.edu.au;sugi@k.u-tokyo.ac.jp,8;1;8,,Reject,0,10,0,yes,9/25/19,RIKEN;RIKEN;RIKEN;University of Sydney;The University of Tokyo,Instance-dependent label noise;Deep learning,-1;-1;-1;64;64,-1;-1;-1;60;36,m;m,NAN,NAN,n
ICLR,2020,Is Deep Reinforcement Learning Really Superhuman on Atari? Leveling the playing field,Marin Toromanoff;Emilie Wirbel;Fabien Moutarde,marin.toromanoff@mines-paristech.fr;emilie.wirbel@valeo.com;fabien.moutarde@mines-paristech.fr,6;3;3,,Reject,0,8,0,yes,9/25/19,Mines ParisTech;Valeo;Mines ParisTech,Reinforcement Learning;Deep Learning;Atari benchmark;Reproducibility,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Bilingual Generative Transformer for Semantic Sentence Embedding,John Wieting;Graham Neubig;Taylor Berg-Kirkpatrick,jwieting@cs.cmu.edu;gneubig@cs.cmu.edu;tberg@eng.ucsd.edu,3;6;3,,Reject,0,5,0,yes,9/25/19,"Carnegie Mellon University;Carnegie Mellon University;University of California, San Diego",sentence embedding;semantic similarity;multilingual;latent variables;vae,1;1;-1,27;27;31,m;m,usa,usa,n
ICLR,2020,TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph,Feiliang Ren,renfeiliang@cse.neu.edu.cn,1;1;3,,Reject,0,3,0,yes,9/25/19,Northeastern University,Chinese knowledge graph building,16,906,m;m,usa,usa,n
ICLR,2020,Wasserstein Adversarial Regularization (WAR) on label noise,Bharath Damodaran;Kilian Fatras;Sylvain Lobry;R√©mi Flamary;Devis Tuia;Nicolas Courty,bharath-bhushan.damodaran@irisa.fr;kilian.fatras@irisa.fr;sylvain.lobry@wur.nl;remi.flamary@unice.fr;devis.tuia@wur.nl;ncourty@irisa.fr,8;3;6,,Reject,0,5,0,yes,9/25/19,IRISA;IRISA;Uni Wageningen;Universit√© C√¥te d'Azur;Uni Wageningen;IRISA,Label Noise;Adversarial regularization;Wasserstein,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,europe,fr,y
ICLR,2020,Enhancing the Transformer with explicit relational encoding for math problem solving,Imanol Schlag;Paul Smolensky;Roland Fernandez;Nebojsa Jojic;J√ºrgen Schmidhuber;Jianfeng Gao,imanol@idsia.ch;paul.smolensky@gmail.com;rfernand@microsoft.com;jojic@microsoft.com;juergen@idsia.ch;jfgao@microsoft.com,3;6;6,,Reject,1,4,0,yes,9/25/19,IDSIA;Microsoft;Microsoft;Microsoft;IDSIA;Microsoft,Tensor Product Representation;Transformer;Mathematics Dataset;Attention,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Constant Curvature Graph Convolutional Networks,Gregor Bachmann;Gary B√©cigneul;Octavian-Eugen Ganea,gregorb@student.ethz.ch;garyb@mit.edu;oct@mit.edu,1;8;6,,Reject,0,5,0,yes,9/25/19,Swiss Federal Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,graph convolutional neural networks;hyperbolic spaces;gyrvector spaces;riemannian manifolds;graph embeddings,-1;5;5,-1;5;5,m;m,usa,usa,y
ICLR,2020,Plan2Vec: Unsupervised Representation Learning by Latent Plans,Ge Yang;Amy Zhang;Ari Morcos;Joelle Pineau;Pieter Abbeel;Roberto Calandra,yangge1987@gmail.com;amyzhang2011@gmail.com;arimorcos@gmail.com;jpineau@cs.mcgill.ca;pabbeel@cs.berkeley.edu;rcalandra@fb.com,3;1;1,,Reject,0,5,0,yes,9/25/19,Massachusetts Institute of Technology;University of California Berkeley;Facebook;McGill University;University of California Berkeley;Facebook,Unsupervised Learning;Reinforcement Learning;Manifold Learning,-1;-1;-1;102;-1;-1,-1;13;-1;42;13;-1,m;m,NAN,NAN,n
ICLR,2020,Generating Dialogue Responses From A Semantic Latent Space,Wei-Jen Ko;Avik Ray;Yilin Shen;Hongxia Jin,wjko@outlook.com;avik.r@samsung.com;yilin.shen@samsung.com;hongxia.jin@samsung.com,3;3;3,,Reject,0,3,1,yes,9/25/19,"University of Texas, Austin;Samsung;Samsung;Samsung",dialog;chatbot;open domain conversation;CCA,-1;-1;-1;-1,-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Learning Key Steps to Attack Deep Reinforcement Learning Agents,Chien-Min Yu;Hsuan-Tien Lin,r07922080@csie.ntu.edu.tw;htlin@csie.ntu.edu.tw,3;3;1,,Reject,0,4,0,yes,9/25/19,Nanyang Technological University;Nanyang Technological University,deep reinforcement learning;adversarial attacks,43;43,49;49,m;m,asia,sg,n
ICLR,2020,"If MaxEnt RL is the Answer, What is the Question?",Benjamin Eysenbach;Sergey Levine,beysenba@cs.cmu.edu;svlevine@eecs.berkeley.edu,8;3;3,,Reject,0,14,0,yes,9/25/19,Carnegie Mellon University;University of California Berkeley,reinforcement learning;maximum entropy;POMDP,1;-1,27;13,m;m,usa,usa,y
ICLR,2020,Learning to Control Latent Representations for Few-Shot Learning of Named Entities,Omar U. Florez;Erik Mueller,omar.florez@aggiemail.usu.edu;erikmueller@capitalone.com,3;1;1,,Reject,0,0,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Capital One Bank,Memory management;neuroscience;reinforcement learning;learning with small data,-1;-1,299;-1,m;m,NAN,NAN,n
ICLR,2020,Variational Hyper RNN for Sequence Modeling,Ruizhi Deng;Yanshuai Cao;Bo Chang;Leonid Sigal;Greg Mori;Marcus Brubaker,ruizhid@sfu.ca;yanshuaicao@gmail.com;bchang@stat.ubc.ca;lsigal@cs.ubc.ca;mori@cs.sfu.ca;marcus.brubaker@borealisai.com,6;6;6,,Reject,0,9,0,yes,9/25/19,Simon Fraser University;;University of British Columbia;University of British Columbia;Simon Fraser University;Borealis AI,variational autoencoder;hypernetwork;recurrent neural network;time series,52;-1;64;64;52;-1,272;-1;34;34;272;-1,m;m,NAN,NAN,n
ICLR,2020,Weighted Empirical Risk Minimization: Transfer Learning based on Importance Sampling,Robin Vogel;Mastane Achab;Charles Tillier;St√©phan Cl√©men√ßon,robin.vogel@telecom-paris.fr;mastane.achab@telecom-paris.fr;charles.tillier@telecom-paris.fr;stephan.clemencon@telecom-paris.fr,3;3;3,,Reject,0,4,0,yes,9/25/19,T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris,statistical learning theory;importance sampling;positive unlabeled (PU) learning;selection bias,-1;-1;-1;-1,187;187;187;187,f;m,NAN,NAN,y
ICLR,2020,Provenance detection through learning transformation-resilient watermarking,Jamie Hayes;Krishnamurthy Dvijotham;Yutian Chen;Sander Dieleman;Pushmeet Kohli;Norman Casagrande,j.hayes@cs.ucl.ac.uk;dvij@google.com;yutianc@google.com;sedielem@google.com;pushmeet@google.com;ncasagrande@google.com,1;6;8,,Reject,0,3,0,yes,9/25/19,University College London;Google;Google;Google;Google;Google,watermarking;provenance detection,52;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Underwhelming Generalization Improvements From Controlling Feature Attribution,Joseph D Viviano;Becks Simpson;Francis Dutil;Yoshua Bengio;Joseph Paul Cohen,joseph@viviano.ca;becks.simpson@imagia.com;francis.dutil@imagia.com;yoshua.bengio@mila.quebec;joseph@josephpcohen.com,3;3;3,,Reject,0,3,0,yes,9/25/19,University of Montreal;Imagia;Imagia;Mila;Stanford University,interpretability;medical;generalization;saliency,118;-1;-1;143;5,85;-1;-1;336;4,m;m,usa,usa,n
ICLR,2020,Combining graph and sequence information to learn protein representations,Hassan Kan√©;Mohamed Coulibali;Pelkins Ajanoh;Ali Abdalla,hassanmohamed@alum.mit.edu;mohamed-konoufo.coulibali.1@ulaval.ca;pelkins@alum.mit.edu;aabdalla@alum.mit.edu,1;1;3,,Reject,0,0,0,yes,9/25/19,Massachusetts Institute of Technology;Laval university;Massachusetts Institute of Technology;Massachusetts Institute of Technology,NLP;Protein;Representation Learning,5;-1;5;5,5;272;5;5,m;m,usa,usa,n
ICLR,2020,Sensible adversarial learning,Jungeum Kim;Xiao Wang,kim2712@purdue.edu;wangxiao@purdue.edu,3;6;8,,Reject,2,9,0,yes,9/25/19,Purdue University;Purdue University,adversarial learning;deep neural networks;trade-off;margins;sensible reversion;sensible robustness,24;24,88;88,m;m,usa,usa,y
ICLR,2020,YaoGAN: Learning Worst-case Competitive Algorithms from Self-generated Inputs,Goran Zuzic;Di Wang;Aranyak Mehta;D. Sivakumar,zuza777@gmail.com;wadi@google.com;aranyak@google.com;siva@google.com,6;3;3,,Reject,0,8,0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Remember from a Multi-Task Teacher,Yuwen Xiong;Mengye Ren;Raquel Urtasun,yuwen@cs.toronto.edu;mren@cs.toronto.edu;urtasun@uber.com,1;3;8,,Reject,0,6,0,yes,9/25/19,University of Toronto;University of Toronto;Uber,Meta-learning;sequential learning;catastrophic forgetting,18;18;-1,18;18;-1,m;f,southamerica,br,n
ICLR,2020,Pretraining boosts out-of-domain robustness for pose estimation,Alexander Mathis;Mert Y√ºksekg√∂n√ºl;Byron Rogers;Matthias Bethge;Mackenzie W. Mathis,amathis@fas.harvard.edu;mertyuksekgonul@gmail.com;byron@performancegenetics.com;matthias.bethge@uni-tuebingen.de;mathis@rowland.harvard.edu,1;1,,Reject,1,3,0,yes,9/25/19,Harvard University;Bogazici University;Performancegenetics;University of Tuebingen;Harvard University,pose estimation;robustness;out-of-domain;transfer learning,52;316;-1;143;52,7;672;-1;91;7,m;f,usa,usa,n
ICLR,2020,Self-Induced Curriculum Learning in Neural Machine Translation,Dana Ruiter;Cristina Espa√±a-Bonet;Josef van Genabith,druiter@lsv.uni-saarland.de;cristinae@dfki.de;josef.van_genabith@dfki.de,6;3;1,,Reject,0,4,0,yes,9/25/19,Saarland University;German Research Center for AI;German Research Center for AI,curriculum learning;neural machine translation;self-supervised learning,92;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Adapt-to-Learn: Policy Transfer in Reinforcement Learning,Girish Joshi;Girish Chowdhary,girishj2@illinois.edu;girishc@illinois.edu,1;6;6,,Reject,0,1,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Transfer Learning;Reinforcement Learning;Adaptation,-1;-1,-1;-1,m;m,usa,usa,n
ICLR,2020,The Surprising Behavior Of Graph Neural Networks,Vivek Kothari;Catherine Tong;Nicholas Lane,vivek.kothari@cs.ox.ac.uk;eu.tong@cs.ox.ac.uk;nicholas.lane@cs.ox.ac.uk,6;3;1,,Reject,0,4,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,Graph Neural Networks;Graph Toplogy;Noise;Attributed Networks,46;46;46,1;1;1,m;m,europe,uk,n
ICLR,2020,On the Reflection of Sensitivity in the Generalization Error,Mahsa Forouzesh;Farnood Salehi;Patrick Thiran,mahsa.forouzesh@epfl.ch;farnood.salehi@epfl.ch;patrick.thiran@epfl.ch,3;3,,Reject,0,5,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Generalization Error;Sensitivity Analysis;Deep Neural Networks;Bias-variance Decomposition,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Bio-Inspired Hashing for Unsupervised Similarity Search,Chaitanya K. Ryali;John J. Hopfield;Dmitry Krotov,rckrishn@eng.ucsd.edu;hopfield@princeton.edu;krotov@ibm.com,6;6;3,,Reject,0,0,1,yes,9/25/19,"University of California, San Diego;Princeton University;International Business Machines",unsupervised learning;similarity search;neuroscience,-1;30;-1,31;6;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Program Synthesis By Self-Learning,Yifan Xu;Lu Dai;Udaikaran Singh;Kening Zhang;Zhuowen Tu,yix081@ucsd.edu;dldaisy@mail.ustc.edu.cn;u1singh@ucsd.edu;kez040@ucsd.edu;ztu@ucsd.edu,3;1;3,,Reject,0,3,2,yes,9/25/19,"University of California, San Diego;University of Science and Technology of China;University of California, San Diego;University of California, San Diego;University of California, San Diego",Neural Program Synthesis;Reinforcement Learning;Deep learning;Self-Learning,-1;-1;-1;-1;-1,31;80;31;31;31,m;m,usa,usa,n
ICLR,2020,The Variational InfoMax AutoEncoder,Vinenzo Crescimanna;Bruce Graham,vincenzo.crescimanna1@stir.ac.uk;bruce.graham@stir.ac.uk,3;6;1,,Reject,0,3,0,yes,9/25/19,University of Stirling;University of Stirling,autoencoder;information theory;infomax;vae,-1;-1,350;350,m;m,NAN,NAN,n
ICLR,2020,Neural Network Out-of-Distribution Detection for Regression Tasks,Geoff Pleiss;Amauri Souza;Joseph Kim;Boyi Li;Kilian Q. Weinberger,geoff@cs.cornell.edu;ahd64@cornell.edu;jk2569@cornell.edu;bl728@cornell.edu;kqw4@cornell.edu,3;3;1;1,,Reject,0,5,0,yes,9/25/19,Cornell University;Cornell University;Cornell University;Cornell University;Cornell University,Out-of-distribution;deep learning;regression,7;7;7;7;7,19;19;19;19;19,m;m,usa,usa,n
ICLR,2020,Stein Self-Repulsive Dynamics: Benefits from Past Samples,Mao Ye;Tongzheng Ren;Qiang Liu,lushleaf21@gmail.com;rtz19970824@gmail.com;lqiang@cs.utexas.edu,6;3;6,,Reject,0,8,0,yes,9/25/19,"University of Texas, Austin;;University of Texas, Austin",Approximate Inference;Markov Chain Monte Carlo;Stein Variational Gradient Descent,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Mesh-Free Unsupervised Learning-Based PDE Solver of Forward and Inverse problems,Leah Bar;Nir Sochen,barleah.libra@gmail.com;sochen@tauex.tau.ac.il,6;3;3,,Reject,0,5,0,yes,9/25/19,Tel Aviv University;Tel Aviv University,PDEs;forward problems;inverse problems;unsupervised learning;deep networks;EIT,30;30,188;188,f;m,europe,il,n
ICLR,2020,Gaussian Conditional Random Fields for Classification,Andrija Petrovic;Mladen Nikolic;Milos Jovanovic;Boris Delibasic,aapetrovic@mas.bg.ac.rs;nikolic@matf.bg.ac.rs;milos.jovanovic@fon.bg.ac.rs;boris.delibasic@fon.bg.ac.rs,1;6;6,,Reject,0,4,0,yes,9/25/19,University of Belgrade - Faculty of Organizational Sciences;University of Belgrade - Faculty of Organizational Sciences;University of Belgrade - Faculty of Organizational Sciences;University of Belgrade - Faculty of Organizational Sciences,Structured classification;Gaussian conditional random fields;Empirical Bayes;Local variational approximation;discriminative graph-based model,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Visual Hide and Seek,Boyuan Chen;Shuran Song;Hod Lipson;Carl Vondrick,bchen@cs.columbia.edu;shurans@cs.columbia.edu;hod.lipson@columbia.edu;vondrick@cs.columbia.edu,3;3;8,,Reject,0,6,0,yes,9/25/19,Columbia University;Columbia University;Columbia University;Columbia University,Embodied Learning;Self-supervised Learning;Reinforcement Learning,24;24;24;24,16;16;16;16,m;m,usa,usa,n
ICLR,2020,Supervised learning with incomplete data via sparse representations,Cesar F. Caiafa;Ziyao Wang;Jordi Sol√©-Casals;Qibin Zhao,ccaiafa@gmail.com;zy_wang@seu.edu.cn;jordi.sole@uvic.cat;qibin.zhao@riken.jp,6;6;1,,Reject,0,4,0,yes,9/25/19,CONICET;Southeast University;University of Victoria;RIKEN,Incomplete data;supervised learning;sparse representations,-1;-1;194;-1,-1;570;449;-1,m;m,NAN,NAN,y
ICLR,2020,Transfer Active Learning For Graph Neural Networks,Shengding Hu;Meng Qu;Zhiyuan Liu;Jian Tang,hsd16@mails.tsinghua.edu.cn;meng.qu@umontreal.ca;liuzy@tsinghua.edu.cn;jian.tang@hec.ca,3;3;3,,Reject,0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;University of Montreal;Tsinghua University, Tsinghua University;HEC Montreal",Active Learning;Graph Neural Networks;Transfer Learning;Reinforcement Learning,4;118;4;-1,23;85;23;-1,m;m,canada,ca,n
ICLR,2020,Equivariant Entity-Relationship Networks,Devon Graham;Siamak Ravanbakhsh,drgraham@cs.ubc.ca;siamak@cs.mcgill.ca,3;3;3;8;3,,Reject,0,11,0,yes,9/25/19,University of British Columbia;McGill University,deep learning;relational model;knowledge graph;exchangeability;equivariance,64;102,34;42,m;m,canada,ca,y
ICLR,2020,Assessing Generalization in TD methods for Deep Reinforcement Learning,Emmanuel Bengio;Doina Precup;Joelle Pineau,bengioe@gmail.com;dprecup@cs.mcgill.ca;jpineau@cs.mcgill.ca,3;6;6,,Reject,0,5,0,yes,9/25/19,McGill University;McGill University;McGill University,reinforcement learning;deep learning;generalization,102;102;102,42;42;42,m;f,canada,ca,n
ICLR,2020,Chordal-GCN: Exploiting sparsity in training large-scale graph convolutional networks,Xin Jiang*;Kewei Cheng*;Song Jiang*;Yizhou Sun,jiangxjames@ucla.edu;viviancheng@cs.ucla.edu;songjiang@cs.ucla.edu;yzsun@cs.ucla.edu,6;1;3,,Reject,0,4,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",graph convolutional network;semi-supervised learning,-1;-1;-1;-1,17;17;17;17,m;f,usa,usa,n
ICLR,2020,Certifying Distributional Robustness using Lipschitz Regularisation,Zac Cranko;Zhan Shi;Xinhua Zhang;Simon Kornblith;Richard Nock,zac.cranko@anu.edu.au;zshi22@uic.edu;zhangx@uic.edu;skornblith@google.com;richard.nock@data61.csiro.au,6;3;6,,Reject,0,6,0,yes,9/25/19,"Australian National University;University of Illinois, Chicago;University of Illinois, Chicago;Google;CSIRO",kernel method;adversarial learning;distributionally robust optimization,102;-1;-1;-1;-1,50;-1;-1;-1;-1,m;m,asia,in,y
ICLR,2020,"Continuous Control with Contexts, Provably",Simon Du;Mengdi Wang;Ruosong Wang;Lin F. Yang,ssdu@ias.edu;mengdiw@princeton.edu;ruosongw@andrew.cmu.edu;linyang@ee.ucla.edu,3;1;6,,Reject,0,5,0,yes,9/25/19,"Institue for Advanced Study, Princeton;Princeton University;Carnegie Mellon University;University of California, Los Angeles",continuous control;learning;context,-1;30;1;-1,-1;6;27;17,m;m,usa,usa,y
ICLR,2020,Using Hindsight to Anchor Past Knowledge in Continual Learning,Arslan Chaudhry;Albert Gordo;David Lopez-Paz;Puneet K. Dokania;Philip Torr,arslan.chaudhry@eng.ox.ac.uk;agordo@fb.com;david@lopezpaz.org;puneet@robots.ox.ac.uk;philip.torr@eng.ox.ac.uk,6;6;6,,Reject,2,5,1,yes,9/25/19,University of Oxford;Facebook;Facebook;University of Oxford;University of Oxford,Continual Learning;Lifelong Learning;Catastrophic Forgetting,46;-1;-1;46;46,1;-1;-1;1;1,m;m,europe,uk,n
ICLR,2020,Solving single-objective tasks by preference multi-objective reinforcement learning,Jinsheng Ren;Shangqi Guo;Feng Chen,rjs17@mails.tsinghua.edu.cn;gsq15@mails.tsinghua.edu.cn;chenfeng@mail.tsinghua.edu.cn,3;1,,Reject,0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",reinforcement learning;single-objective tasks;multi-objectivization,4;4;4,23;23;23,m;m,NAN,NAN,y
ICLR,2020,Transfer Alignment Network for Double Blind Unsupervised Domain Adaptation,Huiwen Xu;U Kang,xuhuiwen33@gmail.com;ukang@snu.ac.kr,1;1;1,,Reject,0,3,0,yes,9/25/19,Seoul National University;Seoul National University,unsupervised domain adaptation;double blind domain adaptation,39;39,64;64,m;m,asia,kr,n
ICLR,2020,Policy Optimization by Local Improvement through Search,Jialin Song;Joe Wenjie Jiang;Amir Yazdanbakhsh;Ebrahim Songhori;Anna Goldie;Navdeep Jaitly;Azalia Mirhoseini,jssong@caltech.edu;wenjiej@google.com;ayazdan@google.com;esonghori@google.com;agoldie@google.com;ndjaitly@google.com;azalia@google.com,3;3;1,,Reject,0,3,0,yes,9/25/19,California Institute of Technology;Google;Google;Google;Google;Google;Google,policy learning;imitation learning,143;-1;-1;-1;-1;-1;-1,2;-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,y
ICLR,2020,Regularly varying representation for sentence embedding,Hamid Jalalzai;Pierre Colombo;Chlo√© Clavel;Eric Gaussier;Giovanna Varni;Emmanuel Vignon;Anne Sabourin,hamid.jalalzai@telecom-paris.fr;pierre.colombo@telecom-paris.fr;chloe.clavel@telecom-paris.fr;giovanna.varni@telecom-paris.fr;emmanuel.vignon@fr.ibm.com;anne.sabourin@telecom-paris.fr,3;1;3,,Reject,0,3,0,yes,9/25/19,T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris;T√©l√©com Paris;International Business Machines;T√©l√©com Paris,extreme value theory;classification;supvervised learning;data augmentation;representation learning,-1;-1;-1;-1;-1;-1,187;187;187;187;-1;187,m;f,NAN,NAN,y
ICLR,2020,Statistical Verification of General Perturbations by Gaussian Smoothing,Marc Fischer;Maximilian Baader;Martin Vechev,marcfisc@student.ethz.ch;mbaader@inf.ethz.ch;martin.vechev@inf.ethz.ch,3;3;3,,Reject,0,4,1,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,adversarial robustness;certified network;randomised smoothing;geometric perturbations,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Learning to Anneal and Prune Proximity Graphs for Similarity Search,Minjia Zhang;Wenhan Wang;Yuxiong He,minjiaz@microsoft.com;wenhanw@microsoft.com;yuxhe@microsoft.com,6;6;8,,Reject,0,4,0,yes,9/25/19,Microsoft;Microsoft;Microsoft,Similarity search;Proximity graph;Learning to prune;Edge heterogeneity;Annealing;Efficiency,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport,Tengfei Ma;Jie Chen,tengfei.ma1@ibm.com;chenjie@us.ibm.com,3;6;6,,Reject,0,6,0,yes,9/25/19,International Business Machines;International Business Machines,Unsupervised learning;hierarchical representation learning;graph neural networks,-1;-1,-1;-1,m;f,NAN,NAN,y
ICLR,2020,Bayesian Variational Autoencoders for Unsupervised Out-of-Distribution Detection,Erik Daxberger;Jos√© Miguel Hern√°ndez-Lobato,ead54@cam.ac.uk;jmh233@cam.ac.uk,3;3;3,,Reject,0,6,0,yes,9/25/19,University of Cambridge;University of Cambridge,variational autoencoders;out-of-distribution detection;stochastic gradient MCMC,79;79,3;3,m;m,europe,uk,n
ICLR,2020,Robust Instruction-Following in a Situated Agent via Transfer-Learning from Text,Felix Hill;Sona Mokra;Nathaniel Wong;Tim Harley,felixhill@google.com;sonka@google.com;nathanielwong@google.com;tharley@google.com,3;3;6,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google,agent;language;3D;simulation;policy;instruction;transfer,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Fully Polynomial-Time Randomized Approximation Schemes for Global Optimization of High-Dimensional Folded Concave Penalized Generalized Linear Models,Charles Hernandez;Hungyi Lee;Hongchen Liu,cdhernandez@ufl.edu;hungyilee@ufl.edu;hliu@ise.ufl.edu,3;3;8,,Reject,0,3,0,yes,9/25/19,University of Florida;University of Florida;University of Florida,statistical learning;FPRAS;global optimization;folded concave penalty;GLM;high dimensional learning,168;168;168,174;174;174,m;m,usa,usa,y
ICLR,2020,MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS,Ronan Perry;Tyler M. Tomita;Jesse Patsolic;Benjamin Falk;Joshua Vogelstein,rperry27@jhu.edu;ttomita2@jhmi.edu;jpatsolic@jhu.edu;falk.ben@jhu.edu;jovo@jhu.edu,3;3;1,,Reject,0,0,0,yes,9/25/19,Johns Hopkins University;;Johns Hopkins University;Johns Hopkins University;Johns Hopkins University,machine learning;structured learning;projections;structured data;images;classification,73;-1;73;73;73,12;-1;12;12;12,m;m,usa,usa,n
ICLR,2020,Granger Causal Structure Reconstruction from Heterogeneous Multivariate Time Series,Yunfei Chu;Xiaowei Wang;Chunyan Feng;Jianxin Ma;Jingren Zhou;Hongxia Yang,yfchu@bupt.edu.cn;daemon.wxw@alibaba-inc.com;cyfeng@bupt.edu.cn;jason.mjx@alibaba-inc.com;jingren.zhou@alibaba-inc.com;yang.yhx@alibaba-inc.com,3;8;6,,Reject,0,4,0,yes,9/25/19,Beijing University of Post and Telecommunication;Alibaba Group;Beijing University of Post and Telecommunication;Alibaba Group;Alibaba Group;Alibaba Group,causal inference;Granger causality;time series;inductive;LSTM;attention,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Towards Disentangling Non-Robust and Robust Components in Performance Metric,Yujun Shi;Benben Liao;Guangyong Chen;Yun Liu;Ming-ming Cheng;Jiashi Feng,shiyujun1016@gmail.com;bliao@tencent.com;gycchen@tencent.com;nk12csly@mail.nankai.edu.cn;cmm@nankai.edu.cn;elefjia@nus.edu.sg,1;1;3,,Reject,0,5,0,yes,9/25/19,National University of Singapore;Tencent AI Lab;Tencent AI Lab;Nankai University;Nankai University;National University of Singapore,adversarial examples;robust machine learning,17;-1;-1;-1;-1;17,25;-1;-1;366;366;25,m;m,asia,sg,y
ICLR,2020,Distributed Training Across the World,Ligeng Zhu;Yao Lu;Yujun Lin;Song Han,ligeng@mit.edu;luyao11175@gmail.com;yujunlin@mit.edu;songhan@mit.edu,3;3;6,,Reject,0,7,0,yes,9/25/19,Massachusetts Institute of Technology;;Massachusetts Institute of Technology;Massachusetts Institute of Technology,Distributed Training;Bandwidth,5;-1;5;5,5;-1;5;5,m;m,usa,usa,n
ICLR,2020,Risk Averse Value Expansion for Sample Efficient and Robust Policy Learning,Bo Zhou;Fan Wang;Hongsheng Zeng;Hao Tian,zhoubo01@baidu.com;wangfan04@baidu.com;zenghongsheng@baidu.com;tianhao@baidu.com,3;3;6;3,,Reject,0,4,0,yes,9/25/19,Baidu;Baidu;Baidu;Baidu,reinforcement learning;model-based RL;risk-sensitive;sample efficiency,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,MANAS: Multi-Agent Neural Architecture Search,Fabio Maria Carlucci;Pedro M Esperan√ßa;Marco Singh;Victor Gabillon;Antoine Yang;Hang Xu;Zewei Chen;Jun Wang,fabiom.carlucci@gmail.com;pedro.esperanca@huawei.com;marco.singh@huawei.com;victor.gabillon@huawei.com;antoineyang3@gmail.com;xu.hang@huawei.com;chen.zewei@huawei.com;w.j@huawei.com,6;3;6,,Reject,0,4,0,yes,9/25/19,Facebook;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Neural Architecture Search;NAS;AutoML;Computer Vision,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Neural Architecture Search by Learning Action Space for Monte Carlo Tree Search,Linnan Wang;Saining Xie;Teng Li;Rodrigo Fonseca;Yuandong Tian,linnan_wang@brown.edu;s9xie@fb.com;yuandong@fb.com;tengli@fb.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Brown University;Facebook;Facebook;Facebook,MCTS;Neural Architecture Search;Search,85;-1;-1;-1,53;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,A multi-task U-net for segmentation with lazy labels,Rihuan Ke;Aur√©lie Bugeau;Nicolas Papadakis;Peter Schuetz;Carola-Bibiane Sch√∂nlieb,rk621@cam.ac.uk;aurelie.bugeau@labri.fr;nicolas.papadakis@math.u-bordeaux.fr;peter.schuetz@unilever.com;cbs31@cam.ac.uk,6;6;1,,Reject,0,7,0,yes,9/25/19,University of Cambridge;LaBRI;University of Bordeaux;Unilever;University of Cambridge,multi-task learning;weak labels;semisupervised learning;image segmentation,79;-1;-1;-1;79,3;646;430;-1;3,m;f,europe,uk,n
ICLR,2020,Deep automodulators,Ari Heljakka;Yuxin Hou;Juho Kannala;Arno Solin,ari.heljakka@aalto.fi;yuxin.hou@aalto.fi;arno.solin@aalto.fi;juho.kannala@aalto.fi,3;3;6,,Reject,0,4,0,yes,9/25/19,Aalto University;Aalto University;Aalto University;Aalto University,unsupervised learning;generative models;autoencoders;disentanglement;style transfer,118;118;118;118,182;182;182;182,m;m,europe,dk,n
ICLR,2020,Towards Certified Defense for Unrestricted Adversarial Attacks,Shengjia Zhao;Yang Song;Stefano Ermon,sjzhao@stanford.edu;yangsong@cs.stanford.edu;ermon@cs.stanford.edu,1;3;3,,Reject,0,1,0,yes,9/25/19,Stanford University;Stanford University;Stanford University,Adversarial Defense;Certified Defense;Adversarial Examples,5;5;5,4;4;4,m;m,usa,usa,y
ICLR,2020,Best feature performance in codeswitched hate speech texts,Edward Ombui;Lawrence Muchemi;Peter Wagacha,eombui@anu.ac.ke;lmuchemi@uonbi.ac.ke;waiganjo@uonbi.ac.ke,3;1;1,,Reject,0,0,0,yes,9/25/19,Africa Nazarene University;University of Nairobi;University of Nairobi,Hate Speech;Code-switching;feature selection;representation learning,-1;-1;-1,-1;871;871,m;m,NAN,NAN,n
ICLR,2020,Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination,Shauharda Khadka;Somdeb Majumdar;Santiago Miret;Stephen McAleer;Kagan Tumer,shauharda.khadka@intel.com;somdeb.majumdar@intel.com;santiago.miret@intel.com;smcaleer@uci.edu;kagan.tumer@oregonstate.edu,1;6;8,,Reject,0,5,0,yes,9/25/19,"Intel;Intel;Intel;University of California, Irvine;Oregon State University",reinforcement learning;multiagent;neuroevolution,-1;-1;-1;-1;79,-1;-1;-1;96;373,m;m,usa,usa,n
ICLR,2020,Gaussian Process Meta-Representations Of Neural Networks,Theofanis Karaletsos;Thang Bui,theofanis.karaletsos@gmail.com;thang.buivn@gmail.com,6;6;6,,Reject,0,12,1,yes,9/25/19,Facebook;University of Sydney,Bayesian Neural Networks;Representation Learning;Gaussian Processes;Variational Inference,-1;64,-1;60,m;m,europe,uk,n
ICLR,2020,Training Deep Neural Networks with Partially Adaptive Momentum,Jinghui Chen;Dongruo Zhou;Yiqi Tang;Ziyan Yang;Yuan Cao;Quanquan Gu,jc4zg@virginia.edu;drzhou@cs.ucla.edu;yt6ze@virginia.edu;zy3cx@virginia.edu;yuanc@princeton.edu;qgu@cs.ucla.edu,1;6;3,,Reject,0,3,0,yes,9/25/19,"University of Virginia;University of California, Los Angeles;University of Virginia;University of Virginia;Princeton University;University of California, Los Angeles",,52;-1;52;52;30;-1,107;17;107;107;6;17,m;m,usa,usa,y
ICLR,2020,Scalable Deep Neural Networks via Low-Rank Matrix Factorization,Atsushi Yaguchi;Taiji Suzuki;Shuhei Nitta;Yukinobu Sakata;Akiyuki Tanizawa,atsushi.yaguchi@toshiba.co.jp;taiji@mist.i.u-tokyo.ac.jp;shuhei.nitta@toshiba.co.jp;yuki.sakata@toshiba.co.jp;akiyuki.tanizawa@toshiba.co.jp,3;1;1,,Reject,1,4,0,yes,9/25/19,Toshiba Corporation;The University of Tokyo;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation,Deep Learning;Deep Neural Networks;Low-Rank Matrix Factorization;Model Compression,-1;64;-1;-1;-1,-1;36;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Antifragile and Robust Heteroscedastic Bayesian Optimisation,Ryan Rhys-Griffiths;Miguel Garcia-Ortegon;Alexander A. Aldrick;Alpha A. Lee,rrg27@cam.ac.uk;mg770@cam.ac.uk;av495@cam.ac.uk;aal44@cam.ac.uk,3;1;1,,Reject,0,1,0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge,Bayesian Optimisation;Gaussian Processeses;Heteroscedasticity,79;79;79;79,3;3;3;3,m;m,europe,uk,n
ICLR,2020,Compressed Sensing with Deep Image Prior and Learned Regularization,Dave Van Veen;Ajil Jalal;Mahdi Soltanolkotabi;Eric Price;Sriram Vishwanath;Alexandros G. Dimakis,davemvanveen@gmail.com;ajiljalal@utexas.edu;soltanol@usc.edu;ecprice@cs.utexas.edu;sriram@austin.utexas.edu;dimakis@austin.utexas.edu,3;6;6;6,,Reject,0,0,0,yes,9/25/19,"University of Texas, Austin;University of Texas, Austin;University of Southern California;University of Texas, Austin;University of Texas, Austin;University of Texas, Austin",compressed sensing;sparsity;inverse problems,-1;-1;36;-1;-1;-1,-1;-1;62;-1;-1;-1,m;m,usa,usa,y
ICLR,2020,Unsupervised Hierarchical Graph Representation Learning with Variational Bayes,Shashanka Ubaru;Jie Chen,shashanka.ubaru@ibm.com;chenjie@us.ibm.com,3;6;3,,Reject,0,4,0,yes,9/25/19,International Business Machines;International Business Machines,Hierarchical Graph Representation;Unsupervised Graph Learning;Variational Bayes;Graph classification,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,Learning Algorithmic Solutions to Symbolic Planning Tasks with a Neural Computer,Daniel Tanneberg;Elmar Rueckert;Jan Peters,daniel@robot-learning.de;rueckert@rob.uni-luebeck.de;mail@jan-peters.net,6;6;3,,Reject,0,5,0,yes,9/25/19,TU Darmstadt;Universit‚àö¬ßt zu L‚àö¬∫beck;TU Darmstadt,,-1;-1;59,-1;-1;-1,m;m,europe,de,n
ICLR,2020,Multi-Step Decentralized Domain Adaptation,Akhil Mathur;Shaoduo Gan;Anton Isopoussu;Fahim Kawsar;Nadia Berthouze;Nicholas D. Lane,akhilmathurs@gmail.com;sgan@inf.ethz.ch;anton.isopoussu@gmail.com;fahim.kawsar@gmail.com;nadia.berthouze@gmail.com;nicholasd.lane@gmail.com,6;3;3;6,,Reject,0,7,0,yes,9/25/19,University College London;Swiss Federal Institute of Technology;;;;University of Oxford,domain adaptation;decentralization,-1;-1;-1;-1;-1;46,-1;-1;-1;-1;-1;1,m;m,europe,uk,n
ICLR,2020,Robust saliency maps with distribution-preserving decoys,Yang Young Lu;Wenbo Guo;Xinyu Xing;William Stafford Noble,ylu465@uw.edu;wzg13@ist.psu.edu;xxing@ist.psu.edu;william-noble@uw.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,"University of Washington, Seattle;Pennsylvania State University;Pennsylvania State University;University of Washington, Seattle",explainable machine learning;explainable AI;deep learning interpretability;saliency maps;perturbation;convolutional neural network,11;43;43;11,26;-1;-1;26,m;m,NAN,NAN,y
ICLR,2020,Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors,Jiezhang Cao;Jincheng Li;Xiping Hu;Peilin Zhao;Mingkui Tan,secaojiezhang@mail.scut.edu.cn;sejinchengli@mail.scut.edu.cn;huxp@lzu.edu.cn;peilinzhao@hotmail.com;mingkuitan@scut.edu.cn,3;3;6,,Reject,1,4,0,yes,9/25/19,South China University of Technology;South China University of Technology;University of Science and Technology of China;;South China University of Technology,Interpretability of DNNs;Wasserstein distance;Layer behavior,-1;-1;-1;-1;-1,501;501;80;-1;501,m;m,NAN,NAN,y
ICLR,2020,Robust Graph Representation Learning via Neural Sparsification,Cheng Zheng;Bo Zong;Wei Cheng;Dongjin Song;Jingchao Ni;Wenchao Yu;Haifeng Chen;Wei Wang,chengzheng@cs.ucla.edu;bzong@nec-labs.com;weicheng@nec-labs.com;dsong@nec-labs.com;jni@nec-labs.com;yuwenchao@ucla.edu;haifeng@nec-labs.com;weiwang@cs.ucla.edu,6;1;8,,Reject,0,6,0,yes,9/25/19,"University of California, Los Angeles;NEC-Labs;NEC-Labs;NEC-Labs;NEC-Labs;University of California, Los Angeles;NEC-Labs;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1;-1;-1,17;-1;-1;-1;-1;17;-1;17,m;f,usa,usa,n
ICLR,2020,Good Semi-supervised VAE Requires Tighter Evidence Lower Bound,Haozhe Feng;Kezhi Kong;Tianye Zhang;Siyue Xue;Wei Chen,fenghz@zju.edu.cn;kong@cs.umd.edu;zhangtianye1026@zju.edu.cn;3160104527@zju.edu.cn;chenwei@cad.zju.edu.cn,3;3;3,,Reject,1,4,0,yes,9/25/19,"Zhejiang University;University of Maryland, College Park;Zhejiang University;Zhejiang University;Zhejiang University",VAE;Semi-supervised Learning;ELBO;Generative Model,39;12;39;39;39,107;91;107;107;107,m;m,asia,cn,n
ICLR,2020,EDUCE: Explaining model Decision through Unsupervised Concepts Extraction,Diane Bouchacourt;Ludovic Denoyer,dianeb@fb.com;denoyer@fb.com,6;3;8,,Reject,0,9,0,yes,9/25/19,Facebook;Facebook,Interpretability;explainability;text processing,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,Projected Canonical Decomposition for Knowledge Base Completion,Timoth√©e Lacroix;Guillaume Obozinski;Joan Bruna;Nicolas Usunier,timothee.lax@gmail.com;guillaume.obozinski@epfl.ch;bruna@cims.nyu.edu;usunier@fb.com,3;8;3,,Reject,0,4,0,yes,9/25/19,Facebook;Swiss Federal Institute of Technology Lausanne;New York University;Facebook,knowledge base completion;adagrad,-1;-1;22;-1,-1;-1;29;-1,m;m,NAN,NAN,n
ICLR,2020,Lossless Data Compression with Transformer,Gautier Izacard;Armand Joulin;Edouard Grave,gizacard@gmail.com;ajoulin@fb.com;egrave@fb.com,3;1;3,,Reject,0,3,0,yes,9/25/19,Ecole Normale Superieure;Facebook;Facebook,data compression;transformer,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Stochastically Controlled Compositional Gradient for the Composition problem,Liu Liu;Ji Liu;Cho-Jui Hsieh;Dacheng Tao,liu.liu1@sydney.edu.au;ji.liu.uwisc@gmail.com;chohsieh@cs.ucla.edu;dacheng.tao@sydney.edu.au,6;3;3,,Reject,0,3,0,yes,9/25/19,"University of Sydney;;University of California, Los Angeles;University of Sydney",Non-convex optimisation;Composition problem;Stochastically controlled compositional gradient,64;-1;-1;64,60;-1;17;60,f;m,europe,uk,y
ICLR,2020,Domain Adaptation via Low-Rank Basis Approximation,Christoph Raab;Frank-Michael Schleif,christoph.raab@fhws.de;frank-michael.schleif@fhws.de,1;3;1,,Reject,0,5,0,yes,9/25/19,University of Applied Sciences W√ºrzburg-Schweinfurt;University of Applied Sciences W√ºrzburg-Schweinfurt,Domain Adaptation;Basis Transfer;Transfer Learning;Low Rank Approximation;Nystr√∂m Approximation,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,SGD with Hardness Weighted Sampling for Distributionally Robust Deep Learning,Lucas Fidon;Sebastien Ourselin;Tom Vercauteren,lucas.fidon@kcl.ac.uk;sebastien.ourselin@kcl.ac.uk;tom.vercauteren@kcl.ac.uk,3;3;3,,Reject,0,7,0,yes,9/25/19,King's College London;King's College London;King's College London,distributionally robust optimization;distributionally robust deep learning;over-parameterized deep neural networks;deep neural networks;AI safety;hard example mining,168;168;168,36;36;36,m;m,europe,uk,y
ICLR,2020,Fast Training of Sparse Graph Neural Networks on Dense Hardware,Matej Balog;Bart van Merri√´nboer;Subhodeep Moitra;Yujia Li;Daniel Tarlow,matej.balog@gmail.com;bartvm@google.com;smoitra@google.com;yujiali@google.com;dtarlow@google.com,3;6;6,,Reject,0,12,0,yes,9/25/19,University of Cambridge;Google;Google;Google;Google,,79;-1;-1;-1;-1,3;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,CGT: Clustered Graph Transformer for Urban Spatio-temporal Prediction,Xu Geng;Lingyu Zhang;Shulin Li;Yuanbo Zhang;Lulu Zhang;Leye Wang;Qiang Yang;Hongtu Zhu;Jieping Ye,xgeng@connect.ust.hk;zhanglingyu@didiglobal.com;lishulin_i@didiglobal.com;bozhangyuanbo_i@didiglobal.com;zhanglulululu@didiglobal.com;leyewang@pku.edu.cn;qyang@cse.ust.hk;zhuhongtu@didiglobal.com;yejieping@didiglobal.com,3;3;1,,Reject,0,5,0,yes,9/25/19,The Hong Kong University of Science and Technology;Didi Chuxing;Didi Chuxing;Didi Chuxing;Didi Chuxing;Peking University;The Hong Kong University of Science and Technology;Didi Chuxing;Didi Chuxing,Unsmooth spatiotemporal forecasting;Clustered graph neural network;Graph-Transformer;Urban computing,-1;-1;-1;-1;-1;14;-1;-1;-1,47;-1;-1;-1;-1;24;47;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Regularizing Black-box Models for Improved Interpretability,Gregory Plumb;Maruan Al-Shedivat;Eric Xing;Ameet Talwalkar,gdplumb@andrew.cmu.edu;alshedivat@cs.cmu.edu;epxing@cs.cmu.edu;talwalkar@cmu.edu,6;3;1,,Reject,0,5,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Interpretable Machine Learning;Local Explanations;Regularization,1;1;1;1,27;27;27;27,m;m,usa,usa,y
ICLR,2020,AlgoNet: $C^\infty$ Smooth Algorithmic Neural Networks,Felix Petersen;Christian Borgelt;Oliver Deussen,felix.petersen@uni.kn;christian@borgelt.net;oliver.deussen@uni.kn,1;3;1,,Reject,0,0,0,yes,9/25/19,University of Konstanz;University of Salzburg;University of Konstanz,Algorithms;Smoothness;Differentiable;Inverse Problems;Adversarial Training;Neural Networks;Deep Learning;Differentiable Renderer;3D Mesh;Turing-completeness;Library,-1;248;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,CAPACITY-LIMITED REINFORCEMENT LEARNING: APPLICATIONS IN DEEP ACTOR-CRITIC METHODS FOR CONTINUOUS CONTROL,Tyler James Malloy;Matthew Riemer;Miao Liu;Tim Klinger;Gerald Tesauro;Chris R. Sims,mallot@rpi.edu;mdriemer@us.ibm.com;miao.liu1@ibm.com;tklinger@us.ibm.com;gtesauro@us.ibm.com;simsc3@rpi.edu,3;1;1,,Reject,0,0,0,yes,9/25/19,Rensselaer Polytechnic Institute;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Rensselaer Polytechnic Institute,Reinforcement Learning;Generalization;Information Theory;Rate-Distortion Theory,248;-1;-1;-1;-1;248,438;-1;-1;-1;-1;438,m;m,usa,usa,n
ICLR,2020,AdvCodec: Towards A Unified Framework for Adversarial Text Generation,Boxin Wang;Hengzhi Pei;Han Liu;Bo Li,boxinw2@illinois.edu;hzpei16@fudan.edu.cn;hanliu@northwestern.edu;lbo@illinois.edu,3;6;3,,Reject,0,7,0,yes,9/25/19,"University of Illinois, Urbana Champaign;Fudan University;Northwestern University;University of Illinois, Urbana Champaign",adversarial text generation;tree-autoencoder;human evaluation,-1;73;46;-1,-1;109;22;-1,m;f,usa,usa,n
ICLR,2020,Function Feature Learning of Neural Networks,Guangcong Wang;Jianhuang Lai;Guangrun Wang;Wenqi Liang,wanggc3@mail2.sysu.edu.cn;stsljh@mail.sysu.edu.cn;wanggrun@mail2.sysu.edu.cn;liangwq8@mail2.sysu.edu.cn,3;3,,Reject,0,3,1,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1;-1,299;299;299;299,m;m,NAN,NAN,n
ICLR,2020,Unsupervised domain adaptation with imputation,Matthieu Kirchmeyer;Patrick Gallinari;Alain Rakotomamonjy;Amin Mantrach,m.kirchmeyer@criteo.com;patrick.gallinari@lip6.fr;a.rakotomamonjy@criteo.com;a.mantrach@criteo.com,8;3;3,,Reject,0,5,0,yes,9/25/19,Criteo;LIP6;Criteo;Criteo,domain adaptation;imputation;missing data;advertising,-1;445;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Path Space for Recurrent Neural Networks with ReLU Activations,Yue Wang;Qi Meng;Wei Chen;Yuting Liu;Zhi-Ming Ma;Tie-Yan Liu,11271012@bjtu.edu.cn;meq@microsoft.com;wche@microsoft.com;ytliu@bjtu.edu.cn;mazm@amt.ac.cn;tie-yan.liu@microsoft.com,3;3;1,,Reject,0,4,0,yes,9/25/19,Beijing Jiaotong University;Microsoft;Microsoft;Beijing Jiaotong University;Chinese Academy of Sciences;Microsoft,optimization;neural network;positively scale-invariant;path space;deep learning;RNN,-1;-1;-1;-1;30;-1,952;-1;-1;952;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Fast Machine Learning with Byzantine Workers and Servers,El-Mahdi El-Mhamdi;Rachid Guerraoui;Arsany Guirguis,elmahdi.elmhamdi@epfl.ch;rachid.guerraoui@epfl.ch;arsany.guirguis@epfl.ch,3;6;3,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Distributed machine learning;Byzantine resilience;Fault tolerance,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Topology-Aware Pooling via Graph Attention,Hongyang Gao;Shuiwang Ji,hongyang.gao@tamu.edu;sji@tamu.edu,3;6;1,,Reject,0,0,0,yes,9/25/19,Texas A&M;Texas A&M,,46;46,177;177,m;m,NAN,NAN,n
ICLR,2020,Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,Alex X. Lee;Anusha Nagabandi;Pieter Abbeel;Sergey Levine,alexlee_gk@cs.berkeley.edu;nagaban2@berkeley.edu;pabbeel@cs.berkeley.edu;svlevine@eecs.berkeley.edu,8;3;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,n
ICLR,2020,Localised Generative Flows,Rob Cornish;Anthony Caterini;George Deligiannidis;Arnaud Doucet,rcornish@robots.ox.ac.uk;anthony.caterini@stats.ox.ac.uk;deligian@stats.ox.ac.uk;doucet@stats.ox.ac.uk,3;3;1,,Reject,1,6,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Deep generative models;normalizing flows;variational inference,46;46;46;46,1;1;1;1,m;m,europe,uk,y
ICLR,2020,Guided Adaptive Credit Assignment for Sample Efficient Policy Optimization,Hao Liu;Richard Socher;Caiming Xiong,lhao499@gmail.com;rsocher@salesforce.com;cxiong@salesforce.com,3;6;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;SalesForce.com;SalesForce.com,credit assignment;sparse reward;policy optimization;sample efficiency,-1;-1;-1,13;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Proactive Sequence Generator via Knowledge Acquisition,Qing Sun;James Cross;Dmitriy Genzel,qingsun@fb.com;jcross@fb.com;dgenzel@fb.com,3;3;3,,Reject,0,6,0,yes,9/25/19,Facebook;Facebook;Facebook,neural machine translation;knowledge distillation;exposure bias;reinforcement learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Reinforcement Learning without Ground-Truth State,Xingyu Lin;Harjatin Singh Baweja;David Held,xlin3@cs.cmu.edu;dheld@andrew.cmu.edu;harjatis@andrew.cmu.edu,3;1;3,,Reject,0,4,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,Self-supervised;goal-conditioned reinforcement learning,1;1;1,27;27;27,m;m,usa,usa,n
ICLR,2020,Generalized Inner Loop Meta-Learning,Edward Grefenstette;Brandon Amos;Denis Yarats;Phu Mon Htut;Artem Molchanov;Franziska Meier;Douwe Kiela;Kyunghyun Cho;Soumith Chintala,egrefen@gmail.com;brandon.amos.cs@gmail.com;denisyarats@cs.nyu.edu;pmh330@nyu.edu;a.molchanov86@gmail.com;fmeier@fb.com;dkiela@fb.com;kyunghyun.cho@nyu.edu;soumith@gmail.com,3;3;3,,Reject,0,10,0,yes,9/25/19,Facebook;Facebook;New York University;New York University;NVIDIA;Facebook;Facebook;New York University;Facebook,meta-learning,-1;-1;22;22;-1;-1;-1;22;-1,-1;-1;29;29;-1;-1;-1;29;-1,m;m,NAN,NAN,n
ICLR,2020,Channel Equilibrium Networks,Wenqi Shao;Shitao Tang;Xingang Pan;Ping Tan;Xiaogang Wang;Ping Luo,weqish@link.cuhk.edu.hk;shitaot@sfu.ca;px117@ie.cuhk.edu.hk;pingtan@sfu.ca;xgwang@ee.cuhk.edu.hk;pluo.lhi@gmail.com,3;6;3,,Reject,0,4,0,yes,9/25/19,The Chinese University of Hong Kong;Simon Fraser University;The Chinese University of Hong Kong;Simon Fraser University;The Chinese University of Hong Kong;The University of Hong Kong,Deep learning;convolutional neural networks;building block design,316;52;316;52;316;92,35;272;35;272;35;35,m;m,NAN,NAN,y
ICLR,2020,Zeroth Order Optimization by a Mixture of Evolution Strategies,Jun-Kun Wang;Xiaoyun Li;Ping Li,jimwang@gatech.edu;xl374@scarletmail.rutgers.edu;liping11@baidu.com,3;1;1,,Reject,0,0,0,yes,9/25/19,Georgia Institute of Technology;Rutgers University;Baidu,,13;30;-1,38;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Limitations for Learning from Point Clouds,Christian Bueno;Alan G. Hylton,christianbueno@ucsb.edu;alan.g.hylton@nasa.gov,8;3;3,,Reject,0,4,0,yes,9/25/19,UC Santa Barbara;NASA Ames,universal approximation;point clouds;deep learning;hausdorff metric;wasserstein metric,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,WORD SEQUENCE PREDICTION FOR AMHARIC LANGUAGE,Nuniyat Kifle;Ermias Abebe,nunukifle2@gmail.com;ermiasabebe@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Addis Ababa University;Addis Ababa University,Word prediction;POS;Statistical approach,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Learning Underlying Physical Properties From Observations For Trajectory Prediction,Ekaterina Nikonova;Jochen Renz,ekaterina.nikonova@anu.edu.au;jochen.renz@anu.edu.au,1;3;3,,Reject,0,4,0,yes,9/25/19,Australian National University;Australian National University,Physical Games;Deep Learning;Physical Reasoning;Transfer of Knowledge,102;102,50;50,f;m,australasia,au,n
ICLR,2020,Provable Representation Learning for Imitation Learning via Bi-level Optimization,Sanjeev Arora;Simon S. Du;Sham Kakade;Yuping Luo;Nikunj Saunshi,arora@cs.princeton.edu;ssdu@ias.edu;sham@cs.washington.edu;yupingl@cs.princeton.edu;nsaunshi@cs.princeton.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,"Princeton University;Institue for Advanced Study, Princeton;University of Washington;Princeton University;Princeton University",imitation learning;representation learning;multitask learning;theory;behavioral cloning;imitation from observations alone;reinforcement learning,30;-1;11;30;30,6;-1;26;6;6,m;m,usa,usa,y
ICLR,2020,Anchor & Transform: Learning Sparse Representations of Discrete Objects,Paul Pu Liang;Manzil Zaheer;Yuan Wang;Amr Ahmed,pliang@cs.cmu.edu;manzilzaheer@google.com;yuanwang@google.com;amra@google.com,3;3;6,,Reject,0,5,0,yes,9/25/19,Carnegie Mellon University;Google;Google;Google,sparse representation learning;discrete inputs;natural language processing,1;-1;-1;-1,27;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,EgoMap: Projective mapping and structured egocentric memory for Deep RL,Edward Beeching;Christian Wolf;Jilles Dibangoye;Olivier Simonin,edward.beeching@inria.fr;christian.wolf@insa-lyon.fr;jilles.dibangoye@inria.fr;olivier.simonin@inria.fr,6;3;6,,Reject,0,5,0,yes,9/25/19,INRIA;INSA de Lyon;INRIA;INRIA,Reinforcement Learning;Deep Learning;Computer Vision;Robotics;Neural Memory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,europe,gr,n
ICLR,2020,Few-shot Learning by Focusing on Differences,Muhammad Rizki Maulana;Lee Wee Sun,maulana@comp.nus.edu.sg;leews@comp.nus.edu.sg,3;3;3,,Reject,0,3,0,yes,9/25/19,National University of Singapore;National University of Singapore,Deep learning;few-shot learning,17;17,25;25,m;m,asia,sg,n
ICLR,2020,On the Parameterization of Gaussian Mean Field Posteriors in Bayesian Neural Networks,Jakub ≈öwiƒÖtkowski;Kevin Roth;Bastiaan S. Veeling;Linh Tran;Joshua V. Dillon;Jasper Snoek;Stephan Mandt;Tim Salimans;Rodolphe Jenatton;Sebastian Nowozin,kuba.swiatkowski@gmail.com;kevin.roth@inf.ethz.ch;basveeling@gmail.com;linh.tran@imperial.ac.uk;jvdillon@google.com;jaspersnoek@gmail.com;stephan.mandt@gmail.com;salimans@google.com;rjenatton@google.com;nowozin@google.com,3;1;3,,Reject,0,3,0,yes,9/25/19,"NoMagic;Swiss Federal Institute of Technology;Google;Imperial College London;Google;Google;University of California, Irvine;Google;Google;Google",variational Bayes;Bayesian neural networks;mean field,-1;-1;-1;52;-1;-1;-1;-1;-1;-1,-1;-1;-1;10;-1;-1;96;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Deep unsupervised feature selection,Ian Covert;Uygar Sumbul;Su-In Lee,icovert@cs.washington.edu;uygars@alleninstitute.org;suinlee@cs.washington.edu,3;1;6,,Reject,0,0,0,yes,9/25/19,University of Washington;Allen Institute;University of Washington,Single cell rna;microarray;feature selection;feature ranking,11;-1;11,26;-1;26,m;f,usa,usa,y
ICLR,2020,Efficient Bi-Directional Verification of ReLU Networks via Quadratic Programming,Aleksei Kuvshinov;Stephan Guennemann,kuvshino@in.tum.de;guennemann@in.tum.de,3;8;6,,Reject,0,5,0,yes,9/25/19,Technical University Munich;Technical University Munich,,-1;-1,-1;-1,m;m,NAN,NAN,y
ICLR,2020,AdaScale SGD: A Scale-Invariant Algorithm for Distributed Training,Tyler B. Johnson;Pulkit Agrawal;Haijie Gu;Carlos Guestrin,tbjohns@apple.com;pulkit_agrawal@apple.com;jaygu@apple.com;guestrin@apple.com,3;3;3,,Reject,2,4,0,yes,9/25/19,Apple;Apple;Apple;Apple,Large-batch SGD;large-scale learning;distributed training,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Small-GAN: Speeding up GAN Training using Core-Sets,Samarth Sinha;Han Zhang;Anirudh Goyal;Yoshua Bengio;Hugo Larochelle;Augustus Odena,samarth.sinha@mail.utoronto.ca;zhanghan@google.com;anirudhgoyal9119@gmail.com;yoshua.bengio@mila.quebec;hugolarochelle@google.com;augustusodena@google.com,3;6;6,,Reject,0,9,1,yes,9/25/19,Toronto University;Google;;Mila;Google;Google,GANs;Coreset,-1;-1;-1;143;-1;-1,-1;-1;-1;336;-1;-1,m;m,NAN,NAN,n
ICLR,2020,AUGMENTED POLICY GRADIENT METHODS FOR EFFICIENT REINFORCEMENT LEARNING,Kai Lagemann;Gregor Roering;Christoph Henke;Rene Vossen;Frank Hees,kai.lagemann@rwth-aachen.de;gregor.roering@rwth-aachen.de;christoph.henke@ifu.rwth-aachen.de;rene.vossen@ifu.rwth-aachen.de;hees.office@ima-ifu.rwth-aachen.de,1;1;1,,Reject,0,0,0,yes,9/25/19,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;RWTH Aachen University,model-free reinforcement learning;model-based reinforcement learning;Baysian neural network;deep learning;reinforcement learning,118;118;118;118;118,98;98;98;98;98,m;m,NAN,NAN,n
ICLR,2020,Neural Approximation of an Auto-Regressive Process through Confidence Guided Sampling,YoungJoon Yoo;Sanghyuk Chun;Jaejun Yoo;Sangdoo Yun;Jung Woo Ha,youngjoon.yoo@navercorp.com;sanghyuk.c@navercorp.com;jaejun.yoo@navercorp.com;sangdoo.yun@navercorp.com;jungwoo.ha@navercorp.com,6;3;6,,Reject,0,0,0,yes,9/25/19,NAVER;NAVER;NAVER;NAVER;NAVER,Neural approximation method;Auto-regressive model;Sequential sample generation,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,europe,gr,n
ICLR,2020,Certifiably Robust Interpretation in Deep Learning,Alexander Levine;Sahil Singla;Soheil Feizi,alevine0@cs.umd.edu;ssingla@cs.umd.edu;sfeizi@cs.umd.edu,3;1;3,,Reject,0,6,1,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",deep learning interpretation;robustness certificates;adversarial examples,12;12;12,91;91;91,m;m,usa,usa,y
ICLR,2020,Towards More Realistic Neural Network Uncertainties,Joachim Sicking;Alexander Kister;Matthias Fahrland;Stefan Eickeler;Fabian Hueger;Stefan Rueping;Peter Schlicht;Tim Wirtz,joachim.sicking@iais.fraunhofer.de;alexander.kister@iais.fraunhofer.de;matthias.fahrland@iav.de;stefan.eickeler@iais.fraunhofer.de;fabian.hueger@volkswagen.de;stefan.rueping@iais.fraunhofer.de;peter.schlicht@volkswagen.de;tim.wirtz@iais.fraunhofer.de,1;3;1,,Reject,0,0,0,yes,9/25/19,"Fraunhofer IIS;Fraunhofer IIS;;Fraunhofer IIS;Machine Learning Research Lab, Volkswagen Group;Fraunhofer IIS;Machine Learning Research Lab, Volkswagen Group;Fraunhofer IIS",uncertainty;variational inference;MC dropout;variational autoencoder;evaluation,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Adversarial Training: embedding adversarial perturbations into the parameter space of a neural network to build a robust system,Shixian Wen;Laurent Itti,shixianw@usc.edu;itti@usc.edu,1;3;3,,Reject,0,0,0,yes,9/25/19,University of Southern California;University of Southern California,Adversarial Training;Adversarial Examples,36;36,62;62,m;m,usa,usa,n
ICLR,2020,Neural Linear Bandits: Overcoming Catastrophic Forgetting through Likelihood Matching,Tom Zahavy;Shie Mannor,tomzahavy@gmail.com;shiemannor@gmail.com,3;3;3,,Reject,0,4,0,yes,9/25/19,"DeepMind;Technion, Technion",,-1;27,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Non-additive Utility Aggregation,Markus Zopf,mzopf@ke.tu-darmstadt.de,3;1;1,,Reject,0,5,0,yes,9/25/19,TU Darmstadt,,59,-1,m;m,europe,de,n
ICLR,2020,Understanding the functional and structural differences across excitatory and inhibitory neurons,Sun Minni;Li Ji-An;Theodore Moskovitz;Grace Lindsay;Kenneth Miller;Mario Dipoppa;Guangyu Robert Yang,sunminni1031@gmail.com;jian.li.acad@gmail.com;thmoskovitz@gmail.com;gracewlindsay@gmail.com;kendmiller@gmail.com;mario.dipoppa@gmail.com;gyyang.neuro@gmail.com,6;6;8,,Reject,0,11,0,yes,9/25/19,Columbia University;;University College London;University College London;Columbia University;;Columbia University,Neuroscience,24;-1;52;52;24;-1;24,16;-1;-1;-1;16;-1;16,f;m,usa,usa,n
ICLR,2020,Skew-Explore: Learn faster in continuous spaces with sparse rewards,Xi Chen;Yuan Gao;Ali Ghadirzadeh;Marten Bjorkman;Ginevra Castellano;Patric Jensfelt,xi8@kth.se;gaoyuankidult@gmail.com;algh@kth.se;celle@csc.kth.se;ginevra.castellano@it.uu.se;patric@kth.se,3;3;3,,Reject,0,5,0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;Uppsala University;KTH Royal Institute of Technology, Stockholm, Sweden",reinforcement learning;exploration;sparse reward,194;-1;194;194;194;194,222;-1;222;222;102;222,m;m,NAN,NAN,y
ICLR,2020,Self-Supervised Speech Recognition via Local Prior Matching,Wei-Ning Hsu;Ann Lee;Gabriel Synnaeve;Awni Hannun,wnhsu@mit.edu;annl@fb.com;gab@fb.com;awni@fb.com,6;3;3,,Reject,0,4,0,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook,speech recognition;self-supervised learning;language model;semi-supervised learning;pseudo labeling,5;-1;-1;-1,5;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Reusable Options for Multi-Task Reinforcement Learning,Francisco M. Garcia;Chris Nota;Philip S. Thomas,fmaxgarcia@gmail.com;cnota@cs.umass.edu;pthomas@cs.umass.edu,3;6;1,,Reject,0,6,0,yes,9/25/19,"Amazon;University of Massachusetts, Amherst;University of Massachusetts, Amherst",Reinforcement Learning;Temporal Abstraction;Options;Multi-Task RL,-1;24;24,-1;209;209,m;m,usa,usa,y
ICLR,2020,A Unified framework for randomized smoothing based certified defenses,Tianhang Zheng;Di Wang;Baochun Li;Jinhui Xu,th.zheng@mail.utoronto.ca;dwang45@buffalo.edu;bli@ece.toronto.edu;jinhui@buffalo.edu,3;1;3,,Reject,3,4,0,yes,9/25/19,"Toronto University;State University of New York, Buffalo;University of Toronto;State University of New York, Buffalo",Certificated Defense;Randomized Smoothing;A Unified and Self-Contained Framework,-1;-1;18;-1,-1;-1;18;-1,m;m,NAN,NAN,y
ICLR,2020,Closed loop deep Bayesian inversion:  Uncertainty driven acquisition for fast MRI,Thomas Sanchez;Igor Krawczuk;Zhaodong Sun;Volkan Cevher,thomas.sanchez@epfl.ch;igor.krawczuk@epfl.ch;zhaodong.sun@epfl.ch;volkan.cevher@epfl.ch,3;3;3;3,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,Deep Bayesian Inversion;accelerated MRI;uncertainty quantification;sampling mask design,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Scalable Differentially Private Data Generation via Private  Aggregation  of  Teacher Ensembles,Yunhui Long;Suxin Lin;Zhuolin Yang;Carl A. Gunter;Han Liu;Bo Li,ylong4@illinois.edu;linsuxin28@gmail.com;lucas110550@sjtu.edu.cn;cgunter@illinois.edu;hanliu@northwestern.edu;lbo@illinois.edu,3;1;8,,Reject,0,4,0,yes,9/25/19,"University of Illinois, Urbana Champaign;;Shanghai Jiao Tong University;University of Illinois, Urbana Champaign;Northwestern University;University of Illinois, Urbana Champaign",,-1;-1;30;-1;46;-1,-1;-1;157;-1;22;-1,f;f,usa,usa,y
ICLR,2020,Adaptive Generation of Unrestricted Adversarial Inputs,Isaac Dunn;Hadrien Pouget;Tom Melham;Daniel Kroening,isaac.dunn@cs.ox.ac.uk;hadrien.pouget@cs.ox.ac.uk;tom.melham@cs.ox.ac.uk;kroening@cs.ox.ac.uk,3;6;6,,Reject,0,9,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Adversarial Examples;Adversarial Robustness;Generative Adversarial Networks;Image Classification,46;46;46;46,1;1;1;1,m;m,europe,uk,n
ICLR,2020,GPNET: MONOCULAR 3D VEHICLE DETECTION BASED ON LIGHTWEIGHT WHEEL GROUNDING POINT DETECTION NETWORK,zizhang.wu,wuzizhang87@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,0,applications in vision;audio;speech;natural language processing;robotics,,,m,NAN,NAN,n
ICLR,2020,Training Neural Networks for and by Interpolation,Leonard Berrada;Andrew Zisserman;Pawan M. Kumar,lberrada@robots.ox.ac.uk;az@robots.ox.ac.uk;pawan@robots.ox.ac.uk,1;6;6;6,,Reject,0,5,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,optimization;adaptive learning-rate;Polyak step-size;Newton-Raphson,46;46;46,1;1;1,m;m,europe,uk,y
ICLR,2020,On the expected running time of nonconvex optimization with early stopping,Thomas Flynn;Kwang Min Yu;Abid Malik;Shinjae Yoo;Nicholas D'Imperio,thomasflynn918@gmail.com;kyu@bnl.gov;amalik@bnl.gov;sjyoo@bnl.gov;dimperio@bnl.gov,3;6;3,,Reject,0,0,0,yes,9/25/19,Brookhaven National Laboratory;Brookhaven National Laboratory;Brookhaven National Laboratory;Brookhaven National Laboratory;Brookhaven National Laboratory,non-convex;stopping times;statistics;gradient descent;early stopping,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Interpreting video features: a comparison of 3D convolutional networks and convolutional LSTM networks,Joonatan M√§ntt√§ri*;Sofia Broom√©*;John Folkesson;Hedvig Kjellstr√∂m,sbroome@kth.se;manttari@kth.se;johnf@kth.se;hedvig@kth.se,6;1;3,,Reject,0,4,0,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",interpretability;spatiotemporal;video;features;saliency;temporal,194;194;194;194,222;222;222;222,m;f,NAN,NAN,n
ICLR,2020,Deep Multiple Instance Learning for Taxonomic Classification of Metagenomic read sets,Andreas Georgiou;Vincent Fortuin;Harun Mustafa;Gunnar R√§tsch,geandrea@ethz.ch;fortuin@inf.ethz.ch;harun.mustafa@inf.ethz.ch;raetsch@inf.ethz.ch,3;3;1,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning with Long-term Remembering: Following the Lead of Mixed Stochastic Gradient,Yunhui Guo;Mingrui Liu;Tianbao Yang;Tajana Rosing,yug185@eng.ucsd.edu;mingrui-liu@uiowa.edu;tianbao-yang@uiowa.edu;tajana@ucsd.edu,3;3;3,,Reject,0,8,0,yes,9/25/19,"University of California, San Diego;University of Iowa;University of Iowa;University of California, San Diego",lifelong learning;continual learning,-1;168;168;-1,31;227;227;31,m;f,usa,usa,n
ICLR,2020,Skew-Fit: State-Covering Self-Supervised Reinforcement Learning,Vitchyr H. Pong;Murtaza Dalal;Steven Lin;Ashvin Nair;Shikhar Bahl;Sergey Levine,vitchyr@berkeley.edu;mdalal@berkeley.edu;stevenlin598@berkeley.edu;anair17@berkeley.edu;shikharbahl@berkeley.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,9,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,deep reinforcement learning;goal space;goal conditioned reinforcement learning;self-supervised reinforcement learning;goal sampling;reinforcement learning,-1;-1;-1;-1;-1;-1,13;13;13;13;13;13,m;m,usa,usa,y
ICLR,2020,Uncertainty - sensitive learning and planning with ensembles,Piotr Mi≈Ço≈õ;≈Åukasz Kuci≈Ñski;Konrad Czechowski;Piotr Kozakowski;Maciej Klimek,pmilos@mimuw.edu.pl;lukasz.kucinski@gmail.com;konrad.czechowski@gmail.com;p.kozakowski@mimuw.edu.pl;maciej.klimek@gmail.com,3;6;1,,Reject,1,3,0,yes,9/25/19,"University of Washington, Seattle;;University of Washington, Seattle;University of Washington, Seattle;Uppsala University",deep reinfocement learning;mcts;ensembles;uncertainty,11;-1;11;11;-1,26;-1;26;26;-1,m;m,asia,in,y
ICLR,2020,Gradient-based training of Gaussian Mixture Models in High-Dimensional Spaces,Alexander Gepperth;Benedikt Pf√ºlb,alexander.gepperth@cs.hs-fulda.de;benedikt.pfuelb@cs.hs-fulda.de,3;3;1,,Reject,0,4,0,yes,9/25/19,University of Applied Sciences Fulda;University of Applied Sciences Fulda,GMM;SGD,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Counterfactual Regularization for Model-Based Reinforcement Learning,Lawrence Neal;Li Fuxin;Xiaoli Fern,nealla@oregonstate.edu;fuxin.li@oregonstate.edu;xiaoli.fern@oregonstate.edu,3;3;3,,Reject,0,1,0,yes,9/25/19,Oregon State University;Oregon State University;Oregon State University,Counterfactual;Model-Based Reinforcement Learning,79;79;79,373;373;373,m;f,usa,usa,n
ICLR,2020,Three-Head Neural Network Architecture for AlphaZero Learning,Chao Gao;Martin Mueller;Ryan Hayward;Hengshuai Yao;Shangling Jui,cgao3@ualberta.ca;mmueller@ualberta.ca;hayward@ualberta.ca;hengshuai.yao@huawei.com;jui.shangling@huawei.com,6;3;6,,Reject,0,3,0,yes,9/25/19,University of Alberta;University of Alberta;University of Alberta;Huawei Technologies Ltd.;Huawei Technologies Ltd.,alphazero;reinforcement learning;two-player games;heuristic search;deep neural networks,102;102;102;-1;-1,136;136;136;-1;-1,m;m,NAN,NAN,n
ICLR,2020,GATO: Gates Are Not the Only Option,Mark Goldstein*;Xintian Han*;Rajesh Ranganath,goldstein@nyu.edu;xh1007@nyu.edu;rajeshr@cims.nyu.edu,3;8;3,,Reject,0,5,0,yes,9/25/19,New York University;New York University;New York University,Sequence Models;Vanishing Gradients;Recurrent neural networks;Long-term dependence,22;22;22,29;29;29,m;m,usa,usa,n
ICLR,2020,Collaborative Inter-agent Knowledge Distillation for Reinforcement Learning,Zhang-Wei Hong;Prabhat Nagarajan;Guilherme Maeda,williamd4112@gapp.nthu.edu.tw;prabhat@preferred.jp;gjmaeda@preferred.jp,3;8;6,,Reject,0,7,0,yes,9/25/19,"National Tsing Hua University;Preferred Networks, Inc.;Preferred Networks, Inc.",Reinforcement learning;distillation,194;-1;-1,365;-1;-1,m;m,NAN,NAN,n
ICLR,2020,THE EFFECT OF ADVERSARIAL TRAINING: A THEORETICAL CHARACTERIZATION,Mingyang Yi;Huishuai Zhang;Wei Chen;Zhi-Ming Ma;Tie-Yan Liu,yimingyang17@mails.ucas.edu.cn;huzhang@microsoft.com;wche@microsoft.com;mazm@amt.ac.cn;tie-yan.liu@microsoft.com,1;1;1,,Reject,0,4,0,yes,9/25/19,University of Chinese Academy of Sciences;Microsoft;Microsoft;Chinese Academy of Sciences;Microsoft,adversarial training;robustness;separable data,30;-1;-1;30;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Flexible and Efficient Long-Range Planning Through Curious Exploration,Aidan Curtis;Minjian Xin;Kevin Feigelis;Dan Yamins,southpawac@gmail.com;xinminjian@sjtu.edu.cn;feigelis@stanford.edu;yamins@stanford.edu,3;1;6,,Reject,0,16,0,yes,9/25/19,Rice University;Shanghai Jiao Tong University;Stanford University;Stanford University,Curiosity;Planning;Reinforcement Learning;Robotics;Exploration,-1;30;5;5,-1;157;4;4,m;m,usa,usa,n
ICLR,2020,Learning Latent Dynamics for Partially-Observed Chaotic Systems,Said ouala;Duong Nguyen;Lucas Drumetz;Bertrand Chapron;Ananda Pascual;Fabrice Collard;Lucile Gaultier;Ronan Fablet,said.ouala@imt-atlantique.fr;van.nguyen1@imt-atlantique.fr;lucas.drumetz@imt-atlantique.fr;bertrand.chapron@ifremer.fr;ananda.pascual@imedea.uib-csic.es;dr.fab@oceandatalab.com;lucile.gaultier@oceandatalab.com;ronan.fablet@imt-atlantique.fr,3;3;6,,Reject,0,8,0,yes,9/25/19,IMT Atlantique;IMT Atlantique;IMT Atlantique;;Spanish National Research Council;Oceandatalab;Oceandatalab;IMT Atlantique,Dynamical systems;Neural networks;Embedding;Partially observed systems;Forecasting;chaos,-1;-1;-1;-1;-1;-1;-1;-1,393;393;393;-1;-1;-1;-1;393,m;m,NAN,NAN,n
ICLR,2020,Make Lead Bias in Your Favor: A Simple and Effective Method for News Summarization,Chenguang Zhu;Ziyi Yang;Robert Gmyr;Michael Zeng;Xuedong Huang,chezhu@microsoft.com;zy99@stanford.edu;rogmyr@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com,6;1;6,,Reject,0,6,0,yes,9/25/19,Microsoft;Stanford University;Microsoft;Microsoft;Microsoft,Summarization;Pretraining,-1;5;-1;-1;-1,-1;4;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,High performance RNNs with spiking neurons,Manu V Nair;Giacomo Indiveri,mnair@ini.uzh.ch;giacomo@ini.uzh.ch,6;6;1,,Reject,0,5,1,yes,9/25/19,University of Zurich;University of Zurich,RNNs;Spiking neurons;Neuromorphics,118;118,90;90,m;m,europe,ch,n
ICLR,2020,Universal Learning Approach for Adversarial Defense,Uriya Pesso;Koby Bibas;Meir Feder,uriyapes@gmail.com;kobybibas@gmail.com;meir@eng.tau.ac.il,3;1;3,,Reject,0,3,0,yes,9/25/19,Tel Aviv University;Tel Aviv University;Tel Aviv University,Adversarial examples;Adversarial training;Universal learning;pNML for DNN,-1;30;30,-1;188;188,m;m,europe,il,n
ICLR,2020,Re-Examining Linear Embeddings for High-dimensional Bayesian Optimization,Benjamin Letham;Roberto Calandra;Akshara Rai;Eytan Bakshy,bletham@fb.com;rcalandra@fb.com;akshararai@fb.com;ebakshy@fb.com,3;1;3,,Reject,0,4,0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook,Bayesian optimization;high-dimensional;Gaussian process,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Salient Explanation for Fine-grained Classification,Kanghan Oh;Sungchan Kim;Il-Seok Oh,blastps@gmail.com;s.k@jbnu.ac.kr;iosh@jbnu.ac.kr,1;1;3,,Reject,0,0,0,yes,9/25/19,Chonbuk National University;Chonbuk National University;Chonbuk National University,Visual explanation;XAI;Constitutional Neural Network,-1;-1;-1,965;965;965,f;m,NAN,NAN,n
ICLR,2020,Deep Coordination Graphs,Wendelin Boehmer;Vitaly Kurin;Shimon Whiteson,wendelin.boehmer@cs.ox.ac.uk;vitaly.kurin@cs.ox.ac.uk;shimon.whiteson@cs.ox.ac.uk,6;3;3,,Reject,0,3,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford,multi-agent reinforcement learning;coordination graph;deep Q-learning;value factorization;relative overgeneralization,46;46;46,1;1;1,m;m,europe,uk,n
ICLR,2020,Adversarial Training Generalizes Data-dependent Spectral Norm Regularization,Kevin Roth;Yannic Kilcher;Thomas Hofmann,kevin.roth@inf.ethz.ch;yannic.kilcher@inf.ethz.ch;thomas.hofmann@inf.ethz.ch,1;3;8,,Reject,0,11,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Adversarial Robustness;Adversarial Training;Spectral Norm Regularization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,TriMap: Large-scale Dimensionality Reduction Using Triplets,Ehsan Amid;Manfred K. Warmuth,eamid@ucsc.edu;manfred@ucsc.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,University of Southern California;University of Southern California,Dimensionality Reduction;Triplets;Data Visualization;t-SNE;LargeVis;UMAP,36;36,62;62,m;m,usa,usa,n
ICLR,2020,Unsupervised Temperature Scaling: Robust Post-processing Calibration for Domain Shift,Azadeh Sadat Mozafari;Hugo Siqueira Gomes;Christian Gagne,azadeh-sadat.mozafari.1@ulaval.ca;hugo.siqueira-gomes.1@ulaval.ca;christian.gagne@gel.ulaval.ca,3;1;6,,Reject,0,10,0,yes,9/25/19,Laval university;Laval university;Laval university,calibration;domain shift;uncertainty prediction;deep neural networks;temperature scaling,-1;-1;-1,272;272;272,f;m,NAN,NAN,y
ICLR,2020,Uncertainty-Aware Prediction for Graph Neural Networks,Xujiang Zhao;Feng Chen;Shu Hu;jin-Hee Cho,xxz190020@utdallas.edu;feng.chen@utdallas.edu;shu2@albany.edu;jicho@vt.edu,3;3;3,,Reject,0,7,0,yes,9/25/19,"University of Texas, Dallas;University of Texas, Dallas;State University of New York, Albany;Virginia Tech",Uncertainty;Graph Neural Networks;Subjective Logic;Bayesian,-1;-1;-1;64,-1;-1;350;-1,m;f,usa,usa,n
ICLR,2020,Hydra: Preserving Ensemble Diversity for Model Distillation,Linh Tran;Bastiaan S. Veeling;Kevin Roth;Jakub ≈öwiƒÖtkowski;Joshua V. Dillon;Jasper Snoek;Stephan Mandt;Tim Salimans;Sebastian Nowozin;Rodolphe Jenatton,linh.tran@imperial.ac.uk;basveeling@gmail.com;kevin.roth@inf.ethz.ch;kuba.swiatkowski@gmail.com;jvdillon@google.com;jaspersnoek@gmail.com;stephan.mandt@gmail.com;salimans@google.com;nowozin@google.com;rjenatton@google.com,6;3;1,,Reject,0,5,0,yes,9/25/19,"Imperial College London;Google;Swiss Federal Institute of Technology;NoMagic;Google;Google;University of California, Irvine;Google;Google;Google",model distillation;ensemble models,52;-1;-1;-1;-1;-1;-1;-1;-1;-1,10;-1;-1;-1;-1;-1;96;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Finding Deep Local Optima Using Network Pruning,Yangzi Guo;Yiyuan She;Ying Nian Wu;Adrian Barbu,yguo@math.fsu.edu;yshe@stat.fsu.edu;ywu@stat.ucla.edu;abarbu@stat.fsu.edu,3;6;3,,Reject,0,0,0,yes,9/25/19,"SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;University of California, Los Angeles;SUN YAT-SEN UNIVERSITY",network pruning;non-convex optimization,-1;-1;-1;-1,299;299;17;299,m;m,NAN,NAN,n
ICLR,2020,Advantage Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning,Xue Bin Peng;Aviral Kumar;Grace Zhang;Sergey Levine,xbpeng@berkeley.edu;aviralkumar2907@gmail.com;grace.zhang@berkeley.edu;svlevine@eecs.berkeley.edu,6;3;6,,Reject,0,31,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;policy search;control,-1;-1;-1;-1,13;13;13;13,m;m,usa,usa,y
ICLR,2020,Generative Teaching Networks: Accelerating Neural Architecture Search by Learning  to Generate Synthetic Training Data,Felipe Petroski Such;Aditya Rawal;Joel Lehman;Kenneth Stanley;Jeff Clune,felipe.such@uber.com;aditya.rawal@uber.com;joel.lehman@uber.com;kstanley@uber.com;jeffclune@uber.com,3;6;6,,Reject,0,13,0,yes,9/25/19,Uber;Uber;Uber;Uber;Uber,Generative models;generating synthetic data;neural architecture search;learning to teach;meta-learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,southamerica,br,n
ICLR,2020,Compression without Quantization,Gergely Flamich;Marton Havasi;Jos√© Miguel Hern√°ndez-Lobato,gf332@cam.ac.uk;mh740@cam.ac.uk;jmh233@cam.ac.uk,3;3;6;1,,Reject,0,5,0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge,Image Compression;Bits-back efficient;Quantization,79;79;79,3;3;3,m;m,europe,uk,y
ICLR,2020,CLAREL: classification via retrieval loss for zero-shot learning,Boris N. Oreshkin;Negar Rostamzadeh;Pedro O. Pinheiro;Christopher Pal,boris@elementai.com;negar@elementai.com;pedro@elementai.com;christopher.pal@elementai.com,1;6;3,,Reject,0,6,0,yes,9/25/19,Element AI;Element AI;Element AI;Element AI,zero-shot learning;representation learning;fine-grained classification,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Generating Semantic Adversarial Examples with Differentiable Rendering,Lakshya Jain;Steven Chen;Wilson Wu;Uyeong Jang;Varun Chandrasekaran;Sanjit Seshia;Somesh Jha,lakshya.jain@berkeley.edu;scchen@berkeley.edu;wilswu@berkeley.edu;wjang@cs.wisc.edu;vchandrasek4@wisc.edu;sseshia@eecs.berkeley.edu;jha@cs.wisc.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of Southern California;University of Southern California;University of California Berkeley;University of Southern California,semantic adversarial examples;inverse graphics;differentiable rendering,-1;-1;-1;36;36;-1;36,13;13;13;62;62;13;62,m;m,usa,usa,n
ICLR,2020,Constant Time Graph Neural Networks,Ryoma Sato;Makoto Yamada;Hisashi Kashima,r.sato@ml.ist.i.kyoto-u.ac.jp;myamada@i.kyoto-u.ac.jp;kashima@i.kyoto-u.ac.jp,6;3;6,,Reject,0,5,0,yes,9/25/19,Kyoto University;Kyoto University;Kyoto University,graph neural networks;constant time algorithm,168;168;168,65;65;65,m;m,europe,fi,y
ICLR,2020,SSE-PT: Sequential Recommendation Via Personalized Transformer,Liwei Wu;Shuqing Li;Cho-Jui Hsieh;James Sharpnack,liwu@ucdavis.edu;qshli@ucdavis.edu;chohsieh@cs.ucla.edu;jsharpna@ucdavis.deu,1;6;6,,Reject,0,3,0,yes,9/25/19,"University of California, Davis;University of California, Davis;University of California, Los Angeles;University of California, Davis",sequential recommendation;personalized transformer;stochastic shared embeddings,-1;-1;-1;-1,55;55;17;-1,m;m,asia,in,n
ICLR,2020,Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier,Zhenwei Dai;Anshumali Shrivastava,zd11@rice.edu;anshumali@rice.edu,3;6;6,,Reject,0,4,0,yes,9/25/19,Rice University;Rice University,Ada-BF;Bloom filter;machine learning;memory efficient,92;92,105;105,m;m,australasia,au,y
ICLR,2020,Classification Attention for Chinese NER,Yuchen Ge;FanYang;PeiYang,geyc2@lenovo.com;yangfan24@lenovo.com;yangpei4@lenovo.com,3;3;3,,Reject,0,0,0,yes,9/25/19,Lenovo Research;Lenovo Research;Lenovo Research,Chinese NER;NER;tagging;deeplearning;nlp,-1;-1;-1,-1;-1;-1,m;u,NAN,NAN,n
ICLR,2020,Global-Local Network for Learning Depth with Very Sparse Supervision,Antonio Loquercio;Alexey Dosovitskiy;Davide Scaramuzza,loquercio@ifi.uzh.ch;adosovitskiy@google.com;sdavide@ifi.uzh.ch,6;1;3,,Reject,0,4,0,yes,9/25/19,University of Zurich;Google;University of Zurich,Depth Perception;Learning from Sparse Supervision;Learning from Interaction.,118;-1;118,90;-1;90,m;m,europe,ch,n
ICLR,2020,Localized Generations with Deep Neural Networks for Multi-Scale Structured Datasets,Yoshihiro Nagano;Shiro Takagi;Yuki Yoshida;Masato Okada,nagano@mns.k.u-tokyo.ac.jp;takagi@mns.k.u-tokyo.ac.jp;yoshida@mns.k.u-tokyo.ac.jp;okada@edu.k.u-tokyo.ac.jp,3;3;8,,Reject,0,5,0,yes,9/25/19,The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo,Variational autoencoder;Local learning;Model-agnostic meta-learning;Disentangled representation,64;64;64;64,36;36;36;36,m;m,NAN,NAN,n
ICLR,2020,CrossNorm: On Normalization for Off-Policy Reinforcement Learning,Aditya Bhatt;Max Argus;Artemij Amiranashvili;Thomas Brox,aditya@bhatts.org;argus.max@gmail.com;amiranas@cs.uni-freiburg.de;brox@cs.uni-freiburg.de,3;6;3,,Reject,0,4,0,yes,9/25/19,TU Berlin;;Universit√§t Freiburg;Universit√§t Freiburg,RL;Normalization,118;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Diagonal Graph Convolutional Networks with Adaptive Neighborhood Aggregation,Jie Zhang;Yuxiao Dong;Jie Tang,zhangjie.exe@gmail.com;yuxdong@microsoft.com;jietang@tsinghua.edu.cn,3;3;3,,Reject,0,0,0,yes,9/25/19,"WeBank Co., Ltd.;Microsoft;Tsinghua University, Tsinghua University",data mining;graph convolutional networks,-1;-1;4,-1;-1;23,m;m,NAN,NAN,n
ICLR,2020,Variance Reduced Local SGD with Lower Communication Complexity,Xianfeng Liang;Shuheng Shen;Jingchang Liu;Zhen Pan;Yifei Cheng;Enhong Chen,zeroxf@mail.ustc.edu.cn;vaip@mail.ustc.edu.cn;jliude@cse.ust.hk;pzhen@mail.ustc.edu.cn;chengyif@mail.ustc.edu.cn;cheneh@ustc.edu.cn,3;1;6,,Reject,0,3,0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;The Hong Kong University of Science and Technology;University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China,variance reduction;local SGD;distributed optimization,-1;-1;-1;-1;-1;-1,80;80;47;80;80;80,m;m,NAN,NAN,y
ICLR,2020,White Box Network: Obtaining a right composition ordering of functions,Eun saem Lee;Hyung Ju Hwang,dmstoa2502@postech.ac.kr;hjhwang@postech.ac.kr,1;1;1,,Reject,0,6,0,yes,9/25/19,POSTECH;POSTECH,white box;black box;function composition;neural network;ordering functions;reverse engineering;programmable logic controller;plc;white box network;WBN,118;118,146;146,f;f,asia,kr,n
ICLR,2020,Neural Embeddings for Nearest Neighbor Search Under Edit Distance,Xiyuan Zhang;Yang Yuan;Piotr Indyk,zhangxiyuan@zju.edu.cn;yuanyang@tsinghua.edu.cn;indyk@mit.edu,6;6;3,,Reject,0,7,0,yes,9/25/19,"Zhejiang University;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology",Embedding;Edit Distance;Nearest Neighbor Search;Learning-Augmented Algorithm,39;4;5,107;23;5,m;m,usa,usa,y
ICLR,2020,Accelerating First-Order Optimization Algorithms,Ange Tato;Roger Nkambou,angetato@gmail.com;nkambou@gmail.com,3;3;1,,Reject,0,0,0,yes,9/25/19,Universit√© du Qu√©bec √† Montr√©al;Universit√© du Qu√©bec √† Montr√©al,Neural Networks;Gradient Descent;First order optimization,-1;-1,-1;-1,f;m,asia,in,y
ICLR,2020,A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING,Qi Qi;Yan Yan;Zixuan Wu;Xiaoyu Wang;Tianbao Yang,qi-qi@uiowa.edu;yanyan.tju@gmail.com;wuzu@bc.edu;fanghuaxue@gmail.com;tianbao-yang@uiowa.edu,6;6;3,,Reject,0,3,0,yes,9/25/19,University of Iowa;SUN YAT-SEN UNIVERSITY;Boston College;Snap Inc.;University of Iowa,Deep Metric Learning;Distributionally Robust Optimization,168;-1;248;-1;168,227;299;323;-1;227,f;m,europe,de,y
ICLR,2020,Local Label Propagation for Large-Scale Semi-Supervised Learning,Chengxu Zhuang;Chaofei Fan;Xuehao Ding;Divyanshu Murli;Daniel Yamins,chengxuz@stanford.edu;stfan@stanford.edu;xhding@stanford.edu;divymurli@gmail.com;yamins@stanford.edu,3;6;6,,Reject,0,6,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Freelance;Stanford University,,5;5;5;-1;5,4;4;4;-1;4,m;m,usa,usa,n
ICLR,2020,Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes,Sophia Sanborn;Michael Chang;Sergey Levine;Thomas Griffiths,sanborn@berkeley.edu;mbchang@berkeley.edu;svlevine@eecs.berkeley.edu;tomg@princeton.edu,1;6;3,,Reject,0,1,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley;Princeton University,hierarchical reinforcement learning;unsupervised learning;compression,-1;-1;-1;30,13;13;13;6,f;m,usa,usa,n
ICLR,2020,"JAX MD: End-to-End Differentiable, Hardware Accelerated, Molecular Dynamics in Pure Python",Samuel S. Schoenholz;Ekin D. Cubuk,schsam@google.com;cubuk@google.com,6;3;3,,Reject,0,3,0,yes,9/25/19,Google;Google,Automatic Differentiation;Software Library;Physics Simulation;Differentiable Physics,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,ROS-HPL: Robotic Object Search with Hierarchical Policy Learning and Intrinsic-Extrinsic Modeling,Xin Ye;Shibin Zheng;Yezhou Yang,xinye1@asu.edu;szheng31@asu.edu;yz.yang@asu.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Robotic Object Search;Hierarchical Reinforcement Learning,-1;-1;-1,299;299;299,m;m,NAN,NAN,n
ICLR,2020,Fractional Graph Convolutional Networks (FGCN) for Semi-Supervised Learning,Yuzhou Chen;Yulia R. Gel;Konstantin Avrachenkov,yuzhouc@smu.edu;ygl@utdallas.edu;konstentin.avratchankov@inria.fr,6;3;8,,Reject,1,0,0,yes,9/25/19,"Singapore Management University;University of Texas, Dallas;INRIA",convolutional networks;node classification;Levy flight;graph-based semi-supervised learning;local graph topology,79;-1;-1,-1;-1;-1,m;m,europe,gr,y
ICLR,2020,Graph Neural Networks For Multi-Image Matching,Stephen Phillips;Kostas Daniilidis,stephi@seas.upenn.edu;kostas@seas.upenn.edu,3;6;3,,Reject,0,8,0,yes,9/25/19,University of Pennsylvania;University of Pennsylvania,Graph Neural Networks;Multi-image Matching,20;20,11;11,m;m,usa,usa,n
ICLR,2020,Cost-Effective Testing of a Deep Learning Model through Input Reduction,Jianyi Zhou;Feng Li;Jinhao Dong;Hongyu Zhang;Dan Hao,zhoujianyi@pku.edu.cn;lifeng2014@pku.edu.cn;xdu_jhdong@163.com;hongyu.zhang@newcastle.edu.au;haod@sei.pku.edu.cn,8;6;3,,Reject,0,4,0,yes,9/25/19,"Peking University;Peking University;163;University of Newcastle, Australia;Peking University",Software Testing;Deep Learning;Input Data Reduction,14;14;-1;316;14,24;24;-1;311;24,u;f,asia,cn,n
ICLR,2020,Decoupling Weight Regularization from Batch Size for Model Compression,Dongsoo Lee;Se Jung Kwon;Byeongwook Kim;Yongkweon Jeon;Baeseong Park;Jeongin Yun;Gu-Yeon Wei,dslee3@gmail.com;mogndrewk@gmail.com;quddnr145@gmail.com;dragwon.jeon@gmail.com;qkrqotjd91@gmail.com;yji6373@naver.com;gywei@g.harvard.edu,8;3;3,,Reject,0,7,0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Samsung;Samsung;Harvard University,Model compression;Weight Regularization;Batch Size;Gradient Descent,-1;-1;-1;-1;-1;-1;52,-1;-1;-1;-1;-1;-1;7,m;m,usa,usa,n
ICLR,2020,Amharic Text Normalization with Sequence-to-Sequence Models,Seifedin Shifaw Mohamed;Solomon Teferra Abate (PhD),seifedin28@gmail.com;solomon_teferra_7@yahoo.com,1;1;1,,Reject,0,0,0,yes,9/25/19,Addis Ababa University;Addis Ababa University,Text Normalization;Sequence-to-Sequence Model;Encoder-Decoder,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Star-Convexity in Non-Negative Matrix Factorization,Johan Bjorck;Carla Gomes;Kilian Weinberger,njb225@cornell.edu;gomes@cs.cornell.edu;kilianweinberger@cornell.edu,3;6;3,,Reject,0,7,0,yes,9/25/19,Cornell University;Cornell University;Cornell University,nmf;convexity;nonconvex optimization;average-case-analysis,7;7;7,19;19;19,m;m,usa,usa,y
ICLR,2020,Learning Compact Reward for Image Captioning,Nannan Li;Zhenzhong Chen,live@whu.edu.cn;zzchen@whu.edu.cn,6;1;6,,Reject,0,5,0,yes,9/25/19,Wuhan University;Wuhan University,image captioning;adversarial learning;inverse reinforcement learning;vision;language,194;194,354;354,f;m,europe,uk,n
ICLR,2020,Learning Entailment-Based Sentence Embeddings from Natural Language Inference,Rabeeh Karimi Mahabadi*;Florian Mai*;James Henderson,rkarimi@idiap.ch;florian.mai@idiap.ch;james.henderson@idiap.ch,6;6;6,,Reject,0,3,1,yes,9/25/19,Idiap Research Institute;Idiap Research Institute;Idiap Research Institute,sentence embeddings;textual entailment;natural language inference;interpretability,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Word embedding re-examined: is the symmetrical factorization optimal?,Zhichao Han;Jia Li;Xu Li;Hong Cheng,zchan@se.cuhk.edu.hk;lijia@se.cuhk.edu.hk;xuli@se.cuhk.edu.hk;hcheng@se.cuhk.edu.hk,6;3;3,,Reject,0,3,0,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong;The Chinese University of Hong Kong,word embedding;matrix factorization;linear transformation;neighborhood structure,316;316;316;316,35;35;35;35,m;f,NAN,NAN,y
ICLR,2020,Structured consistency loss for semi-supervised semantic segmentation,JongMok Kim;Joo Young Jang;Hyunwoo Park,win98man1@gmail.com;jyjang1090@gmail.com;phw08132@gmail.com,1;1,,Reject,0,0,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;;Seoul National University,semi-supervised learning;semantic segmentation;structured prediction;structured consistency loss,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Attention on Abstract Visual Reasoning,Lukas Hahne;Timo L√ºddecke;Florentin W√∂rg√∂tter;David Kappel,l.hahne@stud.uni-goettingen.de;timo.lueddecke@phys.uni-goettingen.de;worgott@gwdg.de;david.kappel@phys.uni-goettingen.de,3;3;1,,Reject,0,2,0,yes,9/25/19,University of Goettingen;University of Goettingen;;University of Goettingen,Transformer Networks;Self-Attention;Wild Relation Networks;Procedurally Generated Matrices,316;316;-1;316,123;123;-1;123,m;m,europe,de,n
ICLR,2020,Event extraction from unstructured Amharic text,Ephrem Tadesse;Rosa Tsegaye;Kuulaa Qaqqabaa,ephe11ta@gmail.com;rosatsegaye@gmail.com;kuulaa@gmail.com,3;1;1,,Reject,0,0,0,yes,9/25/19,Jimma University;;Addis Ababa Science and Technology University,Event extraction;machine learning classifiers;Nominal events,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Discovering Topics With Neural Topic Models Built From PLSA Loss,sileye ba,sileye.ba@outlook.com,1;1;3,,Reject,2,0,0,yes,9/25/19,0,neural network;topic model;neural topic model;bag-of-words;PLSA,,,m;m,NAN,NAN,n
ICLR,2020,Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness,J√∂rn-Henrik Jacobsen;Jens Behrmann;Nicholas Carlini;Florian Tram√®r;Nicolas Papernot,j.jacobsen@vectorinstitute.ai;jensb@uni-bremen.de;nicholas@carlini.com;tramer@cs.stanford.edu;nicolas.papernot@utoronto.ca,3;6;6,,Reject,0,5,0,yes,9/25/19,Vector Institute;Universit√§t Bremen;Google;Stanford University;Toronto University,Invariance;Robustness;Adversarial Examples,-1;-1;-1;5;-1,-1;-1;-1;4;-1,m;m,NAN,NAN,n
ICLR,2020,WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia,Holger Schwenk;Vishrav Chaudhary;Shuo Sun;Hongyu Gong;Francisco Guzm√°n,schwenk@fb.com;vishrav@fb.com;ssun32@jhu.edu;hgong6@illinois.edu;fguzman@fb.com,3;6;8;3,,Reject,0,4,0,yes,9/25/19,"Facebook;Facebook;Johns Hopkins University;University of Illinois, Urbana Champaign;Facebook",multilinguality;bitext mining;neural MT;Wikipedia;low-resource languages;joint sentence representation,-1;-1;73;-1;-1,-1;-1;12;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ProtoAttend: Attention-Based Prototypical Learning,Sercan O. Arik;Tomas Pfister,soarik@google.com;tpfister@google.com,3;6;3,,Reject,0,4,0,yes,9/25/19,Google;Google,Interpretability;sample-based explanations;prototypes;confidence estimation,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Discourse-Based Evaluation of Language Understanding,Damien Sileo;Tim Van-De-Cruys;Camille Pradel;Philippe Muller,damien.sileo@irit.fr;tim.vandecruys@irit.fr;camille.pradel@synapse-fr.com;philippe.muller@irit.fr,6;6;6,,Reject,0,5,0,yes,9/25/19,"IRIT, CNRS;IRIT, CNRS;Synapse-fr;IRIT, CNRS",Natural Language Understanding;Pragmatics;Discourse;Semantics;Evaluation;BERT;Natural Language Processing,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,SINGLE PATH ONE-SHOT NEURAL ARCHITECTURE SEARCH WITH UNIFORM SAMPLING,Zichao Guo;Xiangyu Zhang;Haoyuan Mu;Wen Heng;Zechun Liu;Yichen Wei;Jian Sun,guozichao@megvii.com;zhangxiangyu@megvii.com;muhy17@mails.tsinghua.edu.cn;hengwen@megvii.com;zliubq@connect.ust.hk;weiyichen@megvii.com;sunjian@megvii.com,6;8;6,,Reject,1,6,1,yes,9/25/19,"Megvii Technology Inc.;Megvii Technology Inc.;Tsinghua University, Tsinghua University;Megvii Technology Inc.;The Hong Kong University of Science and Technology;Megvii Technology Inc.;Megvii Technology Inc.",Neural Architecture Search;Single Path,-1;-1;4;-1;-1;-1;-1,-1;-1;23;-1;47;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Inducing Stronger Object Representations in Deep Visual Trackers,Ross Goroshin;Jonathan Tompson;Debidatta Dwibedi,goroshin@google.com;tompson@google.com;debidatta@google.com,3;3;1,,Reject,1,4,0,yes,9/25/19,Google;Google;Google,Object Tracking;Computer Vision;Deep Learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Automatically Learning Feature Crossing from Model Interpretation for Tabular Data,Zhaocheng Liu;Qiang Liu;Haoli Zhang,zhaocheng.liu@realai.ai;qiang.liu@realai.ai;haoli.zhang@realai.ai,3;3;3,,Reject,1,13,0,yes,9/25/19,RealAI;RealAI;RealAI,AutoML;feature crossing;interpretation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Semi-Supervised Boosting via Self Labelling,Akul Goyal;Yang Liu,akulg2@illinois.edu;yangliu@ucsc.edu,1;1;3,,Reject,0,5,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Southern California",semi-supervised learning;boosting;noise-resistant,-1;36,-1;62,m;m,usa,usa,y
ICLR,2020,Depth creates no more spurious local minima in linear networks,Li Zhang,liqzhang@google.com,3;6;3,,Reject,0,4,0,yes,9/25/19,Google,local minimum;deep linear network,-1,-1,m,NAN,NAN,y
ICLR,2020,Learning by shaking: Computing policy gradients by physical forward-propagation,Arash Mehrjou;Ashkan Soleymani;Stefan Bauer;Bernhard Sch√∂lkopf,amehrjou@tuebingen.mpg.de;soli.ashkan98@gmail.com;stefan.bauer@tuebingen.mpg.de;bs@tuebingen.mpg.de,1;1;3;1,,Reject,0,5,0,yes,9/25/19,Max-Planck Institute;;Max-Planck Institute;Max-Planck Institute,Reinforcement Learning;Control Theory,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Consistent Meta-Reinforcement Learning via Model Identification and Experience Relabeling,Russell Mendonca;Xinyang Geng;Chelsea Finn;Sergey Levine,russellm@berkeley.edu;young.geng@berkeley.edu;cbfinn@cs.stanford.edu;svlevine@eecs.berkeley.edu,3;6;3,,Reject,0,8,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;University of California Berkeley,Meta-Reinforcement Learning;Reinforcement Learning;Off-Policy;Model Based,-1;-1;5;-1,13;13;4;13,m;m,usa,usa,n
ICLR,2020,Accelerating Monte Carlo Bayesian Inference via Approximating Predictive Uncertainty over the Simplex,Yufei Cui;Wuguannan Yao;Qiao Li;Antoni Chan;Chun Jason Xue,yufeicui92@gmail.com;satie.yao@my.cityu.edu.hk;qiaoli045@gmail.com;abchan@cityu.edu.hk;jasonxue@cityu.edu.hk,3;3;6,,Reject,0,6,0,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,,118;118;-1;118;118,171;171;-1;171;171,f;m,asia,hk,n
ICLR,2020,Trajectory growth through random deep ReLU networks,Ilan Price;Jared Tanner,ilan.price@maths.ox.ac.uk;tanner@maths.ox.ac.uk,3;6;3,,Reject,0,7,0,yes,9/25/19,University of Oxford;University of Oxford,Deep networks;expressivity;trajectory growth;sparse neural networks,46;46,1;1,m;m,europe,uk,y
ICLR,2020,Ellipsoidal Trust Region Methods for Neural Network Training,Leonard Adolphs;Jonas Kohler;Aurelien Lucchi,ladolphs@inf.ethz.ch;jonas.kohler@inf.ethz.ch;aurelien.lucchi@inf.ethz.ch,3;3;6,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,non-convex;optimization;neural networks;trust-region,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Defensive Tensorization: Randomized Tensor Parametrization for Robust Neural Networks,Adrian Bulat;Jean Kossaifi;Sourav Bhattacharya;Yannis Panagakis;Georgios Tzimiropoulos;Nicholas D.  Lane;Maja Pantic,adrian@adrianbulat.com;jean.kossaifi@gmail.com;bsourav@gmail.com;i.panagakis@imperial.ac.uk;georgios.t@samsung.com;nic.lane@samsung.com;maja.pantic@gmail.com,6;6;6,,Reject,1,5,0,yes,9/25/19,Samsung;NVIDIA;;Imperial College London;Samsung;Samsung;Imperial College London,tensor decomposition;tensor factorization;randomization;robustness,-1;-1;-1;52;-1;-1;52,-1;-1;-1;10;-1;-1;10,m;f,europe,uk,n
ICLR,2020,The Dual Information Bottleneck,Zoe Piran;Naftali Tishby,zoe.piran@mail.huji.ac.il;tishby@cs.huji.ac.il,3;6;3,,Reject,0,4,0,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem,optimal prediction learning;exponential families;critical points;information theory,85;85,216;216,f;m,europe,il,y
ICLR,2020,ADAPTIVE GENERATION OF PROGRAMMING PUZZLES,Ashwin Kalyan;Oleksandr Polozov;Adam Tauman Kalai,ashwinkv@gatech.edu;alex.polozov@microsoft.com;adam.kalai@microsoft.com,3;8;3,,Reject,0,4,0,yes,9/25/19,Georgia Institute of Technology;Microsoft;Microsoft,program synthesis;reasoning;math problems,13;-1;-1,38;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Feature-map-level Online Adversarial Knowledge Distillation,Inseop Chung;SeongUk Park;Jangho Kim;Nojun Kwak,jis3613@snu.ac.kr;swpark0703@snu.ac.kr;kjh91@snu.ac.kr;nojunk@snu.ac.kr,3;3;6,,Reject,0,4,0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University;Seoul National University,Computer vision;Image classification;Knowledge distillation;Deep Learning,39;39;39;39,64;64;64;64,m;m,asia,kr,n
ICLR,2020,Graph convolutional networks for learning with few clean and many noisy labels,Ahmet Iscen;Giorgos Tolias;Yannis Avrithis;Ondrej Chum;Cordelia Schmid,iscen@google.com;giorgos.tolias@cmp.felk.cvut.cz;yannis@avrithis.net;chum@cmp.felk.cvut.cz;cordelias@google.com,6;6;6,,Reject,0,3,0,yes,9/25/19,Google;Czech Technical University in Prague;INRIA;Czech Technical University in Prague;Google,,-1;168;-1;168;-1,-1;956;-1;956;-1,m;f,NAN,NAN,n
ICLR,2020,Visual Interpretability Alone Helps Adversarial Robustness,Akhilan Boopathy;Sijia Liu;Gaoyuan Zhang;Pin-Yu Chen;Shiyu Chang;Luca Daniel,akhilan@mit.edu;sijia.liu@ibm.com;gaoyuan.zhang@ibm.com;pin-yu.chen@ibm.com;shiyu.chang@ibm.com;dluca@mit.edu,3;6;3,,Reject,0,9,0,yes,9/25/19,Massachusetts Institute of Technology;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Massachusetts Institute of Technology,adversarial robustness;visual explanation;CNN;image classification,5;-1;-1;-1;-1;5,5;-1;-1;-1;-1;5,m;m,usa,usa,y
ICLR,2020,Linguistic Embeddings as a Common-Sense Knowledge Repository: Challenges and Opportunities,Nancy Fulda,nfulda@byu.edu,1;1;3,,Reject,0,0,0,yes,9/25/19,The Hong Kong Polytechnic University,knowledge representation;word embeddings;sentence embeddings;common-sense knowledge,118,171,f,asia,hk,n
ICLR,2020,Starfire: Regularization-Free Adversarially-Robust Structured Sparse Training,Noah Gamboa;Kais Kudrolli;Anand Dhoot;Ardavan Pedram,ngamboa@stanford.edu;kudrolli@stanford.edu;anandd@stanford.edu;perdavan@stanford.edu,1;1;1,,Reject,0,4,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,Structured Sparsity;Sparsity;Training;Compression;Adversarial;Regularization;Acceleration,5;5;5;5,4;4;4;4,m;m,usa,usa,n
ICLR,2020,Pixel Co-Occurence Based Loss Metrics for Super Resolution Texture Recovery,Ying Da Wang;Pawel Swietojanski;Ryan T Armstrong;Peyman Mostaghimi,yingda.wang@unsw.edu.au;p.swietojanski@unsw.edu.au;ryan.armstrong@unsw.edu.au;peyman@unsw.edu.au,1;1;3,,Reject,0,1,0,yes,9/25/19,University of New South Wales;University of New South Wales;University of New South Wales;University of New South Wales,Super Resolution Generative Adversarial Networks;Perceptual Loss Functions,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Cross-Iteration Batch Normalization,Zhuliang Yao;Yue Cao;Shuxin Zheng;Gao Huang;Stephen Lin;Jifeng Dai,yaozhuliang13@gmail.com;yuecao@microsoft.com;shuxin.zheng@microsoft.com;gaohuang@tsinghua.edu.cn;stevelin@microsoft.com;jifdai@microsoft.com,6;3;6,,Reject,3,9,0,yes,9/25/19,"Tsinghua University;Microsoft;Microsoft;Tsinghua University, Tsinghua University;Microsoft;Microsoft",batch normalization;small batch size,-1;-1;-1;4;-1;-1,-1;-1;-1;23;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Exploration via Flow-Based Intrinsic Rewards,Hsuan-Kung Yang;Po-Han Chiang;Min-Fong Hong;Chun-Yi Lee,hellochick@gapp.nthu.edu.tw;ymmoy999@gapp.nthu.edu.tw;romulus@gapp.nthu.edu.tw;cylee@gapp.nthu.edu.tw,6;3;3,,Reject,0,10,0,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;National Tsing Hua University,reinforcement learning;exploration;curiosity;optical flow;intrinsic rewards,194;194;194;194,365;365;365;365,m;m,asia,tw,n
ICLR,2020,Embodied Multimodal Multitask Learning,Devendra Singh Chaplot;Lisa Lee;Ruslan Salakhutdinov;Devi Parikh;Dhruv Batra,chaplot@cs.cmu.edu;lslee@cs.cmu.edu;rsalakhu@cs.cmu.edu;parikh@gatech.edu;dbatra@gatech.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Georgia Institute of Technology;Georgia Institute of Technology,Visual Grounding;Semantic Goal Navigation;Embodied Question Answering,1;1;1;13;13,27;27;27;38;38,m;m,usa,usa,n
ICLR,2020,Towards Principled Objectives for Contrastive Disentanglement,Anwesa Choudhuri;Ashok Vardhan Makkuva;Ranvir Rana;Sewoong Oh;Girish Chowdhary;Alexander Schwing,anwesac2@illinois.edu;makkuva2@illinois.edu;rbrana2@illinois.edu;sewoong@cs.washington.edu;girishc@illinois.edu;aschwing@illinois.edu,3;3;3,,Reject,0,4,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Washington;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",Disentanglement;Contrastive,-1;-1;-1;11;-1;-1,-1;-1;-1;26;-1;-1,f;m,usa,usa,y
ICLR,2020,Hebbian Graph Embeddings,Shalin Shah;Venkataramana Kini,shalin.shah@target.com;venkataramana.kini@target.com,1;1;1,,Reject,0,5,0,yes,9/25/19,Target;Target,graph embeddings;hebbian learning;simulated annealing,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Probabilistic modeling the hidden layers of deep neural networks,Xinjie Lan;Kenneth E. Barner,lxjbit@udel.edu;barner@udel.edu,6;6;8,,Reject,1,8,0,yes,9/25/19,University of Delaware;University of Delaware,Neural Networks;Gaussian Process;Probabilistic Representation for Deep Learning,194;194,295;295,m;m,usa,usa,y
ICLR,2020,Empirical confidence estimates for classification by deep neural networks,Chris Finlay;Adam M. Oberman,christopher.finlay@gmail.com;adam.oberman@mcgill.ca,1;6;6,,Reject,0,4,0,yes,9/25/19,Deep Render;McGill University,confidence;classification;uncertainty;anomaly;robustness,-1;102,-1;42,m;m,canada,ca,n
ICLR,2020,TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising,Ziyi Yang;Chenguang Zhu;Michael Zeng;Xuedong Huang;Eric Darve,ziyi.yang@stanford.edu;chezhu@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com;darve@stanford.edu,8;8;6,,Reject,0,4,0,yes,9/25/19,Stanford University;Microsoft;Microsoft;Microsoft;Stanford University,text summarization;unsupervised learning;natural language processing,5;-1;-1;-1;5,4;-1;-1;-1;4,m;m,usa,usa,n
ICLR,2020,Biologically Plausible Neural Networks via Evolutionary Dynamics and Dopaminergic Plasticity,Sruthi Gorantla;Anand Louis;Christos H. Papadimitriou;Santosh Vempala;Naganand Yadati,sruthi@comp.nus.edu.sg;anandl@iisc.ac.in;christos@columbia.edu;vempala@gatech.edu;y.naganand@gmail.com,1;3;3,,Reject,0,3,0,yes,9/25/19,National University of Singapore;Indian Institute of Science;Columbia University;Georgia Institute of Technology;Indian Institute of Science,Biological plausibility;dopaminergic plasticity;allele frequency;neural net evolution,17;-1;24;13;-1,25;301;16;38;-1,f;m,asia,in,y
ICLR,2020,Meta-Learning Initializations for Image Segmentation,Sean M. Hendryx;Andrew B. Leach;Paul D. Hein;Clayton T. Morrison,seanmhendryx@gmail.com;imaleach@gmail.com;pauldhein@email.arizona.edu;claytonm@email.arizona.edu,3;3;3,,Reject,0,8,0,yes,9/25/19,University of Arizona;Google;University of Arizona;University of Arizona,meta-learning;image segmentation,-1;-1;194;194,-1;-1;103;103,m;m,usa,usa,n
ICLR,2020,Sequence-level Intrinsic Exploration Model for Partially Observable Domains,Haiyan Yin;Jianda Chen;Sinno Jialin Pan,yinhaiyan@outlook.com;jianda001@e.ntu.edu.sg;sinnopan@ntu.edu.sg,6;3;6,,Reject,0,4,0,yes,9/25/19,Baidu;Nanyang Technological University;Nanyang Technological University,deep learning;reinforcement learning,-1;43;43,-1;49;49,f;m,asia,sg,n
ICLR,2020,EINS: Long Short-Term Memory with Extrapolated Input Network Simplification,Nicholas I-Hsien Kuo;Mehrtash T. Harandi;Nicolas Fourrier;Gabriela Ferraro;Christian Walder;Hanna Suominen,u6424547@anu.edu.au;mehrtash.harandi@monash.edu;nicolas.fourrier@devinci.fr;gabriela.ferraro@csiro.au;gabriela.ferraro@data61.csiro.au;christian.walder@data61.csiro.au;hanna.suominen@anu.edu.au,1;1;1,,Reject,0,0,0,yes,9/25/19,Australian National University;Monash University;Ecole Superieur d'Ingenieurs Leonard de Vinci;CSIRO;CSIRO;CSIRO;Australian National University,recurrent neural network;RNN;long short-term memory;LSTM;gated recurrent network;GRU;dynamical mathematics;interpretability,102;92;-1;-1;-1;-1;102,50;75;-1;-1;-1;-1;50,m;f,australasia,au,pdf miss
ICLR,2020,Connectivity-constrained interactive annotations for panoptic segmentation,Ruobing Shen;Bo Tang;Ismail Ben Ayed;Andrea Lodi;Thomas Guthier,ruobing.shen@gmobis.com;lucastang1994@gmail.com;ismail.benayed@etsmtl.ca;andrea.lodi@polymtl.ca;thomas.guthier@gmobis.com,1;3;3;3,,Reject,0,5,0,yes,9/25/19,Hyundai Mobis;;√âcole de technologie sup√©rieure;Polytechnique Montreal;Hyundai Mobis,Panoptic Segmentation;Semantic Segmentation;Interactive Segmentation;Integer Programming,-1;-1;-1;316;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Frustratingly easy quasi-multitask learning,G√°bor Berend;Norbert Kis-Szab√≥,berendg@inf.u-szeged.hu;kis-szabo.norbert@stud.u-szeged.hu,1;3,,Reject,0,2,0,yes,9/25/19,University of Szeged;University of Szeged,multitask learning;ensembling,445;445,874;874,m;m,europe,de,n
ICLR,2020,Towards Effective 2-bit Quantization: Pareto-optimal Bit Allocation for Deep CNNs Compression,Zhe Wang;Jie Lin;Mohamed M. Sabry Aly;Sean I Young;Vijay Chandrasekhar;Bernd Girod,mark.wangzhe@gmail.com;lin-j@i2r.a-star.edu.sg;msabry@ntu.edu.sg;sean.i.young@stanford.edu;vijay@i2r.a-star.edu.sg;bgirod@stanford.edu,8;6;1,,Reject,1,9,0,yes,9/25/19,"Stanford University;Institute for Infocomm Research, A*STAR;Nanyang Technological University;Stanford University;Institute for Infocomm Research, A*STAR;Stanford University",,-1;-1;43;5;-1;5,-1;-1;49;4;-1;4,m;m,usa,usa,y
ICLR,2020,Representing Unordered Data Using Multiset Automata and Complex Numbers,Justin DeBenedetto;David Chiang,jdebened@nd.edu;dchiang@nd.edu,6;3;6,,Reject,0,4,0,yes,9/25/19,University of Notre Dame;University of Notre Dame,sets;multisets;automata;complex numbers;position encodings,118;118,157;157,m;m,usa,usa,y
ICLR,2020,Domain-invariant Learning using Adaptive Filter Decomposition,Ze Wang;Xiuyuan Cheng;Guillermo Sapiro;Qiang Qiu,ze.w@duke.edu;xiuyuan.cheng@duke.edu;guillermo.sapiro@duke.edu;qiang.qiu@duke.edu,6;1;6,,Reject,0,3,0,yes,9/25/19,Duke University;Duke University;Duke University;Duke University,,46;46;46;46,20;20;20;20,m;m,europe,se,y
ICLR,2020,Gradient-free Neural Network Training by Multi-convex Alternating Optimization,Junxiang Wang;Fuxun Yu;Xiang Chen;Liang Zhao,jwang40@gmu.edu;fyu2@gmu.edu;xchen26@gmu.edu;lzhao9@gmu.edu,1;6,,Reject,0,2,0,yes,9/25/19,George Mason University;George Mason University;George Mason University;George Mason University,neural network;alternating minimization;global convergence,85;85;85;85,282;282;282;282,m;m,usa,usa,y
ICLR,2020,GDP: Generalized Device Placement for Dataflow Graphs,Yanqi Zhou;Sudip Roy;Amirali Abdolrashidi;Daniel Wong;Peter C. Ma;Qiumin Xu;Ming Zhong;Hanxiao Liu;Anna Goldie;Azalia Mirhoseini;James Laudon,yanqiz@google.com;sudipr@google.com;abdolrashidi@google.com;wonglkd@google.com;pcma@google.com;qiuminxu@google.com;mingzhong@google.com;hanxiaol@google.com;agoldie@google.com;azalia@google.com;jlaudon@google.com,6;3;6,,Reject,0,6,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google;Google;Google;Google,device placement;reinforcement learning;graph neural networks;transformer,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Policy Optimization In the Face of Uncertainty,Tung-Long Vuong;Han Nguyen;Hai Pham;Kenneth Tran,longvt94@vnu.edu.vn;hann1@andrew.cmu.edu;htpham@cs.cmu.edu;ktran@microsoft.com,3;3;1,,Reject,0,3,0,yes,9/25/19,Australian National University;Carnegie Mellon University;Carnegie Mellon University;Microsoft,Reinforcement Learning;Model-based Reinforcement Learning,102;1;1;-1,50;27;27;-1,m;m,NAN,NAN,n
ICLR,2020,Learning relevant features for statistical inference,C√©dric B√©ny,cedric.beny@gmail.com,3;3;1,,Reject,0,4,0,yes,9/25/19,0,unsupervised learning;non-parametric probabilistic model;singular value decomposition;fisher information metric;chi-squared distance,,,m;m,NAN,NAN,n
ICLR,2020,Accelerating Reinforcement Learning Through GPU Atari Emulation,Steven Dalton;Michael Garland;Iuri Frosio,sdalton@nvidia.com;mgarland@nvidia.com;ifrosio@nvidia.com,1;8;8,,Reject,0,4,0,yes,9/25/19,NVIDIA;NVIDIA;NVIDIA,GPU;reinforcement learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Discrete InfoMax Codes for Meta-Learning,Yoonho Lee;Wonjae Kim;Seungjin Choi,einet89@gmail.com;dandelin.kim@kakaocorp.com;seungjin.choi.mlg@gmail.com,3;3;3,,Reject,0,4,0,yes,9/25/19,AITRICS;Kakao;BARO AI Academy,meta-learning;generalization;discrete representations,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Efficient Saliency Maps for Explainable AI,T. Nathan Mundhenk;Barry Chen;Gerald Friedland,mundhenk1@llnl.gov;chen52@llnl.gov;fractor@eecs.berkeley.edu,6;6;3,,Reject,0,22,0,yes,9/25/19,Lawrence Livermore National Labs;Lawrence Livermore National Labs;University of California Berkeley,Saliency;XAI;Efficent;Information,-1;-1;-1,-1;-1;13,m;m,usa,usa,n
ICLR,2020,Monte Carlo Deep Neural Network Arithmetic,Julian Faraone;Philip Leong,julian.faraone@sydney.edu.au;philip.leong@sydney.edu.au,3;3;6,,Reject,0,4,0,yes,9/25/19,University of Sydney;University of Sydney,deep learning;quantization;floating point;monte carlo methods,64;64,60;60,m;m,europe,uk,n
ICLR,2020,Language-independent Cross-lingual Contextual Representations,Xiao Zhang;Song Wang;Dejing Dou;Xien Liu;Thien Huu Nguyen;Ji Wu,xzhang19@mails.tsinghua.edu.cn;wangsong16@mails.tsinghua.edu.cn;dou@cs.uoregon.edu;xeliu@mail.tsinghua.edu.cn;thien@cs.uoregon.edu;wuji_ee@mail.tsinghua.edu.cn,3;3;3,,Reject,0,1,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;University of Oregon;Tsinghua University, Tsinghua University;University of Oregon;Tsinghua University, Tsinghua University",contextual representation;cross-lingual;transfer learning,4;4;194;4;194;4,23;23;288;23;288;23,m;m,NAN,NAN,n
ICLR,2020,Deep Nonlinear Stochastic Optimal Control for Systems with Multiplicative Uncertainties,Marcus Pereira;Ziyi Wang;Tianrong Chen;Evangelos Theodorou,mpereira30@gatech.edu;zwang450@gatech.edu;tianrong.chen@gatech.edu;evangelos.theodorou@gatech.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,Deep Learning;Stochastic Optimal Control;Robotics;Biomechanics;LSTM,13;13;13;13,38;38;38;38,m;m,usa,usa,n
ICLR,2020,Causal Induction from Visual Observations for Goal Directed Tasks,Suraj Nair;Yuke Zhu;Silvio Savarese;Li Fei-Fei,surajn@stanford.edu;yukez@cs.stanford.edu;ssilvio@stanford.edu;feifeili@cs.stanford.edu,6;3;6,,Reject,0,3,0,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,meta-learning;causal reasoning;policy learning,5;5;5;5,4;4;4;4,m;f,usa,usa,n
ICLR,2020,Towards Understanding the Spectral Bias of Deep Learning,Yuan Cao;Zhiying Fang;Yue Wu;Ding-Xuan Zhou;Quanquan Gu,yuancao@cs.ucla.edu;zyfang4-c@my.cityu.edu.hk;ywu@cs.ucla.edu;mazhou@cityu.edu.hk;qgu@cs.ucla.edu,3;6;6,,Reject,0,3,0,yes,9/25/19,"University of California, Los Angeles;The Hong Kong Polytechnic University;University of California, Los Angeles;The Hong Kong Polytechnic University;University of California, Los Angeles",,-1;118;-1;118;-1,17;171;17;171;17,m;m,usa,usa,y
ICLR,2020,Reweighted Proximal Pruning for Large-Scale Language Representation,Fu-Ming Guo;Sijia Liu;Finlay S. Mungall;Xue Lin;Yanzhi Wang,elphinkuo@gmail.com;sijia.liu@ibm.com;fmungall@gmail.com;xue.lin@northeastern.edu;yanz.wang@northeastern.edu,6;6;6,,Reject,0,7,1,yes,9/25/19,Northeastern University;International Business Machines;;Northeastern University;Northeastern University,Language Representation;Machine Learning;Deep Learning;Optimizer;Statistical Learning;Model Compression,-1;-1;-1;16;16,-1;-1;-1;906;906,m;m,usa,usa,n
ICLR,2020,Distilled embedding: non-linear embedding factorization using knowledge distillation,Vasileios Lioutas;Ahmad Rashid;Krtin Kumar;Md Akmal Haidar;Mehdi Rezagholizadeh,vasileios.lioutas@carleton.ca;ahmad.rashid@huawei.com;krtin.kumar@huawei.com;md.akmal.haidar@huawei.com;mehdi.rezagholizadeh@huawei.com,3;3;3,,Reject,0,6,0,yes,9/25/19,Carleton University;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Model Compression;Embedding Compression;Low Rank Approximation;Machine Translation;Natural Language Processing;Deep Learning,194;-1;-1;-1;-1,535;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Switched linear projections and inactive state sensitivity for deep neural network interpretability,Lech Szymanski;Brendan McCane;Craig Atkinson,lechszym@cs.otago.ac.nz;mccane@cs.otago.ac.nz;atkcr398@student.otago.ac.nz,1;3;6;6,,Reject,0,17,0,yes,9/25/19,University of Otago;University of Otago;University of Otago,deep learning;interpretability;artificial neural networks,445;445;445,218;218;218,m;m,australasia,nz,y
ICLR,2020,SpectroBank: A filter-bank convolutional layer for CNN-based audio applications,Helena Peic Tukuljac;Benjamin Ricaud;Nicolas Aspert;Pierre Vandergheynst,helena.peictukuljac@epfl.ch;benjamin.ricaud@epfl.ch;nicolas.aspert@epfl.ch;pierre.vandergheynst@epfl.ch,3;3;3,,Reject,0,8,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,audio;classification;convolutional neural network;deep learning;filter;filter-bank;raw waveform,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Stochastic Latent Residual Video Prediction,Jean-Yves Franceschi;Edouard Delasalles;Mickael Chen;Sylvain Lamprier;Patrick Gallinari,jean-yves.franceschi@lip6.fr;edouard.delasalles@lip6.fr;mickael.chen@lip6.fr;sylvain.lamprier@lip6.fr;patrick.gallinari@lip6.fr,6;3;6,,Reject,0,4,1,yes,9/25/19,LIP6;LIP6;LIP6;LIP6;LIP6,stochastic video prediction;variational autoencoder;residual dynamics,445;445;445;445;445,-1;-1;-1;-1;-1,m;m,asia,ir,n
ICLR,2020,Large-scale Pretraining for Neural Machine Translation with Tens of Billions of Sentence Pairs,Yuxian Meng;Xiangyuan Ren;Zijun Sun;Xiaoya Li;Arianna Yuan;Fei Wu;Jiwei Li,yuxian_meng@shannonai.com;xiangyuan_re@shannonai.com;zijun_sun@shannonai.com;xiaoya_li@shannonai.com;xfyuan@stanford.edu;wufei@zju.edu.cn;jiwei_li@shannonai.com,3;6;3,,Reject,1,4,0,yes,9/25/19,Shannon.AI;Shannon.AI;Shannon.AI;Shannon.AI;Stanford University;Zhejiang University;Shannon.AI,,-1;-1;-1;-1;5;39;-1,-1;-1;-1;-1;4;107;-1,m;m,NAN,NAN,n
ICLR,2020,Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures,Mohamed El Amine Seddik;Cosme Louart;Mohamed Tamaazousti;Romain Couillet,melaseddik@gmail.com;cosme.louart@gmail.com;mohamed.tamaazousti@cea.fr;romain.couillet@gmail.com,6;3;1,,Reject,0,5,0,yes,9/25/19,Ecole polytechnique;;CEA;Institut Polytechnique de Grenoble,Random Matrix Theory;Deep Learning Representations;GANs,-1;-1;194;-1,93;-1;1027;-1,m;m,asia,in,y
ICLR,2020,The advantage of using Student's t-priors in variational autoencoders,Najmeh Abiri;Mattias Ohlsson,najmeh@thep.lu.se;mattias@thep.lu.se,1;1;1,,Reject,0,0,0,yes,9/25/19,Lund University;Lund University,Variational Autoencoders;DLVMs;Posterior Collapse,445;445,98;98,f;m,asia,cn,n
ICLR,2020,Neural Communication Systems with Bandwidth-limited Channel,Karen Ullrich;Fabio Viola;Danilo J. Rezende,mail.karen.ullrich@gmail.com;fviola@google.com;danilor@google.com,3;6;6,,Reject,0,3,0,yes,9/25/19,Facebook;Google;Google,variational inference;joint coding;bandwidth-limited channel;deep learning;representation learning;compression,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Unified Probabilistic Deep Continual Learning through Generative Replay and Open Set Recognition,Martin Mundt;Sagnik Majumder;Iuliia Pliushch;Visvanathan Ramesh,mmundt@em.uni-frankfurt.de;majumder@ccc.cs.uni-frankfurt.de;pliushch@em.uni-frankfurt.de;ramesh@fias.uni-frankfurt.de,6;3;3,,Reject,0,5,0,yes,9/25/19,Goethe University;Goethe University;Goethe University;Goethe University,Continual Learning;Open Set Recognition;Probabilistic Deep Learning;Variational Inference,316;316;316;316,305;305;305;305,m;m,NAN,NAN,n
ICLR,2020,Optimizing Loss Landscape Connectivity via Neuron Alignment,N. Joseph Tatro;Pin-Yu Chen;Payel Das;Igor Melnyk;Prasanna Sattigeri;Rongjie Lai,tatron@rpi.edu;pin-yu.chen@ibm.com;daspa@us.ibm.com;igor.melnyk@ibm.com;psattig@us.ibm.com;lair@rpi.edu,1;6;3,,Reject,0,6,0,yes,9/25/19,Rensselaer Polytechnic Institute;International Business Machines;International Business Machines;International Business Machines;International Business Machines;Rensselaer Polytechnic Institute,deep learning;optimization;non-convex optimization,248;-1;-1;-1;-1;248,438;-1;-1;-1;-1;438,m;m,usa,usa,y
ICLR,2020,Adaptive Online Planning for Continual Lifelong Learning,Kevin Lu;Igor Mordatch;Pieter Abbeel,kzl@berkeley.edu;imordatch@google.com;pabbeel@cs.berkeley.edu,1;6;3,,Reject,0,5,0,yes,9/25/19,University of California Berkeley;Google;University of California Berkeley,reinforcement learning;model predictive control;planning;model based;model free;uncertainty;computation,-1;-1;-1,13;-1;13,m;m,usa,usa,n
ICLR,2020,Adversarially Robust Generalization Just Requires More Unlabeled Data,Runtian Zhai;Tianle Cai;Di He;Chen Dan;Kun He;John E. Hopcroft;Liwei Wang,zhairuntian@pku.edu.cn;caitianle1998@pku.edu.cn;dihe@microsoft.com;cdan@cs.cmu.edu;brooklet60@hust.edu.cn;jeh17@cornell.edu;wanglw@cis.pku.edu.cn,3;3;3,,Reject,0,0,0,yes,9/25/19,Peking University;Peking University;Microsoft;Carnegie Mellon University;Hong Kong University of Science and Technology;Cornell University;Peking University,Adversarial Robustness;Semi-supervised Learning,14;14;-1;1;-1;7;14,24;24;-1;27;47;19;24,m;m,asia,cn,y
ICLR,2020,Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing,Dinghuai Zhang*;Mao Ye*;Chengyue Gong*;Zhanxing Zhu;Qiang Liu,zhangdinghuai@pku.edu.cn;lushleaf21@gmail.com;cygong@cs.utexas.edu;zhanxing.zhu@pku.edu.cn;lqiang@cs.utexas.edu,1;1;3,,Reject,2,5,0,yes,9/25/19,"Peking University;;University of Texas, Austin;Peking University;University of Texas, Austin",Adversarial Certification;Randomized Smoothing;Functional Optimization,14;-1;-1;14;-1,24;-1;-1;24;-1,m;m,usa,usa,y
ICLR,2020,Zeno++: Robust Fully Asynchronous SGD,Cong Xie;Oluwasanmi Koyejo;Indranil Gupta,cx2@illinois.edu;sanmi@illinois.edu;indy@illinois.edu,3;3;6,,Reject,0,9,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",fault-tolerance;Byzantine-tolerance;security;SGD;asynchronous,-1;-1;-1,-1;-1;-1,m;m,usa,usa,y
ICLR,2020,LARGE SCALE REPRESENTATION LEARNING FROM TRIPLET COMPARISONS,Siavash Haghiri;Leena Chennuru Vankadara;Ulrike von Luxburg,siyavash.haghiri@gmail.com;leena.chennuru-vankadara@uni-tuebingen.de;luxburg@informatik.uni-tuebingen.de,3;1;3;6,,Reject,0,9,0,yes,9/25/19,University of Tuebingen;University of Tuebingen;University of Tuebingen,representation learning;triplet comparison;contrastive learning;ordinal embedding,-1;143;143,-1;91;91,m;f,europe,de,n
ICLR,2020,A Mean-Field Theory for Kernel Alignment with Random Features in Generative Adverserial Networks,Masoud Badiei Khuzani;Liyue Shen;Shahin Shahrampour;Lei Xing,mbadieik@stanford.edu;liyues@stanford.edu;shahin@tamu.edu;lei@stanford.edu,1;6;6,,Reject,0,3,0,yes,9/25/19,Stanford University;Stanford University;Texas A&M;Stanford University,Kernel Learning;Generative Adversarial Networks;Mean Field Theory,5;5;46;5,4;4;177;4,m;m,usa,usa,y
ICLR,2020,Homogeneous Linear Inequality Constraints for Neural Network Activations,Thomas Frerix;Matthias Nie√üner;Daniel Cremers,thomas.frerix@tum.de;niessner@tum.de;cremers@tum.de,1;3;3,,Reject,0,4,0,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,deep learning;constrained optimization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Distributed Online Optimization with Long-Term Constraints,Deming Yuan;Alexandre Proutiere;Guodong Shi,dmyuan1012@gmail.com;alepro@kth.se;guodong.shi@anu.edu.au,3;6;6,,Reject,0,5,0,yes,9/25/19,"Australian National University;KTH Royal Institute of Technology, Stockholm, Sweden;Australian National University",,-1;194;102,-1;222;50,m;m,australasia,au,y
ICLR,2020,Semi-supervised Pose Estimation with Geometric Latent Representations,Luis A. Perez Rey;Dmitri Jarnikov;Mike Holenderski,l.a.perez.rey@tue.nl;d.s.jarnikov@tue.nl;m.holenderski@tue.nl,3;3;1,,Reject,0,3,0,yes,9/25/19,Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology,Semi-supervised learning;pose estimation;angle estimation;variational autoencoders,-1;-1;-1,185;185;185,m;m,NAN,NAN,n
ICLR,2020,Parallel Scheduled Sampling,Daniel Duckworth;Arvind Neelakantan;Ben Goodrich;Lukasz Kaiser;Samy Bengio,duckworthd@google.com;aneelakantan@google.com;bgoodrich@google.com;lukaszkaiser@google.com;bengio@google.com,6;3;6,,Reject,0,7,0,yes,9/25/19,Google;Google;Google;Google;Google,deep learning;generative models;teacher forcing;scheduled sampling,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ADAPTING PRETRAINED LANGUAGE MODELS FOR LONG DOCUMENT CLASSIFICATION,Matthew Lyle Olson;Lisa Zhang;Chun-Nam Yu,olsomatt@oregonstate.edu;lisa.zhang@nokia-bell-labs.com;cnyu@cs.cornell.edu,3;3;6,,Reject,0,3,0,yes,9/25/19,Oregon State University;Bell Labs;Cornell University,NLP;Deep Learning;Language Models;Long Document,79;-1;7,373;-1;19,m;m,usa,usa,n
ICLR,2020,Composable Semi-parametric Modelling for Long-range Motion Generation,Jingwei Xu;Huazhe Xu;Bingbing Ni;Xiaokang Yang;Trevor Darrell,xjwxjw@sjtu.edu.cn;huazhe_xu@eecs.berkeley.edu;nibingbing@sjtu.edu.cn;xkyang@sjtu.edu.cn;trevor@eecs.berkeley.edu,3;6;3,,Reject,0,3,0,yes,9/25/19,Shanghai Jiao Tong University;University of California Berkeley;Shanghai Jiao Tong University;Shanghai Jiao Tong University;University of California Berkeley,Semi-parametric;Long-range;Motion Generation,30;-1;30;30;-1,157;13;157;157;13,m;m,usa,usa,n
ICLR,2020,Finding Mixed Strategy Nash Equilibrium for Continuous Games through Deep Learning,Zehao Dou;Xiang Yan;Dongge Wang;Xiaotie Deng,zehaodou@pku.edu.cn;yxghost@sjtu.edu.cn;dgwang96@pku.edu.cn;xiaotie@pku.edu.cn,6;6;3,,Reject,0,9,0,yes,9/25/19,Peking University;Shanghai Jiao Tong University;Peking University;Peking University,Mixed strategy Nash Equilibrium;Continuous Game;Pushforward Measure;NI Function,14;30;14;14,24;157;24;24,m;m,asia,cn,y
ICLR,2020,Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets,Zhilu Zhang;Adrian V. Dalca;Mert R. Sabuncu,zz452@cornell.edu;adalca@mit.edu;msabuncu@cornell.edu,3;1;1,,Reject,0,3,0,yes,9/25/19,Cornell University;Massachusetts Institute of Technology;Cornell University,Uncertainty Estimation;Calibration;Deep Learning,7;5;7,19;5;19,m;m,usa,usa,n
ICLR,2020,Online Learned Continual Compression with Stacked Quantization Modules,Lucas Caccia;Eugene Belilovsky;Massimo Caccia;Joelle Pineau,lucas.page-caccia@mail.mcgill.ca;belilovsky.eugene@gmail.com;massimo.p.caccia@gmail.com;jpineau@cs.mcgill.ca,3;3;6;3;6,,Reject,1,4,0,yes,9/25/19,McGill University;University of Montreal;University of Montreal;McGill University,continual learning;lifelong learning,102;118;118;102,42;85;85;42,m;f,canada,ca,n
ICLR,2020,Yet another but more efficient black-box adversarial attack: tiling and evolution strategies,Laurent Meunier;Jamal Atif;Olivier Teytaud,laurent.meunier1995@gmail.com;jamal.atif@dauphine.fr;oteytaud@fb.com,3;3;3,,Reject,0,5,0,yes,9/25/19,Univerist√© Paris-Dauphine;Univerist‚àö¬© Paris-Dauphine;Facebook,adversarial examples;black-box attacks;derivative free optimization;deep learning,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,AlignNet: Self-supervised Alignment Module,Antonia Creswell;Luis Piloto;David Barrett;Kyriacos Nikiforou;David Raposo;Marta Garnelo;Peter Battaglia;Murray Shanahan,tonicreswell@google.com;piloto@google.com;peterbattaglia@google.com;knikiforou@google.com;barrettdavid@google.com;garnelo@google.com;mshanahan@google.com;draposo@google.com,6;3;1,,Reject,0,3,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google;Google,Graph networks;alignment;objects;relation networks,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,A Simple Recurrent Unit with Reduced Tensor Product Representations,Shuai Tang;Paul Smolensky;Virginia R. de Sa,shuaitang93@ucsd.edu;paul.smolensky@gmail.com;desa@ucsd.edu,6;3;3,,Reject,0,1,0,yes,9/25/19,"University of California, San Diego;Microsoft;University of California, San Diego",RNNs;TPRs,-1;-1;-1,31;-1;31,m;f,usa,usa,n
ICLR,2020,A Hierarchy of Graph Neural Networks Based on Learnable Local Features,Michael Lingzhi Li;Meng Dong;Jiawei Zhou;Alexander M. Rush,mlli@mit.edu;mengdong@g.harvard.edu;jzhou02@g.harvard.edu;srush@cornell.edu,3;8;3,,Reject,0,6,0,yes,9/25/19,Massachusetts Institute of Technology;Harvard University;Harvard University;Cornell University,Graph Neural Networks;Hierarchy;Weisfeiler-Lehman;Discriminative Power,5;52;52;7,5;7;7;19,m;m,usa,usa,y
ICLR,2020,Discriminability Distillation in Group Representation Learning,Manyuan ZhangÔºåGuanglu SongÔºåYu LiuÔºåHang Zhou,zhangmanyuan@sensetime.com;songguanglu@sensetime.com;yuliu@ee.cuhk.edu.hk;zhouhang@link.cuhk.edu.hk,3;1;6;6,,Reject,0,4,0,yes,9/25/19,SenseTime Group Limited;SenseTime Group Limited;The Chinese University of Hong Kong;The Chinese University of Hong Kong,,-1;-1;316;316,-1;-1;35;35,f;m,NAN,NAN,n
ICLR,2020,Blurring Structure and Learning to Optimize and Adapt Receptive Fields,Evan Shelhamer;Dequan Wang;Trevor Darrell,shelhamer@cs.berkeley.edu;dqwang@eecs.berkeley.edu;trevor@eecs.berkeley.edu,3;6;3,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,scale;deep learning;dynamic inference;fully convolutional,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Conditional Flow Variational Autoencoders for Structured Sequence Prediction,Apratim Bhattacharyya;Michael Hanselmann;Mario Fritz;Bernt Schiele;Christoph-Nikolas Straehle,abhattac@mpi-inf.mpg.de;michael.hanselmann@de.bosch.com;fritz@cispa.saarland;schiele@mpi-inf.mpg.de;christoph-nikolas.straehle@de.bosch.com,6;6;1,,Reject,0,4,0,yes,9/25/19,Max-Planck Institute;Bosch;CISPA Helmholtz Center for Information Security;Max-Planck Institute;Bosch,Variational Inference;Normalizing Flows;Trajectories,-1;-1;92;-1;-1,-1;297;-1;-1;297,m;m,NAN,NAN,n
ICLR,2020,LAVAE: Disentangling Location and Appearance,Andrea Dittadi;Ole Winther,adit@dtu.dk;olwi@dtu.dk,1;1;3,,Reject,0,2,0,yes,9/25/19,Technical University of Denmark;Technical University of Denmark,structured scene representations;compositional representations;generative models;unsupervised learning,-1;-1,182;182,m;m,NAN,NAN,n
ICLR,2020,BETANAS: Balanced Training and selective drop for Neural Architecture Search,Muyuan Fang;Qiang Wang;Jian Zhang;Zhao Zhong,fangmuyuan@huawei.com;wangqiang168@huawei.com;zhangjian157@huawei.com;zorro.zhongzhao@huawei.com,3;3;6,,Reject,0,4,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,neural architecture search;weight sharing;auto machine learning;deep learning;CNN,-1;-1;-1;-1,-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Unifying Graph Convolutional Neural Networks and Label Propagation,Hongwei Wang;Jure Leskovec,wanghongwei55@gmail.com;jure@cs.stanford.edu,3;6;1,,Reject,0,3,0,yes,9/28/20,Stanford University;Stanford University,graph convolutional neural networks;label propagation;node classification,5;5,4;4,m;m,usa,usa,y
ICLR,2020,Defective Convolutional Layers Learn Robust CNNs,Tiange Luo;Tianle Cai;Xiaomeng Zhang;Siyu Chen;Di He;Liwei Wang,luotg@pku.edu.cn;caitianle1998@pku.edu.cn;zhan147@usc.edu;siyuchen@pku.edu.cn;dihe@microsoft.com;wanglw@cis.pku.edu.cn,3;1;6,,Reject,0,4,0,yes,9/25/19,Peking University;Peking University;University of Southern California;Peking University;Microsoft;Peking University,adversarial examples;robust machine learning;cnn structure;deep feature representations,14;14;36;14;-1;14,24;24;62;24;-1;24,m;m,asia,cn,n
ICLR,2020,Unsupervised Progressive Learning and the STAM Architecture,James Smith;Constantine Dovrolis,jamessealesmith@gatech.edu;constantine@gatech.edu,8;3;8,,Reject,0,5,2,yes,9/28/20,Georgia Institute of Technology;Georgia Institute of Technology,continual learning;unsupervised learning;online learning,13;13,38;38,m;m,usa,usa,n
ICLR,2020,Asymptotic learning curves of kernel methods: empirical data v.s. Teacher-Student paradigm,Stefano Spigler;Mario Geiger;Matthieu Wyart,stefano.spigler@epfl.ch;mario.geiger@epfl.ch;matthieu.wyart@epfl.ch,3;3;6,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation,Ran Tian;Shashi Narayan;Thibault Sellam;Ankur P. Parikh,tianran@google.com;shashinarayan@google.com;tsellam@google.com;aparikh@google.com,6;3;8;3,,Reject,0,9,0,yes,9/25/19,Google;Google;Google;Google,Natural Language Processing;Text Generation;Data-to-Text Generation;Hallucination;Calibration;Variational Bayes,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Evidence-Aware Entropy Decomposition For  Active Deep Learning,Weishi Shi;Xujiang Zhao;Feng Chen;Qi Yu,ws7586@rit.edu;xujiang.zhao@utdallas.edu;feng.chen@utdallas.edu;qi.yu@rit.edu,6;3,,Reject,0,5,0,yes,9/25/19,"Rochester Institute of Technology;University of Texas, Dallas;University of Texas, Dallas;Rochester Institute of Technology",active learning;entropy decomposition;uncertainty,118;-1;-1;118,843;-1;-1;843,m;m,usa,usa,y
ICLR,2020,Meta-Learning by Hallucinating Useful Examples,Yu-Xiong Wang;Yuki Uchiyama;Martial Hebert;Karteek Alahari,yuxiongw@cs.cmu.edu;braverthan2@gmail.com;hebert@ri.cmu.edu;karteek.alahari@inria.fr,3;6;6,,Reject,0,5,0,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University;INRIA,few-shot learning;meta-learning,1;-1;1;-1,27;-1;27;-1,m;m,europe,gr,n
ICLR,2020,PDP: A General Neural Framework for Learning SAT Solvers,Saeed Amizadeh;Sergiy Matusevych;Markus Weimer,saamizad@microsoft.com;sergiym@microsoft.com;markus.weimer@microsoft.com,1;6;3,,Reject,0,3,0,yes,9/25/19,Microsoft;Microsoft;Microsoft,Neural SAT solvers;Graph Neural Networks;Neural Message Passing;Unsupervised Learning;Neural Decimation,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Consistency-Based Semi-Supervised Active Learning: Towards Minimizing Labeling Budget,Mingfei Gao;Zizhao Zhang;Guo Yu;Sercan O. Arik;Larry S. Davis;Tomas Pfister,mgao@cs.umd.edu;zizhaoz@google.com;gy63@uw.edu;soarik@google.com;lsd@umiacs.umd.edu;tpfister@google.com,6;6,,Reject,0,6,0,yes,9/25/19,"University of Maryland, College Park;Google;University of Washington, Seattle;Google;University of Maryland, College Park;Google",Active learning;semi-supervised learning,12;-1;11;-1;12;-1,91;-1;26;-1;91;-1,m;m,NAN,NAN,y
ICLR,2020,TabNet: Attentive Interpretable Tabular Learning,Sercan O. Arik;Tomas Pfister,soarik@google.com;tpfister@google.com,6;3;3,,Reject,1,8,0,yes,9/25/19,Google;Google,Tabular data;interpretable neural networks;attention models,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Adapting Behaviour for Learning Progress,Tom Schaul;Diana Borsa;David Ding;David Szepesvari;Georg Ostrovski;Will Dabney;Simon Osindero,schaul@google.com;borsa@google.com;fding@google.com;dsz@google.com;ostrovski@google.com;wdabney@google.com;osindero@google.com,6;3;3;3,,Reject,0,6,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,adaptation;behaviour;reinforcement learning;modulated behaviour;exploration;deep reinforcement learning,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Improving Differentially Private Models with Active Learning,Zhengli Zhao;Nicolas Papernot;Sameer Singh;Neoklis Polyzotis;Augustus Odena,zhengliz@uci.edu;papernot@google.com;sameer@uci.edu;npolyzotis@google.com;augustusodena@google.com,3;3;1,,Reject,1,5,0,yes,9/25/19,"University of California, Irvine;Google;University of California, Irvine;Google;Google",Differential Privacy;Active Learning,-1;-1;-1;-1;-1,96;-1;96;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Style-based Encoder Pre-training for Multi-modal Image Synthesis,Moustafa Meshry;Yixuan Ren;Ricardo Martin-Brualla;Larry Davis;Abhinav Shrivastava,mmeshry@cs.umd.edu;yxren@cs.umd.edu;rmbrualla@google.com;lsd@umiacs.umd.edu;abhinav@cs.umd.edu,3;3;3,,Reject,0,4,0,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;Google;University of Maryland, College Park;University of Maryland, College Park",image-to_image translation;representation learning;multi-modal image synthesis;GANs,12;12;-1;12;12,91;91;-1;91;91,m;m,usa,usa,n
ICLR,2020,GRAPH ANALYSIS AND GRAPH POOLING IN THE SPATIAL DOMAIN,Mostafa Rahmani;Ping Li,mostafarahmani@baidu.com;liping11@baidu.com,6;6;3,,Reject,0,9,1,yes,9/25/19,Baidu;Baidu,Graph Neural Network;Graph Classification;Graph Pooling;Graph Embedding,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Cover Filtration and Stable Paths in the Mapper,Dustin L. Arendt;Matthew Broussard;Bala Krishnamoorthy;Nathaniel Saul,dustin.arendt@pnnl.gov;matthew.broussard@wsu.edu;kbala@wsu.edu;nat@riverasaul.com,1;6,,Reject,0,7,0,yes,9/25/19,Pacific Northwest National Laboratory;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Riverasaul,cover and nerve;Jaccard distance;stable paths in filtration;Mapper;recommender systems;explainable machine learning,-1;-1;-1;-1,-1;299;299;-1,m;m,NAN,NAN,y
ICLR,2020,Rigging the Lottery: Making All Tickets Winners,Utku Evci;Erich Elsen;Pablo Castro;Trevor Gale,ue225@nyu.edu;eriche@google.com;tgale@google.com;psc@google.com,3;6;6,,Reject,0,13,4,yes,9/25/19,New York University;Google;Google;Google,sparse training;sparsity;pruning;lottery tickets;imagenet;resnet;mobilenet;efficiency;optimization;local minima,22;-1;-1;-1,29;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Disentangled GANs for Controllable Generation of High-Resolution Images,Weili Nie;Tero Karras;Animesh Garg;Shoubhik Debhath;Anjul Patney;Ankit B. Patel;Anima Anandkumar,wn8@rice.edu;tkarras@nvidia.com;garg@cs.toronto.edu;shoubhikdn@gmail.com;anjul.patney@gmail.com;abp4@rice.edu;animakumar@gmail.com,3;3;3,,Reject,0,5,0,yes,9/25/19,Rice University;NVIDIA;University of Toronto;NVIDIA;Facebook;Rice University;California Institute of Technology,Disentangled GANs;controllable generation;high-resolution image synthesis;semantic manipulation;fine-grained factors,92;-1;18;-1;-1;92;143,105;-1;18;-1;-1;105;2,m;f,usa,usa,n
ICLR,2020,UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS,Israr Ul Haq;Yoshinobu Kawahara,israr.haq@riken.jp;kawahara@imi.kyushu-u.ac.jp,3;3;6,,Reject,0,0,0,yes,9/25/19,RIKEN;Kyushu University,Non-linear dynamics;Convolutional Autoencoder;Foreground modeling;Video classification;Dynamic mode decomposition,-1;-1,-1;460,m;m,NAN,NAN,n
ICLR,2020,First-Order Preconditioning via Hypergradient Descent,Ted Moskovitz;Rui Wang;Janice Lan;Sanyam Kapoor;Thomas Miconi;Jason Yosinski;Aditya Rawal,thmoskovitz@gmail.com;ruiwang@uber.com;janlan@uber.com;sanyam@uber.com;tmiconi@uber.com;yosinski@uber.com;aditya.rawal@uber.com,3;3;3,,Reject,0,6,0,yes,9/25/19,University College London;Uber;Uber;Uber;Uber;Uber;Uber,optimization;deep learning;hypgergradient,52;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,southamerica,br,n
ICLR,2020,Zero-shot task adaptation by homoiconic meta-mapping,Andrew K. Lampinen;James L. McClelland,lampinen@stanford.edu;jlmcc@stanford.edu,3;3;3,,Reject,0,8,0,yes,9/25/19,Stanford University;Stanford University,Meta-mapping;zero-shot;task adaptation;task representation;meta-learning,5;5,4;4,m;m,usa,usa,n
ICLR,2020,MLModelScope: A Distributed Platform for ML Model Evaluation and Benchmarking at Scale,Cheng Li;Abdul Dakkak;Jinjun Xiong;Wen-mei Hwu,cli99@illinois.edu;dakkak@illinois.edu;jinjun@us.ibm.com;w-hwu@illinois.edu,1;6;6,,Reject,0,13,0,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;International Business Machines;University of Illinois, Urbana Champaign",Evaluation;Scalable;Repeatable;Fair;System,-1;-1;-1;-1,-1;-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Efficient Multivariate Bandit Algorithm with Path Planning,Keyu Nie;Zezhong Zhang;Ted Tao Yuan;Rong Song;Pauline Berry Burke,keyunie@google.com;zezzhang@ebay.com;teyuan@ebay.com;rsong@ebay.com;pmburke10@gmail.com,3;1;6,,Reject,0,2,0,yes,9/25/19,Google;eBay;eBay;eBay;eBay,Multivariate Multi-armed Bandit;Monte Carlo Tree Search;Thompson Sampling;Path Planning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;f,asia,in,n
ICLR,2020,Statistical Adaptive Stochastic Optimization,Pengchuan Zhang;Hunter Lang;Qiang Liu;Lin Xiao,penzhan@microsoft.com;hjl@mit.edu;lqiang@cs.utexas.edu;lin.xiao@microsoft.com,6;8;3,,Reject,0,6,0,yes,9/25/19,"Microsoft;Massachusetts Institute of Technology;University of Texas, Austin;Microsoft",,-1;5;-1;-1,-1;5;-1;-1,m;m,NAN,NAN,n
ICLR,2020,The Benefits of Over-parameterization at Initialization in Deep ReLU Networks,Devansh Arpit;Yoshua Bengio,devansharpit@gmail.com;yoshua.bengio@mila.quebec,1;3;3;3,,Reject,0,0,0,yes,9/25/19,SalesForce.com;Mila,deep relu networks;he initialization;norm preserving;gradient preserving,-1;143,-1;336,m;m,NAN,NAN,n
ICLR,2020,Multichannel Generative Language Models,Harris Chan;Jamie Kiros;William Chan,hchan@cs.toronto.edu;kiros@google.com;williamchan@google.com,3;3;1,,Reject,0,3,0,yes,9/25/19,University of Toronto;Google;Google,text generation;generative language models;natural language processing,18;-1;-1,18;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Set Functions for Time Series,Max Horn;Michael Moor;Christian Bock;Bastian Rieck;Karsten Borgwardt,max.horn@bsse.ethz.ch;michael.moor@bsse.ethz.ch;christian.bock@bsse.ethz.ch;bastian.rieck@bsse.ethz.ch;karsten.borgwardt@bsse.ethz.ch,6;6;3,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Time Series;Set functions;Irregularly sampling;Medical Time series;Dynamical Systems;Time series classification,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,HIPPOCAMPAL NEURONAL REPRESENTATIONS IN CONTINUAL LEARNING,Samia Mohinta;Rui Ponte Costa;Stephane Ciocchi,dc18393@bristol.ac.uk;rui.costa@bristol.ac.uk,1;1;3;6,,Reject,0,4,0,yes,9/25/19,University of Bristol;University of Bristol,,118;118,87;87,f;m,europe,uk,n
ICLR,2020,Augmenting Transformers with KNN-Based Composite Memory,Angela Fan;Claire Gardent;Chloe Braud;Antoine Bordes,angelafan@fb.com;claire.gardent@loria.fr;chloe.braud@loria.fr;abordes@fb.com,6;6;3,,Reject,0,3,0,yes,9/25/19,Facebook;University of Lorraine;University of Lorraine;Facebook,knn;memory-augmented networks;language generation;dialogue,-1;-1;-1;-1,-1;624;624;-1,f;m,NAN,NAN,n
ICLR,2020,Winning Privately: The Differentially Private Lottery Ticket Mechanism,Lovedeep Gondara;Ke Wang;Ricardo Silva Carvalho,lgondara@sfu.ca;wang@sfu.ca;ricardo_silva_carvalho@sfu.ca,3;3;3,,Reject,1,3,0,yes,9/25/19,Simon Fraser University;Simon Fraser University;Simon Fraser University,Differentially private neural networks;lottery ticket hypothesis;differential privacy,52;52;52,272;272;272,m;m,canada,ca,y
ICLR,2020,Localizing and Amortizing: Efficient Inference for Gaussian Processes,Linfeng Liu;Liping Liu,linfeng.liu@tufts.edu;liping.liu@tufts.edu,1;3;3,,Reject,1,5,0,yes,9/25/19,Tufts University;Tufts University,Gaussian Processes;Variational Inference;Amortized Inference;Nearest Neighbors,194;194,139;139,m;m,usa,usa,n
ICLR,2020,BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning,Xinyue Chen;Zijian Zhou;Zheng Wang;Che Wang;Yanqiu Wu;Qing Deng;Keith Ross,xc1305@nyu.edu;zz1435@nyu.edu;zw1454@nyu.edu;cw1681@nyu.edu;yanqiu.wu@nyu.edu;qd319@nyu.edu;keithwross@nyu.edu,3;1;3,,Reject,0,3,0,yes,9/25/19,New York University;New York University;New York University;New York University;New York University;New York University;New York University,Deep Reinforcement Learning;Batch Reinforcement Learning;Sample Efficiency,22;22;22;22;22;22;22,29;29;29;29;29;29;29,f;m,usa,usa,n
ICLR,2020,Entropy Penalty: Towards Generalization Beyond the IID Assumption,Devansh Arpit;Caiming Xiong;Richard Socher,devansharpit@gmail.com;cxiong@salesforce.com;rsocher@salesforce.com,1;3;3,,Reject,0,0,0,yes,9/25/19,SalesForce.com;SalesForce.com;SalesForce.com,domain shift;information bottleneck;entropy penalty;out of distribution generalization,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Causal View on Robustness  of Neural Networks,Cheng Zhang;Yingzhen Li,cheng.zhang@microsoft.com;yingzhen.li@microsoft.com,3;8;8,,Reject,0,2,1,yes,9/25/19,Microsoft;Microsoft,Neural Network Robustness;Variational autoencoder (VAE);Causality;Deep generative model,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing,Philip May,eniak.info@gmail.com,1;1;1,,Reject,0,0,0,yes,9/25/19,T-Systems on site services GmbH,image augmentation;cnn;images;augmentation,-1,-1,m,NAN,NAN,n
ICLR,2020,Model-free Learning Control of Nonlinear Stochastic Systems with Stability Guarantee,Minghao Han;Yuan Tian;Lixian Zhang;Jun Wang;Wei Pan,mhhan@hit.edu.cn;yuantian013@163.com;lixianzhang@hit.edu.cn;jun.wang@cs.ucl.ac.uk;wei.pan@tudelft.nl,1;6;3,,Reject,0,7,0,yes,9/25/19,Harbin Institute of Technology;163;Harbin Institute of Technology;University College London;Delft University of Technology,Reinforcement learning;nonlinear stochastic system;Lyapunov,168;-1;168;52;-1,424;-1;424;-1;67,m;m,NAN,NAN,y
ICLR,2020,A Theoretical Analysis of  Deep Q-Learning,Zhuoran Yang;Yuchen Xie;Zhaoran Wang,zy6@princeton.edu;yuchenxie2020@u.northwestern.edu;zhaoranwang@gmail.com,8;3;3,,Reject,0,6,0,yes,9/25/19,Princeton University;Northwestern University;Northwestern University,reinforcement learning;deep Q network;minimax-Q learning;zero-sum Markov Game,30;46;46,6;22;22,m;m,usa,usa,y
ICLR,2020,On the Pareto Efficiency of Quantized CNN,Ting-Wu Chin;Pierce I-Jen Chuang;Vikas Chandra;Diana Marculescu,tingwuc@cmu.edu;pichuang@fb.com;vchandra@fb.com;dianam@cmu.edu,3;6;3,,Reject,0,3,0,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Carnegie Mellon University,convolutional neural networks quantization;model compression;efficient neural network,1;-1;-1;1,27;-1;-1;27,f;m,usa,usa,y
ICLR,2020,Robust Reinforcement Learning via Adversarial Training with  Langevin Dynamics,Huang Yu-Ting;Parameswaran Kamalaruban;Paul Rolland;Ya-Ping Hsieh;Volkan Cevher,yu.huang@epfl.ch;kamalaruban.parameswaran@epfl.ch;paul.rolland@epfl.ch;ya-ping.hsieh@epfl.ch;volkan.cevher@epfl.ch,3;3;3;6,,Reject,0,6,0,yes,9/25/19,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne,deep reinforcement learning;robust reinforcement learning;min-max problem,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Robust Reinforcement Learning with Wasserstein Constraint,Linfang Hou;Liang Pang;Xin Hong;Yanyan Lan;Zhiming Ma;Dawei Yin,houlinfang09@gmail.com;pangliang@ict.ac.cn;hongxin19b@ict.ac.cn;lanyanyan@ict.ac.cn;mazm@amt.ac.cn;yindawei@acm.org,3;3;3,,Reject,0,3,0,yes,9/25/19,"JD AI Research;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Chinese Academy of Sciences;Baidu Inc.",,-1;30;30;30;30;-1,-1;-1;-1;-1;-1;-1,u;m,asia,in,y
ICLR,2020,Representation Learning for Remote Sensing: An Unsupervised Sensor Fusion Approach,Aidan M. Swope;Xander H. Rudelis;Kyle T. Story,aidanswope@gmail.com;xander@descarteslabs.com;kyle@descarteslabs.com,3;3;3,,Reject,0,3,0,yes,9/25/19,"California Institute of Technology;Descartes Labs, Inc;Descartes Labs, Inc",unsupervised learning;representation learning;deep learning;remote sensing;sensor fusion,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning to Combat Compounding-Error in Model-Based Reinforcement Learning,Chenjun Xiao;Yifan Wu;Chen Ma;Dale Schuurmans;Martin M√ºller,chenjun@ualberta.ca;yw4@andrew.cmu.edu;chenchloem@gmail.com;daes@ualberta.ca;mmueller@ualberta.ca,1;6;8,,Reject,0,3,0,yes,9/25/19,University of Alberta;Carnegie Mellon University;;University of Alberta;University of Alberta,reinforcement learning;model-based RL,102;1;-1;102;102,136;27;-1;136;136,u;m,canada,ca,y
ICLR,2020,Recurrent Neural Networks are Universal Filters,Wenjie Xu;Xiuqiong Chen;Stephen S.-T. Yau,1155118056@link.cuhk.edu.hk;cxq0828@tsinghua.edu.cn;yau@uic.edu,3;3;6,,Reject,0,4,0,yes,9/25/19,"The Chinese University of Hong Kong;Tsinghua University, Tsinghua University;University of Illinois, Chicago",Recurrent Neural Networks;Expressive Power;Deep Learning Theory,316;4;-1,35;23;-1,m;m,usa,usa,y
ICLR,2020,Soft Token Matching for Interpretable Low-Resource Classification,Federico Errica;Fabrizio Silvestri;Bora Edizel;Sebastian Riedel;Ludovic Denoyer;Vassilis Plachouras,federico.errica@phd.unipi.it;fabrizio.silvestri@gmail.com;b.edizel@gmail.com;sebastian.riedel@gmail.com;denoyer@fb.com;vplachouras@fb.com,3;3;1,,Reject,0,6,0,yes,9/25/19,University of Pisa;Sapienza University of Rome;Facebook;Facebook;Facebook;Facebook,low-resource classification;semantic matching;error boosting;text classification;natural language processing,248;102;-1;-1;-1;-1,366;258;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Mention-Pair Model of Annotation with Nonparametric User Communities,Silviu Paun;Juntao Yu;Jon Chamberlain;Udo Kruschwitz;Massimo Poesio,s.paun@qmul.ac.uk;juntao.yu@qmul.ac.uk;jchamb@essex.ac.uk;udo@essex.ac.uk;m.poesio@qmul.ac.uk,3;8;6;6,,Reject,0,5,0,yes,9/25/19,Queen Mary University London;Queen Mary University London;University of Essex;University of Essex;Queen Mary University London,model of annotation;coreference resolution;anaphoric annotation;mention pair model;bayesian nonparametrics,-1;-1;248;248;-1,-1;-1;272;272;-1,m;m,europe,uk,n
ICLR,2020,Towards Finding Longer Proofs,Zsolt Zombori;Adri√°n Csisz√°rik;Henryk Michalewski;Cezary Kaliszyk;Josef Urban,zombori@renyi.hu;csadrian@renyi.hu;henrykmichalewski@gmail.com;cezary.kaliszyk@uibk.ac.at;josef.urban@gmail.com,6;3;3,,Reject,0,4,0,yes,9/28/20,Alfr√©d R√©nyi Institute of Mathematics;Alfr√©d R√©nyi Institute of Mathematics;;University of Innsbruck;Czech Technical University in Prague,automated theorem proving;reinforcement learning;curriculum learning;internal guidance,-1;-1;-1;-1;168,-1;-1;-1;415;956,m;m,NAN,NAN,n
ICLR,2020,iWGAN: an Autoencoder WGAN for Inference,Yao Chen;Qingyi Gao;Xiao Wang,chen2037@purdue.edu;gao424@purdue.edu;wangxiao@purdue.edu,8;3;3,,Reject,0,3,0,yes,9/25/19,Purdue University;Purdue University;Purdue University,Generative model;Autoencoder;Inference,24;24;24,88;88;88,m;m,usa,usa,y
ICLR,2020,Teacher-Student Compression with Generative Adversarial Networks,Ruishan Liu;Nicolo Fusi;Lester Mackey,ruishan@stanford.edu;lmackey@stanford.edu;fusi@microsoft.com,3;3;3,,Reject,0,0,0,yes,9/25/19,Stanford University;Stanford University;Microsoft,,5;5;-1,4;4;-1,u;m,NAN,NAN,n
ICLR,2020,Characterize and Transfer Attention in Graph Neural Networks,Mufei Li;Hao Zhang;Xingjian Shi;Minjie Wang;Yixing Guan;Zheng Zhang,limufe@amazon.com;sufeidechabei@gmail.com;xshiab@connect.ust.hk;wmjlyjemaine@gmail.com;guayixin@amazon.com;zz@nyu.edu,3;6;1,,Reject,0,7,0,yes,9/25/19,Amazon;;The Hong Kong University of Science and Technology;;Amazon;New York University,Graph Neural Networks;Graph Attention Networks;Attention;Transfer Learning;Empirical Study,-1;-1;-1;-1;-1;22,-1;-1;47;-1;-1;29,m;m,usa,usa,n
ICLR,2020,Benchmarking Model-Based Reinforcement Learning,Tingwu Wang;Xuchan Bao;Ignasi Clavera;Jerrick Hoang;Yeming Wen;Eric Langlois;Shunshi Zhang;Guodong Zhang;Pieter Abbeel;Jimmy Ba,tingwuwang@cs.toronto.edu;xuchan.bao@mail.utoronto.ca;iclavera@berkeley.edu;jhoang@cs.toronto.edu;ywen@cs.toronto.edu;edl@cs.toronto.edu;matthew.zhang@mail.utoronto.ca;gdzhang@cs.toronto.edu;pabbeel@cs.berkeley.edu;jba@cs.toronto.edu,1;6;6,,Reject,0,5,0,yes,9/25/19,University of Toronto;Toronto University;University of California Berkeley;University of Toronto;University of Toronto;University of Toronto;Toronto University;University of Toronto;University of California Berkeley;University of Toronto,Reinforcement learning;model based Reinforcement learning;Benchmarking,18;-1;-1;18;18;18;-1;18;-1;18,18;-1;13;18;18;18;-1;18;13;18,m;m,canada,ca,n
ICLR,2020,Gradient Perturbation is Underrated for Differentially Private Convex Optimization,Da Yu;Huishuai Zhang;Wei Chen;Tie-yan Liu;Jian Yin,yuda3@mail2.sysu.edu.cn;huishuai.zhang@microsoft.com;wche@microsoft.com;tie-yan.liu@microsoft.com;issjyin@mail.sysu.edu.cn,6;3;6,,Reject,0,4,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft;Microsoft;SUN YAT-SEN UNIVERSITY,minimum curvature;gradient perturbation;DP-GD;DP-SGD,-1;-1;-1;-1;-1,299;-1;-1;-1;299,m;m,NAN,NAN,y
ICLR,2020,BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation,Jin-Young  Kim;Sung-Bae Cho,seago0828@yonsei.ac.kr;sbcho@yonsei.ac.kr,1;1;1,,Reject,1,20,0,yes,9/25/19,Yonsei University;Yonsei University,variational autoencoder;latent space;basis;disentangled representation,143;143,196;196,m;m,asia,cn,y
ICLR,2020,How many weights are enough : can tensor factorization learn efficient policies ?,Pierre H. Richemond;Arinbjorn Kolbeinsson;Yike Guo,phr17@ic.ac.uk;ak711@imperial.ac.uk;y.guo@imperial.ac.uk,3;1;3,,Reject,0,4,0,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London,reinforcement learning;Q-learning;tensor factorization;low-rank approximation;data efficiency;second-order optimization;scattering,52;52;52,10;10;10,m;m,europe,uk,n
ICLR,2020,Superseding Model Scaling by Penalizing Dead Units and Points with Separation Constraints,Carles Riera;Camilo Rey-Torres;Eloi Puertas;Oriol Pujol,blauigris@gmail.com;camilorey@gmail.com;epuertas@ub.edu;oriol_pujol@ub.edu,3;3;3,,Reject,0,13,1,yes,9/25/19,Universitat de Barcelona;Universidad Sergio Arboleda;Universitat de Barcelona;Universitat de Barcelona,Dead Point;Dead Unit;Model Scaling;Separation Constraints;Dying ReLU;Constant Width;Deep Neural Networks;Backpropagation,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,AHash: A Load-Balanced One Permutation Hash,Chenxingyu Zhao;Jie Gui;Yixiao Guo;Jie Jiang;Tong Yang;Bin Cui;Gong Zhang,dkzcxy@pku.edu.cn;guisj2017@pku.edu.cn;1700016637@pku.edu.cn;jie.jiang@pku.edu.cn;yangtongemail@gmail.com;bin.cui@pku.edu.cn;nicholas.zhang@huawei.com,1;6;3;6,,Reject,0,0,0,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;;Peking University;Huawei Technologies Ltd.,Data Representation;Probabilistic Algorithms,14;14;14;14;-1;14;-1,24;24;24;24;-1;24;-1,m;m,NAN,NAN,y
ICLR,2020,Representation Quality Explain Adversarial Attacks,Danilo Vasconcellos Vargas;Shashank Kotyan;Moe Matsuki,vargas@inf.kyushu-u.ac.jp;shashankkotyan@gmail.com;matsuki.sousisu@gmail.com,1;3;1,,Reject,0,3,0,yes,9/25/19,Kyushu University;Kyushu University;Kyushu University,Representation Metrics;Adversarial Machine Learning;One-Pixel Attack;DeepFool;CapsNet,-1;-1;-1,460;460;-1,m;m,asia,in,n
ICLR,2020,Explaining A Black-box By Using A Deep Variational Information Bottleneck Approach,Seojin Bang;Pengtao Xie;Heewook Lee;Wei Wu;Eric Xing,seojinb@cs.cmu.edu,6;6;3,,Reject,0,12,0,yes,9/25/19,Carnegie Mellon University,interpretable machine learning;information bottleneck principle;black-box,1,27,f;m,usa,usa,n
ICLR,2020,Neural networks are a priori biased towards Boolean functions with low entropy,Chris Mingard;Joar Skalse;Guillermo Valle-P√©rez;David Mart√≠nez-Rubio;Vladimir Mikulik;Ard A. Louis,christopher.mingard@hertford.ox.ac.uk;joar.skalse@hertford.ox.ac.uk;guillermo.valle@dtc.ox.ac.uk;david.martinez@cs.ox.ac.uk;vladimir.mikulik@hertford.ox.ac.uk;ard.louis@physics.ox.ac.uk,3;6;6,,Reject,0,4,0,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford,class imbalance;perceptron;inductive bias;simplicity bias;initialization,46;46;46;46;46;46,1;1;1;1;1;1,m;m,europe,uk,y
ICLR,2020,Learning Structured Communication for Multi-agent Reinforcement Learning,Junjie Sheng;Xiangfeng Wang;Bo Jin;Junchi Yan;Wenhao Li;Tsung-Hui Chang;Jun Wang;Hongyuan Zha,52194501003@stu.ecnu.edu.cn;xfwang@sei.ecnu.edu.cn;bjin@cs.ecnu.edu.cn;yanjunchi@sjtu.edu.cn;52194501026@stu.ecnu.edu.cn;changtsunghui@cuhk.edu.cn;jwang@sei.ecnu.edu.cn;zha@sei.ecnu.edu.cn,6;3;3,,Reject,0,4,0,yes,9/25/19,"East China Normal University;East China Normal University;East China Normal University;Shanghai Jiao Tong University;East China Normal University;The Chinese University of Hong Kong, Shenzhen;East China Normal University;East China Normal University",Learning to communicate;Multi-agent reinforcement learning;Hierarchical communication network,-1;-1;-1;30;-1;46;-1;-1,544;544;544;157;544;35;544;544,m;m,NAN,NAN,n
ICLR,2020,Lipschitz Lifelong Reinforcement Learning,Erwan Lecarpentier;David Abel;Kavosh Asadi;Yuu Jinnai;Emmanuel Rachelson;Michael L. Littman,erwan.lecarpentier@isae-supaero.fr;david_abel@brown.edu;k8@brown.edu;yuu_jinnai@brown.edu;emmanuel.rachelson@isae-supaero.fr;michael_littman@brown.edu,6;6;3,,Reject,0,5,0,yes,9/25/19,Institut Sup√©rieur de l'A√©ronautique et de l'Espace;Brown University;Brown University;Brown University;Institut Sup√©rieur de l'A√©ronautique et de l'Espace;Brown University,Reinforcement Learning;Lifelong Learning,-1;85;85;85;-1;85,-1;53;53;53;-1;53,m;m,usa,usa,y
ICLR,2020,Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas,Fei Wang;Zhanfu Yang;Ziliang Chen;Guannan Wei;Tiark Rompf,wang603@purdue.edu;yang1676@purdue.edu;c.ziliang@yahoo.com;wei220@purdue.edu;tiark@purdue.edu,6;8;3,,Reject,0,0,0,yes,9/25/19,Purdue University;Purdue University;;Purdue University;Purdue University,Graph Neural Networks;2-Quantified Boolean Formula;Symbolic Reasoning,24;24;-1;24;24,88;88;-1;88;88,m;m,usa,usa,n
ICLR,2020,Semi-Supervised Few-Shot Learning with a Controlled Degree of Task-Adaptive Conditioning,Sung Whan Yoon;Jun Seo;Jaekyun Moon,shyoon8@kaist.ac.kr;tjwns0630@kaist.ac.kr;jmoon@kaist.edu,3;6;1,,Reject,0,4,0,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;KAIST,few-shot learning;meta-learning;semi-supervised learning;task-adaptive clustering;task-adaptive projection space,-1;-1;15,110;110;110,m;m,asia,in,n
ICLR,2020,Deep Lifetime Clustering,S Chandra Mouli;Leonardo Teixeira;Jennifer Neville;Bruno Ribeiro,chandr@purdue.edu;lteixeir@purdue.edu;ribeiro@cs.purdue.edu;neville@cs.purdue.edu,6;6;3,,Reject,0,7,0,yes,9/25/19,Purdue University;Purdue University;Purdue University;Purdue University,Lifetime Clustering;Deep Learning;Survival Distributions;Kuiper two-sample test,24;24;24;24,88;88;88;88,m;m,usa,usa,n
ICLR,2020,PassNet: Learning pass probability surfaces from single-location labels. An architecture for visually-interpretable soccer analytics,Javier Fern√°ndez;Luke Bornn,javier.fernandezr@fcbarcelona.cat;lbornn@kings.com,3;8;6,,Reject,0,5,0,yes,9/25/19,Universitat Polit√®cnica de Catalunya;Kings,fully convolutional neural networks;convolutional neural networks;sports analytics;interpretable machine learning;deep learning,-1;-1,-1;843,m;m,NAN,NAN,n
ICLR,2020,Few-Shot One-Class Classification via Meta-Learning,Ahmed Frikha;Denis Krompa√ü;Hans-Georg Koepken;Volker Tresp,ahmed.frikha@siemens.com;denis.krompass@siemens.com;hans-georg.koepken@siemens.com;volker.tresp@siemens.com,1;3;3,,Reject,0,13,0,yes,9/25/19,Siemens Corporate Research;Siemens Corporate Research;Siemens Corporate Research;Siemens Corporate Research,meta-learning;few-shot learning;one-class classification;class-imbalance learning,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Simple is Better: Training an End-to-end Contract Bridge Bidding Agent without Human Knowledge,Qucheng Gong;Yu Jiang;Yuandong Tian,qucheng@fb.com;tinayujiang@fb.com;yuandong@fb.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Facebook;Facebook;Facebook,Contract Bridge;Bidding;Selfplay;AlphaZero,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Rethinking deep active learning: Using unlabeled data at model training,Oriane Sim√©oni;Mateusz Budnik;Yannis Avrithis;Guillaume Gravier,oriane.simeoni@inria.fr;mateusz.budnik@inria.fr;yannis@avrithis.net;guig@irisa.fr,3;3;3,,Reject,0,7,0,yes,9/25/19,INRIA;INRIA;INRIA;IRISA,active learning;deep learning;semi-supervised learning;unsupervised feature learning,-1;-1;-1;-1,-1;-1;-1;-1,f;m,europe,fr,n
ICLR,2020,Why Convolutional Networks Learn Oriented Bandpass Filters: A Hypothesis,Richard P. Wildes,wildes@cse.yorku.ca,3;3;1;3,,Reject,0,0,0,yes,9/25/19,York University,convolutional networks;computer vision;oriented bandpass filters;linear systems theory,194,416,m,asia,kr,n
ICLR,2020,Deep Expectation-Maximization in Hidden Markov Models via Simultaneous Perturbation Stochastic Approximation,Chong Li;Dan Shen;C.J. Richard Shi;Hongxia Yang,chongli@uw.edu;dshen@alibaba-inc.com;cjshi@uw.edu;yang.yhx@alibaba-inc.com,3;3,,Reject,0,2,0,yes,9/25/19,"University of Washington, Seattle;Alibaba Group;University of Washington, Seattle;Alibaba Group",recommender system;gradient approximation;Hidden Markov Model,11;-1;11;-1,26;-1;26;-1,m;f,NAN,NAN,y
ICLR,2020,Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling,Ouyu Lan*;Xiao Huang*;Bill Yuchen Lin;He Jiang;Xiang Ren,olan@usc.edu;huan183@usc.edu;yuchen.lin@usc.edu;jian567@usc.edu;xiangren@usc.edu,6;6;3,,Reject,0,6,0,yes,9/25/19,University of Southern California;University of Southern California;University of Southern California;University of Southern California;University of Southern California,crowdsourcing;domain adaptation;sequence labeling;named entity recognition;weak supervision,36;36;36;36;36,62;62;62;62;62,f;m,usa,usa,n
ICLR,2020,Disentangled Cumulants Help Successor Representations Transfer to New Tasks,Chris Grimm;Irina Higgins;Andre Barreto;Denis Teplyashin;Markus Wulfmeier;Tim Hertweck;Raia Hadsell;Satinder Singh,crgrimm@umich.edu;irinah@google.com;andrebarreto@google.com;teplyashin@google.com;mwulfmeier@google.com;thertweck@google.com;raia@google.com;baveja@google.com,6;6;3,,Reject,0,0,0,yes,9/25/19,University of Michigan;Google;Google;Google;Google;Google;Google;Google,reinforcement learning;representation learning;intrinsic reward;intrinsic control;endogenous;generalized policy improvement;successor features;variational;monet;disentangled,7;-1;-1;-1;-1;-1;-1;-1,21;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Adversarial training with perturbation generator networks,Hyeungill Lee;Sungyeob Han;Jungwoo Lee,hyungil0113@snu.ac.kr;yubise7en@snu.ac.kr;junglee@snu.ac.kr,3;3;3,,Reject,0,9,0,yes,9/25/19,Seoul National University;Seoul National University;Seoul National University,Adversarial training;Generative model;Adaptive perturbation generator;Robust optimization,39;39;39,64;64;64,u;m,asia,kr,n
ICLR,2020,Batch Normalization has Multiple Benefits: An Empirical Study on Residual Networks,Soham De;Samuel L Smith,sohamde@google.com;slsmith@google.com,3;1;3,,Reject,1,4,0,yes,9/25/19,Google;Google,batch normalization;residual networks;initialization;batch size;learning rate;ImageNet,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION,Jin Zhang;Weipeng Ming;Pengfei Liu,zhangjin9@100tal.com;mingweipeng@100tal.com;liupengfei1@100tal.com,1;3;6,,Reject,0,0,0,yes,9/25/19,TAL Education Group;TAL Education Group;TAL Education Group,mathematical expressions recognition;seq2seq model,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,The Sooner The Better: Investigating Structure of Early Winning Lottery Tickets,Shihui Yin;Kyu-Hyoun Kim;Jinwook Oh;Naigang Wang;Mauricio Serrano;Jae-Sun Seo;Jungwook Choi,shihui.yin@ibm.com;kimk@us.ibm.com;ohj@us.ibm.com;nwang@us.ibm.com;mserrano@us.ibm.com;jaesun.seo@asu.edu;choij@hanyang.ac.kr,6;3;3,,Reject,0,6,0,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;SUN YAT-SEN UNIVERSITY;Hanyang University,pruning;lottery ticket hypothesis;deep neural network;compression;image classification,-1;-1;-1;-1;-1;-1;194,-1;-1;-1;-1;-1;299;393,m;m,asia,kr,n
ICLR,2020,How Well Do WGANs Estimate the Wasserstein Metric?,Anton Mallasto;Guido Mont√∫far;Augusto Gerolin,anton.mallasto@gmail.com;montufar@math.ucla.edu;augustogerolin@gmail.com,1;3;3,,Reject,0,3,0,yes,9/25/19,"Aalto University;University of California, Los Angeles;VU University Amsterdam",Optimal Transport;Wasserstein Metric;Generative Adversial Networks,118;-1;-1,182;17;-1,m;m,asia,in,n
ICLR,2020,A Group-Theoretic Framework for Knowledge Graph Embedding,Tong Yang;Long Sha;Pengyu Hong,yangto@bc.edu;longsha@brandeis.edu;hongpeng@brandeis.edu,3;3;3,,Reject,4,4,0,yes,9/25/19,Boston College;Brandeis University;Brandeis University,group theory;knowledge graph embedding;representation learning,248;248;248,323;244;244,m;m,usa,usa,n
ICLR,2020,Accelerated Information Gradient flow,Yifei Wang;Wuchen Li,zackwang24@pku.edu.cn;wcli@math.ucla.edu,3;3,,Reject,0,3,0,yes,9/25/19,"Peking University;University of California, Los Angeles",Optimal transport;Information geometry;Nesterov accelerated gradient method,14;-1,24;17,m;m,usa,usa,y
ICLR,2020,Time2Vec: Learning a Vector Representation of Time,Seyed Mehran Kazemi;Rishab Goel;Sepehr Eghbali;Janahan Ramanan;Jaspreet Sahota;Sanjay Thakur;Stella Wu;Cathal Smyth;Pascal Poupart;Marcus Brubaker,mehran.kazemi@borealisai.com;rishab.goel@borealisai.com;sepehr.eghbali@rbc.com;janahan.ramanan@borealisai.com;jaspreet.sahota@borealisai.com;sttsanjay@gmail.com;stella.wu@borealisai.com;cathal.smyth@rbc.com;pascal.poupart@borealisai.com;marcus.brubaker@borealisai.com,6;1;3;8,,Reject,0,5,0,yes,9/25/19,Borealis AI;Borealis AI;Borealis AI;Borealis AI;Borealis AI;;Borealis AI;Borealis AI;Borealis AI;Borealis AI,,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction of Sepsis,Margherita Rosnati;Vincent Fortuin,mrosnati@ethz.ch;fortuin@inf.ethz.ch,3;1;8,,Reject,0,3,0,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,time series analysis;interpretability;Gaussian Processes;attention neural networks,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,NESTED LEARNING FOR MULTI-GRANULAR TASKS,Rapha√´l Achddou;J. Matias Di Martino;Guillermo Sapiro,raphael.achddou@telecom-paristech.fr;matiasdm@fing.edu.uy;guillermo.sapiro@duke.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,T√©l√©com ParisTech;Facultad de Ingenier√≠a;Duke University,Nested learning,-1;-1;46,187;-1;20,m;m,europe,se,n
ICLR,2020,Attack-Resistant Federated Learning with Residual-based Reweighting,Shuhao Fu;Chulin Xie;Bo Li;Qifeng Chen,sfuab@connect.ust.hk;chulinxie@zju.edu.cn;lbo@illinois.edu;chenqifeng22@gmail.com,3;6;3,,Reject,0,1,0,yes,9/25/19,"The Hong Kong University of Science and Technology;Zhejiang University;University of Illinois, Urbana Champaign;Hong Kong University of Science and Technology",robust federated learning;backdoor attacks,-1;39;-1;-1,47;107;-1;47,m;m,NAN,NAN,y
ICLR,2020,Self-Supervised Policy Adaptation,Christopher Mutschler;Sebastian Pokutta,christopher.mutschler@iis.fraunhofer.de;pokutta@zib.de,1;1;1,,Reject,0,1,0,yes,9/25/19,Fraunhofer IIS;ZIB,reinforcement learning;environment representation;representation learning;model mismatch,-1;-1,-1;-1,m;m,europe,gr,n
ICLR,2020,Efficient generation of structured objects with Constrained Adversarial Networks,Jacopo Gobbi;Luca Di Liello;Pierfrancesco Ardino;Paolo Morettin;Stefano Teso;Andrea Passerini,jacopo.gobbi@studenti.unitn.it;luca.diliello@studenti.unitn.it;pierfrancesco.ardino@unitn.it;paolo.morettin@unitn.it;stefano.teso@gmail.com;andrea.passerini@unitn.it,3;3;3,,Reject,0,3,0,yes,9/25/19,University of Trento;University of Trento;University of Trento;University of Trento;University of Trento;University of Trento,deep generative models;generative adversarial networks;constraints,143;143;143;143;143;143,307;307;307;307;307;307,m;f,europe,gr,y
ICLR,2020,Subgraph Attention for Node Classification and Hierarchical Graph Pooling,Sambaran Bandyopadhyay;Manasvi Aggarwal;M. N. Murty,sambaran.ban89@gmail.com;manasvia@iisc.ac.in;mnm@iisc.ac.in,3;6;1,,Reject,0,5,0,yes,9/25/19,International Business Machines;Indian Institute of Science;Indian Institute of Science,Graph Neural Network;Graph Attention;Graph Pooling;Node Classification;Graph Classification;Network Representation Learning,-1;-1;-1,-1;301;301,m;m,NAN,NAN,n
ICLR,2020,Learning from Partially-Observed Multimodal Data with Variational Autoencoders,Yu Gong;Hossein Hajimirsadeghi;Jiawei He;Megha Nawhal;Thibaut Durand;Greg Mori,yu_gong@sfu.ca;hossein.hajimirsadeghi@gmail.com;jha203@sfu.ca;mnawhal@sfu.ca;thibaut.p.durand@borealisai.com;mori@cs.sfu.ca,3;3;3;6,,Reject,0,7,0,yes,9/25/19,Simon Fraser University;Borealis AI;Simon Fraser University;Simon Fraser University;Borealis AI;Simon Fraser University,data imputation;variational autoencoders;generative models,52;-1;52;52;-1;52,272;-1;272;272;-1;272,m;m,canada,ca,n
ICLR,2020,A Simple Approach to the Noisy Label Problem Through the Gambler's Loss,Liu Ziyin;Ru Wang;Paul Pu Liang;Ruslan Salakhutdinov;Louis-Philippe Morency;Masahito Ueda,zliu@cat.phys.s.u-tokyo.ac.jp;wangru1994305@gmail.com;pliang@cs.cmu.edu;rsalakhu@cs.cmu.edu;morency@cs.cmu.edu;ueda@phys.s.u-tokyo.ac.jp,6;3;3,,Reject,0,7,0,yes,9/25/19,The University of Tokyo;;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;The University of Tokyo,noisy labels;robust learning;early stopping;generalization,64;-1;1;1;1;64,36;-1;27;27;27;36,u;m,NAN,NAN,y
ICLR,2020,Contextual Temperature for Language Modeling,Pei-Hsin Wang;Sheng-Iou Hsieh;Shieh-Chieh Chang;Jia-Yu Pan;Yu-Ting Chen;Wei Wei;Da-Cheng Juan,peihsin@gapp.nthu.edu.tw;steins1111@gapp.nthu.edu.tw;scchang@cs.nthu.edu.tw;jypan@google.com;yutingchen@google.com;wewei@google.com;dacheng@google.com,3;6;3,,Reject,0,5,0,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Google;Google;Google;Google,natural language processing;language modeling;sequence modeling;temperature scaling,194;194;194;-1;-1;-1;-1,365;365;365;-1;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS,Tao Zheng;Ivor Tsang;Xin Yao,tao.zheng@student.uts.edu.au;ivor.tsang@uts.edu.au;xiny@sustech.edu.cn,1;3;1,,Reject,0,0,0,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;Southern University of Science and Technology,metric learning;representation learning;multi-label classification;multi-output,73;73;-1,193;193;317,m;u,NAN,NAN,n
ICLR,2020,Unsupervised Data Augmentation for Consistency Training,Qizhe Xie;Zihang Dai;Eduard Hovy;Minh-Thang Luong;Quoc V. Le,qizhex@cs.cmu.edu;dzihang@cs.cmu.edu;hovy@cs.cmu.edu;thangluong@google.com;qvl@google.com,8;3;3,,Reject,0,11,1,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Google;Google,Semi-supervised learning;computer vision;natural language processing,1;1;1;-1;-1,27;27;27;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Representation Learning Through Latent Canonicalizations,Or Litany;Ari Morcos;Srinath Sridhar;Leonidas Guibas;Judy Hoffman,orlitany@gmail.com;arimorcos@gmail.com;ssrinath@cs.stanford.edu;guibas@cs.stanford.edu;judy@gatech.edu,3;8;3,,Reject,0,5,0,yes,9/25/19,NVIDIA;Facebook;Stanford University;Stanford University;Georgia Institute of Technology,representation learning;latent canonicalization;sim2real;few shot;disentanglement,-1;-1;5;5;13,-1;-1;4;4;38,m;f,usa,usa,n
ICLR,2020,Molecular Graph Enhanced Transformer for Retrosynthesis Prediction,Kelong Mao;Peilin Zhao;Tingyang Xu;Yu Rong;Xi Xiao;Junzhou Huang,mkl18@mails.tsinghua.edu.cn;masonzhao@tencent.com;tingyangxu@tencent.com;yu.rong@hotmail.com;xiaox@sz.tsinghua.edu.cn;joehhuang@tencent.com,3;3;1,,Reject,0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tsinghua University, Tsinghua University;Tencent AI Lab",,4;-1;-1;-1;4;-1,23;-1;-1;-1;23;-1,m;m,NAN,NAN,n
ICLR,2020,Frequency Pooling: Shift-Equivalent and Anti-Aliasing Down Sampling,Zhendong Zhang;Cheolkon Jung,zhd.zhang.ai@gmail.com;zhengzk@xidian.edu.cn,1;6;3,,Reject,0,7,0,yes,9/25/19,Xidian University;Xidian University,pooling;anti-aliasing;shift-equivalent;frequency,-1;-1,-1;919,m;m,asia,cn,n
ICLR,2020,Where is the Information in a Deep Network?,Alessandro Achille;Stefano Soatto,achille@cs.ucla.edu;soatto@cs.ucla.edu,6;8;6,,Reject,0,8,1,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",Information;Learning Dynamics;PAC-Bayes;Deep Learning,-1;-1,17;17,m;m,usa,usa,y
ICLR,2020,FleXOR: Trainable Fractional Quantization,Dongsoo Lee;Se Jung Kwon;Byeongwook Kim;Yongkweon Jeon;Baeseong Park;Jeongin Yun;Gu-Yeon Wei,dslee3@gmail.com;mogndrewk@gmail.com;quddnr145@gmail.com;dragwon.jeon@gmail.com;qkrqotjd91@gmail.com;yji6373@naver.com;gywei@g.harvard.edu,3;6;3,,Reject,0,4,0,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Samsung;Samsung;Harvard University,Quantization;Model Compression;Trainable Compression;XOR;Encryption,-1;-1;-1;-1;-1;-1;52,-1;-1;-1;-1;-1;-1;7,m;m,usa,usa,n
ICLR,2020,Mixture Distributions for Scalable Bayesian Inference,Pranav Poduval;Hrushikesh Loya;Rajat Patel;Sumit Jain,pranav97.poduval@gmail.com;loyahrushikesh@gmail.com;prajat5232@iitb.ac.in;sumitjain3033@gmail.com,1;3;3,,Reject,0,13,0,yes,9/25/19,Indian Institute of Technology Bombay;;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay,uncertainty estimation;Deep Ensembles;Adverserial Robustness,-1;-1;-1;-1,-1;-1;480;-1,m;m,asia,in,n
ICLR,2020,On the Invertibility of Invertible Neural Networks,Jens Behrmann;Paul Vicol;Kuan-Chieh Wang;Roger B. Grosse;J√∂rn-Henrik Jacobsen,jensb@uni-bremen.de;pvicol@cs.toronto.edu;wangkua1@cs.toronto.edu;rgrosse@cs.toronto.edu;j.jacobsen@vectorinstitute.ai,6;3;3,,Reject,0,6,0,yes,9/25/19,Universit√§t Bremen;University of Toronto;University of Toronto;University of Toronto;Vector Institute,Invertible Neural Networks;Stability;Normalizing Flows;Generative Models;Evaluation of Generative Models,-1;18;18;18;-1,-1;18;18;18;-1,m;m,NAN,NAN,y
ICLR,2020,Meta Learning via Learned Loss,Sarah Bechtle;Artem Molchanov;Yevgen Chebotar;Edward Grefenstette;Ludovic Righetti;Gaurav Sukhatme;Franziska Meier,sbechtle@tuebingen.mpg.de;molchano@usc.edu;ychebota@usc.edu;egrefen@gmail.com;ludovic.righetti@nyu.edu;gaurav@usc.edu;fmeier@fb.com,3;3;6,,Reject,0,5,0,yes,9/25/19,Max-Planck Institute;University of Southern California;University of Southern California;Facebook;New York University;University of Southern California;Facebook,Meta Learning;Reinforcement Learning;Loss Learning,-1;36;36;-1;22;36;-1,-1;62;62;-1;29;62;-1,f;f,NAN,NAN,n
ICLR,2020,Demonstration Actor Critic,Guoqing Liu;Li Zhao;Pushi Zhang;Jiang Bian;Tao Qin;Nenghai Yu;Tie-Yan Liu,lgq1001@mail.ustc.edu.cn;lizo@microsoft.com;zpschang@gmail.com;jiang.bian@microsoft.com;taoqin@microsoft.com;ynh@ustc.edu.cn;tyliu@microsoft.com,6;6;1,,Reject,0,9,0,yes,9/25/19,University of Science and Technology of China;Microsoft;;Microsoft;Microsoft;University of Science and Technology of China;Microsoft,Deep Reinforcement Learning;Reinforcement Learning from Demonstration,-1;-1;-1;-1;-1;-1;-1,80;-1;-1;-1;-1;80;-1,m;m,NAN,NAN,y
ICLR,2020,Moniqua: Modulo Quantized Communication in Decentralized SGD,Yucheng Lu;Christopher De Sa,yl2967@cornell.edu;cdesa@cs.cornell.edu,3;3;3;8,,Reject,0,10,0,yes,9/25/19,Cornell University;Cornell University,decentralized training;quantization;communicaiton;stochastic gradient descent,7;7,19;19,m;m,usa,usa,y
ICLR,2020,Testing For Typicality with Respect to an Ensemble of Learned Distributions,Forrest Laine;Claire Tomlin,forrest.laine@berkeley.edu;tomlin@eecs.berkeley.edu,3;1;6,,Reject,0,5,0,yes,9/25/19,University of California Berkeley;University of California Berkeley,anomaly detection;density estimation;generative models,-1;-1,13;13,m;f,usa,usa,y
ICLR,2020,Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML,Sijia Liu;Songtao Lu;Xiangyi Chen;Yao Feng;Kaidi Xu;Abdullah Al-Dujaili;Minyi Hong;Una-May Obelilly,sijia.liu@ibm.com;songtao@ibm.com;chen5719@umn.edu;feng-y16@mails.tsinghua.edu.cn;xu.kaid@husky.neu.edu;aldujail@mit.edu;mhong@umn.edu;unamay@csail.mit.edu,3;6;6,,Reject,0,7,0,yes,9/25/19,"International Business Machines;International Business Machines;University of Minnesota, Minneapolis;Tsinghua University, Tsinghua University;Northeastern University;Massachusetts Institute of Technology;University of Minnesota, Minneapolis;Massachusetts Institute of Technology",nonconvex optimization;min-max optimization;robust optimization;adversarial attack,-1;-1;73;4;16;5;73;5,-1;-1;79;23;906;5;79;5,m;f,usa,usa,y
ICLR,2020,Wyner VAE: A Variational Autoencoder with Succinct Common Representation Learning,J. Jon Ryu;Yoojin Choi;Young-Han Kim;Mostafa El-Khamy;Jungwon Lee,jongha.ryu@gmail.com;yoojin.c@samsung.com;yhk@ucsd.edu;mostafa.e@samsung.com;jungwon2.lee@samsung.com,6;6;3;6,,Reject,0,15,0,yes,9/25/19,"University of California, San Diego;Samsung;University of California, San Diego;Samsung;Samsung",Wyner's common information;information theoretic regularization;information bottleneck;representation learning;generative models;conditional generation;joint generation;style transfer;variational autoencoders,-1;-1;-1;-1;-1,31;-1;31;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Improving Confident-Classifiers For Out-of-distribution Detection,Sachin Vernekar;Ashish Gaurav;Vahdat Abdelzad;Taylor Denouden;Rick Salay;Krzysztof Czarnecki,sverneka@uwaterloo.ca;a5gaurav@uwaterloo.ca;vabdelza@gsd.uwaterloo.ca;tadenoud@uwaterloo.ca;rsalay@gsd.uwaterloo.ca;kczarnec@gsd.uwaterloo.ca,3;3;6,,Reject,0,3,0,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo,Out-of-distribution detection;Manifold;Nullspace;Variational Auto-encoder;GAN;Confident-classifier,30;30;30;30;30;30,235;235;235;235;235;235,m;m,canada,ca,n
ICLR,2020,FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS,Dogu Araci;Zulkuf Genc,dogu.araci@naspers.com;zulkuf.genc@naspers.com,3;3;1;3,,Reject,0,0,0,yes,9/25/19,Naspers;Prosus,Financial sentiment analysis;financial text classification;transfer learning;pre-trained language models;BERT;NLP,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Rethinking Neural Network Quantization,Qing Jin;Linjie Yang;Zhenyu Liao,jinqingking@gmail.com;yljatthu@gmail.com;liaozhenyu2004@gmail.com,3;3;1,,Reject,0,7,0,yes,9/25/19,Northeastern University;ByteDance;Kuaishou Technology,Deep Learning;Convolutional Network;Network Quantization;Efficient Learning,16;-1;-1,906;-1;-1,u;m,NAN,NAN,n
ICLR,2020,A Simple and Scalable Shape Representation for 3D Reconstruction,Mateusz Michalkiewicz;Eugene Belilovsky;Mahsa Baktashmotagh;Anders Eriksson,78lhar@gmail.com;belilovsky.eugene@gmail.com;m.baktashmotlagh@uq.edu.au;a.eriksson@uq.edu.au,6;3;3,,Reject,0,4,0,yes,9/25/19,University of Queensland;University of Montreal;University of Queensland;University of Queensland,Computer Vision;3D Reconstruction,-1;118;248;248,-1;85;66;66,m;m,australasia,au,n
ICLR,2020,Learning Cross-Context Entity Representations from Text,Jeffrey Ling;Nicholas FitzGerald;Zifei Shan;Livio Baldini Soares;Thibault F√©vry;David Weiss;Tom Kwiatkowski,jeffreyling@google.com;nfitz@google.com;zifeis@google.com;liviobs@google.com;tfevry@google.com;djweiss@google.com;tomkwiat@google.com,3;3;6,,Reject,0,4,0,yes,9/25/19,Google;Google;Google;Google;Google;Google;Google,entities;entity representations;knowledge representation;entity linking;entity typing,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unsupervised Few Shot Learning via Self-supervised Training,Zilong Ji;Xiaolong Zou;Tiejun Huang;Si Wu,jizilong@mail.bnu.edu.cn;xiaolz@pku.edu.cn;tjhuang@pku.edu.cn;siwu@pku.edu.cn,1;6;3,,Reject,0,4,0,yes,9/25/19,Australian National University;Peking University;Peking University;Peking University,few shot learning;self-supervised learning;meta-learning,102;14;14;14,50;24;24;24,m;f,asia,cn,n
ICLR,2020,Confidence-Calibrated Adversarial Training: Towards Robust Models Generalizing Beyond the Attack Used During Training,David Stutz;Matthias Hein;Bernt Schiele,david.stutz@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de;matthias.hein@uni-tuebingen.de,3;3;6,,Reject,0,9,0,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;University of Tuebingen,Adversarial Training;Adversarial Examples;Adversarial Robustness;Confidence Calibration,-1;-1;143,-1;-1;91,m;m,europe,de,y
ICLR,2020,Optimal Unsupervised Domain Translation,Emmanuel de B√©zenac;Ibrahim Ayed;Patrick Gallinari,emmanuel.de-bezenac@lip6.fr;ayedibrahim@gmail.com;patrick.gallinari@lip6.fr,3;6;6,,Reject,0,4,0,yes,9/25/19,LIP6;LIP6;LIP6,Unsupervised Domain Translation;CycleGAN;Optimal Transport,445;445;445,-1;-1;-1,m;m,asia,ir,y
ICLR,2020,A Uniform Generalization Error Bound for Generative Adversarial Networks,Hao Chen;Zhanfeng Mo;Qingyi Gao;Zhouwang Yang;Xiao Wang,ch330822@mail.ustc.edu.cn;oscarmzf@mail.ustc.edu.cn;gao424@purdue.edu;yangzw@ustc.edu.cn;wangxiao@purdue.edu,1;3;3,,Reject,0,5,0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;Purdue University;University of Science and Technology of China;Purdue University,GANs;Uniform Generalization Bound;Deep Learning;Weight normalization,-1;-1;24;-1;24,80;80;88;80;88,m;m,usa,usa,y
ICLR,2020,Efficient Wrapper Feature Selection using Autoencoder and Model Based Elimination,Sharan Ramjee;Aly El Gamal,sramjee@purdue.edu;elgamala@purdue.edu,1;3;3,,Reject,1,5,0,yes,9/25/19,Purdue University;Purdue University,Wrapper Feature Selection;AMBER;Ranker Model;Generative Training;Wireless Subsampling,24;24,88;88,m;m,usa,usa,n
ICLR,2020,Training Data Distribution Search with Ensemble Active Learning,Kashyap Chitta;Jose M. Alvarez;Elmar Haussmann;Clement Farabet,kashyap.chitta@tue.mpg.de;josea@nvidia.com;ehaussmann@nvidia.com;cfarabet@nvidia.com,6;6;1,,Reject,0,3,0,yes,9/25/19,Max-Planck Institute;NVIDIA;NVIDIA;NVIDIA,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Coresets for Accelerating Incremental Gradient Methods,Baharan Mirzasoleiman;Jeff Bilmes;Jure Leskovec,baharanm@cs.stanford.edu;bilmes@uw.edu;jure@cs.stanford.edu,8;3;3,,Reject,0,3,0,yes,9/25/19,"Stanford University;University of Washington, Seattle;Stanford University",,5;11;5,4;26;4,f;m,usa,usa,y
ICLR,2020,Gaussian MRF Covariance Modeling for Efficient Black-Box Adversarial Attacks,Anit Kumar Sahu;J. Zico Kolter;Satya Narayan Shukla,anit.sahu@gmail.com;zkolter@cs.cmu.edu;snshukla@cs.umass.edu,8;3;3,,Reject,0,5,0,yes,9/25/19,"Amazon;Carnegie Mellon University;University of Massachusetts, Amherst",Black-Box Adversarial Attacks;Gaussian Markov Random Fields,-1;1;24,-1;27;209,m;m,usa,usa,n
ICLR,2020,How can we generalise learning distributed representations of graphs?,Paul M Scherer;Pietro Lio,pms69@cam.ac.uk;pl219@cam.ac.uk,3;6;1,,Reject,0,8,0,yes,9/25/19,University of Cambridge;University of Cambridge,graphs;distributed representations;similarity learning,79;79,3;3,m;m,europe,uk,n
ICLR,2020,Graph Residual Flow for Molecular Graph Generation,Shion Honda;Hirotaka Akita;Katsuhiko Ishiguro;Toshiki Nakanishi;Kenta Oono,26x.orc.ed5.1hs@gmail.com;akita714@preferred.jp;k.ishiguro.jp@ieee.org;nakanishi@preferred.jp;oono@preferred.jp,3;3;3,,Reject,0,3,0,yes,9/25/19,"The University of Tokyo;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.;Preferred Networks, Inc.",deep generative model;normalizing flow;graph generation;cheminformatics,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Regularizing Deep Multi-Task Networks using Orthogonal Gradients,Mihai Suteu;Yi-ke Guo,m.suteu16@imperial.ac.uk;y.guo@imperial.ac.uk,3;3;3,,Reject,0,3,0,yes,9/25/19,Imperial College London;Imperial College London,multi-task learning;gradient regularization;orthogonal gradients,52;52,10;10,m;m,europe,uk,n
ICLR,2020,Blending Diverse Physical Priors with Neural Networks,Yunhao Ba;Guangyuan Zhao;Achuta Kadambi,yhba@ucla.edu;zhaoguangyuan@ucla.edu;achuta@ee.ucla.edu,6;3;6,,Reject,0,6,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Physics-based learning;Physics-aware learning,-1;-1;-1,17;17;17,m;m,usa,usa,n
ICLR,2020,The Detection of Distributional Discrepancy for Text Generation,Xingyuan Chen;Ping Cai;Peng Jin;Haokun Du;Hongjun Wang;Xinyu Dai;Jiajun Chen,1045258214@qq.com;1061185275@qq.com;jandp@pku.edu.cn;626913553@qq.com;wanghongjun@swjtu.edu.cn;daixinyu@nju.edu.cn;chenjj@nju.edu.cn,1;3;1,,Reject,0,0,0,yes,9/25/19,Nanjing University;;Peking University;;Southwest Jiaotong University;Zhejiang University;Zhejiang University,,-1;-1;14;-1;-1;39;39,-1;-1;24;-1;1072;107;107,m;f,asia,cn,n
ICLR,2020,DG-GAN: the GAN with the duality gap,Cheng Peng;Hao Wang;Xiao Wang;Zhouwang Yang,pch0051@mail.ustc.edu.cn;wh001@mail.ustc.edu.cn;wangxiao@purdue.edu;yangzw@ustc.edu.cn,1;1;1,,Reject,0,3,0,yes,9/25/19,University of Science and Technology of China;University of Science and Technology of China;Purdue University;University of Science and Technology of China,GAN;duality gap;metric;saddle point;game,-1;-1;24;-1,80;80;88;80,m;m,NAN,NAN,n
ICLR,2020,Samples Are Useful? Not Always: denoising policy gradient updates using variance explained,Yannis Flet-Berliac;Philippe Preux,yannis.flet-berliac@inria.fr;philippe.preux@inria.fr,3;6;6,,Reject,0,4,0,yes,9/25/19,INRIA;INRIA,reinforcement learning;policy gradient;sampling,-1;-1,-1;-1,m;m,europe,gr,n
ICLR,2020,Continual Learning via Principal Components Projection,Gyuhak Kim;Bing Liu,gkim87@uic.edu;liub@uic.edu,3;3;3,,Reject,0,0,0,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago",Neural network;continual learning;catastrophic forgetting;lifelong learning,-1;-1,-1;-1,u;m,usa,usa,n
ICLR,2020,Iterative Deep Graph Learning for Graph Neural Networks,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,3;6;3,,Reject,0,5,0,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,deep learning;graph neural networks;graph learning,248;194;248,438;-1;438,f;m,usa,usa,n
ICLR,2020,Training Deep Neural Networks by optimizing over nonlocal paths in hyperparameter space,Vlad Pushkarov;Yonathan Efroni;Mykola Maksymenko;Maciej Koch-Janusz,vladpush@icloud.com;jonathan.efroni@gmail.com;mmaks@softserveinc.com;maciejk@ethz.ch,6;3;3,,Reject,0,3,0,yes,9/25/19,Icloud;;SoftServe Inc.;Swiss Federal Institute of Technology,deep learning;Hyperparameter optimization;dropout,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,An Optimization Principle Of Deep Learning?,Cheng Chen;Junjie Yang;Yi Zhou,u0952128@utah.edu;yang.4972@buckeyemail.osu.edu;yi.zhou@utah.edu,3;1;1,,Reject,0,4,0,yes,9/25/19,University of Utah;Ohio State University;University of Utah,,64;59;64,219;70;219,f;m,europe,uk,y
ICLR,2020,Amata: An Annealing Mechanism for Adversarial Training Acceleration,Nanyang Ye;Qianxiao Li;Zhanxing Zhu,yn272@cam.ac.uk;qianxiao@nus.edu.sg;zhanxing.zhu@pku.edu.cn,6;6;3,,Reject,0,4,0,yes,9/25/19,University of Cambridge;National University of Singapore;Peking University,,79;17;14,3;25;24,m;m,asia,cn,y
ICLR,2020,Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets,Thu Dinh*;Bao Wang*;Andrea L. Bertozzi;Stanley J. Osher;Jack Xin,thud2@uci.edu;wangbaonj@gmail.com;bertozzi@math.ucla.edu;sjo@math.ucla.edu;jxin@math.uci.edu,3;3;1,,Reject,0,4,0,yes,9/25/19,"University of California, Irvine;University of Utah;University of California, Los Angeles;University of California, Los Angeles;University of California, Irvine",Sparse Network;Model Compression;Adversarial Training,-1;64;-1;-1;-1,96;219;17;17;96,m;m,usa,usa,y
ICLR,2020,Perceptual Generative Autoencoders,Zijun Zhang;Ruixiang Zhang;Zongpeng Li;Yoshua Bengio;Liam Paull,zijun.zhang@ucalgary.ca;sodabeta7@gmail.com;zongpeng@whu.edu.cn;yoshua.bengio@mila.quebec;paulll@iro.umontreal.ca,3;3;3,,Reject,0,5,0,yes,9/25/19,"University of Calgary;Mila, UdeM;Wuhan University;Mila;University of Montreal",,248;-1;194;143;118,210;-1;354;336;85,m;m,canada,ca,y
ICLR,2020,Deep symbolic regression,Brenden K. Petersen,petersen33@llnl.gov,3;6;1,,Reject,0,4,0,yes,9/25/19,Lawrence Livermore National Labs,symbolic regression;reinforcement learning;automated machine learning,-1,-1,m,NAN,NAN,n
ICLR,2020,Task-Relevant Adversarial Imitation Learning,Konrad Zolna;Scott Reed;Alexander Novikov;Ziyu Wang;Sergio G√≥mez;David Budden;Serkan Cabi;Misha Denil;Nando de Freitas,konrad.zolna@gmail.com;reedscot@google.com;anovikov@google.com;ziyu@google.com;sergomez@google.com;budden@google.com;cabi@google.com;mdenil@google.com;nandodefreitas@google.com,8;6;3,,Reject,1,5,0,yes,9/25/19,Jagiellonian University;Google;Google;Google;Google;Google;Google;Google;Google,adversarial;imitation;robot;manipulation,-1;-1;-1;-1;-1;-1;-1;-1;-1,610;-1;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,"Imitation Learning of Robot Policies using Language, Vision and Motion",Simon Stepputtis;Joseph Campbell;Mariano Phielipp;Chitta Baral;Heni Ben Amor,sstepput@asu.edu;jacampb1@asu.edu;mariano.j.phielipp@intel.com;chitta@asu.edu;hbenamor@asu.edu,6;3;1,,Reject,0,6,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Intel;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,robot learning;imitation learning;natural language processing,-1;-1;-1;-1;-1,299;299;-1;299;299,m;m,NAN,NAN,n
ICLR,2020,Why Learning of Large-Scale Neural Networks Behaves Like Convex Optimization,Hui Jiang,hj@cse.yorku.ca,1;1;1;1,,Reject,0,0,0,yes,9/25/19,York University,function space;canonical space;neural networks;stochastic gradient descent;disparity matrix,194,416,m,asia,kr,y
ICLR,2020,Information Theoretic Model Predictive Q-Learning,Mohak Bhardwaj;Ankur Handa;Dieter Fox;Byron Boots,mohakb@cs.washington.edu;ahanda@nvidia.com;fox@cs.washington.edu;bboots@cs.washington.edu,3;6;3,,Reject,0,9,0,yes,9/25/19,University of Washington;NVIDIA;University of Washington;University of Washington,entropy regularized reinforcement learning;information theoretic MPC;robotics,11;-1;11;11,26;-1;26;26,m;m,usa,usa,n
ICLR,2020,Learning to Optimize via Dual space Preconditioning,S√©lim Chraibi;Adil Salim;Samuel Horv√°th;Filip Hanzely;Peter Richt√°rik,selimsepthuit@gmail.com;adil.salim@kaust.edu.sa;samuel.horvath@kaust.edu.sa;filip.hanzely@kaust.edu.sa;richtarik@gmail.com,3;3;1,,Reject,0,3,0,yes,9/25/19,CNRS;KAUST;KAUST;KAUST;KAUST,Optimization;meta-learning,-1;102;102;102;102,-1;-1;-1;-1;-1,m;m,europe,gr,y
ICLR,2020,HaarPooling: Graph Pooling with Compressive Haar Basis,Yu Guang Wang;Ming Li;Zheng Ma;Guido Montufar;Xiaosheng Zhuang;Yanan Fan,yuguang.wang@unsw.edu.au;ming.li.ltu@gmail.com;mzheng@princeton.edu;montufar@math.ucla.edu;xzhuang7@cityu.edu.hk;y.fan@unsw.edu.au,3;3;3;6,,Reject,0,9,0,yes,9/25/19,"University of New South Wales;Australian National University;Princeton University;University of California, Los Angeles;The Hong Kong Polytechnic University;University of New South Wales",graph pooling;graph neural networks;tree;graph classification;graph regression;deep learning;Haar wavelet basis;fast Haar transforms,-1;102;30;-1;118;-1,-1;50;6;17;171;-1,m;f,NAN,NAN,y
ICLR,2020,Neural-Guided Symbolic Regression with Asymptotic Constraints,Li Li;Minjie Fan;Rishabh Singh;Patrick Riley,leeley@google.com;mjfan@google.com;rising@google.com;pfr@google.com,3;3;8,,Reject,0,12,0,yes,9/25/19,Google;Google;Google;Google,symbolic regression;program synthesis;monte carlo tree search,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Handwritten Amharic Character Recognition System Using Convolutional Neural Networks,Fetulhak Abdurahman,afetulhak@yahoo.com,1;1;1,,Reject,1,1,0,yes,9/25/19,0,Amharic;Handwritten;Character;Convolutional neural network;Recognition,,,m,NAN,NAN,n
ICLR,2020,Deep Relational Factorization Machines,Hongchang Gao;Gang Wu;Ryan Rossi;Viswanathan Swaminathan;Heng Huang,hongchanggao@gmail.com;gawu@adobe.com;ryrossi@adobe.com;vishy@adobe.com;henghuanghh@gmail.com,1;1;3,,Reject,0,1,0,yes,9/25/19,University of Pittsburgh;Adobe Systems;Adobe Systems;Adobe Systems;University of Pittsburgh,,79;-1;-1;-1;79,113;-1;-1;-1;113,m;m,usa,usa,n
ICLR,2020,Dirichlet Wrapper to Quantify Classification Uncertainty in Black-Box Systems,Jos√© Mena Rold√°n;Oriol Pujol Vila;Jordi Vitri√† Marca,jmenarol7@alumnes.ub.edu;oriol_pujol@ub.edu;jordi.vitria@ub.edu,6;1;1;1,,Reject,0,0,0,yes,9/25/19,Universitat de Barcelona;Universitat de Barcelona;Universitat de Barcelona,uncertainty;black-box classifiers;rejection;deep learning;NLP;CV,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images,Tianshuo Cong;Dan Peng;Furui Liu;Zhitang Chen,cts17@mails.tsinghua.edu.cn;lepangdan@outlook.com;liufurui2@huawei.com;chenzhitang2@huawei.com,1;1;6,,Reject,0,3,0,yes,9/25/19,"Tsinghua University, Tsinghua University;;Huawei Technologies Ltd.;Huawei Technologies Ltd.",Causality discovery;AutoEncoder;Deep representation learning;Do-calculus,4;-1;-1;-1,23;-1;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Forecasting Deep Learning Dynamics with Applications to Hyperparameter Tuning,Piotr Kozakowski;≈Åukasz Kaiser;Afroz Mohiuddin,p.kozakowski@mimuw.edu.pl;lukaszkaiser@google.com;afrozm@google.com,3;6;1,,Reject,0,5,0,yes,9/25/19,"University of Washington, Seattle;Google;Google",,11;-1;-1,26;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Disentangling Trainability and Generalization in Deep Learning,Lechao Xiao;Jeffrey Pennington;Sam Schoenholz,xlc@google.com;jpennin@google.com;schsam@google.com,3;3;3,,Reject,0,4,0,yes,9/25/19,Google;Google;Google,NTK;NNGP;mean field theory;CNN;trainability and generalization;Gaussian process,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Versatile Anomaly Detection with Outlier Preserving Distribution Mapping Autoencoders,Walter Gerych;Elke Rundensteiner;Emmanuel Agu,wgerych@wpi.edu;rundenst@wpi.edu;emmanuel@wpi.edu,6;6;3,,Reject,0,3,0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute,Anomaly detection;outliers;deep learning;distribution mapping;wasserstein autoencoders,143;143;143,628;628;628,m;m,usa,usa,y
ICLR,2020,DeepPCM: Predicting Protein-Ligand Binding using Unsupervised Learned Representations,Paul Kim;Robin Winter;Djork-Arn√© Clevert,paul.kim@bayer.com;robin.winter@bayer.com;djork-arne.clevert@bayer.com,3;1;3,,Reject,2,0,0,yes,9/25/19,Bayer Ag;Bayer Ag;Bayer Ag,Unsupervised Representation Learning;Computational biology;computational chemistry;protein-ligand binding,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning transitional skills with intrinsic motivation,Qiangxing Tian;Jinxin Liu;Donglin Wang,11821087@zju.edu.cn;liujinxin@westlake.edu.cn;wangdonglin@westlake.edu.cn,3;3;6,,Reject,0,3,0,yes,9/25/19,Zhejiang University;University of Science and Technology of China;University of Science and Technology of China,,39;-1;-1,107;80;80,m;m,NAN,NAN,n
ICLR,2020,Preventing Imitation Learning with Adversarial Policy Ensembles,Albert Zhan;Pieter Abbeel;Stas Tiomkin,albertzhan@berkeley.edu;pabbeel@cs.berkeley.edu;stasti@gmail.com,3;1;3,,Reject,0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,Imitation Learning;Reinforcement Learning;Representation Learning,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,Noisy Machines: Understanding noisy neural networks and enhancing robustness to analog hardware errors using distillation,Chuteng Zhou;Prad Kadambi;Matthew Mattina;Paul N. Whatmough,chu.zhou@arm.com;pkadambi@asu.edu;matthew.mattina@arm.com;paul.whatmough@arm.com,3;6;6;3,,Reject,0,5,0,yes,9/25/19,arm;SUN YAT-SEN UNIVERSITY;arm;arm,network noise robustness;analog accelerator;noise injection;distillation;error rate,59;-1;59;59,289;299;289;289,m;m,asia,in,n
ICLR,2020,Mutual Information Maximization for Robust Plannable Representations,Yiming Ding;Ignasi Clavera;Pieter Abbeel,dingyiming0427@berkeley.edu;iclavera@berkeley.edu;pabbeel@cs.berkeley.edu,3;1;6,,Reject,0,3,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,reinforcement learning;robust learning;model based;planning;representation learning,-1;-1;-1,13;13;13,f;m,usa,usa,n
ICLR,2020,Removing input features via a generative model to explain their attributions to classifier's decisions,Chirag Agarwal;Dan Schonfeld;Anh Nguyen,chiragagarwall12@gmail.com;dans@uic.edu;anh.ng8@gmail.com,1;3;6,,Reject,0,8,0,yes,9/25/19,"Harvard University;University of Illinois, Chicago;Auburn University",attribution maps;generative models;inpainting;counterfactual;explanations;interpretability;explainability,52;-1;445,7;-1;651,m;m,usa,usa,n
ICLR,2020,Gauge Equivariant Spherical CNNs,Berkay Kicanaoglu;Pim de Haan;Taco Cohen,b.kicanaoglu@uva.nl;pimdehaan@gmail.com;taco.cohen@gmail.com,8;8;3,,Reject,0,4,0,yes,9/25/19,University of Amsterdam;University of Amsterdam;University of Amsterdam,deep learning;convolutional networks;equivariance;gauge equivariance;symmetry;geometric deep learning;manifold convolution,143;143;-1,62;62;-1,m;m,asia,in,n
ICLR,2020,Relation-based Generalized Zero-shot Classification with the Domain Discriminator on the shared representation,Masahiro Suzuki;Yutaka Matsuo,masa@weblab.t.u-tokyo.ac.jp;matsuo@weblab.t.u-tokyo.ac.jp,6;3;6,,Reject,0,6,0,yes,9/25/19,The University of Tokyo;The University of Tokyo,,64;64,36;36,m;m,NAN,NAN,n
ICLR,2020,Machine Truth Serum,Tianyi Luo;Yang Liu,tluo6@ucsc.edu;yangliu@ucsc.edu,6;1;3,,Reject,0,4,0,yes,9/25/19,University of Southern California;University of Southern California,Ensemble method;Classification;Machine Truth Serum;Minority;Machine Learning,36;36,62;62,m;m,usa,usa,y
ICLR,2020,A Gradient-Based Approach to Neural Networks Structure Learning,Amir Ali Moinfar;Amirkeivan Mohtashami;Mahdieh Soleymani;Ali Sharifi-Zarchi,moinfar@ce.sharif.edu;mohtashami@ce.sharif.edu;soleymani@sharif.edu;sharifi@sharif.edu,6;3;3,,Reject,0,3,0,yes,9/25/19,Sharif University of Technology;Sharif University of Technology;Sharif University of Technology;Sharif University of Technology,,316;316;316;316,564;564;564;564,m;m,asia,ir,y
ICLR,2020,Learning Generative Models using Denoising Density Estimators,Siavash Bigdeli;Geng Lin;Tiziano Portenier;Andrea Dunbar;Matthias Zwicker,siavash.bigdeli@csem.ch;geng@cs.umd.edu;tiziano.portenier@vision.ee.ethz.ch;andrea.dunbar@csem.ch;zwicker@cs.umd.edu,1;3;6,,Reject,0,7,0,yes,9/25/19,"Swiss Center for Electronics and Micro Electronics;University of Maryland, College Park;Swiss Federal Institute of Technology;Swiss Center for Electronics and Micro Electronics;University of Maryland, College Park",generative probabilistic models;denoising autoencoders;neural density estimation,-1;12;-1;-1;12,-1;91;-1;-1;91,m;m,usa,usa,y
ICLR,2020,NPTC-net: Narrow-Band Parallel Transport Convolutional Neural Network on Point Clouds,Pengfei Jin;Tianhao Lai;Rongjie Lai;Bin Dong,jinpf@pku.edu.cn;howeverlth@pku.edu.cn;lair@rpi.edu;dongbin@math.pku.edu.cn,3;3;3,,Reject,0,3,0,yes,9/25/19,Peking University;Peking University;Rensselaer Polytechnic Institute;Peking University,geometric convolution;point cloud;parallel transport,14;14;248;14,24;24;438;24,u;m,asia,cn,n
ICLR,2020,Attributed Graph Learning with 2-D Graph Convolution,Qimai Li;Xiaotong Zhang;Han Liu;Xiao-Ming Wu,csqmli@comp.polyu.edu.hk;zxt.dut@hotmail.com;liu.han.dut@gmail.com;xiao-ming.wu@polyu.edu.hk,3;6;6,,Reject,0,4,0,yes,9/25/19,The Hong Kong Polytechnic University;;;The Hong Kong Polytechnic University,2-D Graph Convolution;Attributed Graph;Representation learning,118;-1;-1;118,171;-1;-1;171,m;f,asia,hk,y
ICLR,2020,Pareto Optimality in No-Harm Fairness,Natalia Martinez;Martin Bertran;Guillermo Sapiro,natalia.martinez@duke.edu;martin.bertran@duke.edu;guillermo.sapiro@duke.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,Duke University;Duke University;Duke University,Fairness;Fairness in Machine Learning;No-Harm Fairness,46;46;46,20;20;20,f;m,europe,se,y
ICLR,2020,Conditional generation of molecules from disentangled representations,Amina Mollaysa;Brooks Paige;Alexandros  Kalousis,amina.mollaysa@gmail.com;tbpaige@gmail.com;alexandros.kalousis@hesge.ch,3;1;6,,Reject,0,5,0,yes,9/25/19,"University of Geneva, Switzerland;University College London;University of Applied Sciences Western Switzerland",molecule generation;disentangling,-1;52;-1,144;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Overparameterized Neural Networks Can Implement Associative Memory,Adityanarayanan Radhakrishnan;Mikhail Belkin;Caroline Uhler,aradha@mit.edu;mbelkin@cse.ohio-state.edu;cuhler@mit.edu,3;3;3,,Reject,0,9,0,yes,9/25/19,"Massachusetts Institute of Technology;University of California, San Diego;Massachusetts Institute of Technology",Associative Memory;Memorization and Recall;Attractors;Deep Autoencoders,5;-1;5,5;31;5,m;f,usa,usa,y
ICLR,2020,TinyBERT: Distilling BERT for Natural Language Understanding,Xiaoqi Jiao;Yichun Yin;Lifeng Shang;Xin Jiang;Xiao Chen;Linlin Li;Fang Wang;Qun Liu,jiaoxiaoqi@hust.edu.cn;yinyichun@huawei.com;shang.lifeng@huawei.com;jiang.xin@huawei.com;chen.xiao2@huawei.com;lynn.lilinlin@huawei.com;wangfang@hust.edu.cn;qun.liu@huawei.com,8;3;6,,Reject,1,9,1,yes,9/25/19,Hong Kong University of Science and Technology;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Hong Kong University of Science and Technology;Huawei Technologies Ltd.,BERT Compression;Transformer Distillation;TinyBERT,-1;-1;-1;-1;-1;-1;-1;-1,47;-1;-1;-1;-1;-1;47;-1,u;m,NAN,NAN,n
ICLR,2020,Cross Domain Imitation Learning,Kun Ho Kim;Yihong Gu;Jiaming Song;Shengjia Zhao;Stefano Ermon,khkim@cs.stanford.edu;gyh15@mails.tsinghua.edu.cn;jiaming.tsong@gmail.com;sjzhao@stanford.edu;ermon@cs.stanford.edu,3;6;8,,Reject,1,5,0,yes,9/25/19,"Stanford University;Tsinghua University, Tsinghua University;Stanford University;Stanford University;Stanford University",Imitation Learning;Domain Adaptation;Reinforcement Learning;Zeroshot Learning;Machine Learning;Artificial Intelligence,5;4;5;5;5,4;23;4;4;4,m;m,usa,usa,y
ICLR,2020,Multi-source Multi-view Transfer Learning in Neural Topic Modeling with Pretrained Topic and Word Embeddings,Pankaj Gupta;Yatin Chaudhary;Hinrich Sch√ºtze,pankaj_gupta96@yahoo.com;yatinchaudhary91@gmail.com;hinrich@hotmail.com,6;3;6,,Reject,0,6,0,yes,9/25/19,DRIMCo GmbH;;Centrum fuer Informations- und Sprachverarbeitung,Neural Topic Modeling;Transfer Learning;Unsupervised learning;Natural Language Processing,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Natural Image Manipulation for Autoregressive Models Using Fisher Scores,Wilson Yan;Jonathan Ho;Pieter Abbeel,wilson1.yan@berkeley.edu;jonathanho@berkeley.edu;pabbeel@cs.berkeley.edu,3;8;1,,Reject,0,4,0,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,fisher score;generative models;image interpolation,-1;-1;-1,13;13;13,m;m,usa,usa,n
ICLR,2020,SPECTRA: Sparse Entity-centric Transitions,Rim Assouel;Yoshua Bengio,rim.assouel@hotmail.fr;yoshua.bengio@mila.quebec,3;3;3,,Reject,0,1,0,yes,9/25/19,University of Montreal;Mila,representation learning;slot-structured representations;sparse slot-structured transitions;entity-centric representation;unsupervised learning;object-centric,-1;143,-1;336,f;m,NAN,NAN,n
ICLR,2020,Attentive Sequential Neural Processes,Jaesik Yoon;Gautam Singh;Sungjin Ahn,jaesik817@gmail.com;singh.gautam.iitg@gmail.com;sjn.ahn@gmail.com,6;1;3,,Reject,0,6,0,yes,9/25/19,Rutgers University;;Rutgers University,meta-learning;neural processes;attention;sequential modeling,30;-1;30,-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Generative Latent Flow,Zhisheng Xiao;Qing Yan;Yali Amit,zxiao@uchicago.edu;yanq@uchicago.edu;amit@marx.uchicago.edu,3;3;6,,Reject,0,6,0,yes,9/25/19,University of Chicago;University of Chicago;University of Chicago,Generative Model;Auto-encoder;Normalizing Flow,51;51;51,9;9;9,m;m,usa,usa,n
ICLR,2020,"Farkas layers: don't shift the data, fix the geometry",Aram-Alexandre Pooladian;Chris Finlay;Adam M Oberman,aram-alexandre.pooladian@mail.mcgill.ca;christopher.finlay@gmail.com;adam.oberman@mcgill.ca,1;3;3,,Reject,0,3,0,yes,9/25/19,McGill University;Deep Render;McGill University,initialization;deep networks;residual networks;batch normalization;training;optimization,102;-1;102,42;-1;42,m;m,canada,ca,y
ICLR,2020,STABILITY AND CONVERGENCE THEORY FOR LEARNING RESNET: A FULL CHARACTERIZATION,Huishuai Zhang;Da Yu;Mingyang Yi;Wei Chen;Tie-yan Liu,huishuai.zhang@microsoft.com;yuda3@mail2.sysu.edu.cn;v-minyi@microsoft.com;wche@microsoft.com;tie-yan.liu@microsoft.com,3;1;6,,Reject,1,4,0,yes,9/25/19,Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft;Microsoft;Microsoft,ResNet;stability;convergence theory;over-parameterization,-1;-1;-1;-1;-1,-1;299;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Universal approximations of permutation invariant/equivariant functions by deep neural networks,Akiyoshi Sannai;Yuuki Takai;Matthieu Cordonnier,akiyoshi.sannai@riken.jp;yuuki.takai@riken.jp;matthieu.cordonnier@ens-paris-saclay.fr,3;3;3,,Reject,0,3,0,yes,9/25/19,RIKEN;RIKEN;Ecole Normale Superieure,finite group;invariant;equivariant;neural networks,-1;-1;118,-1;-1;-1,m;m,europe,fr,y
ICLR,2020,Context-aware Attention Model for Coreference Resolution,Yufei Li;Xiangyu Zhou;Jie Ma;Yu Long;Xuan Wang;Chen Li,vermouthtarot@gmail.com;zxy951005@stu.xjtu.edu.cn;majack@stu.xjtu.edu.cn;longyu95@stu.xjtu.edu.cn;wangxuan8888@stu.xjtu.edu.cn;cli@xjtu.edu.cn,1;1;1,,Reject,0,0,0,yes,9/25/19,Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University,Coreference resolution;Feature Attention,-1;-1;-1;-1;-1;-1,-1;555;555;555;555;555,u;m,NAN,NAN,n
ICLR,2020,A Random Matrix Perspective on Mixtures of Nonlinearities in High Dimensions,Ben Adlam;Jake Levinson;Jeffrey Pennington,adlam@google.com;jpennin@google.com;jlev@google.com,8;3;6,,Reject,0,5,0,yes,9/25/19,Google;Google;Google,,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,CaptainGAN: Navigate Through Embedding Space For Better Text Generation,Chun-Hsing Lin;Alvin Chiang;Chi-Liang Liu;Chien-Fu Lin;Po-Hsien Chu;Siang-Ruei Wu;Yi-En Tsai;Chung-Yang (Ric) Huang,jsaon92@gmail.com;alvin.chiang.180@gmail.com;liangtaiwan1230@gmail.com;gblin75468@gmail.com;cph@yoctol.com;raywu0@gmail.com;ypiheyn.imm02g@g2.nctu.edu.tw;cyhuang@ntu.edu.tw,6;6;3,,Reject,0,12,0,yes,9/25/19,National Taiwan University;;;;Yoctol;;National Chiao Tung University;Nanyang Technological University,Generative Adversarial Network;Text Generation;Straight-Through Estimator,-1;-1;-1;-1;-1;-1;118;43,-1;-1;-1;-1;-1;-1;564;49,m;m,asia,sg,n
ICLR,2020,Policy Optimization with Stochastic Mirror Descent,Long Yang;Gang Zheng;Zavier Zhang;Yu Zhang;Qian Zheng;Jun Wen;Gang Pana sample efficient policy gradient method with stochastic mirror descent.,yanglong@zju.edu.cn;gang_zheng@zju.edu.cn;21721269@zju.edu.cn;hzzhangyu@zju.edu.cn;csqianzheng@gmail.com;junwen@zju.edu.cn;gpan@zju.edu.cn,3;3;6,,Reject,0,5,0,yes,9/25/19,Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;;Zhejiang University;Zhejiang University,reinforcement learning;policy gradient;stochastic variance reduce gradient;sample efficiency;stochastic mirror descent,39;39;39;39;-1;39;39,107;107;107;107;-1;107;107,m;u,asia,cn,y
ICLR,2020,A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization,Guangzeng Xie;Luo Luo;Zhihua Zhang,smsxgz@pku.edu.cn;rickyluoluo@gmail.com;zhzhang@math.pku.edu.cn,3;8;6,,Reject,1,4,0,yes,9/25/19,Peking University;;Peking University,convex optimization;lower bound complexity;proximal incremental first-order oracle,14;-1;14,24;-1;24,m;m,asia,cn,y
ICLR,2020,Reducing Computation in Recurrent Networks by Selectively Updating State Neurons,Thomas Hartvigsen;Cansu Sen;Xiangnan Kong;Elke Rundensteiner,twhartvigsen@wpi.edu;csen@wpi.edu;xkong@wpi.edu;rundenst@wpi.edu,6;6;6,,Reject,0,4,0,yes,9/25/19,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute;Worcester Polytechnic Institute,recurrent neural networks;conditional computation;representation learning,143;143;143;143,628;628;628;628,m;f,usa,usa,n
ICLR,2020,Selective Brain Damage: Measuring the Disparate Impact of Model Pruning,Sara Hooker;Yann Dauphin;Aaron Courville;Andrea Frome,shooker@google.com;ynd@google.com;aaron.courville@gmail.com;onepinkfairyarmadillo@gmail.com,3;3;3,,Reject,0,4,0,yes,9/25/19,Google;Google;University of Montreal;Google,machine learning,-1;-1;118;-1,-1;-1;85;-1,f;f,asia,in,n
ICLR,2020,Deep exploration by novelty-pursuit with maximum state entropy,Zi-Niu Li;Xiong-Hui Chen;Yang Yu,liziniu1997@gmail.com;chenxh@lamda.nju.edu.cn;yuy@lamda.nju.edu.cn,1;3;3,,Reject,0,4,0,yes,9/25/19,The Chinese University of Hong Kong;Zhejiang University;Zhejiang University,Exploration;Reinforcement Learning,-1;39;39,-1;107;107,m;m,asia,cn,y
ICLR,2020,Smart Ternary Quantization,Gregoire Morin;Ryan Razani;Vahid Partovi Nia;Eyyub Sari,gregoire.morin@huawei.com;ryan.razani@huawei.com;vahid.partovinia@huawei.com;eyyub.sari@huawei.com,3;6;1;3,,Reject,0,3,0,yes,9/25/19,Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.;Huawei Technologies Ltd.,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Alleviating Privacy Attacks via Causal Learning,Shruti Tople;Amit Sharma;Aditya Nori,t-shtopl@microsoft.com;amshar@microsoft.com;adityan@microsoft.com,3;6;3,,Reject,0,14,0,yes,9/25/19,Microsoft;Microsoft;Microsoft,Causal learning;Membership Inference Attacks;Differential Privacy,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,y
ICLR,2020,Generalized Domain Adaptation with Covariate and Label Shift CO-ALignment,Shuhan Tan;Xingchao Peng;Kate Saenko,tanshh@mail2.sysu.edu.cn;xpeng@bu.edu;saenko@bu.edu,6;1;1,,Reject,1,5,0,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Boston University;Boston University,Domain Adaptation;Label Shift;Covariate Shift,-1;79;79,299;61;61,m;f,europe,it,y
ICLR,2020,Deeper Insights into Weight Sharing in Neural Architecture Search,Yuge Zhang;Quanlu Zhang;Junyang Jiang;Zejun Lin;Yujing Wang,scottyugochang@gmail.com;quanlu.zhang@microsoft.com;jyjiang97@gmail.com;gdzejlin@gmail.com;yujing.wang@microsoft.com,3;3;3,,Reject,0,3,0,yes,9/25/19,Microsoft;Microsoft;;;Microsoft,Neural Architecture Search;NAS;AutoML;AutoDL;Deep Learning;Machine Learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;u,NAN,NAN,n
ICLR,2020,Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels,Shuang Song;David Berthelot;Afshin Rostamizadeh,shuangsong@google.com;dberth@google.com;rostami@google.com,3;6;3,,Reject,0,3,0,yes,9/25/19,Google;Google;Google,active learning;semi-supervised learning,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Perceptual Regularization: Visualizing and Learning Generalizable Representations,Hongzhou Lin;Joshua Robinson;Stefanie Jegelka,hongzhou@mit.edu;joshrob@mit.edu;stefje@csail.mit.edu,6;1;3,,Reject,0,6,0,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,regularization;representation learning;visualization,5;5;5,5;5;5,m;f,usa,usa,n
ICLR,2020,Attention Forcing for Sequence-to-sequence Model Training,Qingyun Dou;Yiting Lu;Joshua Efiong;Mark J.F. Gales,qd212@cam.ac.uk;ytl28@cam.ac.uk;je369@cam.ac.uk;mjfg@cam.ac.uk,1;3;3,,Reject,2,4,0,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;University of Cambridge,deep learning;sequence-to-sequence model;attention mechanism;speech synthesis;machine translation,79;79;79;79,3;3;3;3,m;m,europe,uk,n
ICLR,2020,Transferable Recognition-Aware Image Processing,Zhuang Liu;Tinghui Zhou;Zhiqiang Shen;Bingyi Kang;Trevor Darrell,zhuangl@berkeley.edu;tinghuiz@eecs.berkeley.edu;zhiqians@andrew.cmu.edu;kang@u.nus.edu;trevor@eecs.berkeley.edu,8;1;3,,Reject,0,8,0,yes,9/28/20,University of California Berkeley;University of California Berkeley;Carnegie Mellon University;National University of Singapore;University of California Berkeley,Image Recognition;Image Processing,-1;-1;1;17;-1,13;13;27;25;13,m;m,usa,usa,n
ICLR,2020,NeuralUCB: Contextual Bandits with Neural Network-Based Exploration,Dongruo Zhou;Lihong Li;Quanquan Gu,drzhou@cs.ucla.edu;lihongli.cs@gmail.com;qgu@cs.ucla.edu,3;6;6,,Reject,0,10,0,yes,9/25/19,"University of California, Los Angeles;Amazon;University of California, Los Angeles",contextual bandits;neural network;upper confidence bound,-1;-1;-1,17;-1;17,m;m,usa,usa,y
ICLR,2020,Quantized Reinforcement Learning (QuaRL),Srivatsan Krishnan;Sharad Chitlangia;Maximilian Lam;Zishen Wan;Aleksandra Faust;Vijay Janapa Reddi,srivatsan@seas.harvard.edu;f20170472@goa.bits-pilani.ac.in;maxlam@g.harvard.edu;zishenwan@g.harvard.edu;sandrafaust@google.com;vj@eecs.harvard.edu,3;3;3,,Reject,0,3,0,yes,9/25/19,"Harvard University;BITS Pilani, BITS Pilani;Harvard University;Harvard University;Google;Harvard University",Deep Reinforcement Learning;Quantization,52;445;52;52;-1;52,7;-1;7;7;-1;7,m;m,usa,usa,n
ICLR,2020,CNAS: Channel-Level Neural Architecture Search,Heechul Lim;Min-Soo Kim;Jinjun Xiong,skyde1021@dgist.ac.kr;mskim@dgist.ac.kr;jinjun@us.ibm.com,3;1;3;3,,Reject,0,0,0,yes,9/25/19,DGIST;DGIST;International Business Machines,Neural architecture search,15;15;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?,Hiroaki Yamane;Chin-Yew Lin;Tatsuya Harada,hiroaki.yamane@riken.jp;cyl@microsoft.com;harada@mi.t.u-tokyo.ac.jp,1;3;1,,Reject,0,0,0,yes,9/25/19,RIKEN;Microsoft;The University of Tokyo,numerical common sense;word embedding;semantic representation,-1;-1;64,-1;-1;36,m;m,NAN,NAN,n
ICLR,2020,Semi-supervised Semantic Segmentation using Auxiliary Network,Wei-Hsu Chen;Hsueh-Ming Hang,qoososola520.ee06g@nctu.edu.tw;hmhang@nctu.edu.tw,3;3;3,,Reject,0,0,0,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,deep learning;semi-supervised segmentation;semantic segmentation;CNN,118;118,564;564,m;m,asia,tw,n
ICLR,2020,DeepSFM: Structure From Motion Via Deep Bundle Adjustment,Xingkui Wei;Yinda Zhang;Zhuwen Li;Yanwei Fu;Xiangyang Xue,xkwei19@fudan.edu.cn;yindaz@cs.princeton.edu;lzhuwen@gmail.com;yanweifu@fudan.edu.cn;xyxue@fudan.edu.cn,6;6;3,,Reject,0,4,0,yes,9/25/19,"Fudan University;Princeton University;Nuro, Inc;Fudan University;Fudan University",Computer Vision;Bundle Ajustment;Structure from Motion,73;30;-1;73;73,109;6;-1;109;109,m;m,asia,cn,n
ICLR,2020,A Base Model Selection Methodology for Efficient Fine-Tuning,Yosuke Ueno;Masaaki Kondo,ueno@hal.ipc.i.u-tokyo.ac.jp;kondo@hal.ipc.i.u-tokyo.ac.jp,3;3;3,,Reject,0,4,0,yes,9/25/19,The University of Tokyo;The University of Tokyo,transfer learning;fine-tuning;parameter transfer,64;64,36;36,m;m,NAN,NAN,n
ICLR,2020,Localized Meta-Learning: A PAC-Bayes Analysis for Meta-Leanring Beyond Global Prior,Chenghao Liu;Tao Lu;Doyen Sahoo;Yuan Fang;Steven C.H. Hoi.,chliu@smu.edu.sg;lutaott@zju.edu.cn;doyensahoo@gmail.com;yfang@smu.edu.sg;shoi@salesforce.com,3;3;8;6,,Reject,0,9,0,yes,9/25/19,Singapore Management University;Zhejiang University;;Singapore Management University;SalesForce.com,localized meta-learning;PAC-Bayes;meta-learning,79;39;-1;79;-1,-1;107;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Searching to Exploit Memorization Effect in Learning from Corrupted Labels,Hansi Yang;Quanming Yao;Bo Han;Gang Niu,yhs17@mails.tsinghua.edu.cn;qyaoaa@connect.ust.hk;bo.han@riken.jp;gang.niu@riken.jp,3;3;3,,Reject,0,5,0,yes,9/25/19,"Tsinghua University, Tsinghua University;The Hong Kong University of Science and Technology;RIKEN;RIKEN",Noisy Label;Deep Learning;Automated Machine Learning,4;-1;-1;-1,23;47;-1;-1,u;m,NAN,NAN,n
ICLR,2020,Attention over Phrases,Wanyun Cui,cui.wanyun@sufe.edu.cn,3;1;1,,Reject,1,2,0,yes,9/25/19,University of Science and Technology of China,representation learning;natural language processing;attention,-1,80,m,NAN,NAN,n
ICLR,2020,Retrospection: Leveraging the Past for Efficient Training of Deep Neural Networks,Ayush Chopra;Surgan Jandial;Mausoom Sarkar;Balaji Krishnamurthy;Vineeth Balasubramanian,ayuchopr@adobe.com;cs17btech11038@iith.ac.in;msarkar@adobe.com;kbalaji@adobe.com;vineethnb@iith.ac.in,8;3,,Reject,0,6,0,yes,9/25/19,Adobe Systems;Indian Institute of Technology Hyderabad;Adobe Systems;Adobe Systems;Indian Institute of Technology Hyderabad,Deep Neural Networks;Supervised Learning;Classification;Training Strategy;Generative Adversarial Networks;Convolutional Neural Networks,-1;-1;-1;-1;-1,-1;713;-1;-1;713,m;m,NAN,NAN,n
ICLR,2020,Improving Dirichlet Prior Network for Out-of-Distribution Example Detection,Jay Nandy,a0123886@u.nus.edu,3;3;6,,Reject,0,5,0,yes,9/25/19,National University of Singapore,predictive uncertainty;distributional uncertainty;Dirichlet distribution;out-of-distribution detection;deep learning,17,25,m,asia,sg,n
ICLR,2020,Continual Density Ratio Estimation (CDRE): A new method for evaluating generative models in continual learning,Yu Chen;Song Liu;Tom Diethe;Peter Flach,yc14600@bristol.ac.uk;song.liu@bristol.ac.uk;tdiethe@amazon.com;peter.flach@bristol.ac.uk,1;1;6,,Reject,0,5,0,yes,9/25/19,University of Bristol;University of Bristol;Amazon;University of Bristol,density ratio estimation;continual learning;evaluation;generative model;f divergence,118;118;-1;118,87;87;-1;87,m;m,europe,uk,n
ICLR,2020,Prune or quantize? Strategy for Pareto-optimally low-cost and accurate CNN,Kengo Nakata;Daisuke Miyashita;Asuka Maki;Fumihiko Tachibana;Shinichi Sasaki;Jun Deguchi,kengo1.nakata@toshiba.co.jp;daisuke1.miyashita@toshiba.co.jp;asuka.maki@toshiba.co.jp;fumihiko.tachibana@toshiba.co.jp;shinichi8.sasaki@toshiba.co.jp;jun.deguchi@toshiba.co.jp,3;3;3,,Reject,0,11,0,yes,9/25/19,Toshiba Corporation;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation;Toshiba Corporation,CNN;Quantization;Pruning;Accelerator;Computational cost,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Concise Multi-head Attention Models,Srinadh Bhojanapalli;Chulhee Yun;Ankit Singh Rawat;Sashank Reddi;Sanjiv Kumar,bsrinadh@google.com;chulheey@mit.edu;ankitsrawat@google.com;sashank@google.com;sanjivk@google.com,1;3;3,,Reject,0,3,0,yes,9/25/19,Google;Massachusetts Institute of Technology;Google;Google;Google,Transformers;Attention;Multihead;expressive power;embedding size,-1;5;-1;-1;-1,-1;5;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,A Finite-Time Analysis of  Q-Learning with Neural Network Function Approximation,Pan Xu;Quanquan Gu,panxu@cs.ucla.edu;qgu@cs.ucla.edu,3;6;6,,Reject,4,6,0,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",Reinforcement Learning;Neural Networks,-1;-1,17;17,m;m,usa,usa,y
ICLR,2020,SCELMo: Source Code Embeddings from Language Models,Rafael - Michael Karampatsis;Charles Sutton,mpatsis13@gmail.com;charlessutton@google.com,3;3;8,,Reject,0,4,0,yes,9/25/19,University of Edinburgh;Google,Transfer Learning;Pretraining;Program Repair,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,GraphMix: Regularized Training of Graph Neural Networks for Semi-Supervised Learning,Vikas Verma;Meng Qu;Alex Lamb;Yoshua Bengio;Juho Kannala;Jian Tang,vikasverma.iitm@gmail.com;meng.qu@umontreal.ca;lambalex@iro.umontreal.ca;yoshua.bengio@mila.quebec;juho.kannala@aalto.fi;jian.tang@hec.ca,3;3;6,,Reject,1,5,0,yes,9/25/19,Aalto University;University of Montreal;University of Montreal;Mila;Aalto University;HEC Montreal,Regularization;Graph Neural Networks;Mixup;Manifold Mixup;Semi-supervised Object Classification over graph Data,118;118;118;143;118;-1,182;85;85;336;182;-1,m;m,canada,ca,n
ICLR,2020,Neural networks with motivation,Sergey A. Shuvaev;Ngoc B. Tran;Marcus Stephenson-Jones;Bo Li;Alexei A. Koulakov,sshuvaev@cshl.edu;ntran@cshl.edu;mstephen@cshl.edu;bli@cshl.edu;akula@cshl.edu,1;3;3,,Reject,0,11,0,yes,9/25/19,Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory;Cold Spring Harbor Laboratory,neuroscience;brain;motivation;learning;reinforcement learning;recurrent neural network;deep learning,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Measuring causal influence with back-to-back regression: the linear case,Jean-Remi King;Francois Charton;Maxime Oquab;David Lopez-Paz,jeanremi@fb.com;fcharton@fb.com;qas@fb.com;dlp@fb.com,6;3;3,,Reject,0,6,0,yes,9/25/19,Facebook;Facebook;Facebook;Facebook,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Longitudinal Enrichment of Imaging Biomarker Representations for Improved Alzheimer's Disease Diagnosis,Saad Elbeleidy;Lyujian Lu;L. Zoe Baker;Hua Wang;Feiping Nie,selbeleidy@mymail.mines.edu;lyujianlu@mines.edu;laurenzoebaker@mymail.mines.edu;huawangcs@gmail.com;feipingnie@gmail.com,1;3;1,,Reject,0,0,0,yes,9/25/19,Colorado School of Mines;Colorado School of Mines;Colorado School of Mines;Colorado School of Mines;Tsinghua University,,248;248;248;248;-1,343;343;343;343;-1,m;m,asia,in,y
ICLR,2020,RefNet: Automatic Essay Scoring by Pairwise Comparison,Jiaxin Li;Jinan Zhou,jiaxin.li@link.cuhk.edu.hk;jinan.zhou@link.cuhk.edu.hk,1;3;1,,Withdrawn,0,0,,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong,Natural Language Processing;Automatic Essay Scoring;Few-shot Learning;Neural Network;,316;316,35;35,m;m,NAN,NAN,n
ICLR,2020,Topology of deep neural networks,Gregory Naitzat;Andrey Zhitnikov;Lek-Heng Lim,gregn@uchicago.edu;andreyz@technion.ac.il;lekheng@galton.uchicago.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,"University of Chicago;Technion, Technion;University of Chicago",theoretical issues in deep learning;topology;Betti numbers;,51;27;51,9;-1;9,m;m,usa,usa,pdf miss
ICLR,2020,Provable Convergence and Global Optimality  of Generative Adversarial Network,Qi Cai;Zhuoran Yang;Jason D. Lee;Shaolei S. Du;Zhaoran Wang,qicai2022@u.northwestern.edu;zy6@princeton.edu;jasonlee@princeton.edu;ssdu@ias.edu;zhaoranwang@gmail.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"Northwestern University;Princeton University;Princeton University;Institue for Advanced Study, Princeton;Northwestern University",generative adversarial network;IPM-based GANs;overparametrized neural network;,46;30;30;-1;46,22;6;6;-1;22,f;m,usa,usa,n
ICLR,2020,Improving Irregularly Sampled Time Series Learning with Dense Descriptors of Time,Rafael Teixeira Sousa;Lucas Ara√∫jo Pereira;Anderson da Silva Soares,rafaelts777@gmail.com;apereiral@outlook.com;engsoares@gmail.com,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Universidade Federal de Mato Grosso;;Federal University of Goias,irregularly sampled;time series;embeddings;,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Understanding and Training Deep Diagonal Circulant Neural Networks,Alexandre Araujo;Benjamin Negrevergne;Yann Chevaleyre;Jamal Atif,alexandre.araujo@dauphine.eu;benjamin.negrevergne@dauphine.psl.eu;yann.chevaleyre@lamsade.dauphine.fr;jamal.atif@lamsade.dauphine.fr,1;3,,Withdrawn,0,2,,yes,9/25/19,Univerist√© Paris-Dauphine;Universit‚àö¬© Paris Dauphine;Univerist‚àö¬© Paris-Dauphine;Univerist‚àö¬© Paris-Dauphine,Deep Learning;Structured Matrices;Compression;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,DP-LSSGD: An Optimization Method to Lift the Utility in Privacy-Preserving ERM,Bao Wang;Quanquan Gu;March Boedihardjo;Farzin Barekat;Stanley J. Osher,wangbaonj@gmail.com;qgu@cs.ucla.edu;march@math.ucla.edu;fbarekat@math.ucla.edu;sjo@math.ucla.edu,3;6;3,,Withdrawn,0,3,,yes,9/25/19,"University of Utah;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",Privacy-preserving ERM;Laplacian Smoothing;Improve Utility;,64;-1;-1;-1;-1,219;17;17;17;17,m;m,usa,usa,y
ICLR,2020,On Global Feature Pooling for Fine-grained Visual Categorization,Pei Guo;Connor Anderson;Ryan Farrell,peiguo@cs.byu.edu;thecatalystak@gmail.com;farrell@cs.byu.edu,6;3;1,,Withdrawn,2,0,,yes,9/25/19,The Hong Kong Polytechnic University;;The Hong Kong Polytechnic University,global pooling;fine-grained recognition;benchmark;,118;-1;118,171;-1;171,m;m,asia,hk,n
ICLR,2020,Quantifying Exposure Bias for Neural Language Generation,Tianxing He;Jingzhao Zhang;Zhiming Zhou;James Glass,cloudygoose@csail.mit.edu;jzhzhang@mit.edu;heyohai@apex.sjtu.edu.cn;glass@mit.edu,3;3;3,,Withdrawn,0,6,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Shanghai Jiao Tong University;Massachusetts Institute of Technology,language model;exposure bias;language generation;,5;5;30;5,5;5;157;5,m;m,usa,usa,n
ICLR,2020,Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for Neural Language Generation Models,Tianxing He;Jun Liu;Kyunghyun Cho;Myle Ott;Bing Liu;James Glass;Fuchun Peng,tianxing@mit.edu;junliu@fb.com;kyunghyuncho@fb.com;myleott@fb.com;bingl@fb.com;glass@mit.edu;fuchunpeng@fb.com,3;3;6,,Withdrawn,0,3,,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook;Facebook;Massachusetts Institute of Technology;Facebook,language generation;forgetting;pretraining;open-domain dialogue;,5;-1;-1;-1;-1;5;-1,5;-1;-1;-1;-1;5;-1,m;m,NAN,NAN,n
ICLR,2020,INVOCMAP: MAPPING METHOD NAMES TO METHOD INVOCATIONS VIA MACHINE LEARNING,Hung Phan;Ali Jannesari,hungphd@iastate.edu;jannesar@iastate.edu,1;1;1,,Withdrawn,0,4,,yes,9/25/19,Iowa State University;Iowa State University,Statistical Machine Translation;Method Invocation;Auto Code Completion;Software Engineering;,194;194,399;399,m;m,usa,usa,n
ICLR,2020,Fix-Net: pure fixed-point representation of deep neural networks,Lukas Enderich;Fabian Timm;Lars Rosenbaum;Wolfram Burgard,lukas.enderich@de.bosch.com;fabian.timm@de.bosch.com;lars.rosenbaum@de.bosch.com;burgard@informatik.uni-freiburg.de,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Bosch;Bosch;Bosch;Universit√§t Freiburg,Deep neural networks;fixed-point quantization;bit-shift;soft quantization;,-1;-1;-1;-1,297;297;297;-1,m;m,NAN,NAN,n
ICLR,2020,Random Partition Relaxation for Training Binary and Ternary Weight Neural Network,Lukas Cavigelli;Luca Benini,cavigelli@iis.ee.ethz.ch;benini@iis.ee.ethz.ch,1;3;1;3,,Withdrawn,0,1,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,binary weight neural networks;ternary weight neural networks;quantization;quantized neural networks;,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Emergent Communication in Networked Multi-Agent Reinforcement Learning,Shubham Gupta;Rishi Hazra;Amebdkar Dukkipati,shubhamg@iisc.ac.in;rishihazra@iisc.ac.in;ambedkar@iisc.ac.in,3;1;3,,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;Indian Institute of Science,emergent communication;multi-agent reinforcement learning;,-1;-1;-1,301;301;301,m;m,NAN,NAN,n
ICLR,2020,Recognizing Plans by Learning Embeddings from Observed Action Distributions,Yantian Zha;Yikang Li;Sriram Gopalakrishnan;Hankz Hankui Zhuo;Baoxin Li;Subbarao Kambhampati,yantian.zha@asu.edu;yikangli@asu.edu;sgopal28@asu.edu;zhuohank@mail.sysu.edu.cn;baoxin.li@asu.edu;rao@asu.edu,1;3;1;3,,Withdrawn,0,5,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,action representation learning;plan recognition;shallow model planning;,-1;-1;-1;-1;-1;-1,299;299;299;299;299;299,m;m,NAN,NAN,n
ICLR,2020,Cancer homogeneity in single cell revealed by Bi-state model and Binary matrix factorization,Changlin Wan;Wennan Chang;Sha Cao;Xiao Wang;Chi Zhang,wan82@purdue.edu;chang534@purdue.edu;shacao@iu.edu;wangxiao@purdue.edu;czhang87@iu.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,"Purdue University;Purdue University;Indiana University, Bloomington;Purdue University;Indiana University, Bloomington",Boolean Matrix factorization;single cell analysis;computational biology;cancer research;,24;24;64;24;64,88;88;134;88;134,m;m,NAN,NAN,n
ICLR,2020,Residual EBMs: Does Real vs. Fake Text Discrimination Generalize?,Anton Bakhtin;Sam Gross;Myle Ott;Yuntian Deng;Marc'Aurelio Ranzato;Arthur Szlam,yolo@fb.com;sgross@fb.com;myleott@fb.com;dengyuntian@g.harvard.edu;ranzato@fb.com;aszlam@fb.com,1;3;3;1,,Withdrawn,0,0,,yes,9/25/19,Facebook;Facebook;Facebook;Harvard University;Facebook;Facebook,energy-based models;real fake discrimination;text modeling;,-1;-1;-1;52;-1;-1,-1;-1;-1;7;-1;-1,m;m,NAN,NAN,n
ICLR,2020,EnsembleNet: A novel architecture for Incremental Learning,Suri Bhasker Sri Harsha;Y Kalidas,cs18s506@iittp.ac.in;ykalidas@iittp.ac.in,1;1;1,,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Technology Tirupati;Indian Institute of Technology Tirupati,,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,Dual Sequential Monte Carlo: Tunneling Filtering and Planning in Continuous POMDPs,Yunbo Wang;Bo Liu;Jiajun Wu;Yuke Zhu;Simon Shaolei Du;Li Fei-Fei;Joshua B. Tenenbaum,yunbo.thu@gmail.com;bliu@cs.utexas.edu;jiajunw@stanford.edu;yukez@cs.stanford.edu;ssdu@ias.edu;feifeili@cs.stanford.edu;jbt@mit.edu,1;3;3,,Withdrawn,0,4,,yes,9/25/19,"Shanghai Jiao Tong University;University of Texas, Austin;Stanford University;Stanford University;Institue for Advanced Study, Princeton;Stanford University;Massachusetts Institute of Technology",,30;-1;5;5;-1;5;5,157;-1;4;4;-1;4;5,m;m,usa,usa,y
ICLR,2020,Fast Bilinear Matrix Normalization via  Rank-1 Update,Tan Yu;Yunfeng Cai;Ping Li,tanyu01@baidu.com;caiyunfeng@baidu.com;liping11@baidu.com,6;3;1,,Withdrawn,0,7,,yes,9/25/19,Baidu;Baidu;Baidu,Computer Vision;Bilinear Pooling;Efficient Network;Fine-grained Classification;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Task-Mediated Representation Learning,Sergei Bugrov;Ron Sun,bugros@rpi.edu;rsun@rpi.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute,,248;248,438;438,m;m,usa,usa,n
ICLR,2020,Universality Theorems for Generative Models,Valentin Khrulkov;Ivan Oseledets,khrulkov.v@gmail.com;i.oseledets@skoltech.ru,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Yandex;Skolkovo Institute of Science and Technology,generative models;theory;universality;manifolds;differential geometry;,-1;-1,-1;-1,m;m,europe,russia,y
ICLR,2020,Embodied Language Grounding with Implicit 3D Visual Feature Representations,Mihir Prabhudesai;Hsiao-Yu Fish Tung;Syed Ashar Javed;Maximilian Sieb;Adam W. Harley;Katerina Fragkiadaki,mprabhud@cs.cmu.edu;htung@cs.cmu.edu;sajaved@andrew.cmu.edu;aharley@cs.cmu.edu;katef@cs.cmu.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1;1,27;27;27;27;27,m;f,usa,usa,n
ICLR,2020,Geometry-Aware Visual Predictive Models of Intuitive Physics,Hsiao-Yu Fish Tung;Zhou Xian;Mihir Prabhudesai;Katerina Fragkiadaki,htung@cs.cmu.edu;zhouxian@cmu.edu;mprabhud@cs.cmu.edu;katef@cs.cmu.edu,3;6;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,,1;1;1;1,27;27;27;27,f;f,usa,usa,n
ICLR,2020,PNEN: Pyramid Non-Local Enhanced Networks,Feida Zhu;Chaowei Fang;Kai-Kuang Ma,feida.zhu@ntu.edu.sg;chwfang@connect.hku.hk;ekkma@ntu.edu.sg,1;1;6,,Withdrawn,0,0,,yes,9/25/19,Nanyang Technological University;The University of Hong Kong;Nanyang Technological University,,43;92;43,49;35;49,m;m,asia,sg,n
ICLR,2020,"Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks",Agustinus Kristiadi;Matthias Hein;Philipp Hennig,agustinus.kristiadi@uni-tuebingen.de;matthias.hein@uni-tuebingen.de;philipp.hennig@uni-tuebingen.de,1;1;3,,Withdrawn,0,1,,yes,9/25/19,University of Tuebingen;University of Tuebingen;University of Tuebingen,uncertainty quantification;overconfidence;Bayesian inference;,143;143;143,91;91;91,m;m,europe,de,y
ICLR,2020,Auto Network Compression with Cross-Validation Gradient,Nannan Tian;Yong Liu,tiannannan@iie.ac.cn;liuyong@iie.ac.cn,1;3;1,,Withdrawn,0,1,,yes,9/25/19,"Institute of information engineering, CAS;Institute of information engineering, CAS",,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,Feature-based Augmentation for Semi-Supervised Learning,Min-Hye Oh;Byung-Gook Park,listogato3@gmail.com;bgpark@snu.ac.kr,3;1;6,,Withdrawn,0,0,,yes,9/25/19,Seoul National University;Seoul National University,semi-supervised learning;,-1;39,-1;64,m;m,asia,kr,n
ICLR,2020,Capsule Networks without Routing Procedures,Zhenhua Chen;Xiwen Li;Chuhua Wang;David Crandall,chen478@iu.edu;xiwenli@wustl.edu;cw234@iu.edu;djcran@indiana.edu,1;3;3,,Withdrawn,6,3,,yes,9/25/19,"Indiana University, Bloomington;Washington University, St. Louis;Indiana University, Bloomington;Indiana University",CapsNets;routing procedures;,64;-1;64;64,134;-1;134;134,m;m,usa,usa,n
ICLR,2020,Noisy $\ell^{0}$-Sparse Subspace Clustering on Dimensionality Reduced Data,Yingzhen Yang,superyyzg@gmail.com,3;6;3,,Withdrawn,0,0,,yes,9/25/19,0,Sparse Subspace Clustering (SSC);Noisy L0-SSC;Subspace Detection Property;,,,m,NAN,NAN,y
ICLR,2020,Side-Tuning: Network Adaptation via Additive Side Networks,Alexander Sax;Jeffrey Zhang;Amir Zamir;Silvio Savarese;Jitendra Malik,sax@berkeley.edu;jozhang@berkeley.edu;zamir@cs.stanford.edu;ssilvio@cs.stanford.edu;malik@eecs.berkeley.edu,3;3;3,,Withdrawn,0,6,,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;Stanford University;University of California Berkeley,sidetuning;finetuning;transfer learning;representation learning;lifelong learning;incremental learning;continual learning;meta-learning;,-1;-1;5;5;-1,13;13;4;4;13,m;m,usa,usa,n
ICLR,2020,Deep Multivariate Mixture of Gaussians for Object Detection under Occlusion,Yihui He;Jianren Wang,he2@andrew.cmu.edu;jianrenw@andrew.cmu.edu,1;1;6,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,object detection;multivariate mixture of Gaussian;,1;1,27;27,m;m,usa,usa,n
ICLR,2020,Dynamic Graph Message Passing Networks,Li Zhang;Dan Xu;Anurag Arnab;Philip H.S. Torr,lz@robots.ox.ac.uk;danxu@robots.ox.ac.uk;anurag.arnab@gmail.com;phst@robots.ox.ac.uk,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of Oxford;University of Oxford;Google;University of Oxford,,46;46;-1;46,1;1;-1;1,m;m,europe,uk,n
ICLR,2020,POLYNOMIAL ACTIVATION FUNCTIONS,Vikas Gottemukkula,vikas11187@gmail.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Zoloz,Activation functions;Deep Learning;,-1,-1,m,NAN,NAN,n
ICLR,2020,CopyCAT: Taking Control of Neural Policies with Constant Attacks,L√©onard Hussenot;Matthieu Geist;Olivier Pietquin,hussenot@google.com;mfgeist@google.com;pietquin@google.com,1;3;3,,Withdrawn,0,4,,yes,9/25/19,Google;Google;Google,reinforcement learning;adversarial examples;attack;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Influence-aware Memory for Deep Reinforcement Learning,Miguel Suau;Elena Congeduti;Rolf A.N. Starre;Aleksander Czechowski;Frans A. Oliehoek,m.suaudecastro@tudelft.nl;e.congeduti@tudelft.nl;a.t.czechowski@tudelft.nl;r.a.n.starre@tudelft.nl;f.a.oliehoek@tudelft.nl,1;3;1,,Withdrawn,1,4,,yes,9/25/19,Delft University of Technology;Delft University of Technology;Delft University of Technology;Delft University of Technology;Delft University of Technology,Deep Reinforcement Learning;POMDP;Influence;Memory;Recurrent Neural Networks;,-1;-1;-1;-1;-1,67;67;67;67;67,m;m,NAN,NAN,n
ICLR,2020,CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition,Yuge Huang;Yuhan Wang;Ying Tai;Xiaoming Liu;Pengcheng Shen;Shaoxin Li;Jilin Li;Feiyue Huang,huangyg@zju.edu.cn;wang_yuhan@zju.edu.cn;yingtai@tencent.com;liuxm@cse.msu.edu;quantshen@tencent.com;darwinli@tencent.com;jerolinli@tencent.com;garyhuang@tencent.com,3;6;3,,Withdrawn,0,3,,yes,9/25/19,Zhejiang University;Zhejiang University;Tencent AI Lab;Michigan State University;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab,CurricularFace;Adaptive Curriculum Learning;Face Recognition;,39;39;-1;102;-1;-1;-1;-1,107;107;-1;84;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Compressive Hyperspherical Energy Minimization,Rongmei Lin;Weiyang Liu;Zhen Liu;Chen Feng;Zhiding Yu;James M. Rehg;Li Xiong;Le Song,rongmei.lin@emory.edu;wyliu@gatech.edu;zhen.liu.2@umontreal.ca;cfeng@nyu.edu;zhidingy@nvidia.com;rehg@gatech.edu;lxiong@emory.edu;lsong@cc.gatech.edu,6;3;3;3,,Withdrawn,0,9,,yes,9/25/19,Emory University;Georgia Institute of Technology;University of Montreal;New York University;NVIDIA;Georgia Institute of Technology;Emory University;Georgia Institute of Technology,,194;13;118;22;-1;13;194;13,80;38;85;29;-1;38;80;38,f;m,usa,usa,y
ICLR,2020,Testing Robustness Against Unforeseen Adversaries,Daniel Kang*;Yi Sun*;Dan Hendrycks;Tom Brown;Jacob Steinhardt,ddkang@stanford.edu;yisun@math.columbia.edu;hendrycks@berkeley.edu;tom@openai.com;jsteinhardt@berkeley.edu,3;3;3,,Withdrawn,1,4,,yes,9/28/20,Stanford University;Columbia University;University of California Berkeley;OpenAI;University of California Berkeley,adversarial examples;adversarial training;adversarial attacks;,5;24;-1;-1;-1,4;16;13;-1;13,m;m,usa,usa,n
ICLR,2020,Reasoning-Aware Graph Convolutional Network for Visual Question Answering,Yangyang Cheng;Chun Yuan,chengyang317@gmail.com;yuanc@sz.tsinghua.edu.cn,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",graph convolutional networks;visual reasoning;visual question answering;,4;4,23;23,f;m,NAN,NAN,n
ICLR,2020,Text Embedding Bank Module for Detailed Image Paragraph Caption,Zengming Shen;Arjun Gupta;Thomas S. Huang,zshen5@illinois.edu;arjung2@illinois.edu;t-huang1@illinois.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",caption;text embedding;,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n
ICLR,2020,FNNP: Fast Neural Network Pruning Using Adaptive Batch Normalization,Bailin Li;Bowen Wu;Jiang Su;Guangrun Wang,bl-zorro@163.com;wubw6@mail2.sysu.edu.cn;sujiang@dm-ai.cn;wangguangrun@dm-ai.cn,3;3;1,,Withdrawn,1,5,,yes,9/25/19,163;SUN YAT-SEN UNIVERSITY;DMAI Inc.;DMAI Inc.,,-1;-1;-1;-1,-1;299;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Boosting Ticket: Towards Practical Pruning for Adversarial Training with Lottery Ticket Hypothesis,Bai Li;Shiqi Wang;Yunhan Jia;Yantao Lu;Zhenyu Zhong;Lawrence Carin;Suman Jana,bai.li@duke.edu;tcwangshiqi@cs.columbia.edu;jack0082010@gmail.com;ylu25@syr.edu;edwardzhong@baidu.com;lcarin@duke.edu;suman@cs.columbia.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Duke University;Columbia University;University of Michigan;Syracuse University;Baidu;Duke University;Columbia University,neural networks;adversarial training;prune;,46;24;7;194;-1;46;24,20;16;21;292;-1;20;16,m;m,usa,usa,n
ICLR,2020,Stabilizing Neural ODE Networks with Stochasticity,Xuanqing Liu;Tesi Xiao;Si Si;Qin Cao;Sanjiv Kumar;Cho-Jui Hsieh,xqliu@cs.ucla.edu;texiao@ucdavis.edu;sisidaisy@google.com;qincao@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Los Angeles;University of California, Davis;Google;Google;Google;University of California, Los Angeles",,-1;-1;-1;-1;-1;-1,17;55;-1;-1;-1;17,m;m,usa,usa,n
ICLR,2020,Robustness and/or Redundancy Emerge in Overparametrized Deep Neural Networks,Stephen Casper;Xavier Boix;Vanessa D'Amario;Christopher Rodriguez;Ling Guo;Kasper Vinken;Gabriel Kreiman,scasper@college.harvard.edu;xboix@mit.edu;vanedamario@gmail.com;chrizrodz@gmail.com;kasper.vinken@kuleuven.be;gabriel.kreiman@childrens.harvard.edu,8;1;3,,Withdrawn,0,0,,yes,9/25/19,Harvard University;Massachusetts Institute of Technology;;;KU Leuven;Harvard University,overparametrized dnns;robustness;redundancy;compressibility;generalization;,52;5;-1;-1;143;52,7;5;-1;-1;45;7,m;m,usa,usa,n
ICLR,2020,Interpretable Deep Neural Network Models: Hybrid of Image Kernels and Neural Networks,Mr. Jay Hoon Jung;and Prof. YoungMin Kwon,jay.jung@stonybrook.edu;youngmin.kwon@sunykorea.ac.kr,1;1;3,,Withdrawn,0,0,,yes,9/25/19,"State University of New York, Stony Brook;Korea University",Interpretability;DNN;Hybrid Networks;,-1;168,-1;179,m;m,asia,kr,y
ICLR,2020,EnsembleNet: End-to-End Optimization of Multi-headed Models,Hanhan Li;Joe Ng;Apostol (Paul) Natsev,mirror.haha@gmail.com;yhng@google.com;natsev@google.com,3;3;1,,Withdrawn,0,6,,yes,9/25/19,Google;Google;Google,Computer Vision;Deep Learning;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PatchVAE: Learning Local Latent Codes for Recognition,Kamal Gupta;Saurabh Singh;Abhinav Shrivastava,kamalgupta308@gmail.com;saurabhsingh@google.com;abhinav@cs.umd.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"University of Maryland, College Park;Google;University of Maryland, College Park",unsupervised learning;deep learning;representation learning;recognition;computer vision;,12;-1;12,91;-1;91,m;m,usa,usa,n
ICLR,2020,Improving One-Shot NAS By Suppressing The Posterior Fading,Xiang Li*;Chen Lin*;Chuming Li;Ming Sun;Wei Wu;Junjie Yan;Wanli Ouyang,xiang_li_1@brown.edu;linchen@sensetime.com;lichuming@sensetime.com;sunming1@sensetime.com;wuwei@sensetime.com;yanjunjie@sensetime.com;wanli.ouyang@sydney.edu.au,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Brown University;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;University of Sydney,Computer vision;Image classification;Neural Architecture Search;,85;-1;-1;-1;-1;-1;64,53;-1;-1;-1;-1;-1;60,m;m,europe,uk,n
ICLR,2020,Min-max Entropy for Weakly Supervised Pointwise Localization,Belharbi Soufiane;Rony J√©r√¥me;Dolz Jose;Ben Ayed Ismail;McCaffrey Luke;Granger Eric,soufiane.belharbi.1@etsmtl.net;jerome.rony.1@etsmtl.net;jose.dolz@etsmtl.ca;ismail.benayed@etsmtl.ca;luke.mccaffrey@mcgill.ca;eric.granger@etsmtl.ca,3;3;1,,Withdrawn,0,0,,yes,9/25/19,√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;√âcole de technologie sup√©rieure;McGill University;√âcole de technologie sup√©rieure,weakly supervised pointwise localization;deep learning;interpretability;computer vision;,-1;-1;-1;-1;102;-1,-1;-1;-1;-1;42;-1,m;m,NAN,NAN,n
ICLR,2020,Context-Gated Convolution,Xudong Lin;Lin Ma;Wei Liu;Shih-Fu Chang,xudong.lin@columbia.edu;forest.linma@gmail.com;wl2223@columbia.edu;shih.fu.chang@columbia.edu,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Columbia University;;Columbia University;Columbia University,Convolutional Neural Network;Context-Gated Convolution;Global Context Information;,24;-1;24;24,16;-1;16;16,m;m,usa,usa,n
ICLR,2020,FAKE CAN BE REAL IN GANS,Song Tao;Jia Wang,taosong@sjtu.edu.cn;jiawang@sjtu.edu.cn,1;3;8,,Withdrawn,0,4,,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,GANs;Mode collapse;Gradient exploding;Stability;,30;30,157;157,m;f,asia,cn,y
ICLR,2020,WHAT ILLNESS OF LANDSCAPE CAN OVER-PARAMETERIZATION ALONE CURE?,Dawei Li;Tian Ding;Ruoyu Sun,dawei2@illinois.edu;dt016@ie.cuhk.edu.hk;ruoyus@illinois.edu,3;3;1,,Withdrawn,0,9,,yes,9/25/19,"University of Illinois, Urbana Champaign;The Chinese University of Hong Kong;University of Illinois, Urbana Champaign",,-1;316;-1,-1;35;-1,m;m,usa,usa,y
ICLR,2020,Representational Disentanglement for Multi-Domain Image Completion,Liyue Shen;Wentao Zhu;Xiaosong Wang;Lei Xing;John Pauly;Baris Turkbey;Stephanie Harmon;Thomas Sanford;Sherif Mehralivand;Peter L. Choyke;Bradford J. Wood;Daguang Xu,liyues@stanford.edu;wentaoz@nvidia.com;xiaosongw@nvidia.com;lei@stanford.edu;pauly@stanford.edu;ismail.turkbey@nih.gov;stephanie.harmon@nih.gov;thomas.sanford@nih.gov;sherif.mehralivand@nih.gov;pchoyke@mail.nih.gov;bwood@nih.gov;daguangx@nvidia.com,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Stanford University;NVIDIA;NVIDIA;Stanford University;Stanford University;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;NVIDIA,,5;-1;-1;5;5;-1;-1;-1;-1;-1;-1;-1,4;-1;-1;4;4;-1;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,SCL: Towards Accurate Domain Adaptive Object Detection via Gradient Detach Based Stacked Complementary Losses,Zhiqiang Shen;Harsh Maheshwari;Weichen Yao;Marios Savvides,zhiqians@andrew.cmu.edu;harshmaheshwari135@gmail.com;wyao2@andrew.cmu.edu;marioss@andrew.cmu.edu,3;3;3,,Withdrawn,1,5,,yes,9/25/19,Carnegie Mellon University;;Carnegie Mellon University;Carnegie Mellon University,Domain Adaptation;Object Detection;Gradient Detach;Stacked Complementary Losses;,1;-1;1;1,27;-1;27;27,m;m,usa,usa,n
ICLR,2020,Relevant-features based Auxiliary Cells for Robust and Energy Efficient Deep Learning,Aparna Aketi;Priyadarshini Panda;Kaushik Roy,saketi@purdue.edu;priya.panda@yale.edu;kaushik@purdue.edu,1;3;6,,Withdrawn,0,5,,yes,9/25/19,Purdue University;Yale University;Purdue University,Machine learning;deep neural networks;error detection;robust deep learning;energy efficiency;adversarial robustness;out-of-distribution detection;abnormal inputs detection;misclassified samples detection;,24;73;24,88;8;88,f;m,usa,usa,n
ICLR,2020,Learning to Transfer Learn,Linchao Zhu;Sercan O. Arik;Yi Yang;Tomas Pfister,zhulinchao7@gmail.com;soarik@google.com;yi.yang@uts.edu.au;tpfister@google.com,3;3,,Withdrawn,0,4,,yes,9/25/19,University of Technology Sydney;Google;University of Technology Sydney;Google,transfer learning;adaptive training;,73;-1;73;-1,193;-1;193;-1,u;m,NAN,NAN,n
ICLR,2020,Variational lower bounds on mutual information based on nonextensive statistical mechanics,Valeriu Balaban;Yang Zikun;Paul Bogdan,vbalaban@usc.edu;yangzikun@buaa.edu.cn;pbogdan@usc.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Southern California;Beihang University;University of Southern California,mutual information;variational bounds;nonextensive statistical mechanics;,36;102;36,62;594;62,m;m,usa,usa,n
ICLR,2020,Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets,Yogesh Balaji;Tom Goldstein;Judy Hoffman,yogesh@cs.umd.edu;tomg@cs.umd.edu;judy@gatech.edu,3;6;3,,Withdrawn,0,5,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;Georgia Institute of Technology",Adversarial training;Improving generalization;robustness-accuracy tradeoff;,12;12;13,91;91;38,m;f,usa,usa,n
ICLR,2020,Robust Few-Shot Learning with Adversarially Queried Meta-Learners,Micah Goldblum;Liam Fowl;Tom Goldstein,goldblumcello@gmail.com;lhfowl@gmail.com;tomg@cs.umd.edu,3;6;3,,Withdrawn,0,4,,yes,9/25/19,"University of Maryland, College Park;;University of Maryland, College Park",meta-learning;adversarial;robust;few-shot;,-1;-1;12,-1;-1;91,m;m,usa,usa,n
ICLR,2020,Mixture Density Networks Find Viewpoint the Dominant Factor for Accurate Spatial Offset Regression,Ali Varamesh;Tinne Tuytelaars,ali.varamesh@kuleuven.be;tinne.tuytelaars@esat.kuleuven.be,3;1;3,,Withdrawn,0,3,,yes,9/25/19,KU Leuven;KU Leuven,Mixture Density Estimation;Spatial Offset Regression;Dense Prediction;Human Pose Estimation;,143;143,45;45,m;f,europe,be,n
ICLR,2020,Learning Adversarial Grammars for Future Prediction,AJ Piergiovanni;Alexander Toshev;Anelia Angelova;Michael Ryoo,ajpiergi@indiana.edu;toshev@google.com;anelia@google.com;mryoo@google.com,1;1,,Withdrawn,0,2,,yes,9/25/19,Indiana University;Google;Google;Google,future prediction;grammar;,64;-1;-1;-1,134;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Dual-Component Deep Domain Adaptation: A New Approach for Cross Project Software Vulnerability Detection,Van Nguyen;Trung Le;Olivier de Vel;Paul Montague;John C Grundy;Dinh Phung,van.nk@monash.edu;trunglm@monash.edu;olivier.devel@dst.defence.gov.au;paul.montague@dst.defence.gov.au;john.grundy@monash.edu;dinh.phung@monash.edu,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Monash University;Monash University;Defence Science and Technology Group;Defence Science and Technology Group;Monash University;Monash University,Domain adaptation;Cyber security;Software vulnerability detection;Machine learning;Deep learning;,92;92;-1;-1;92;92,75;75;-1;-1;75;75,f;m,australasia,au,n
ICLR,2020,FAN: Focused Attention Networks,Chu Wang;Babak Samari;Vladimir Kim;Siddhartha Chaudhuri;Kaleem Siddiqi,chuwang@cim.mcgill.ca;babak@cim.mcgill.ca;vokim@adobe.com;sidch@adobe.com;siddiqi@cim.mcgill.ca,3;3;3,,Withdrawn,0,8,,yes,9/25/19,McGill University;McGill University;Adobe Systems;Adobe Systems;McGill University,Deep Learning;Attention Mechanism;Loss Functions;Computer Vision;Natural Language Processing;,102;102;-1;-1;102,42;42;-1;-1;42,m;m,canada,ca,n
ICLR,2020,State2vec: Off-Policy Successor Feature Approximators,Sephora Madjiheurem;Laura Toni,sephora.madjiheurem.17@ucl.ac.uk;l.toni@ucl.ac.uk,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University College London;University College London,reinforcement learning;meta learning;transfer learning;value function approximation;,52;52,-1;-1,f;f,europe,uk,n
ICLR,2020,Semi-supervised Autoencoding Projective Dependency Parsing,Xiao Zhang;Dan Goldwasser,zhang923@purdue.edu;dgoldwas@purdue.edu,1;3;6,,Withdrawn,0,0,,yes,9/25/19,Purdue University;Purdue University,Dependency Parsing;Semi-supervised Learning;Tractable Inference;Evidence Lowerbound;,24;24,88;88,m;m,usa,usa,n
ICLR,2020,Progressive Knowledge Distillation For Generative Modeling,Yu-Xiong Wang;Adrien Bardes;Ruslan Salakhutdinov;Martial Hebert,yuxiongw@cs.cmu.edu;adrien.bardes@dbmail.com;rsalakhu@cs.cmu.edu;hebert@ri.cmu.edu,3;3;6,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Dbmail;Carnegie Mellon University;Carnegie Mellon University,knowledge distillation;generative modeling;deep learning;,1;-1;1;1,27;-1;27;27,m;m,usa,usa,n
ICLR,2020,Lyceum: An efficient and scalable ecosystem for robot learning,Colin X. Summers;Kendall Lowrey;Aravind Rajeswaran;Emanuel Todorov;Siddhartha Srinivasa,colinxs@cs.washington.edu;klowrey@cs.washington.edu;todorov@cs.washington.edu;siddh@cs.washington.edu;aravraj@cs.washington.edu,1;6;3,,Withdrawn,0,1,,yes,9/25/19,University of Washington;University of Washington;University of Washington;University of Washington;University of Washington,Robotics;RL;Julia;,11;11;11;11;11,26;26;26;26;26,m;m,usa,usa,n
ICLR,2020,Adversarial Attribute Learning by  Exploiting negative correlated attributes,Satoshi Tsutsui;Yanwei Fu;David Crandall,stsutsui@indiana.edu;yanweifu@fudan.edu.cn;djcran@indiana.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Indiana University;Fudan University;Indiana University,,64;73;64,134;109;134,m;m,usa,usa,n
ICLR,2020,VISUALIZING POINT CLOUD CLASSIFIERS BY MORPHING POINT CLOUDS INTO POTATOES,Ziwen Chen;Wenxuan Wu;Zhongang Qi;Fuxin Li,chenziwe@grinnell.edu;wuwen@oregonstate.edu;qiz@oregonstate.edu;lif@oregonstate.edu,3;3;3;6,,Withdrawn,0,4,,yes,9/25/19,Grinnell College;Oregon State University;Oregon State University;Oregon State University,point cloud;3D computer vision;visualization;,-1;79;79;79,-1;373;373;373,f;m,usa,usa,n
ICLR,2020,Learning Multi-Agent Communication Through Structured Attentive Reasoning,Murtaza Rangwala;Ryan Williams,murtazar@vt.edu;rywilli1@vt.edu,3;1;1,,Withdrawn,0,3,,yes,9/25/19,Virginia Tech;Virginia Tech,Multi-Agent;Deep Reinforcement Learning;Communication;,64;64,-1;-1,m;m,usa,usa,n
ICLR,2020,The Power of  Semantic Similarity based Soft-Labeling for Generalized Zero-Shot Learning,Shabnam Daghaghi;Tharun Medini;Anshumali Shrivastava,shabnam.daghaghi@rice.edu;tharun.medini@rice.edu;anshumali@rice.edu,6;1;3;3;3,,Withdrawn,0,5,,yes,9/25/19,Rice University;Rice University;Rice University,Zero Shot Learning;,92;92;92,105;105;105,f;m,australasia,au,n
ICLR,2020,Spline Templated Based Handwriting Generation,Daniel Clothiaux;Ravi Starzl,dclothia@andrew.cmu.edu;rstarzl@cs.cmu.edu,6;3;1,,Withdrawn,0,3,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,,1;1,27;27,m;m,usa,usa,n
ICLR,2020,Improving the robustness of ImageNet classifiers using elements of human visual cognition,Emin Orhan;Brenden Lake,aeminorhan@gmail.com;brenden@nyu.edu,3;1;3,,Withdrawn,0,3,,yes,9/25/19,New York University;New York University,human vision;robustness;large-scale image recognition;,22;22,29;29,m;m,usa,usa,n
ICLR,2020,Going Deeper with Lean Point Networks,Eric-Tuan Le;Iasonas Kokkinos;Niloy J. Mitra,eric-tuan.le.18@ucl.ac.uk;i.kokkinos@cs.ucl.ac.uk;n.mitra@cs.ucl.ac.uk,1;6;3,,Withdrawn,0,3,,yes,9/25/19,University College London;University College London;University College London,point cloud processing;point convolutions;memory-efficient training;deep neural network design;,52;52;52,-1;-1;-1,m;m,europe,uk,n
ICLR,2020,Newton Residual Learning,Grigorios Chrysos;Jiankang Deng;Yannis Panagakis;Stefanos Zafeiriou,g.chrysos@imperial.ac.uk;j.deng16@imperial.ac.uk;i.panagakis@imperial.ac.uk;s.zafeiriou@imperial.ac.uk,8;1;3,,Withdrawn,1,1,,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,Residual learning;Resnet;Newton;,52;52;52;52,10;10;10;10,m;m,europe,uk,n
ICLR,2020,Training-Free Uncertainty Estimation for Neural Networks,Lu Mi;Hao Wang;Yonglong Tian;Nir Shavit,lumi@mit.edu;hoguewang@gmail.com;yonglong@mit.edu;shanir@csail.mit.edu,1;6;6;1,,Withdrawn,0,5,,yes,9/25/19,Massachusetts Institute of Technology;Rutgers University;Massachusetts Institute of Technology;Massachusetts Institute of Technology,uncertainty estimation;training-free;neural network;,5;30;5;5,5;-1;5;5,m;m,usa,usa,n
ICLR,2020,AMUSED: A Multi-Stream Vector Representation Method for Use In Natural Dialogue,Gaurav Kumar;Rishabh Joshi;Jaspreet Singh;Promod Yenigalla,gaurav.k1@samsung.com;rjoshi2@andrew.cmu.edu;jaspreet.ahluwalia@stonybrook.edu;promod.y@samsung.com,6;1;3,,Withdrawn,0,3,,yes,9/25/19,"Samsung;Carnegie Mellon University;State University of New York, Stony Brook;Samsung",Natural Language Processing;Dialogue Systems;Learning Embeddings;Knowledge Graphs;Memory Networks;Graph Convolution Networks;,-1;1;-1;-1,-1;27;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PAD-Nets: Learning Dynamic Receptive Fields via Pixel-Wise Adaptive Dilation,Dongdong Wang;Hao Hu;Jie Yao;Zihang Zou;Liqiang Wang,daniel.wang@knights.ucf.edu;hhu@fxpal.com;17112098@bjtu.edu.cn;zzz@knights.ucf.edu;lwang@cs.ucf.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Central Florida;FX Palo Alto Laboratory;Beijing Jiaotong University;University of Central Florida;University of Central Florida,receptive field;dilated CNN;representation learning;,73;-1;-1;73;73,609;-1;952;609;609,m;m,usa,usa,n
ICLR,2020,Posterior Sampling: Make Reinforcement Learning Sample Efficient Again,Calvin Seward;Urs Bergmann;Roland Vollgraf;Sepp Hochreiter,seward@bioinf.jku.at;urs.bergmann@zalando.de;roland.vollgraf@zalando.de;hochreit@bioinf.jku.at,3;3;6;1,,Withdrawn,0,4,,yes,9/25/19,Johannes Kepler University Linz;Zalando SE;Zalando SE;Johannes Kepler University Linz,Model Based Reinforcement Learning;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Unifying Part Detection And Association For Multi-person Pose Estimation,Rania Briq;Andreas Doering;Juergen Gall,briq@iai.uni-bonn.de;doering@iai.uni-bonn.de;gall@iai.uni-bonn.de,3;6;3,,Withdrawn,0,0,,yes,9/25/19,University of Bonn;University of Bonn;University of Bonn,,143;143;143,106;106;106,f;m,europe,uk,n
ICLR,2020,Slow Thinking Enables Task-Uncertain Lifelong and Sequential Few-Shot Learning,Rosalie Dolor;Hsin-Chi Chu;Shan-Hung Wu,rosalie@ghtinc.com;hcchu@datalab.cs.nthu.edu.tw;shwu@cs.nthu.edu.tw,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Ghtinc;National Tsing Hua University;National Tsing Hua University,lifelong learning;few-shot learning;memory-augmented models;runtime adaptation;,-1;194;194,-1;365;365,u;m,asia,tw,n
ICLR,2020,How Aggressive Can Adversarial Attacks Be: Learning Ordered Top-k Attacks,Zekun Zhang;Tianfu Wu,zzhang56@ncsu.edu;tianfu_wu@ncsu.edu,3;3;1,,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,Adversarial Attack;Adversarial Distillation;Ordered Top-k Attack;,-1;-1,299;299,m;m,NAN,NAN,n
ICLR,2020,PolyGAN: High-Order Polynomial Generators,Grigorios Chrysos;Stylianos Moschoglou;Yannis Panagakis;Stefanos Zafeiriou,g.chrysos@imperial.ac.uk;s.moschoglou@imperial.ac.uk;i.panagakis@imperial.ac.uk;s.zafeiriou@imperial.ac.uk,1;3;1;1,,Withdrawn,0,1,,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,tensor decomposition;Generative Adversarial Networks;polynomial expansion;function approximation;,52;52;52;52,10;10;10;10,m;m,europe,uk,y
ICLR,2020,Generative Multi Source Domain Adaptation,Subhankar Roy;Aliaksandr Siarohin;Enver Sangineto;Moin Nabi;Tassilo Klein;Nicu Sebe;Elisa Ricci,subhankar.roy@unitn.it;aliaksandr.siarohin@unitn.it;enver.sangineto@unitn.it;m.nabi@sap.com;tassilo.klein@sap.com;niculae.sebe@unitn.it;eliricci@fbk.eu,3;3;1,,Withdrawn,0,5,,yes,9/25/19,University of Trento;University of Trento;University of Trento;SAP;SAP;University of Trento;Fondazione Bruno Kessler,Domain Adaptation;Generative Adversarial Networks;,143;143;143;316;316;143;-1,307;307;307;258;258;307;-1,m;f,NAN,NAN,n
ICLR,2020,Semi-Supervised Named Entity Recognition with CRF-VAEs,Thomas Effland;Michael Collins,teffland@cs.columbia.edu;mcollins@cs.columbia.edu;mc3354@columbia.edu,3;3;1,,Withdrawn,1,3,,yes,9/25/19,Columbia University;Columbia University;Columbia University,vae;ner;tagging;crf;nlp;semi-supervised learning;,24;24;24,16;16;16,m;m,usa,usa,n
ICLR,2020,Understanding the (Un)interpretability of Natural Image Distributions Using Generative Models,Ryen Krusinga;Sohil Shah;Matthias Zwicker;Tom Goldstein;David Jacobs,krusinga@cs.umd.edu;sohilas@umd.edu;zwicker@inf.unibe.ch;tom@cs.umd.edu;djacobs@umiacs.umd.edu,1;3;3,,Withdrawn,1,0,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Bern;University of Maryland, College Park;University of Maryland, College Park",GANs;Generative Models;Density Estimation;,12;12;316;12;12,91;91;113;91;91,m;m,usa,usa,n
ICLR,2020,Depth-Recurrent Residual Connections for Super-Resolution of Real-Time Renderings,Erik Franz;Mengyu Chu;R√ºdiger Westermann;Nils Thuerey,franzer@in.tum.de;mengyu.chu@tum.de;westermann@tum.de;nils.thuerey@tum.de,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich,temporal coherence;anti-aliasing;super-resolution;GAN;RNN;real-time rendering;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,The Blessing of Dimensionality: An Empirical Study of Generalization,W. Ronny Huang;Zeyad Emam;Micah Goldblum;Liam Fowl;Justin K. Terry;Furong Huang;Tom Goldstein,wrhuang@umd.edu;zeyad@math.umd.edu;goldblum@math.umd.edu;lfowl@math.umd.edu;jkterry@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",deep neural networks;convolutional neural networks;generalization;visualization;loss landscape;optimization;,12;12;12;12;12;12;12,91;91;91;91;91;91;91,m;m,usa,usa,n
ICLR,2020,Strong Baseline Defenses Against Clean-Label Poisoning Attacks,Neal Gupta;W. Ronny Huang;Liam Fowl;Chen Zhu;Soheil Feizi;Tom Goldstein;John Dickerson,ngupta@cs.umd.edu;wronnyhuang@gmail.com;lhfowl@gmail.com;chenzhu@cs.umd.edu;sfeizi@cs.umd.edu;tomg@cs.umd.edu;john@cs.umd.edu,3;3;1,,Withdrawn,0,3,,yes,9/25/19,"University of Maryland, College Park;Google;;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",poisoning;defenses;robustness;adversarial;ML security;ML safety;,12;-1;-1;12;12;12;12,91;-1;-1;91;91;91;91,m;m,usa,usa,n
ICLR,2020,MetaPoison:   Learning to craft adversarial poisoning examples via meta-learning,W. Ronny Huang;Jonas Geiping;Liam Fowl;Gavin Taylor;Tom Goldstein,wronnyhuang@gmail.com;jonas.geiping@uni-siegen.de;lfowl@math.umd.edu;taylor@usna.edu;tomg@cs.umd.edu,3;3;1,,Withdrawn,0,3,,yes,9/25/19,"Google;University of Siegen;University of Maryland, College Park;University of Arizona;University of Maryland, College Park",Adversarial Examples;Poisoning;Backdoor Attacks;Deep Learning;,-1;316;12;194;12,-1;570;91;103;91,m;m,usa,usa,n
ICLR,2020,Domain-Relevant Embeddings for Question Similarity,Clara McCreery;Namit Katariya;Anitha Kannan;Manish Chablani;Xavier Amatriain,mccreery@stanford.edu;namit@curai.com;anitha@curai.com;manish@curai.com;xavier@curai.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Stanford University;Curai;Curai;Curai;Curai,Question Similarity;Medical Domain;Transfer Learning;Question Entailment;,5;-1;-1;-1;-1,4;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Divide-and-Conquer Adversarial Learning for High-Resolution Image Enhancement,Zhiwu Huang;Danda Pani Paudel;Guanju Li;Jiqing Wu;Radu Timofte;Luc Van Gool,zhiwu.huang@vision.ee.ethz.ch;paudel@vision.ee.ethz.ch;ligua@student.ethz.ch;jwu@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,divide-and-conquer;adversarial learning;image enhancement;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Out-of-distribution Detection without Out-of-distribution Data,Yen-Chang Hsu;Yilin Shen;Hongxia Jin;Zsolt Kira,yenchang.hsu@gatech.edu;yilin.shen@samsung.com;hongxia.jin@samsung.com;zkira@gatech.edu,3;3;1,,Withdrawn,3,1,,yes,9/25/19,Georgia Institute of Technology;Samsung;Samsung;Georgia Institute of Technology,out-of-distribution;deep learning;neural networks;,13;-1;-1;13,38;-1;-1;38,m;m,usa,usa,n
ICLR,2020,Domain Adaptation Through Label Propagation: Learning Clustered and Aligned Features,Changhwa Park;Jaeyoon Yoo;Youngjun Hong;Sungroh Yoon,omega6464@snu.ac.kr;yjy765@snu.ac.kr;youngjun.hong@enerzai.com;sryoon@snu.ac.kr,3;3;3,,Withdrawn,1,10,,yes,9/25/19,Seoul National University;Seoul National University;Enerzai;Seoul National University,domain adaptation;label propagation;manifold regularization;computer vision;,39;39;-1;39,64;64;-1;64,m;m,asia,kr,y
ICLR,2020,ManiGAN: Text-Guided Image Manipulation,Bowen Li;Xiaojuan Qi;Thomas Lukasiewicz;Philip H. S. Torr,bowen.li@cs.ox.ac.uk;xiaojuan.qi@eng.ox.ac.uk;thomas.lukasiewicz@cs.ox.ac.uk;philip.torr@eng.ox.ac.uk,1;6;6,,Withdrawn,0,3,,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,Image Manipulation;Natural Language;Generative Adversarial Networks;,46;46;46;46,1;1;1;1,m;m,europe,uk,n
ICLR,2020,Empirical observations pertaining to learned priors for deep latent variable models,Rogan Morrow;Wei-Chen Chiu,rogan.o.morrow@gmail.com;walon@cs.nctu.edu.tw,3;1;3,,Withdrawn,0,4,,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,,118;118,564;564,m;m,asia,tw,n
ICLR,2020,Variational inference of latent hierarchical dynamical systems in neuroscience: an application to calcium imaging data,Luke Y. Prince;Blake A. Richards,luke.prince@utoronto.ca;blake.richards@mcgill.ca,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Toronto University;McGill University,variational autoencoders;neuroscience;dynamic systems;hierarchical;generative model;calcium imaging;,-1;102,-1;42,m;m,canada,ca,n
ICLR,2020,Characterizing convolutional neural networks with one-pixel signature,Shanjiaoyang Huang;Weiqi Peng;Zhuowen Tu,shh236@ucsd.edu;wep012@ucsd.edu;ztu@ucsd.edu,3;3;3,,Withdrawn,0,3,,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego",Neural Network characterization;backdoor detection;one-pixel signature;,-1;-1;-1,31;31;31,m;m,usa,usa,n
ICLR,2020,Increasing batch size through instance repetition improves generalization,Elad Hoffer;Tal Ben-Nun;Itay Hubara;Niv Giladi;Torsten Hoefler;Daniel Soudry,elad.hoffer@gmail.com;talbn@inf.ethz.ch;itayhubara@gmail.com;giladiniv@campus.technion.ac.il;htor@inf.ethz.ch;daniel.soudry@gmail.com,3;3;6,,Withdrawn,2,3,,yes,9/25/19,"Habana Labs (Intel);Swiss Federal Institute of Technology;;Technion, Technion;Swiss Federal Institute of Technology;Technion, Technion",,-1;-1;-1;27;-1;27,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,"Mix & Match: training convnets with mixed image sizes for improved accuracy, speed and scale resiliency",Elad Hoffer;Berry Weinstein;Itay Hubara;Tal Ben-Nun;Torsten Hoefler;Daniel Soudry,elad.hoffer@gmail.com;bweinstein@habana.ai;itayhubara@gmail.com;talbn@inf.ethz.ch;htor@inf.ethz.ch;daniel.soudry@gmail.com,6;3;3,,Withdrawn,0,3,,yes,9/25/19,"Habana Labs (Intel);Habana Labs (Intel);;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Technion, Technion",convolutional networks;deep learning;,-1;-1;-1;-1;-1;27,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Revisit Knowledge Distillation: a Teacher-free Framework,Li Yuan;Francis EH Tay;Guilin Li;Tao Wang;Jiashi Feng,ylustcnus@gmail.com;mpetayeh@nus.edu.sg;liguilin2@huawei.com;twangnh@gmail.com;elefjia@nus.edu.sg,6;3;3,,Withdrawn,0,5,,yes,9/25/19,National University of Singapore;National University of Singapore;Huawei Technologies Ltd.;;National University of Singapore,Knowledge Distillation;Label Smoothing Regularization;,17;17;-1;-1;17,25;25;-1;-1;25,m;m,asia,sg,n
ICLR,2020,On learning visual odometry errors,Andrea De Maio;Simon Lacroix,andrea.de-maio@laas.fr;simon.lacroix@laas.fr,1;3;3,,Withdrawn,0,4,,yes,9/25/19,LAAS / CNRS;LAAS / CNRS,visual odometry;deep learning in robotics;uncertainty estimation in computer vision;,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,Mitigating Posterior Collapse in Strongly Conditioned Variational Autoencoders,Mohammad Sadegh Aliakbarian;Fatemeh Sadat Saleh;Mathieu Salzmann;Lars Petersson;Stephen Gould,sadegh.aliakbarian@anu.edu.au;fatemehsadat.saleh@anu.edu.au;mathieu.salzmann@epfl.ch;lars.petersson@data61.csiro.au;stephen.gould@anu.edu.au,3;1;1,,Withdrawn,0,4,,yes,9/25/19,Australian National University;Australian National University;Swiss Federal Institute of Technology Lausanne;CSIRO;Australian National University,conditional variational autoencoder;posterior collapse;generative models;,102;102;-1;-1;102,50;50;-1;-1;50,m;m,australasia,au,n
ICLR,2020,Unsupervised  Video-to-Video Translation via Self-Supervised Learning,Kangning Liu;Shuhang Gu;Radu Timofte,kl3141@nyu.edu;shuhang.gu@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch,3;3;3,,Withdrawn,0,4,,yes,9/25/19,New York University;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Self-supervised learning;Unsupervised video-to-video translation;,22;-1;-1,29;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ROBUST SINGLE-STEP ADVERSARIAL TRAINING,B.S. Vivek;R. Venkatesh Babu,svivek@iisc.ac.in;venky@iisc.ac.in,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science,Adversarial Defense;robust deep neural networks;,-1;-1,301;301,m;m,NAN,NAN,n
ICLR,2020,Attentive Weights Generation for Few Shot Learning via Information Maximization,Yiluan Guo;Ngai-Man Cheung,guoyl1990@outlook.com;ngaiman_cheung@sutd.edu.sg,1;6;6,,Withdrawn,0,5,,yes,9/25/19,Singapore University of Technology and Design;Singapore University of Technology and Design,few shot learning;meta learning;information maximization;image classification;,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,DropGrad: Gradient Dropout Regularization for Meta-Learning,Hung-Yu Tseng;Yi-Wen Chen;Yi-Hsuan Tsai;Sifei Liu;Yen-Yu Lin;Ming-Hsuan Yang,htseng6@ucmerced.edu;ychen319@ucmerced.edu;wasidennis@gmail.com;sifeil@nvidia.com;lin@cs.nctu.edu.tw;mhyang@ucmerced.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,University of California at Merced;University of California at Merced;NEC-Labs;NVIDIA;National Chiao Tung University;University of California at Merced,,-1;-1;-1;-1;118;-1,-1;-1;-1;-1;564;-1,m;m,usa,usa,n
ICLR,2020,Hierarchical Image-to-image Translation with Nested Distributions Modeling,Shishi Qiao;Ruiping Wang;Shiguang Shan;Xilin Chen,qiaoshishi14@mails.ucas.ac.cn;wangruiping@ict.ac.cn;sgshan@ict.ac.cn;xlchen@ict.ac.cn,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",,30;30;30;30,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Deep Neural Forests: An Architecture for Tabular Data,Ami Abutbul;Gal Elidan;Liran Katzir;Ran El-Yaniv,amramabutbul@cs.technion.ac.il;elidan@google.com;lirank@google.com;elyaniv@google.com,3;3;3;3,,Withdrawn,0,4,,yes,9/25/19,"Technion, Technion;Google;Google;Google",neural architectures;tabular data;multi-modal data;decision trees;gradient boosting;,27;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Is my Deep Learning Model Learning more than I want it to?,Naveen Panwar;Tarun Tater;Anush Sankaran;Senthil Mani,naveen.panwar@in.ibm.com;anussank@in.ibm.com;taruntater3@gmail.com;sentmani@in.ibm.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,International Business Machines;International Business Machines;;International Business Machines,model trust;disentangled representation;colored mnist;face attribute preservation;new dataset;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Mixing Up Real Samples and Adversarial Samples for Semi-Supervised Learning,Yun Ma;Xudong Mao;Yangbin Chen;Qing Li,mayun371@gmail.com;xudong.xdmao@gmail.com;robinchen2-c@my.cityu.edu.hk;qing-prof.li@polyu.edu.hk,1;3;1,,Withdrawn,0,1,,yes,9/25/19,The Hong Kong Polytechnic University;Xiamen University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,,-1;-1;118;118,-1;579;171;171,m;m,asia,hk,n
ICLR,2020,ADASAMPLE: ADAPTIVE SAMPLING OF HARD POSITIVES FOR DESCRIPTOR LEARNING,Xin-Yu Zhang;Jia-Wang Bian;Le Zhang;Zao-Yi Zheng;Yun Liu;Ming-Ming Cheng;Ian Reid,xinyuzhang@mail.nankai.edu.cn;jiawang.bian@gmail.com;zhangleuestc@gmail.com;roymarssss@gmail.com;nk12csly@mail.nankai.edu.cn;cmm@nankai.edu.cn;ian.reid@adelaide.edu.au,3;6;3,,Withdrawn,0,5,,yes,9/25/19,Nankai University;;;;Nankai University;Nankai University;The University of Adelaide,Descriptor;Correspondence;,-1;-1;-1;-1;-1;-1;102,366;-1;-1;-1;366;366;120,m;m,NAN,NAN,y
ICLR,2020,Better Optimization for Neural Architecture Search with Mixed-Level Reformulation,Chaoyang He;Haishan Ye;Tong Zhang,chaoyang.he@usc.edu;yhs12354123@163.com;tongzhang@tongzhang-ml.org,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Southern California;163;Google,,36;-1;-1,62;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Amharic Light Stemmer,Girma Neshir;Andeas Rauber;and Solomon Atnafu,girma1978@gmail.com;rauber@ifs.tuwien.ac.at;solomon.atnafu@aau.edu.et,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Addis Ababa University;TU Wien Vienna University of Technology;Addis Ababa University,Amharic light Stemmer;Affixes;Amharic Sentiment Classification;,-1;102;-1,-1;360;-1,m;m,NAN,NAN,n
ICLR,2020,Neural Reverse Engineering of Stripped Binaries,Yaniv David;Uri Alon;Eran Yahav,yanivd@cs.technion.ac.il;urialon@cs.technion.ac.il;yahave@cs.technion.ac.il,6;3;3,,Withdrawn,0,7,,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion",,27;27;27,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Cost-Effective Interactive Neural Attention Learning,Jay Heo;Junhyeon Park;Hyewon Jeong;Wuhyun Shin;Kwang Joon Kim;juho Lee;Eunho Yang;Sung Ju Hwang,jayheo@kaist.ac.kr;pjh2941@kaist.ac.kr;jhw162@kaist.ac.kr;wuhyun.shin@kaist.ac.kr;preppie@yuhs.ac.kr;juho@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,3;3;3;1,,Withdrawn,0,4,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Kyung Hee;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,interactive learning;neural process;attention mechanism;interpretable machine learning;influence functions;uncertainty.;,-1;-1;-1;-1;445;-1;-1;-1,110;110;110;110;319;-1;110;110,m;m,NAN,NAN,n
ICLR,2020,Gated Channel Transformation for Visual Recognition,Zongxin Yang;Linchao Zhu;Yu Wu;Yi Yang,zongxin.yang@student.uts.edu.au;zhulinchao7@gmail.com;yu.wu-3@student.uts.edu.au;yi.yang@uts.edu.au,3;1;6,,Withdrawn,0,3,,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,,73;73;73;73,193;193;193;193,m;m,australasia,au,n
ICLR,2020,Masked Translation Model,Arne Nix;Yunsu Kim;Jan Rosendahl;Shahram Khadivi;Hermann Ney,nix@i6.informatik.rwth-aachen.de;kim@i6.informatik.rwth-aachen.de;rosendahl@i6.informatik.rwth-aachen.de;skhadivi@ebay.com;ney@i6.informatik.rwth-aachen.de,3;3;3,,Withdrawn,1,1,,yes,9/25/19,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;eBay;RWTH Aachen University,Neural Machine Translation;Non-Autoregressive Decoding;Deep Learning;Transformer;,118;118;118;-1;118,98;98;98;-1;98,m;m,NAN,NAN,n
ICLR,2020,Target-directed Atomic Importance Estimation via Reverse Self-attention,Gyoung S. Na;Hyun Woo Kim,ngs0726@gmail.com;ahwk@krict.re.kr,1;1;3,,Withdrawn,0,3,,yes,9/25/19,POSTECH;POSTECH,Scientific Application;Knowledge Discovery;Graph Neural Network;Attention Mechanism;,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,ProxNet: End-to-End Learning of  Structured Representation by Proximal Mapping,Mao Li;Yingyi Ma;Xinhua Zhang,mli206@uic.edu;yma36@uic.edu;zhangx@uic.edu,3;1;3,,Withdrawn,0,2,,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",representation learning;multiview learning;,-1;-1;-1,-1;-1;-1,f;m,usa,usa,n
ICLR,2020,Measure by Measure: Automatic Music Composition with Traditional Western Music Notation,Yujia Yan;Zhiyao Duan,yujia.yan.w@gmail.com;zhiyao.duan@rochester.edu,1;1;1,,Withdrawn,0,1,,yes,9/25/19,University of Rochester;University of Rochester,,102;102,173;173,u;m,europe,uk,pdf miss
ICLR,2020,When Do Variational Autoencoders Know  What They Don't Know?,Bin Dai;David Wipf,daib13@mails.tsinghua.edu.cn;davidwipf@gmail.com,8;6;8,,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University, Tsinghua University;Amazon",variational autoencoder;generative model;,4;-1,23;-1,m;m,NAN,NAN,y
ICLR,2020,Irrationality can help reward inference,Lawrence Chan;Andrew Critch;Anca Dragan,chanlaw@berkeley.edu;critch@berkeley.edu;anca@berkeley.edu,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,preference inference;inverse reinforcement learning;reward inference;irrationality;,-1;-1;-1,13;13;13,m;f,usa,usa,n
ICLR,2020,Teaching GAN to generate per-pixel annotation,Danil Galeev;Konstantin Sofiyuk;Danila Rukhovich;Anton Konushin;Mikhail Romanov,denemmy@gmail.com;ksofiyuk@gmail.com;danrukh@gmail.com;a.konushin@samsung.com;m.romanov@samsung.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Samsung;Samsung;Samsung;Samsung;Samsung,GAN;unsupervised representation learning;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,One Generation Knowledge Distillation by Utilizing Peer Samples,Xingjian Li;Haozhe An;Haoyi Xiong;Jun Huan;Dejing Dou;Chengzhong Xu,1762778193@qq.com;haozhe.an@yahoo.com,1;3;3,,Withdrawn,0,3,,yes,9/25/19,"Baidu;University of Maryland, College Park",,-1;12,-1;91,m;m,usa,usa,n
ICLR,2020,Guided variational autoencoder for disentanglement learning,Zheng Ding;Yifan Xu;Weijian Xu;Yang Yang;Max Welling;Zhuowen Tu,dingz16@mails.tsinghua.edu.cn;yix081@ucsd.edu;wex041@eng.ucsd.edu;yyangy@qti.qualcomm.com;welling.max@gmail.com;ztu@ucsd.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University, Tsinghua University;University of California, San Diego;University of California, San Diego;Qualcomm Inc, QualComm;University of California, Irvine;University of California, San Diego",variational autoencoder;representation learning;disentanglement learning;,4;-1;-1;-1;-1;-1,23;31;31;-1;96;31,m;m,usa,usa,n
ICLR,2020,Learning Sparsity and Quantization Jointly and Automatically for Neural Network Compression via Constrained Optimization,Haichuan Yang;Shupeng Gui;Yuhao Zhu;Ji Liu,h.yang@rochester.edu;sgui2@ur.rochester.edu;yzhu@rochester.edu;ji.liu.uwisc@gmail.com,3;6;3,,Withdrawn,0,0,,yes,9/25/19,University of Rochester;University of Rochester;University of Rochester;Kwai Inc.,model compression;pruning;quantization;autoML;,102;102;102;-1,173;173;173;-1,m;m,asia,in,pdf miss
ICLR,2020,FairFace: A Novel Face Attribute Dataset for Bias Measurement and Mitigation,Kimmo K√§rkk√§inen;Jungseock Joo,kimmo@cs.ucla.edu;jjoo@comm.ucla.edu,3;1;1,,Withdrawn,0,3,,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",dataset bias;face attribute recognition;bias measurement;,-1;-1,17;17,m;m,usa,usa,n
ICLR,2020,Pruning Depthwise Separable Convolutions for Extra Efficiency Gain of Lightweight Models,Cheng-Hao Tu;Jia-Hong Lee;Yi-Ming Chan;Chu-Song Chen,andytu28@iis.sinica.edu.tw;honghenry.lee@iis.sinica.edu.tw;yiming@iis.sinica.edu.tw;song@iis.sinica.edu.tw,3;3;3,,Withdrawn,1,0,,yes,9/25/19,Academia Sinica;Academia Sinica;Academia Sinica;Academia Sinica,Deep Learning;Network Pruning;Lightweight CNN;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Benchmarking Adversarial Robustness,Yinpeng Dong;Qi-An Fu;Xiao Yang;Tianyu Pang;Hang Su;Jun Zhu,dyp17@mails.tsinghua.edu.cn;fqa19@mails.tsinghua.edu.cn;yangxiao19@mails.tsinghua.edu.cn;pty17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,1;3;1,,Withdrawn,0,0,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Adversarial Example;Robustness;Benchmark;,4;4;4;4;4;4,23;23;23;23;23;23,m;m,NAN,NAN,n
ICLR,2020,Unsupervised Learning from Video with Deep Neural Embeddings,Chengxu Zhuang;Tianwei She;Alex Andonian;Daniel Yamins,chengxuz@stanford.edu;shetw@stanford.edu;aandonia@mit.edu;yamins@stanford.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Stanford University;Stanford University;Massachusetts Institute of Technology;Stanford University,Unsupervised learning;action recognition;video learning;deep neural networks;,5;5;5;5,4;4;5;4,m;m,usa,usa,n
ICLR,2020,Towards Unifying Neural Architecture Space Exploration and Generalization,Kartikeya Bhardwaj;Radu Marculescu,bhardwajkartikeya@gmail.com;radum@cmu.edu,3;1,,Withdrawn,0,0,,yes,9/25/19,arm;Carnegie Mellon University,Neural Architecture Space Exploration;Generalization;Model Compression;Network Science;Convolutional Neural Networks;,59;1,289;27,m;m,usa,usa,y
ICLR,2020,IEG: Robust neural net training with severe label noises,Zizhao Zhang;Han Zhang;Sercan Arik;Honglak Lee;Tomas Pfister,zizhaoz@google.com;zhanghan@google.com;soarik@google.com;honglak@google.com;tpfister@google.com,1;3;3,,Withdrawn,0,6,,yes,9/25/19,Google;Google;Google;Google;Google,Robust deep learning;label noise;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Stochastic Geodesic Optimization for Neural Networks,Zana Rashidi;Aijun An;Xiaogang Wang,zrashidi@eecs.yorku.ca;aan@cse.yorku.ca;stevenw@mathstat.yorku.ca,1;3;3,,Withdrawn,0,1,,yes,9/25/19,York University;York University;York University,Neural Network Optimization;Geodesic Optimization;Momentum;,194;194;194,416;416;416,m;m,asia,kr,n
ICLR,2020,WEEGNET: an wavelet based Convnet for Brain-computer interfaces,Mouad Riyad;Mohammed Khalil;Abdellah Adib,riyadmouad1@gmail.com;medkhalil87@gmail.com;adib@fstm.ma,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Faculty of Sciences and Technologies -Mohammedia;;Faculty of Sciences and Technologies -Mohammedia,BCI;EEG;Convnet;DWT;WEEGNET;,-1;-1;-1,-1;-1;-1,m;m,asia,in,n
ICLR,2020,Classification as Decoder: Trading Flexibility for Control in Multi Domain Dialogue,Sam Shleifer;Manish Chablani;Namit Katariya;Anitha Kannan;Xavier Amatriain,sshleifer@gmail.com;manish@curai.com;namit@curai.com;anitha@curai.com;xavier@curai.com,1;3;1,,Withdrawn,0,3,,yes,9/25/19,Stanford University;Curai;Curai;Curai;Curai,NLP;dialogue;chatbot;weak supervision;language model;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Anomaly Detection and Localization in Images using Guided Attention,Shashanka Venkataramanan;Rajat Vikram Singh;Kuan-Chuan Peng,shashankv@knights.ucf.edu;singh.rajat@siemens.com;kp388@cornell.edu,6;3;3,,Withdrawn,0,5,,yes,9/25/19,University of Central Florida;Siemens Corporate Research;Cornell University,,73;-1;7,609;-1;19,m;m,usa,usa,n
ICLR,2020,In-training Matrix Factorization for Parameter-frugal Neural Machine Translation,Zachary Kaden;Teven Le Scao;Raphael Olivier,kadenzack@gmail.com;tlescao@andrew.cmu.edu;rolivier@cs.cmu.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,natural language processing;neural machine translation;matrix factorization;model compression;,-1;1;1,-1;27;27,m;m,usa,usa,n
ICLR,2020,Dataset Distillation,Tongzhou Wang;Jun-Yan Zhu;Antonio Torralba;Alexei A. Efros,tongzhou.wang.1994@gmail.com;junyanz@mit.edu;torralba@mit.edu;efros@eecs.berkeley.edu,6;3;3,,Withdrawn,2,11,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley,knowledge distillation;deep learning;few-shot learning;continual learning;,5;5;5;-1,5;5;5;13,m;m,usa,usa,n
ICLR,2020,Spatial Information is Overrated for Image Classification,Yue Fan;Yongqin Xian;Max Maria Losch;Bernt Schiele,yfan@mpi-inf.mpg.de;yxian@mpi-inf.mpg.de;mlosch@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de,6;1;1,,Withdrawn,0,1,,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Max-Planck Institute,,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modelling,Yahui Liu;Marco De Nadai;Jian Yao;Nicu Sebe;Bruno Lepri;Xavier Alameda-Pineda,yahui.liu@unitn.it;denadai@fbk.eu;jian.yao@whu.edu.cn;niculae.sebe@unitn.it;lepri@fbk.eu;xavier.alameda-pineda@inria.fr,6;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Trento;Fondazione Bruno Kessler;Wuhan University;University of Trento;Fondazione Bruno Kessler;INRIA,GANs;image-to-image translation;multi-domain image translation;multi-modal image translation;Gaussian Mixture Model;,143;-1;194;143;-1;-1,307;-1;354;307;-1;-1,m;m,europe,gr,n
ICLR,2020,Information lies in the eye of the beholder: The effect of representations on observed mutual information,Julian Zilly;Lorenz Hetzel;Andrea Censi;Emilio Frazzoli,jzilly@ethz.ch;hetzell@ethz.ch;acensi@ethz.ch;emilio.frazzoli@idsc.mavt.ethz.ch,3;1;1,,Withdrawn,0,2,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep learning;Information theory;representation;coding;mutual information estimation;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Quantitatively Disentangling and Understanding Part Information in CNNs,Quanshi Zhang;Yu Yang;Haotian Ma;Ying Nian Wu,zqs1022@sjtu.edu.cn;yy19970901@ucla.edu;11612807@mail.sustc.edu.cn;ywu@stat.ucla.edu,6;3;3,,Withdrawn,0,0,,yes,9/25/19,"Shanghai Jiao Tong University;University of California, Los Angeles;University of Science and Technology of China;University of California, Los Angeles",Convolutional Neural Networks;Interpretability;Deep Learning;,30;-1;-1;-1,157;17;80;17,m;m,usa,usa,n
ICLR,2020,Graph-based motion planning networks,Tai Hoang;Ngo Anh Vien,thobotics@gmail.com;v.ngo@qub.ac.uk,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Queen's University Belfast,motion planning;reinforcement learning;graph-based planning;transfer-planning;zero-shot planning;,-1;248,-1;204,m;m,europe,uk,n
ICLR,2020,Bridging ELBO objective and MMD,Talip Ucar,pilatracu@gmail.com,1;1;1,,Withdrawn,0,3,,yes,9/25/19,University College London,ELBO;MMD;VAE;Posterior collapse;,52,-1,m,europe,uk,n
ICLR,2020,Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom,Juan Luis Gonzalez Bello;Munchurl Kim,juanluisgb@kaist.ac.kr;mkimee@kaist.ac.kr,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,Deep learning;novel view synthesis;Deep 3D Zoom;,-1;-1,110;110,m;m,NAN,NAN,n
ICLR,2020,Through the Lens of Neural Network: Analyzing Neural QA Models via Quantized Latent Representation,Tsung-Han Wu;Chun-Cheng Hsieh;Yen-Hao Chen;Hung-yi Lee,ynnekuw@gmail.com;syasyunjyo@gmail.com;r07921112@ntu.edu.tw;hungyilee@ntu.edu.tw,3;3;1,,Withdrawn,0,0,,yes,9/25/19,National Taiwan University;;Nanyang Technological University;Nanyang Technological University,Question Answering;Discrete Representation;Vector Quantization;,-1;-1;43;43,-1;-1;49;49,m;m,asia,sg,n
ICLR,2020,Hierarchical Complement Objective Training,Hao-Yun Chen;Li-Huang Tsai;Shih-Chieh Chang;Jia-Yu Pan;Yu-Ting Chen;Wei Wei;Da-Cheng Juan,haoyunchen@gapp.nthu.edu.tw;lihuangtsai@gapp.nthu.edu.tw;scchang@cs.nthu.edu.tw;jypan@google.com;yutingchen@google.com;wewei@google.com;dacheng@google.com,3;3;3,,Withdrawn,0,3,,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Google;Google;Google;Google,category hierarchy;optimization;entropy;image recognition;semantic segmentation;deep learning;,194;194;194;-1;-1;-1;-1,365;365;365;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Anomalous Pattern Detection in Activations and Reconstruction Error of Autoencoders,Celia Cintas;Skyler Speakman;Victor Akinwande;Srihari Sridharan;William Ogallo;Edward McFowland III,celia.cintas@ibm.com;skyler@ke.ibm.com;victor.akinwande1@ibm.com;sriharis.sridharan@ke.ibm.com;william.ogallo@ibm.com;mcfowland@umn.edu,3;1;1,,Withdrawn,0,3,,yes,9/25/19,"International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Minnesota, Minneapolis",unsupervised anomaly detection;adversarial attacks;autoencoders;subset scanning;,-1;-1;-1;-1;-1;73,-1;-1;-1;-1;-1;79,f;m,NAN,NAN,n
ICLR,2020,Dynamically Balanced Value Estimates for Actor-Critic Methods,Nicolai Dorka;Joschka Boedecker;Wolfram Burgard,dorka@cs.uni-freiburg.de;jboedeck@cs.uni-freiburg.de;burgard@cs.uni-freiburg.de,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Universit√§t Freiburg;Universit√§t Freiburg;Universit√§t Freiburg,Reinforcement Learning;Actor-Critic;Continuous Control;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Incorporating Perceptual Prior to Improve Model's Adversarial Robustness,B.S. Vivek;Arya Baburaj;Ashutosh B Sathe;R. Venkatesh Babu,svivek@iisc.ac.in;aryababuraj@iisc.ac.in;satheab16.mech@coep.ac.in;venky@iisc.ac.in,1;1;1,,Withdrawn,0,5,,yes,9/25/19,"Indian Institute of Science;Indian Institute of Science;College of Engineering, Pune;Indian Institute of Science",Representation learining;adversarial defense;robust neural networks;,-1;-1;-1;-1,301;301;-1;301,m;m,NAN,NAN,n
ICLR,2020,MultiGrain: a unified image embedding for classes and instances,Maxim Berman;Herv√© J√©gou;Andrea Vedaldi;Iasonas Kokkinos;Matthijs Douze,maxim.berman@esat.kuleuven.be;rvj@fb.com;vedaldi@fb.com;iasonas.kokkinos@gmail.com;matthijs@fb.com,3;3;3,,Withdrawn,0,4,,yes,9/25/19,KU Leuven;Facebook;Facebook;Ariel AI;Facebook,classification;image retrieval;deep learning;data augmentation;,143;-1;-1;-1;-1,45;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,A Simple Geometric Proof for the Benefit of Depth in ReLU Networks,Asaf Amrami;Yoav Goldberg,asaf.amrami@gmail.com;yoav.goldberg@gmail.com,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Bar Ilan University;Bar-Ilan University,,-1;102,-1;513,m;m,europe,il,y
ICLR,2020,How does Lipschitz Regularization Influence GAN Training?,Yipeng Qin;Niloy Mitra;Peter Wonka,qinyipeng1991@gmail.com;niloym@gmail.com;pwonka@gmail.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Cardiff University;University College London;KAUST,,168;52;102,196;-1;-1,m;m,europe,gr,y
ICLR,2020,SIMULTANEOUS ATTRIBUTED NETWORK EMBEDDING AND CLUSTERING,Lazhar labiod;Mohamed Nadif,lazhar.labiod@parisdescartes.fr;mohamed.nadif@parisdescartes.fr,1;1;1,,Withdrawn,0,0,,yes,9/25/19,University Paris Descartes;University Paris Descartes,Attributed network;Embedding;clustering;matrix decomposition;spectral rotation;,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,Tree-structured Attention Module for Image Classification,Gyungin Shin;Sung-Ho Bae;and Yong-Jae Moon,gishin@khu.ac.kr;shbae@khu.ac.kr;moonyj@khu.ac.kr,3;3;3,,Withdrawn,0,3,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,inter-channel relationship;attention module;point-wise group convolution;,445;445;445,319;319;319,m;m,asia,kr,n
ICLR,2020,Task Level Data Augmentation for Meta-Learning,Jialin Liu;Fei Chao;Chih-Min Lin,31520171153232@stu.xmu.edu.cn;fchao@xmu.edu.cn;cml@saturn.yzu.edu.tw,3;3;6,,Withdrawn,0,1,,yes,9/25/19,Xiamen University;Xiamen University;National Tsing Hua University,Meta-learning;few-shot learning;data augmentation;,-1;-1;194,579;579;365,f;m,asia,tw,n
ICLR,2020,Learning Semantic Correspondences from Noisy Data-text Pairs by Local-to-Global Alignments,Feng Nie;Jinpeng Wang;Rong Pan;Chin-Yew Lin,fengniesysu@gmail.com;jinpwa@microsoft.com;panr@sysu.edu.cn;cyl@microsoft.com,3;8,,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft,textual grounding;data-to-text generation;multi-instance learning;conditional random fields;,-1;-1;-1;-1,-1;-1;299;-1,u;m,NAN,NAN,n
ICLR,2020,VideoEpitoma: Efficient Recognition of Long-range Actions,Noureldien Hussein;Babak Ehteshami Bejnordi;Mihir Jain,nhussein@uva.nl;behtesha@qti.qualcomm.com;mijain@qti.qualcomm.com,1;3;1,,Withdrawn,0,3,,yes,9/25/19,"University of Amsterdam;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",Computer Vision;Action Recognition;Video Understanding;Efficient CNNs;,143;-1;-1,62;-1;-1,m;m,NAN,NAN,n
ICLR,2020,StacNAS: Towards Stable and Consistent  Optimization for Differentiable  Neural Architecture Search,Li Guilin;Zhang Xing;Wang Zitong;Li Zhenguo;Zhang Tong,hiliguilin@gmail.com;zhang.xing1@huawei.com;ztwang@math.cuhk.edu.hk;li.zhenguo@huawei.com;tongzhang@tongzhang-ml.org,6;3;3,,Withdrawn,1,3,,yes,9/25/19,National University of Singapore;Huawei Technologies Ltd.;The Chinese University of Hong Kong;Huawei Technologies Ltd.;Google,Differentiable  Neural Architecture Search;,-1;-1;316;-1;-1,-1;-1;35;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Construction of Macro Actions for Deep Reinforcement Learning,"Yi-Hsiang Chang;Kuan-Yu	Chang;Henry Kuo;Chun-Yi Lee",shawn420@gapp.nthu.edu.tw;kychang@elsa.cs.nthu.edu.tw;hkuo@college.harvard.edu;cylee@gapp.nthu.edu.tw,1;1;3,,Withdrawn,0,1,,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;Harvard University;National Tsing Hua University,macro action;genetic algorithm;deep reinforcement learning;,194;194;52;194,365;365;7;365,u;m,asia,tw,n
ICLR,2020,Towards Understanding Generalization in Gradient-Based Meta-Learning,Simon Guiroy;Vikas Verma;Christopher J. Pal,simon.guiroy@umontreal.ca;vikasverma.iitm@gmail.com;christopher.pal@polymtl.ca,3;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Montreal;Aalto University;Polytechnique Montreal,meta-learning;objective landscapes;,118;118;316,85;182;-1,m;m,canada,ca,n
ICLR,2020,Structural Multi-agent Learning,Kaiqian Han;Liangliang Ren;Jiwen Lu;Jie Zhou,hkg16@mails.tsinghua.edu.cn;renll16@mails.tsinghua.edu.cn;lujiwen@tsinghua.edu.cn;jzhou@tsinghua.edu.cn,1;3;6,,Withdrawn,0,4,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Multi-agent Learning;Communication;Graph Network;,4;4;4;4,23;23;23;23,m;m,NAN,NAN,n
ICLR,2020,AdamT: A Stochastic Optimization with Trend Correction Scheme,Bingxin Zhou;Xuebin Zheng;Junbin Gao,bzho3923@uni.sydney.edu.au;xzhe2914@uni.sydney.edu.au;junbin.gao@sydney.edu.au,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney,Optimization;ADAM;Stochastic Gradient Descent;Deep Learning;,64;64;64,60;60;60,m;m,europe,uk,y
ICLR,2020,Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Imbalanced Data,Utkarsh Ojha;Krishna Kumar Singh;Cho-Jui Hsieh;Yong Jae Lee,uojha@ucdavis.edu;krsingh@ucdavis.edu;chohsieh@cs.ucla.edu;yongjaelee@ucdavis.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Davis;University of California, Davis;University of California, Los Angeles;University of California, Davis",Generative Adversarial Networks;Imbalanced data;Data Augmentation;,-1;-1;-1;-1,55;55;17;55,m;m,usa,usa,n
ICLR,2020,Generalizing Deep Multi-task Learning with Heterogeneous Structured Networks,Ming Hou;Xinqi Chen;Shifeng Huang;Shengli Xie;Guoxu Zhou;Qibin Zhao,ming.hou@riken.jp;xinqicham@gmail.com;sfengmmin@163.com;shlxie@gdut.edu.cn;gx.zhou@gdut.edu.cn;qibin.zhao@riken.jp,3;1;3,,Withdrawn,0,0,,yes,9/25/19,RIKEN;;163;South China University of Technology;South China University of Technology;RIKEN,deep multi-task learning;heterogenous network architectures;tensor representation;,-1;-1;-1;-1;-1;-1,-1;-1;-1;501;501;-1,m;m,NAN,NAN,n
ICLR,2020,Rethinking Data Augmentation: Self-Supervision and Self-Distillation,Hankook Lee;Sung Ju Hwang;Jinwoo Shin,hankook.lee@kaist.ac.kr;sjhwang82@kaist.ac.kr;jinwoos@kaist.ac.kr,1;3;3,,Withdrawn,0,2,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,self-supervision;data augmentation;,-1;-1;-1,110;110;110,m;m,NAN,NAN,n
ICLR,2020,Dynamical Clustering of Time Series Data Using Multi-Decoder RNN Autoencoder,Daisuke Kaji;Kazuho Watanabe;Masahiro Kobayashi,daisuke.kaji.j3a@jp.denso.com;wkazuho@cs.tut.ac.jp;kobayashi@lisl.cs.tut.ac.jp,3;3;1,,Withdrawn,0,3,,yes,9/25/19,Denso Corporation;Meiji University;Meiji University,Dynamical system;Recurrent neural network;Autoencoder;Variational Bayes;Clustering;Time series data;Driving data;,-1;-1;-1,-1;1323;1323,u;u,asia,jp,n
ICLR,2020,Regularizing Predictions via Class-wise Self-knowledge Distillation,Sukmin Yun;Jongjin Park;Kimin Lee;Jinwoo Shin,sukmin.yun@kaist.ac.kr;jongjin.park@kaist.ac.kr;kiminlee@kaist.ac.kr;jinwoos@kaist.ac.kr,3;1;6,,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,regularization;knowledge distillation;,-1;-1;-1;-1,110;110;110;110,m;m,NAN,NAN,n
ICLR,2020,Imbalanced Classification via Adversarial Minority Over-sampling,Jaehyung Kim;Jongheon Jeong;Jinwoo Shin,jaehyungkim@kaist.ac.kr;jongheonj@kaist.ac.kr;jinwoos@kaist.ac.kr,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,imbalanced classification;adversarial examples;,-1;-1;-1,110;110;110,m;m,NAN,NAN,n
ICLR,2020,Neuron ranking - an informed way to compress convolutional neural networks,Kamil Adamczewski;Mijung Park,kamil.m.adamczewski@gmail.com;mijung.park@tuebingen.mpg.de,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Max-Planck Institute;Max-Planck Institute,convolutional neural network;compression;shapley value;importance switch;variational inference;interpretability;,-1;-1,-1;-1,m;f,NAN,NAN,n
ICLR,2020,Compressing Deep Neural Networks With Learnable Regularization,Yoojin Choi;Mostafa El-Khamy;Jungwon Lee,yoojin.c@samsung.com;mostafa.e@samsung.com;jungwon2.lee@samsung.com,3;6;3;3,,Withdrawn,0,1,,yes,9/25/19,Samsung;Samsung;Samsung,,-1;-1;-1,-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Image Classification Through Top-Down Image Pyramid Traversal,Athanasios Papadopoulos;Pawel Korus;Nasir Memon,ap4094@nyu.edu;pkorus@nyu.edu;memon@nyu.edu,3;1;3,,Withdrawn,0,4,,yes,9/25/19,New York University;New York University;New York University,image classification;multi-scale processing;attention;,22;22;22,29;29;29,m;m,usa,usa,n
ICLR,2020,PAC-Bayes Few-shot Meta-learning with Implicit Learning of Model Prior Distribution,Cuong Nguyen;Thanh-Toan Do;Gustavo Carneiro,cuong.nguyen@adelaide.edu.au;thanh-toan.do@liverpool.ac.uk;gustavo.carneiro@adelaide.edu.au,6;1;1,,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;University of Liverpool;The University of Adelaide,meta-learning;few-shot learning;,102;118;102,120;165;120,m;m,NAN,NAN,y
ICLR,2020,CRAP: Semi-supervised Learning via Conditional Rotation Angle Prediction,Hai-Ming Xu;Lingqiao Liu,hai-ming.xu@adelaide.edu.au;lingqiao.liu@adelaide.edu.au,3;3;3,,Withdrawn,0,2,,yes,9/25/19,The University of Adelaide;The University of Adelaide,Semi-supervised Learning;Self-supervised Learning;,102;102,120;120,m;m,NAN,NAN,n
ICLR,2020,A novel text representation which enables image classifiers to perform text classification,Stephen M. Petrie;T'Mir D. Julius,spetrie@swin.edu.au;tdjempire@gmail.com,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Swinburne University of Technology;University of Melbourne,supervised representation learning;natural language processing;image pattern recognition;named entity disambiguation;,-1;-1,389;-1,m;f,asia,in,n
ICLR,2020,FACE SUPER-RESOLUTION GUIDED BY 3D FACIAL PRIORS,xiaobin hu;wenqi ren;jiaolong yang;xiaochun cao;Xiaoming Li;John LaMaster;Bjoern Menze;wei liu,xiaobin.hu@tum.de;rwq.renwenqi@gmail.com;jiaoyan@microsoft.com;caoxiaochun@iie.ac.cn;hit.xmshr@gmail.com;jlamaste@gmail.com;bjoern.menze@tum.de;wl2223@columbia.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Technical University Munich;Institute of information engineering, CAS;Microsoft;Institute of information engineering, CAS;;Technical University Munich;Technical University Munich;Columbia University",Super-resolution;3D Facial priors;Spatial Attention Mechanism;,-1;-1;-1;-1;-1;-1;-1;24,-1;-1;-1;-1;-1;-1;-1;16,m;m,usa,usa,n
ICLR,2020,Doubly Normalized Attention,Nan Ding;Xinjie Fan;Zhenzhong Lan;Dale Schuurmans;Radu Soricut,dingnan@google.com;fan.xinjiebuaa@gmail.com;lanzhzh@google.com;schuurmans@google.com;rsoricut@google.com,3;1;1,,Withdrawn,0,3,,yes,9/25/19,Google;;Google;Google;Google,,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Correctness Verification of Neural Network,Yichen Yang;Martin Rinard,yicheny@csail.mit.edu;rinard@csail.mit.edu,1;3;1,,Withdrawn,0,3,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,Neural network verification;safety;reliability;,5;5,5;5,m;m,usa,usa,y
ICLR,2020,Diversely Stale Parameters for Efficient Training of Deep Convolutional Networks,An Xu;Zhouyuan Huo;Heng Huang,an.xu@pitt.edu;zhouyuan.huo@pitt.edu;heng.huang@pitt.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Pittsburgh;University of Pittsburgh;University of Pittsburgh,Layer-wise Staleness;Parallel Training;Convolutional Neural Networks;,79;79;79,113;113;113,m;m,usa,usa,pdf miss
ICLR,2020,WHAT DATA IS USEFUL FOR MY DATA: TRANSFER LEARNING WITH A MIXTURE OF SELF-SUPERVISED EXPERTS,Xi Yan;David Acuna;Sanja Fidler,xi.yan@mail.utoronto.ca;davidj@cs.toronto.edu;fidler@cs.toronto.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Toronto University;University of Toronto;University of Toronto,,-1;18;18,-1;18;18,f;f,canada,ca,n
ICLR,2020,Classification Logit Two-sample Testing by Neural Networks,Xiuyuan Cheng;Alexander Cloninger,xiuyuan.cheng@duke.edu;acloninger@ucsd.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"Duke University;University of California, San Diego",,46;-1,20;31,m;m,usa,usa,y
ICLR,2020,Frontal low-rank random tensors for high-order feature representation,Yan Zhang;Krikamol Muandet;Qianli Ma;Heiko Neumann;Siyu Tang,yan.zhang@tuebingen.mpg.de;krikamol@tuebingen.mpg.de;qianli.ma@tue.mpg.de;heiko.neumann@uni-ulm.de;stang@tuebingen.mpg.de,6;3;3;3,,Withdrawn,0,1,,yes,9/25/19,Max-Planck Institute;Max-Planck Institute;Max-Planck Institute;Ulm University;Max-Planck Institute,,-1;-1;-1;-1;-1,-1;-1;-1;141;-1,f;f,NAN,NAN,y
ICLR,2020,Interpretability Evaluation Framework for Deep Neural Networks,Junxiang Wang;Liang Zhao;Yanfang Ye and Houman Homayoun,jwang40@gmu.edu;lzhao9@gmu.edu;yanfang.ye@mail.wvu.edu;hhomayou@gmu.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,George Mason University;George Mason University;West Virginia University;George Mason University,Interpretability Evaluation;Deep Neural Networks;Alternating Direction Method of Multipliers;,85;85;316;85,282;282;601;282,m;m,usa,usa,pdf miss
ICLR,2020,CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement Learning problem,Arpan Kusari,arpan.kusari@gmail.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,0,inverse reinforcement learning;conditional variational auto-encoder;wasserstein;,,,m,NAN,NAN,n
ICLR,2020,"Study of a Simple, Expressive and Consistent Graph Feature Representation",Pineau Edouard,pineau.edouard@gmail.com,1;3;3,,Withdrawn,0,1,,yes,9/25/19,0,Graph representation;Spectral;Graph perturbation;,,,m,NAN,NAN,y
ICLR,2020,Input Alignment along Chaotic directions increases Stability in Recurrent Neural Networks,Priyadarshini Panda;Kaushik Roy,priya.panda@yale.edu;kaushik@purdue.edu,6;1;1,,Withdrawn,0,0,,yes,9/25/19,Yale University;Purdue University,Reservoir Models;Stability;Chaos;Input Alignment;Mean Field Analysis;,73;24,8;88,f;m,usa,usa,n
ICLR,2020,All Neural Networks are Created Equal,Guy Hacohen;Leshem Choshen;Daphna Weinshall,guy.hacohen@mail.huji.ac.il;leshem.choshen@mail.huji.ac.il;daphna@cs.huji.ac.il,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,deep learning;empirical machine learning;learning dynamics;curriculum;consistency score;consensus score;network comparison;,85;85;85,216;216;216,m;f,europe,il,n
ICLR,2020,Hyperbolic Image Embeddings,Valentin Khrulkov;Leyla Mirvakhabova;Evgeniya Ustinova;Ivan Oseledets;Victor Lempitsky,khrulkov.v@gmail.com;leyla.mirvakhabova@skoltech.ru;evgeniya.ustinova@skoltech.ru;i.oseledets@skoltech.ru;v.lempitsky@samsung.com,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Yandex;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Samsung,hyperbolic;poincare;image embeddings;few show learning;reidentification;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Instant Quantization of Neural Networks using Monte Carlo Methods,Gon√ßalo Mordido;Matthijs Van Keirsbilck;Alexander Keller,goncalo.mordido@hpi.de;matthijsv@nvidia.com;akeller@nvidia.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Hasso Plattner Institute;NVIDIA;NVIDIA,monte carlo;importance sampling;network quantization;,143;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Gating Revisited: Deep Multi-layer RNNs That Can Be Trained,Mehmet Ozgur Turkoglu;Stefano D'Aronco;Jan Dirk Wegner;Konrad Schindler,ozgur.turkoglu@geod.baug.ethz.ch;stefano.daronco@geod.baug.ethz.ch;jan.wegner@geod.baug.ethz.ch;schindler@geod.baug.ethz.ch,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,Deep RNN;Multi-layer RNN;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ILS-SUMM: Iterated Local Search for Unsupervised Video Summarization,Yair Shemer;Daniel Rotman;Nahum Shimkin,sy@campus.technion.ac.il;danieln@il.ibm.com;shimkin@ee.technion.ac.il,1;3;6,,Withdrawn,0,1,,yes,9/25/19,"Technion, Technion;International Business Machines;Technion, Technion",,27;-1;27,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Quadratic GCN for graph classification,Omer Nagar;Yoram Louzoun,ovednagar@hotmail.com;louzouy@math.biu.ac.il,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Bar Ilan University;Bar Ilan University,GCN;Quadratic activation;graph classification;,-1;102,-1;513,m;m,europe,il,n
ICLR,2020,Topological based classification using graph convolutional networks,Roy Abel;Idan Benami;Yoram Louzoun,royabel10@gmail.com;louzouy@math.biu.ac.il,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Bar Ilan University;Bar Ilan University,Graph Neural Networks;Graph Convolutional Networks;Graph;Topology;,-1;102,-1;513,m;m,europe,il,n
ICLR,2020,Quantifying Layerwise Information Discarding of Neural Networks and Beyond,Haotian Ma;Yinqing Zhang;Fan Zhou;Quanshi Zhang,11612807@mail.sustc.edu.cn;zhangyinqing@sjtu.edu.cn;zhoufan98@sjtu.edu.cn;zqs1022@sjtu.edu.cn,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Deep Learning;Information Theory;Interpretability;Convolutional Neural Networks;,-1;30;30;30,80;157;157;157,m;m,asia,cn,n
ICLR,2020,Real or Fake: An Empirical Study and Improved Model for Fake Face Detection,Zhengzhe Liu;Xiaojuan Qi;Jiaya Jia;Philip H. S. Torr,liuzhengzhelzz@gmail.com;xiaojuan.qi@eng.ox.ac.uk;leojia@cse.cuhk.edu.hk;philip.torr@eng.ox.ac.uk,3;3;3,,Withdrawn,0,3,,yes,9/25/19,"The Chinese University of Hong Kong;University of Oxford;Department of Computer Science and Engineering, The Chinese University of Hong Kong;University of Oxford",global image texture;generative adversarial networks;Gram matrix;,-1;46;46;46,-1;1;35;1,m;m,europe,uk,pdf miss
ICLR,2020,Minimizing Change in Classifier Likelihood to Mitigate Catastrophic Forgetting,Ashish Gaurav;Sachin Vernekar;Sean Sedwards;Jaeyoung Lee;Vahdat Abdelzad;Krzysztof Czarnecki,ashish.gaurav@uwaterloo.ca;sachin.vernekar@uwaterloo.ca;sean.sedwards@uwaterloo.ca;jaeyoung.lee@uwaterloo.ca;vabdelza@gsd.uwaterloo.ca;kczarnec@gsd.uwaterloo.ca,3;3;3,,Withdrawn,1,1,,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo,catastrophic forgetting;continual learning;classification;regularization;,30;30;30;30;30;30,235;235;235;235;235;235,m;m,canada,ca,n
ICLR,2020,A Memory-augmented Neural Network by Resembling Human Cognitive Process of Memorization,Dongjing Shan;Xiongwei Zhang;Chao Zhang;Limin Wang,shandongjing@pku.edu.cn;xwzhang9898@163.com;chzhang@cis.pku.edu.cn;07wanglimin@gmail.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Peking University;163;Peking University;Zhejiang University,,14;-1;14;39,24;-1;24;107,u;m,asia,cn,n
ICLR,2020,Molecule Property Prediction and Classification with Graph Hypernetworks,Eliya Nachmani;Lior Wolf,enk100@gmail.com;wolf@fb.com,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Facebook;Facebook,,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020, Sparsity Learning in Deep Neural Networks,Amirsina Torfi;Rouzbeh A. Shirvani;Sobhan Soleymani;Nasser M. Nasrabadi,atorfi@vt.edu;rouzbeh.asghari@gmail.com;ssoleyma@mix.wvu.edu;nasser.nasrabadi@mail.wvu.edu,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Virginia Tech;;West Virginia University;West Virginia University,Neural Networks;Deep Learning;Sparsity;Guided Attention;,64;-1;316;316,-1;-1;601;601,m;m,usa,usa,n
ICLR,2020,A Harmonic Structure-Based Neural Network Model for Musical Pitch Detection,Xian Wang;Lingqiao Liu;Qinfeng Shi,xian.wang01@adelaide.edu.au;lingqiao.liu@adelaide.edu.au;javen.shi@adelaide.edu.au,3;3;3,,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,musical pitch detection;automatic music transcription;,102;102;102,120;120;120,m;m,NAN,NAN,n
ICLR,2020,SEERL : Sample Efficient Ensemble Reinforcement Learning,Rohan Saphal;Balaraman Ravindran;Dheevatsa Mudigere;Sasikanth Avancha;Bharat Kaul,rohansaphal@gmail.com;ravi@cse.iitm.ac.in;dheevatsa@fb.com;sasikanth.avancha@intel.com;bharat.kaul@intel.com,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Oxford;Indian Institute of Technology Madras;Facebook;Intel;Intel,Reinforcement learning;,-1;-1;-1;-1;-1,-1;641;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Exploring by Exploiting Bad Models in Model-Based Reinforcement Learning,Yixin Lin;Sarah Bechtle;Ludovic Righetti;Akshara Rai;Franziska Meier,yixinlin@fb.com;sbechtle@tuebingen.mpg.de;ludovic.righetti@nyu.edu;akshararai@fb.com;fmeier@fb.com,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Facebook;Max-Planck Institute;New York University;Facebook;Facebook,,-1;-1;22;-1;-1,-1;-1;29;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Defensive Quantization Layer For Convolutional Network Against Adversarial Attack,Sirui Song;Qinglong Wang;Derek Yang;Yan Song;Xue Liu;Tong Zhang,siruisong97@gmail.com;qinglong.wang@mail.mcgill.ca;dyang1206@gmail.com;songyan@chuangxin.com;xueliu@cs.mcgill.ca;tongzhang0@gmail.com,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Tsinghua University;McGill University;;Sinovation Ventures;McGill University;Google,quantization;adversarial example;robustness;convolutional neural network;concept;,-1;102;-1;-1;102;-1,-1;42;-1;-1;42;-1,m;m,NAN,NAN,n
ICLR,2020,Learnable Higher-order Representation for Action Recognition,Kai Hu;Bhiksha Raj,kaihu@cmu.edu;bhiksha@cs.cmu.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,action recognition;context learning;,1;1,27;27,u;u,usa,usa,n
ICLR,2020,Meta Module Network for Compositional Visual Reasoning,Wenhu Chen;Zhe Gan;Linjie Li;Yu Cheng;William Wang;Jingjing Liu,wenhuchen@ucsb.edu;zhe.gan@microsoft.com;lindsey.li@microsoft.com;yu.cheng@microsoft.com;william@cs.ucsb.edu;jingjl@microsoft.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,UC Santa Barbara;Microsoft;Microsoft;Microsoft;UC Santa Barbara;Microsoft,Module Network;Visual Reasoning;Question Answering;Program Synthesis;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Multi-Task Adapters for On-Device Audio Inference,M. Tagliasacchi;F. de Chaumont Quitry;D. Roblek,mtagliasacchi@google.com;fcq@google.com;droblek@google.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Google;Google;Google,Audio;multi-task learning;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning audio representations with self-supervision,M. Tagliasacchi;B. Gfeller;F. de Chaumont Quitry;D. Roblek,mtagliasacchi@google.com;beatg@google.com;fcq@google.com;droblek@google.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Google;Google;Google;Google,Audio representations;self-supervised learning;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Scholastic-Actor-Critic For Multi Agent Reinforcement Learning,Weiying ChenÔºåRuize Hou,dissolution@126.com;fsszns@163.com,1;1;1;1,,Withdrawn,0,4,,yes,9/25/19,126;163,multi-agent reinforcement learning;Actor-Critic;,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Non-Gaussian processes and neural networks at finite widths,Sho Yaida,shoyaida@fb.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Facebook,Gaussian process;perturbation theory;renormalization group;Bayesian inference;,-1,-1,m,NAN,NAN,n
ICLR,2020,Uncertainty-aware Variational-Recurrent Imputation Network for Clinical Time Series,Ahmad Wisnu Mulyadi;Eunji Jun;Heung-Il Suk,wisnumulyadi@korea.ac.kr;ejjun92@korea.ac.kr;hisuk@korea.ac.kr,1;3;6;1,,Withdrawn,0,0,,yes,9/25/19,Korea University;Korea University;Korea University,Missing data imputation;electronic health Records;deep generative models;deep learning;,168;168;168,179;179;179,m;m,asia,kr,n
ICLR,2020,An Information Theoretic Perspective on Disentangled Representation Learning,Xiaojiang Yang;Wendong Bi;Yu Cheng;Junchi Yan,yangxiaojiang@sjtu.edu.cn;biwendong1997@gmail.com;yu.cheng@microsoft.com;yanjunchi@sjtu.edu.cn,1;1;3,,Withdrawn,0,4,,yes,9/25/19,Shanghai Jiao Tong University;;Microsoft;Shanghai Jiao Tong University,,30;-1;-1;30,157;-1;-1;157,m;m,asia,cn,n
ICLR,2020,Towards a Unified Evaluation of Explanation Methods without Ground Truth,Hao Zhang;Jiayi Chen;Haotian Xue;Quanshi Zhang,1603023-zh@sjtu.edu.cn;miracle3310@sjtu.edu.cn;xavihart@sjtu.edu.cn;zqs1022@sjtu.edu.cn,3;1;6,,Withdrawn,0,3,,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,Deep Learning;Interpretability;Evaluation;Convolutional Neural Networks;,30;30;30;30,157;157;157;157,m;m,asia,cn,n
ICLR,2020,Fast Sparse ConvNets,Erich Elsen;Marat Dukhan;Trevor Gale;Karen Simonyan,eriche@google.com;maratek@google.com;tgale@google.com;simonyan@google.com,3;6;3,,Withdrawn,0,3,,yes,9/25/19,Google;Google;Google;Google,Sparsity;Vision;CNNs;ConvNets;Inference;Mobile;Kernels;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Locally adaptive activation functions with slope recovery term for deep and physics-informed neural networks,Ameya D. Jagtap;Kenji Kawaguchi;George Em Karniadakis,ameya_jagtap@brown.edu;kawaguch@mit.edu;george_karniadakis@brown.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Brown University;Massachusetts Institute of Technology;Brown University,PINN;machine learning;stochastic gradients;accelerated training;,85;5;85,53;5;53,m;m,usa,usa,y
ICLR,2020,GumbelClip: Off-Policy Actor-Critic Using Experience Replay,Norman Tasfi;Miriam Capretz,ntasfi@gmail.com,1;3;3,,Withdrawn,0,1,,yes,9/25/19,University of Western Ontario,reinforcement learning;off-policy;actor-critic;experience replay;,-1,-1,m;f,NAN,NAN,n
ICLR,2020,Adversarial Neural Pruning,Divyam Madaan;Jinwoo Shin;Sung Ju Hwang,dmadaan@kaist.ac.kr;jinwoos@kaist.ac.kr;sjhwang82@kaist.ac.kr,1;3;3,,Withdrawn,0,3,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,adversarial examples;robust machine learning;robust optimization;network pruning;,-1;-1;-1,110;110;110,m;m,NAN,NAN,n
ICLR,2020,Auto-Encoding Explanatory Examples,C√©sar Ojeda;David Biesner;Ramses Sanchez;Kostadin Cvejoski;Jannis Schuecker;Christian Bauckhage;Bodgan Georgiev,cesarali07@gmail.com;david.biesner@iais.fraunhofer.de;sanchez@bit.uni-bonn.de;kostadin.cvejoski@iais.fraunhofer.de;jannis.schuecker@iais.fraunhofer.de;christian.bauckhage@iais.fraunhofer.de;bogdan.georgiev@iais.fraunhofer.de,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Fraunhofer IAIS;Fraunhofer IIS;University of Bonn;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS,Variational Auto Encoders;Interpolations;Explanations;Stochastic Processes;,-1;-1;143;-1;-1;-1;-1,-1;-1;106;-1;-1;-1;-1,m;m,NAN,NAN,y
ICLR,2020,Affine Self Convolution,Nichita Diaconu;Daniel E. Worrall,diacon995@gmail.com;d.e.worrall@uva.nl,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Amsterdam;University of Amsterdam,Self-attention;convolution;equivariant;,-1;143,-1;62,m;m,europe,nl,n
ICLR,2020,Universal Source-Free Domain Adaptation,Jogendra Nath Kundu;Naveen Venkat;Rahul M V;R. Venkatesh Babu,jogendrak@iisc.ac.in;nav.naveenvenkat@gmail.com;rmvenkat@andrew.cmu.edu;venky@iisc.ac.in,3;3;3,,Withdrawn,0,4,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;Carnegie Mellon University;Indian Institute of Science,unsupervised domain adaptation;knowledge transfer;source-free adaptation;,-1;-1;1;-1,301;301;27;301,m;m,NAN,NAN,n
ICLR,2020,Learning an off-policy predictive state representation for deep reinforcement learning for vision-based steering in autonomous driving,Daniel Graves,dgraves@ualberta.ca,1;3;3,,Withdrawn,0,4,,yes,9/25/19,University of Alberta,Predictive representations;general value functions;reinforcement learning;off-policy learning;behavior estimation;,102,136,m,canada,ca,n
ICLR,2020,$\textrm{D}^2$GAN: A Few-Shot Learning Approach with Diverse and Discriminative Feature Synthesis,Kai Li;Yulun Zhang;Kunpeng Li;Yun Fu,li.kai.gml@gmail.com;yulun100@gmail.com;kunpengli@ece.neu.edu;yunfu@ece.neu.edu,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Northeastern University;Northeastern University;Northeastern University;Northeastern University,few-shot learning;generative adversarial networks;,-1;16;16;16,-1;906;906;906,m;m,usa,usa,n
ICLR,2020,Hardware-aware One-Shot Neural Architecture Search in Coordinate Ascent Framework,Li Lyna Zhang;Yuqing Yang;Yuhang Jiang;Wenwu Zhu;Yunxin Liu,lzhani@microsoft.com;yuqing.yang@microsoft.com;jyh17@mails.tsinghua.edu.cn;wwzhu@tsinghua.edu.cn;yunxin.liu@microsoft.com,3;1;6,,Withdrawn,0,0,,yes,9/25/19,"Microsoft;Microsoft;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Microsoft",Neural Architecture Search;Hardware Diversity;Search Space;,-1;-1;4;4;-1,-1;-1;23;23;-1,f;m,NAN,NAN,n
ICLR,2020,Multi-task Network Embedding with Adaptive Loss Weighting,Fatemeh Salehi Rizi;Michael Granitzer,fatemeh.salehirizi@uni-passau.de;michael.granitzer@uni-passau.de,3;1;3,,Withdrawn,0,0,,yes,9/25/19,University of Passau;University of Passau,,316;316,252;252,f;m,europe,de,n
ICLR,2020,Perception-Driven Curiosity with Bayesian Surprise,Bernadette Bucher;Anton Arapin;Ramanan Sekar;Marc Badger;Feifei Duan;Oleh Rybkin;Kostas Daniilidis,bucherb@seas.upenn.edu;aarapin@fandm.edu;ramanans@seas.upenn.edu;mbadger@seas.upenn.edu;feifeid@seas.upenn.edu;oleh@seas.upenn.edu;kostas@seas.upenn.edu,1;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Pennsylvania;Franklin & Marshall College;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,deep reinforcement learning;exploration;curiosity;variational methods;deep autoencoders;,20;-1;20;20;20;20;20,11;-1;11;11;11;11;11,f;m,usa,usa,n
ICLR,2020,Global reasoning network for image super-resolution,Jiahui Zhang;Bin Zhou;Qingchang Tao;Deqiang Wang,jhzhang988@gmail.com;binzhou@sdu.edu.cn;taoqingchang@mail.tsinghua.edu.cn;wdq_sdu@sdu.edu.cn,1;3;3,,Withdrawn,1,2,,yes,9/25/19,"Shandong University;Shandong University;Tsinghua University, Tsinghua University;Shandong University",Global reasoning network;upsampling module;graph model;image super-resolution;,-1;143;4;143,-1;658;23;658,u;u,asia,cn,n
ICLR,2020,MUSE: Multi-Scale Attention Model for Sequence to Sequence Learning,Guangxiang Zhao;Xu Sun;Jingjing Xu;Zhiyuan Zhang;Liangchen Luo,1701214310@pku.edu.cn;xusun@pku.edu.cn;jingjingxu@pku.edu.cn;zzy1210@pku.edu.cn;luolc@pku.edu.cn,3;3;3,,Withdrawn,0,6,,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;Peking University,Attention;Sequence to sequence learning;Deep neural networks;Machine Translation;Natural Language Processing;,14;14;14;14;14,24;24;24;24;24,m;m,asia,cn,n
ICLR,2020,Utility Analysis of Network Architectures for 3D Point Cloud Processing,Shikun Huang;Binbin Zhang;Wen Shen;Zhihua Wei;Quanshi Zhang,hsk@tongji.edu.cn;0206zbb@tongji.edu.cn;1810068@tongji.edu.cn;zhihua_wei@tongji.edu.cn;zqs1022@sjtu.edu.cn,6;3;1,,Withdrawn,0,3,,yes,9/25/19,Tongji University;Tongji University;Tongji University;Tongji University;Shanghai Jiao Tong University,3D Point Cloud Processing;Interpretability;Deep Learning;,316;316;316;316;30,441;441;441;441;157,m;m,asia,cn,n
ICLR,2020,Reducing Sentiment Bias in Language Models via Counterfactual Evaluation,Po-Sen Huang;Huan Zhang;Ray Jiang;Robert Stanforth;Johannes Welbl;Jack Rae;Vishal Maini;Dani Yogatama;Pushmeet Kohli,posenhuang@google.com;huan@huan-zhang.com;rayjiang@google.com;stanforth@google.com;j.welbl@cs.ucl.ac.uk;jwrae@google.com;vmaini@google.com;dyogatama@google.com;pushmeet@google.com,3;3;3,,Withdrawn,0,6,,yes,9/25/19,Google;Carnegie Mellon University;Google;Google;University College London;Google;Google;Google;Google,language model;fairness;counterfactual analysis;sentiment analysis;,-1;1;-1;-1;52;-1;-1;-1;-1,-1;27;-1;-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,BERT for Sequence-to-Sequence Multi-Label Text Classification,Ramil Yarullin;Pavel Serdyukov,ramly@ya.ru;pavel.serdyukov@gmail.com,3;3;1,,Withdrawn,0,4,,yes,9/25/19,Yandex;Yandex,Multi-Label Text Classification;Sequence-to-Sequence Learning;BERT;Sequence Generation;Hierarchical Text Classification;,-1;-1,-1;-1,m;m,asia,in,n
ICLR,2020,Boosting Generative Models by Leveraging Cascaded Meta-Models,Fan Bao;Hang Su;Jun Zhu,bf19@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,1;6;1,,Withdrawn,0,0,,yes,9/25/19,"Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",Probabilistic Machine Learning;Learning Generative Models;Unsupervised Learning;,4;4;4,23;23;23,m;m,NAN,NAN,y
ICLR,2020,RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers,Bailin Wang*;Richard Shin*;Xiaodong Liu;Oleksandr Polozov;Matthew Richardson,bailin.wang@ed.ac.uk;ricshin@cs.berkeley.edu;xiaodl@microsoft.com;polozov@microsoft.com;mattri@microsoft.com,6;1;3,,Withdrawn,0,4,,yes,9/25/19,University of Edinburgh;University of California Berkeley;Microsoft;Microsoft;Microsoft,semantic parsing;text-to-sql;self-attention;program synthesis;transformer;representation learning;natural language processing;,36;-1;-1;-1;-1,30;13;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Shape Features Improve General Model Robustness,Chaowei Xiao;Mingjie Sun;Haonan Qiu;Han Liu;Mingyan Liu;Bo Li,xiaocw@umich.edu;mingjies@andrew.cmu.edu;haonanqiu@link.cuhk.edu.cn;hanliu@northwestern.edu;mingyan@umich.ed;lxbosky@gmail.com,1;1;6,,Withdrawn,0,0,,yes,9/25/19,"University of Michigan;Carnegie Mellon University;The Chinese University of Hong Kong, Shenzhen;Northwestern University;;University of California Berkeley",adversarial machine learning;robustness;backdoor attacks;,7;1;46;46;-1;-1,21;27;35;22;-1;13,m;f,usa,usa,n
ICLR,2020,The Secret Revealer: Generative Model Inversion Attacks Against Deep Neural Networks,Yuheng Zhang;Ruoxi Jia;Hengzhi Pei;Wenxiao Wang;Bo Li;Dawn Song,16307130075@fudan.edu.cn;ruoxijia@berkeley.edu;hzpei16@fudan.edu.cn;wangwx16@mails.tsinghua.edu.cn;lxbosky@gmail.com,6;1;3,,Withdrawn,0,0,,yes,9/25/19,"Fudan University;University of California Berkeley;Fudan University;Tsinghua University, Tsinghua University;University of California Berkeley",Model inversion attack;privacy;deep learning;,73;-1;73;4;-1,109;13;109;23;13,m;f,usa,usa,y
ICLR,2020,Common sense and Semantic-Guided Navigation via Language in Embodied Environments,Dian Yu;Chandra Khatri;Alexandros Papangelis;Mahdi Namazifar;Andrea Madotto;Huaixiu Zheng;Gokhan Tur,dian.yu@uber.com;chandrak@uber.com;apapangelis@uber.com;mahdin@uber.com;amadotto@connect.ust.hk;huaixiu.zheng@uber.com;gokhan@uber.com,1;1;3,,Withdrawn,0,0,,yes,9/25/19,Uber;Uber;Uber;Uber;The Hong Kong University of Science and Technology;Uber;Uber,,-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;47;-1;-1,f;m,southamerica,br,n
ICLR,2020,TransINT: Embedding Implication Rules in Knowledge Graphs with Isomorphic Intersections of Linear Subspaces,So Yeon Min;Preethi Raghavan;Peter Szolovits,symin95@mit.edu;praghav@us.ibm.com;psz@mit.edu,3;3;1,,Withdrawn,2,3,,yes,9/25/19,Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology,Knowledge Graph Embedding;Knowledge Graph;Common Sense;Rules;Isomorphic Embedding;Isomorphism;Semantics Mining;Rule Mining;,5;-1;5,5;-1;5,u;m,usa,usa,y
ICLR,2020,Meta Label Correction for Learning with Weak Supervision,Guoqing Zheng;Ahmed Hassan Awadallah;Susan Dumais,zheng@microsoft.com;hassanam@microsoft.com;sdumais@microsoft.com,3;3;8;1,,Withdrawn,0,1,,yes,9/25/19,Microsoft;Microsoft;Microsoft,,-1;-1;-1,-1;-1;-1,m;f,NAN,NAN,n
ICLR,2020,Towards Effective and Efficient Zero-shot Learning by Fine-tuning with  Task Descriptions,Tian Jin*;Zhun Liu*;Shengjia Yan;Alexandre Eichenberger;Louis-Philippe Morency,tian.jin1@ibm.com;zhunl@andrew.cmu.edu;sjyan@nyu.edu;alexe@us.ibm.com;morency@cs.cmu.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,International Business Machines;Carnegie Mellon University;New York University;International Business Machines;Carnegie Mellon University,zero-shot learning;meta-learning;convolutional neural;dynamic parameter generation;,-1;1;22;-1;1,-1;27;29;-1;27,u;m,usa,usa,n
ICLR,2020,Multi-hop Question Answering via Reasoning Chains,Jifan Chen;Shih-ting Lin;Greg Durrett,jfchen@cs.utexas.edu;j0717lin@gmail.com;gdurrett@cs.utexas.edu,6;3;3,,Withdrawn,0,4,,yes,9/25/19,"University of Texas, Austin;;University of Texas, Austin",natural language processing;question answering;multi-hop reasoning;reasoning chain extraction;,-1;-1;-1,-1;-1;-1,m;m,usa,usa,n
ICLR,2020,Factorized Multimodal Transformer for Multimodal Sequential Learning,Amir Zadeh;Chengfeng Mao;Jiaxin Shi;Yiwei Zhang;Paul Pu Liang;Soujanya Poria;Louis-Philippe Morency,abagherz@andrew.cmu.edu;chengfem@andrew.cmu.edu;jiaxins1@andrew.cmu.edu;yiweizh2@andrew.cmu.edu;pliang@cs.cmu.edu;sporia@ntu.edu.sg;morency@cs.cmu.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Nanyang Technological University;Carnegie Mellon University,Multimodal Machine Learning;Multimodal Transformer;Multimodal Language;Sentiment Analysis;Emotion Recognition;,1;1;1;1;1;43;1,27;27;27;27;27;49;27,m;m,usa,usa,n
ICLR,2020,Faster and Just As Accurate: A Simple Decomposition for Transformer Models,Qingqing Cao;Harsh Trivedi;Aruna Balasubramanian;Niranjan Balasubramanian,qicao@cs.stonybrook.edu;hjtrivedi@cs.stonybrook.edu;arunab@cs.stonybrook.edu;niranjan@cs.stonybrook.edu,6;3;3,,Withdrawn,1,4,,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook",Faster Inference;Transformers;Pre-trained Representations;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Function-Specific Word Representations,Daniela Gerz;Ivan Vuliƒá;Marek Rei;Roi Reichart;Anna Korhonen,dsg40@cam.ac.uk;iv250@cam.ac.uk;marek.rei@cl.cam.ac.uk;roiri@technion.ac.il;alk23@cam.ac.uk,3;6;3,,Withdrawn,0,0,,yes,9/25/19,"University of Cambridge;University of Cambridge;University of Cambridge;Technion, Technion;University of Cambridge",representation learning;associations;word embeddings;SVO;thematic fit;selectional preference;,79;79;79;27;79,3;3;3;-1;3,f;f,europe,uk,n
ICLR,2020,Attention over Parameters for Dialogue Systems,Andrea Madotto;Zhaojiang Lin;Chien-Sheng Wu;Jamin Shin;Pascale Fung,amadotto@connect.ust.hk;zlinao@connect.ust.hk;wu.jason@salesforce.com;jay.shin@connect.ust.hk;pascale@ece.ust.hk,1;3;1,,Withdrawn,0,3,,yes,9/25/19,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;SalesForce.com;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,end-to-end dialogue systems;natural language processing;,-1;-1;-1;-1;-1,47;47;-1;47;47,f;f,NAN,NAN,n
ICLR,2020,"RL-ST: Reinforcing Style, Fluency and Content Preservation for Unsupervised Text Style Transfer",Bhargav Upadhyay;Akhilesh Sudhakar;Arjun Maheswaran,bhargav@agaralabs.com;akhilesh@agaralabs.com;arjun@agaralabs.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Agara;Agara;Agara,style transfer;text generation;reinforcement learning;sentiment transfer;RL;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Extreme Language Model Compression with Optimal Subwords and Shared Projections,Sanqiang Zhao;Raghav Gupta;Yang Song;Denny Zhou,sanqiang.zhao@pitt.edu;raghavgupta@google.com;yangso@google.com;dennyzhou@google.com,3;3;3,,Withdrawn,0,3,,yes,9/25/19,University of Pittsburgh;Google;Google;Google,NLP;BERT;Knowledge Distillation;Model Compression;Language Modeling;,79;-1;-1;-1,113;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Distilling the Knowledge of BERT for Text Generation,Yen-Chun Chen;Zhe Gan;Yu Cheng;Jingzhou Liu;Jingjing Liu,yen-chun.chen@microsoft.com;zhe.gan@microsoft.com;yu.cheng@microsoft.com;jingzhol@andrew.cmu.edu;jingjl@microsoft.com,1;6;3,,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Microsoft;Carnegie Mellon University;Microsoft,text generation;neural machine translation;abstractive summarization;,-1;-1;-1;1;-1,-1;-1;-1;27;-1,m;f,NAN,NAN,n
ICLR,2020,DCTD: Deep Conditional Target Densities for Accurate Regression,Fredrik K. Gustafsson;Martin Danelljan;Goutam Bhat;Thomas B. Sch√∂n,fredrik.gustafsson@it.uu.se;martin.danelljan@vision.ee.ethz.ch;goutam.bhat@vision.ee.ethz.ch;thomas.schon@it.uu.se,3;6;1,,Withdrawn,0,0,,yes,9/25/19,Uppsala University;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Uppsala University,Computer vision;deep learning;regression;object detection;visual tracking;,194;-1;-1;194,102;-1;-1;102,m;m,europe,se,n
ICLR,2020,A Gradient-based Architecture HyperParameter Optimization Approach,Zechun Liu;Xiangyu Zhang;Zhe Li;Yichen Wei;Kwang-Ting Cheng;Jian Sun,zliubq@connect.ust.hk;zhangxiangyu@megvii.com;lizhe@megvii.com;weiyichen@megvii.com;timcheng@ust.hk;sunjian@megvii.com,3;1;3,,Withdrawn,0,0,,yes,9/25/19,The Hong Kong University of Science and Technology;Megvii Technology Inc.;Megvii Technology Inc.;Megvii Technology Inc.;The Hong Kong University of Science and Technology;Megvii Technology Inc.,gradient-based;neural architecture search;architecture hyperparameter optimization;,-1;-1;-1;-1;-1;-1,47;-1;-1;-1;47;-1,f;m,NAN,NAN,n
ICLR,2020,Generalizing Natural Language Analysis through Span-relation Representations,Zhengbao Jiang;Wei Xu;Jun Araki;Graham Neubig,zhengbaj@cs.cmu.edu;weixu@cse.ohio-state.edu;jun.araki@us.bosch.com;gneubig@cs.cmu.edu,3;3;6,,Withdrawn,0,1,,yes,9/25/19,Carnegie Mellon University;;Bosch;Carnegie Mellon University,Span-Relation Representation;Task-Independent Framework;Natural Language Analysis;Benchmark;,1;-1;-1;1,27;-1;297;27,m;m,usa,usa,n
ICLR,2020,On the Distribution of Penultimate Activations of Classification Networks,Minkyo Seo;Yoonho Lee;Suha Kwak,mkseo@postech.ac.kr;einet89@gmail.com;suha.kwak@postech.ac.kr,1;3;3,,Withdrawn,0,0,,yes,9/25/19,POSTECH;AITRICS;POSTECH,,118;-1;118,146;-1;146,m;m,asia,kr,n
ICLR,2020,Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control,Yu-Wei Chao;Jimei Yang;Weifeng Chen;Jia Deng,ychao@nvidia.com;jimyang@adobe.com;wfchen@umich.edu;jiadeng@princeton.edu,3;3;1,,Withdrawn,0,0,,yes,9/25/19,NVIDIA;Adobe Systems;University of Michigan;Princeton University,physics-based motion synthesis;hierarchical reinforcement learning;motion capture data;,-1;-1;7;30,-1;-1;21;6,m;m,usa,usa,n
ICLR,2020,"Unsupervised Few-shot Object Recognition by Integrating Adversarial, Self-supervision, and Deep Metric Learning of Latent Parts",Khoi Nguyen;Sinisa Todorovic,nguyenkh@oregonstate.edu;sinisa@oregonstate.edu,1;1;3,,Withdrawn,0,0,,yes,9/25/19,Oregon State University;Oregon State University,Unsupervised Few-shot Learning;Deep Metric Learning;Self-supervised Learning;,79;79,373;373,m;m,usa,usa,n
ICLR,2020,BERT Wears GloVes: Distilling Static Embeddings from Pretrained Contextual Representations,Rishi Bommasani;Kelly Davis;Claire Cardie,rb724@cornell.edu;kdavis@mozilla.com;cardie@cs.cornell.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Cornell University;Mozilla;Cornell University,Pretrained Word Representations;Lightweight Representations;NLP;Social Bias;Word Embeddings;,7;-1;7,19;-1;19,m;f,usa,usa,n
ICLR,2020,Mixed Setting Training Methods for Incremental Slot-Filling Tasks,Daniel C. Michelin;Jonathan K. Kummerfeld;Kevin Leach;Stefan Larson;Yunqi Zhang;Joeseph J. Peper,daniel@clinc.com;jkk@clinc.com;kevin.leach@clinc.com;slars@clinc.com;yunqi@clinc.com;joe@clinc.com,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Clinc;Clinc;Clinc;Clinc;Clinc;Clinc,incremental learning;slot-filling;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,PLEX: PLanner and EXecutor for Embodied Learning in Navigation,Gil Avraham;Yan Zuo;Tom Drummond,gil.avraham@monash.edu;yan.zuo@monash.edu;tom.drummond@monash.edu,3;1;1,,Withdrawn,0,0,,yes,9/25/19,Monash University;Monash University;Monash University,Hierarchical Reinforcement Learning;Embodied Learning;Navigation;,92;92;92,75;75;75,m;m,australasia,au,y
ICLR,2020,UniLoss: Unified Surrogate Loss by Adaptive Interpolation,Lanlan Liu;Mingzhe Wang;Jia Deng,llanlan@umich.edu;mingzhew@cs.princeton.edu;jiadeng@princeton.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,University of Michigan;Princeton University;Princeton University,,7;30;30,21;6;6,f;m,usa,usa,n
ICLR,2020,MobileBERT: Task-Agnostic Compression of BERT by Progressive Knowledge Transfer,Zhiqing Sun;Hongkun Yu;Xiaodan Song;Renjie Liu;Yiming Yang;Denny Zhou,zhiqings@andrew.cmu.edu;hongkuny@google.com;xiaodansong@google.com;renjieliu@google.com;yiming@cs.cmu.edu;dennyzhou@google.com,6;3;3;3,,Withdrawn,0,8,,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Carnegie Mellon University;Google,BERT;knowledge transfer;model compression;,1;-1;-1;-1;1;-1,27;-1;-1;-1;27;-1,m;m,NAN,NAN,n
ICLR,2020,Interactive Classification by Asking Informative Questions,Lili Yu;Howard Chen;Sida I. Wang;Yoav Artzi and Tao Lei,liliyu@asapp.com;hchen@asapp.com;sidaw@cs.princeton.edu;yoav@cs.cornell.edu;tao@asapp.com,6;1;3,,Withdrawn,0,0,,yes,9/25/19,ASAPP Inc.;ASAPP Inc.;Princeton University;Cornell University;ASAPP Inc.,NLP;interactive classification;interactive system;text classification;data collection;,-1;-1;30;7;-1,-1;-1;6;19;-1,f;m,NAN,NAN,n
ICLR,2020,Cross-Lingual Vision-Language Navigation,An Yan;Xin Wang;Jiangtao Feng;Lei Li;William Wang,ayan@ucsd.edu;xwang@cs.ucsb.edu;fengjiangtao@bytedance.com;lileilab@bytedance.com;william@cs.ucsb.edu,6;3;1,,Withdrawn,0,0,,yes,9/25/19,"University of California, San Diego;UC Santa Barbara;ByteDance;ByteDance;UC Santa Barbara",Vision-Language Navigation;Cross-lingual Representation Learning;Cross-lingual Adaptation;,-1;-1;-1;-1;-1,31;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Single Deep Counterfactual Regret Minimization,Eric Steinberger,ericsteinberger.est@gmail.com,3;6;1,,Withdrawn,0,1,,yes,9/25/19,0,Game Theory;Deep Reinforcement Learning;Counterfactual Regret Minimization;Imperfect Information Games;Games;Poker;Nash Equilibrium;,,,m,NAN,NAN,y
ICLR,2020,I love your chain mail! Making knights smile in a fantasy game world,Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Emily Dinan;Douwe Kiela;Jason Weston;Arthur Szlam,sprabhum@cs.cmu.edu;margaretli@fb.com;jju@fb.com;edinan@fb.com;dkiela@fb.com;jase@fb.com;aszlam@fb.com,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,reinforcement learning;dialogue systems;goal-oriented chit-chat;,1;-1;-1;-1;-1;-1;-1,27;-1;-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,DOUBLE-HARD DEBIASING: TAILORING WORD EMBEDDINGS FOR GENDER BIAS MITIGATION,Tianlu Wang;Xi Victoria Lin;Nazneen Fatema Rajani;Vicente Ordonez;Caimng Xiong,tianlu@virginia.edu;xilin@salesforce.com;nazneen.rajani@salesforce.com;vicente@virginia.edu;cxiong@salesforce.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Virginia;SalesForce.com;SalesForce.com;University of Virginia;SalesForce.com,Gender bias;Word embeddings;,52;-1;-1;52;-1,107;-1;-1;107;-1,f;m,NAN,NAN,n
ICLR,2020,Joint text classification on multiple levels with multiple labels,Miruna P√Æslar;Marek Rei,miruna.pislar@gmail.com;marek.rei@cl.cam.ac.uk,1;3;1,,Withdrawn,0,3,,yes,9/25/19,DeepMind;University of Cambridge,multi-head attention;zero-shot learning;multi-task learning;text classification;sequence labeling;,-1;79,-1;3,f;m,europe,uk,n
ICLR,2020,Discrete Transformer,Jambay Kinley;Yuntian Deng;Alexander M. Rush,j_kinley@college.harvard.edu;dengyuntian@seas.harvard.edu;arush@cornell.edu,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Harvard University;Harvard University;Cornell University,transformer;natural language processing;attention;,52;52;7,7;7;19,m;m,usa,usa,n
ICLR,2020,Pragmatic Evaluation of Adversarial Examples in Natural Language,John Morris;Eli Lifland;Ji Gao;Jack Lanchantin;Yangfeng Ji;Yanjun Qi,jm8wx@virginia.edu;edl9cy@virginia.edu;jg6yd@virginia.edu;jjl5sw@virginia.edu;yj3fs@virginia.edu;yq2h@virginia.edu,6;3;3,,Withdrawn,1,3,,yes,9/25/19,University of Virginia;University of Virginia;University of Virginia;University of Virginia;University of Virginia;University of Virginia,adversarial examples;natural language processing;analysis;,52;52;52;52;52;52,107;107;107;107;107;107,m;f,usa,usa,n
ICLR,2020,Question Generation from Paragraphs: A Tale of Two Hierarchical Models,Vishwajeet Kumar;Raktim Chaki;Sai Teja Talluri;Ganesh Ramakrishnan;Yuan-Fang Li;Gholamreza Haffari,vishwajeet@cse.iitb.ac.in;raktimchaki@cse.iitb.ac.in;saiteja.talluri@gmail.com;ganesh@cse.iitb.ac.in;yuanfang.li@monash.edu;gholamreza.haffari@monash.edu,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;;Indian Institute of Technology Bombay;Monash University;Monash University,Question Generation;Hierarchical models;Transformer;BiLSTM;LSTM;,-1;-1;-1;-1;92;92,480;480;-1;480;75;75,m;m,australasia,au,n
ICLR,2020,Should All Cross-Lingual Embeddings Speak English?,Antonios Anastasopoulos;Graham Neubig,aanastas@andrew.cmu.edu;gneubig@cs.cmu.edu,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,multilingual embeddings;cross-lingual embeddings;under-represented languages;,1;1,27;27,m;m,usa,usa,n
ICLR,2020,Couple-VAE: Mitigating the Encoder-Decoder Incompatibility in Variational Text Modeling with Coupled Deterministic Networks,Chen Wu;Prince Zizhuang Wang;William Yang Wang,wu-c16@mails.tsinghua.edu.cn;zizhuang_wang@ucsb.edu;william@cs.ucsb.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University, Tsinghua University;UC Santa Barbara;UC Santa Barbara",variational autoencoders;posterior collapse;text modeling;amortized variational inference;,4;-1;-1,23;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Task-agnostic Continual Learning via Growing Long-Term Memory Networks,Germ√°n Kruszewski;Ionut Teodor Sorodoc;Tomas Mikolov,germank@gmail.com;ionutteodor.sorodoc@upf.edu;tmikolov@fb.com,6;6;3,,Withdrawn,0,0,,yes,9/25/19,Naver Labs Europe;Universitat Pompeu Fabra;Facebook,growing;long term memory;continual learning;catastrophic forgetting;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Exploring the Pareto-Optimality between Quality and Diversity in Text Generation,Jianing Li;Yanyan Lan;Jiafeng Guo;Xueqi Cheng,lijianing@ict.ac.cn;lanyanyan@ict.ac.cn;guojiafeng@ict.ac.cn;cxq@ict.ac.cn,1;3;3,,Withdrawn,0,3,,yes,9/25/19,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",text generation;quality;diversity;,30;30;30;30,-1;-1;-1;-1,u;m,NAN,NAN,y
ICLR,2020,An Empirical Study of Encoders and Decoders in Graph-Based Dependency Parsing,Ge Wang;Ziyuan Hu;Zechuan Hu;Kewei Tu,wangge@shanghaitech.edu.cn;huzy@shanghaitech.edu.cn;huzch@shanghaitech.edu.cn;tukw@shanghaitech.edu.cn,3;3,,Withdrawn,0,0,,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;ShanghaiTech University,dependency parsing;high order decoding;empirical study;,316;316;316;316,-1;-1;-1;-1,m;m,asia,cn,n
ICLR,2020,Hierarchical Summary-to-Article Generation,Wangchunshu Zhou;Tao Ge;Ke Xu;Furu Wei;Ming Zhou,v-waz@microsoft.com;tage@microsoft.com;kexu@nlsde.buaa.edu.cn;fuwei@microsoft.com;mingzhou@microsoft.com,3;3;3,,Withdrawn,0,4,,yes,9/25/19,Microsoft;Microsoft;Beihang University;Microsoft;Microsoft,text generation;reinforcement learning;hierarchical generation;,-1;-1;102;-1;-1,-1;-1;594;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Anomaly Detection by Deep Direct Density Ratio Estimation,Masahiro Abe;Masashi Sugiyama,masahiro.abe@d2c.co.jp;sugi@k.u-tokyo.ac.jp,3;3;3,,Withdrawn,0,0,,yes,9/25/19,The University of Tsukuba;The University of Tokyo,anomaly detection;density ratio estimation;neural networks;,-1;64,-1;36,m;m,NAN,NAN,n
ICLR,2020,Generating Biased Datasets for Neural Natural Language Processing,Alvin Chan;Yi Tay;Yew Soon Ong;Aston Zhang,guoweial001@e.ntu.edu.sg;ytay017@e.ntu.edu.sg;asysong@ntu.edu.sg;astonz@amazon.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Amazon,bias;natural language processing;text classification;natural language inference;,43;43;43;-1,49;49;49;-1,m;m,NAN,NAN,n
ICLR,2020,3D-SIC: 3D Semantic Instance Completion for RGB-D Scans,Ji Hou;Angela Dai;Matthias Niessner,ji.hou@tum.de;angela.dai@tum.de;niessner@tum.de,6;3;3,,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,3d reconstruction;rgb-d scanning;3d learning;3d scene understanding;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation,Bo Pang;Erik Nijkamp;Wenjuan Han;Alex Zhou,bopang@g.ucla.edu;erik.nijkamp@gmail.com;hanwj0309@gmail.com;alexzhou907@gmail.com,1;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Los Angeles;;;ShanghaiTech University",open-dialogue system;generation evaluation;natural language processing;,-1;-1;-1;-1,17;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders,Zixia Jia;Youmi Ma;Jiong Cai;Kewei Tu,jiazx@shanghaitech.edu.cn;maym@shanghaitech.edu.cn;caijiong@shanghaitech.edu.cn;tukw@shanghaitech.edu.cn,3;6;3,,Withdrawn,0,0,,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;ShanghaiTech University,Semi-Supervised Learning;Semantic Dependency Parsing;CRF Autoencoder;Natural Language Processing;,316;316;316;316,-1;-1;-1;-1,m;m,asia,cn,n
ICLR,2020,A Syntax-Aware Approach for Unsupervised Text Style Transfer,Yun Ma;Yangbin Chen;Xudong Mao;Qing Li,mayun371@gmail.com;robinchen2-c@my.cityu.edu.hk;xudong.xdmao@gmail.com;qing-prof.li@polyu.edu.hk,3;3;3,,Withdrawn,0,1,,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Xiamen University;The Hong Kong Polytechnic University,,-1;118;-1;118,-1;171;579;171,m;m,asia,hk,n
ICLR,2020,Contextualized Sparse Representation with Rectified N-Gram Attention for Open-Domain Question Answering,Jinhyuk Lee;Minjoon Seo;Hannaneh Hajishirzi;Jaewoo Kang,jinhyuk_lee@korea.ac.kr;minjoon@cs.washington.edu;hannaneh@washington.edu;kangj@korea.ac.kr,6;3;3,,Withdrawn,0,4,,yes,9/25/19,Korea University;University of Washington;University of Washington;Korea University,Open-Domain Question Answering;Sparse Representation;Phrase Representation;Information Retrieval;,168;11;11;168,179;26;26;179,m;m,asia,kr,n
ICLR,2020,Recurrent Layer Attention Network,Eunseok Kim;Inwook Shim,eunseok1117@gmail.com;inugi00@gmail.com,1;3;1,,Withdrawn,2,1,,yes,9/25/19,Agency for Defense Development;Korea Advanced Institute of Science and Technology,attention mechanism;recurrent neural network;image recognition;deep learning;,-1;-1,-1;-1,u;m,asia,in,n
ICLR,2020,Super-AND: A Holistic Approach to Unsupervised Embedding Learning,Sungwon Han;Yizhan Xu;Sungwon Park;Meeyoung Cha;Cheng-Te Li,lion4151@kaist.ac.kr;re6071020@gs.ncku.edu.tw;psw0416@kaist.ac.kr;mcha@ibs.re.kr;chengte@mail.ncku.edu.tw,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Peking University;Korea Advanced Institute of Science and Technology;Institute for Basic Science;Peking University,Unsupervised embedding learning;computer vision;anchor neighborhood discovery;image clustering;,-1;14;-1;-1;14,110;24;110;-1;24,m;m,asia,cn,n
ICLR,2020,Natural Language State Representation for Reinforcement Learning,Erez Schwartz;Guy Tennenholtz;Chen Tessler;Shie Mannor,erezschwartz@campus.technion.ac.il;sguyt@campus.technion.ac.il;chen.tessler@gmail.com;shiemannor@gmail.com,1;1;6,,Withdrawn,0,1,,yes,9/25/19,"Technion, Technion;Technion, Technion;Technion, Technion;Technion, Technion",Reinforcement Learning;Natural Language;Representation Learning;Deep Learning;,27;27;27;27,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,BEAN: Interpretable Representation Learning with Biologically-Enhanced Artificial Neuronal Assembly Regularization,Yuyang Gao;Giorgio Ascoli;Liang Zhao,ygao13@gmu.edu;ascoli@gmu.edu;lzhao9@gmu.edu,3;1;3,,Withdrawn,0,1,,yes,9/25/19,George Mason University;George Mason University;George Mason University,regularization;interpretability;bio-inspired deep learning;neuroscience;computational biology;,85;85;85,282;282;282,m;m,usa,usa,n
ICLR,2020,Revisiting Fine-tuning for Few-shot Learning,Akihiro Nakamura;Tatsuya Harada,nakamura@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,1;3;1,,Withdrawn,0,0,,yes,9/25/19,The University of Tokyo;The University of Tokyo,few-shot learning;fine-tuning;,64;64,36;36,m;m,NAN,NAN,n
ICLR,2020,Unrestricted Adversarial Attacks For Semantic Segmentation,Guangyu Shen;Chengzhi Mao;Junfeng Yang;Baishakhi Ray,shen447@purdue.edu;cm3797@columbia.edu;junfeng@cs.columbia.edu;rayb@cs.columbia.edu,6;6;1,,Withdrawn,0,0,,yes,9/25/19,Purdue University;Columbia University;Columbia University;Columbia University,Adversarial Attacks;Semantic Segmentation;Computer Vision;,24;24;24;24,88;16;16;16,m;f,usa,usa,n
ICLR,2020,End-to-End Multi-Domain Task-Oriented Dialogue Systems with Multi-level Neural Belief Tracker,Hung Le;Doyen Sahoo;Chenghao Liu;Nancy F. Chen;Steven C.H. Hoi,l.hung1610@gmail.com;dsahoo@salesforce.com;chliu@smu.edu.sg;nfychen@i2r.a-star.edu.sg;shoi@salesforce.com,3;3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Singapore Management University;SalesForce.com;Singapore Management University;Institute for Infocomm Research, A*STAR;SalesForce.com",task-oriented;dialogues;dialogue state tracking;end-to-end;,79;-1;79;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Accelerate DNN Inference  By Inter-Operator Parallelization,Yaoyao Ding;Ligeng Zhu;Zhihao Jia;Song Han,yyding@mit.edu;ligeng@mit.edu;zhihao@cs.stanford.edu;songhan@mit.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Stanford University;Massachusetts Institute of Technology,,5;5;5;5,5;5;4;5,m;m,usa,usa,n
ICLR,2020,Posterior Control of Blackbox Generation ,Xiang Lisa Li;Alexander M. Rush,xli150@jhu.edu;srush@seas.harvard.edu,3;3;6,,Withdrawn,0,0,,yes,9/25/19,Johns Hopkins University;Harvard University,nlp;text generation;deep latent variable models;variational autoencoders;,73;52,12;7,f;m,usa,usa,n
ICLR,2020,Learning to Generate 3D Training Data through Hybrid Gradient,Dawei Yang;Jia Deng,ydawei@umich.edu;jiadeng@princeton.edu,8;3;3,,Withdrawn,0,0,,yes,9/25/19,University of Michigan;Princeton University,,7;30,21;6,m;m,usa,usa,n
ICLR,2020,Learning to Learn via Gradient Component Corrections,Christian Simon;Piotr Koniusz;Richard Nock;Mehrtash Harandi,christian.simon@anu.edu.au;peter.koniusz@data61.csiro.au;richard.nock@data61.csiro.au;mehrtash.harandi@monash.edu,1;3;3,,Withdrawn,0,1,,yes,9/25/19,Australian National University;CSIRO;CSIRO;Monash University,meta-learning;classification;regression;,102;-1;-1;92,50;-1;-1;75,m;m,australasia,au,pdf miss
ICLR,2020,Counting the Paths in Deep Neural Networks as a Performance Predictor,Michele Sasdelli;Ian Reid;Gustavo Carneiro,michele.sasdelli@adelaide.edu.au;ian.reid@adelaide.edu.au;gustavo.carneiro@adelaide.edu.au,3;1;3,,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,learning theory;deep learning;convolutional neural networks;,102;102;102,120;120;120,m;m,NAN,NAN,n
ICLR,2020,VUSFA:Variational Universal Successor Features Approximator ,Shamane Siriwardhana;Rivindu Weerasakera;Denys J.C. Matthies;Suranga Nanayakkara,shamane@ahlab.org;rivindu@ahlab.org;denys@ahlab.org;suranga@ahlab.org,1;1;1,,Withdrawn,0,3,,yes,9/25/19,University of Auckland;;;University of Auckland,Universal Successor Features;Successor Features;Model Free Deep Reinforcement Learning;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,asia,in,n
ICLR,2020,Data Annealing Transfer learning Procedure for Informal Language Understanding Tasks,Jing Gu;Yu Zhou,jkgu@ucdavis.edu;joyu@ucdavis.edu,3;3;1;3,,Withdrawn,0,0,,yes,9/25/19,"University of California, Davis;University of California, Davis",,-1;-1,55;55,f;f,usa,usa,n
ICLR,2020,Building Hierarchical Interpretations in Natural Language via Feature Interaction Detection,Hanjie Chen;Guangtao Zheng;Yangfeng Ji,hc9mx@virginia.edu;gz5hp@virginia.edu;yangfeng@virginia.edu,3;1;1,,Withdrawn,0,1,,yes,9/25/19,University of Virginia;University of Virginia;University of Virginia,Hierarchical Interpretations;Natural Language Processing;Feature Interaction;,52;52;52,107;107;107,f;m,usa,usa,n
ICLR,2020,Mem2Mem: Learning to Summarize Long Texts with Memory-to-Memory Transfer,Jaehong Park;Jonathan Pilault;Christopher Pal,jaehong.park@elementai.com;jonathan.pilault@elementai.com;christopher.pal@elementai.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Element AI;Element AI;Element AI,Abstractive summarization;Memory augmented networks;Memory Augmented Encoder Decoder;Memory transfer;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Improving Neural Abstractive Summarization Using Transfer Learning and Factuality-Based Evaluation: Towards Automating Science Journalism,Rumen Dangovski*;Michelle Shen*;Dawson Byrd*;Li Jing*;Preslav Nakov;Marin Soljacic,rumenrd@mit.edu;mcshen99@mit.edu;dbyrd@exeter.edu;ljing@mit.edu;pnakov@qf.org.qa;soljacic@mit.edu,1;1;1,,Withdrawn,0,1,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Phillips Exeter Academy;Massachusetts Institute of Technology;IDKT-RDI QF;Massachusetts Institute of Technology,neural abstractive summarization;transfer learning;multitask learning;natural language processing;,5;5;-1;5;-1;5,5;5;-1;5;-1;5,m;m,usa,usa,n
ICLR,2020,Higher-order Weighted Graph Convolutional Networks,Songtao Liu;Lingwei Chen;Hanze Dong;Zihao Wang;Dinghao Wu;Zengfeng Huang,stliu15@fudan.edu.cn;lvc5613@psu.edu;hdongaj@ust.hk;zzw166@psu.edu;duw12@psu.edu;huangzf@fudan.edu.cn,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Fudan University;Pennsylvania State University;The Hong Kong University of Science and Technology;Pennsylvania State University;Pennsylvania State University;Fudan University,Graph Convolutional Networks;Lasso;Classification;Higher-order neighbors;,73;43;-1;43;43;73,109;-1;47;-1;-1;109,m;m,asia,cn,y
ICLR,2020,Distilling Neural Networks for Faster and Greener Dependency Parsing,Mark Anderson;Carlos G√≥mez-Rodr√≠guez,mark.anderson.nlp@gmail.com;carlos.gomez@udc.es,3;6;1,,Withdrawn,0,5,,yes,9/25/19,Universidade da Coru√±a;Universidade da Coru√±a,dependency parsing;efficiency;green AI;compression;distillation;syntax;NLP;,-1;-1,-1;-1,m;m,NAN,NAN,n
ICLR,2020,From Here to There: Video Inbetweening Using Direct 3D Convolutions,Yunpeng Li;Dominik Roblek;Marco Tagliasacchi,yunpeng@google.com;droblek@google.com;mtagliasacchi@google.com,3;3;3,,Withdrawn,0,1,,yes,9/25/19,Google;Google;Google,Computer vision;video generation;generative models;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,ON SOLVING COOPERATIVE DECENTRALIZED MARL PROBLEMS WITH SPARSE REINFORCEMENTS,Rajiv Ranjan Kumar;Pradeep Varakantham,rajivrk.2017@phdis.smu.edu.sg;pradeepv@smu.edu.sg,1;6;1,,Withdrawn,0,0,,yes,9/25/19,Singapore Management University;Singapore Management University,Deep Reinforcement Learning;Cooperative Multi Agent Systems;Sparse Reward;Decentralized Decision Making;,79;79,-1;-1,m;m,asia,sg,n
ICLR,2020,On the Anomalous Generalization of GANs,Jinchen Xuan;Yunchang Yang;Ze Yang;Di He;Liwei Wang,1600012865@pku.edu.cn;1500010650@pku.edu.cn;yangze@pku.edu.cn;dihe@microsoft.com;wanglw@cis.pku.edu.cn,1;3;6,,Withdrawn,0,0,,yes,9/25/19,Peking University;Peking University;Peking University;Microsoft;Peking University,GANs;Generalization;,14;14;14;-1;14,24;24;24;-1;24,m;m,asia,cn,y
ICLR,2020,Bridging the domain gap in cross-lingual document classification,Guokun Lai;Barlas Oguz;Yiming Yang;Veselin Stoyanov,guokun@cs.cmu.edu;barlaso@fb.com;yiming@cs.cmu.edu;ves@fb.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Facebook;Carnegie Mellon University;Facebook,cross-lingual;document classification;semi-supervised learning;,1;-1;1;-1,27;-1;27;-1,m;m,NAN,NAN,n
ICLR,2020,NAMSG: An Efficient Method for Training Neural Networks,Yushu Chen;Hao Jing;Wenlai Zhao;Zhiqiang Liu;Ouyi Li;Liang Qiao;Haohuan Fu;Wei Xue;Guangwen Yang,yschen11@126.com;jinghao0320@gmail.com;cryinlaugh@gmail.com;gt_liuzq@163.com;18801087946@163.com;qiaoliang6363@163.com;haohuan@tsinghua.edu.cn;xuewei@mail.tsinghua.edu.cn;ygw@mail.tsinghua.edu.cn,3;3;1,,Withdrawn,2,4,,yes,9/25/19,"126;;;163;163;163;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University;Tsinghua University, Tsinghua University",neural networks;training;adaptive methods;,-1;-1;-1;-1;-1;-1;4;4;4,-1;-1;-1;-1;-1;-1;23;23;23,f;m,NAN,NAN,y
ICLR,2020,INTERPRETING CNN  PREDICTION THROUGH  LAYER - WISE SELECTED DISCERNIBLE NEURONS,Md Tauhid Bin Iqbal;Abdul Muqeet;Sung-Ho Bae,tauhidiq@khu.ac.kr;amuqeet@khu.ac.kr;shbae@khu.ac.kr,1;3;1,,Withdrawn,0,0,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,,445;445;445,319;319;319,m;m,asia,kr,n
ICLR,2020,Toward Controllable Text Content Manipulation,Shuai Lin;Wentao Wang;Zhiting Hu;Zichao Yang;Xiaodan Liang;Haoran Shi;Frank Xu;Eric Xing,shuailin97@gmail.com;wwt.cpp@gmail.com;zhitinghu@gmail.com;yangtze2301@gmail.com;xdliang328@gmail.com;haoranshi97@gmail.com;eric.xing@petuum.com,3;1;6,,Withdrawn,0,0,,yes,9/25/19,"Sun Yat-sen University;Peking University;University of California, San Diego;;;;Petuum Inc.",,-1;14;-1;-1;-1;-1;-1,-1;24;31;-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality Regularization and Singular Value Sparsification,Huanrui Yang;Minxue Tang;Wei Wen;Feng Yan;Daniel Hu;Ang Li;Hai Li,huanrui.yang@duke.edu;tangmx16@mails.tsinghua.edu.cn;wei.wen@duke.edu;fyan@unr.edu;danielhu2003@gmail.com;ang.li630@duke.edu;hai.li@duke.edu,3;1,,Withdrawn,0,0,,yes,9/25/19,"Duke University;Tsinghua University, Tsinghua University;Duke University;University of Nevada, Reno;;Duke University;Duke University",Deep neural network;low-rank factorization;singular value decomposition;,46;4;46;248;-1;46;46,20;23;20;-1;-1;20;20,m;f,europe,se,n
ICLR,2020,FAST LEARNING VIA EPISODIC MEMORY: A PERSPECTIVE FROM ANIMAL DECISION-MAKING,Xiaohan Zhang;Lu Liu;Guodong Long;jing jiang;Shenquan Liu,xh1315255662@gmail.com;lu.liu.cs@icloud.com;guodong.long@uts.edu.au;jing.jiang@uts.edu.au;mashqliu@scut.edu.cn,1;1,,Withdrawn,0,0,,yes,9/25/19,South China University of Technology;Icloud;University of Technology Sydney;University of Technology Sydney;South China University of Technology,neuroscience;cognitive science;memory;perception;,-1;-1;73;73;-1,-1;-1;193;193;501,f;u,NAN,NAN,pdf miss
ICLR,2020,Improving and Stabilizing Deep Energy-Based Learning,Lifu Tu;Richard Yuanzhe Pang;Kevin Gimpel,lifu@ttic.edu;yzpang@nyu.edu;kgimpel@ttic.edu,6;1;1,,Withdrawn,0,0,,yes,9/25/19,Toyota Technological Institute at Chicago;New York University;Toyota Technological Institute at Chicago,deep structured prediction;energy-based learning;inference networks;sequence labeling;training objectives;,-1;22;-1,-1;29;-1,m;m,NAN,NAN,n
ICLR,2020,INTERPRETING CNN COMPRESSION USING INFORMATION BOTTLENECK,Hui Xiang;Feifei Shi;Peng Wang;Qigang Wang;Zhongchao Shi,xianghui1@lenovo.com;shiff3@lenovo.com;wangpeng31@lenovo.com;wangqg1@lenovo.com;shizc2@lenovo.com,1;1;1,,Withdrawn,0,0,,yes,9/25/19,Lenovo Research;Lenovo Research;Lenovo Research;Lenovo Research;Lenovo Research,Learning Representation;Information Bottleneck;Model Compression;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,m;m,NAN,NAN,pdf miss
ICLR,2020,Conversation Generation with Concept Flow,Houyu Zhang;Zhenghao Liu;Chenyan Xiong;Zhiyuan Liu,houyu_zhang@brown.edu;liu-zh16@mails.tsinghua.edu.cn;chenyan.xiong@microsoft.com;liuzy@tsinghua.edu.cn,6;3;3,,Withdrawn,0,0,,yes,9/25/19,"Brown University;Tsinghua University, Tsinghua University;Microsoft;Tsinghua University, Tsinghua University",Grounded Natural Language Generation;Conversation Response Generation;ConceptNet;ConceptFlow;Conversation Flow;,85;4;-1;4,53;23;-1;23,m;m,NAN,NAN,n
ICLR,2020,iSOM-GSN: An Integrative Approach for Transforming Multi-omic Data into Gene Similarity Networks via Self-organizing Maps,Nazia Fatima;Johan Fernandes;Luis Rueda,fatiman@uwindsor.ca;ferna11i@uwindsor.ca;lrueda@uwindsor.ca,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Windsor;University of Windsor;University of Windsor,Gene similarity networks;self-organizing maps;convolutional neural networks;multi-omics data integration;graph representation learning;dimensionality reduction;,445;445;445,605;605;605,f;m,canada,ca,n
ICLR,2020,Task-Agnostic Robust Encodings for Combating Adversarial Typos,Erik Jones;Robin Jia;Aditi Raghunathan;Percy Liang,erik.jones313@gmail.com;robinjia@stanford.edu;aditir@stanford.edu;pliang@cs.stanford.edu,3;3;3,,Withdrawn,0,4,,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,Natural language processing;adversarial examples;robustness;,-1;5;5;5,-1;4;4;4,m;m,usa,usa,n
ICLR,2020,Natural Language Adversarial Attack and Defense in Word Level,Xiaosen Wang;Hao Jin;Kun He,xiaosen@hust.edu.cn;mailtojinhao@hust.edu.cn;brooklet60@hust.edu.cn,6;3;3,,Withdrawn,0,2,,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,adversarial examples;text adversarial defense;text adversarial attack;synonym encoding;natural language processing;,-1;-1;-1,47;47;47,m;f,NAN,NAN,n
ICLR,2020,Randomness in Deconvolutional Networks for Visual Representation,Kun He;Jingbo Wang;Haochuan Li;Yao Shu;Liwei Wang;John E. Hopcroft,brooklet60@hust.edu.cn;jingbow@usc.edu;lhchuan@pku.edu.cn;shuyao95@gmail.com;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,1;3;3,,Withdrawn,0,0,,yes,9/25/19,Hong Kong University of Science and Technology;University of Southern California;Peking University;;Peking University;Cornell University,Deep representation;random representation;untrained deconvolutional network;image reconstruction;,-1;36;14;-1;14;7,47;62;24;-1;24;19,f;m,usa,usa,y
ICLR,2020,An Inter-Layer Weight Prediction and Quantization for Deep Neural Networks based on Smoothly Varying Weight Hypothesis,Kang-Ho Lee;JoonHyun Jung;Sung-Ho Bae,ho7719@khu.ac.kr;doublejtoh@khu.ac.kr;shbae@khu.ac.kr,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,Network Compression;Quantization;Weight Prediction;,445;445;445,319;319;319,m;m,asia,kr,n
ICLR,2020,Generalized Transformation-based Gradient,Anbang Wu,wab@zju.edu.cn,3;1;6,,Withdrawn,0,3,,yes,9/25/19,Zhejiang University,variational inference;stochastic optimization;stochastic gradient;,39,107,u,asia,cn,n
ICLR,2020,Learning Multi-facet Embeddings of Phrases and Sentences using Sparse Coding for Unsupervised Semantic Applications,Haw-Shiuan Chang;Amol Agrawal;Andrew McCallum,hschang@cs.umass.edu;amolagrawal@cs.umass.edu;mccallum@cs.umass.edu,3;3;3,,Withdrawn,0,1,,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",lexical semantics;sparse coding;multi-mode embeddings;unsupervised sentence embedding;clustering;set decoder;semantic similarity;,24;24;24,209;209;209,m;m,usa,usa,n
ICLR,2020,Making DenseNet Interpretable: A Case Study in Clinical Radiology,Kwun Ho Ngan;Artur d'Avila Garcez;Karen M. Knapp;Andy Appelboam;Constantino Carlos Reyes-Aldasoro,kwun-ho.ngan@city.ac.uk;a.garcez@city.ac.uk;k.m.knapp@exeter.ac.uk;andy.appelboam@nhs.net;reyes@city.ac.uk,1;1;3,,Withdrawn,0,1,,yes,9/25/19,"City, University of London;City, University of London;University of Exeter;;City, University of London",Model Interpretation;Medical Image Analysis;Deep Learning;,248;248;316;-1;248,422;422;146;-1;422,m;m,europe,uk,n
ICLR,2020,Learning Classifier Synthesis for Generalized Few-Shot Learning,Han-Jia Ye;Hexiang Hu;De-Chuan Zhan;Fei Sha,yehj@lamda.nju.edu.cn;hexiang.frank.hu@gmail.com;zhandc@nju.edu.cn;feisha@usc.edu,3;3;1,,Withdrawn,0,1,,yes,9/25/19,Zhejiang University;;Zhejiang University;University of Southern California,Generalized Few-Shot Learning (GFSL);Few-Shot Learning;Meta-Learning;,39;-1;39;36,107;-1;107;62,m;m,usa,usa,n
ICLR,2020,Restoration of Video Frames from a Single Blurred Image with Motion Understanding,Dawit Mureja Argaw;Junsik Kim;Francois Rameau;Chaoning Zhang;In so Kweon,dawitmureja@kaist.ac.kr;mibastro@gmail.com;rameau.fr@gmail.com;chaoningzhang1990@gmail.com;iskweon77@kaist.ac.kr,3;6;3,,Withdrawn,0,0,,yes,9/25/19,Korea Advanced Institute of Science and Technology;;;;Korea Advanced Institute of Science and Technology,Blur-to-Video;Motion deblurring;Encoder-Decoder;,-1;-1;-1;-1;-1,110;-1;-1;-1;110,m;m,NAN,NAN,n
ICLR,2020,Open-Set Domain Adaptation with Category-Agnostic Clusters,Yingwei Pan;Ting Yao;Yehao Li;Chong-Wah Ngo;Tao Mei,panyw.ustc@gmail.com;tingyao.ustc@gmail.com;yehaoli.sysu@gmail.com;cscwngo@cityu.edu.hk;tmei@live.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,JD AI Research;JD AI Research;;The Hong Kong Polytechnic University;JD AI Research,Unsupervised Domain Adaptation;Open-set Domain Adaptation;Category-agnostic Clusters;,-1;-1;-1;118;-1,-1;-1;-1;171;-1,m;m,NAN,NAN,n
ICLR,2020,Understanding Distributional Ambiguity via Non-robust Chance Constraint,Shumin MA;LEUNG Cheuk Hang;Qi WU;Wei Liu,shuminma@cityu.edu.hk;chleung87@cityu.edu.hk;qiwu55@cityu.edu.hk;wl2223@columbia.edu,3;1;3,,Withdrawn,0,0,,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Columbia University,Heavy tail distribution;Chance constraint;Distributionally robust optimization;,118;118;118;24,171;171;171;16,m;m,usa,usa,y
ICLR,2020,Simple but effective techniques to reduce dataset biases,Rabeeh Karimi Mahabadi;James Henderson,rkarimi@idiap.ch;james.henderson@idiap.ch,3;6;1,,Withdrawn,0,1,,yes,9/25/19,Idiap Research Institute;Idiap Research Institute,bias reduction;natural language inference;robust models;out-of-domain performance;,-1;-1,-1;-1,f;m,NAN,NAN,n
ICLR,2020,EfferenceNets for latent space planning,Hlynur Dav√≠√∞ Hlynsson;Merlin Sch√ºler;Robin Schiewer;Laurenz Wiskott,hlynurd@gmail.com;merlin.schueler@ini.rub.de;robin.schiewer@ini.rub.de;laurenz.wiskott@ini.rub.de,1;1;1,,Withdrawn,0,0,,yes,9/25/19,KTH Royal Institute of Technology;Ruhr-Universt‚àö¬ßt Bochum;Ruhr-Universt‚àö¬ßt Bochum;Ruhr-Universt‚àö¬ßt Bochum,Informed Search;Deep Learning;Heuristics;Transfer Learning;Efference Theory;,-1;-1;-1;-1,-1;-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Mining GANs for knowledge transfer to small domains,Yaxing Wang;Abel Gonzalez-Garcia;David Berga;Luis Herranz;Fahad Shahbaz Khan;Joost van de Weijer,yaxing@cvc.uab.es;agonzalez@cvc.uab.es;dberga@cvc.uab.es;lherranz@cvc.uab.es;fahad.khan@liu.se;joost@cvc.uab.es,3;3;3,,Withdrawn,0,0,,yes,9/25/19,"Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Computer Vision Center, Universitat Aut√≤noma de Barcelona;Link√∂ping University;Computer Vision Center, Universitat Aut√≤noma de Barcelona",Generative adversarial networks;transferring learning;small domains;deep Learning;,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;407;-1,m;m,NAN,NAN,n
ICLR,2020,"EMS: End-to-End Model Search for Network Architecture, Pruning and Quantization",Tianzhe Wang;Kuan Wang;Han Cai;Ji Lin;Yujun Lin;Zhijian Liu;Song Han,usedtobe@mit.edu;wangkuan15@mails.tsinghua.edu.cn;hancai@mit.edu;jilin@mit.edu;yujunlin@mit.edu;zhijian@mit.edu;songhan@mit.edu,3;1;1,,Withdrawn,1,0,,yes,9/25/19,"Massachusetts Institute of Technology;Tsinghua University, Tsinghua University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology",End-to-end Design;Joint Optimization;Architecture Search;Network Pruning;Network Quanzation;,5;4;5;5;5;5;5,5;23;5;5;5;5;5,m;m,usa,usa,n
ICLR,2020,Deflecting Adversarial Attacks,Yao Qin;Nicholas Frosst;Colin Raffel;Garrison Cottrell;Geoffrey Hinton,yaq007@eng.ucsd.edu;frosst@google.com;craffel@google.com;gary@eng.ucsd.edu;geoffhinton@google.com,3;3;3,,Withdrawn,0,2,,yes,9/25/19,"University of California, San Diego;Google;Google;University of California, San Diego;Google",Adversarial Examples;,-1;-1;-1;-1;-1,31;-1;-1;31;-1,f;m,NAN,NAN,n
ICLR,2020,One Demonstration Imitation Learning,Bradly C. Stadie;Siyan Zhao;Qiqi Xu;Bonnie Li;Lunjun Zhang,bstadie@berkeley.edu;siyan.zhao@mail.utoronto.ca;frances.xu@mail.utoronto.ca;bonnieli20010901@gmail.com;lunjun.zhang@mail.utoronto.ca,1;1;3,,Withdrawn,0,0,,yes,9/25/19,University of California Berkeley;Toronto University;Toronto University;;Toronto University,imitation learning;one shot imitation learning;reinforcement learning;exploration;representation learning;,-1;-1;-1;-1;-1,13;-1;-1;-1;-1,m;u,NAN,NAN,pdf miss
ICLR,2020,SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering,Chenguang Zhu;Michael Zeng;Xuedong Huang,chezhu@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com,3;3;3,,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Microsoft,Machine Reading Comprehension;Conversational Question Answering;,-1;-1;-1,-1;-1;-1,m;m,NAN,NAN,n
ICLR,2020,Differentially Private Survival Function Estimation,Lovedeep Gondara;Ke Wang,lgondara@sfu.ca;wang@sfu.ca,1;1;3,,Withdrawn,0,1,,yes,9/25/19,Simon Fraser University;Simon Fraser University,Survival function;differential privacy;healthcare;,52;52,272;272,m;m,canada,ca,n
ICLR,2020,GPU Memory Management for Deep Neural Networks Using Deep Q-Network,Shicheng Chen,coder.chen.shi.cheng@gmail.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,0,GPU memory management;deep reinforcement learning;neural networks;,,,u,NAN,NAN,n
ICLR,2020,Meta Decision Trees for Explainable Recommendation Systems,Eyal Shulman;Lior Wolf,shulmaneyal@gmail.com;wolf@fb.com,3;8;3,,Withdrawn,0,1,,yes,9/25/19,Tel Aviv University;Facebook,,30;-1,188;-1,m;m,NAN,NAN,n
ICLR,2020,Parameterized Action Reinforcement Learning for Inverted Index Match Plan Generation,Linfeng Zhao;Lifei Zhu;Qi Chen;Hui Xue;Haidong Wang;Chuanjie Liu;Yuan Liu;Lawson Wong;Lintao Zhang,zhao.linf@husky.neu.edu;v-lifzh@microsoft.com;cheqi@microsoft.com;xuehui@microsoft.com;haidwa@microsoft.com;chuanli@microsoft.com;yuanliu@neu.edu.cn;lawsonlsw@northeastern.edu;lintaoz@microsoft.com,3;3;1,,Withdrawn,0,5,,yes,9/25/19,Northeastern University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Northeastern University;Northeastern University;Microsoft,,16;-1;-1;-1;-1;-1;16;16;-1,906;-1;-1;-1;-1;-1;906;906;-1,m;m,NAN,NAN,n
ICLR,2020,Fault Tolerant Reinforcement Learning via A Markov Game of Control and Stopping,David Mguni,davidmguni@hotmail.com,3;1;3,,Withdrawn,0,0,,yes,9/25/19,Prowler.io,Fault-Tolerance;Robust Control;Reinforcement Learning;Stochastic Games;Markov Games;Optimal Stopping;,-1,-1,m,NAN,NAN,y
ICLR,2020,Fuzzing-Based Hard-Label Black-Box Attacks Against Machine Learning Models,Yi Qin;Chuan Yue,yiqin@mines.edu;chuanyue@mines.edu,3;1;1,,Withdrawn,0,5,,yes,9/25/19,Colorado School of Mines;Colorado School of Mines,,248;248,343;343,u;m,usa,usa,n
ICLR,2020,"Read, Highlight and Summarize: A Hierarchical Neural Semantic Encoder-based Approach",Rajeev Bhatt Ambati;Saptarashmi Bandyopadhyay;Prasenjit Mitra,rajeev24811@gmail.com;sbandyo20@gmail.com;pum10@psu.edu,3;1,,Withdrawn,0,0,,yes,9/25/19,"Pennsylvania State University;University of Maryland, College Park;Pennsylvania State University",Abstractive summarization;text summarization;memory augmented neural network;extractive summarization;self critical reinforcement learning;policy gradient;,-1;12;43,-1;91;-1,m;m,usa,usa,n
ICLR,2020,Generalization Puzzles in Deep Networks,Qianli Liao;Brando Miranda;Lorenzo Rosasco;Andrzej Banburski;Robert Liang;Jack Hidary;Tomaso Poggio,lql@mit.edu;miranda9@illinois.edu;lrosasco@mit.edu;kappa666@mit.edu;bobliang345@gmail.com;hidary@google.com;tp@csail.mit.edu,1;1;6,,Withdrawn,0,3,,yes,9/25/19,"Massachusetts Institute of Technology;University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Google;Massachusetts Institute of Technology",deep learning;theory;generalization;cross-entropy loss;overfitting;,5;-1;5;5;-1;-1;5,5;-1;5;5;-1;-1;5,m;m,usa,usa,n
ICLR,2020,Recurrent Chunking Mechanisms for Conversational Machine Reading Comprehension,Hongyu Gong;Yelong Shen;Dian Yu;Jianshu Chen;Dong Yu,hgong6@illinois.edu;yelongshen@tencent.com;yudian@tencent.com;jianshuchen@tencent.com;dyu@tencent.com,6;3;1,,Withdrawn,0,8,,yes,9/25/19,"University of Illinois, Urbana Champaign;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab",Recurrent Chunking Policy;Machine Reading Comprehension;Reinforcement Learning;,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,f;m,NAN,NAN,n
ICLR,2020,Rethinking Generalized Matrix Factorization for Recommendation: The Importance of Multi-hot Encoding,Lei Feng;Hongxin Wei;Qingyu Guo;Zhuoyi Lin;Bo An,feng0093@e.ntu.edu.sg;owenwei@ntu.edu.sg;qguo005@e.ntu.edu.sg;zhuoyi001@e.ntu.edu.sg;boan@ntu.edu.sg,3;3;1,,Withdrawn,0,0,,yes,9/25/19,Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University;Nanyang Technological University,supervised representation learning;recommender systems;,43;43;43;43;43,49;49;49;49;49,m;m,asia,sg,n
ICLR,2020,Extractor-Attention Network: A New Attention Network with Hybrid Encoders for Chinese Text Classification,Junhao Qiu;Ronghua Shi;Fangfang Li (the corresponding author);Jinjing Shi;Wangmin Liao,qiujunhao@csu.edu.cn;shirh@csu.edu.cn;lifangfang@csu.edu.cn;shijinjing@csu.edu.cn;0909123117@csu.edu.cn,1;6;1,,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,,-1;-1;-1;-1;-1,299;299;299;299;299,m;u,NAN,NAN,n
ICLR,2020,Fooling Pre-trained Language Models: An Evolutionary Approach to Generate Wrong Sentences with High Acceptability Score,Marco Di Giovanni;Marco Brambilla,marco.digiovanni@polimi.it;marco.brambilla@polimi.it,3;3;1,,Withdrawn,0,6,,yes,9/25/19,Politecnico di Milano;Politecnico di Milano,Pre-trained Language Models;Adversarial Attack;Evolutionary Algorithm;BERT;RoBERTa;CoLA;,143;143,-1;-1,m;m,europe,it,n
ICLR,2020,The Convex Information Bottleneck Lagrangian,Borja Rodr√≠guez G√°lvez;Ragnar Thobaben;Mikael Skoglund,borjarg@kth.se;ragnart@kth.se;skoglund@kth.se,3;3;1,,Withdrawn,0,5,,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",information bottleneck;representation learning;,194;194;194,222;222;222,m;m,NAN,NAN,y
ICLR,2020,Deep Learning-Based Average Consensus,Masako Kishida;Masaki Ogura;Yuichi Yoshida;Tadashi Wadayama,kishida@nii.ac.jp;oguram@is.naist.jp;yyoshida@nii.ac.jp;wadayama@nitech.ac.jp,1;1;3,,Withdrawn,0,4,,yes,9/25/19,"National Institute of Informatics;Nara Institute of Science and Technology, Japan;National Institute of Informatics;Nagoya Institute of Technology",complex network;optimization;deep-learning;,-1;-1;-1;-1,-1;-1;-1;1157,u;m,NAN,NAN,y
ICLR,2020,STYLE EXAMPLE-GUIDED TEXT GENERATION USING GENERATIVE ADVERSARIAL TRANSFORMERS,Kuo-Hao Zeng;Mohammad Shoeybi;Ming-Yu Liu,khzeng@cs.washington.edu;mshoeybi@nvidia.com;sean.mingyu.liu@gmail.com,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of Washington;NVIDIA;NVIDIA,Language generation;Transformer;GANs;,11;-1;-1,26;-1;-1,m;m,asia,in,n
ICLR,2020,GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,1;1,,Withdrawn,0,0,,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,deep learning;graph neural networks;natural language processing;reading comprehension;,248;194;248,438;-1;438,f;m,usa,usa,n
ICLR,2020,Revisiting the Information Plane,Martin Schiemer;Juan Ye,martin.schiemer@web.de;juan.ye@st-andrews.ac.uk,3;3;1,,Withdrawn,0,0,,yes,9/25/19,University of St Andrews;University of St Andrews,Deep Learning;Information Theory;Information Bottleneck;Neural Network Design;,-1;316,-1;201,m;f,europe,uk,n
ICLR,2020,Fully Quantized Transformer for Improved Translation,Gabriele Prato;Ella Charlaix;Mehdi Rezagholizadeh,prato.gab@gmail.com;ella.charlaix@huawei.com;mehdi.rezagholizadeh@huawei.com,3;1;3,,Withdrawn,0,3,,yes,9/25/19,University of Montreal;Huawei Technologies Ltd.;Huawei Technologies Ltd.,Transformer;quantization;machine translation;compression;pruning;,118;-1;-1,85;-1;-1,f;m,NAN,NAN,n