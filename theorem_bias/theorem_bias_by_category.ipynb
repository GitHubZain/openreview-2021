{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../openreview.csv')\n",
    "binary_decisions = {'Accept (Oral)':1, 'Accept (Poster)':1, 'Accept (Spotlight)':1, 'Accept (Talk)':1, 'Withdrawn':0, 'Reject':0, 'Invite to Workshop Track':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(cat):\n",
    "    scores =[]\n",
    "    theorem_indicator=[]\n",
    "    target=[]\n",
    "\n",
    "    for rating, decision, theorem, category in zip(data['ratings'], data['decisions'], data['theorem'], data['categories_list']):\n",
    "        if theorem == 'pdf miss':\n",
    "            continue\n",
    "        try:\n",
    "            category_list = category.split(';')\n",
    "            found = False\n",
    "            for c in category_list: \n",
    "                if int(c)==cat:\n",
    "                    found=True\n",
    "                    break\n",
    "            if not(found): continue\n",
    "        except: continue\n",
    "\n",
    "        if theorem =='y':\n",
    "            theorem_indicator.append(1)\n",
    "        else:\n",
    "            theorem_indicator.append(0)\n",
    "\n",
    "        avg_rating=0\n",
    "        for i in rating.split(';'):\n",
    "            avg_rating += int(i)\n",
    "        scores.append(avg_rating/len(rating.split(';')))\n",
    "\n",
    "        target.append(binary_decisions[decision])\n",
    "\n",
    "    x=pd.DataFrame()\n",
    "    x['mean reviewer score']=scores\n",
    "    x['theorem']=theorem_indicator\n",
    "    x['constant']=[1]*len(scores)\n",
    "    y=np.array(target)\n",
    "\n",
    "    logit_model = sm.Logit(y, x)\n",
    "    summary = logit_model.fit().summary()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=0)\n",
    "    logisticRegr = LogisticRegression(random_state=0)\n",
    "    model = logisticRegr.fit(x_train, y_train)\n",
    "    accuracy = logisticRegr.score(x_test, y_test)\n",
    "\n",
    "    return summary, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591442\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  308\n",
      "Model:                          Logit   Df Residuals:                      306\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 02 Oct 2021   Pseudo R-squ.:                0.006428\n",
      "Time:                        21:13:16   Log-Likelihood:                -182.16\n",
      "converged:                       True   LL-Null:                       -183.34\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1247\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theorem        0.4187      0.271      1.547      0.122      -0.112       0.949\n",
      "constant      -1.0622      0.155     -6.852      0.000      -1.366      -0.758\n",
      "==============================================================================\n",
      "Accuracy:  0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "summary, score = logistic_regression(11)\n",
    "print(summary)\n",
    "print('Accuracy: ', score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
